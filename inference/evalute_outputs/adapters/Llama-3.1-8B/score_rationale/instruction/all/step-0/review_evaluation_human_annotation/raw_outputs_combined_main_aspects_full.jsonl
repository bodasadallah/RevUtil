{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and out-of-context images. The reviewer implies that more analysis is needed to assess the dataset\\'s quality and potential noise. While the comment highlights an important area for improvement, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the dataset\\'s quality but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and out-of-context images. However, it does not specify which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing the concern about the dataset\\'s quality and suggesting additional analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and out-of-context images. The reviewer provides a logical reasoning by pointing out that the dataset is artificially created, which could introduce noise. However, the comment lacks specific examples or references to support the claim about the dataset\\'s quality, making it somewhat verifiable. The authors would need to conduct additional analysis to address this concern, but the comment provides a clear direction for further investigation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and out-of-context images. This is an important point that the authors should address to ensure the robustness and validity of their analysis. The comment provides a clear direction for improvement by suggesting that more analysis is needed around the quality of the dataset and the potential noise it might contain. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what aspects of the theory should be investigated or how to demonstrate convergence properties. Without specific instructions or examples, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references to specific sections or examples, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the theory should be explored or how convergence properties could be demonstrated. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks an exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the theory are missing or how convergence could be demonstrated, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it lacks an exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. This is a critical area that could enhance the understanding and applicability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular theoretical analyses or experiments to conduct. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of operators used in the paper, specifically questioning why the \"and\" operator or element-wise max were not considered. While the comment implies that the authors should provide a rationale for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain their reasoning. However, the comment does provide a clear direction for the authors to consider, which makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or element-wise max, which corresponds to the ideas of union and intersection from the \"or\" operator and element-wise min. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of operators used in the paper, specifically asking why the \"and\" operator or element-wise max were not considered. The reviewer provides a logical reasoning by suggesting that these operators correspond to the ideas of union and intersection, respectively, which are related to the \"or\" operator and element-wise min. However, the comment lacks specific examples or references to support the claim that these operators are better options. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors may need to provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the choice of operators used in the paper, specifically questioning why the \"and\" operator or element-wise max were not considered. It suggests that these operators might correspond to the ideas of union and intersection, respectively, and that the current choice of operators is not clear. This feedback is somewhat helpful as it prompts the authors to consider alternative operators and provide a rationale for their choice. However, the comment could be more helpful if it offered specific suggestions or examples of how these alternative operators might be applied or why they are better options. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment identifies a potential issue with the description and suggests a possible reason for concern, it does not provide explicit guidance on how to clarify the description or address the potential noise issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the description and potentially explore alternative approaches. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by describing the unclear description of HIERENC and providing a detailed explanation of what is unclear. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate the reasoning to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires additional evidence or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, suggesting that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, noting that only one of these instantiations is likely to be correct and that this could introduce noise. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and provides a logical reasoning for why it might be problematic. By pointing out this issue, the comment empowers the authors to reconsider their approach and potentially improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area that needs attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it implies that the authors should provide an explanation or justification for this selection, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and its potential impact on performance estimation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential confusion in the paper regarding the selection of sentences from raw data versus those with syntactic information. It suggests that the description could be revised to clarify the source of the data, specifically mentioning Li et al. (2019a) earlier. While the comment implies that the authors should revise the description to make it clearer, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors know they need to clarify the description but may not be sure of the exact changes needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (226-238 and 242-244) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the apparent contradiction between suggesting the selection of sentences from raw data and the presence of syntactic information. The comment further suggests that the data selected is a subset of Li et al. (2019a)\\'s dataset and recommends revising the description to clarify this. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a potential contradiction in the paper regarding the selection of sentences from raw data versus those with syntactic information. The reviewer suggests that the data selected is a subset of Li et al. (2019a)\\'s dataset and recommends revising the description to clarify this. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to mention Li et al. (2019a) earlier is a logical step, but the comment could be strengthened with more detailed evidence or references. Therefore, the claim is somewhat verifiable, as it provides a basis for improvement but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the selection of sentences from raw data versus those with syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\\'s dataset and recommends revising the description to clarify this. This feedback is clear and actionable, as it provides a specific suggestion for improvement by mentioning Li et al. (2019a) earlier in the description. By addressing this issue, the authors can enhance the clarity and precision of their work. However, the comment could be more helpful if it included additional context or examples to further guide the authors in making the necessary revisions. Overall, the comment is mostly helpful, as it provides valuable insight and direction for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question about the purpose and content of the reported duration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This is a request for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This feedback is somewhat helpful as it identifies a potential area of confusion or lack of clarity in the paper. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the explanation in the paper. While it prompts the authors to consider the purpose and content of the reported duration, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests clarification regarding the splits used for obtaining the ATIS numbers in Table 4. The comment is clear and direct, providing a specific action for the authors to take. The authors know exactly what needs to be clarified and can address this by providing the necessary information. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by requesting clarification on the splits used for obtaining the ATIS numbers in Table 4. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and transparency of their work. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important. Despite this, the feedback is mostly helpful as it guides the authors toward improving the clarity and completeness of their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential cognitive bias among NLP researchers, suggesting that the wording \"on par or better\" may be misleading. The reviewer recommends correcting this wording but does not provide specific guidance on how to do so. While the action is explicit, it lacks concrete details on how to implement the suggested change, leaving the authors with a general direction but no clear steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias among NLP researchers and suggests that the wording \"on par or better\" should be corrected. The comment provides a clear direction for improvement by specifying what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a general cognitive bias among NLP researchers, suggesting that instances where they perform worse are mapped to \"on par\" and all the rest to \"better.\" The reviewer recommends correcting this wording. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it provides a general observation but lacks the necessary depth to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential cognitive bias among NLP researchers, specifically pointing out the use of the phrase \"on par or better\" in the paper. It suggests that this wording may be misleading and recommends correcting it. While the comment highlights a specific issue, it does not provide detailed guidance on how to correct the wording or why it might be misleading. Additionally, the comment does not offer any suggestions for improving the experimental results beyond this wording correction. Therefore, the feedback is somewhat helpful, as it points out a potential issue but lacks depth and actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOS-V. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these questions or improve their interpretation of the results. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the interpretation of the results, particularly regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOS-V. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOS-V. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOS-V. While it identifies areas of potential confusion or ambiguity, it does not provide any suggestions or guidance on how the authors might address these issues or clarify the results. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point points out a specific issue with the formatting of Table 2 and Table 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is explicit and provides a clear action for the authors to take, which is to ensure consistency in the formatting across all items in the tables. However, the comment does not specify how the authors should address this issue, such as whether they should remove the spaces or add them consistently. While the action is explicit, the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent spacing between accuracy and standard deviation, which affects the beauty of the tables. This provides clear guidance on what needs to be addressed to improve the presentation of the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the formatting of tables, specifically noting inconsistencies in the spacing between accuracy and standard deviation. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a specific formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is relevant and could affect the visual appeal of the tables. However, the comment does not provide any guidance on how to address this issue or why it is important, leaving the authors without actionable feedback on how to improve their draft. While it identifies a potential problem, the lack of detailed suggestions or explanations makes the comment barely helpful, as it does not offer a clear path for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the references, such as missing antecedents and incorrect capitalization or bibliographic details. It provides explicit actions for the authors to take, such as checking the references for format and correcting any errors. The feedback is clear and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"both tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on checking the references for format, such as capitalization and bibliographic details. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification, such as checking the references for format and correcting capitalization errors. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific issues with the references, such as missing antecedents and incorrect capitalization or bibliographic details. It provides clear and actionable feedback by suggesting that the authors check the references for format and correct any errors. This guidance is valuable as it directly addresses a concrete issue that could impact the clarity and accuracy of the paper. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the references. Overall, the feedback is mostly helpful as it provides clear actions for the authors to take, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and image-text models, and that the related work section nicely summarizes this. The reviewer suggests that the only new effort is to apply similar ideas to video-text models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of novelty or improve their work. Without actionable suggestions or a clear direction for improvement, the authors are left without a path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the lack of novelty in the paper, specifically regarding adversarial attacks by perturbing text. It references the related work section, suggesting that the only new effort is to apply similar ideas to video-text models. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the lack of novelty, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, specifically regarding adversarial attacks by perturbing text. It supports this claim by referencing related work that has already explored this concept on NLP models and image-text models. The reviewer further notes that the only new effort is to apply similar ideas to video-text models. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the related work mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the paper for lacking novelty, specifically in the context of adversarial attacks by perturbing text. It acknowledges that this concept has been explored in related work, but suggests that the only new effort is to apply it to video-text models. While the comment identifies a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback lacks depth and specificity, leaving the authors without a clear path for improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it had separate paragraphs dedicated to each of the lexical features and sentence-level features. While the comment provides a clear action for the authors to take\u2014organizing the section into separate paragraphs\u2014it does not offer detailed guidance on how to implement this change or what specific content should be included in each paragraph. The action is explicit but somewhat vague, as the authors know what needs to be done but may need further guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations for features being intertwined and confusing, and it provides a suggestion for improvement by recommending separate paragraphs for lexical features and sentence-level features. This level of detail helps the authors understand what needs to be addressed and how to improve the organization of the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations for features in Section 3.2 are intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs dedicated to each of the lexical features and sentence-level features. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors may need to invest additional effort to understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it were organized with separate paragraphs dedicated to each of the lexical features and sentence-level features. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the clarity and structure of their paper. By following this advice, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it included specific examples or further guidance on how to separate the paragraphs effectively. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of usefulness regarding the dedicated section and experimental results, suggesting that the space allocated for this information is excessive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived issue or suggestions for potential improvements. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the allocation of space for a section and experimental results, suggesting that it is excessive. However, it does not specify which section or results are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. Additionally, the comment lacks specificity regarding what aspects of the section or results are considered not useful. Without clear guidance or examples, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion that the dedicated section and experimental results are not useful, suggesting that the space allocated for them is excessive. However, the comment lacks specific reasoning or examples to support this claim, such as explaining why the information is not useful or how it could be improved. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion that the dedicated section and experimental results are not useful, suggesting that the space allocated for them is excessive. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the section or results are considered not useful or how they could be improved. This makes the comment barely helpful, as it identifies a potential issue but does not offer meaningful guidance for the authors to address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors conduct an ablation study to evaluate the importance of the post-processing steps proposed in the paper. While the comment implies that an ablation study is necessary, it does not explicitly instruct the authors to perform it. The suggestion is concrete in terms of what needs to be done, but it lacks explicit guidance on how to conduct the ablation study. Therefore, the comment is mostly actionable, as the authors know what action to take but need more detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"post-processing steps\" and \"false-positive neurons,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of an ablation study to evaluate the importance of the post-processing steps. The comment provides a clear suggestion for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not demonstrate the importance of the post-processing steps proposed for filtering out \"false-positive\" neurons. The reviewer suggests that an ablation study may be needed to evaluate this importance. However, the comment lacks specific examples or detailed reasoning to support the claim that the post-processing steps are crucial or that an ablation study is necessary. The suggestion is somewhat verifiable, as it provides a logical rationale for conducting an ablation study, but the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the paper\\'s use of integrated gradients for attribution and the proposed post-processing steps to filter out \"false-positive\" neurons. It points out that the paper does not demonstrate the importance of these post-processing steps, suggesting that an ablation study may be needed to evaluate their impact. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by conducting an ablation study. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, given the authors\\' proposed method of matching the head of noun phrases. It questions the applicability of this method when the head word is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or modify their method to handle situations where the head word is not a pronoun. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific concern about the identification of antecedents when the prediction is a pronoun, particularly in the context of the authors\\' proposed method of matching the head of noun phrases. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the proposed method and how it might not handle situations where the head word is not a pronoun. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning the applicability of the authors\\' proposed method of matching the head of noun phrases. The comment highlights a potential issue with the method\\'s limitations, but it does not provide specific examples or detailed reasoning to fully substantiate the claim. While the authors are alerted to a potential weakness, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' proposed method for identifying antecedents when the prediction is a pronoun. It questions how the method would handle situations where the head word is not a pronoun, which is a relevant and important point for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve their method to handle these situations. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to implement this suggestion, such as which models to include or how to structure the comparison. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the comparison of the proposed models with models that only consider different senses but not sememes. It mentions the MST baseline as a potential example and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. This provides some guidance on what needs to be addressed, but it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison of the proposed models to models that only consider different senses but not sememes is unclear. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim. The reasoning is somewhat logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the comparison of the proposed models with models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment provides a clear direction for improvement by recommending the inclusion of more baselines based on related work, which would strengthen the paper. However, the comment could be more helpful if it offered specific suggestions on which models to include or how to structure the comparison. Overall, the feedback is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a suggestion for improving the abstract by pointing out that \"evaluating with gold answers is inconsistent with human evaluation\" and offering an example of the inconsistency, such as models getting ranked differently. This feedback is explicit and provides a concrete action for the authors to take, which is to include an example of the inconsistency in the abstract. The comment clearly guides the authors on how to enhance their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by pointing out an inconsistency in the abstract and offering an example of how it could be addressed. The comment specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract is well-written and intriguing but suggests that it could be improved by addressing an inconsistency in evaluating with gold answers versus human evaluation. The comment provides a specific example of the inconsistency, such as models getting ranked differently, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how this inconsistency affects the paper\\'s contribution. Overall, the claim is mostly verifiable as it provides a clear direction for improvement but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the abstract is well-written and intriguing but suggests a specific area for improvement. It points out an inconsistency in evaluating with gold answers versus human evaluation and provides an example of how this inconsistency could be addressed, such as models getting ranked differently. This feedback is clear and actionable, offering the authors a concrete suggestion for enhancing their draft. By identifying a specific issue and providing a potential solution, the comment empowers the authors to make a targeted improvement to their abstract. Therefore, it is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding how the frame similarity factors and attributes similarity factors are selected. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit, as the authors can infer that they need to provide more detailed information on the selection process, but it lacks concrete steps or examples to guide them. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue regarding the selection of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it might be related to the methodology or results sections, but without explicit references, the comment is weakly grounded. It is specific in detailing the issue of clarity regarding the selection process, which provides some guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. This feedback is somewhat helpful as it points out a potential issue that the authors need to clarify in their paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as by explaining the selection process or providing examples. To be more helpful, the comment could include actionable steps or examples to assist the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include discussions on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. This feedback is explicit in its request for additional discussion, but it lacks concrete guidance on what specific aspects should be included in these discussions. While the authors are given a clear direction to improve their draft, the lack of detailed instructions on how to implement the suggested discussions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for additional discussion on convergence, but without clear grounding, the authors may struggle to identify the exact section where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. The comment implies that without such discussions, it may be difficult to replicate the results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current explanation is insufficient. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks the necessary details to fully substantiate the need for additional discussion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that discussions on the convergence of the proposed joint learning process are needed. It highlights the importance of understanding how stable points in the probabilistic metric space are obtained, which is crucial for replicating the results. While the comment provides a clear direction for improvement, it lacks detailed guidance on what specific aspects of the convergence process should be discussed or how to present this information. This limits the comment\\'s usefulness, as it does not offer comprehensive suggestions for enhancing the draft. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests discussing the results for the task of inferring knowledge on objects and includes results for model (B), while also recommending using consistent terminology for the model in Tables 1 and 2. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs.\" These suggestions are clear and concrete, giving the authors specific steps to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (681 and 778) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B), and it questions the omission of objects in relation to \"latent in verbs.\" This level of detail and explicit references to specific parts of the paper make the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of requests for clarification and suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also questions the omission of objects in relation to \"latent in verbs.\" These are requests for clarification or suggestions, not claims that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback, suggesting that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out the inconsistency in terminology used for the model in Tables 1 and 2, recommending a more consistent approach. Additionally, the comment questions why objects are not mentioned in relation to \"latent in verbs,\" which could prompt the authors to clarify this aspect of their work. This feedback is clear and constructive, offering the authors specific areas to address and improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the wording in line 212, suggesting that the sentence is not strictly correct and provides a correction. It also references Figure 2 to support the suggested change. This feedback is explicit and provides concrete guidance on how to improve the draft by correcting the wording and aligning it with the figure. The authors know exactly what needs to be changed and where to make the correction, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 212\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence in line 212 and provides a correction, suggesting that the correct way to describe the process would be to use a bidirectional encoder. This level of detail helps the authors understand what needs to be revised, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in line 212 is not strictly correct and suggests a correction based on the description in Figure 2. The reviewer provides a specific suggestion for improvement, which is a clear and logical reasoning for the claim. However, the comment could be strengthened by referencing the specific elements in Figure 2 that support the suggested correction. Overall, the claim is mostly verifiable, as it provides a logical basis for the correction but lacks detailed references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the paper, pointing out that the sentence in line 212 is not strictly correct. It provides a clear and actionable suggestion for improvement by recommending that the authors use a bidirectional encoder to encode the source sentence into a set of vectors, as shown in Figure 2. This feedback is valuable as it directly addresses a potential misunderstanding in the paper and offers a concrete correction, empowering the authors to enhance the clarity and accuracy of their draft. However, the comment could be more helpful if it explained why the current wording is incorrect or how the suggested change would improve the paper. Overall, the comment is mostly helpful, as it provides clear guidance for improvement but could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement the suggested baselines or what other baselines might be relevant. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this comment pertains to, making it weakly grounded. The suggestion to include additional baselines is specific, as it provides a concrete example of what could be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work is a \"fairly straightforward extension of existing retrofitting work\" and suggests adding additional baselines, such as character embeddings. However, the comment lacks specific examples or references to support the claim that the work is a straightforward extension or to justify the need for additional baselines. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out that the work is a straightforward extension of existing retrofitting work and suggests adding additional baselines, such as character embeddings. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on how to incorporate these baselines or why they would be beneficial. The feedback is somewhat helpful as it prompts the authors to consider expanding their work, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the adopted baseline models. First, it notes that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. Second, it points out that the authors do not compare their models to other domain adaptation methods, as mentioned in Section 8. The comment also corrects a grammatical error in the paper. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how the authors should address these issues or conduct the comparisons. The actions are implicit and somewhat vague, as the authors need to infer that they should include comparisons with Campos et al. (2020) and other domain adaptation methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 8\" and \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the adopted baseline models, noting the lack of comparison with Campos et al. (2020) and other domain adaptation methods. Additionally, it corrects a grammatical error. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak, providing two reasons for this assertion. First, it notes that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. Second, it points out that the authors do not compare their models to other domain adaptation methods, as mentioned in Section 8. These claims are supported by specific references to external works, providing a clear basis for the reviewer\\'s opinion. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would improve the paper. Overall, the claim is mostly verifiable, as it provides a solid foundation but could benefit from additional elaboration.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two specific issues with the adopted baseline models. First, it points out that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks, suggesting that this comparison is necessary. Second, it notes that the authors do not compare their models to other domain adaptation methods, as mentioned in Section 8. This feedback is clear and actionable, as it highlights areas where the authors can strengthen their work by including additional comparisons. Additionally, the comment corrects a grammatical error, which is a minor but important detail. Overall, the comment provides valuable insights and suggestions for improvement, making it mostly helpful for the authors.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific change to the y-axis label in Figure 5, recommending the use of \"Exact Match ratio\" instead of the current label. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The comment is also concrete, as it specifies exactly what needs to be changed, allowing the authors to implement the suggestion directly. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to change the y-axis label to \"Exact Match ratio.\" This level of detail guides the authors on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a change to the y-axis label in Figure 5, recommending the use of \"Exact Match ratio\" instead of the current label. This is a specific suggestion that provides a clear and direct improvement to the figure. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would enhance the clarity or understanding of the figure. Without additional context or explanation, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is somewhat verifiable, as it provides a specific suggestion but lacks detailed justification or reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of the paper. By recommending a change to the y-axis label in Figure 5, the reviewer offers a clear and concrete way for the authors to enhance the presentation of their results. This feedback is valuable as it directly addresses a particular aspect of the paper, guiding the authors on how to improve the visual representation of their data. However, the comment could be more helpful if it explained why the current label is unclear or how the suggested change would benefit the reader. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment mentions \"Comments - I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig,\" which appears to be a separate issue unrelated to the main concern about biases. The lack of actionable advice and the disconnected nature of the comment make it difficult for the authors to know what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not specify which part of the paper this concern pertains to, making it weakly grounded. The comment also lacks specificity as it does not provide detailed guidance on what needs to be addressed or how to improve the description. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. This is an important consideration, especially in the context of AI and natural language processing, where biases can significantly impact the accuracy and fairness of the models. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure their knowledge bases are bias-free. Additionally, the mention of \"Comments - I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig\" appears to be a separate issue unrelated to the main concern about biases. The lack of actionable feedback and the disconnected nature of the comment make it somewhat helpful, as it identifies an important area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the real value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the specific issues with the attention mechanism or how to make it work. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment does not specify which part of the paper discusses attention in seq2seq MTL, making it weakly grounded. It does provide some specificity by suggesting that the authors should focus on understanding why the attention mechanism fails and how to improve it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to make it work. The comment provides a logical reasoning by contrasting the ease of showing failure with the importance of understanding the root cause and making improvements. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific issues with the attention mechanism and how to address them, which could be challenging without detailed guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the real value lies in understanding why it fails and making changes to the attention mechanism to make it work. This feedback highlights a gap in the paper, suggesting that the authors should focus on understanding the root causes of failure and making improvements to the attention mechanism. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing potential changes or areas to explore. While it points out a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the absence of strong baselines in Table 3, specifically mentioning the baselines in [1]. It asks the authors to justify the reason for not including these baselines in their comparison. While the comment implies that the authors should provide a justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should provide this justification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the absence of strong baselines in Table 3 and asks for a justification for not including them. The mention of specific baselines from [1] provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of strong baselines in Table 3, specifically mentioning the baselines in [1]. This is a request for clarification or justification, not a claim. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting the absence of strong baselines that are not compared, such as those mentioned in [1]. It raises a valid point about the need for justification for not including these baselines in the comparison. This feedback is clear and actionable, as it prompts the authors to provide a rationale for their choice of baselines, which could enhance the comprehensiveness and validity of their analysis. However, the comment could be more helpful if it suggested specific baselines to consider or provided guidance on how to justify the choice of baselines. Overall, the comment is mostly helpful as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper relies on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the independence of the paper. The action is implicit, as the authors can infer that they need to make the paper more self-contained, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"S3.1\" and \"Sup. Fig. 6,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the paper relies on supplemental space and is not truly independent, particularly in the context of references to supplemental figures and model comparisons. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper relies on supplemental space to contain its content, making it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not truly independent. While it highlights certain sections that rely on supplemental material, it does not provide a comprehensive analysis or evidence to substantiate the claim. This makes the comment somewhat verifiable, as it points out potential issues but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. This feedback is valuable as it highlights a potential weakness in the paper\\'s independence and self-containedness. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to integrate the supplemental material more effectively into the main text. Despite this, the comment is mostly helpful as it directs the authors\\' attention to a critical area that needs improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests adding that the input to the Lample et al. Bi-LSTM-CRF model is word embeddings, similar to Lample et al. Second, it asks for clarification regarding whether the KNs in Figure 3 are in the source language or in English, given that the mentions have been translated to English. The authors are given clear instructions on what to do to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as adding that the input to the Lample et al. Bi-LSTM-CRF model is word embeddings and clarifying whether the KNs in Figure 3 are in the source language or in English. This level of detail helps the authors understand what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification, such as asking for clarification on whether the KNs in Figure 3 are in the source language or in English. It does not contain subjective opinions, claims, or suggestions that require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests that the authors should clarify that the input to the Lample et al. Bi-LSTM-CRF model is word embeddings, similar to Lample et al. This addition would help readers understand the methodology better. Second, it questions whether the KNs in Figure 3 are in the source language or in English, given that the mentions have been translated to English. The comment also acknowledges that the authors have already addressed the issue of the figure in their response. This feedback is clear and actionable, offering the authors specific ways to enhance their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several weaknesses in the paper, specifically related to the experiments. It notes that the experiments are limited to an extremely low-resource regime, which may not be representative of real-world applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights areas for improvement, it does not provide explicit or concrete actions for the authors to take. The feedback is somewhat actionable as it points out specific issues, but it lacks detailed guidance on how to address them, such as suggesting additional experiments or tasks to explore. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific weaknesses in the paper, particularly related to the experiments. It mentions that the experiments are limited to an extremely low-resource regime, which may not be representative of real-world applications, and that sentence classification is an easier task. The reviewer also suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. However, the comment does not specify which sections or experiments these issues pertain to, making it weakly grounded. The feedback is specific in detailing the weaknesses and potential improvements, but without explicit references to sections or experiments, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s experiments are weak due to their focus on an extremely low-resource regime and an easier task (sentence classification). The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. The comment provides a logical reasoning for the claim, noting that the experiments may not be representative of real-world applications. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reviewer\\'s points and potentially expand their experiments to address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific weaknesses in the paper, particularly related to the experiments. It points out that the experiments are limited to an extremely low-resource regime, which may not be representative of real-world applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it provides insights into the limitations of the current work, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether concept map extraction should be treated as a separate task. It provides a rationale for both sides of the argument, suggesting that generic summarization systems build similar knowledge graphs and that the concept map becomes harder to distinguish with increasing node numbers. However, the comment does not explicitly instruct the authors to make a decision or take any specific action. The authors are left to infer that they might need to reconsider their approach to concept map extraction, but without concrete guidance on how to address this issue, the comment remains somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it might be related to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its reasoning but lacks grounding, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning and evidence to fully understand the basis of the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions that generic summarization systems build similar knowledge graphs and that the concept map becomes harder to distinguish with increasing node numbers. This feedback is somewhat helpful as it prompts the authors to reconsider their approach and potentially integrate concept map extraction into a broader summarization framework. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or providing examples of how to integrate concept map extraction. Therefore, while it identifies a potential area for improvement, it does not offer detailed actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide more information about the traits of the experts and to justify why annotation must be carried out by the experts, rather than focusing solely on commercial values. It also asks specific questions about the expertise of the annotators, whether the annotation process differed from what non-experts would do, and if it introduced any linguistic challenges. These questions provide clear guidance on what the authors need to address, making the comment highly actionable. The authors know exactly what information to include and what questions to answer to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed description of the traits of the experts and a justification for why annotation must be carried out by the experts, rather than focusing solely on commercial values. The comment also asks specific questions about the expertise of the annotators and the nature of the annotation process, providing clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the need for more information regarding the traits of the experts and the justification for using experts for annotation, rather than focusing solely on commercial values. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should describe more about the traits of the experts involved in the annotation process and justify why annotation must be carried out by experts, rather than focusing solely on commercial values. It raises important questions about the expertise of the annotators, whether the annotation process differed from what non-experts would do, and if it introduced any linguistic challenges. This feedback is clear and directs the authors to provide additional context and justification, which can help improve the clarity and credibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or provided examples of what additional information would be beneficial. Overall, the comment is mostly helpful as it guides the authors toward enhancing their draft with relevant details and justifications.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the text in lines 102-106, stating that it is misleading. It points out that while the statements about intersection and probs are true, the phrase \"such distribution\" cannot refer to the discussion in the above. However, the comment does not provide any guidance on how to address this issue or suggest alternative wording. The action is implicit and vague, as the authors are left to infer that they need to clarify or rephrase the text but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that the phrase \"such distribution\" is misleading and cannot refer to the discussion in the above. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading because the phrase \"such distribution\" cannot refer to the discussion in the above. However, the comment does not provide any further explanation or reasoning to support this claim, such as what specific aspect of the discussion is being referred to or why the phrase is misleading. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the text in lines 102-106, pointing out that the phrase \"such distribution\" is misleading because it cannot refer to the discussion in the above. This feedback is clear and actionable, as it directs the authors to clarify or rephrase the text to ensure it is accurate and consistent. However, the comment could be more helpful if it provided suggestions on how to rephrase the text or offered additional context to better understand the issue. Overall, the comment is mostly helpful as it highlights a potential misunderstanding in the text, prompting the authors to make a specific improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include examples of their system applied to actual texts rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the type of examples or how they should be presented. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of the system applied to actual texts, rather than focusing on other components or models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of examples, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be valuable or necessary. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include examples of their system applied to actual texts, rather than focusing solely on other components or models. This feedback is somewhat helpful as it provides a specific direction for enhancing the paper by demonstrating the system's practical application. However, the comment lacks depth and does not offer detailed guidance on how to present these examples or what specific aspects of the system should be highlighted. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are lacking in depth or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims need further analysis and how to proceed without explicit instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are lacking in depth or provide examples of what kind of analysis is needed. Additionally, it does not mention any specific sections or parts of the paper, making it difficult for the authors to identify the exact areas that need improvement. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a number of claims from this paper would benefit from more in-depth analysis.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of claims that lack depth, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the depth of analysis in the paper, suggesting that several claims could benefit from more in-depth examination. However, it lacks specificity and does not provide any guidance or examples on which claims are lacking depth or how the authors might address this issue. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two areas that need improvement in the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It provides specific questions and suggestions for clarification, such as defining whether E_i represents the type or identity of AC i. The comment also suggests that the left-hand side of Equation (7) should be a conditional probability. These explicit and concrete actions provide clear guidance for the authors on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (397 and 472) and equations (7) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, such as the pooling method used for embedding features and the clarity of Equation (7). The comment provides detailed questions and suggestions for clarification, ensuring that the authors know exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and suggestions for clarification, such as the pooling method used for embedding features and the interpretation of Equation (7). These questions and suggestions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features, which is important for understanding the model's architecture. Additionally, it questions the clarity of Equation (7), suggesting that the random variable E_i might represent either the type or identity of AC i, and that the left-hand side of the equation should be a conditional probability. This feedback is clear and detailed, offering the authors concrete steps to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in making these improvements. Overall, the comment is mostly helpful, as it effectively directs the authors to specific areas needing attention, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper raises two hypotheses about multilinguality and country/language-specific bias but does not actually study these hypotheses or mention them again. The reviewer suggests that the hypotheses could be tested as given and that the paper should go deeper into these topics. While the comment implies that the authors should address the hypotheses and provide more depth, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to test or expand upon the hypotheses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 078-086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the hypotheses, noting that they are not phrased optimally and could be tested as given. The comment further specifies that the paper does not actually study these hypotheses and suggests that the paper should delve deeper into the respective topics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper raises two hypotheses about multilinguality and country/language-specific bias but does not actually study these hypotheses or mention them again. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into these topics. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the hypotheses are not studied or discussed further. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/language-specific bias but does not actually study these hypotheses or discuss them further. This is considered misleading, as the hypotheses are not tested or explored in depth. The comment provides a clear and actionable suggestion for improvement by recommending that the paper delve deeper into these topics, at least to some extent. This feedback is valuable as it highlights a critical gap in the paper and offers a specific direction for enhancement. However, the comment could be more helpful if it provided additional guidance on how to test or explore these hypotheses. Overall, the comment is mostly helpful, as it effectively directs the authors to address a significant weakness in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether feature engineering could improve the performance of the current work. It references a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of hand-crafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. While the comment implies that the authors should consider using feature engineering, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore feature engineering and consider using the same feature set as Uto et al. (2020). Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether feature engineering could improve the performance of the current work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of hand-crafted features. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where feature engineering could be applied. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, while the comment provides a reference to Uto et al. (2020) and suggests using their feature set, it does not specify how this could be implemented or what specific features are being referred to. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether feature engineering could improve the performance of the current work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of hand-crafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. However, the comment lacks specific details or examples from the current work to support the claim that feature engineering would be beneficial. While it references Uto et al. (2020), it does not provide a direct comparison or analysis of the current work's features. This makes the claim somewhat verifiable, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about whether feature engineering could improve the performance of the current work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of hand-crafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. While the comment identifies a potential area for improvement and provides a reference for further exploration, it lacks specific guidance or detailed suggestions on how the authors might implement feature engineering or adapt Uto et al. (2020)'s feature set. The feedback is somewhat helpful as it prompts the authors to consider a specific approach, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It explicitly asks whether the CS is used to augment the training material and requests information about the data split. While the comment does not provide explicit instructions, it does imply that the authors should clarify these aspects. The action is implicit but concrete, as it directs the authors to provide specific information about the use of the CS. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the use of the Challenge Set (CS) in the evaluation and training process. It explicitly mentions the CS, which allows the authors to identify the part of the paper being addressed. However, the comment does not specify what is unclear or what needs to be clarified about the use of the CS. While it provides some guidance by asking about the data split, it lacks detailed specificity regarding the issues with the CS\\'s use. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or important. Without additional context or explanation, the authors may find it challenging to understand the significance of these questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. While the comment identifies a potential area of confusion, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to clarify an aspect of their methodology, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the paper\\'s claim that the model generalizes to different knowledge, specifically questioning the representation of substructure as a sequence of words and the use of \"knowledge\" to describe the constituent parse. The reviewer suggests that this is misleading because \"knowledge\" is typically used to refer to external knowledge, such as a knowledge base of entities, whereas the paper is discussing syntax or semantics. While the comment identifies a potential issue with the terminology and the representation of knowledge, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology and representation of knowledge. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the model\\'s generalization to different knowledge. It questions the representation of substructure as a sequence of words and the use of \"knowledge\" to describe the constituent parse. The reviewer provides a detailed critique, suggesting that the term \"knowledge\" is misleading as it typically refers to external knowledge, such as a knowledge base of entities, whereas the paper is discussing syntax or semantics. This feedback is specific and provides clear guidance on what needs to be addressed, such as clarifying the terminology and representation of knowledge. However, it does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the paper\\'s use of the term \"knowledge\" in relation to the model\\'s generalization. The reviewer questions the representation of substructure as a sequence of words and suggests that \"knowledge\" is typically used to refer to external knowledge, such as a knowledge base of entities. The comment provides a logical reasoning by contrasting the typical usage of \"knowledge\" with the paper\\'s application, which is more focused on syntax or semantics. However, the comment could be strengthened by providing specific examples or references to support the claim. Overall, the claim is mostly verifiable, as it provides a logical argument but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the paper\\'s claim that the model generalizes to different knowledge, specifically questioning the representation of substructure as a sequence of words. The reviewer suggests that this representation may not be straightforward and questions the use of \"knowledge\" to describe the constituent parse. The comment also points out that the term \"knowledge\" is typically used to refer to external knowledge, such as a knowledge base of entities, whereas the paper is discussing syntax or semantics. This feedback is somewhat helpful as it identifies a potential misunderstanding in the paper\\'s terminology and suggests a need for clarification. However, it lacks specific guidance on how the authors might address this issue or improve the clarity of their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the relatively poor performance of TWSI on nouns, which is expected due to its nature. It also notes that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the comment identifies areas of concern and suggests further exploration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the gap and reconcile the contradictory claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of TWSI on nouns, which is expected due to its nature, and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about performance and the contradiction with the claim, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the relatively poor performance of TWSI on nouns is disconcerting, given the nature of TWSI and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. The comment also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the reviewer provides a logical reasoning for the concern, it lacks specific examples or references to support the claim about the oracle GAP being higher than most clustering approaches. This makes the claim somewhat verifiable, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern about the performance of TWSI on nouns, which is expected due to its nature. It also highlights the fact that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. This feedback is somewhat helpful as it directs the authors to investigate the performance gap and reconcile the contradictory claims. However, it could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the generalizability claim. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to provide examples of spurious structures in the discussion of section 5.2, which is a direct and concrete action. The authors know exactly what they need to do to address this feedback, which is to include specific examples to clarify the discussion. This makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, stating that it is too abstract and lacks examples of spurious structures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 5.2 is too abstract and lacks examples of spurious structures. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed examples or references to what is considered abstract or lacking, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks examples of spurious structures. This feedback is clear and actionable, as it directs the authors to provide concrete examples to clarify the discussion and demonstrate the advantages of the new model over MH. By addressing this feedback, the authors can enhance the clarity and persuasiveness of their paper. However, the comment could be more helpful if it provided suggestions on how to present these examples or what specific aspects of the discussion need more detail. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a baseline smaller PCFG with state size being r, where $H, I, J, K, L$ are directly parameterized as learned matrices of $\\mathcal{R}^{r \\times r}$, $\\mathcal{R}^{r \\times o}$, $\\mathcal{R}^{r}$, etc. This suggestion is explicit and provides concrete details on how to implement the action, such as specifying the matrices to be learned. The authors know exactly what changes to make to their draft to address this feedback. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a baseline smaller PCFG with specific parameterizations for $H, I, J, K, L$. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, the comment is weakly grounded. The suggestion is specific in detailing the changes to be made, providing clear guidance on how to improve the draft. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a baseline smaller PCFG with specific parameterizations, stating that this would allow for a comparison of perplexity. The comment provides a logical reasoning for why this change would be beneficial, as it addresses the issue of direct comparability. However, it lacks specific examples or references to support the claim that perplexity can still be compared under this setting. While the reasoning is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors might need additional context to fully understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by proposing a baseline smaller PCFG with state size being r, where $H, I, J, K, L$ are directly parameterized as learned matrices. This suggestion is clear and actionable, offering a concrete way for the authors to enhance their draft by adding a comparative baseline. The comment also explains why this change might be beneficial, noting that it could allow for a comparison of perplexity even if parsing F-1 is not directly comparable. This level of detail and guidance makes the comment highly helpful, as it empowers the authors to make a meaningful improvement to their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit action that provides clear guidance on what needs to be added to the draft. The suggestion is concrete, as it specifies exactly what information should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is the maximum number of tasks done by any annotator. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include the maximum number of tasks done by any annotator. While this is a specific and actionable piece of feedback, it does not provide any context or explanation as to why this information is important or how it would enhance the paper. The comment lacks depth and does not offer any additional insights or suggestions for improvement. Therefore, it is somewhat helpful, as it provides a clear direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions the clarity of how the experiments relate to the underlying research question and specific hypothesis tested. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the connections between the experiments and the research question, but it lacks concrete steps or examples on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions the clarity of how the experiments relate to the underlying research question and specific hypothesis tested. However, the comment does not specify which parts of the paper are particularly challenging to understand, making it weakly grounded. The authors can infer that it relates to the sections containing empirical results and analyses, but without explicit references, it is difficult to pinpoint the exact areas needing attention. The comment is specific in its questioning of the overall coherence and clarity of the results, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions the clarity of how the experiments relate to the underlying research question and specific hypothesis tested. However, the comment does not provide specific examples or detailed reasoning to support the claim that the results are difficult to understand. Without additional context or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that despite the many empirical results and analyses presented, it is difficult to understand the overall picture of what the experiments tell us about the underlying research question and specific hypothesis tested. This feedback is valuable as it highlights a critical area for improvement, namely the clarity and coherence of the results and their connection to the research question. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as by restructuring the presentation of results or providing additional explanations. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment specifies exactly what needs to be added to the table, making it highly actionable. The authors know exactly how to implement this suggestion, ensuring a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not contain subjective judgments, suggestions, or deductions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance their results section. By including this baseline, the authors can better illustrate the effectiveness of their methods and provide a more comprehensive comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the overall understanding of the paper. Despite this, the suggestion is valuable and actionable, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of numerical results and expresses curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to consider or how to conduct the comparisons. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include these comparisons. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses curiosity about the lack of numerical results and suggests that the authors should provide comparisons with existing DP algorithms. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and expressing curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\\'s contribution and impact. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as which algorithms to consider or how to conduct the comparisons. While it points out a critical area for enhancement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The suggestion is concrete, as it specifies exactly what needs to be done to improve the experimental section. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, it does not specify which part of the paper discusses the experimental comparisons, making it weakly grounded. The comment is specific in suggesting a particular comparison that could be made, but without explicit references to the paper, the authors may struggle to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental comparisons are insufficient and suggests testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, the comment does not provide any supporting evidence or reasoning to justify why these comparisons are necessary or how they would enhance the paper. Without specific examples or references to existing work that uses these wider backbones, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section of the paper. It points out that the experimental comparisons are insufficient and suggests testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the robustness and comprehensiveness of their experimental results. By addressing this feedback, the authors can strengthen their paper and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it explained why these wider backbones are important or how they might impact the results. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection is not drawn well and recommends either cementing the connection more formally or adjusting the language to clarify. While the comment implies that the authors should take action to improve the clarity of the probabilistic connection, it does not provide specific guidance on how to achieve this. The action is explicit but somewhat vague, as it lacks concrete details on how to formalize or adjust the language. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the probabilistic connection in the paper, suggesting that it is not drawn well and is not formally established. However, it does not specify which part of the paper discusses this probabilistic connection, making it weakly grounded. The comment is specific in suggesting that the authors either formalize the connection or adjust the language to clarify it. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection is not drawn well and suggests that it is not formally established. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or evidence to substantiate the assertion that the connection is not well-drawn, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for the authors to fully understand and act upon the feedback.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the probabilistic connection, suggesting that it is not drawn well and lacks formalization. It provides a clear and actionable suggestion for the authors to either cement the connection more formally or adjust the language to clarify it. This feedback is specific and offers a constructive path for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it included examples or further guidance on how to formalize the connection or adjust the language. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This is an explicit request for additional data or analysis to substantiate the claim made in the paper. The action is clear and concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific evidence or analysis is needed. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in suggesting the need for empirical evidence but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the algorithm is better suited for this problem. Without such evidence or justification, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by including additional data or analysis. However, the comment could be more helpful if it provided guidance on how to conduct this empirical evaluation or suggested specific metrics to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the robustness of their scheme. The action is implicit and vague, as the authors are left to infer that they need to explore ways to enhance the robustness of their scheme, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. However, it does not specify which part of the paper discusses this scheme or where the issue of scaling is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the scaling issue, but it lacks grounding as it does not reference a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those in high-dimensional domains. The reviewer suggests that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. While the comment identifies a potential limitation of the approach, it lacks specific suggestions or guidance on how the authors might address this issue or improve the robustness of their scheme. The feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions what kind of style shifts might occur within this timeframe and suggests that without these answers, it is difficult to appreciate what the model is capturing. While the comment implies that the authors should provide more information on the datasets and the time period, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. However, it does not specify which part of the paper discusses these datasets or the time period, making it weakly grounded. The comment is specific in questioning the adequacy of the time period and the nature of style shifts, providing a clear direction for the authors to address these concerns. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of the time period (4 years) to study style shifts and asks for clarification on the kind of style shifts that might occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support the claim that 4 years is insufficient. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions whether this timeframe is adequate to capture the desired style shifts and suggests that without addressing this issue, it is difficult to appreciate what the model is capturing. This feedback is somewhat helpful as it identifies a potential weakness in the study and prompts the authors to provide more context and justification for their dataset selection. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of alternative datasets or timeframes that might be more appropriate. Overall, the comment provides a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct the callout to table 5, suggesting it should point to table 3 instead. It also mentions a misdirected callout in figure 6, providing specific guidance on where the issue is located. This feedback is clear and direct, giving the authors concrete actions to take to improve their draft. The explicit nature of the instructions and the detailed guidance on where to make corrections make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 7, section 5, last par.\" and \"figure 6,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue with the callouts, indicating that the callout to table 5 should point to table 3 instead and that the callout in figure 6 is not directing properly. This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out two errors in the paper. It identifies that the callout to table 5 should be directed to table 3 instead and that the callout in figure 6 is not directing properly. This feedback is clear and direct, allowing the authors to make precise corrections to their draft. However, the comment could be more helpful if it explained why these corrections are necessary or how they might impact the reader\\'s understanding of the paper. Despite this, the comment is mostly helpful as it guides the authors to improve the accuracy and clarity of their references, which is crucial for the reader\\'s understanding.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights concerns about the experiments, specifically noting that the paper only reports self-comparisons and lacks explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments and provides a suggestion for improvement, it does not explicitly instruct the authors to make these comparisons or explain how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide a rationale for their choice of self-comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the lack of comparisons with other methods like SketchRNN, and the need for a better explanation of the self-comparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has a \"biggest concern\" with its experiments, specifically noting that it only reports self-comparisons and lacks explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue with the experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with SketchRNN is a logical one, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the paper, specifically the lack of comparisons with other methods, such as SketchRNN, in the experiments. It highlights the issue of only reporting self-comparisons and the need for a better explanation of this choice. This feedback is clear and actionable, as it points out a specific area for improvement and suggests a potential direction for enhancing the paper. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects of SketchRNN should be considered. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" and provides specific examples to support this disagreement. The comment clearly outlines the action needed, which is to conduct further analysis and provide additional comments on the performance trends. The feedback is explicit and provides concrete guidance on what the authors should focus on, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3, specifically disagreeing with the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity.\" The comment provides specific examples and observations, such as the performance of DeiT-B models on APTOS2019 and the lack of significant improvement over DeiT-T and DeiT-S on other datasets. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a claim that the authors\\' viewpoint on the performance of ViT (DeiT) is incorrect and provides specific examples to support this claim. It references Figure 3 and provides detailed observations about the performance of DeiT-B models on different datasets compared to DeiT-T and DeiT-S. This level of detail and specific examples make the claim fully verifiable, as it provides a clear basis for the reviewer\\'s disagreement. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" by pointing out specific instances where DeiT-B models do not outperform DeiT-T or DeiT-S on certain datasets. The comment also highlights that CNNs tend to provide more consistent model improvements as capacity increases, except on the ISIC2019 dataset. This feedback is clear and provides the authors with a specific area to focus on for improving their analysis and understanding of the performance trends. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide explicit guidance on how to address these potential sources of confusion. The comment lacks actionable details, such as suggesting specific changes or improvements to clarify these areas. As a result, the authors are left without a clear understanding of what steps to take to enhance the clarity of their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not specify which parts of the paper are confusing or what aspects need clarification. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper are being addressed. This lack of grounding and specificity makes it difficult for the authors to understand and address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide any examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the potential sources of confusion. Without specific references or explanations, the claim lacks verifiability, leaving the authors without a clear path to improvement. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide any details or examples of what these confusing areas are, nor does it offer suggestions on how to address them. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be improved or clarified. This lack of detail and direction makes the comment barely helpful, as it does not provide meaningful insights or direction for the authors to enhance their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the claim \"there is no corresponding set of tools for the reinforcement learning setting\" is false, and it provides references to support this assertion. The comment is clear and direct, leaving no ambiguity about the action required, which is to correct the claim in the paper. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim that \"there is no corresponding set of tools for the reinforcement learning setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim that this statement is false, which helps the authors understand what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It supports this claim by providing references, both from the submitted paper and external sources. This level of detail and evidence makes the claim fully verifiable, as it provides a clear basis for the reviewer\\'s assertion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it directly addresses a factual error in the paper, specifically the claim that \"there is no corresponding set of tools for the reinforcement learning setting.\" By providing references to support the claim that this statement is false, the comment empowers the authors to correct this error in their draft. This feedback is actionable and provides a clear path for the authors to improve the accuracy and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of the results being non-obvious or how to make them more accessible to a broader audience. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results section, specifically mentioning that they are based on \"standard\" techniques but are not obvious a priori. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in pointing out the issue of the results being non-obvious and requiring technical competency, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples of these \"standard\" techniques or explain why they are not obvious to a broader audience. This lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. This observation highlights a potential limitation in the accessibility of the results, suggesting that they may not be immediately understandable to a broader audience. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as by explaining the techniques in more detail or providing additional context. While it identifies a weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide explicit guidance on how to implement this distinction or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to differentiate between these types of updates, but they are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This is a specific and actionable piece of feedback that could help the authors clarify their work and improve the clarity of their paper. By differentiating between these types of updates, the authors can provide a more nuanced understanding of their methodology and its implications. However, the comment could be more helpful if it provided examples or further elaboration on how this distinction might be made or why it is important. Overall, the comment is mostly helpful as it directs the authors to a meaningful improvement in their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the end-to-end system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the data usage or analysis. The action is implicit and vague, as the authors are left to infer that they should reconsider their data usage or analysis, but without concrete steps or suggestions, the comment lacks actionability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the amount of data used to train the text disambiguation model compared to the end-to-end system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not specify which part of the paper discusses these models or their performance, making it weakly grounded. The comment is specific in detailing the issue with the data usage and the implications for the conclusion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the conclusion that the direct model is clearly superior, given the small difference in performance compared to the end-to-end system. The comment highlights a discrepancy in the amount of data used for training, suggesting that this could impact the conclusion. However, the comment lacks specific examples or references to support the claim that the difference in performance is insignificant. Without detailed evidence or comparisons, the claim remains somewhat verifiable, as it provides a logical reasoning but lacks concrete data or references to substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the conclusion that the direct model is clearly superior, given the small difference in performance compared to the end-to-end system. It highlights a discrepancy in the amount of data used for training, which could impact the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two main issues: the lack of motivation for GaRare compared to GaLore and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment provides explicit actions for the authors to take, such as providing evidence or justification for GaRare\\'s advantages and clarifying the algorithmic presentation. However, it does not specify how to provide this evidence or clarification, leaving some room for interpretation. Overall, the comment is mostly actionable as it clearly identifies the areas needing improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing or unclear, such as the motivation for GaRare and the need for a more detailed algorithmic presentation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for GaRare and does not provide evidence or justification for its advantages over GaLore. It also notes the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper. First, it points out the lack of motivation for GaRare, specifically noting the absence of evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is clear and actionable, as it prompts the authors to provide a more thorough explanation of the benefits and advantages of GaRare. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it directs the authors to enhance the clarity and understanding of their algorithmic approach. Overall, the comment provides specific and constructive feedback that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also suggests conducting an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. These requests are clear and provide specific actions for the authors to take, making the comment highly actionable. The authors know exactly what experiments to perform to address the reviewer\\'s concerns, ensuring a clear path for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. Additionally, it suggests conducting an ablation study on the visDial dataset to further validate the proposed model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also asks for an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. While the comment provides a clear suggestion for additional experiments, it lacks specific reasoning or evidence to support why these experiments are necessary or how they would contribute to the paper\\'s validity. The request for an ablation study is somewhat verifiable, as it suggests a logical next step, but the lack of detailed justification or examples makes it difficult for the authors to fully understand the importance of these experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting additional experiments to further validate the proposed visual reference resolution model. It recommends conducting an ablation study on the visDial dataset to provide more robust evidence of the model\\'s effectiveness. Additionally, it asks for an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory, which could help clarify the model\\'s strengths and limitations. This feedback is clear and detailed, offering the authors a concrete path to enhance the validity and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This feedback provides a clear and direct action for the authors to take, which is to include these references in their work. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, a reference to these works that have a similar structure to the CRF and can perform exact inference. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This claim is somewhat verifiable as it references specific works that could be relevant to the paper. However, the comment does not provide detailed reasoning or examples of how these works are similar or how they could enhance the paper, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF). These works have a similar structure to the CRF and can perform exact inference, which could be relevant to the paper. By suggesting the inclusion of these references, the comment provides clear and actionable feedback that can help the authors enhance the context and relevance of their work. However, the comment could be more helpful if it explained why these references are important or how they could contribute to the paper. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide an explanation for why WPA works, specifically asking what the model is predicting with np.ones input and whether any input would serve as a white paper. It also questions why Gaussian noise input does not work as well as WPA and why the authors spend time showing WPA improves test performance without providing insights into how it works. The comment implies that the authors should address these questions to enhance the paper\\'s contribution and potential for future research. While the actions are implicit, they are concrete in nature, as the authors know exactly what needs to be addressed to improve the draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and suggestions for improvement, such as explaining why WPA works, what the model is predicting with np.ones input, and why Gaussian noise input does not work as well as WPA. The comment also highlights the importance of providing insights into how WPA works, which can spark future research directions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and suggestions, such as asking for an explanation of why WPA works and why Gaussian noise input does not work as well as WPA. It also notes that the authors spend time showing WPA improves test performance without providing insights into how it works. While the comment identifies areas for improvement, it lacks specific evidence, reasoning, or references to support the claims or suggestions. The authors are left to infer the basis of the critique, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a series of questions and suggestions that could significantly enhance the paper. It challenges the authors to explain why WPA works, particularly with np.ones input and whether any input could serve as a white paper. It also questions the effectiveness of Gaussian noise input compared to WPA, which is an important point given the authors\\' focus on improving test performance. The comment highlights the need for more insight into how WPA works, which could spark future research directions. While the feedback is clear and actionable, it could be more helpful if it offered specific suggestions on how to address these questions or provided examples of similar approaches in the literature. Overall, the comment is mostly helpful as it guides the authors toward improving the depth and clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It asks the author to provide more clarification on this similarity. While the comment implies that the authors should clarify the distinction between their method and the related work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the similarity, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any specific examples or detailed reasoning to support the claim of similarity. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a valid concern about the originality and distinctiveness of the method, which is important for the authors to address. However, the comment lacks specific guidance or suggestions on how the authors might clarify the distinction or improve the originality of their work. While it points out an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this does not provide specific guidance on how to improve the paper. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this is not a claim that requires verification. Therefore, the comment lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claims made. The authors would need to infer the issues and address them without clear guidance from the review. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the questions raised or how they could enhance their work. As a result, the comment is barely helpful, as it identifies some areas of concern but does not provide enough detail or direction for the authors to make meaningful improvements to their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental section (Section 3) does not mention or discuss how important parameters, such as the minimum cluster size and conductance threshold, are set and how sensitive the performance is to these parameters. This feedback implies that the authors should include a discussion on these parameters in the experimental section, providing explicit guidance on what needs to be addressed. However, the comment does not specify how the authors should present this information or what specific details should be included. While the action is explicit, it lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the absence of discussion on important parameters, such as the minimum cluster size and conductance threshold, in the experimental section. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental section (Section 3) does not mention or discuss how important parameters, such as the minimum cluster size and conductance threshold, are set and how sensitive the performance is to these parameters. This is a valid claim as it highlights a gap in the paper that could impact the interpretation of the results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of these parameters based on the context provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that important parameters, such as the minimum cluster size and conductance threshold, are not discussed in the experimental section. This feedback highlights a critical area for improvement, as understanding how these parameters are set and their impact on performance is crucial for the interpretation and reproducibility of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific sections where this information should be included or suggesting ways to present it. Despite this, the comment is mostly helpful as it directs the authors to a specific area that needs attention and improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer that they should make the section more detailed without concrete suggestions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is tersely written and suggests that it could have benefitted from a slower development for easier readability. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing style of Section 4, noting that it is tersely written and could benefit from a slower development for easier readability. This feedback is somewhat helpful as it points out a potential area for improvement, suggesting that the authors might need to expand or clarify their explanations in that section. However, the comment lacks specific guidance or suggestions on how to achieve this slower development or what aspects of the section could be expanded. While it provides some direction, it does not offer detailed actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks specific guidance on how the authors might address this concern or improve their approach. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not specify which part of the paper this issue pertains to, nor does it provide detailed guidance on how to address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity regarding what aspects of the reinforcement learning approach are problematic or how it could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. While the comment identifies a potential issue, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous question about the distribution of videos of different lengths within the benchmark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths across the dataset and explaining how the authors ensured a balanced representation of different video lengths across the 11 categories. This claim is somewhat verifiable as it provides a logical reasoning for the importance of the distribution and suggests a specific action to address the issue. However, it lacks detailed examples or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a critical aspect of the paper that is not adequately addressed: the distribution of videos of different lengths within the benchmark. It highlights the importance of this distribution for assessing reasoning ability and robustness, and it provides specific suggestions for improvement, such as including a table showing the distribution of video lengths across the dataset and explaining how the authors ensured a balanced representation. This feedback is clear and actionable, offering the authors a concrete path to enhance their draft by providing the necessary information and analysis. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests clarifying how the implemented bilinear layer differs from other approaches that use bilinear pooling. It asks specific questions about the differences in dimensionality, the swapping out of the bilinear layer with the Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still done in this case. These questions provide explicit guidance on what the authors need to clarify in their draft. The feedback is concrete and direct, giving the authors clear actions to take to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and requests for clarification regarding the implementation of the bilinear layer and its differences from other approaches. The comment specifies what needs to be addressed, such as the dimensionality of embeddings, the swapping out of the bilinear layer, and the compression of representations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests clarifying how the implemented bilinear layer differs from other approaches that use bilinear pooling. It asks specific questions about the differences in dimensionality, the swapping out of the bilinear layer with the Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still done in this case. These questions are logical and provide a clear direction for the authors to address in their paper. However, the comment does not provide specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors clarify how their implemented bilinear layer differs from other approaches that use bilinear pooling. It asks questions about the differences in dimensionality, the swapping out of the bilinear layer with the Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still done in this case. This feedback is clear and directs the authors to address a potential area of confusion or misunderstanding in their paper. By answering these questions, the authors can enhance the clarity and comprehensiveness of their work. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improvement but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly advises the authors to take a cautious approach regarding their contribution until the promised dataset is made publicly available. This is a clear and direct action for the authors to take, as it specifies the need to wait for the dataset to be accessible before making any claims or contributions based on it. The comment provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of the promised dataset not being publicly available, which is a specific concern regarding the contribution of the paper. However, it does not specify which part of the paper discusses the dataset or where the promise was made, making it weakly grounded. The comment is specific in its request for caution until the dataset is openly accessible, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the promised dataset has not been made publicly available, which is a factual statement. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment highlights a critical issue regarding the promised dataset not being publicly available, which is a significant concern for the contribution of the paper. By pointing out this gap, the comment provides the authors with a clear and actionable area for improvement. It advises the authors to take a cautious approach until the dataset is openly accessible, which is a logical and necessary step to ensure the validity and reproducibility of the research. However, the comment could be more helpful if it suggested ways to address this issue, such as providing a timeline for dataset release or offering alternative approaches to validate the findings. Overall, the comment is mostly helpful as it identifies a critical problem and guides the authors toward a solution, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method is too similar to other attentional modules proposed in previous works, specifically mentioning [1, 2, 3] and ResNeSt [4]. It notes that although these works did not evaluate their performance on object detection and instance segmentation, the overall structures are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the differences or provide additional context, but without concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, specifically mentioning its similarity to other attentional modules in previous works and its relationship to ResNeSt. However, it does not explicitly mention which part of the paper discusses these comparisons or the proposed method, making it weakly grounded. The comment is specific in detailing the similarities and lack of discussion regarding ResNeSt, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It provides specific references to [1, 2, 3] and mentions the relationship to ResNeSt [4], which helps substantiate the claim. However, the comment lacks detailed comparisons or examples of how the proposed method differs from these previous works, which would strengthen the justification. Overall, the claim is mostly verifiable as it provides some supporting evidence but could be more robust with additional details. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It specifically mentions the group attention design and its relationship to ResNeSt, which is not discussed in the paper. While the comment highlights a critical weakness, it lacks actionable suggestions on how the authors might differentiate their work or address the similarity concerns. The feedback is somewhat helpful as it points out a key area for improvement, but it could be more beneficial with specific guidance or examples of how to enhance the novelty. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results presented in Figure 3, specifically regarding the preactivation values of two networks being the same membrane potentials. It suggests that the output cosine similarity would be high and asks why the results of the latter loss term of Equation 13 are not directly illustrated. While the comment implies that the authors should provide additional results or explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these results or explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3 e\" and \"Eqn 13,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by questioning the rationale behind not directly illustrating the results of the latter loss term of Equation 13. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind not directly illustrating the results of the latter loss term of Equation 13, suggesting that the output cosine similarity would be high due to the preactivation values being the same membrane potentials. This is a logical claim based on the information provided, as it challenges the authors to explain why this aspect is not included in the results. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Figure 3, specifically questioning why the results of the latter loss term of Equation 13 are not directly illustrated. This feedback is somewhat helpful as it points out a potential gap in the presentation of results, prompting the authors to consider including additional information that could enhance the clarity and completeness of their analysis. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative ways to present the results or explaining the significance of the latter loss term. Therefore, while it identifies a potential area for improvement, it does not fully support the authors in making those improvements, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a comparison with test-time adaptation (TTA) methods, such as A-B, which also aim to adapt to out-of-distribution data when the input data is disturbed by noise. The reviewer questions whether data processing is superior to model parameter adjustment and suggests making a comparison based on experimental results. While the comment implies that the authors should include a comparison with TTA methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"video action recognition\" and \"test-time adaptation (TTA) methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comparison with TTA methods and questioning the superiority of data processing over model parameter adjustment. The comment provides a clear direction for improvement by recommending a comparison based on experimental results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparison with test-time adaptation (TTA) methods, suggesting that such comparisons could be beneficial. The reviewer provides a logical reasoning by pointing out that TTA methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and that these methods primarily focus on updating model parameters, while the paper focuses on adjusting input data. The reviewer questions whether data processing is superior to model parameter adjustment and suggests making a comparison based on experimental results. This reasoning is clear and provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific TTA methods or providing examples of how such comparisons could be conducted. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting that it lacks comparison with test-time adaptation (TTA) methods, which are relevant for robustness in video action recognition. The reviewer suggests that such comparisons could be beneficial, particularly in terms of evaluating the superiority of data processing over model parameter adjustment. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a direction for further analysis. However, the comment could be more helpful if it included examples of TTA methods or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance their draft by incorporating a relevant comparison.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(st0, \u03c0\u03b8(st0)). This provides a clear and direct action for the authors to take, which is to correct the expression. The feedback is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the first expression for J(\u03b8), stating that it should be Q(st0, \u03c0\u03b8(st0)). This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides a correction. This is a factual statement that does not require verification or justification. It is a direct observation about the content of the paper, making it a normal statement and fitting the label \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the first expression for J(\u03b8) in Section 3.2.1, pointing out that it should be Q(st0, \u03c0\u03b8(st0)). This feedback is clear and actionable, providing the authors with a precise correction that needs to be made in their draft. By addressing this error, the authors can ensure the accuracy and correctness of their work, which is crucial for the integrity of their research. However, the comment could be more helpful if it explained why the correction is necessary or how it impacts the overall analysis. Despite this, the comment is mostly helpful as it directly guides the authors in improving their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a series of corrections to be made in the manuscript, including changes to the text and references. These corrections are explicit and provide clear guidance on what needs to be changed, making the actions concrete. The authors know exactly what needs to be done to address the issues identified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper (e.g., \"p.8\") and references, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the corrections needed, such as capitalizing certain words in the references and correcting errors in the text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of corrections to be made in the manuscript, including changes to the text and references. These corrections are factual and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a list of corrections to be made in the manuscript, including changes to the text and references. It specifies the exact words that need to be capitalized, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many of the papers, and \"Advances in neural information processing systems\" in several of the papers. Additionally, it corrects the publication details for Dusenberry et al. (2020), Osawa et al. (2019), and Swiatkowski et al. (2020). These detailed corrections are clear and actionable, allowing the authors to make precise changes to their draft. However, the comment could be more helpful if it provided context or explained why these corrections are necessary. Overall, the feedback is mostly helpful as it guides the authors on specific improvements to make, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests information about the model parameters for task 1 and the lambda value chosen for the Boltzmann policy. It also asks how the parameters were chosen, suggesting that maximum likelihood estimates might be used. These questions are clear and direct, providing the authors with specific actions to take to address the reviewer\\'s concerns. The feedback is explicit and concrete, giving the authors a clear understanding of what information is needed and how to provide it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"task 1\" and \"Boltzmann policy,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing, such as the model parameters for task 1 and the lambda value chosen for the Boltzmann policy. Additionally, it asks how the parameters were chosen, suggesting maximum likelihood estimates as a possibility. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions seeking clarification on specific parameters and their choices. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by noting the absence of information about certain model parameters, such as those for task 1 and the lambda value for the Boltzmann policy. It also raises a question about how the parameters were chosen, suggesting maximum likelihood estimates as a possibility. This feedback is clear and actionable, as it directs the authors to provide missing information and clarifies the methodology used in parameter selection. By addressing these points, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and completeness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The comment implies that the authors should conduct comparisons with existing detection methods, but this is not directly stated. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, questioning the validity of this claim. It suggests that the performance is primarily due to the first step and implies that comparisons with existing detection methods are necessary. However, the comment does not specify which part of the paper discusses these claims or where the authors should conduct comparisons. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections needing revision. While the comment is specific in its critique, it is not grounded, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. The reviewer provides a logical reasoning by questioning the validity of the claim and suggesting that comparisons with existing detection methods are necessary. However, the comment lacks specific examples or references to support the claim that the performance is primarily due to the first step. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to validate the claim. While the comment identifies a potential weakness in the paper\\'s claims, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. It explicitly asks the authors to provide an explanation for this observation. While the comment does not explicitly instruct the authors to conduct further analysis or make changes, it does imply that the authors should investigate and provide an explanation. The action is clear but not directly stated, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the application of Conditional Batch Norm (CBN) to layer 2, compared to when CBN is applied to layers 4 and 3 only, and asks for an explanation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. The reviewer asks for an explanation, suggesting that the authors should provide insight into why this might be happening. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or guide the authors in their response. As a result, the claim is unverifiable, as it lacks the necessary justification or evidence to support the inquiry. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) in Table 2, noting that applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. This observation is relevant and could help the authors understand the impact of their experimental setup. However, the comment only raises a question and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential area for exploration, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks a comparison with a highly relevant method, specifically mentioning the use of \"inter-task ensemble\" and \"intra-task\" ensemble. It also notes that the authors did not include a method or performance comparison. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison with the relevant method and its performance. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of a method or performance comparison, particularly in relation to the use of \"inter-task ensemble\" and \"intra-task\" ensemble. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning the use of \"inter-task ensemble\" and \"intra-task\" ensemble. The reviewer provides a specific reference to another work that proposes a similar approach, which supports the claim that such a comparison is necessary. However, the comment could be strengthened by providing more detailed reasoning or examples of how the comparison would benefit the paper. Overall, the claim is mostly verifiable, as it provides a logical basis for the suggestion but lacks comprehensive evidence or detailed examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method. It specifically mentions the use of \"inter-task ensemble\" and \"intra-task\" ensemble, which are important aspects of the proposed method. By highlighting this omission, the comment provides clear and actionable feedback for the authors to include a comparison with the relevant method, enhancing the comprehensiveness and validity of their work. This feedback is valuable as it directs the authors to a specific area for improvement, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the \"implicit call to the Witness oracle,\" describing it as confusing. However, it does not provide any guidance or suggestions on how to clarify this aspect or what changes should be made to improve the draft. The comment lacks explicit instructions or concrete details on how to address the confusion, leaving the authors without a clear understanding of what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the \"implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location of the problem. Additionally, the comment lacks specificity regarding what aspect of the call is confusing or how it could be clarified. Without explicit references or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this is confusing or how it could be clarified. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any further explanation, reasoning, or suggestions on how to clarify this aspect or what changes could be made to improve the draft. Without additional context or guidance, the authors are left without actionable feedback to address the issue effectively. Therefore, the comment is not helpful at all, as it does not offer any meaningful direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the proposed method\\'s inability to handle headpose, questioning why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as it lacks specific guidance on what modifications or additions should be made to the draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method\\'s inability to handle headpose, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the proposed method\\'s inability to handle headpose, questioning why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). The comment provides a specific reference to a previous work that addresses this issue, which is a clear and direct way to support the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the previous work to fully substantiate the claim. Overall, the claim is mostly verifiable, as it provides a solid foundation but lacks some depth in explanation. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose. It questions why the method cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021), which is already able to control both facial expression and headpose. This feedback is clear and actionable, as it prompts the authors to address this limitation and potentially improve their method by incorporating headpose control. However, the comment could be more helpful if it provided specific suggestions or examples on how to achieve this improvement. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) [1] to illustrate this point. The comment also mentions the well-known impact of rare spurious examples on trained models. While the comment provides a clear comparison and references external work, it does not explicitly instruct the authors to make any changes or improvements to their draft. The action is implicit and somewhat vague, as the authors can infer that they should consider the implications of these similarities but are not given specific guidance on how to address them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features discussed in the paper and backdoor triggers, providing examples from external works (Chen et al., 2017, and Gu et al., 2019) to support the comparison. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers, citing examples from Chen et al. (2017) and Gu et al. (2019) [1]. It also mentions the well-known impact of rare spurious examples on trained models. The comment provides specific references to external works, which helps substantiate the claim. However, it could be more fully verifiable if it included detailed explanations or examples of how these spurious features affect the model's performance. Overall, the comment is mostly verifiable, as it provides a solid foundation for the claim but lacks some depth in the explanation. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) [1] to illustrate this point. The comment also highlights the well-known impact of rare spurious examples on trained models. While the comment provides valuable context and references, it does not offer specific suggestions or guidance on how the authors might address this similarity or its implications for their work. The feedback is somewhat helpful as it points out an interesting observation, but it lacks actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the structural optimization is a key component of the paper and has been emphasized multiple times. However, it notes that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. While the comment identifies a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should either explain the source of the optimization algorithm or modify it to enhance the originality of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"structural optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the optimization algorithm is directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the structural optimization is a key component of the paper, but it is unclear whether this is a subjective opinion or a factual observation. The comment further suggests that the optimization algorithm is directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as it provides a general critique but lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the structural optimization is a key component that has been emphasized multiple times but appears to be directly taken from previous works. This observation raises a concern about the originality and contribution of the paper, as it suggests that the authors may not be adding significant value to the field by simply using existing optimization algorithms. The comment is somewhat helpful as it points out a specific area that could be improved, but it lacks detailed guidance on how the authors might address this issue or enhance the originality of their work. To be more helpful, the comment could suggest ways to differentiate the paper from previous works or provide examples of how to innovate in this area. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the introduction of baseline models or how to enhance the pipeline style method to achieve better results. Without specific suggestions or instructions, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need attention. The comment is specific in its critique of the results and the introduction of baseline models, but it lacks grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. It points out that the method does not provide better average results for both XVNLI and MaRVL, which is a critical observation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the performance or introduce the baseline models more effectively. Without detailed feedback or recommendations, the authors are left with a general understanding of the issues but without a clear path to address them. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or what specific changes they should consider. As a result, the authors are left without a clear understanding of how to address the feedback or enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context about the literature and the methodology used, it lacks specific details on what aspects of the paper are problematic or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the historical context of similar observations in the literature, suggesting that the current observation is not novel. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the literature to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. While the comment highlights a potential issue with the novelty of the observation, it lacks specific suggestions or guidance on how the authors might improve their work or address the critique. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable advice or detailed insights into how the authors might enhance their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This provides a clear and direct action for the authors to take, ensuring that their discussion of related work is comprehensive and accurate. The comment also highlights the importance of this action by noting that the current introduction may give a misleading impression. The explicit nature of the instruction, combined with the concrete reference to [A], makes this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: mentioning related work on modular networks for VQA, such as [A], to avoid giving a misleading impression about the state of the field. This provides clear guidance on how to improve the introduction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction does not mention related work on modular networks for VQA, which could give a misleading impression about the state of the field. The reviewer suggests that mentioning such work is crucial to provide a comprehensive overview. However, the comment does not provide specific examples or references to these related works, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references limits the verifiability of the claim, as the authors may struggle to identify and incorporate the missing information. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the discussion of related work on modular networks for VQA. It highlights the importance of mentioning such work to provide a comprehensive overview of the field and avoid giving a misleading impression about the state of the art. This feedback is clear and actionable, as it directs the authors to include relevant references in their related work section. However, the comment could be more helpful if it provided specific examples or references to guide the authors in selecting the appropriate works to mention. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment highlights an area for improvement, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should include comparisons with these methods but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific area of focus in the paper, namely the authors\\' emphasis on SSC and their lack of comparison with other subsequent methods like TSC and greedy subspace clustering by Park. However, it does not specify which part of the paper this focus is discussed in, making it weakly grounded. The comment is specific in identifying the need for comparisons with other methods, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The comment provides a logical reasoning by pointing out the lack of comparison with other methods, which is a common practice in research papers. However, it does not provide specific examples or references to these subsequent methods, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. This feedback is valuable as it highlights a gap in the paper\\'s comparison and analysis, prompting the authors to consider including these methods for a more comprehensive evaluation. However, the comment could be more helpful if it provided suggestions on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the distinction between when their proposed method is trained using only weak supervision and when it is semi-supervised trained. It provides a specific suggestion for renaming the column in Table 1 to \"Fully supervised\" from \"Supervised,\" which is a concrete action. Additionally, the comment suggests a more comprehensive approach by specifying the data used to train each model and creating two big columns to differentiate between mixture and single-source data. This feedback is clear and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of distinguishing between weak supervision and semi-supervised training, and it provides a concrete suggestion for renaming the column in Table 1. Additionally, it offers a more comprehensive approach by suggesting the use of two big columns to differentiate between mixture and single-source data. This level of detail and guidance makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors clarify the distinction between when their proposed method is trained using only weak supervision and when it is semi-supervised trained. It provides a specific example by suggesting a renaming of the column in Table 1 to \"Fully supervised\" from \"Supervised.\" The comment also offers a more comprehensive approach by suggesting the use of two big columns to differentiate between mixture and single-source data. This feedback is clear and provides a logical reasoning for the suggested changes, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the need for this distinction. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific area where the paper lacks clarity: the distinction between when the proposed method is trained using only weak supervision and when it is semi-supervised trained. It offers a concrete suggestion for renaming the column in Table 1 to \"Fully supervised\" from \"Supervised,\" which would help readers understand the data used for training. Additionally, the comment proposes a more comprehensive approach by suggesting the use of two big columns to differentiate between mixture and single-source data. This feedback is detailed and provides the authors with a clear path to improve the clarity and organization of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the contributions of the paper are small compared to previous methods, such as NCNet [6] and Sparse NCNet [21], and that it mostly consists of engineering improvements. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment does not provide any explicit or implicit actions for the authors to take in response to these observations. It lacks guidance on how the authors might address the concerns raised or improve their work. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper\\'s contributions, suggesting that they are small and mostly engineering-based, and notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, it does not specify which parts of the paper are being addressed, such as specific sections, experiments, or results that highlight these contributions. Additionally, the comment lacks specificity in detailing what aspects of the paper are considered small or engineering-based, or how the authors might differentiate their work from predecessors. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contributions of the paper are small and mostly engineering-based, and it is challenging to differentiate it from its predecessors due to similar performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the paper for its small contributions compared to previous methods, such as NCNet [6] and Sparse NCNet [21], and suggests that it mostly consists of engineering improvements. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment lacks specificity and actionable feedback, as it does not provide guidance on how the authors might address these concerns or improve their work. Without detailed suggestions or examples, the authors are left without a clear path for improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to remove the statements about semantic segmentation being a low-level cue from the paper. This is a clear and direct action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of semantic segmentation being classified as a low-level cue, suggesting that this classification is incorrect. However, it does not specify which part of the paper discusses this classification or where the statements about semantic segmentation being a low-level cue are located. Without explicit references to sections or specific statements, the authors cannot confidently determine the exact parts of the paper being addressed. This makes the comment weakly grounded, as the authors can only infer the general area of the paper being discussed. The comment is specific in its request to remove the statements about semantic segmentation being a low-level cue, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"semantic\" segmentation is not low-level since the categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this classification is incorrect. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the classification of semantic segmentation as a low-level cue. It suggests that this classification is incorrect because the categories are specified for each pixel, which contradicts the notion of low-level cues. This feedback is clear and actionable, as it directs the authors to reconsider their classification of semantic segmentation and potentially revise their statements accordingly. However, the comment could be more helpful if it provided additional context or examples to support the reasoning behind the classification. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. While the comment identifies a potential issue with the presentation of the results, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is implicit and somewhat vague, as it lacks concrete instructions on how to improve the presentation of the results. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the results, noting that the performance without reinforcement learning dropped lower than without dependency tree, and that the tables do not include cases where both dependency tree and reinforcement learning are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. This is a factual observation about the presentation of the results, which does not require verification or justification. The comment does not contain subjective opinions, suggestions, or claims that need to be supported. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the results in the ablation experiment. It points out that the performance without reinforcement learning dropped lower than without dependency tree, and it notes that the tables do not include cases where both dependency tree and reinforcement learning are not used. This feedback is clear and actionable, as it highlights a potential error or omission in the results that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to correct or clarify these issues. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should expand their experimental evaluation to include more datasets from the Federated learning benchmarks, such as LEAF, and consider relevant works like FedProx and FedMAX. It provides specific examples of datasets and references to relevant literature, which gives the authors clear guidance on how to improve their experimental section. The comment also highlights the importance of a comprehensive experimental evaluation for the paper to be considered strong. Therefore, the comment is highly actionable, as it provides explicit and concrete details on what the authors need to do to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and the specific issue of the results being presented only on the CIFAR-10 dataset, without considering other datasets from Federated learning benchmarks. It also provides specific examples of datasets and references to relevant works like FedProx and FedMAX, which helps the authors understand what needs to be addressed. The comment is specific because it clearly identifies the issue and provides actionable suggestions for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments section is a weakness because it only presents results on the CIFAR-10 dataset and does not consider other datasets from Federated learning benchmarks. The reviewer suggests that the authors should refer to relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is mostly verifiable as it provides specific references to external works that could support the suggestion for a more comprehensive experimental evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works address the issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. It suggests that the authors should consider other datasets from Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for guidance on different datasets and model types. This feedback is clear and actionable, providing the authors with a concrete direction for improving the comprehensiveness of their experimental evaluation. By addressing this issue, the authors can enhance the robustness and applicability of their findings. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, as stated in the table. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to use an alternative dataset is specific, as it provides a concrete example of what could be done to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a logical suggestion to verify the claim, as it proposes a method to test the robustness of the results. However, the comment lacks specific reasoning or evidence to support why the current dataset may not be sufficient or why the alternative datasets are more appropriate. While the suggestion is reasonable, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This feedback is somewhat helpful as it points out a potential weakness in the current dataset choice and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why the current dataset might not be suitable or how using an alternative dataset would address the issue. Overall, the comment provides some direction for the authors to consider, but it lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple CVEs or CWEs simultaneously and questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment also notes that the results are difficult to interpret or are marginal improvements at best. While the comment implies that the authors should clarify their methodology and its implications, it does not provide explicit guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their methodology and its relevance to previous work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It mentions previous work that considers multiple CVEs or CWEs simultaneously and questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. However, the comment does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and the interpretation of results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the ecological validity of the vulnerability discovery methodology, specifically the practice of considering a single vulnerability at a time. The reviewer references previous work that considers multiple CVEs or CWEs simultaneously and suggests that the results are difficult to interpret or are marginal improvements at best. However, the comment lacks specific references or detailed reasoning to support the claim about the ecological validity of the methodology. While it provides a general critique, it does not fully substantiate the claim with evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a significant concern about the vulnerability discovery methodology used in the paper. It questions the ecological validity of considering a single vulnerability at a time, noting that previous work has considered multiple CVEs or CWEs simultaneously. The comment also points out that the results are difficult to interpret or are marginal improvements at best. This feedback is valuable as it highlights a potential limitation in the study's methodology and suggests that the authors should clarify their approach and its relevance to existing work. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or improve the methodology. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for more explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how to address this issue or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors are left to infer what additional explanations are needed and how to present them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the need for more explanation regarding the relationship between a small degree of bias and a clear community structure, as well as the lack of intuitive understanding of the relationship between GCL and degree bias. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relationship between a small degree of bias and a clear community structure is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed explanation or references leaves the claim somewhat verifiable, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the relationship between a small degree of bias and a clear community structure needs more explanation. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the relationship between these concepts. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of similar approaches in the literature. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment does not explicitly instruct the authors to clarify or revise their methodology, it implies that the authors should provide a detailed explanation of this process. The action is implicit and somewhat vague, as it does not specify exactly what information should be added or how to address the question. However, the authors can infer that they need to clarify the methodology, which makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (182-183) and figures (2.c) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for non-stochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. The comment does not contain subjective opinions, suggestions, or judgments that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This is a clear and specific inquiry that prompts the authors to clarify a potentially confusing aspect of their methodology. By addressing this question, the authors can provide a more comprehensive explanation of their approach, which could enhance the clarity and understanding of their work for readers. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context. Overall, the comment is somewhat helpful as it identifies a gap in the paper and encourages the authors to clarify their methodology, but it could be more actionable with further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion regarding the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed. It specifically mentions the variables \"S\" and \"Xt\" and implies that the authors should provide additional information to clarify these terms. While the comment identifies the need for clarification, it does not explicitly instruct the authors to add this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation, but they are not given detailed instructions on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed. It mentions the variables \"S\" and \"Xt,\" which provides some grounding as the authors can infer that this relates to the methodology or results sections. However, the comment does not specify which part of the paper this issue occurs in, making it weakly grounded. The comment is specific in detailing what is confusing and what additional information is needed, but it lacks full grounding because it does not explicitly mention the section where this issue arises. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the notation and the explicit split between \"static\" and temporal features are confusing, requiring more information than is provided in the paper. The reviewer suggests that the variables \"S\" and \"Xt\" need clarification. However, the comment does not provide specific examples or detailed reasoning to support why this notation is confusing or how it could be improved. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, suggesting that it is confusing and requires more information. It points out the need for clarification regarding the variables \"S\" and \"Xt,\" which is a clear and actionable piece of feedback. By highlighting this confusion, the comment provides the authors with a specific area to address and improve the clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to clarify the notation or provided examples of how to present the information more clearly. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and lacks clarity. It notes that the paper states the choice is empirical but provides little motivation for this specific form. While the comment identifies a lack of clarity, it does not provide explicit guidance or suggestions on how the authors might improve the explanation or provide additional motivation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed justification for the choice of $\\\\theta$. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3. It highlights the lack of clarity and motivation for this choice, noting that the paper states it is empirical but provides little explanation. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically the motivation for a particular choice in Theorem 3. The comment is also specific because it details what is missing in the explanation, namely the motivation for the exact form of $\\\\theta$. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and lacks clarity. The reviewer notes that the paper states the choice is empirical but provides little motivation for this specific form. This claim is somewhat verifiable as it highlights a lack of explanation in the paper, but it does not provide specific examples or references to support the assertion. The authors would need to address this gap themselves to fully understand and improve the motivation for the choice. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3. It points out that while the paper states the choice is empirical, it provides little explanation or motivation for this specific form. This feedback is clear and actionable, as it directs the authors to enhance the clarity and justification of their choice, which is crucial for the paper\\'s understanding and credibility. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or examples of what additional information might be included. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a critical area of confusion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. While the comment implies that the authors should provide more details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides some specific feedback, suggesting that more details could be provided, such as the definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The authors might infer that it relates to the sections discussing graph notions or Algorithm 1, but this inference is not explicit. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1. However, the comment lacks specific examples or references to support the claim that more details are needed, making it somewhat verifiable. The authors would need to infer the exact areas where more detail is required, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It provides specific suggestions for improvement, such as providing more details on the definition of the resistance distance and offering more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. This feedback is clear and actionable, guiding the authors on how to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the writing style or organization of the paper. Overall, the comment is mostly helpful as it provides valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the originality of their work. There is no explicit or implicit action for the authors to take, leaving them without any direction on how to enhance the originality of their paper. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the originality are lacking or how the authors could address these issues. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or references to existing works that have already explored variable splitting or similar algorithms, the claim remains unverifiable. The authors are left without a clear understanding of why the originality is limited or how to address this issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific examples or references to existing works that have already explored variable splitting or similar algorithms. Without detailed guidance or suggestions for improvement, the comment lacks actionable feedback that could help the authors enhance the originality or novelty of their work. As a result, the comment is not helpful at all, as it does not offer any constructive direction for the authors to address the issue raised. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the evaluation of shape model invariance, specifically questioning whether the results on transformations of training images are sufficient to prove the point. It suggests that quantitative results on testing images might be needed to fully validate the claim. While the comment implies that the authors should provide such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the evaluation or what metrics to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the sufficiency of the evaluation on transformations of training images and suggests that quantitative results on testing images might be needed. This provides clear guidance on what aspect of the evaluation needs further exploration. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance. It suggests that quantitative results on testing images might be necessary to fully validate the claim. However, the comment does not provide specific examples, references, or detailed reasoning to support why testing images are crucial or how they would provide additional insight. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of testing images based on the general suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the evaluation of shape model invariance, questioning whether the results on transformations of training images are sufficient to prove the point. It suggests that quantitative results on testing images might be necessary to fully validate the claim. This feedback is clear and actionable, as it prompts the authors to consider additional evaluation methods or data to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what metrics to use. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss and compare their work with the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. This feedback is explicit and provides a clear action for the authors to take, which is to include a discussion and comparison with this related work. The comment also specifies the reason for this action, highlighting the relevance of the AAAI15 paper to the authors\\' work. Therefore, the comment is highly actionable, as it gives the authors a concrete step to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a discussion and comparison with this related work. This provides clear guidance on how to improve the paper by ensuring it covers relevant state-of-the-art work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the AAAI15 paper by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared to provide a better understanding of the state-of-the-art. The comment provides a specific reference to the AAAI15 paper, which is a clear and explicit source of evidence supporting the claim. This makes the claim mostly verifiable, as it offers a concrete reference for the authors to consider. However, the comment could be strengthened by providing more detailed reasoning or examples of how this work relates to the authors\\' paper, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential gap in the authors\\' work by pointing out a related paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this paper should be discussed and compared to provide a better understanding of the state-of-the-art. This feedback is clear and actionable, as it directs the authors to include a discussion and comparison with this related work, which could enhance the context and relevance of their paper. However, the comment could be more helpful if it provided specific guidance on how to integrate this comparison or discussed potential areas of overlap or divergence. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It explicitly asks for an evaluation of the method\\'s scalability on normal machines with a few cores and inquires about the conversion from the Sinkhorn method to optimal transport. These questions provide clear and explicit actions for the authors to take, such as conducting scalability tests and clarifying the conversion process. The feedback is specific and actionable, giving the authors concrete steps to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions the approach used to compute optimal transport, specifically asking about the conversion from the Sinkhorn method to optimal transport. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. The reviewer points out that the Sinkhorn method provides a doubly stochastic matrix, but it is not clear how to convert it to optimal transport. This claim is somewhat verifiable as it highlights a potential issue with the method\\'s scalability and the conversion process, but it lacks specific examples or references to support the claim fully. The authors would need to provide additional information or clarification to fully understand and address the concerns raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It specifically asks for an evaluation of the method\\'s scalability on normal machines with a few cores and inquires about the conversion from the Sinkhorn method to optimal transport. These questions are clear and actionable, providing the authors with specific areas to address and improve their draft. By seeking clarification on the scalability and conversion process, the comment offers valuable guidance that can help the authors enhance the comprehensiveness and robustness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study, which could lead to confusion and additional experimentation for practitioners. It specifically mentions the role of \\\\sigma in the RBF kernel and suggests analyzing how \\\\eta and \\\\tau in equation (7) affect performance. While the comment identifies areas that need further exploration, it does not provide explicit instructions on how to conduct these analyses or what specific experiments to perform. The feedback is somewhat actionable as it points out the need for additional analysis but lacks concrete guidance on how to implement it. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the ablation study, the RBF kernel, and Figure 4. It also specifies what is missing, namely an analysis of the role of \\\\sigma in the RBF kernel and how \\\\eta and \\\\tau in equation (7) affect performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an ablation study is missing, which could lead to confusion and additional experimentation for practitioners. It provides specific examples, such as the role of \\\\sigma in the RBF kernel and the impact of \\\\eta and \\\\tau in equation (7), suggesting that these aspects should be analyzed. The comment is mostly verifiable as it provides clear examples and logical reasoning for the claim, but it could be strengthened by referencing similar studies or providing more detailed explanations. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study, which could lead to confusion and additional experimentation for practitioners. It provides specific examples of what is missing, such as the analysis of the role of \\\\sigma in the RBF kernel and how \\\\eta and \\\\tau in equation (7) affect performance. This feedback is clear and actionable, as it guides the authors on what specific analyses are needed to improve the paper. However, the comment could be more helpful if it suggested how to conduct these analyses or provided examples of similar studies. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance their draft by addressing a critical gap in the methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might clarify or simplify the experimental procedures or evaluations to make the paper more accessible. Without actionable advice or specific recommendations, the authors are left without a clear path to address the issues raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not specify which part of the paper is particularly challenging to follow, making it weakly grounded. The comment is specific in identifying the issue of clarity in the experimental procedures and evaluations, but without explicit references to sections or figures, the authors cannot pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to identify and address the issues mentioned. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issues raised. Therefore, the comment is not helpful at all, as it does not offer any constructive direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the claim in section 2 about INRs operating on a per-data-instance basis is true but does not consider it an advantage. The reviewer suggests that a model that can only handle a single time series data is almost useless. While the comment highlights a potential limitation, it does not provide specific guidance on how the authors might address this issue or improve their draft. The action is explicit but lacks concrete details on how to implement changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2\" and a specific claim within that section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, pointing out that while it is true, it is not considered an advantage due to the limitation of handling only a single time series data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a model that can only handle a single time series data is almost useless, but it does not provide any supporting evidence or reasoning to substantiate this claim. The comment lacks specific examples or references to justify why this limitation is significant or how it impacts the model\\'s utility. Without additional context or evidence, the claim remains unverifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific claim in section 2 of the paper regarding the operation of INRs on a per-data-instance basis. It points out that while the claim is true, it is not considered an advantage because a model that can only handle a single time series data is almost useless. This feedback is somewhat helpful as it highlights a potential limitation in the paper\\'s claims, prompting the authors to reconsider the significance of their findings. However, the comment could be more helpful if it provided suggestions on how to address this limitation or improve the paper\\'s claims. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should introduce specific aspects of the model that are relevant to the example model being discussed. It provides a concrete example of what should be clarified, such as the fact that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is explicit and provides clear guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line 132, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be introduced, namely the specific aspects of the model that are relevant to the example model being discussed. The comment specifies that certain parameters are bounded on one side and that the model operates in a setting with finite subdivisions. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify specific aspects of the model, such as the finite subdivisions for certain parameters and the boundedness of parameters like acceleration and scaling. This feedback is based on logical reasoning, as it highlights the need for clarity in the context of the example model being discussed. However, the comment does not provide specific examples or references to support the claim, which could strengthen the justification. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors introduce the aspects of the specific model that are specific to the example model being discussed. It highlights the need for clarity regarding the finite subdivisions for certain parameters and the boundedness of parameters like acceleration and scaling. This feedback is clear and offers a concrete direction for improvement, helping the authors to enhance the clarity and specificity of their paper. However, the comment could be more helpful if it included additional suggestions or examples on how to effectively introduce these aspects. Overall, the comment is mostly helpful as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, specifically noting that most experiments are limited to RoBERTa-base and questioning the generalizability of the results to other models. It suggests investigating the results\\' generalizability to differences in model size, objective function, and architecture, and explicitly mentions the inclusion of more analysis and discussion for GPT-2. The reviewer provides a specific example by requesting the results of Figure 2 for GPT-2. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the experiments, noting the limited scope to RoBERTa-base and the need for generalization to other models. The comment further specifies the areas that require more analysis and discussion, such as GPT-2, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited to RoBERTa-base and questions the generalizability of the results to other models. It suggests investigating the results\\' generalizability to differences in model size, objective function, and architecture. The comment provides a specific example by requesting the results of Figure 2 for GPT-2, which adds a level of detail to the claim. However, the comment lacks references or detailed reasoning to fully substantiate the claim about the limitations of the experiments. Therefore, the claim is mostly verifiable, as it provides a clear direction for improvement but could benefit from more detailed justification or evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically noting that most experiments are limited to RoBERTa-base and questioning the generalizability of the results to other models. It suggests investigating the results\\' generalizability to differences in model size, objective function, and architecture, and provides a specific example by requesting the results of Figure 2 for GPT-2. This feedback is clear and actionable, as it directs the authors to expand their analysis and discussion to include more models, such as GPT-2, which could significantly enhance the comprehensiveness and robustness of the study. By addressing this feedback, the authors can improve the generalizability and applicability of their findings, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should consider applying their principles to other research areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate generalizability. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters, model, and experiments to areas beyond image data and ViT, suggesting that the authors should explore other research areas such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate generalizability. The comment provides a logical reasoning by questioning the focus on state-of-the-art performance and suggesting that the method should be tested on different architectures and tasks. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional evidence or context to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate the generalizability of their method. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their work and improve its relevance. However, the comment could be more helpful if it offered additional guidance on how to approach these other areas or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the scope and applicability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights an interesting observation about the performance of TTA methods on non-standard benchmarks, suggesting that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. While the comment implies that the authors should consider evaluating TTA on WILDS, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this evaluation or what specific aspects of WILDS should be considered. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA on more conditions of natural distribution shift, such as WILDS, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes an observation about the performance of TTA methods on non-standard benchmarks, suggesting that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. The comment provides a logical reasoning by suggesting that evaluating TTA on a more diverse set of conditions could enhance the paper\\'s contribution. However, it lacks specific examples or references to WILDS or other relevant datasets, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights an interesting observation about the performance of TTA methods on non-standard benchmarks, suggesting that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper\\'s scope and relevance. However, it lacks detailed guidance on how to implement this evaluation or what specific aspects of WILDS should be considered. While it offers a clear direction for improvement, the comment could be more helpful with additional details or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the condition or find an alternative approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the condition and the need for a more realistic approach, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and is unrealistic. The reviewer provides a logical reasoning by stating that they have never seen a step size grow with the sample size in practice, which would lead to unreasonably large learning rates for large-scale datasets. This reasoning is based on common knowledge and experience in the field, making the claim somewhat verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the required condition on the learning rate, which scales with the number of samples. It points out that this condition is not scalable and is unrealistic, as step sizes are not typically seen to grow with the sample size in practice. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition itself. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. The feedback is somewhat helpful as it directs the authors' attention to a potential weakness in their methodology, but it lacks actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the usefulness of the results in the context of machine learning algorithms and the analysis of the algorithm. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the paper. The comment lacks actionable details, such as recommending specific ways to demonstrate the significance of the paper or suggesting how to better integrate the results into machine learning applications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the usefulness of the results in the context of machine learning algorithms and the analysis of the algorithm, suggesting that the significance of the paper is poor. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology, making it difficult for the authors to identify the exact area needing revision. The comment is specific in its critique of the paper\\'s significance but lacks grounding, as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the significance of the paper is poor because the results are not clear in terms of their usefulness to machine learning algorithms or the analysis of the algorithm. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the usefulness of the results in the context of machine learning algorithms or the analysis of the algorithm is unclear. This feedback highlights a critical area for improvement, as it suggests that the paper\\'s significance may be compromised due to a lack of clarity in its application. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the clarity of the paper. While it points out a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use a more convincing setting for their unlabeled data, similar to the one used in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. (2018). The comment explicitly states the action to take, which is to use a more convincing setting, and provides a specific reference to guide the authors on how to implement this change. The suggestion is clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the label distribution of unlabeled data is impractical in real-world applications and suggests using a more convincing setting as in the referenced paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in real-world applications. The reviewer suggests using a more convincing setting as in the referenced paper by He et al. (2018), which directly samples unlabeled data from millions of reviews. This claim is somewhat verifiable as it provides a specific reference to support the suggestion for a more realistic setting. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current setting is impractical. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of unlabeled data in the paper, noting that the label distribution is perfectly balanced, which is impractical in real-world applications. It suggests that the authors should use a more convincing setting, as demonstrated in a referenced paper, to address this issue. The comment provides a clear and actionable suggestion for improvement, offering a specific reference to guide the authors in making their approach more realistic. This feedback is detailed and constructive, making it highly helpful for the authors to enhance their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify the sampling process or provide additional information, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible. The comment further compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that sampling from the DPP is more difficult. This makes the claim somewhat verifiable, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This feedback is clear and actionable, as it points out a potential area of confusion in the paper and prompts the authors to clarify the sampling process. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue, such as recommending specific methods or examples to clarify the sampling process. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that the observations presented do not evaluate their generalizability to few-shot learners beyond Prototypical Networks. This suggests that the scope of the submission\\'s contributions may be limited in terms of understanding the properties of episodic training. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or evaluate the generalizability of their observations. The action is implicit and vague, as the authors are left to infer that they need to expand their evaluation to include other few-shot learners, but without concrete steps or examples, it remains unclear how to implement this suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of generalizability of the observations presented in the paper, specifically questioning whether they extend beyond Prototypical Networks to other few-shot learners. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in its critique of the lack of evaluation for generalizability, but without clear grounding, the authors may struggle to identify the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the observations presented in the paper do not evaluate their generalizability to few-shot learners beyond Prototypical Networks, which limits the scope of the submission\\'s contributions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that the observations presented do not evaluate their generalizability to few-shot learners beyond Prototypical Networks. This critique highlights a potential gap in the scope of the submission\\'s contributions, suggesting that the paper may not fully explore the properties of episodic training. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or expand their evaluation to include other few-shot learners. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. While it identifies an area of potential improvement, it lacks concrete steps or actions for the authors to take. The feedback is somewhat actionable as it highlights an issue but does not offer specific guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not specify which part of the paper discusses Equation 3 or where this issue is addressed, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper. The comment is specific in detailing the issue with Equation 3 and the potential problem with modal subsets, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that this issue exists or needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s methodology, specifically questioning how Equation 3 addresses the problem of different modalities contributing differently across instances. It highlights a concern about instances with good performance in modality A versus modality B, suggesting that Equation 3 may not adequately handle this variation. While the comment raises an important point, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides feedback on the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the abstract. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details on evaluation and outcomes, but they are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues. This provides clear guidance on what needs to be addressed in the abstract, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This is a subjective claim that requires justification, as it suggests that the abstract is incomplete in terms of evaluation and outcome. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to enhance the abstract by including details on evaluation and outcomes. However, the comment could be more helpful if it provided suggestions on how to effectively incorporate these details or examples of what might be included. Despite this, the comment is mostly helpful as it guides the authors toward improving the clarity and completeness of their abstract.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the experimental results and questions the usefulness of the experiments section. It points out that the paper aims to solve POMDP problems with non-convex value functions but does not provide experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacy-preserving data collection. The comment implies that the authors should include experiments on these settings to better motivate their solution. However, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to add experiments but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with non-convex value function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on specific settings, such as surveillance in museums with thresholded rewards or privacy-preserving data collection. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses skepticism about the experimental results, questioning the usefulness of the experiments section. It suggests that the paper should include experiments on specific settings, such as surveillance in museums with thresholded rewards or privacy-preserving data collection, to better motivate the solution. However, the comment lacks specific examples or detailed reasoning to support why these experiments are necessary or how they would improve the paper. The lack of concrete evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these experiments based on the general critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a significant concern about the experimental results, questioning their relevance and usefulness. It points out that the paper aims to solve POMDP problems with non-convex value functions but does not provide experiments on specific settings mentioned, such as surveillance in museums with thresholded rewards or privacy-preserving data collection. This feedback is clear and actionable, as it highlights a gap in the experimental section that the authors need to address to better motivate their solution. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these experiments or what additional data or analysis would be beneficial. Overall, the comment is mostly helpful as it identifies a critical area for improvement and guides the authors toward enhancing the experimental section of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment also points out a discrepancy between the problem setting description and the original MFDA paper. While the comment highlights an issue, it does not provide explicit instructions or concrete suggestions on how the authors should address this confusion or reconcile the differences. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description and potentially align it with the original MFDA paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section\" and references specific elements of the description, such as \"single target domain with sparse labels\" and \"target distribution p_T(x, y) with label observation.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the confusion regarding the use of unlabeled data in source domains and the discrepancy with the original MFDA paper. It raises questions about the problem setting and suggests that the authors clarify these aspects. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It references the original MFDA paper (Yue et al., 2021a) to highlight a discrepancy in the problem setting description. The comment questions whether the unlabeled data in source domains are used during training, as in the original paper. This provides a logical basis for the claim, as it points out a potential inconsistency in the paper\\'s description. However, the comment could be strengthened by providing more detailed examples or references to specific sections in the paper where the confusion arises. Overall, the claim is mostly verifiable, as it provides a logical reasoning and references an external work, but it lacks detailed evidence or examples within the paper itself. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It points out a discrepancy between the description in the paper and the original MFDA paper, which could lead to misunderstandings among readers. The comment raises important questions about the problem setting and suggests that the authors clarify these aspects. While it highlights a critical issue, it could be more helpful by providing specific suggestions on how to address the confusion or align the description with the original paper. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a crucial area for clarification, but it lacks detailed guidance on how to improve the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an epoch-wise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative analysis of deterministic and stochastic methods. While the comment implies that the authors should consider including an epoch-wise analysis, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this analysis. The action is implicit and somewhat vague, as the authors can infer the need for an epoch-wise analysis but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an analysis of epoch-wise behavior, particularly for finite sum settings, to gain insights into optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis of deterministic and stochastic methods. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of the type of analysis and potential insights it could provide, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an epoch-wise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. The comment also mentions the potential for comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear direction for further analysis, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a reasonable basis for the suggestion but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a potential area for improvement by proposing an epoch-wise analysis, particularly for finite sum settings, to gain insights into the behaviors of optimization algorithms. It provides a specific example of investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis of deterministic and stochastic methods. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their analysis and understanding of their results. However, it could be more helpful if it included specific suggestions on how to implement this analysis or examples of similar studies that have used epoch-wise analysis. Overall, the comment is mostly helpful as it provides a valuable insight into improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they should include these citations and algorithms, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide direct steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the article is incremental, stating that it is essentially a combination of GraphRAG and GraphCare. It also notes the absence of key baselines and the need to introduce essential RAG algorithms like MedRetriever and KGRAG. While the comment provides some reasoning by referencing specific algorithms, it lacks detailed justification or examples to fully substantiate the claim about the incremental nature of the contribution. The mention of specific algorithms like MedRetriever and KGRAG adds some support, but the overall justification is somewhat vague. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some support but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper, identifying several areas for improvement. It highlights the incremental nature of the contribution, noting that it is essentially a combination of existing methods like GraphRAG and GraphCare. The comment also points out the lack of citation for key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is clear and actionable, as it directs the authors to address specific gaps in their work, such as providing a more comprehensive literature review and introducing relevant algorithms. However, the comment could be more helpful if it offered suggestions on how to integrate these algorithms or provided examples of how to enhance the contribution. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by identifying key areas for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper\\'s classification of extreme speech, noting that the distinction between derogatory and exclusionary extreme speech is unclear. It provides a concrete example from the sample data file, asking why a particular instance is classified as exclusionary extreme speech but derogatory extreme speech. The comment also raises questions about the role of local regulations in annotations and their impact on zero-shot cross-country classification. While the comment identifies a clear issue and provides specific examples, it does not explicitly instruct the authors on how to address these concerns. The action is implicit but concrete, as the authors can infer that they need to clarify the classification criteria and potentially address the impact of local regulations. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Paper Summary\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clear distinction between the three classes of extreme speech and provides a specific example from the sample data file to illustrate the confusion. The comment raises questions about the role of local regulations in annotations and their impact on zero-shot cross-country classification, which further clarifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the distinction between derogatory and exclusionary extreme speech, specifically questioning the classification of a particular instance. It provides a concrete example from the sample data file and highlights the role of local regulations in annotations. This level of detail and specific questioning supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to specific regulations, which would further solidify the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion in the paper regarding the distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file to illustrate the issue, which is a valuable step towards clarifying the classification criteria. The comment also raises questions about the role of local regulations in annotations and their impact on zero-shot cross-country classification, prompting the authors to consider these factors in their analysis. By offering detailed feedback and specific examples, the comment empowers the authors to make significant improvements in their draft, making it highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment also offers a rationale for why this information is important, which further clarifies the action. Therefore, the comment is highly actionable, as it provides explicit guidance on what needs to be done and why.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added to the paper, namely, a graph to understand the performance improvement and whether it stems from the network design or the nature of ImageNet. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. The comment provides a logical reasoning for why this information is important, as it helps understand whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment does not provide specific examples or references to support the claim that \"large fraction of images can be done with Glance,\" which would strengthen the justification. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This request is clear and directly addresses a gap in the paper, offering a concrete way for the authors to enhance their analysis and understanding of the performance improvement. Additionally, the comment raises an important question about whether the performance improvement is due to the network design or the nature of ImageNet, which is a valuable consideration for the authors to explore. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in understanding the implications of this analysis. Overall, the feedback is mostly helpful as it offers clear and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to change their notation to make it mathematically correct, unless doing so would make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment implies that the authors should make these changes, it does not provide explicit instructions on how to implement them or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer that they need to modify the notation but may not be entirely sure of the exact changes required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear feedback on the need for mathematical correctness and the introduction of notation, specifying what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the notation used in the paper, specifically \"L_l\" instead of \"L,\" needs to be changed to be mathematically correct. The reviewer provides a logical reasoning by stating that the current notation might make other equations messy. However, the comment lacks specific examples or references to support why the current notation is incorrect or how it affects the mathematical correctness of the paper. This makes the claim somewhat verifiable, as the authors would need to further investigate and justify the changes themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the need for mathematical correctness and the introduction of notation. It suggests that the notation \"L_l\" should be changed to \"L\" and that this change should be introduced beforehand. This feedback is clear and actionable, providing the authors with concrete steps to improve the mathematical rigor and clarity of their work. However, the comment could be more helpful if it explained why the current notation is problematic or how it affects the mathematical correctness of the paper. Overall, the comment is mostly helpful as it directs the authors to make specific improvements, but it could be more comprehensive with additional context or reasoning. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or conduct the study. The action is implicit and vague, as the authors are left to infer that they should investigate the effect of noise accumulation and its implications for homomorphic encryption. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitations of using homomorphic encryption for sequential ensembling, specifically mentioning the issue of noise accumulation. However, it does not specify which part of the paper discusses sequential ensembling or homomorphic encryption, making it weakly grounded. The comment is specific in identifying the issue of noise accumulation and its impact on the use of deep neural networks, but it lacks grounding in terms of the paper\\'s structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the limitations of using homomorphic encryption for sequential ensembling prevent the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the use of homomorphic encryption for sequential ensembling, namely the issue of noise accumulation. It highlights the importance of studying this effect and its implications for the use of even single deep neural networks on homomorphically encrypted data. While the comment points out a relevant area for further investigation, it lacks actionable guidance or suggestions on how the authors might address this limitation or conduct the necessary study. The feedback is somewhat helpful as it provides insight into a potential area for improvement, but it could be more beneficial with additional direction or specific recommendations. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, as shown in Figure 5. It suggests that the proposed method might be more effective under scenarios where the training and evaluation time-steps are different. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as it leaves the authors to infer that they should explore scenarios with different time-steps but does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation time-steps are the same. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation time-steps are different. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed methods is questionable when the training and evaluation time-steps are the same, as shown in Figure 5. The reviewer suggests that the proposed method might be more effective under scenarios where the training and evaluation time-steps are different. However, the comment lacks specific examples or detailed reasoning to support this claim. It provides a logical suggestion but does not fully substantiate the claim with evidence or references, making it somewhat verifiable. The authors would need to explore this further to fully understand the basis of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, as shown in Figure 5. It questions the significance of the proposed methods in achieving good performance when the time-steps are identical. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation time-steps are different. This feedback is clear and actionable, as it prompts the authors to explore and discuss scenarios where the time-steps differ, potentially leading to a more comprehensive understanding of the method\\'s effectiveness. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback provides a clear and explicit action for the authors to take, which is to further elaborate on the disentanglement process and its guarantees. The comment is specific and actionable, as it directs the authors to address a particular aspect of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed and suggesting that the authors highlight how disentanglement is realized and guaranteed without certain bias types. However, it does not specify which part of the paper discusses disentanglement, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding disentanglement, such as highlighting how it is realized and guaranteed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions disentanglement as a limitation, but suggests that the authors should further elaborate on how disentanglement is realized and guaranteed without certain bias types. This feedback is somewhat verifiable as it provides a logical reasoning for the claim by pointing out a potential gap in the paper. However, it lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the disentanglement process and its guarantees. By addressing this feedback, the authors can enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improvement but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, it does not provide specific details on which regularization trick should be used or how to implement it. The action is explicit but vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its recommendation but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or how it would improve the comparison. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on which regularization trick to use or how to implement it. The suggestion is somewhat helpful as it points out a possible enhancement, but it does not offer actionable steps for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3. This suggestion is clear and provides a concrete action for the authors to take, as it specifies exactly what needs to be added to the figure for comparison. The authors know exactly what to do to improve their draft based on this feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the left graph of Figure 3, namely, the learning curve for a model without any mean teacher or pi regularization. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3 to compare the effect of these techniques on learning. This is a logical suggestion to enhance the clarity and comprehensiveness of the figure, but it does not contain any subjective claims, opinions, or judgments that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3, which would allow for a direct comparison of the effects of these techniques on learning. This feedback is clear and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their results. By addressing this suggestion, the authors can provide a more thorough analysis of their findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed objective equation requires optimization over both the parameters of the transformation and the shared model, but it does not discuss the effect on the number of parameters compared to prior work like AlignFlow. While the comment highlights an area that needs clarification, it does not provide explicit guidance on how the authors should address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the effect on the number of parameters, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clearer discussion on the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to AlignFlow or other relevant works, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation and the shared model. It points out that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. This feedback is clear and actionable, as it highlights an area where the authors need to provide more detailed analysis and comparison with existing work. By addressing this point, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific suggestions on how to present this comparison or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the handling of different types of inputs, such as bio-medical signals or speech, and suggests that the authors should discuss and present their solutions in the paper. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what aspects of the solutions should be discussed. The mention of \"citation\" being \"a bit disordered\" is vague and does not offer actionable advice. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement the suggested changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the handling of different types of inputs, such as bio-medical signals or speech, and suggests discussing and presenting solutions in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting that the authors should discuss and present their solutions regarding different types of inputs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the handling of different types of inputs, such as bio-medical signals or speech, and suggests discussing and presenting solutions in the paper. However, the comment does not provide specific examples or detailed reasoning to support why this is an issue or how it could be addressed. The mention of \"citation\" being \"a bit disordered\" is vague and lacks context. Without additional explanation or examples, the claim is difficult for the authors to understand and address, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should discuss and present their solutions for handling different types of inputs, such as bio-medical signals or speech. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance its applicability and relevance. However, the comment could be more helpful if it provided specific examples or suggestions on how to approach this discussion or solution. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is somewhat actionable as it points out a potential limitation in the results, but it lacks specific guidance on how the authors might address this issue or improve their methodology. Overall, the comment is somewhat actionable, as it raises questions and points out a potential limitation but does not provide concrete steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the implications of Eq. 4 and critiques the improvement of the designed solutions in Table 5, providing a clear example of the marginal improvement on the OfficeHome dataset. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that requires no verification, as it is a request for clarification. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This is a factual statement without a claim or opinion, as it describes the results without suggesting changes or making subjective judgments. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two points. First, it questions the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that prompts the authors to clarify their mathematical reasoning. Second, it critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is somewhat helpful as it points out a potential limitation in the results, but it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. Overall, the comment provides some insight but could be more actionable with additional details or suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing state-of-the-art reference in the experiment of face recognition, specifically mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. It also provides a link to the work and notes that the triplet loss is used, reporting results on a dataset similar to Webface. The comment further compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This feedback is explicit and provides concrete details on what reference should be included and how it compares to the current results. The authors know exactly what action to take to improve their draft by adding this reference and potentially revising their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the \"state-of-the-art references,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the missing reference, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu, and provides a link to the work. Additionally, it details the comparison with the VRF results on LFW, noting that it is better than the results in Table 3. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the experiment of face recognition, specifically mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. The reviewer provides a link to the work and notes that it uses the triplet loss and reports results on a dataset similar to Webface. The comment further compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This provides a clear and specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or additional context to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting the absence of certain state-of-the-art references in the experiment of face recognition. It mentions a particular work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and provides a link to the work. The comment also highlights that the triplet loss is used in this work, which is similar to the dataset used in the paper, and reports better results on LFW compared to those presented in Table 3. This feedback is actionable as it directs the authors to include a relevant reference and potentially revise their results to improve the credibility and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this reference into the paper. Overall, the comment is mostly helpful, as it offers clear guidance on an area for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Wh-types\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, as the authors are left to infer that they need to explore alternative methods or improve the template mapping process. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the question answering process, namely the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper discusses this process, making it weakly grounded. The comment is specific in detailing the potential issue with generalization for questions that are not \"Wh-types\" or transformable. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process might lead to poor generalization due to the use of template mapping to transform questions into masked statements. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases or studies that demonstrate the potential issue with generalization. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support for the authors to fully understand and address the issue.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Wh-types\" or transformable. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative methods. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform [1]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of non-novelty or how to improve the draft based on this information. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a volumetric representation in the deformation field, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it references the work of VolumeDeform [1], which provides a clear context for the non-novelty claim. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform [1]. This claim is supported by the inclusion of a specific reference, which provides a clear basis for the assertion. However, the comment could be strengthened by providing more detailed information about how VolumeDeform [1] uses volumetric grids or how it relates to the current work. Overall, the claim is mostly verifiable due to the reference, but it could be more robust with additional context or explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform [1]. While this information is relevant, the comment lacks actionable feedback or suggestions for improvement. It does not provide guidance on how the authors might address this issue or how it could impact their work. Without specific advice or constructive criticism, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICL-HAR, which is a method aimed at improving consistency and verifiability. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the action is explicit, it lacks concrete guidance on how to discuss or acknowledge this issue in detail. The authors are given a clear direction to address the problem but may struggle with the specifics of how to do so effectively. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ICL-HAR, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the significant drop in accuracy scores (from 70.4 to 55.6 on TRIP) and suggests that this should be discussed or acknowledged in more detail. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation of ICL-HAR has significantly impacted the accuracy scores, specifically noting a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICL-HAR method, which is aimed at improving consistency and verifiability. It suggests that this issue should be discussed or acknowledged in more detail in the main text. This feedback is clear and actionable, as it highlights a potential trade-off between accuracy and other benefits, such as consistency and verifiability. By addressing this point, the authors can provide a more comprehensive understanding of the method\\'s impact and potential limitations. However, the comment could be more helpful if it offered specific suggestions on how to discuss or acknowledge this issue in detail. Overall, the comment is mostly helpful, as it directs the authors to an important area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is clearly inspired by an example from previous work. This is a direct and concrete action, leaving no ambiguity about what the authors need to do. The comment provides a clear and specific instruction, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to cite the source of the example. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by an example from previous work and requests appropriate citation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to verify the claim or identify the source of inspiration. Without detailed evidence or references, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by an example from previous work and requests appropriate citation. This feedback is clear and actionable, as it directs the authors to address a potential issue with plagiarism or lack of attribution. By citing the source, the authors can ensure proper credit and avoid any potential ethical or academic integrity concerns. However, the comment could be more helpful if it provided examples of similar work or suggested how to integrate the citation into the text. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the limited innovations in network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address these limitations. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the limited innovations in network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not specify which part of the paper discusses these limitations or how they could be improved. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment lacks specificity as it does not provide detailed guidance on what aspects of the network architecture or constraint embedding need improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the innovations in network architecture design and constraint embedding are limited, and it references the authors\\' discussion about the performance being limited by the oracle expert. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim somewhat verifiable, as it requires more information to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not provide any specific suggestions or guidance on how the authors might address this limitation or improve their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that comparing the performance of the model only pre-trained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the authors should provide the performance of the models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The explicit nature of the action and the detailed suggestion make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that comparing the performance of the model only pre-trained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the authors should provide the performance of the models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in detailing what needs to be addressed, such as providing performance comparisons with different losses. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparing the performance of the model only pre-trained on synthetic data is unfair and suggests that demonstrating the importance of the proposed three projection errors is more appropriate. The comment provides a logical reasoning by suggesting that a more comprehensive evaluation should include fine-tuning on real-world datasets with different losses. However, it lacks specific examples or references to support the claim that the current approach is unfair or to substantiate the suggestion for a more comprehensive evaluation. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that comparing the performance of the model only pre-trained on synthetic data is unfair. It suggests that a more appropriate approach would be to demonstrate the importance of the proposed three projection errors by providing the performance of the models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This feedback is clear and actionable, offering a specific suggestion for improving the experimental design and analysis. By addressing this critique, the authors can enhance the validity and comprehensiveness of their results. Therefore, the comment is rated as highly helpful, as it provides detailed guidance that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. It suggests that it is also common to average over subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). While the comment highlights a potential alternative approach, it does not explicitly instruct the authors to adopt this method or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer that they might consider averaging over subword representations but are not given explicit instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular statement about taking the embedding of the first subword token as the verb embedding and suggests an alternative approach by referencing Hewitt and Manning (2019, footnote 4). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach to handling subword representations, referencing Hewitt and Manning (2019, footnote 4). This provides a specific reference to support the claim that averaging over subword representations is a common practice. However, the comment does not elaborate on why this alternative approach is preferable or how it might improve the paper. While the reference is a step towards verification, the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by pointing out a common practice in handling subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). This feedback is actionable and offers a concrete alternative approach that the authors can consider to enhance their work. However, the comment could be more helpful if it explained why averaging over subword representations might be beneficial or how it could improve the paper\\'s methodology. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages discussing the difference between the traditional method and the proposed method. While the comment implies that these actions should be taken, it does not provide explicit instructions on how to conduct the calibration curves or discuss the differences. The authors can infer the actions but may find it challenging to execute them without detailed guidance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the model AUC\" and \"the related studies,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as conducting calibration curves to demonstrate consistency between predicted scores and actual risks, and discussing the difference between the traditional method and the proposed method. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The reviewer encourages the use of calibration curves to show this agreement. The comment provides a logical reasoning for the claim, suggesting that the model AUC may not fully capture the clinical relevance of the scoring system. However, it lacks specific examples or references to support the claim or provide guidance on how to conduct calibration curves. This makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the model's ability to assess discriminant ability, specifically the lack of consistency between predicted scores and actual risks. It suggests that calibration curves could be used to demonstrate this agreement, which is crucial for clinical scoring systems. The comment also encourages discussing the difference between the traditional method and the proposed method, providing actionable feedback on areas for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct calibration curves or discussed potential challenges in implementing this approach. Overall, the feedback is mostly helpful as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional details or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2\\'s requirement for an approximately identical mean as the assumption. The reviewer suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. While the comment identifies areas that need further discussion, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not seem to change much with sparsification, and it questions the importance of Lemma 2\\'s requirement for an approximately identical mean as the assumption. The comment further suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2\\'s requirement for an approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2\\'s requirement for an approximately identical mean as the assumption. The reviewer points out that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This feedback is clear and actionable, as it highlights a critical area that needs further discussion and explanation. By addressing these points, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to discuss or address these conditions. Overall, the comment is mostly helpful, as it directs the authors to a specific area that requires attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the update, suggesting that it should integrate over all possible environments to be meaningful. It also mentions that the bolded sections on page 6 should be broken out into paragraphs due to being a \"huge wall of text.\" While the comment implies that the authors should clarify the meaning of the update and consider restructuring the text, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the update and restructure the text. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it is a \"huge wall of text\" and should be broken out into paragraphs. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of the update, suggesting that it should integrate over all possible environments to be meaningful. The reviewer provides a logical reasoning by stating that the true environment is not known at update time, implying that the update should consider all possibilities. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The suggestion to break out the bolded sections into paragraphs is a factual statement without a claim, so it is classified as \"No.\" Therefore, the overall comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the meaning of the update, suggesting that it should integrate over all possible environments to be meaningful. This is a relevant point that could help the authors clarify their methodology. Additionally, the comment points out that the bolded sections on page 6 should be broken out into paragraphs due to being a \"huge wall of text,\" which is a clear and actionable suggestion for improving the readability and structure of the paper. However, the comment could be more helpful if it provided specific examples or further guidance on how to integrate the update or restructure the text. Overall, the feedback is mostly helpful as it identifies two areas for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the experiments, questioning the strength and fairness of the baselines used. It suggests that the authors should use the default settings of these baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as which baselines to include or how to discuss limitations. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues related to the experiments, including the strength and fairness of the baselines, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as using the default settings of baselines and including specific baselines related to BO with discrete and categorical variables. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the lack of strength and fairness in the experiments, the absence of certain baselines, and the need to discuss limitations and societal impacts. However, the comment lacks specific examples or detailed reasoning to support these claims. It provides general observations without concrete evidence or references to substantiate the assertions. This makes the claims difficult for the authors to address effectively, as they are not provided with sufficient information to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It questions the strength and fairness of the experiments, suggesting that the authors should use the default settings of baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment highlights important areas for enhancement, it lacks specific guidance or suggestions on how to address these issues, such as which baselines to include or how to discuss limitations. This limits the comment\\'s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point observes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation, whether it is a concern or a normal part of the training process, or what steps the authors should consider to improve their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a specific observation about a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a particular experiment or analysis. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. This lack of grounding makes it difficult for the authors to understand the context of the comment. Additionally, the comment lacks specificity as it does not provide details on what needs to be addressed or improved regarding this observation. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point observes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the observation or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment observes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any context, explanation, or suggestions for how this observation might impact the paper or what the authors should do to address it. Without additional information or guidance, the authors are left without a clear understanding of the significance of this observation or how to improve their draft. Therefore, the comment is not helpful at all, as it lacks actionable feedback or insight.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. It also points out a typo in the text, suggesting a correction. While the comment identifies a potential area for further exploration and provides a specific correction, it does not offer explicit guidance on how the authors should address the lack of insight or conduct further analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the reasons behind the similar performance and consider whether it is specific to the sparsity detection problem or a broader issue with GNNs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of insight into why all sparsity patterns perform similarly and suggesting that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. Additionally, it corrects a typo in the text, which further clarifies the specific issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform similarly without providing insight into why this is the case. It raises a question about whether this is a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This feedback is somewhat helpful as it prompts the authors to consider the implications of their findings and potentially explore further analysis or discussion to provide more insight into the results. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue or what additional analysis might be beneficial. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the derivation from Equation 3 to Equation 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, ensuring that the temperature \u03c4 is included in the derivation or mentioned in the paper. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqn. 3\" and \"Eqn. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing temperature \u03c4 in the derivation. The comment provides a clear and actionable suggestion to either show the temperature \u03c4 in a rigorous way or mention it in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the inclusion of \u03c4 is necessary or how it would impact the derivation. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the derivation in the paper, noting that the temperature \u03c4 is missing from the equations. It provides a clear and actionable suggestion to either show the temperature in a rigorous way or mention it in the paper. This feedback is valuable as it directs the authors to a specific area that needs attention and provides a concrete step to improve the clarity and rigor of their work. However, the comment could be more helpful if it explained why the inclusion of \u03c4 is important or how it affects the derivation. Overall, the comment is mostly helpful as it offers actionable guidance, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests adding a citation on differential privacy, specifically mentioning a standard work like [2] as a reference. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. The comment specifies a particular standard work, [2], which could be used as a reference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and specific request for additional information, providing a direct action for the authors to take. The suggestion is well-supported by the explicit mention of a specific reference, which helps the authors understand the need for this addition. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the addition of a citation on differential privacy, specifically mentioning a standard work like [2]. This feedback is clear and direct, offering the authors a concrete step to enhance the comprehensiveness and credibility of their work. By including this reference, the authors can provide a more thorough context for their discussion on differential privacy, which is beneficial for both the reader and the authors themselves. Therefore, the comment is highly helpful, as it offers a clear and actionable suggestion that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part addresses a claim in the paper regarding the methodology requiring significant additional assumptions. The reviewer challenges this claim by pointing out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback provides a clear and explicit action for the authors to reconsider their claim and potentially revise it. The second part of the comment points out an inequality with the wrong sign, providing a specific line number for correction. This feedback is explicit and concrete, giving the authors clear guidance on how to address both issues. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the claim regarding additional assumptions and the inequality with the wrong sign. The comment specifies what needs to be addressed, such as reconsidering the claim about additional assumptions and correcting the inequality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a claim about the methodology requiring significant additional assumptions and a correction regarding an inequality. The first part challenges the claim by providing a logical reasoning that the additional assumption is natural in many machine learning settings, which supports the claim that the assumption is not as extreme as stated. The second part provides a specific correction to an inequality, which is a factual statement requiring no verification. Overall, the comment is mostly verifiable for the first part due to the logical reasoning provided, while the second part is verifiable as it corrects a factual error. Therefore, the overall score is 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it challenges the claim in the paper that the methodology requires significant additional assumptions, pointing out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback is helpful as it prompts the authors to reconsider their claim and potentially revise it, providing a more accurate perspective on the methodology\\'s assumptions. Second, the comment corrects an inequality on line 310, specifying that the base alpha should be less than one. This is a clear and actionable suggestion that directly improves the accuracy of the paper. Both pieces of feedback are specific and constructive, making the comment mostly helpful. However, it could be more comprehensive by offering additional suggestions or explanations for improving the clarity of the assumptions or the inequality. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by comparing them experimentally. It also recommends including a significant discussion on the advantages and disadvantages of the three methods for transforming high-dimensional data to low-dimensional latent space. While the comment implies that the authors should conduct additional experiments and provide a more comprehensive discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as comparing Shapely values with other methods like CaCE or raw gradients, and discussing the advantages and disadvantages of different methods for transforming high-dimensional data to low-dimensional latent space. This level of detail provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by comparing them experimentally. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming high-dimensional data to low-dimensional latent space. While the comment provides a logical reasoning for the need to compare methods and discuss their advantages, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming high-dimensional data to low-dimensional latent space. This feedback is clear and actionable, as it guides the authors to conduct additional experiments and provide a more comprehensive analysis of the methods being compared. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on in the discussion. Overall, the comment is mostly helpful as it provides valuable insights for improving the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should include a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 is being addressed, making it weakly grounded. The comment is specific in suggesting a comparison with prior efforts, which provides some guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it explain why such a comparison would be beneficial. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential area for improvement in the paper, suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is somewhat helpful as it points out a specific aspect of the related work section that could be strengthened by including a comparative analysis. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects should be highlighted. While it provides a direction for improvement, it does not offer actionable steps or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not provide explicit instructions on how to conduct this analysis or what specific steps the authors should take to address this suggestion. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of varying the number of scenarios, but they are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting an area for further exploration, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. This feedback is somewhat helpful as it identifies a potential area for further exploration and analysis, which could lead to a deeper understanding of the results. However, the comment lacks specific guidance on how to conduct this analysis or what specific questions to address, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model\\'s ability to predict it. It suggests that disturbances in the training data might affect the model\\'s ability to generate correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should consider the impact of disturbances on the model\\'s performance but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between generating a quality label and the model\\'s ability to predict it, suggesting that disturbances in the training data might affect the model\\'s performance. However, it does not specify which part of the paper this issue pertains to, such as a specific section, experiment, or methodology. Additionally, while it raises a concern, it lacks specificity in terms of what needs to be addressed or improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model\\'s ability to predict it, suggesting that disturbances in the training data might affect the model\\'s performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the question or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the relationship between generating a quality label and the model\\'s ability to predict it. It suggests that disturbances in the training data might affect the model\\'s performance, which is a valid concern that could impact the robustness and accuracy of the model. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or conduct further experiments to validate the model\\'s performance under different conditions. While it identifies a potential area for improvement, the feedback is incomplete and does not offer detailed insights or steps for the authors to take. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit suggestions for improvement or areas that need further exploration. Without any actionable feedback or guidance, the authors are left without a clear understanding of what aspects of their work could be enhanced or what specific changes might be beneficial. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper these experiments are discussed in, nor does it provide any specific feedback or suggestions for improvement. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments need further exploration or improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual statement describing the experiments conducted, which is consistent with the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any feedback, suggestions, or critique that could help the authors improve their work. Without any actionable advice or guidance, the comment lacks value in assisting the authors in enhancing their draft. Therefore, it is rated as 1: Not Helpful at All.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current setting is only a first step towards real strategic settings, as the opponent does not behave strategically. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment implies that the authors should consider incorporating strategic behavior into their setting, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the current setting is only a first step towards real strategic settings, as the opponent does not behave strategically. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. The authors can infer that it relates to the discussion of \"strategic predictions\" mentioned in line 28, but this inference is not explicit. The comment is specific in identifying the issue of strategic behavior, but it lacks grounding as it does not clearly indicate the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current setting is only a first step towards real strategic settings, as the opponent does not behave strategically. The reviewer provides a logical reasoning by contrasting the claim of \"strategic predictions\" with the observation that the opponent does not behave strategically. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the strategic behavior expected in the setting to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, noting that the current setting is only a first step towards real strategic settings. It points out that the opponent does not behave strategically, which contradicts the claim of \"strategic predictions.\" This feedback is somewhat helpful as it highlights an area where the paper could be improved by incorporating strategic behavior into the setting. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or experiments. While it provides some insight into a potential weakness, it does not offer detailed actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with Appendix A.2, noting that it does not clearly illustrate the state space representation of the environment. However, it does not provide any explicit or implicit guidance on how to address this issue or improve the clarity of the representation. The authors are left without any actionable steps to take, such as suggestions for additional explanations, examples, or changes to the representation. Without specific instructions or examples, the comment lacks actionability, leaving the authors uncertain about how to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed in the appendix. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the clarity of the state space representation in Appendix A.2, which is an important aspect of the paper. However, it lacks depth and does not provide any suggestions or guidance on how to improve the clarity of the representation. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is somewhat helpful, as it points out a problem but does not offer a path to resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the authors\\' approach, stating that it is only applicable for small or medium-scale problems and that large-scale problems may overwhelm current LP-solvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle larger-scale problems. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the authors\\' approach, stating that it is only applicable for small or medium-scale problems and that large-scale problems may overwhelm current LP-solvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach need to be improved or how the authors might address this limitation. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable for small or medium-scale problems, and that large-scale problems may overwhelm current LP-solvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the authors\\' approach, noting that it is only applicable for small or medium-scale problems and may struggle with large-scale problems. However, it does not provide any suggestions or guidance on how the authors might address this limitation or improve their approach to handle larger-scale problems. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue in their draft. It lacks actionable details, such as recommending specific changes or improvements to the bounded noise assumption. As a result, the authors are left without clear direction on how to apply the information provided. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounded noise assumption, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses this assumption, making it weakly grounded. The comment is specific in mentioning efforts to extend these noise conditions and provides references to specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. This provides a clear direction for the authors to consider in their work. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. This provides a basis for the claim, as it highlights efforts to extend the noise conditions in these works. However, the comment could be strengthened by providing more detailed explanations or examples from these references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a foundation for the claim but lacks comprehensive evidence or detailed reasoning. This aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a potential limitation in the paper, specifically the bounded noise assumption, which is somewhat restrictive in the stochastic optimization literature. It references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou, which have made efforts to extend these noise conditions. While the comment identifies a relevant issue, it lacks actionable guidance or suggestions for the authors to address this limitation in their work. It does not provide specific advice on how to incorporate these extensions or improve the bounded noise assumption. As a result, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance for the authors to act upon.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation behind using characteristic function regularization is unclear. However, it does not provide any explicit or implicit suggestions on how the authors might clarify this motivation or improve the clarity of their explanation. Without guidance on what specific aspects of the motivation are unclear or how to address them, the authors are left without a clear path for improvement. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall motivation behind using characteristic function regularization, but it does not specify which part of the paper this issue pertains to, such as a specific section or subsection. This makes it difficult for the authors to pinpoint the exact area that needs revision. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Without detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the overall motivation behind using characteristic function regularization is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a critical issue with the paper, noting that the overall motivation behind using characteristic function regularization is unclear. This is an important observation that could impact the paper\\'s clarity and impact. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or examples, the authors are left without a clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights a significant issue but does not offer detailed guidance for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the originality or novelty of the work, nor are there suggestions for potential areas of improvement or additional contributions. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper these techniques are discussed in, making it weakly grounded. The comment is specific in detailing the combination of existing techniques and the perceived lack of originality, but it lacks grounding as it does not direct the authors to a specific section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is limited to a combination of existing techniques, which is not surprising and thus considered incremental. The comment references specific works (Lykouris et al., 2018; Zhou et al., 2021) to support the claim, providing some evidence for the assertion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the referenced works to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. It references specific works (Lykouris et al., 2018; Zhou et al., 2021) to support the claim, which provides some context for the authors to understand the basis of the critique. However, the comment lacks actionable suggestions or guidance on how the authors might enhance the originality or novelty of their work. While it identifies a potential weakness, it does not offer specific advice on how to address it, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the comment, ensuring a clear path for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiscale modeling,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by requesting clarification on the aggregation operation after \"Integration\" and suggesting the inclusion of more details in the main paper. Additionally, it advises acknowledging the structure of other architectures if they are referred to. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification and requests more details in the main paper. It also advises acknowledging the structure of other architectures if they are referred to. However, the comment does not provide specific examples or references to support the claim that the aggregation operation is unclear or how it should be clarified. Without detailed justification or examples, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It suggests that the authors provide more details in the main paper and, if referring to other architectures, acknowledge their structure properly. This feedback is clear and actionable, as it directs the authors to clarify a particular aspect of their work and ensures proper attribution of other architectures. By addressing these points, the authors can enhance the clarity and completeness of their paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify the aggregation operation or examples of other architectures to consider. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what steps to take to rectify the writing problems. As a result, the comment is unactionable, as it does not offer a clear path for the authors to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding which grammatical errors, mathematical symbols, or unclear sentences are problematic. Without detailed guidance, the authors cannot effectively address the issues. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed evidence to support these claims. Without concrete examples or references to particular sections of the paper, the authors may find it challenging to understand and address the issues effectively. This lack of specificity makes the claim difficult to verify, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. Without concrete suggestions or actionable feedback, the authors are left with a general understanding of the problems but without a clear path to improvement. This lack of specificity and actionable advice makes the comment barely helpful, as it does not effectively guide the authors in enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit instructions for the authors to run additional experiments and add the results to the figures and Table 1. It also requests clarification on specific aspects of the figures, such as whether the network was trained on random data or evaluated with random data. The comment is clear and actionable, as it specifies exactly what the authors need to do to address the reviewer\\'s concerns. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Fig 3c and Fig 3) and requests clarification on certain aspects of the data. It also provides clear and specific suggestions for additional experiments and the inclusion of results in figures and Table 1. This level of detail allows the authors to accurately identify the parts of the paper being addressed and what needs to be clarified or improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of requests for clarification and suggestions for additional experiments. It does not contain subjective opinions, judgments, or claims that require verification. The requests for clarification are factual and do not necessitate any additional evidence or justification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by requesting additional experiments and clarifications on the figures. It explicitly instructs the authors to run experiments for untrained networks and add the results to the figures and Table 1. This guidance is clear and provides a direct path for the authors to improve their draft. Additionally, the comment seeks clarification on specific aspects of the figures, such as whether the network was trained on random data or evaluated with random data. These requests for clarification are also helpful in ensuring the paper is clear and comprehensive. Overall, the comment is highly helpful as it offers concrete suggestions for improvement and enhances the clarity of the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the meaning of \"100 steps\" in the search models comparison section 5.1. It also inquires about whether these steps refer to sampled strategies. This comment provides a clear and direct action for the authors to take, which is to clarify the terminology used in the paper. The authors know exactly what needs to be addressed and how to do so, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps\" and whether it refers to sampled strategies. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the meaning of \"100 steps\" in the search models comparison section. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it directly addresses a specific area of confusion in the paper, namely the meaning of \"100 steps\" in the search models comparison section. By asking for clarification on whether these steps refer to sampled strategies, the reviewer provides a clear and actionable suggestion for the authors to clarify their terminology. This feedback is valuable as it helps the authors improve the clarity and precision of their work, ensuring that readers can fully understand the experimental setup. However, the comment could be more helpful if it also suggested how the authors might clarify this point in the text, such as by providing a definition or explanation. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, and encourages the authors to explore this further. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, as discussed in the related work review. While the comment highlights a potential overlap with existing work, it does not provide specific guidance on how the authors should address this issue or differentiate their work. The action is implicit and somewhat vague, as it suggests exploring the energy model further but does not specify how to do so or how to distinguish the work from the prior VAE paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the similarity of the model\\'s motivation and goals to those of a prior VAE paper, as discussed in the related work review. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to those of a prior VAE paper. The comment provides a logical reasoning by comparing the model to existing work, which is a common practice in the field. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to explore the related work section to fully understand the basis of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, which is a positive observation. It encourages the authors to explore this area further, recognizing its potential for innovation. However, the comment also points out a potential issue by noting that the model\\'s motivation and goals are similar to those of a prior VAE paper, as discussed in the related work review. This feedback is valuable as it highlights a potential overlap with existing work, prompting the authors to consider how their work differs or adds value. While the comment identifies a potential weakness, it could be more helpful by suggesting specific ways to differentiate the work or address the overlap. Overall, the comment is mostly helpful as it provides actionable feedback on both the novelty and potential overlap with existing work, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the improvement over previous methods is statistically significant. This provides a clear and direct action for the authors to take. The comment also specifies that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, which is another actionable point. The reviewer's suggestion to reject the paper due to limited novelty and marginal improvement adds a layer of urgency to the feedback. Overall, the comment is highly actionable as it provides explicit and concrete steps for the authors to follow, ensuring they know exactly what actions to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the results, noting the lack of mean and standard deviation reported and the difficulty in determining statistical significance. The comment further suggests repeating the experiments and conducting statistical significance analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement over previous methods is small, about 0.2%-1%, and suggests that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer provides a clear and logical reasoning for the claim, noting the limited novelty and marginal improvement. However, the comment could be strengthened by providing specific examples or references to support the claim about the small improvement. Despite this, the reasoning is mostly verifiable, as it provides a logical basis for the suggestion to repeat the experiments and conduct statistical significance analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, about 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis to address these issues. This feedback is clear and actionable, providing the authors with specific steps to take to improve the paper. However, the comment could be more helpful by offering suggestions on how to enhance the novelty or significance of the work beyond the limited improvement. Overall, the comment is mostly helpful as it guides the authors toward improving the draft but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends running experiments on a different benchmark, such as Atari, to evaluate the method\\'s generalizability to other domains. It also suggests verifying whether the method works with discrete action spaces and high-dimensional observations. This feedback provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The suggestion is explicit and offers specific guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation being conducted on a single domain, Meta World, and suggests running experiments on a different benchmark like Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the lack of generalizability to other domains and the need to verify the method\\'s performance with discrete action spaces and high-dimensional observations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited to a single domain, Meta World, and suggests running experiments on a different benchmark like Atari to assess generalizability. The comment provides a logical reasoning for the claim by noting the difficulty in judging the method\\'s generalizability without testing on other domains. However, it lacks specific references or examples of how Atari would be a suitable benchmark or how it would address the issue of discrete action spaces and high-dimensional observations. While the suggestion is reasonable, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the method, noting that it is only tested on a single domain, Meta World, which makes it difficult to judge its generalizability. The reviewer provides a clear and actionable suggestion by recommending running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This would not only help assess the method\\'s generalizability but also verify its performance with discrete action spaces and high-dimensional observations. The feedback is specific and offers a concrete step for the authors to take to improve their draft, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects of the model should be explored. The comment implies that the authors should consider the feedback or suggestions provided, but it does not specify what those suggestions are. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges that the method is presented nicely and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not specify which part of the paper lacks this analysis or provide examples of what kind of analysis would be beneficial. The comment is not grounded as it does not identify a specific section or aspect of the paper being addressed, and it is also not specific in detailing what kind of analysis is missing. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is necessary or how it could enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the method is presented well and the experiments are good and complete, but it points out a missing aspect: analysis on what the model does, which could be interesting. This feedback identifies a specific area for improvement, suggesting that the authors should include an analysis of the model's behavior or functionality. However, the comment does not provide detailed guidance on how to conduct this analysis or what specific aspects should be explored. While it highlights a potential enhancement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a lack of clarity in the task setup, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. This provides a clear action for the authors to take, which is to clarify these aspects in their description. The comment is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: which notes in the EHR are used as input and how far away the outcomes are from the last note date. This provides clear guidance on what the authors need to address to improve the clarity of their task setup. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the task setup, specifically asking which notes in the EHR are used as input and how far away the outcomes are from the last note date. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the task setup, questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it prompts the authors to clarify these aspects in their description. By addressing this point, the authors can enhance the clarity and comprehensibility of their task setup, which is crucial for readers to understand the methodology and results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information more effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss the reason why the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works using the double momentum technique, such as SUSTAIN and MRBO. It also suggests discussing the theoretical differences between DMLCBO and these previous works. This feedback provides a clear and direct action for the authors to take, ensuring they understand what needs to be addressed in their paper. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm \"DMLCBO\" and the double momentum technique, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the convergence rate of DMLCBO with previous works like SUSTAIN and MRBO, pointing out the difference in convergence rates. The comment further instructs the authors to discuss the reason for this difference and the theoretical technique differences between DMLCBO and the previous works. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works using the double momentum technique, such as SUSTAIN and MRBO. The reviewer provides a logical reasoning by comparing the convergence rates of these algorithms, noting that DMLCBO only achieves a convergence rate of $\\mathcal{\\widetilde O}(\\epsilon^{-4})$ compared to the $\\mathcal{\\widetilde O}(\\epsilon^{-3})$ achieved by the previous works. This comparison is based on common knowledge in the field and provides a clear basis for the claim. However, the comment could be strengthened by referencing specific sections of the paper where this issue is discussed or by providing more detailed reasoning or examples. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks some depth in explanation or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed algorithm, DMLCBO, by comparing its convergence rate to that of previous works using the double momentum technique. It points out that while previous works achieve a convergence rate of $\\mathcal{\\widetilde O}(\\epsilon^{-3})$, DMLCBO only achieves $\\mathcal{\\widetilde O}(\\epsilon^{-4})$. The comment encourages the authors to discuss the reason for this difference and the theoretical technique differences between DMLCBO and the previous works. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could impact its theoretical contribution. By providing a specific comparison and suggesting a discussion, the comment offers valuable guidance for improving the draft. Therefore, it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more like additional information rather than an extension. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which can guide the authors in understanding the expected format for the approach section. This feedback is clear and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the supplementary material should be used more like additional information and not as an extension to the paper. The comment provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which further clarifies the expectation for the approach section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more like additional information rather than an extension. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which supports the claim that the supplementary material should be used appropriately. This provides a clear and specific reference, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the approach section should be structured. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant omission in the main paper, specifically the absence of an \"approach section.\" It highlights that the supplementary material should be used more like additional information and not as an extension to the paper. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which can guide the authors in understanding the expected format for the approach section. This feedback is clear and actionable, offering a concrete suggestion for improvement that can help the authors enhance the structure and clarity of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it may be too weak. The reviewer provides a counterargument by stating that backpropagation is widely accepted as biologically implausible. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the statement in the introduction. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific statement in the introduction regarding the biological plausibility of backpropagation. It critiques the statement by suggesting that it may be too weak and provides a counterargument that backpropagation is widely accepted as biologically implausible. However, the comment does not specify which part of the introduction this statement is located in, making it weakly grounded. The comment is specific in its critique of the statement but lacks grounding, as the authors cannot confidently determine the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. The reviewer provides a counterargument to the original claim, which is a logical reasoning based on common knowledge in the field. However, the comment could be strengthened by providing specific references or examples to support the claim that backpropagation is widely considered biologically implausible. Despite this, the comment provides a reasonable basis for the claim, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the introduction, specifically the statement regarding the biological plausibility of backpropagation. It points out that the current phrasing may be too weak, as backpropagation is widely accepted as biologically implausible. This feedback is valuable as it highlights a critical area that could be improved to enhance the credibility and accuracy of the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as proposing alternative phrasing or references to support the claim. Overall, the comment is somewhat helpful as it directs the authors' attention to a specific area needing improvement but lacks detailed guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the modulator being heuristically designed, questioning whether there might be scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the scalability of their modulator. The comment lacks actionable details, such as recommending specific methods or approaches to address the scalability issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on what aspects of the modulator design or scalability need to be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is barely helpful, as it highlights an area for improvement but does not offer sufficient direction for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments performed in the paper incorporated a significant amount of domain knowledge into the structure of f_R and f_P, implying that a less informed version of these functions might require an impractical amount of data to learn. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experiments. It lacks concrete details on what changes could be made to reduce the reliance on domain knowledge or how to ensure that the experiments are more data-efficient. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the adaptability of f_R and f_P over time and the incorporation of domain knowledge in the experiments. However, it does not specify which part of the paper discusses these functions or experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the reliance on domain knowledge and the potential data requirements for a less informed version of f_R/f_P, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments performed in the paper incorporated a significant amount of domain knowledge into the structure of f_R and f_P, suggesting that a less informed version of these functions might require an impractical amount of data to learn. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experiments, suggesting that the functions f_R and f_P may require an impractical amount of data to learn due to the incorporation of significant domain knowledge. This feedback highlights a limitation in the current approach and could prompt the authors to consider alternative methods or adjustments to reduce the reliance on domain knowledge. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative techniques or providing examples of how to balance domain knowledge with data efficiency. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to determine if there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to design or execute them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the application of imitation learning and the challenges in obtaining labeled data. However, it does not specify which part of the paper discusses imitation learning or where the experiments on data acquisition and performance changes are lacking. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in terms of the issues it raises, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no experiments on the difficulties in obtaining labeled data and how performance changes with varying data sizes. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to determine if there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for further experimentation. However, the comment could be more helpful if it offered suggestions on how to design these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward enhancing their draft by addressing a critical aspect of their methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the implications of overparameterization leading to powerful memorization and good generalization performance. It suggests that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve their draft. The suggestion to consider the implications of robust memorization on generalization is implicit, but the lack of concrete steps or suggestions makes it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the implications of overparameterization on memorization and generalization, particularly in the context of robust memorization. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the lack of connection between robust memorization and robust generalization, and it references the authors\\' acknowledgment of this issue in the conclusion. This provides some guidance on what needs to be addressed, but the lack of explicit section references makes it challenging for the authors to pinpoint the exact areas needing revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the implications of overparameterization on memorization and generalization, suggesting that the necessary conditions for robust memorization might have stronger implications for robust generalization. The reviewer acknowledges that the authors address this issue in the conclusion, but argues that it is a serious question that deserves further exploration. While the comment highlights a potential gap in the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the conclusion provides some context, but the comment could be strengthened with more explicit evidence or analysis. Therefore, the claim is somewhat verifiable, as it provides a basis for further exploration but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the implications of overparameterization on memorization and generalization, specifically in the context of robust memorization. It points out that while the authors acknowledge this issue in the conclusion, it is a serious question that deserves further exploration. This feedback is somewhat helpful as it identifies a potential gap in the paper and encourages the authors to delve deeper into the connection between robust memorization and robust generalization. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this issue or what additional analysis could be conducted. Overall, the comment prompts the authors to consider a significant aspect of their work but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limitation is noted as somewhat restricting the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or explore the implications for other NLP tasks. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation pertains to, such as specific sections or experiments that could be expanded. Additionally, the comment lacks specificity in terms of what aspects of other NLP tasks should be explored or how the generalizability could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment lacks specific examples or references to other NLP tasks that could be explored, making it difficult for the authors to understand the exact scope of the limitation. The claim is somewhat verifiable as it highlights a potential gap in the paper, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the value of the paper\\'s insights for contrastive learning in code search tasks but points out a limitation in its generalizability to other NLP tasks. This feedback is somewhat helpful as it identifies an area where the paper could be improved by exploring the implications of the proposed method for other NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their exploration. Without actionable advice, the authors may find it challenging to determine the exact steps needed to enhance the generalizability of their results. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the use of the term \"certificate\" in some contexts, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should reconsider the use of \"certificate\" and potentially replace it with a more appropriate term. Additionally, the comment lacks concrete details on how to implement this change, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" explaining that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, nor does it explain how the term might be misinterpreted or why it is problematic. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a relevant observation that could help the authors clarify their terminology and ensure that their work is understood correctly by readers. However, the comment lacks specific examples or suggestions on how to address this issue, such as recommending alternative terminology or providing context for the term \"certificate.\" While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the novelty of the OOD experiments, noting that the trained network demonstrates strong OOD generalization. It suggests that the authors should mention the recent work by Ulyanov et al. (CVPR 2018) and place their method in context, ideally comparing it with those methods. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate the comparison or context. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion to mention recent work by Ulyanov et al. (CVPR 2018) and place the current method in context, ideally comparing it with those methods. This level of detail guides the authors on what specific aspects need to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the OOD experiments are interesting because the trained network demonstrates strong OOD generalization. It then suggests that the authors should mention recent work by Ulyanov et al. (CVPR 2018) and place their method in context, ideally comparing it with those methods. The claim is somewhat verifiable as it provides a reference to recent work in the field, which supports the suggestion to include a comparison. However, the comment lacks specific examples or detailed reasoning on how the current method compares to the referenced work, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the novelty of the OOD experiments, noting that the trained network demonstrates strong OOD generalization. It then suggests that the authors should mention recent work by Ulyanov et al. (CVPR 2018) and place their method in context, ideally comparing it with those methods. This feedback is mostly helpful as it provides a clear direction for the authors to enhance their paper by contextualizing their work within the existing literature and potentially comparing it with relevant methods. However, the comment could be more helpful if it included specific suggestions on how to incorporate this comparison or context, such as which aspects to focus on or what metrics to use. Overall, the comment offers valuable guidance for improving the paper, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments are limited to toy data and recommends exploring the performance of the method on real data problems where barycenters can be used. While the comment implies that the authors should expand their experiments to include real data, it does not provide specific guidance on how to do so or which real data problems to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are limited to toy data and recommends exploring the performance of the method on real data problems where barycenters can be used. However, it does not specify which part of the paper discusses the experiments or where the authors should include results on real data problems. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in suggesting an area for improvement, namely expanding the experiments to real data problems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to toy data and suggests exploring the performance of the method on real data problems. However, the comment lacks specific examples or references to real data problems where barycenters could be used, making it difficult for the authors to understand the scope of the suggestion. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as it provides a general direction but lacks the necessary details for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are restricted to toy data. It suggests that the authors should explore the performance of their method on real data problems where barycenters can be used. This feedback is somewhat helpful as it points out a potential area for improvement and provides a direction for expanding the scope of the experiments. However, the comment lacks specific guidance on which real data problems to consider or how to implement these changes, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting more experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, to strengthen the paper. It provides specific examples of references that could guide the authors in their experiments. This feedback is clear and actionable, as it directly instructs the authors on what additional experiments to perform and where to find relevant references. The authors know exactly what actions to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for more experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet. This allows the authors to accurately identify the part of the paper being addressed, which is the experimental section. The comment is also specific because it provides clear guidance on what additional experiments are needed to strengthen the paper, including references to relevant works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting more experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, to strengthen the paper. This suggestion is supported by references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing. These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional experiments would contribute to the paper\\'s strength. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet. This feedback is specific and offers concrete guidance on how the authors can enhance the robustness and applicability of their work. The inclusion of references to relevant literature, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, further supports the suggestion and provides a basis for the authors to explore these areas. However, the comment could be more helpful if it explained why these additional experiments are necessary or how they would contribute to the paper\\'s strength. Overall, the comment is mostly helpful as it offers clear and actionable feedback, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their explanation. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to clarify their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not specify which part of the paper discusses this mechanism or where the issue of clarity arises. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the explanation are unclear or how the authors might clarify the mechanism. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of why the proposed sample selection mechanism helps preserve the label distribution. This is a relevant observation that could help the authors improve their explanation or justification of their method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable feedback or detailed advice, the authors may find it challenging to know exactly what steps to take to enhance their explanation. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on whether the authors should evaluate additional models, what types of models should be considered, or how to address the issue of evaluating only a limited number of models. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the results and analysis are detailed and comprehensive, but it also points out that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this evaluation is based on, such as a specific section or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a specific issue with the models evaluated, it does not provide detailed guidance on how to address this issue or what specific models should be considered. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the results and analysis are detailed and comprehensive, but it also notes that only two relatively old and small models are evaluated. This claim is somewhat verifiable as it provides a logical reasoning for the critique, suggesting that the evaluation could be more comprehensive by including a broader range of models. However, the comment lacks specific examples or references to support the claim, such as comparisons with newer or larger models. This makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a limitation in the evaluation of the results and analysis, noting that only two relatively old and small models are evaluated. While the comment identifies a specific area for improvement, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples of alternative models to consider, the feedback is somewhat vague and does not fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this reformulation could simplify the solution for the stochastic problem in Eq.(1), thereby clarifying the motivation of Algorithm 1. However, the comment does not explicitly instruct the authors to make this reformulation or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for reformulation and figure out how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the prox-linear subproblem can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is somewhat verifiable as it provides a logical reasoning for the equivalence, suggesting that the reformulation could simplify the solution for the stochastic problem in Eq.(1). However, the comment lacks specific examples or references to support the claim fully, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could help the authors clarify the rationale behind their algorithm and potentially simplify its implementation. However, the comment does not provide specific guidance on how to make this reformulation or how it would impact the overall structure of the paper. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that KD and LS are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under specific conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its claim about the equivalence of KD and LS under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that KD (Knowledge Distillation) can be viewed as a special form of LS (Label Smoothing) under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This reasoning is based on a clear understanding of the concepts and their relationship, which provides a solid foundation for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This observation could be valuable for the authors, as it offers a deeper understanding of the relationship between these two methods. However, the comment lacks actionable suggestions or guidance on how this insight might impact the paper or its presentation. While it provides some insight, it does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that more recent works should be included in the paper and that results on large-scale datasets, such as ImageNet, should be provided to further verify the effectiveness of the proposed method. This feedback is clear and provides concrete actions for the authors to take, such as updating the literature review and conducting additional experiments on larger datasets. The explicit nature of the suggestions and the concrete details on what needs to be done make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more recent works and results on large-scale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the competing dynamic-pruning methods are outdated and suggests including more recent works. It also points out that only results on small-scale datasets are provided and recommends including results on large-scale datasets like ImageNet to verify the effectiveness of the proposed method. However, the comment lacks specific references or detailed reasoning to support the claim that the methods are outdated or to justify the need for results on larger datasets. This makes the claim somewhat verifiable, as it provides a general direction but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It points out that the dynamic-pruning methods discussed are outdated and suggests including more recent works. Additionally, it notes that only results on small-scale datasets are provided and recommends including results on large-scale datasets like ImageNet to further verify the effectiveness of the proposed method. This feedback is clear and actionable, providing the authors with specific directions to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on which specific recent works to include or how to conduct experiments on larger datasets. Overall, the comment is mostly helpful as it guides the authors toward improving the depth and scope of their study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to provide an explanation for the observed performance degradation when using additional information about missing, wrong, or redundant data in the FBN results. This request is clear and direct, leaving no ambiguity about what the authors need to do. The comment provides a specific action for the authors to take, which is to clarify the reason behind the performance degradation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for an explanation of the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to explain why the performance degrades when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the FBN results in Table 5, where the performance degrades when using additional information about missing, wrong, or redundant data. It requests clarification from the authors on this observation, which is a clear and actionable suggestion for improvement. By addressing this point, the authors can provide a more comprehensive explanation of their results, potentially leading to a better understanding of the methodology and its limitations. However, the comment could be more helpful if it offered additional guidance or suggestions on how to address this issue or interpret the results. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback by pointing out specific sections of the paper that are difficult to read and suggesting that the author failed to explain each method clearly. It includes concrete examples of what is unclear, such as the stacked LSTM in Figure 2 and the sentence in line 96. This feedback is actionable because it directs the authors to clarify these specific points in their draft. The authors know exactly what needs to be addressed and can use the examples provided to improve the clarity of their explanations. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of what is unclear, such as the stacked LSTM in Figure 2 and the sentence in line 96, which helps the authors understand what needs to be clarified. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first two sections of the paper are difficult to read due to the lack of clear explanations of previous approaches. It provides specific examples, such as the stacked LSTM in Figure 2 and the sentence in line 96, to illustrate the confusion. This level of detail supports the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific literature or methods that the authors should follow to improve clarity. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific sections of the paper that are difficult to read due to the lack of clear explanations of previous approaches. It provides concrete examples, such as the stacked LSTM in Figure 2 and the sentence in line 96, which helps the authors understand where the confusion lies. By pointing out these specific issues, the comment offers actionable feedback that can guide the authors in improving the clarity and readability of their draft. However, the comment could be more helpful if it included suggestions on how to clarify these sections or provided examples of better explanations. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, suggesting that they make the captions more descriptive and explain the scramble network better. These instructions are clear and concrete, giving the authors a direct path to improve their draft. The comment is highly actionable as it specifies exactly what needs to be done to enhance the clarity and comprehensibility of the figures and their captions.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the captions\" and \"the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: making the captions more descriptive and explaining the scramble network better. This level of detail helps the authors understand exactly what changes are needed to enhance the clarity and comprehensibility of their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the captions of the figures are not descriptive enough, requiring the authors to search for interpretations on a different page. It also requests an explanation of the \"scramble network.\" However, the comment does not provide specific examples or detailed reasoning to support why the captions are inadequate or how the explanation of the scramble network could be improved. Without these details, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or explanation to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the captions of the figures should be more descriptive, allowing readers to understand the figures without needing to search for explanations elsewhere. It also requests an explanation of the \"scramble network,\" which could help clarify its role and significance in the paper. This feedback is clear and constructive, offering the authors a direct path to improve the clarity and accessibility of their work. However, the comment could be more helpful if it included examples of how the captions could be improved or suggestions for explaining the scramble network. Overall, the comment is mostly helpful as it guides the authors toward enhancing the readability and comprehensibility of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It explicitly asks for an explanation of why this particular dimension of difficulty is interesting. This request is clear and direct, providing the authors with a specific action to take: explaining the rationale behind this choice. The comment is highly actionable as it gives the authors a concrete step to improve their draft by providing a clear and explicit request for justification.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of randomly sampled CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and asks for an explanation of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not well-motivated. The comment does not provide any specific reasoning or evidence to support why this particular dimension of difficulty is not interesting or why it should be avoided. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not well-motivated. It asks for an explanation of why this particular dimension of difficulty is interesting, which is a valid point that could help the authors clarify their rationale. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the paper. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the analysis regarding the flatness of the minima found by the proposed method. It explicitly states that the authors need to provide an analysis on the losses of the noise-injected models after training to support their claim that the minima found are flat. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis about flatness, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis, namely the analysis on the losses of the noise-injected models after training. This provides clear guidance on what the authors need to address to improve their draft. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis about flatness is missing, despite the paper arguing that the proposed method finds the flat minima. The reviewer provides a logical reasoning by pointing out that minimizing the averaged loss across noise-injected models does not ensure the flatness of the minima. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or equations where the analysis is lacking, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical gap in the analysis of the paper, specifically regarding the flatness of the minima found by the proposed method. It points out that while the paper argues that the method finds flat minima, the analysis on flatness is missing. The comment provides a clear and actionable suggestion by indicating that the authors need to analyze the losses of the noise-injected models after training to support their claim. This feedback is valuable as it directs the authors to a specific area that requires further exploration and justification, which can significantly enhance the robustness of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that this text should be roughly the same size as the manuscript text. This feedback provides a clear and direct action for the authors to take, ensuring that the text is legible and consistent with the rest of the manuscript. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figure\" and \"labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text being too small and suggests that it should be the same size as the manuscript text. This provides clear guidance on what needs to be addressed to improve the readability of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and the labels are too small to read without zooming, and suggests that they should be the same size as the manuscript text. This is a factual observation about the readability of the figure, which does not require any subjective judgment or opinion. It is purely descriptive and does not contain a claim that needs verification. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the figures in the paper, noting that the text and labels are too small to be legible without zooming. It provides a clear and actionable suggestion to improve the figures by recommending that the text should be roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a visual aspect of the paper that could impact its accessibility and clarity. By suggesting a simple adjustment, the comment empowers the authors to enhance the overall presentation of their work. Therefore, the comment is rated as mostly helpful, as it offers a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not provide specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. The action is implicit and somewhat vague, as the authors are left to infer what needs to be addressed and how to improve the clarity of the motivation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not specify which parts of the introduction are unclear or what aspects of the motivation need clarification. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need revision. Additionally, the comment does not mention any specific sections or elements of the paper, making it weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the motivation of the paper is unclear, suggesting that the introduction should be revised to make it easier to follow. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable, as it lacks sufficient evidence or justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It suggests that the introduction should be carefully revised to make the paper easier to follow. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the motivation are unclear or how the introduction should be revised. While it highlights an important area for improvement, the feedback is somewhat vague, leaving the authors with a general direction but without concrete steps to take. Therefore, the comment is somewhat helpful, as it points out a critical issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to ensure consistency across categories or proposing alternative methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of including multiple local prompts and notes that the features and their positions may not be the same for different categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment. Without explicit references to the paper, the authors cannot confidently determine the exact part being discussed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that including multiple local prompts can be intuitive but points out a potential issue: the features and their positions may not be the same for different categories. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential problem but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps should be taken to improve the validation process. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation but lacks grounding, as the authors cannot confidently determine which part of the paper this critique relates to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. This is a relevant observation that could impact the reliability and validity of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the validation process. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the presentation of the model in Section 4 is somewhat complicated and requires careful reading, possibly with reference to the supplement. It provides a specific action for improvement by recommending the use of notation and breakout diagrams to illustrate the attention mechanisms. While the comment explicitly states the need for improvement, it does not provide detailed guidance on how to implement these suggestions, such as which parts of the presentation should be rewritten or which diagrams should be included. The authors are given a clear direction but lack concrete steps on how to execute the changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This level of detail guides the authors on what changes to make to enhance the clarity of the presentation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model presentation in Section 4 is somewhat complicated and requires careful reading, possibly with reference to the supplement. It provides a specific recommendation to improve the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment offers a logical suggestion for improvement, it lacks detailed justification or examples of how the current presentation is problematic or how the proposed changes would enhance clarity. This makes the claim somewhat verifiable, as the authors would need to infer the exact issues and benefits of the suggested changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides a constructive suggestion for improvement by recommending the use of notation and breakout diagrams to illustrate the attention mechanisms. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it provided more detailed guidance on which parts of the presentation should be rewritten or how the diagrams should be structured. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement that could significantly enhance the readability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. The reviewer suggests that the method\\'s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and vague, as the authors are left to infer that they should expand their experiments to a broader range of molecules or improve the generalizability of their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability and the need for broader testing, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s value is limited due to its focus on a limited number of molecules and in-distribution testing. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why the method\\'s value would be limited or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. The reviewer suggests that the method\\'s value would be limited if it requires training for each molecule individually. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. The feedback is somewhat helpful as it points out an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the symbols used in the paper are complicated and take time to understand. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how to simplify the symbols or make them more understandable, nor are there any specific actions or changes recommended. As a result, the authors are left without any actionable steps to take in response to this feedback. The comment lacks any direction or detail, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the symbols are complicated and take time to understand, but it does not specify which symbols or parts of the paper are being referred to. This lack of explicit reference to a specific section or figure makes it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment does not provide specific details on what aspects of the symbols are confusing or how they could be simplified. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the symbols used in the paper are complicated and take time to understand. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references to particular symbols or sections of the paper, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the symbols used in the paper are complicated and take time to understand. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to simplify or clarify the symbols. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve the clarity of the symbols. This lack of actionable feedback makes the comment barely helpful, as it identifies a potential issue but does not offer a path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly questions the understanding of the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This provides a clear and direct action for the authors to take: they need to clarify the source of the test data and whether there is a ground truth associated with it. The comment is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the understanding of the red line and asking about the source of the test data and the presence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the red line in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion in the paper, namely the red line in Figure 3. By asking where the test data comes from and whether there is a ground truth, the reviewer provides clear and actionable feedback that prompts the authors to clarify an important aspect of their work. This feedback is valuable as it directs the authors to address a potential misunderstanding or lack of clarity in their presentation, which can significantly improve the comprehensibility and credibility of their results. However, the comment could be more helpful if it suggested ways to address the issue or provided examples of how to clarify the data source or ground truth. Overall, the comment is highly helpful for guiding the authors in improving their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of the results at a similar level to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to conduct additional experiments or analyses to address the question. The action is implicit and somewhat vague, as it lacks specific guidance on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It references the comparison model, which cannot capture periodic relationships, and the experiments involving periodicity. However, the comment does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its inquiry about the impact of adding periodicity to the spectral kernel, but it lacks explicit references to specific sections or experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, may not be able to replicate the results seen in the experiments involving periodicity. The comment implies that adding periodicity to the spectral kernel might be sufficient to achieve similar results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an interesting question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships, and in most experiments, the relationships involve periodicity. The comment suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of these results at a similar level to the explicitly compositional model. This feedback is somewhat helpful as it prompts the authors to consider the role of periodicity in their results and potentially explore its impact on the model's performance. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper is not well-written and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions that there is a lack of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks actionable details such as suggesting ways to enhance clarity, structure, or visual appeal. As a result, the authors are left without a clear understanding of what changes to make to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper being \"not very well-written\" and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. However, the comment does not specify which parts of the paper are particularly problematic or provide detailed feedback on how to improve the writing or formatting. Without specific guidance or references to particular sections, the authors cannot effectively address the issues raised. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not well-written and suggests it was possibly written in a hurry, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion about the writing quality or the impact of a hurried writing process. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper is not well-written and possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how to improve the writing, presentation, or formatting. Without detailed guidance or examples, the authors are left without a clear understanding of what changes to make to enhance the readability and presentation of their work. Therefore, the comment is barely helpful, as it identifies a general issue but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction should be expanded or how to improve the detail. The action is implicit, as the authors need to infer that they should add more detail, and it is vague, as it lacks concrete instructions on what specific details to include. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction is lacking in detail or what specific aspects need to be expanded. This makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity regarding what kind of detail is needed or how it could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples or reasoning to support why this is necessary or how the introduction could be improved. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement in the paper, suggesting that the introduction to orthogonality in Part 2 could be more detailed. This feedback is somewhat helpful as it points out a potential weakness in the paper and encourages the authors to enhance the clarity and depth of their introduction. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the introduction should be expanded or how to improve the detail. To be more helpful, the comment could include suggestions or examples of what additional information could be included. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s main contribution, suggesting that it may not be novel given prior work on sample-wise multiple descent in linear regression. The reviewer recommends that the paper should better highlight its novelty in relation to prior results. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific ways to highlight the novelty. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their results but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper\\'s main contribution in relation to prior work on sample-wise multiple descent in linear regression. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its suggestion to better highlight the novelty of the result in relation to prior results, but it lacks explicit references to sections or figures where this could be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work has already shown sample-wise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper, but suggests that the claims seem correct. However, the comment lacks specific references or detailed reasoning to support the claim about the novelty of the paper\\'s contribution. This makes the claim somewhat verifiable, as it provides some justification but lacks comprehensive evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s main contribution, suggesting that it may not be novel given prior work on sample-wise multiple descent in linear regression. It recommends that the paper should better highlight its novelty in relation to prior results. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or enhance their discussion of novelty. The feedback is somewhat helpful as it prompts the authors to consider the novelty of their results, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to establish a connection between the methods or improve their integration. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed methods, specifically mentioning \"contrastive training objective\" and \"contrastive search.\" However, it does not specify which part of the paper these methods are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of inner connection between these methods in terms of intuition and algorithm. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. This observation highlights a potential weakness in the paper, suggesting that the authors may need to clarify or strengthen the connection between these methods. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing ways to integrate the methods or explaining their relationship. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the goal of the paper and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. While the comment implies that the authors should clarify the paper\\'s goal and provide comparisons or justifications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the paper\\'s goal and provide comparisons or justifications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the goal of the paper and references a specific earthquake detector, \"PhaseNet-Das,\" by Zhu et al. (2023), which the authors cited. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the paper\\'s goal, namely the lack of comparison or justification for the proposed method, and suggests that the authors should clarify their claims and demonstrate or justify a future useful application. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s goal and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. The comment references a specific earthquake detector, \"PhaseNet-Das,\" by Zhu et al. (2023), which the authors cited, providing some context. However, the claim is somewhat verifiable as it lacks detailed reasoning or specific examples of how the proposed method could be compared or applied in future work. The reference to PhaseNet-Das provides some support but does not fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s goal, noting the existence of DAS earthquake detectors and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a direction for the authors to clarify their claims and demonstrate the value of their method. However, the comment could be more helpful if it offered specific suggestions on how to make the comparison or justification, or if it provided examples of potential future applications. Overall, the comment is mostly helpful, as it directs the authors to address a significant gap in their paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the alignment of results in Table 6 with those in Table 1 (MCT-pair) and asks about the ablation studies of MCT without adaptive metrics. While the comment implies that the authors should address these questions or provide explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these points. However, the comment does provide a clear direction for the authors to follow, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCT-pair) and asks about the ablation studies of MCT without adaptive metrics. However, it does not specify which part of the paper these tables or studies are located in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questions but lacks grounding, as it does not provide clear references to the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the alignment of results in Table 6 with those in Table 1 (MCT-pair) and the ablation studies of MCT without adaptive metrics. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCT-pair) and asks about the ablation studies of MCT without adaptive metrics. While it identifies potential inconsistencies or gaps in the presentation of results, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment highlights areas that need clarification but lacks actionable feedback, making it somewhat helpful. The authors are given a direction to explore but are not fully supported in making improvements to their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and by [A, B]. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. It lacks actionable details on how the authors might differentiate their work or present their findings in a novel or more impactful manner. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific prior works and analyses, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the similarity of the analyses and the lack of novelty in the results, providing examples of prior works that have already explored these topics. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses are already present in prior works, making the results not particularly surprising. It supports this claim by referencing specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This provides a clear and specific reference to external works, making the claim fully verifiable. The inclusion of detailed references and examples enhances the credibility of the claim, ensuring that the authors can understand and address the feedback effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This feedback is somewhat helpful as it alerts the authors to the potential lack of novelty in their work. However, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their findings. The comment could be more helpful if it offered actionable advice on how to present the results in a novel or more impactful manner. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the 10 sub-tasks are too simplistic for bAbi and that the authors could solve all the sub-tasks with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not specify what kind of discussions are needed or how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer the specific changes required without detailed guidance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the 10 sub-tasks are too simplistic for bAbi and that the authors could solve all the sub-tasks with their final model. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what kind of discussions are required or how the authors should address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the 10 sub-tasks are too simplistic for bAbi and that the authors could solve all the sub-tasks with their final model. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the simplicity of the 10 sub-tasks used in the bAbi dataset, suggesting that the authors could solve all the sub-tasks with their final model. This feedback highlights a possible weakness in the experimental setup and encourages the authors to provide more discussions on this aspect. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional discussions could be included. While it points out a relevant area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider extending their approach to longer subsequences, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what specific changes to make. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the approach\\'s limitations but lacks grounding, as it does not reference a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it might impact the approach. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. This is a relevant question that prompts the authors to consider the potential limitations of their approach and whether it can be extended to address longer subsequences. However, the comment does not provide specific guidance or suggestions on how to address this limitation or extend the approach. While it identifies an area for potential improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or optimize the trade-off between model size and accuracy. There is no suggestion on whether these parameters should be adjusted, removed, or further explored. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. However, it does not specify which part of the paper discusses these parameters or where they are mentioned, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how to optimize the trade-off between model size and accuracy. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) may introduce significant computational overhead. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. This is a relevant observation that could impact the efficiency and practicality of the proposed method. However, the comment lacks specificity and does not provide actionable advice or suggestions on how the authors might address this issue or optimize the trade-off between model size and accuracy. Without detailed guidance or examples, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues: the definition of \"sqeuence of episodes\" and the lack of related work. The first issue is addressed explicitly, as the reviewer asks for clarification on the term \"sqeuence of episodes.\" This provides a clear action for the authors to take, which is to clarify the term in their draft. The second issue is also explicit, as the reviewer suggests that related work is missing and that it seems related but does not negate the novelty of the work. This feedback is actionable because it directs the authors to include relevant related work to support their claims. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sqeuence of episodes\" and suggesting that practice and evaluation might be the two types of this sequence. Additionally, the comment points out the absence of related work, which is relevant to the context. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims: the first is about the definition of \"sqeuence of episodes,\" and the second is about the lack of related work. The comment does not provide any supporting evidence or reasoning for either claim, such as explaining why the definition is unclear or how the absence of related work affects the novelty of the work. Without additional context or justification, the claims remain unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important points. First, it questions the definition of \"sqeuence of episodes,\" which is unclear and potentially confusing for readers. This feedback is helpful as it prompts the authors to clarify this term, ensuring that their work is more accessible and understandable. Second, the comment points out the absence of related work, suggesting that it is related but does not negate the novelty of the work. This is a valuable observation that could help the authors position their work more effectively within the existing literature. However, the comment could be more helpful if it provided specific examples of related work or suggested how the authors might address this gap. Overall, the feedback is mostly helpful as it identifies clear areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, should be made to their draft. The comment lacks actionable advice, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to pinpoint the exact section being addressed. The comment lacks specificity as it does not provide details on what aspect of the study is being questioned or how it should be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. The comment provides a logical reasoning by explaining that an ablation study typically involves removing a component to assess its impact. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the context of the study to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. While the comment raises a valid point about the terminology used, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not offer guidance on how the authors might address this issue or clarify their methodology. As a result, the comment is barely helpful, as it identifies a potential misunderstanding but does not assist the authors in resolving it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, which uses similar operators. This is an explicit action with concrete details on how to implement it, as it suggests a specific application of AccNet. The authors know exactly what needs to be done to address this feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of the black line in the input and suggesting the inclusion of AccNet as part of a larger predictor. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual statement about the use of a black line in the input and a suggestion to include AccNet as part of a larger predictor. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. This feedback is actionable and offers a clear direction for the authors to consider, which could enhance the applicability and utility of their work. However, the comment could be more helpful if it provided additional context or rationale for why this integration might be beneficial. Overall, the suggestion is mostly helpful as it offers a concrete way to expand the scope of the paper, but it could be more comprehensive with further explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the new proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should test the metric on additional datasets, how they might do so, or what specific datasets would be appropriate. Without any actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the metric or dataset testing are problematic. Without clear guidance on where to address the issue or what specific concerns need to be addressed, the comment is not grounded and not specific. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the new proposed metric is only tested on a single dataset, which is a limitation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. This is a relevant observation that highlights a potential weakness in the study\\'s generalizability and applicability. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the testing of their metric on multiple datasets. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. While the comment implies that the authors should consider adding this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the inclusion of a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. This provides clear guidance on how to strengthen the evaluation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. The comment provides a logical reasoning for this suggestion, as it highlights the importance of comparing the proposed TransferNorm architecture with direct competitors. However, it does not provide specific examples or references to these competitors, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the evaluation section of the paper. It acknowledges the current evaluation, which compares several base DA methods with and without the proposed TransferNorm architecture, and suggests that the evaluation would be stronger if it included comparisons with architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it directs the authors to consider additional comparisons that could strengthen the evaluation of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate these competitors into the evaluation or suggested particular aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for enhancing the evaluation, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: the lack of definition for abbreviations, such as \"NE\" on line 73, and the delayed definition of superscript notation in equation 6, which is not defined until line 166. The comment provides explicit actions for the authors to take, such as defining these abbreviations and ensuring that notation is defined at the point of first use. Additionally, it references relevant literature that could help the authors address these issues. This provides clear and concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L73 and L166) and equations (Eq 6), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of definition for abbreviations and superscript notation, which hinders understanding during the initial read. Additionally, the comment provides references to relevant literature, which further grounds the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some abbreviations are not defined and that superscript notation in Equation 6 is not defined until much later, which hinders understanding during the initial read. The reviewer supports this claim by referencing three external works that address similar issues in their respective papers. This provides a logical basis for the claim, as it suggests that the authors should follow established practices in defining abbreviations and notation. However, the comment could be strengthened by providing more detailed examples or explanations from the referenced works. Overall, the claim is mostly verifiable, as it is supported by external references but could benefit from additional context or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as the lack of definition for abbreviations and the delayed definition of superscript notation, which can hinder understanding during the initial read. By pointing out these issues, the comment provides clear and actionable feedback that the authors can address to improve the clarity and readability of their draft. Additionally, the comment references relevant literature, which can help the authors understand how to address these issues effectively. This level of detail and specificity makes the comment highly helpful, as it empowers the authors to make significant improvements to their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the evaluation as weak and notes that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors might improve the evaluation or select more appropriate baselines. Without guidance on what specific changes should be made or what alternative baselines could be considered, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the evaluation as weak and mentions that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the evaluation are weak or how the baselines could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the baselines are inappropriate or how the evaluation could be strengthened. Without specific details or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a significant weakness in the evaluation of the paper, noting that the baselines used are not designed for fair classification. This is a critical observation that highlights a fundamental issue with the evaluation methodology. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or select more appropriate baselines. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a problem but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first three paragraphs of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to spell out the setting more clearly. The comment suggests that the authors may be claiming credit for a more general approach than what is presented, which muddles the exposition. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It suggests that the authors may be claiming credit for a more general approach than what is presented, which muddles the exposition. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or references makes the claim somewhat verifiable, as it provides a general direction but not enough information for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first three paragraphs of Section 2, suggesting that the setting needs to be clarified more clearly. It implies that the authors may be claiming credit for a more general approach than what is presented, which muddles the exposition. This feedback is somewhat helpful as it points out a potential confusion in the paper and encourages the authors to clarify their setting. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or what aspects need more detailed explanation. Overall, the comment offers some guidance but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experiments, specifically questioning the choice of the old baseline and suggesting that the proposed method should be tested on newer 3D CNNs like X3D and SlowFast. The reviewer also asks for an explanation of the proposed method\\'s advantage over these newer approaches. While the comment implies that the authors should test their method on these newer approaches and provide an advantage comparison, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments, specifically questioning the choice of the old baseline and suggesting that the authors should test their method on newer 3D CNNs like X3D and SlowFast. However, it does not explicitly mention which part of the paper discusses the experiments, making it weakly grounded. The comment is specific in its request for a comparison with newer approaches and an explanation of the proposed method\\'s advantage. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the experiments by suggesting that the choice of the old baseline, such as R3D and C3D, may not be sufficient. It proposes that newer 3D CNNs like X3D and SlowFast should be considered for comparison. The comment raises a valid point about the relevance of the chosen baselines and suggests a potential area for improvement. However, it lacks specific examples or references to support the claim that these newer approaches are more relevant or effective. This makes the claim somewhat verifiable, as it provides a logical basis for improvement but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the experiments, specifically questioning the choice of the old baseline and suggesting that newer 3D CNNs like X3D and SlowFast should be considered for comparison. It also asks for an explanation of the proposed method\\'s advantage over these newer approaches. This feedback is clear and actionable, as it prompts the authors to consider a broader range of baselines and to articulate the advantages of their method over existing approaches. However, the comment could be more helpful if it provided specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward improving the comprehensiveness and relevance of their experimental evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on how the attention module is attached to the backbone ResNet-20 architecture during the search process. It asks for specific details about the number of attention modules used and their placement, such as whether they are used after each block or stage. This feedback provides clear and direct actions for the authors to take, ensuring they know exactly what information needs to be clarified in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"backbone ResNet-20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules used, their placement, and whether they are used after each block or stage. This provides clear guidance on what the authors need to address to improve the clarity of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the attachment of the attention module to the backbone ResNet-20 architecture during the search process. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the attachment of the attention module to the backbone ResNet-20 architecture during the search process. It asks for clarification on the number of attention modules used and their placement, such as whether they are used after each block or stage. This feedback is clear and actionable, as it directs the authors to provide more detailed information that could enhance the clarity and understanding of their methodology. By addressing these questions, the authors can improve the comprehensiveness and transparency of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific concerns: the performance of the proposed method at different bitrates and the suggestion to discuss or compare with a related work. The reviewer explicitly asks for the precise bitrate range used for BD-rate comparison and suggests discussing or comparing with a specific related work. These requests are clear and direct, providing the authors with concrete actions to take. The comment is highly actionable as it specifies what needs to be addressed and how to do so, giving the authors a clear path forward.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"bitrate range used for BD-rate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear request for the precise bitrate range used for BD-rate comparison and suggests discussing or comparing with a related work. This level of detail guides the authors on what needs to be addressed and how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a claim about the performance of the proposed method at different bitrates and a suggestion to discuss or compare with a related work. The first part is a factual statement without an opinion or claim, as it describes the performance of the method at different bitrates. The second part is a suggestion to discuss or compare with a specific related work, which is a request for additional content rather than a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific pieces of feedback. First, it points out that the proposed method performs better at high bitrates but is close to baseline performance at low bitrates, prompting the authors to clarify the precise bitrate range used for BD-rate comparison. This is a clear and actionable suggestion that can help the authors refine their results and analysis. Second, the comment suggests discussing or comparing with a related work on content adaptive algorithms in learned video compression, specifically referencing Guo Lu et al., \"Content Adaptive and Error Propagation Aware Deep Video Compression.\" This recommendation is valuable as it can help the authors place their work in the context of existing research and potentially identify areas for improvement or differentiation. Overall, the comment is mostly helpful as it offers specific and actionable feedback that can guide the authors in enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should distinguish the \"all-or-nothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should clarify this distinction, it does not provide specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish the \"all-or-nothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. Without explicit references to sections or examples, the authors cannot confidently determine where to address this feedback. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should distinguish the \"all-or-nothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this distinction is important or how it would benefit the paper. Without additional context or justification, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should distinguish the \"all-or-nothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or what aspects of the paper need to be revised. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the marginal improvements over previous works and self-implemented baselines, suggesting that further analysis beyond the main experiments is insufficient. However, it does not provide explicit guidance on what specific analyses should be conducted or how the authors might address this issue. The action is implicit and vague, as the authors are left to infer that they need to conduct additional analyses but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the marginal improvements over previous works and self-implemented baselines, suggesting that further analysis beyond the main experiments is insufficient. However, it does not specify which parts of the paper these improvements or analyses are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what kind of further analysis is needed or how the current analysis could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements over previous works and self-implemented baselines are marginal, and further analysis beyond the main experiments is insufficient. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to previous works or baselines, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out that the improvements over previous works and self-implemented baselines are marginal, suggesting that further analysis beyond the main experiments is necessary. This feedback identifies a potential weakness in the paper, indicating that the authors may need to provide more detailed analysis or comparisons to substantiate their claims. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to conduct. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the clarity of the proof or where it should be moved within the main text. Without specific suggestions or instructions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the proof of Theorem 8, and the fact that it is buried at the end of the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any specific reasoning or examples to support why the proof is unclear or how it affects the linear convergence rates. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. This feedback is valuable as it points out a potential weakness in the paper that could impact its clarity and understanding. However, the comment lacks actionable suggestions or guidance on how to improve the clarity of the proof or where it should be moved within the main text. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the paper. First, it points out that the statement about the Walkman algorithm being solved by ADMM is inaccurate, as it has two versions, one solving a local optimization problem and the other solving a gradient approximation. This feedback is explicit and provides a clear action for the authors to correct the statement. Second, the comment highlights a lack of clarity regarding the reference for the pronoun \"it\" in the first paragraph of Section 3. This feedback is also explicit and actionable, as it directs the authors to clarify the reference. Both issues are concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inaccuracies in the statement about the Walkman algorithm and the lack of clarity regarding the reference for the pronoun \"it.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims. The first claim challenges the statement that the Walkman algorithm is solved by ADMM, pointing out that it has two versions, one solving a local optimization problem and the other solving a gradient approximation. This claim is somewhat verifiable as it provides a specific critique of the statement, but it lacks detailed reasoning or references to support the assertion that the statement is inaccurate. The second claim points out a lack of clarity regarding the reference for the pronoun \"it\" in Section 3. This is a factual observation that does not require verification, as it is a matter of clarity within the text. Therefore, the first claim is rated as 3: Somewhat Verifiable, while the second is rated as \"No,\" as it is a factual observation without a claim.', 'verifiability_label': ['3', 'X'], 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two separate issues. First, it corrects an inaccurate statement about the Walkman algorithm, pointing out that it is solved by ADMM with two versions, one solving a local optimization problem and the other solving a gradient approximation. This feedback is helpful as it directs the authors to clarify their statement to ensure accuracy. Second, it identifies a lack of clarity regarding the reference for the pronoun \"it\" in Section 3, which is also actionable. By addressing these points, the authors can improve the clarity and accuracy of their paper. Therefore, the comment is mostly helpful, as it offers clear guidance for improvement but could be more comprehensive by providing additional suggestions or examples. This aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the strong requirement of Gaussian features and noise for the theoretical result, and the lack of comparison with existing rates in the literature. The comment suggests that the authors should address these issues by relaxing the Gaussian assumption and comparing their rates with existing rates. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The actions are concrete, as they specify what needs to be done, but they are implicit in nature. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and the \"proposed algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the theoretical result, namely the strong requirement of Gaussian features and noise, and suggests comparing the rates achieved by the procedure with existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates with existing rates in the literature. The claim is somewhat verifiable as it highlights a specific limitation of the theoretical result and provides a logical reasoning for why it might be a concern. However, the comment lacks specific references or detailed comparisons to existing rates, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the strong requirement of Gaussian features and noise for the theoretical result. It points out that this assumption is a strong constraint on the data, especially given that previous algorithms do not require it. Additionally, the comment suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which would provide a more comprehensive evaluation of the algorithm\\'s performance. This feedback is clear and actionable, as it highlights a critical area for improvement and offers a specific suggestion for enhancing the paper. However, it could be more helpful if it provided examples of existing rates or specific comparisons to guide the authors further. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This comment implies that the authors should include a comparison with the original approach, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or analysis. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a comparison with the original approach, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper by comparing the proposed extension with a relevant prior work. However, the comment lacks specific details or references to the original approach, which would strengthen the justification. The authors would need to infer the relevance of the comparison and the specific aspects to focus on. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison with a relevant prior work. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects to focus on. While it points out a direction for enhancement, it does not offer actionable steps or detailed suggestions, leaving the authors with a general idea but limited guidance on implementation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It explicitly states that the authors should compare their work with additional baselines, specifically mentioning several works that focus on the same questions. This provides a clear and direct action for the authors to take, making the comment highly actionable. The suggestion is concrete, as it specifies the need to include more experiments and references specific works that could be used for comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the addition of more experiments to demonstrate the effectiveness of the proposed method. The comment provides examples of works that focus on the same questions, which further guides the authors on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It claims that there are several works focusing on the same questions, and references specific works ([1,2,3]). This provides a clear and specific suggestion for improvement, supported by references to external works. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional experiments would enhance the paper. Overall, the claim is mostly verifiable, as it provides a solid basis for the suggestion but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that more experiments should be conducted to demonstrate the effectiveness of the proposed method, particularly by including comparisons with other relevant works. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of additional baselines. However, the comment could be more helpful if it offered suggestions on which specific works should be included or how to structure the additional experiments. Overall, the comment is mostly helpful as it guides the authors toward enhancing the experimental section of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This is a direct and concrete action that the authors can take to improve the credibility of their results. The comment provides specific guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported results on the dev set are insufficient for convincing the reader. The reviewer suggests presenting average results on the test set with clearly defined error bars under different random seeds. This claim is somewhat verifiable as it provides a logical reasoning for why the current presentation of results is not sufficient. However, the comment lacks specific examples or references to support the claim, such as comparisons with similar studies or detailed explanations of why the current approach is insufficient. Providing more detailed justification or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the presentation of results in Tables 1 and 2, where the authors report the best results on the dev set with hyper-parameter search and model selection on the dev set. The reviewer points out that this is not sufficient for convincing the reader and suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, providing the authors with a specific direction to improve the credibility and robustness of their results. By addressing this feedback, the authors can enhance the transparency and reliability of their findings, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide more values of alpha, specifically recommending 1e-2 and 1e-3, to improve the ablation study. This feedback is clear and provides concrete guidance on what the authors need to do to enhance their draft. The action is direct and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study, namely the insufficient range of values for alpha (1e-4, 1e-1, 5e-1) and recommends adding more values, such as 1e-2 and 1e-3. This provides clear guidance on what needs to be addressed to improve the study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation study on alpha is insufficient because it only considers a limited range of values (1e-4, 1e-1, 5e-1). The reviewer recommends providing more values, such as 1e-2 and 1e-3, to enhance the study. This claim is somewhat verifiable as it highlights a specific gap in the study and provides a suggestion for improvement. However, it lacks detailed reasoning or references to support why these additional values are necessary or how they would impact the study. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation study on alpha, noting that the range of values tested is insufficient. It suggests that the authors should provide more values, specifically recommending 1e-2 and 1e-3, to enhance the study. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the robustness and comprehensiveness of their analysis. By addressing this point, the authors can strengthen their experimental results and provide a more thorough evaluation of the model\\'s performance. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology and dataset used in the paper. It asks for specific details regarding the number of topics used, the method for obtaining topic-word parameters for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are explicit and provide clear guidance on what information the authors need to provide to improve the clarity and transparency of their work. The feedback is concrete, as it specifies exactly what details are missing and need to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology and dataset used in the paper, specifically asking for details on the number of topics used, the method for obtaining topic-word parameters, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. While the comment does not explicitly mention specific sections of the paper, the authors can infer that these questions pertain to the methodology and dataset sections. The questions are specific, as they request detailed information about the dataset and its parameters. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification on specific aspects of the methodology and dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the methodology and dataset used in the paper. It asks for specific details regarding the number of topics used, the method for obtaining topic-word parameters for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are relevant and provide clear guidance for the authors to improve the transparency and comprehensiveness of their work. By addressing these points, the authors can enhance the clarity and rigor of their paper. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar datasets are typically described. Overall, the comment is mostly helpful as it identifies specific areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived weakness in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net or one-shot approaches. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should expand their analysis to include more NAS approaches. Additionally, the comment lacks concrete details on which specific approaches should be considered or how to incorporate them into the analysis. Therefore, the comment is somewhat actionable, as it points out an area for improvement but does not provide detailed instructions on how to implement the suggested changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis of BRP-NAS, specifically noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net or one-shot approaches. However, it does not specify which part of the paper discusses BRP-NAS, making it weakly grounded. The comment is specific in detailing what is missing in the analysis, namely the comparison with other NAS approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of BRP-NAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like super-net or one-shot approaches. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these other approaches should be included. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net or one-shot approaches. This feedback is somewhat helpful as it points out a gap in the analysis that could be addressed to provide a more comprehensive evaluation. However, the comment lacks specific suggestions or guidance on how the authors might expand their analysis to include these other approaches, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides insight into an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zero-shot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this perceived distraction or how to better align the paper with the reviewer\\'s preference. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a personal preference regarding the focus of the paper, suggesting that the zero-shot version and the connection to density estimation are distracting from the main point. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of these elements are distracting or how they could be better integrated into the main focus. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the focus of the paper, suggesting that the zero-shot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these aspects are distracting or how they could be better integrated. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zero-shot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not offer guidance on how the authors might better align their work with the reviewer\\'s preference. Without actionable advice or constructive criticism, the comment does not help the authors in making meaningful improvements to their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that more information is needed on the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This provides a clear action for the authors to take, which is to provide additional details on these aspects. The comment is explicit and concrete, as it specifies exactly what information is missing and how it should be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset quality. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, specifically regarding the translation and filtering methodology. This claim is somewhat verifiable as it highlights a potential gap in the paper, but it lacks specific examples or references to support the assertion. The authors would need to provide additional information to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology, which is crucial for assessing the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could significantly enhance the comprehensiveness and credibility of their dataset. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions on how to implement these suggestions, such as which attacks to consider or how to analyze the impact of different thresholds. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experiments, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its suggestion to include different attacks and explore threshold impacts, but without clear grounding, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that the current results are insufficient or that different attacks or thresholds are necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support for the authors to make meaningful improvements.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental results, suggesting that the current setup lacks attacks with different strengths and does not explore how different thresholds influence detection performance. This feedback is clear and actionable, as it provides a direction for the authors to enhance their experimental design by considering a broader range of attack scenarios and threshold variations. However, the comment could be more helpful if it offered specific suggestions on which attacks or thresholds to consider or how to analyze the impact of these variations. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their experimental results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It also notes that this is different from Figure 4, as the discriminator is co-adapting with the generator during training. While the comment implies an action, it does not provide explicit instructions on how to implement this evaluation or what specific steps to take. The authors can infer that they need to conduct this evaluation, but the lack of concrete guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that training a discriminator on generations from the learned model is needed to evaluate the claim of reducing exposure bias. The comment provides a clear direction for the authors to address the evaluation aspect of their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It notes that this is different from Figure 4, as the discriminator is co-adapting with the generator during training. The comment provides a logical reasoning for the evaluation method, which is based on a common practice in generative models. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the exact methodology from the suggestion, which could be clearer with additional details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for evaluating the claim of reducing exposure bias. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. This feedback is specific and offers a concrete step for the authors to take to strengthen their evaluation process. However, the comment could be more helpful if it included additional guidance on how to implement this evaluation or what specific metrics to consider. Overall, the comment is mostly helpful as it directs the authors toward a critical aspect of their evaluation, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is an explicit request for additional data or analysis, but it does not specify how the authors should go about obtaining this information or what specific metrics or methods to use. While the action is clear, the lack of detailed guidance on execution makes it somewhat actionable. The authors know what needs to be done but may need to infer the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: information on how much performance difference using different image sizes and different variations of ResNets can lead to. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking for more information on how much performance difference using different image sizes and different variations of ResNets can lead to. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is a clear and actionable suggestion that could help the authors improve their draft by addressing a specific gap in their analysis. However, the comment could be more helpful if it provided additional context or examples of how this information might be presented or analyzed. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the algorithm should be presented and described in detail, which is a clear and explicit action for the authors to take. However, it does not provide specific guidance on how to present or describe the algorithm in detail, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. While the action is explicit, the lack of detailed instructions makes it somewhat vague, as the authors may not be entirely sure of the exact changes needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the algorithm should be presented and described in detail, which is a general request for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithm need more detail or how it should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the algorithm should be presented and described in detail, which is a claim that requires justification. However, the comment does not provide any specific reasoning, examples, or references to support why this level of detail is necessary or how it would benefit the understanding of the proposed method. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the algorithm should be presented and described in detail, which is a valid point as it can help readers better understand the proposed method. However, the feedback is somewhat vague and lacks specific guidance on how to achieve this level of detail or what aspects of the algorithm need more explanation. While it identifies a potential area for improvement, the comment does not provide actionable steps or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speed-up. While the comment implies that the authors should include a runtime comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speed-up. However, it does not specify which part of the paper discusses this possibility, making it weakly grounded. The comment is specific in suggesting a particular type of comparison that could be included, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speed-up. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not present subjective judgments, suggestions, or deductions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speed-up. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting a specific analysis that could be included in the paper. However, the comment lacks depth and does not provide detailed guidance on how to conduct the runtime comparison or what aspects to focus on. While it offers a direction for enhancement, it does not fully support the authors in making the necessary improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test the method on CIFAR10, modify the method to accommodate natural images, or address the issue in the paper. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to real-world applications. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the method\\'s applicability to natural images, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to real-world applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not work on natural images. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to real-world applications. This is a valuable observation that prompts the authors to consider the broader applicability of their method beyond digit or text images. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand their method to accommodate natural images. While it identifies a potential limitation, it does not provide actionable feedback for improvement. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the prompts in Table 6 and 7 are not well-organized, with all sentences squeezed together. However, it does not provide any explicit or implicit suggestions on how the authors might improve the organization or formatting of the prompts. Without guidance on what specific changes could be made or how to address the issue, the authors are left without a clear path forward. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the prompts are not well-organized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prompts in Table 6 and 7 are not well-organized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is somewhat helpful as it points out a potential area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a more structured or visually appealing layout. While it highlights a problem, it does not offer actionable advice, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the figures are not clear, specifically mentioning issues with figure 2 and the lack of labels for modules like CMAF, L_BT, and VoLTA. This provides clear and direct actions for the authors to take, such as improving the clarity of the figures and ensuring all modules are labeled. The feedback is explicit and concrete, giving the authors precise guidance on how to address the issues. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the figure, such as the confusion regarding the relationship between the sub-figures and the lack of labels for modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures are not clear, specifically mentioning issues with figure 2 and the lack of labels for modules like CMAF, L_BT, and VoLTA. This is a subjective claim that requires justification or examples to support the assertion that the figures are unclear. The comment does not provide detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relationship between sub-figures is confusing, and modules like CMAF, L_BT, and VoLTA are not labeled. This feedback is clear and actionable, as it provides the authors with a direct way to improve the clarity and readability of their figures. By addressing these issues, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it offered suggestions on how to improve the labeling or organization of the figures. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the visual presentation of their results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work that offers a way around this issue, the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is explicit in its suggestion to address the issue by adding a line or two to the paper. However, it does not provide specific guidance on how to present this information or what specific content should be included. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFNs\" and \"a linear decomposition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a line or two to acknowledge the lack of a solution for the issue and the open (hard) nature of the problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work that offers a way around this issue, the authors should acknowledge the lack of a solution and the open (hard) nature of the problem. The comment provides a logical reasoning for the suggestion, as it highlights the importance of addressing the omission and its impact on the reader\\'s understanding. However, it does not provide specific references or examples of existing work that could offer an approximation or solution. This makes the claim mostly verifiable, as it requires further exploration by the authors to fully substantiate the suggestion.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that the authors should consider adding a line or two to acknowledge the lack of a solution for this issue and the open (hard) nature of the problem. This feedback is clear and actionable, as it provides a specific suggestion for improvement that would enhance the paper\\'s readability and overall clarity. By addressing this point, the authors can provide a more comprehensive understanding of the limitations and challenges in their work. Therefore, the comment is rated as mostly helpful, as it offers constructive guidance that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after fine-tuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their design choices. The action is implicit, as the authors need to infer that they should consider alternative measures or methods to account for domain drift and catastrophic forgetting. Additionally, the comment lacks concrete details on how to implement these changes, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after fine-tuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment highlights specific issues, it lacks detailed guidance on how to address them. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, questioning whether it adequately addresses aspects of domain drift and catastrophic forgetting. The comment provides a logical reasoning by suggesting that there are other factors to consider, such as domain drift, which are separate from catastrophic forgetting. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and justify their choice of perplexity as a measure, which is a reasonable request but requires additional effort to substantiate. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design choices in the paper, specifically questioning the use of perplexity as a measure of semantic information retention after fine-tuning. It points out that while perplexity may relate to the original task, it does not address aspects of domain drift and catastrophic forgetting, which are separate concerns. The comment raises a valid point by suggesting that the authors should consider how these factors are controlled or addressed in their design. However, it lacks specific suggestions or guidance on how the authors might improve their design or analysis to account for these concerns. While it provides some insight into a potential weakness, the comment could be more helpful with additional details or actionable advice. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. While it implies that the authors should address these questions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of image number on performance and explain BYOL in the abstract. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image number and the explanation of BYOL, but without clear references to specific sections, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. These are relevant points that could help the authors improve their draft by addressing potential gaps in their explanation or methodology. However, the comment lacks specificity and does not provide detailed guidance on how to address these questions or what specific aspects of BYOL should be explained. While it identifies areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the effectiveness of the method, specifically the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what kind of arguments or intuitions are needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the effectiveness of the method, particularly regarding the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. However, the comment does not specify which part of the paper discusses the L_pixel component, making it weakly grounded. The comment is specific in its request for stronger arguments or intuitions, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the observed effects are strong but questions the clarity of why the method works, particularly regarding the L_pixel component. The reviewer suggests that providing stronger arguments or intuitions about why these particular losses are beneficial would be welcome. However, the comment lacks specific examples or references to support the claim that the method is unclear or that the L_pixel component is not well-explained. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the method's effectiveness, particularly the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation of the method's workings. However, the comment could be more helpful if it offered specific suggestions or examples of what kind of arguments or intuitions would be most beneficial. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and justification of their method, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is clear and provides concrete guidance on what needs to be added to the draft. The authors know exactly what aspects to include and can follow the suggestions to improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what is lacking in the current overview of long-context language models, including a list of specific methods and approaches that should be discussed. This level of detail helps the authors understand exactly what needs to be addressed to improve the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section lacks details and suggests that it should provide a more comprehensive overview of existing methods and their limitations. The comment specifically mentions sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods as examples of what should be included. This provides a clear and detailed justification for the claim, making it fully verifiable. The inclusion of specific references to relevant literature supports the reasoning and guides the authors on how to improve their work. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the Related Work section, noting that it lacks details and does not provide a comprehensive overview of existing methods and their limitations. It offers a clear and actionable suggestion by listing specific areas that should be discussed, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is valuable as it guides the authors on how to enhance the Related Work section, ensuring it is more thorough and informative. However, the comment could be more helpful if it provided additional context or examples on how these methods relate to the authors' work. Overall, the comment is mostly helpful, as it offers actionable guidance but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. The reviewer suggests that LLMs are typically trained on trillions of tokens, implying that the dataset size is insufficient. However, the comment does not provide explicit guidance on how the authors might address this concern or suggest ways to improve the dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the dataset size and its implications for capturing user traits and personalities, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. The reasoning is logical but requires more detailed evidence or examples to be fully verifiable. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens, suggesting that the dataset may not be large enough to capture the necessary combinations of personalities and topics. While the comment identifies a potential weakness in the dataset, it lacks specific suggestions or guidance on how the authors might address this issue or improve the dataset. The feedback is somewhat helpful as it highlights an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its suitability for assessing models' understanding of fine-grained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending alternative metrics or methods to assess the models' understanding. As a result, the authors are left without a clear path forward to address the issue raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the use of binary classification as a baseline metric, questioning its suitability for assessing models' understanding of fine-grained errors. However, it does not specify which part of the paper discusses this binary classification or where it is used as a baseline metric. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the binary classification approach but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its suitability for assessing models' understanding of fine-grained errors. The reviewer provides a logical reasoning by suggesting that binary classification might not capture the nuances of fine-grained errors, such as technique errors. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning and evidence to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of binary classification as a baseline metric, questioning its suitability for assessing models' understanding of fine-grained errors. It acknowledges the importance of the TAL task but expresses doubt about the effectiveness of binary classification in capturing the nuances of technique errors. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or explore alternative metrics or methods. While it identifies a potential issue, it does not provide actionable feedback or detailed insights into how the authors might improve their approach. As a result, the comment is somewhat helpful, as it highlights a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or test the method\\'s applicability to other feature types. The comment implies that the authors should consider extending their analysis to include real and categorical features, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the feature types used and the need for clarity on applicability to other types. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. The comment highlights a potential limitation in the method\\'s scope, which is a valid observation. However, it does not provide specific examples or references to support the claim that real and categorical features are common in real-world data. This lack of detailed evidence or examples makes the claim somewhat verifiable, as it points out a potential issue but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the work, noting that it only uses binary features and questioning the applicability of the method to real and categorical features. This is a relevant observation that could impact the generalizability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or test the method\\'s applicability to other feature types. While it points out a critical area for improvement, the feedback could be more actionable and helpful by offering concrete steps or examples. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing should be improved, indicating that certain points in the paper are unclear. However, it does not specify which points are unclear or provide guidance on how to improve the clarity. The action is implicit and vague, as the authors are left to infer which parts of the paper need improvement and how to achieve that. Without concrete examples or suggestions, the authors may struggle to determine the necessary changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to improve the clarity. Without explicit references to sections, figures, or specific content, the authors cannot confidently determine which parts of the paper need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing should be improved because some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable, as it lacks sufficient evidence or reasoning to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it lacks specificity and does not provide detailed guidance or examples of what needs to be clarified or improved. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issue. This makes the comment barely helpful, as it identifies a potential problem but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use other metrics, specifically BERTScore, to evaluate their results. This is an explicit suggestion that provides a clear action for the authors to take. The comment is also concrete, as it specifies the exact metric that should be used, giving the authors a direct and specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or a specific table or figure. Without explicit references to the paper\\'s structure, the authors may find it challenging to determine where to implement this suggestion. The comment is specific in recommending the use of BERTScore, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not provide any reasoning, examples, or references to support why BERTScore is a better or more appropriate metric compared to the ones currently used. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using other metrics, specifically BERTScore, to evaluate the results. While it identifies a potential area for improvement, it lacks specificity and does not provide a rationale or examples of why BERTScore might be a better choice over the current metrics. The comment also does not offer guidance on how to implement this suggestion or address any concerns about the current evaluation methodology. As a result, the feedback is somewhat helpful, as it points out a possible enhancement but does not provide enough detail or guidance for the authors to effectively address the issue. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SynTextBench metric,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there has been a significant amount of work on LLM evaluation, with some metrics not satisfying the proposed desiderata. It further recommends comparing the SynTextBench metric to other metrics in the literature to understand its applicability. The comment provides a logical reasoning by referencing existing work and suggesting a specific comparison, which is a clear and actionable suggestion. However, it lacks specific references to the existing literature or detailed examples of metrics that do not satisfy the proposed desiderata. This makes the claim mostly verifiable, as it provides a solid basis for the suggestion but could be strengthened with more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for the authors to compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This feedback is actionable and offers a clear direction for the authors to enhance their work by providing a context for their metric within the existing literature. However, the comment could be more helpful if it included specific examples or references to the metrics being compared, which would further guide the authors in implementing this suggestion. Overall, the comment is mostly helpful as it provides a valuable insight into improving the paper by contextualizing the metric within the broader literature.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel, as it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not provide any explicit or implicit suggestions for improvement or action that the authors should take. There is no guidance on how to address the lack of novelty or how to enhance the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the algorithm for constructing coresets, specifically mentioning that it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper discusses this algorithm or its novelty, making it weakly grounded. The comment is specific in detailing the lack of novelty, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel, as it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This claim is somewhat verifiable as it provides a logical reasoning for the lack of novelty, but it lacks specific references or detailed examples to fully substantiate the claim. The authors would need to investigate the existing frameworks to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the algorithm for constructing coresets is not novel, as it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. While this feedback highlights a potential limitation of the work, it does not provide any actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without specific advice or recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of their work. The comment lacks actionable details, such as identifying particular sections or aspects that need improvement or suggesting specific changes to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are problematic, making it difficult for the authors to understand and address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing or annotations are unclear, the authors may find it challenging to understand and address the issue. The lack of specific details makes the claim difficult to verify, resulting in a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their work. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is not helpful at all, as it does not offer any actionable insights for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. It highlights a discrepancy between the overall F1 score and the F1 scores for individual types. While the comment identifies an area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should investigate the discrepancy and potentially provide an explanation or clarification. However, the lack of concrete instructions or specific actions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method\\'s performance in terms of achieving SOTA performances and the discrepancy in F1 scores between the overall and individual types. The comment raises a question about the performance in a specific setting, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. It highlights a discrepancy between the overall F1 score and the F1 scores for individual types. While the comment identifies a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in Table 2, noting that only 8 of the 14 evaluation metrics achieve state-of-the-art (SOTA) performances. It also questions the discrepancy between the overall F1 score and the F1 scores for individual types in a particular setting. This feedback is clear and actionable, as it prompts the authors to investigate and explain the performance discrepancies, which could lead to improvements in the draft. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered additional context. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. While the comment implies that the authors should reconsider their approach, it does not explicitly instruct them to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the approach, questioning the rationale behind the chosen methodology. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. The comment provides a logical reasoning by implying that considering all reports would lead to a more comprehensive analysis. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the implications of including all reports to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. This feedback highlights a potential limitation in the methodology and prompts the authors to reconsider their approach. However, the comment does not provide specific suggestions or examples on how to address this issue or improve the analysis. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the incremental nature of the proposed solution compared to the relaxation proposed by Guzman et al. However, it does not provide any specific suggestions or actions for the authors to take. There is no guidance on how to improve the solution or what aspects of the relaxation should be considered. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what needs to be done to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the incremental nature of the proposed solution compared to the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what aspects of the relaxation should be considered or how the proposed solution could be improved. Without specific references or guidance, the authors cannot confidently determine which part of the paper needs attention or how to address the issue. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the incremental nature of the proposed solution compared to the relaxation proposed by Guzman et al. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the comparison or how their work fits within the existing literature. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the incremental nature of the proposed solution compared to the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of how to enhance their work or address the identified issue. As a result, the comment is not helpful at all, as it does not offer any value to the authors in terms of improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of thorough exploration of the scalability bounds of FedDES and the absence of a clear discussion on memory requirements and computational complexity. While it identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the discussion on scalability bounds, memory requirements, and computational complexity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements and computational complexity. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, namely a thorough exploration of scalability bounds and a discussion on memory requirements and computational complexity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements and computational complexity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth and thoroughness, namely the discussion on scalability bounds and the absence of clear discussions on memory requirements and computational complexity. This feedback is valuable as it highlights a critical aspect of the paper that needs further exploration and clarification. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of what a comprehensive discussion might entail. Despite this, the comment is somewhat helpful as it directs the authors' attention to an important area for improvement, prompting them to enhance their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This implies that the authors should consider increasing the complexity of their instances to better test the LLMs\\' ability to model problems with larger instance sizes. However, the comment does not provide specific guidance on how to achieve this, such as suggesting additional constraints or variables to include. While the action is implicit, it lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This implies that the authors should consider increasing the complexity of their instances to better test the LLMs\\' ability to model problems with larger instance sizes. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact area needing revision. The comment is specific in suggesting more constraints and variables but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. The reviewer raises a concern about the LLMs\\' ability to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that the current instance sizes are insufficient. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the number of variables in the instances used to test the LLMs\\' ability to model problems. It suggests that the authors should consider generating instances with more constraints and variables to better test the LLMs\\' capabilities. This feedback is somewhat helpful as it points out an area for improvement, but it lacks specific guidance on how to achieve this or what additional constraints or variables might be relevant. While it provides a direction for enhancing the study, the comment could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results presentation can be improved, specifically mentioning that the y-axis in Figures 2 and 3 is labeled as \"performance,\" which is ambiguous, and that the runtime is not represented. It provides a concrete suggestion to present the results as a scatter plot with the x/y axes being runtime/performance, which would help readers better understand and interpret the results. Additionally, it recommends highlighting the best results in tables. While the comment is explicit in its suggestions, it does not provide detailed guidance on how to implement these changes, such as specific formatting or presentation guidelines. Therefore, the comment is mostly actionable, as it provides clear directions but lacks detailed execution steps.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as the labeling of the y-axis as \"performance\" and the absence of runtime representation in those figures. Additionally, it provides a concrete suggestion to present the results as a scatter plot with x/y axes being runtime/performance, which would help readers better understand and interpret the results. The comment also suggests highlighting the best results in tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results presentation can be improved by providing a scatter plot with x/y axes being runtime/performance, which would help readers better understand and interpret the results. The comment also mentions that the y-axis in Figures 2 and 3 is labeled as \"performance,\" which is ambiguous, and that the runtime is not represented. This feedback is mostly verifiable as it provides a logical reasoning for improving the clarity of the results presentation, but it lacks specific examples or references to support the claim. The authors would need to infer the exact improvements needed based on the suggestion. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies a lack of clarity in the labeling of the y-axis in Figures 2 and 3, which is labeled as \"performance,\" and suggests that the runtime should be represented. The comment offers a concrete suggestion to present the results as a scatter plot with x/y axes being runtime/performance, which would help readers better understand and interpret the results. Additionally, it recommends highlighting the best results in tables. This feedback is clear and actionable, providing the authors with a direct path to enhance the clarity and effectiveness of their results presentation. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, the key nodes for attention, and the model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or clarify the statement in their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this statement is from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the implications of the base node, but it lacks grounding as it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the statement \"NodeSort differentially sorts nodes depending on the base node.\" It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is factual and does not contain a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or address this issue in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the direction of the arrow in Figure 2, asking why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i). While the comment raises a specific question about the direction of the arrow, it does not provide explicit guidance on how the authors should address this issue or what changes, if any, should be made to the figure or the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the direction of the arrow, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and provides a rationale for why it might be unexpected, suggesting that the arrow should be from the latent space to n^(i). This level of detail helps the authors understand what aspect of the figure needs clarification or revision. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) rather than from a Gaussian space. The reviewer provides a logical reasoning for this suggestion, stating that the main purpose might be to influence n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is clear, the absence of additional evidence or references makes the claim somewhat verifiable, as the authors may need to further explore the rationale behind the suggested change. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) rather than from a Gaussian space. This feedback is somewhat helpful as it points out a potential inconsistency or misunderstanding in the figure, prompting the authors to reconsider the direction of the arrow and its implications. However, the comment does not provide detailed guidance on how to address this issue or why it might be important, leaving the authors with a clear question but without a comprehensive understanding of the impact or potential improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with abbreviations in Table 5, noting that \"AR\" stands for domain adaptation tasks and algorithms. This feedback is explicit and provides a clear action for the authors to take, which is to define the abbreviations used in the table. The comment is concrete because it specifies exactly what needs to be done to improve the clarity of the table. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with abbreviations, namely that \"AR\" stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This claim is somewhat verifiable as it provides a specific example of an abbreviation that is unclear, but it lacks broader context or justification for why other abbreviations might also be problematic. The comment could be strengthened by providing more examples or explaining how these abbreviations impact the clarity of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with abbreviations in the paper, noting that many of them lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify the abbreviations used in their work, which can significantly improve the clarity and accessibility of the paper. However, the comment could be more helpful if it suggested ways to define these abbreviations or provided examples of how to do so effectively. Overall, the comment is mostly helpful as it highlights a clear area for improvement and provides a specific example to address, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using advantage instead of q value for analysis, suggesting that there might be other technical considerations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore these considerations or provide an explanation for their choice. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to address the question. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using advantage instead of q value for analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it highlights a potential issue, it does not provide specific guidance on what needs to be addressed or improved. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the choice of using advantage instead of q value for analysis, suggesting that there might be other technical considerations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or what specific technical considerations are at play. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using advantage instead of q value for analysis, suggesting that there might be other technical considerations. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or explore the potential technical considerations. The comment is somewhat helpful as it prompts the authors to consider an alternative approach, but it does not offer actionable advice or detailed feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the setting of Unsupervised Online Adaptation, suggesting that it is not truly unsupervised because the training set requires annotations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or clarify the setting. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, contradicting the notion of unsupervised adaptation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, pointing out that it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This feedback is somewhat helpful as it highlights a possible inconsistency in the paper, prompting the authors to reconsider their approach or clarify the setting. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or explaining the rationale behind the current setup. To be more helpful, the comment could provide more detailed feedback or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the fairness of the performance comparison in Table 1, specifically noting that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, and PRIS set all sample weights as 1. This comment implies that the authors should address the issue of fairness in the performance comparison, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should ensure fairness in the comparison and may not be entirely clear on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness in the performance comparison due to different sample weights used by VINS compared to other baselines like DNS, AOBPR, SA, and PRIS. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair due to different sample weights used by VINS compared to other baselines. This claim is somewhat verifiable as it provides a specific reason for the perceived unfairness, which is the use of different sample weights. However, the comment lacks detailed examples or references to support the claim fully, such as comparing the performance with and without these sample weights. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance comparison in Table 1, noting that the fairness of the comparison is compromised due to different sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential bias in the evaluation that could impact the interpretation of results. By pointing out this issue, the comment provides the authors with a clear direction for improvement, such as ensuring that all methods are evaluated using consistent criteria. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of how to ensure fairness in the comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to optimize the buffer size or alternative methods to reduce complexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the time complexity issue related to the reply buffer being too large, but it does not specify which part of the paper this issue is discussed in. Additionally, it does not provide specific details or examples on how to address this complexity or what changes might be necessary. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs attention or how to improve it. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, and it references PRM-RL as a source. However, the comment does not provide detailed reasoning or examples to support this claim, such as how the time complexity is calculated or how the buffer size affects it. The reference to PRM-RL is a general reference and does not fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks detailed evidence or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could impact the overall performance of the system. However, it does not provide any specific suggestions or guidance on how to address this issue, such as recommending ways to optimize the buffer size or suggesting alternative methods to reduce complexity. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a concern but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative perspectives and baselines to consider, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific examples or references to support the claim that these alternative perspectives are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting alternative perspectives that could enhance the paper\\'s contribution. However, the comment lacks specific guidance on which baselines to consider or how to implement these suggestions, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a brief conclusion and a summary of their contributions. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need for a brief conclusion and a summary of the paper\\'s contributions, providing clear guidance on what needs to be addressed. However, it does not specify which part of the paper this feedback pertains to, such as the conclusion section or the introduction. While the authors can infer that it relates to the conclusion, the lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in detailing what needs to be included, making it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for the authors to provide a brief conclusion and a summary of their contributions. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or improvement, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the need for a brief conclusion and a summary of the paper\\'s contributions. This feedback is clear and actionable, as it provides the authors with a direct suggestion on how to enhance the clarity and completeness of their paper. By addressing this feedback, the authors can better guide readers on the significance and impact of their work. However, the comment could be more helpful if it provided additional guidance on what aspects of the contributions should be highlighted or how to structure the conclusion. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the experiment or explanation need to be addressed or improved. Without actionable suggestions or a clear direction for the authors, this comment leaves them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the synthetic experiment in a non-separable case, mentioning Figure 1. This provides full grounding as it explicitly references a figure in the paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the explanation of how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a valid point that prompts the authors to consider the rationale behind their experimental setup and the implications of the data distribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APE-GAN may not be comprehensive. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on which method to compare with or how to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparison but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, rather than just APE-GAN. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where comparisons are made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in suggesting a comparison with a method that defends against multiple attacks, but it is not grounded because it does not specify where this comparison should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APE-GAN may not be comprehensive. The comment provides a logical reasoning for the suggestion, noting that such a comparison would make the results more meaningful. However, it does not provide specific references or examples of methods that defend against multiple attacks, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should expand their comparison by including a method designed to defend against multiple attacks, rather than just APE-GAN. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically the comprehensiveness of the comparisons. However, the comment does not provide specific guidance on which method to compare with or how to present the results, leaving the authors with a general direction but without detailed actionable steps. While it highlights an important aspect for improvement, the lack of specificity limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results are presented in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, implying that the authors should clarify this aspect. However, the comment does not provide explicit guidance on how to improve the presentation or what specific changes should be made to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the reasoning behind the results presentation but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the presentation of results, specifically mentioning the disregard of safety violations in the first 1000 episodes. This provides some level of grounding as it implies that the issue is related to the results section, but it does not explicitly mention the section or figure where this is discussed. The comment is specific in pointing out the issue with the presentation of results and questioning the reason for this approach. However, without explicit references to specific sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results are presented in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. The comment questions the reason for presenting the results in this way, suggesting that it lacks clarity. However, the comment does not provide specific examples or detailed reasoning to support why the presentation is convoluted or how it disregards safety violations. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the exact issues and address them themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, which is a clear and actionable point for the authors to address. However, the comment could be more helpful if it provided suggestions on how to improve the presentation or offered examples of how to present the results more effectively. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs clarification and improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This is a clear and direct action for the authors to take, providing them with a specific task to complete. The comment is concrete because it specifies exactly what needs to be defined, making it highly actionable. Therefore, this comment aligns with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be defined, which is the bounds for \\\\tau_i^l, and why it is important for understanding the time-warp function. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, specifically asking the authors to define the bounds for \\\\tau_i^l. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides clear and actionable feedback by explicitly requesting the authors to define the bounds for \\\\tau_i^l. This information is crucial for understanding the time-warp function, which is an important aspect of the paper. By addressing this request, the authors can enhance the clarity and comprehensibility of their work, making it more accessible to readers. The comment is specific and actionable, offering a direct path for improvement. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific writing errors, such as \"informative informative\" and \"performance,\" and notes that the latter lacks a title. While the comment identifies these issues, it does not provide explicit guidance on how to correct them or suggest ways to improve the writing. The authors can infer that they need to proofread their manuscript for such errors, but the comment lacks concrete details on how to address these issues. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages (5 and 1) where writing errors are found, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the exact errors, such as \"informative informative\" and \"performance,\" and notes that the latter lacks a title. This level of detail provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights specific writing errors, such as \"informative informative\" and \"performance,\" and notes that the latter lacks a title. However, it does not provide any reasoning or examples to support why these errors are problematic or how they impact the paper\\'s clarity or readability. Without additional context or explanation, the authors may find it challenging to understand the significance of these errors and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific writing errors in the paper, such as \"informative informative\" and \"performance,\" which lack a title. This feedback is valuable as it points out areas where the authors can improve the clarity and professionalism of their manuscript. However, the comment does not provide suggestions on how to correct these errors or offer broader guidance on improving the overall writing quality. While it highlights a specific issue, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific critique of a statement on line 134, pointing out that it is only true for a specific sigmoid function and suggesting that Theorem 4.1 should be elaborated on in the main text. The comment implies that the authors should provide more explanation or intuition regarding why this holds, particularly in the context of the RNN and URNN convergence to the nearest FP. While the action is implicit, it is concrete in suggesting what needs to be addressed, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the statement on line 134 and suggests elaborating on Theorem 4.1 in the main text. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques a statement on line 134, suggesting that it is only true for a specific sigmoid function and that Theorem 4.1 should be elaborated on. The comment provides a logical reasoning by explaining the dependency on the maximum slope and the convergence to the nearest FP for the RNN. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or references to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of a statement on line 134, pointing out that it is only true for a specific sigmoid function and suggesting that Theorem 4.1 should be elaborated on in the main text. It offers a logical explanation of why this is important, particularly in the context of the RNN and URNN convergence to the nearest FP. This feedback is clear and actionable, as it directs the authors to provide more explanation or intuition in the main text to support the claim. However, it could be more helpful if it included specific suggestions on how to elaborate on Theorem 4.1 or what additional information would be beneficial. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and depth of their explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the efficiency of pairwise matching, suggesting that it is not suitable for practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve efficiency or what specific changes could be made to enhance the practicality of the system. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the efficiency of pairwise matching, suggesting it is not suitable for practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency are problematic or how they could be improved. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the assertion, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the efficiency of pairwise matching, suggesting that it may not be suitable for practical application systems. However, it lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear understanding of what changes or improvements could be made to enhance the efficiency of their approach. As a result, the comment is not particularly helpful, as it identifies a problem but does not offer a path for resolution. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how the authors could improve this allocation or what aspects of the figure need to be revised. The comment also mentions that the authors could have edited the space of the main paper more wisely, but again, it lacks concrete details on how to achieve this. As a result, the authors are left without clear actions to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not specify which part of the paper this figure is located in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment mentions that the authors could have edited the space of the main paper more wisely, but it does not provide specific guidance on what aspects of the paper should be improved. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or explanation, the authors may find it challenging to understand and address the feedback. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how the authors could improve this allocation or what aspects of the figure need to be revised. Additionally, the comment mentions that the authors could have edited the space of the main paper more wisely, but again, it lacks detailed feedback or actionable advice. Without clear direction, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the plan-based method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to methods with pre-defined plans, as shown in Table 2. The comment suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the method\\'s generalizability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the plan-based method, specifically mentioning the need for manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also compares the learned plan methods to those with pre-defined plans, as shown in Table 2, and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment does not explicitly mention which part of the paper discusses these methods or tables, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the plan-based method and its generalizability, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also suggests that the learned plan methods are not comparable to those with pre-defined plans, as shown in Table 2, indicating a potential limitation in generalizability. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the plan-based method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, as shown in Table 2, indicating a potential issue with generalizability. This feedback is valuable as it highlights a critical weakness in the methodology and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment could be more helpful if it provided suggestions on how to address this limitation or improve the generalizability of the method. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a key area for improvement but lacks specific guidance on how to resolve the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the first sentence of the abstract. This is a clear and direct action, leaving no ambiguity about what needs to be done. The comment provides a specific and concrete instruction, making it highly actionable. The authors know exactly what step to take to improve their draft, which aligns with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to rewrite the first sentence of the abstract. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for a change, specifically asking for the first sentence of the abstract to be rewritten. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for modification, making it a factual statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment provides a clear and direct suggestion for improvement by instructing the authors to rewrite the first sentence of the abstract. This feedback is actionable and specific, offering a concrete step the authors can take to enhance the clarity and impact of their abstract. However, the comment does not elaborate on why the current sentence is problematic or what specific changes would improve it. While it provides a clear direction, it lacks depth and detailed guidance, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. While the comment implies that this is necessary, it does not explicitly instruct the authors to do so. Additionally, it provides a rationale for why this is important, mentioning the standard practice in most papers on GPs and the potential time constraints due to dataset size. However, the comment lacks concrete guidance on how to implement this suggestion, such as the number of splits or folds to use. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"nearly all experiments\" and \"the results are reported for a single held-out test set,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. The comment provides a clear and specific suggestion for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. The reviewer provides a logical reasoning by stating that this is a standard practice in most papers on GPs and that it would give a more accurate representation of the method\\'s performance. However, the comment lacks specific examples or references to support the claim that using multiple splits is necessary or beneficial in the context of the paper. This makes the claim somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single held-out test set, which is not standard practice in most papers on GPs. The reviewer suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\\'s performance. While the comment highlights an important issue, it does not provide specific guidance on how to implement this suggestion, such as the number of splits or folds to use. Additionally, it does not explain why this is important or how it might impact the interpretation of the results. Despite these limitations, the comment provides a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer what changes might be needed without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the method are considered overly complex or how to simplify it. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While it identifies a potential issue with the complexity of the method, it lacks specificity and does not provide actionable guidance or suggestions for simplifying the method or identifying the underlying principle. The comment points out a possible area for improvement but does not offer detailed advice on how to address it, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the addition of a method to improve transferability as a positive step but suggests that it is not a significant contribution. However, it does not provide any explicit or implicit guidance on how the authors might address this feedback or improve their contribution. There is no suggestion for additional methods, experiments, or analyses that could enhance the significance of the contribution. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the addition of a method to improve transferability. It also lacks specificity because it does not provide details on what aspects of the contribution are considered insignificant or how the authors might address this issue. Without clear references to specific sections or elements of the paper, the authors cannot effectively understand or respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that adding a method to improve transferability is a positive step but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition is not significant. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the addition of a method to improve transferability as a positive step but suggests that it may not be a significant contribution. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance the significance of their contribution or what additional steps could be taken to strengthen their work. Without detailed feedback or constructive advice, the authors are left without a clear path for improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the hGRU architecture appears ad-hoc and lacks motivation, but it does not provide any explicit or implicit suggestions for improvement. It does not offer guidance on how the authors might address this issue or provide specific details on what aspects of the architecture need to be improved or motivated. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the hGRU architecture as \"ad-hoc\" and lacking motivation, but it does not specify which part of the paper discusses this architecture. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered ad-hoc or how it could be better motivated. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the hGRU architecture is \"ad-hoc\" and lacks motivation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what makes the architecture ad-hoc or how it could be better motivated, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the hGRU architecture, suggesting that it appears ad-hoc and lacks motivation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the motivation behind the architecture. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is not helpful at all, as it does not offer any constructive direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment provides a specific suggestion for improvement by recommending the use of \"s_n\" instead of \"s_t\" and requests additional data to support the claim. While the comment is explicit in its request for clarification and additional data, it does not provide detailed guidance on how to implement these changes or what specific data to include. Therefore, the comment is mostly actionable, as it clearly identifies the areas for improvement but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of \"s_n\" instead of \"s_t\" and expresses curiosity about the asymptotic performance of the proposed method. The comment further requests average return results with more environment steps, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment includes a reference to a GitHub repository, which could provide additional context or evidence for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to explore the referenced repository or provide additional information to fully understand and address the concerns raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, which is a clear and actionable suggestion for improvement. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps, which could provide valuable insights into the method\\'s effectiveness. The inclusion of a reference to a GitHub repository further supports the request for additional data. This feedback is detailed and provides the authors with concrete steps to enhance their draft, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0, L1)-smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between their analysis and that of Zhang et al. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what aspects of the analysis need clarification or how to differentiate it from existing work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the challenges when analyzing Adam under the (L0, L1)-smoothness condition. It suggests that the authors should explain these challenges and differentiate their analysis from that of Zhang et al. However, the comment does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as explaining the challenges and differences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unclear what the challenges are when analyzing Adam under the (L0, L1)-smoothness condition. The reviewer suggests that the analysis could be straightforward and recommends explaining the challenges, particularly the differences with Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that the analysis is unclear or that there are challenges. Without such evidence or examples, the authors may find it difficult to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the challenges when analyzing Adam under the (L0, L1)-smoothness condition. It suggests that the authors should clarify these challenges and differentiate their analysis from that of Zhang et al. This feedback is somewhat helpful as it points out a potential area of improvement in the paper, prompting the authors to provide more detailed explanations. However, the comment could be more helpful if it offered specific suggestions on how to address the challenges or differentiate the analysis. Overall, the comment provides some direction but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of multiple comments, each addressing different aspects of the paper. The first comment suggests toning down the statement about the neural network memorizing critical points, providing a specific reference to TopoNet [24] to support the suggestion. This is an explicit action with concrete guidance on how to improve the draft. The second comment suggests compressing the method section and correcting grammatical errors, which are also explicit actions with some level of detail. However, the comment does not specify which grammatical errors need correction, making it somewhat vague. Overall, the comment provides clear and actionable feedback, but the lack of detailed guidance on grammatical errors limits its full actionability. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"34\" and \"the method section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as toning down a statement about neural networks memorizing critical points, compressing the method section, and correcting grammatical errors. The comment even provides a specific example of a grammatical error (\"l\"). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions. The first claim about the neural network not memorizing critical points is supported by a reference to TopoNet [24], providing a specific source for the reviewer\\'s understanding. This makes the claim mostly verifiable. The second suggestion about compressing the method section and correcting grammatical errors is based on the reviewer\\'s subjective opinion and does not require external evidence. The third suggestion about grammatical errors is a request for clarification, not a claim. Therefore, the overall comment is mostly verifiable, as it provides some support for the first claim but lacks detailed evidence for the second and third points.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and constructive feedback that could enhance the clarity and accuracy of the paper. Additionally, it points out that the method section could be compressed to focus on essential definitions, which is a clear and actionable suggestion for streamlining the content. The comment also highlights grammatical errors, which is important for clarity and professionalism. However, the comment could be more helpful if it provided specific examples of grammatical errors or suggestions for improvement. Overall, the feedback is mostly helpful as it offers clear and actionable guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that most person re-ID methods are based on pedestrian detectors (two-step methods) and mentions the existence of end-to-end methods that combine detection and re-ID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or how it relates to their work. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"most of person re-ID methods\" and \"pedestrian detector\" without specifying which part of the paper these methods are discussed in. This makes it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment provides a general observation about the existence of end-to-end methods but does not specify what needs to be addressed or improved regarding this observation. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a factual statement about the basis of person re-identification methods, mentioning that most are based on pedestrian detectors (two-step methods) and that there are also end-to-end methods that combine detection and re-ID. This statement is based on common knowledge in the field and does not require additional evidence or references to be considered factual. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual observation about the basis of person re-identification methods, noting that most are based on pedestrian detectors (two-step methods) and that there are also end-to-end methods that combine detection and re-ID. While this information is relevant and may be of interest to the authors, it does not offer any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to enhance their work or address any specific issues. As a result, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests adding a first sentence to introduce the content of Section 3.2. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to add a first sentence to introduce the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or improvement, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests adding a first sentence to introduce Section 3.2, which is a clear and actionable piece of feedback. By doing so, the authors can better orient the reader to the content of the section, improving the clarity and coherence of the paper. However, the comment could be more helpful if it provided specific guidance on what should be included in the introductory sentence, such as the main focus or objectives of the section. Despite this, the suggestion is still valuable and provides a straightforward way for the authors to enhance their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or address this point in the paper, nor are there suggestions for improvement or correction. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the phrase \"initial rationale selector is perfect\" and provides a logical reasoning that if it were perfect, no additional work would be needed. This clarity in both grounding and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this assumption is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This feedback highlights a potential confusion or misunderstanding in the paper, which could be clarified or addressed by the authors. However, the comment does not provide specific suggestions or guidance on how to clarify this point or improve the draft. While it identifies an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific way to clarify the definition of uncertainty in the paper. It explicitly recommends updating the text to explain that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve the clarity of their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the definition of uncertainty, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for updating the definition of uncertainty, explaining how the epistemic model uncertainty is represented in the prior distribution and how it is updated in the form of a posterior distribution. This level of detail guides the authors on what needs to be addressed to improve the clarity of their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a clarification on the definition of uncertainty, specifically stating that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This suggestion is based on logical reasoning, as it provides a clear explanation of how uncertainty is defined and updated in the context of the paper. However, the comment does not provide specific references or examples to fully substantiate the claim, which could enhance its verifiability. Therefore, the comment is mostly verifiable, as it provides a logical basis for the suggestion but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for clarifying the definition of uncertainty in the paper. It recommends updating the text to explain that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and precision of their work. By addressing this suggestion, the authors can improve the comprehensibility of their draft for both experts and non-experts in the field. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for specific details regarding the number of questions created for the zero-shot intent classifier and its accuracy. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of domain ontologies and asks for details regarding the number of questions created for the zero-shot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It does not contain a claim or opinion but rather seeks clarification on a specific aspect of the methodology. The comment is factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also requests information on the number of questions created for the zero-shot intent classifier and its accuracy. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address the issue or why this information is important. Overall, the comment is mostly helpful as it directs the authors to specific areas needing clarification, providing a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include additional citations to set their work in the context of other Multi-Agent Reinforcement Learning (MARL) work, specifically mentioning recent papers on self-play and population-play with respect to exploration and coordination. The comment provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This guidance is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for additional citations to set the work in the context of other Multi-Agent Reinforcement Learning (MARL) work, specifically referencing recent papers on self-play and population-play with respect to exploration and coordination. The authors can accurately identify the part of the paper that needs attention, which is the section on citations. The comment is also specific because it provides examples of relevant papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail helps the authors understand exactly what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks citations to place it in the context of other Multi-Agent Reinforcement Learning (MARL) work, specifically mentioning recent papers on self-play and population-play with respect to exploration and coordination. The reviewer provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail and reference to external works supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these references would enhance the context of the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper lacks citations to place it in the context of other Multi-Agent Reinforcement Learning (MARL) work, particularly recent papers on self-play and population-play with respect to exploration and coordination. The comment provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which can guide the authors in selecting appropriate references. This feedback is clear and actionable, offering a concrete way for the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it included a rationale for why these references are important or how they would contribute to the paper. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their work with other self-supervised learning methods that are not based on contrastive learning. This is an explicit action that provides a clear direction for the authors to follow. However, it does not specify which specific methods should be compared or how to conduct the comparison, leaving some room for ambiguity. While the action is explicit, it lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the work with other self-supervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to incorporate this comparison. Additionally, the comment lacks specificity regarding which specific methods should be compared or how the comparison should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it would be beneficial to compare the work with other self-supervised learning methods that are not based on contrastive learning. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their work with other self-supervised learning methods that are not based on contrastive learning. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s comparison and suggests a direction for further exploration. However, the comment lacks specificity regarding which specific methods should be considered or how the comparison should be conducted. Without detailed guidance, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is rated as somewhat helpful, as it provides a general direction but lacks depth and actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification from the authors on this matter. While the comment does not explicitly instruct the authors to provide clarification, it implies that they should address the question by elaborating on the abstention process. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the issue. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the basis of the abstention process, whether it is based on a prediction probability threshold or a decision threshold, and requests clarification on this point. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the abstention process used in the paper, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification on this point, which is a relevant and important aspect of the methodology that could impact the interpretation of results. However, the comment does not provide any suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency for COCO-LM and implies that the conclusion might be applicable to these other approaches as well. The comment also includes a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. While the comment raises important points and questions, it does not provide explicit instructions or detailed guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide a rationale for the experimental setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Megatron\" and \"COCO-LM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the overrating of the comparison with Megatron and pointing out that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. Additionally, it raises a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with Megatron is overrated and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This claim is somewhat verifiable as it provides a logical comparison with other models of similar size, which supports the argument that the performance of Megatron and COCO-LM is not significantly different. However, the comment lacks specific references or detailed comparisons to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the similarities and differences between these models to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency for COCO-LM and implies that the conclusion might be applicable to these other approaches as well. Additionally, the comment includes a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. This feedback is somewhat helpful as it identifies a potential issue with the comparison and provides a question that prompts the authors to consider the impact of their experimental choices. However, the comment could be more helpful if it offered suggestions on how to address the overrated comparison or provided more detailed guidance on the experimental setup. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the analysis from line 128 to 149, specifically questioning the reasoning behind the observation that GS-P-50 has smaller class selectivity scores compared to ResNet-50. The reviewer suggests that the authors should provide a reason for this observation indicating that GS-P-50 learns better representations. The comment references two external works to support the claim, which provides some context but does not explicitly instruct the authors on how to address the issue. While the authors can infer that they need to provide a justification for their observation, the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (128-149) and references Figure 3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasoning behind the observation that GS-P-50 has smaller class selectivity scores compared to ResNet-50. The comment provides a hypothesis and suggests that additional context may allow the network to reduce its dependency. However, it lacks specific guidance on how the authors should address this issue or improve their analysis. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the analysis from line 128 to 149, specifically the observation that GS-P-50 has smaller class selectivity scores compared to ResNet-50. The reviewer provides a hypothesis that additional context may allow the network to reduce its dependency, but this is not substantiated with specific evidence or references. The comment references two external works, but these are not directly related to the specific claim being made. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors would need to further develop the argument to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, specifically questioning the reasoning behind the observation that GS-P-50 has smaller class selectivity scores compared to ResNet-50. It suggests that the authors should provide a reason for this observation, indicating that GS-P-50 may learn better representations. The comment references two external works to support the claim, which provides some context but does not fully explain how these references relate to the issue at hand. While the comment highlights a potential weakness in the analysis, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their reasoning. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but does not provide comprehensive feedback or actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the conclusions being unconvincing and suggests that the results might be due to limited exploration of combination methods. It provides specific examples of works that have shown potential in rehearsal-free continual learning, such as [R1], [R2], and [R3]. While the comment implies that the authors should consider these works and their methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these works further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, such as the claim about continuous learning with unlabeled data accumulating noise. It also references specific works, such as [R1], [R2], and [R3], which provide examples of methods that have shown potential in rehearsal-free continual learning. This allows the authors to accurately identify the parts of the paper being addressed and the specific issues raised. The comment is also specific because it provides examples of works that could be considered for comparison or improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some conclusions are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. The reviewer provides examples of works, such as [R1], [R2], and [R3], that have shown potential in rehearsal-free continual learning and feature-replay methods. This provides some support for the claim by referencing relevant literature, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or explanations of how these works relate to the paper\\'s conclusions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s conclusions, suggesting that they are not convincing. It provides a detailed example of a claim that is questioned, specifically regarding continuous learning with unlabeled data accumulating noise. The comment also references relevant works, such as [R1], [R2], and [R3], which have shown potential in rehearsal-free continual learning and feature-replay methods. This provides the authors with a clear direction for improving their work by considering these methods and their potential impact on the paper\\'s conclusions. The feedback is actionable and constructive, making it highly helpful for the authors to enhance the validity and credibility of their findings. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare with a chain-of-thought prompting approach, providing a concrete example of a more meaningful baseline. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their comparisons by including a specific alternative. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking meaningful baselines and suggests a comparison with a chain-of-thought prompting approach. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests comparing with a chain-of-thought prompting approach as a more meaningful baseline. This claim is somewhat verifiable as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how the current baselines are insufficient. The suggestion for a chain-of-thought prompting approach is a logical next step, but the comment could be strengthened by explaining why the current baselines are inadequate or how the chain-of-thought approach would provide a more meaningful comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that the authors limit their comparisons to simple naive baselines, suggesting that this limits the paper\\'s contribution. The comment provides a specific suggestion for improvement by recommending a comparison with a chain-of-thought prompting approach, which could offer a more meaningful baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance the depth and relevance of their comparisons. However, it could be more helpful if it included additional suggestions or examples of other potential baselines to consider. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement that could significantly enhance the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should clarify this aspect in their paper. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the pretraining process for the cardiac signal representation learning model, specifically asking whether it is trained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in its inquiry about the pretraining process and generalization, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the pretraining process for the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. This feedback is valuable as it prompts the authors to clarify a critical aspect of their methodology, which could impact the robustness and applicability of their model. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of best practices in similar contexts. Overall, the comment is somewhat helpful as it identifies a gap in the paper and encourages the authors to provide additional information, but it could be more comprehensive with further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks specific guidance on how to address this issue or what changes should be made to improve the draft. Without actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper this applies to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding which observations or design decisions are hardware or software dependent, leaving the authors without clear guidance on what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. This is a relevant observation that could impact the generalizability and applicability of the findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or mitigate its impact. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential concern but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide explicit instructions or suggestions for the authors to address these questions or improve their draft. The authors are left to infer that they might need to provide additional information or analysis to clarify these points, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not specify which part of the paper these questions pertain to, such as which sections or tables discuss the ground truth or the ablation study. Without explicit references, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions: one about the accuracy of the ground truth and the other about the differences in the results of the ablation study. Neither question contains a claim or opinion that requires verification. They are factual inquiries seeking clarification or additional information. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. By questioning whether the ground truth is sufficiently accurate to detect small differences and whether the differences are due to noise or randomness in the training process, the reviewer prompts the authors to consider the reliability of their findings. This feedback is somewhat helpful as it highlights potential areas for clarification or improvement in the paper. However, it lacks specific suggestions or guidance on how the authors might address these questions, such as recommending additional analyses or experiments. Therefore, the comment provides some insight but does not fully support the authors in improving their draft, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of important experimental details and explanations in the main text, particularly regarding PCA experiments in Figures 3, 7, and 8. It suggests that these details are relegated to the Appendix, which also lacks explanations or interpretations. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations and move them from the Appendix to the main text, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of missing experimental details and explanations, particularly in the context of PCA experiments. The comment provides clear guidance on what needs to be addressed, such as including explanations and interpretations in the main text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained. This claim is somewhat verifiable as it provides specific examples of missing details, but it lacks detailed reasoning or references to support the assertion that all experimental details are missing or inadequately explained. The comment suggests that the authors should provide more detailed explanations in the main text, but it does not fully substantiate the claim with specific examples or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed explanations and interpretations in the main text. By addressing these issues, the authors can significantly improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to integrate these details into the main text or offered examples of how to effectively explain the PCA experiments. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section should include an in-depth exploration of the reasons for the experimental results. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the in-depth exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics in the experimental analysis section. It suggests that there should be an in-depth exploration of the reasons for the experimental results. However, it does not specify which part of the experimental analysis section needs this exploration, making it weakly grounded. The comment is specific in its request for an in-depth exploration, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It further suggests that the experimental analysis section lacks an in-depth exploration of the reasons for the results. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the specific issues from the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an in-depth exploration of the reasons for the results. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by introducing novel evaluation metrics or providing a more comprehensive analysis of the experimental results. However, the comment could be more helpful if it offered specific suggestions on how to introduce new metrics or conduct the in-depth exploration. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the notation should be changed, clarified, or if there is a better way to differentiate between these two uses. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (L166 and L176) where the notation \"K\" is used for different purposes. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, namely its misuse for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the notation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"K\" is abused, as it is used for both a known kernel function and the number of layers. This claim is somewhat verifiable as it highlights a potential issue with notation consistency. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more detailed examples or context would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion in the paper. By pointing out this inconsistency, the comment provides the authors with a specific area to address and clarify, which can significantly improve the clarity and readability of their draft. However, the comment could be more helpful if it suggested alternative notations or provided guidance on how to differentiate between these two uses of \"K.\" Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the weak recovery problem studied, suggesting that it may not have practical impact due to the AMP algorithm\\'s applicability to non-Gaussian problems. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to address the concern about practical impact or improve the applicability of the AMP algorithm. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practical impact of the weak recovery problem studied in the paper, specifically questioning the usefulness of the AMP algorithm for non-Gaussian problems. However, it does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not provide detailed guidance on how to address the concern about practical impact. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for non-Gaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practical impact of the weak recovery problem studied, suggesting that it may be of limited interest due to the AMP algorithm\\'s applicability to non-Gaussian problems. While the comment identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the practical relevance of their work. The feedback lacks actionable details, leaving the authors with a general understanding of the issue but without clear steps to improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\\' statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify the relevance of human cognition in their study. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the relevance of bringing connections to human cognition into the study, particularly in light of the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. It questions the authors\\' statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relevance of human cognition and the need for more citation for comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of bringing connections to human cognition into the study, given the reductionist nature of the problem. It challenges the authors\\' statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. The comment provides a logical reasoning by pointing out the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation, which are typically associated with human cognition. However, it lacks specific references or examples to support the claim fully, making it somewhat verifiable. The authors would need to provide additional context or references to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given the reductionist nature of the problem. It questions the authors\\' statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. The comment also points out the need for more citation for comparison against \"previously appreciated\" insights. While the comment identifies a potential issue and provides some direction for improvement, it lacks specific suggestions or detailed guidance on how the authors might address this concern. The feedback is somewhat helpful as it prompts the authors to reconsider the relevance of human cognition in their study and to provide more context or references, but it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific suggestions or guidance on how to revise the wording or tone. The action is implicit, as the authors can infer that they need to tone down the language, but it lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies an issue but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of overly exaggerated wording and provides a concrete example of the problematic phrase, \"our pioneering contributions herald a new era in robotic adaptability.\" This specificity helps the authors understand what needs to be addressed in the conclusion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without detailed evidence or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it points out a potential weakness in the paper\\'s presentation and suggests a need for more modest language. However, the comment could be more helpful if it provided examples of specific phrases or sections that need revision or offered suggestions for alternative wording. Despite this, the comment still provides valuable insight into how the authors can improve the clarity and impact of their conclusions. Therefore, it is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is highly actionable as it offers concrete guidance on how to enhance the paper by conducting additional experiments.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for ablation experiments and the comparison criteria, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This is a request for additional analysis, not a claim or opinion that requires verification. The comment is factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to improve their draft. It explicitly instructs them to perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is valuable as it guides the authors on how to enhance their work by providing a specific and measurable comparison. However, the comment could be more helpful if it included additional context or rationale for why this comparison is important or how it might impact the paper\\'s contributions. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback implies that the authors should include such comparisons to demonstrate the effectiveness of their proposed approach. However, the comment does not provide specific guidance on which baselines to consider or how to conduct the comparison. While the action is clear\u2014adding comparisons to demonstrate effectiveness\u2014the lack of concrete details on how to implement this makes the comment somewhat actionable. The authors know they need to compare to baselines but may struggle with the specifics of which ones to choose and how to conduct the comparison.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Additionally, while it mentions \"writing style and other issues,\" it does not elaborate on what these issues are or how they could be addressed. As a result, the comment is not grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific, as it lacks detailed guidance on what needs to be improved. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s biggest weakness is the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would improve the paper. Without specific references or detailed explanations, the claim remains unverifiable, as the authors are left without a clear understanding of why this comparison is crucial. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that it lacks a comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback highlights a critical gap in the paper\\'s evaluation, which is essential for demonstrating the effectiveness of the proposed approach. However, the comment does not provide specific suggestions on which baselines to consider or how to conduct the comparison, leaving the authors with a general direction but without detailed guidance. While it points out a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a key weakness but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a mix of explicit and implicit actions. It explicitly asks for more explanations regarding Figure 5a and how the authors dealt with DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as reference [15] did, which is an implicit action. However, the comment does not specify how to provide more explanations or how to analyze energy consumption, leaving some aspects vague. Overall, the comment is mostly actionable as it clearly identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 5a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing more explanations and analyzing energy consumption as reference [15] did. This level of detail provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions. The first claim about \"11\" being wonderful is not verifiable as it lacks supporting evidence or context. The second claim about Figure 5a being strange is not supported by any reasoning or examples, making it difficult for the authors to understand the basis of the critique. The suggestion to analyze energy consumption as reference [15] did is somewhat verifiable, as it provides a direction but lacks specific details or examples. Overall, the comment is a mix of unverifiable and somewhat verifiable claims, justifying a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides some helpful feedback by acknowledging the strength of \"11\" and suggesting that the authors consider other bit operations. It also points out a potential issue with Figure 5a, suggesting that more explanations are needed. Additionally, the comment raises a question about how the authors dealt with DVS input when the input is in aer format. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how other papers have handled similar situations. The feedback is somewhat helpful as it identifies areas for improvement but lacks detailed guidance or actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a gap in the explanation and suggests the need for clarification, it does not provide explicit instructions on how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the combination of embeddings and their use in the CSCM. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"historical observations\" and \"inputs known over all time,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how these observations are combined, given differences in sequence lengths, and requests clarification on how embeddings are combined and fed into the CSCM. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a gap in the explanation, it does not provide specific reasoning or examples to support the claim that further clarification is needed. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the necessity of additional explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embedding and addition with positional encoding but lacks clarification on how these embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations on this aspect of their methodology. By addressing this gap, the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of similar approaches. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the paper\\'s contribution by pointing out that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. However, the comment does not provide any actionable advice or suggestions for the authors to address these concerns or improve their work. It lacks explicit guidance on how the authors might enhance the novelty or originality of their contribution or how they could better differentiate their work from existing approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper\\'s contribution by pointing out that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some specific critique about the lack of novelty, it lacks detailed guidance on how the authors might address these concerns. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the novelty of the paper\\'s contribution by pointing out that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. However, the comment lacks specific examples or references to support the claim about the commonality of the approach or the capabilities of MLMs. This makes the claim somewhat verifiable, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper\\'s contribution by pointing out that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. While the comment identifies a potential weakness in the paper\\'s originality, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it prompts the authors to consider the originality of their contribution, but it does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and that their values are not specified in the paper. This provides a clear action for the authors to take, which is to discuss the sensitivity of these hyper-parameters and specify their values. The comment is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hyper-parameters $m_1$, $m_2$, and $\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion of the sensitivity of these hyper-parameters and the lack of specification of their values. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed, and their values are not specified in the paper. This is a factual statement that describes an omission in the paper, rather than an opinion or suggestion. It does not require verification or justification, as it is a straightforward observation of what is missing from the paper. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth and clarity, namely the discussion of the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$. It points out that these parameters are not specified in the paper, which is a critical omission that could impact the reproducibility and understanding of the results. By highlighting this gap, the comment provides the authors with a clear direction for improvement, encouraging them to include a discussion on the sensitivity of these hyper-parameters and their values. This feedback is actionable and constructive, making it mostly helpful. However, it could be more helpful if it suggested specific ways to address this issue, such as providing guidance on how to present the sensitivity analysis or discuss the impact of these parameters on the results. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these experiments or what specific aspects to focus on. The authors can infer that they need to conduct additional experiments, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and its impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarity-aware positive sample selection or where the experiments on transfer performance are presented. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might infer that it relates to the experimental sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting additional experiments, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and its impact on generalization performance. The reviewer suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not allay the reviewer\\'s concerns. This makes the claim somewhat verifiable, as it provides a logical basis for the concern but lacks sufficient evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and its impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies a potential issue and provides a direction for further experimentation, it lacks specific guidance on how to conduct these experiments or what aspects to focus on. The feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more discussion on the power of different architectures, but without clear grounding, the authors may struggle to determine where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. The comment does not offer detailed feedback or examples of what additional discussion could include, leaving the authors with a general idea of what might be lacking but without a clear path to improvement. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that evaluating the methods across different splits of train-val-test, rather than just different initialisation seeds, would lead to more robust results. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that evaluating the methods across different splits of train-val-test, rather than just different initialisation seeds, would lead to more robust results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting an alternative approach for obtaining robust results, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating the methods across different splits of train-val-test, rather than just different initialisation seeds, would lead to more robust results. The comment provides a logical reasoning for why this approach would be beneficial, as it addresses potential issues with overfitting or bias due to specific initialisation seeds. However, it does not provide specific examples or references to support this claim, which would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that evaluating the methods across different splits of train-val-test, rather than just different initialisation seeds, would lead to more robust results. This feedback is clear and actionable, as it provides a specific suggestion for improving the robustness of the experimental setup. By highlighting this potential enhancement, the comment offers the authors a concrete way to strengthen their methodology and potentially improve the validity of their results. However, the comment could be more helpful if it provided additional context or examples of how this approach might be implemented. Overall, the comment is mostly helpful, as it offers valuable guidance for enhancing the robustness of the study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the first two bullets about contributions in the introduction can be combined. However, it does not provide any explicit guidance or reasoning on why these bullets should be combined or how this would improve the clarity or structure of the introduction. The action is implicit and lacks concrete details on how to implement the suggestion, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions (at the end of the intro),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests combining these two bullets, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the first two bullets about contributions in the introduction can be combined. However, it does not provide any reasoning or justification for why this combination would be beneficial or how it would improve the clarity or structure of the introduction. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the first two bullets about contributions in the introduction can be combined, which could improve the clarity and coherence of the section. However, it lacks specific reasoning or examples to support why this combination would be beneficial or how it would enhance the reader\\'s understanding. Without additional context or guidance, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it identifies a potential improvement but does not provide enough detail or rationale to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve clarity. The action is implicit, as the authors can infer that they need to clarify these aspects, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references, the authors may find it challenging to pinpoint the exact areas needing clarification. The comment is specific in identifying the issue but lacks grounding, as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the types of situations or social norms (e.g., physical and psychological safety) are not clear in the main paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the types of situations or social norms discussed in the main paper, particularly mentioning physical and psychological safety. This feedback is somewhat helpful as it points out a potential weakness in the paper that could benefit from further clarification. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending specific sections to revise or examples to include. While it highlights an area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the paper\\'s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\\'s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottom-up methods. While the comment implies that the authors should refer to recent trends in the vision community, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these references or demonstrate the improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the paper\\'s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\\'s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottom-up methods. However, the comment does not specify which part of the paper this feedback pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting what needs to be addressed, such as demonstrating improvements over existing solutions and robustness against weak boundaries. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the paper\\'s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\\'s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottom-up methods. The comment provides a logical reasoning by highlighting the importance of these aspects for the paper\\'s contribution. However, it lacks specific references or examples to support the claim, making it somewhat verifiable. The authors would need to provide additional evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the paper\\'s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\\'s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottom-up methods. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific examples or references to recent trends in the vision community that the authors could consider. Overall, the feedback is actionable but incomplete, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the inclusion of more baselines and testing in more domains, suggesting that the current choices of weighting and learning density functions are not strongly motivated. It also asks for stronger empirical results by comparing baselines with different design choices and testing in more domains. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and comparisons. The explicit nature of the request and the detailed guidance on what needs to be done make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more baselines should be compared and more domains tested, and it questions the motivation behind the choices of weighting and learning density functions. However, it does not specify which parts of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in its request for stronger empirical results, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more baselines should be compared and more domains tested, and it questions the motivation behind the choices of weighting and learning density functions. The reviewer provides a logical reasoning by asking for stronger empirical results, which implies that the current results are not sufficiently robust. However, the comment lacks specific examples or references to support the claim that other design choices or domains should be tested. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of motivation for the choices of weighting and the way of learning density functions, suggesting that more baselines and domains should be tested to strengthen the empirical results. It provides a clear and actionable suggestion for improvement by asking for stronger empirical evidence through comparisons with other design choices and testing in more domains. This feedback is specific and constructive, offering the authors a clear path to enhance the robustness and validity of their work. However, it could be more helpful if it included specific examples or references to guide the authors in selecting appropriate baselines or domains. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the dashed lines in specific figures, providing a clear and direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions specific figures (2A-B and 4B), allowing the authors to accurately identify the parts of the paper being addressed. It clearly specifies what needs to be defined, which are the dashed lines in these figures. This provides full grounding and specificity, making this comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to define the dashed lines in specific figures. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, requesting the authors to define the dashed lines in specific figures. This feedback is actionable and provides a direct way for the authors to improve their draft by clarifying an aspect that may be unclear to readers. However, the comment could be more helpful if it provided context or explained why these definitions are important. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement that can enhance the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results comparable or what specific changes should be made to enhance the significance of the proposed methods. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not specify which results or methods are being compared, making it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of the results or methods are not comparable or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods lack significance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific comparisons or references to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance the significance of their work. Therefore, the comment is not helpful at all, as it does not offer any constructive direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies areas where the paper could be improved, it does not provide explicit guidance on how to address these issues or specific suggestions for enhancing the novelty or insights. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete steps or examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically mentioning the application of existing literature, such as DeCorr, in a specific domain. It highlights the contribution as the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the introduction and discussion sections, where the novelty and contributions of the paper are typically discussed. The comment is specific in detailing what aspects are lacking in terms of novelty and insights. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, stating that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The comment provides some justification by mentioning the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. However, it lacks specific examples or detailed reasoning to fully substantiate the claim of limited novelty. The mention of modifications like different penalty coefficients for users and items is a minor detail that does not significantly support the claim. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks comprehensive evidence or detailed examples to fully substantiate the claim of limited novelty.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it prompts the authors to consider the uniqueness of their contribution, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or clarify the symbols. The action is implicit, as the authors need to infer that they should clarify the symbols and address the question about redundancy and interference. The feedback is somewhat vague, as it lacks specific instructions on how to improve the figure or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that some symbols are not explained clearly, which provides clear guidance on what needs to be addressed. Additionally, the comment raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process, further specifying the areas that need clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the ambiguity of Figure 2 due to unclear symbols and questions whether there is information redundancy and interference in the multi-sphere icosahedral discretization process. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the specific problems and their potential solutions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. This feedback is valuable as it directs the authors to clarify the symbols in the figure, which could enhance the understanding of the content. Additionally, the comment raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process, prompting the authors to consider and address these issues. However, the comment could be more helpful if it provided specific suggestions on how to clarify the symbols or addressed the question about redundancy and interference. Overall, the feedback is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It notes that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to include Matern kernels in their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their analysis to include other kernel types. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications for the results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is sub-gaussian. It provides a logical reasoning by explaining that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It explains that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. This feedback is valuable as it highlights a potential restriction in the paper\\'s scope and suggests that the authors should consider including other kernel types in their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or expand the analysis to include Matern kernels. Overall, the comment is somewhat helpful as it points out a significant limitation but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the data in Table 4, which indicates the importance of unsupervised pretraining, and the lack of detailed discussion on this topic in the main paper. The reviewer suggests focusing more on the pretraining method in the main paper, implying that the authors should provide a more in-depth analysis of this aspect. While the comment explicitly states the need for more focus on pretraining, it does not provide specific guidance on how to achieve this or what aspects of the pretraining method should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the pretraining method but may not be entirely sure of the specific details to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the main paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining, which is a key factor in the performance gain, as indicated by the data in Table 4. The comment further suggests focusing more on the pretraining method in the main paper, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by the data in Table 4. However, it notes that there is no detailed discussion on this in the main paper, which could be a problem. The reviewer suggests focusing more on the pretraining method in the main paper. While the claim is based on the data in Table 4, it lacks specific examples or detailed reasoning to fully substantiate the importance of the pretraining method. The comment provides a logical basis for the claim but could be strengthened with more detailed evidence or references. Therefore, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting that the unsupervised pretraining, which is a key factor in performance gain, is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, which is a valuable insight for improving the draft. The comment is clear and actionable, providing a specific area for the authors to address and enhance their work. However, it could be more helpful if it offered suggestions on how to structure or present the discussion on pretraining. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of ELM (male/female) and whether it requires knowledge of the speaker\\'s gender beforehand. It also suggests that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the choice of ELM and its implications for accuracy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the choice of ELM and its implications for accuracy. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. The comment provides a logical reasoning by questioning the need for prior knowledge of the speaker\\'s gender and highlighting a potential drawback in the methodology. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of ELM (male/female) and its implications for accuracy. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which could be a drawback if the speaker\\'s gender is required for inference. This feedback is clear and actionable, as it prompts the authors to consider the implications of their choice of ELM and how it might affect the accuracy of their model. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how other researchers have handled similar challenges. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their methodology that requires further consideration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing is difficult to follow in many places and suggests simplification. However, it does not provide specific examples or guidance on how to simplify the writing, nor does it specify which parts of the paper are particularly challenging. The action is implicit and vague, as the authors are left to infer that they need to simplify the writing but without concrete steps or examples to guide them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the writing is difficult to follow in many places and suggests simplification. However, it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This lack of specificity and grounding makes it difficult for the authors to identify and address the issues effectively. The comment is not grounded as it does not point to specific sections or elements of the paper, and it is not specific because it lacks detailed guidance on what needs to be simplified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is difficult to follow in many places and suggests simplification. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it could be simplified. However, it lacks specificity and does not provide detailed guidance or examples of where the writing is unclear or how it could be simplified. Without actionable feedback or suggestions for improvement, the authors are left with a vague understanding of what needs to be addressed. This limits the comment\\'s usefulness, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the technical substance or what specific changes could be made to add more value to the paper. As a result, the comment lacks actionability, leaving the authors without any direction on how to address the feedback. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, it does not specify which part of the paper this critique is based on, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or lacking in technical substance. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, it does not provide any specific examples or detailed feedback on how the paper could be improved or what aspects are considered incremental. Without actionable suggestions or constructive criticism, the authors are left without a clear understanding of how to address the feedback or enhance their draft. Therefore, the comment is not helpful at all, as it does not offer any guidance for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide an intuition for the proof of Theorem 1 and asks questions about the invertible function $f^*$ and its dependence on the fixed $P^*$. It also inquires about the practical implications of determining which $P^*$ to fix. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide additional explanations and address the questions raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and suggestions for improvement, such as requesting an intuition for the proof of Theorem 1 and asking about the dependence of the invertible function $f^*$ on the fixed $P^*$. The comment also inquires about the practical implications of determining which $P^*$ to fix. This level of detail and specificity helps the authors understand what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and suggestions for clarification, such as requesting an intuition for the proof of Theorem 1 and asking about the dependence of the invertible function $f^*$ on the fixed $P^*$. It also inquires about the practical implications of determining which $P^*$ to fix. These are not claims or opinions that require verification, but rather requests for additional information or clarification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include an intuition for the proof of Theorem 1, which would enhance the reader\\'s understanding of the theoretical foundation. It also raises questions about the dependence of the invertible function $f^*$ on the fixed $P^*$ and the practical implications of determining which $P^*$ to fix. These questions prompt the authors to consider additional aspects of their work that could be clarified or expanded upon. While the comment is clear and offers valuable insights, it could be more helpful if it provided specific suggestions on how to address these questions or enhance the intuition. Overall, the feedback is mostly helpful as it directs the authors to areas that could benefit from further explanation or elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inconsistency in the use of variables in equations (7) and (10), specifically questioning why one uses \"X\" and the other \"H^(1).\" While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this inconsistency. The authors are left to infer that they need to clarify the rationale behind the variable choices or potentially revise the equations to make them more consistent. However, the lack of explicit instructions or concrete steps makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by questioning the inconsistency in the use of variables \"X\" and \"H^(1)\" in these equations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inconsistency in the use of variables in equations (7) and (10), specifically noting that one uses \"X\" and the other \"H^(1).\" This is a factual observation that does not contain an opinion, judgment, or suggestion requiring verification. It is a request for clarification, which is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the inconsistency in the use of variables in equations (7) and (10), noting that one uses \"X\" and the other \"H^(1).\" This is a clear and actionable feedback that prompts the authors to clarify the rationale behind these variable choices. By addressing this inconsistency, the authors can improve the clarity and consistency of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or offered additional context on why this inconsistency might be important. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks depth in terms of guidance or explanation. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the applicability of the model to real-world diffusion processes. It suggests that the authors provide empirical evidence to demonstrate that the proposed model captures the diffusion phenomena in real-world scenarios. While the comment implies that the authors should conduct empirical studies to validate the model\\'s applicability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the empirical studies or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of the model to real-world diffusion processes. It suggests that the authors provide empirical evidence to demonstrate the model\\'s ability to capture diffusion phenomena in real-world scenarios. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its request for empirical evidence, it is not grounded because it does not identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the model to real-world diffusion processes. It suggests that the authors provide empirical evidence to demonstrate the model\\'s ability to capture diffusion phenomena in real-world scenarios. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the model is not applicable. Without such evidence or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical concern regarding the applicability of the model to real-world diffusion processes. It highlights the need for empirical evidence to validate the model\\'s ability to capture diffusion phenomena in real-world scenarios. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address by conducting empirical studies or providing additional evidence. However, the comment could be more helpful if it offered suggestions on how to conduct these empirical studies or what specific aspects of the model should be tested. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancing the validity and applicability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should test their method on more datasets to get a better understanding of its performance. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify which datasets should be used or how the results should be analyzed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method should be tested on more datasets to better understand its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding which datasets should be considered or how the results should be analyzed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the method should be tested on more datasets to better understand its performance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why testing on additional datasets is necessary or beneficial. Without such support, the claim remains unverifiable, as the authors may not be convinced of the need for additional testing. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should test their method on more datasets to better understand its performance. While this feedback identifies a potential area for improvement, it lacks specificity and actionable guidance. The comment does not provide suggestions on which additional datasets to consider, how to analyze the results, or why testing on more datasets would be beneficial. Without these details, the authors are left with a general idea of what to do but without a clear path to implementation. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues in Section 4.2: the lack of clarity regarding how the question is used to learn an attention on the image feature, and the ambiguity surrounding the term \\\\sigma\\\\ in the equation. The reviewer suggests clarifying these points by explaining the role of \\\\r^q\\\\ in the equation and specifying whether \\\\sigma\\\\ represents the sigmoid activation. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft by addressing these issues. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in Section 4.2, particularly the absence of \\\\r^q\\\\ in the equation and the ambiguity surrounding \\\\sigma\\\\. The comment provides clear guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the description in Section 4.2, specifically questioning how the question is used to learn an attention on the image feature and the role of \\\\sigma\\\\ in the equation. The reviewer suggests that the equation does not include a term for \\\\r^q\\\\, which is the question representation, and that multiplying two sigmoid activations might be ill-conditioned. While the comment identifies specific areas of confusion, it lacks detailed reasoning or references to support the claim. The authors would need to infer the basis of the concerns and address them themselves. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and accuracy of the description in Section 4.2, particularly regarding the use of the question to learn an attention on the image feature and the role of \\\\sigma\\\\ in the equation. It points out that the description does not match the equation, as the equation does not include a term for \\\\r^q\\\\, which is the question representation. Additionally, it questions the meaning of \\\\sigma\\\\ in the equation and suggests that multiplying two sigmoid activations might be ill-conditioned. This feedback is clear and actionable, as it provides specific areas for clarification and improvement, such as explaining the role of \\\\r^q\\\\ and specifying the meaning of \\\\sigma\\\\. By addressing these points, the authors can enhance the clarity and accuracy of their work. Therefore, the comment is rated as mostly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of non-novelty or what specific alternatives should be considered. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the main contribution of combining attention with other linear mechanisms, noting that it is not novel and that alternatives exist. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the contribution are not novel or which alternatives are being referred to. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, and it references the paper itself, noting that \"a lot of alternatives exist.\" However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references leaves the claim somewhat verifiable, as it requires more information to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as noted in the paper itself. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their contribution. Without actionable feedback or constructive advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a plot of how different weights of the model move after unlearning, specifically to see which layers are affected the most. This is a clear and direct action that the authors can follow to improve their draft. The comment provides a specific and concrete suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the need for a plot showing how different weights of the model move after unlearning, particularly to see which layers are affected the most. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot showing how different weights of the model move after unlearning, specifically to see which layers are affected the most. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, the comment is factual and does not contain a claim, aligning with the label \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing how different weights of the model move after unlearning, particularly to see which layers are affected the most. This feedback is clear and offers a concrete way for the authors to enhance their analysis and presentation of results. By following this advice, the authors can provide a more comprehensive understanding of the model's behavior and potentially identify areas for further exploration. However, the comment could be more helpful if it explained why this analysis is important or how it might impact the interpretation of the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this critique. It lacks guidance on how the authors might address the perceived lack of novelty or improve their contribution. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper these aspects are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not detail what aspects of the ENCODE part or the decomposition part are problematic or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment does not provide any references or detailed reasoning to support this claim, such as comparing the proposed method to the existing work in [10] or explaining how the decomposition part differs from previous approaches. Without specific evidence or detailed analysis, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While the comment implies that the authors should clarify this information, it does not provide explicit guidance on how to address the issue or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the domain of the inputs. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the domain of the inputs, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While this question identifies a potential gap in the paper, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment does not offer suggestions for clarifying the domain of the inputs or how this information could be integrated into the paper. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by [A]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether a comparison is necessary, how it should be conducted, or what specific aspects should be considered. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by [A]. However, it does not specify which part of the paper discusses this algorithm or where the performance comparison should be included. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in asking for a performance comparison but does not provide detailed guidance on how to conduct it or what aspects to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for a performance comparison with the CLN (region proposal generation algorithm) proposed by [A]. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by [A]. While it identifies a potential area for improvement by suggesting a performance comparison, it lacks specificity and does not provide guidance on how to conduct such a comparison or what aspects to focus on. The comment is somewhat helpful as it points out a gap in the paper but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the presentation is too equation-driven and that the notation in Chapter 3 is convoluted and hard to follow. It recommends including an illustrative figure of key concepts in Section 3 to improve clarity. While the comment identifies specific issues and provides a clear suggestion for improvement, it does not specify which equations or notation are particularly problematic or how to create the illustrative figure. The action is explicit but somewhat vague, as the authors know they need to improve the presentation and include an illustrative figure but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific feedback about the presentation being too equation-driven and the notation being convoluted, particularly in Chapter 3. It suggests that an illustrative figure of key concepts in Section 3 would be helpful. This feedback is specific and provides a clear direction for improvement. However, it does not explicitly mention which part of the paper the notation issue is discussed in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. The reviewer suggests that an illustrative figure of key concepts in Section 3 would be helpful. However, the comment lacks specific examples or detailed reasoning to support the claim that the notation is particularly problematic. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the paper, noting that it is too equation-driven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure of key concepts in Section 3 would be helpful to improve clarity. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the paper\\'s readability and accessibility. However, it could be more helpful if it offered additional guidance on which equations or concepts should be illustrated or how to create the figure. Overall, the comment is mostly helpful as it directs the authors toward a concrete improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It suggests that taking Z\\' in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is explicit and provides a clear action for the authors to take: investigate and resolve the apparent contradiction between the second rule and the definition of minimal conditional dependence. The comment is highly actionable as it specifies the exact issue and guides the authors on how to address it.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule and the definition of minimal conditional dependence. The comment provides a specific example by suggesting that taking Z\\' in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. The reviewer provides a logical reasoning by suggesting that taking Z\\' in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This reasoning is clear and provides a specific example to support the claim, making it mostly verifiable. However, the comment could be strengthened by referencing relevant literature or providing more detailed explanations of the conflict. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It provides a specific example by suggesting that taking Z\\' in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is clear and actionable, as it directs the authors to investigate and resolve the apparent contradiction. By pointing out this specific issue, the comment offers a concrete way for the authors to improve their draft, making it highly helpful. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, it does not provide explicit guidance on how to enhance the visual presentation or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the visual presentation but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular aspect of the visual presentation, namely the subscripts, and suggests that they could be improved for better readability and aesthetic appeal. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be improved for better readability and aesthetic appeal. This feedback is somewhat helpful as it points out a potential area for enhancement, which could improve the overall clarity and impact of the figure. However, the comment lacks depth and does not provide specific suggestions or examples of how the subscripts could be improved, leaving the authors with a general direction but without detailed guidance on execution. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest any changes or improvements to the draft, nor does it offer guidance on how the authors might clarify the issue or address the confusion. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the bias and lack of clarity regarding the two normalization methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. The reviewer acknowledges having read other reviews and the author\\'s response, but the comment does not provide any additional reasoning, evidence, or references to support the claim that Online Normalization is unbiased and Batch Normalization is biased. Without further explanation or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. It acknowledges having read other reviews and the author\\'s response but expresses confusion about why Online Normalization is considered unbiased while Batch Normalization is biased. However, the comment does not provide any actionable feedback or suggestions for the authors to clarify or address this confusion in their draft. Without specific guidance or recommendations, the comment offers limited value to the authors in terms of improving their work. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It further suggests that this is grounds for rejection because it effectively violates the 9-page paper limit. The comment provides a clear and direct action for the authors to address, which is to increase the whitespace in their paper to comply with the page limit. The feedback is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of reduced whitespace, crammed equations, and captions too close to figures, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the problem of violating the 9-page paper limit due to these formatting issues. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9-page paper limit. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the problem or how it violates the page limit. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary justification or specificity to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9-page paper limit. While the comment highlights a critical issue, it does not provide actionable suggestions on how to address the problem or improve the formatting. The feedback is clear in its observation but lacks depth and guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion on how to better highlight the scheme or procedure novelty. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"technical details and formulations\" as being limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not specify which parts of the paper these details are lacking in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited technical details and formulations, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance these details or highlight the novelty more effectively. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the clarity of the concept of \"local interactions,\" asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this concept. The action is implicit, as the authors need to infer that they should provide additional explanation or clarification to address the confusion. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the nature of local interactions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential area of confusion regarding the concept of \"local interactions,\" specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify their terminology or explanation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could include examples or suggestions for clarifying the concept, which would empower the authors to make more substantial improvements to their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors should address this issue, such as suggesting ways to improve the validity or diversity of the results or explaining the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning the validity and diversity of the proposed constrained method. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents better results in the Molecule generation experiment (Table 3), but it questions the validity and diversity of the proposed constrained method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. This is a relevant observation that could prompt the authors to reconsider their claims or provide additional analysis to support their results. However, the comment lacks specificity and does not offer actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or suggestions for improvement, the authors may find it challenging to effectively respond to this critique. Therefore, the comment is somewhat helpful, as it identifies a potential issue but does not provide enough detail to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the process of updating archetype positions after their initialisation in Algorithm 2. It explicitly requests the authors to provide a comment on this aspect, which is a clear and direct action. The comment provides a specific area of interest, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is highly actionable, as it gives the authors a clear direction on how to improve their draft by providing additional clarification.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the unclear process of updating archetype positions after initialisation. The comment requests clarification on this aspect, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the process of updating archetype positions after their initialisation in Algorithm 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which is consistent with the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of uncertainty in the paper regarding the process of updating archetype positions after their initialisation in Algorithm 2. It requests clarification on this aspect, which is a clear and actionable suggestion for the authors to address. By prompting the authors to provide additional information, the comment helps to improve the clarity and comprehensiveness of the paper. However, it could be more helpful if it provided some context or examples of how the update process might be explained. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies several areas where additional information is missing from the empirical study, such as recording parameters for MRI, preprocessing steps, resting-state recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These explicit requests provide clear actions for the authors to take, and the comment is specific about what information is needed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what information is missing, such as recording parameters for MRI, preprocessing steps, resting-state recording conditions, a brief explanation of the harmonization technique, and the number of regions in the parcellation. This level of detail provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions about the empirical study, such as the recording parameters for MRI, preprocessing steps, resting-state recording conditions, and the harmonization technique. These questions are factual and do not contain subjective claims or opinions that require verification. The comment is primarily seeking clarification and additional information, which is consistent with a factual statement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, resting-state recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These specific requests provide clear and actionable feedback that can help the authors improve the comprehensiveness and clarity of their study. By addressing these points, the authors can enhance the transparency and reproducibility of their work. Therefore, the comment is mostly helpful, as it offers detailed guidance on areas that need improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The reviewer recommends performing cross-dataset experiments to test the generalization of the work, which the paper currently lacks. While the comment identifies a specific issue and suggests a solution, it does not provide detailed guidance on how to implement the cross-dataset experiments or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors know what needs to be done but may need more detailed instructions to execute it effectively. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential risk of methods exploiting relationships between action units, particularly the variability in these relationships across datasets. The reviewer provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. Additionally, the comment recommends performing cross-dataset experiments to test the generalization of the work, which the paper currently lacks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. The reviewer provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment also recommends performing cross-dataset experiments to test the generalization of the work, which the paper currently lacks. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The reviewer recommends performing cross-dataset experiments to test the generalization of the work, which the paper currently lacks. This feedback is clear and actionable, as it highlights a specific area for improvement and suggests a concrete way to address it. By recommending cross-dataset experiments, the comment provides the authors with a clear path to enhance the robustness and generalizability of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more description of the Starcraft environment, possibly in an appendix. While the comment implies an action, it does not explicitly instruct the authors to add this description or specify where it should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more description and determine where it should be placed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting that additional information about the environment should be included, but it does not provide details on what aspects of the environment need more description. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning or examples to support why this additional description is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the need for this change. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper would benefit from more description of the Starcraft environment, potentially in an appendix. While it identifies a specific area for improvement, it lacks detailed guidance on what aspects of the environment should be described or how this additional information would enhance the paper. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more actionable with specific suggestions or examples of what should be included. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a contradiction between the statement in lines 47-48 and the observation that over-parameterization is beneficial for supervised learning of deep neural networks in practice. It also mentions theoretical works supporting the benefits of over-parametrization. However, the comment does not provide specific guidance on how the authors should address this contradiction or integrate the theoretical works into their paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconcile the conflicting statements and potentially include references to the theoretical works. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (47-48) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a contradiction between the statement about over-parametrization and the observation that it is beneficial for supervised learning. Additionally, the comment provides a reference to theoretical works supporting the benefits of over-parametrization, which further specifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a contradiction between the statement in lines 47-48 and the observation that over-parameterization is beneficial for supervised learning. It supports this claim by referencing theoretical works that demonstrate the benefits of over-parametrization. However, the comment does not provide specific references to these theoretical works, which would strengthen the verifiability of the claim. While the mention of theoretical works provides some support, the lack of detailed references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a contradiction in the paper regarding the statement that over-parametrization leads to worse performance, while also noting that over-parametrization is beneficial for supervised learning in practice. It provides a reference to theoretical works supporting the benefits of over-parametrization, which could help the authors reconcile this contradiction. However, the comment could be more helpful if it offered specific suggestions on how to address this contradiction or integrate the theoretical works into the paper. While it provides some insight, the feedback is somewhat vague and lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the time-consuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the high-order factor graph of the parsing model with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues or what aspects of processing efficiency should be described or compared. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"shape model\" and \"parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the time-consuming nature of the training process due to the pixel-level training of the shape model and the independent training on all font images and characters. Additionally, it suggests that the processing efficiency of training and testing should be described and compared with existing work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the shape model training is time-consuming due to its pixel-level training and independent training on all font images and characters. It also mentions the high-order factor graph of the parsing model with four types of factors. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas that could be improved in the paper. It points out the time-consuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the high-order factor graph of the parsing model with four types of factors, suggesting that the processing efficiency of training and testing should be described and compared with existing work. This feedback is clear and actionable, as it highlights specific aspects of the methodology that could be improved and provides a direction for further analysis. However, the comment could be more helpful if it included suggestions on how to optimize the training process or specific examples of existing work to compare with. Overall, the comment is mostly helpful, as it provides valuable insights for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of innovation in the paper, as it combines existing techniques without proposing new ones. It specifically mentions that the adversarial attack or correction method and the domain adaptation method used by the authors are already proposed by prior work. The comment suggests using other domain adaptation methods to improve performance, which is an implicit action. However, the comment does not provide specific guidance on which domain adaptation methods to consider or how to implement them. While the authors can infer that they need to explore alternative methods, the lack of concrete details makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the combination of existing techniques and the use of an old and simple domain adaptation method, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the lack of innovation and suggests using other domain adaptation methods to improve performance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors combine existing techniques without innovation, specifically mentioning the use of an old and simple domain adaptation method. The reviewer provides a logical reasoning by pointing out that there are many effective domain adaptation methods proposed in recent years, suggesting that the authors should consider using them to improve performance. This reasoning is supported by the reference to the age of the domain adaptation method used, which provides a basis for the claim. However, the comment could be strengthened by providing specific examples of more recent and effective domain adaptation methods, which would make it fully verifiable. Therefore, the comment is mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the authors combine existing techniques without innovation. It specifically points out that the domain adaptation method used is old and simple, suggesting that more recent and effective methods could be employed to improve performance. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the use of other domain adaptation methods. However, the comment could be more helpful if it offered examples of specific methods or provided guidance on how to integrate them into the framework. Despite this, the comment is mostly helpful as it directs the authors to a critical area that could enhance the novelty and effectiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a discussion on the prompt dataset creation and its source for the few-shot case. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area for enhancement, making it highly actionable. The authors know exactly what needs to be added to their draft, and the feedback is concrete in its guidance. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the prompt dataset creation and its source for the few-shot case should be included. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a discussion on the prompt dataset and its source, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the prompt dataset creation and its source should be included. However, it does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include a discussion on the prompt dataset creation and its source for the few-shot case. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by addressing a gap in the current content. However, the comment could be more helpful if it offered additional guidance on how to structure this discussion or what specific aspects should be covered. Despite this, the feedback is mostly helpful as it directs the authors to a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or the content of the paper. The comment lacks actionable details, such as what aspects of the motivation are unclear or how the authors might address the perceived incremental nature of the work. Without concrete steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not specify which part of the paper is unclear or what aspects of the motivation are challenging to follow. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper need revision. The comment is not grounded as it does not identify a specific area for improvement, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is difficult to follow the motivation of the paper and labels it as an \"incremental engineering paper.\" However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide specific feedback or suggestions on how the authors might improve the clarity of their motivation or the content of the paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what needs to be addressed or how to enhance their work. Therefore, the comment is not helpful at all, as it does not offer any constructive feedback or direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study on the weighting method of the cross-entropy loss would be beneficial. It provides a specific example of a scenario where the weighting method might have helped, such as in the Atlantis game where repetitive background sounds could be addressed. While the comment implies that the authors should conduct this ablation study, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit and lacks direct guidance. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the weighting method of the cross-entropy loss and provides a specific example from the Atlantis game, where repetitive background sounds could be addressed. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting an ablation study and providing a scenario where the weighting method might be beneficial. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study on the weighting method of the cross-entropy loss would be beneficial, particularly in scenarios like the Atlantis game where repetitive background sounds could be addressed. The reviewer provides a specific example of a scenario where the weighting method might have helped, which adds some level of justification to the claim. However, the comment lacks detailed reasoning or references to support the claim that the weighting method would be beneficial in general. While the suggestion is logical, it requires more evidence or examples to be fully verifiable. Therefore, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study on the weighting method of the cross-entropy loss, which is a specific and actionable recommendation. It provides a concrete example from the Atlantis game, where repetitive background sounds could be addressed using the weighting method. This feedback is clear and offers a clear direction for the authors to improve their draft by exploring the impact of different weighting methods on their model's performance. However, the comment could be more helpful if it included additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear path for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and that it involves a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might enhance the novelty or incremental nature of their work, or how they could improve their dataset or benchmark. Without actionable suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It provides specific details about the paper\\'s focus on column operations in designing semantic parsers for Text-to-SQL and mentions the use of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it references another synthetic benchmark paper based on a single question template. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issues with novelty and incremental nature, providing a clear understanding of what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, specifically mentioning the use of a new dataset that is a different train/test split of an existing dataset SQUALL. It also references another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim of lack of novelty, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to invest effort to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and that it involves a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper based on a single question template. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this lack of novelty or enhance the incremental nature of their work. Without actionable feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it provides insight into a critical area but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that more experiments are necessary, indicating a clear action for the authors to take. However, it does not specify which additional experiments should be conducted or how they should be designed. The lack of concrete details on what specific experiments are needed or how to implement them makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments are needed, but it does not specify which part of the paper this pertains to, such as the experimental section or a specific game environment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. However, the comment is specific in its request for additional experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"more experiments are necessary\" but does not provide any reasoning or evidence to support this claim. It lacks specific examples or references to justify why additional experiments are needed or what specific aspects of the current experiments are insufficient. Without further explanation or context, the claim remains unverifiable, as the authors are left without a clear understanding of what needs to be improved or how to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point that could help the authors expand the scope and applicability of their findings. However, the comment lacks specificity and does not provide guidance on which additional environments should be considered or how the experiments should be designed. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback provides a clear and direct action for the authors to take, specifying both what needs to be done (explaining the importance of removing these assumptions) and how to do it (using solid examples). The explicit nature of the instruction and the concrete guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of removing these assumptions and the need for solid examples to support this claim. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are significant or how their removal impacts the contribution of the paper. Without such support, the claim remains vague and unverifiable, as the authors are left without a clear understanding of what specific aspects need to be addressed or why they are important. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to provide more explanation and justification. It points out that the removal of assumptions like bounded variance and bounded gradients is presented as an important contribution but lacks detailed explanation or examples to support this claim. This feedback is clear and actionable, as it directs the authors to enhance their draft by providing a more thorough explanation of the significance of these assumptions and their removal. However, the comment could be more helpful if it offered suggestions on how to present this explanation or examples that could be used. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to address the issues of speed or accuracy, nor are there suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the implementation or accuracy are problematic. Without clear grounding and specificity, the authors cannot effectively address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' implementation of ImageNet is slow and has low accuracy, citing specific times and accuracy rates. This claim is somewhat verifiable as it provides numerical evidence to support the assertion. However, the comment lacks detailed reasoning or references to specific methods or benchmarks used for comparison, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address these issues or enhance their implementation. As a result, the comment is not helpful at all, as it does not provide the authors with any actionable insights or direction for improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part explicitly instructs the authors to add a few more sentences explaining the experimental setting for continual learning. This is a clear and direct action, making it concrete. The second part of the comment is more complex. It consists of a series of questions about Figure 3, which are implicit actions for the authors to address. While the questions are specific, they are not explicitly stated as actions, making the comment somewhat actionable. Overall, the comment provides a mix of explicit and implicit actions, with some guidance on how to implement them, aligning with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear and detailed questions about the experimental setting, the correspondence between learning curves and M-PHATE, and the relationship between performance and structural collapse. The comment specifies what needs to be addressed, such as explaining the experimental setting and the correspondence between learning curves and M-PHATE. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and requests for clarification, such as \"explain the correspondence between the learning curves and M-PHATE\" and \"why do you want to want me to look at the learning curves?\" These questions are not claims but rather requests for additional information or clarification. They do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by requesting additional explanations in the experimental setting for continual learning and asking for clarification about the correspondence between learning curves and M-PHATE in Figure 3. It also questions the purpose of looking at the learning curves and seeks clarification on the relationship between performance and structural collapse. These questions and requests for clarification are valuable as they guide the authors to enhance the clarity and comprehensiveness of their experimental results and explanations. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what additional information might be beneficial. Overall, the feedback is mostly helpful as it directs the authors to improve their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The comment implies an action by questioning the current approach and suggesting a potential improvement, but it lacks concrete details on how to execute this suggestion. Therefore, the comment is somewhat actionable, as the authors can infer a possible direction for improvement but need more guidance to fully implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not specify which part of the paper this suggestion pertains to. The authors can infer that it relates to the methodology or experimental setup sections, but without explicit references, the comment is weakly grounded. However, it is specific in suggesting a potential improvement by utilizing labeled data for consistency training. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but this claim is not fully supported by the provided references. The references are relevant to graph contrastive learning, but they do not directly address the specific question of using labeled data for consistency training. The comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, which might enhance the model's ability to deal with the task of graph anomaly detection. This feedback is somewhat helpful as it prompts the authors to consider an alternative approach that could improve their methodology. However, the comment lacks specific guidance or examples on how to implement this suggestion, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. It implies that the authors should restructure the experimental content in the main text to better showcase the advantages of their approach. However, the comment does not provide specific guidance on how to reorganize the content or what changes should be made to improve the experimental section. While the action is implicit, it lacks concrete details on how to implement the suggested changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. It mentions that the current content does not effectively showcase the advantages, implying that the authors should restructure the experimental content in the main text. However, the comment does not specify which parts of the experimental section are problematic or how they could be improved. Additionally, it provides a list of suggestions for what should be included in the main text, but these suggestions are not tied to specific sections or content. As a result, the comment is weakly grounded, as the authors cannot confidently determine which parts of the paper are being addressed, and it is specific in terms of suggesting improvements but lacks detailed guidance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. However, it does not provide specific examples or detailed reasoning to support why the current organization is ineffective or how it could be improved. The suggestion to include specific experimental suggestions in the main text is vague and lacks concrete evidence or references to substantiate the claim. As a result, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient detail and evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental section, noting that it lacks clarity in highlighting the superiority of the method. It suggests that the experimental content in the main text should be reorganized to better showcase the advantages of the approach. Additionally, the comment provides a list of specific suggestions for what should be included in the main text, such as the characteristics of the article and experimental suggestions. This feedback is clear and actionable, offering the authors concrete steps to improve the clarity and impact of their experimental section. However, it could be more helpful if it included additional guidance on how to reorganize the content or specific examples of what changes to make. Overall, the comment is mostly helpful as it provides valuable insights and direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a rationale for why this is important. The comment also implies that theoretical justifications would be beneficial for addressing the issue. While the comment explicitly states the need for reporting classification accuracy on ImageNet data, it does not provide specific guidance on how to conduct the analysis or what theoretical justifications might be necessary. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely clear on the specifics of the analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. It also implies that theoretical justifications would be beneficial for addressing the issue. However, the comment does not specify which part of the paper discusses the proposed network or its classification error, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the need for reporting classification accuracy and theoretical justifications, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. The comment also implies that theoretical justifications would be beneficial for addressing the issue. While the claim is logical and based on a comparison with a well-established standard, it lacks specific examples or references to support the assertion about the classification error. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. It also implies that theoretical justifications would be beneficial for addressing the issue. While the comment identifies a potential weakness in the paper and provides a clear suggestion for improvement, it lacks specific guidance on how to conduct the analysis or what theoretical justifications might be necessary. The feedback is somewhat helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending alternative methods or suggesting specific changes to the experimental design. As a result, the authors are left without a clear understanding of what steps to take to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the argument that recognition lists are recalled based on items. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment provides some specificity by questioning the feasibility of implementing and testing concrete predictions based on this argument, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. The reviewer provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is challenging to see how such an exhaustive list could be effectively implemented. This reasoning is based on common knowledge about memory processes and the limitations of exhaustive lists. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. It provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is challenging to see how such an exhaustive list could be effectively implemented. This feedback highlights a potential limitation in the approach and encourages the authors to consider alternative methods or simulations for testing their predictions. However, the comment could be more helpful if it offered specific suggestions or examples of alternative approaches. Overall, the comment is somewhat helpful as it identifies a critical issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It suggests that this lack of information could impact the results, as shown in Table 1. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental comparison with other methods, specifically questioning the fairness of the comparison due to the proposed method being pre-trained before fine-tuning. It also mentions Table 1, which implies that the authors can identify the part of the paper being discussed. However, the comment does not specify what needs to be addressed in the comparison, such as whether the other methods were also pre-trained or how this affects the results. While the authors can infer the general issue, the comment lacks specificity in detailing what needs to be clarified or improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental comparison with other methods is unfair because the proposed method was pre-trained before fine-tuning, while it is unclear if the compared methods were also initialized with a similar pre-trained model. The comment references Table 1, which shows that the proposed method without SSL performs inferior to most of the compared methods. However, the claim lacks specific evidence or references to support the assertion that the comparison is unfair. The reasoning is somewhat logical but requires more detailed justification or examples to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the proposed method being pre-trained before fine-tuning. It raises a concern about whether the compared methods were also initialized with a similar pre-trained model, which could impact the results. The comment references Table 1, where the proposed method without SSL performs inferior to most of the compared methods, suggesting that this discrepancy might be due to the pre-training. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the fairness of the comparison. The feedback is somewhat helpful as it points out a potential flaw, but it lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using better metadata embeddings for their zero-shot learning results on the CUB dataset. It references a specific paper, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the performance of the proposed method could be improved with better metadata embeddings. While the comment implies an action, it does not explicitly instruct the authors to implement this suggestion. The authors can infer that they should explore using better metadata embeddings, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"attribute,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improving the results by referencing a specific paper and suggesting the use of better metadata embeddings. The comment specifies what needs to be addressed, namely the performance of the proposed method with better metadata embeddings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the meta-data used for zero-shot learning on the CUB dataset, as presented in Table 3 on page 7, is \"attribute.\" It claims that this choice is good for fair comparison but notes that better meta-data embeddings are available, referencing a specific paper. The reviewer provides a clear suggestion to explore the performance of the proposed method with better meta-data embeddings, which is supported by a specific reference to a relevant paper. This level of detail and reference makes the claim mostly verifiable, as it provides a logical basis for the suggestion and a clear path for the authors to follow. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential weakness in the choice of metadata for zero-shot learning on the CUB dataset, noting that \"attribute\" is used but better metadata embeddings are available. The reviewer references a specific paper, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which suggests that better metadata embeddings could lead to improved performance. This feedback is clear and provides a concrete direction for the authors to explore, making it highly helpful. By suggesting a specific reference and a potential avenue for improvement, the comment empowers the authors to enhance their work. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a plot with sparsity on the x-axis and performance on the y-axis to directly compare the flexibility of SGC with LoRA. This suggestion is explicit and provides a clear action for the authors to take, which is to create a visualization to demonstrate the practical benefits of SGC\\'s fine-grained control. The comment is also concrete, as it specifies exactly what type of visualization is needed and how it should be structured. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a plot with sparsity on the x-axis and performance on the y-axis to directly compare the flexibility of SGC with LoRA. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a plot to demonstrate the practical benefits of SGC\\'s fine-grained control. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SGC offers a more flexible, fine-grained tradeoff but that PEFT methods typically target compute-constrained scenarios, where such granular control may require extra tuning that reduces practicality. The reviewer suggests including a plot with sparsity on the x-axis and performance on the y-axis to directly compare the flexibility of SGC with LoRA. This suggestion is based on logical reasoning, as it proposes a visual representation to demonstrate the practical benefits of SGC\\'s fine-grained control. However, the comment could be strengthened by providing specific examples or references to support the claim about the practicality of SGC\\'s control. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the applicability of the proposed method, specifically questioning the practicality of SGC\\'s fine-grained control in compute-constrained scenarios. It suggests that including a plot with sparsity on the x-axis and performance on the y-axis could more intuitively demonstrate the practical benefits of SGC\\'s control. This feedback is clear and actionable, providing a specific suggestion for improving the paper\\'s presentation and analysis. By offering a concrete way to visualize the tradeoffs, the comment empowers the authors to enhance the clarity and persuasiveness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plug-in is similar to Kearns et al. in Experiment 2, it would be beneficial to have the code published. While the comment implies that the authors should address the discrepancy in training times and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the code should be published. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and the \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the shorter training time for these datasets compared to Independent and suggesting that the code should be published due to the similar performance of ERM and plug-in to Kearns et al. in Experiment 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plug-in is similar to Kearns et al. in Experiment 2, it would be beneficial to have the code published. However, the comment lacks specific evidence or references to support the claim about the training time discrepancy or the need for code publication. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plug-in is similar to Kearns et al. in Experiment 2, it would be beneficial to have the code published. This feedback is somewhat helpful as it points out a potential discrepancy in the experimental results and suggests a way to address it by publishing the code. However, the comment could be more helpful if it provided specific guidance on how to analyze or interpret the training time differences or if it offered suggestions on how to improve the code publication process. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment implies that the authors should provide additional explanations or examples to clarify these points. While the action is implicit, it is clear and concrete, as it specifies what the authors need to address: describing alternate formulations for CD and clarifying the role of entropy. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, specifically asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment references specific lines in the paper (lines 113 and 115), providing full grounding as the authors can accurately identify the parts being addressed. However, the comment lacks specificity as it does not provide detailed guidance on what aspects of CD should be clarified or how alternate formulations could be described. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, specifically asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current form of CD and suggesting that additional explanations or examples could clarify its role. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It questions the current form of CD and asks why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This feedback is clear and actionable, as it prompts the authors to provide additional explanations or examples to clarify the role and significance of CD. However, the comment could be more helpful if it offered specific suggestions or examples of alternate formulations to consider. Overall, the comment is mostly helpful as it directs the authors to enhance their explanation and understanding of CD, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. The comment also points out that the abstract mentions a misleading claim about the human baseline beating the model baseline. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. While it identifies a problem, it lacks actionable advice on how to rectify it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"the abstract,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the human baseline and the model baseline, particularly the limited time the human baseline follows compared to the full 15 hours. Additionally, it highlights a misleading claim in the abstract regarding the human baseline. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours, which is a significant factor in making the human baseline weaker. The comment also critiques the abstract for a misleading claim about the human baseline beating the model baseline. However, the comment lacks specific examples or references to support the claim about the human baseline being weaker, making it somewhat verifiable. The authors would need to further investigate the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the human baseline, noting that it is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. This observation is important as it highlights a potential flaw in the experimental setup that could impact the validity of the results. The comment also points out a misleading claim in the abstract regarding the human baseline beating the model baseline, which is crucial for transparency and accuracy. However, the comment does not provide specific suggestions on how to address these issues or improve the draft. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the assumption for termination states of instructions, noting that it is expensive to label a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods or strategies for labeling data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, which implies that it relates to the methodology or experimental setup. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in pointing out the issue with the assumption, noting that labeling a large number of data manually is expensive. This provides some guidance on what needs to be addressed, but without explicit references to sections or specific elements, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is strong and that labeling a large number of data manually is expensive. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption for termination states of instructions, noting that it is expensive to label a large number of data manually. This feedback highlights a limitation in the methodology or experimental setup, which could impact the validity or applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods for labeling data or discussing potential workarounds. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in describing the contribution of the paper with respect to ECE_sweep. It explicitly suggests that the paper should be upfront about its contribution and clarifies that the contribution is essentially a way to choose the number of bins using data, which is not fundamentally different from existing estimators. The comment provides a clear and direct action for the authors to take, which is to clarify the contribution of their work. However, it does not offer specific guidance on how to achieve this clarity, such as suggesting changes to the text or providing examples. Therefore, the comment is mostly actionable, as it identifies a clear action but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the contribution, explaining that it is essentially a way to choose the number of bins using data, which is not fundamentally different from existing estimators. The comment suggests that the paper should be upfront about its contribution and clarifies that the reviewer was initially confused about the paper\\'s point. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the paper regarding ECE_sweep is not clearly described, suggesting that it amounts to a way to choose the number of bins using data. The reviewer provides a logical reasoning by explaining that this is not fundamentally different from existing estimators. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the context and reasoning to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity in describing the contribution with respect to ECE_sweep. It provides a clear explanation of what the contribution entails, which is essentially a way to choose the number of bins using data, and suggests that this is not fundamentally different from existing estimators. The comment also highlights the confusion it caused in the reviewer, emphasizing the need for the paper to be upfront about its contribution. This feedback is actionable and provides the authors with a clear direction for improving the clarity and transparency of their work. However, it could be more helpful if it offered specific suggestions on how to rephrase or present the contribution more effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the authors should include these methods as baselines, compare them to MLE, or address the gap in the literature. Without specific instructions or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work\" and \"other methods for training NMT models beyond MLE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that none of the discussed methods is used as a baseline, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the validity of the statement. Without detailed evidence or references, the claim remains somewhat verifiable, as the authors would need to invest time and effort to identify the missing baselines themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of these methods is used as a baseline. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper. However, it lacks specific suggestions or guidance on how the authors might address this gap or incorporate these methods as baselines. Without actionable advice, the authors are left with a general understanding of the issue but without a clear path to resolution. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential ambiguity in the paper regarding the use of the term \"Efficient Proxy.\" The reviewer suggests that the authors clarify whether they are referring to a specific proxy or a family of proxies. While the comment identifies a specific issue with the terminology, it does not provide explicit guidance on how to address this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and possibly provide examples or definitions to avoid confusion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It suggests that the authors need to clarify whether they are referring to a particular proxy or a family of proxies. However, it does not specify which part of the paper this ambiguity occurs in, making it weakly grounded. The comment is specific in detailing the issue with the terminology, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the ambiguity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the term \"Efficient Proxy\" in the paper. The reviewer suggests that the use of \"is\" implies a specific proxy, but the absence of a proxy named \"Efficient Proxy\" suggests it refers to a family of proxies. This claim is based on logical reasoning and the observation of the text, providing a clear explanation of the ambiguity. However, the comment could be strengthened by referencing similar cases or providing examples of how this ambiguity might impact the reader\\'s understanding. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks additional evidence or references to fully substantiate it.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the paper regarding the term \"Efficient Proxy.\" It points out that the use of \"is\" suggests a specific proxy, but the absence of a proxy named \"Efficient Proxy\" implies a family of proxies. This feedback is clear and actionable, as it prompts the authors to clarify whether they are referring to a specific proxy or a family of proxies. By addressing this ambiguity, the authors can improve the clarity and precision of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the ambiguity or offered examples of how to clarify the terminology. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Group-learning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this stacking is appropriate, whether it should be modified, or how it could be improved. Without any actionable suggestions or questions, the authors are left without a clear understanding of what needs to be done to address this point. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the stacking of methods from Mirzasoleiman et al., 2020 and the Group-learning setting, followed by the use of a classical method DBSCAN for clustering. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the methods being used and the stacking process, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Group-learning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive, making it a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual description of the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Group-learning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not offer any critique, suggestion, or feedback on the effectiveness, appropriateness, or potential improvements of these methods. Without any actionable advice or analysis, the comment lacks helpfulness and does not guide the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this investigation or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the resilience of the metric and determine how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3.a),\" indicating the specific part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment does not specify where this investigation should be conducted, the authors can infer that it relates to the methodology or results sections. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the potential issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment identifies a potential issue, it lacks specific guidance on how to address this concern or what steps the authors should take to investigate the resilience of the metric. The feedback is somewhat helpful as it prompts the authors to consider a potential weakness in their methodology, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for clarification regarding the use of synthetic data in the paper. It asks for an example of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests explicit mention of the model used in the appendix. These requests are explicit and provide clear guidance on what the authors need to do to improve their draft. The feedback is concrete, as it specifies exactly what information should be added or clarified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"synthetic data\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for examples of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests explicit mention of the model used in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, such as asking for examples of synthetic data and clarification on the terms \"support data\" and \"predicted training count data.\" It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific areas where the authors could provide more clarity and detail in their paper. It asks for examples of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests explicit mention of the model used in the appendix. These requests are actionable and provide clear guidance on how the authors can improve the comprehensibility and transparency of their work. However, the comment could be more helpful if it offered suggestions on how to present these examples or models, which would enhance its comprehensiveness. Overall, the feedback is valuable and provides a solid foundation for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is explicit and provides a clear action for the authors to take, which is to include the evaluation of FGT in the main performance evaluation. However, it does not specify how the authors should implement this change or provide detailed guidance on what specific aspects of FGT should be evaluated. While the action is explicit, the lack of concrete details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or beneficial. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of the proposed method, noting that the evaluation of FGT is only used in the ablation study and should be extended to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improving the evaluation section of the paper. By addressing this point, the authors can enhance the comprehensiveness and robustness of their evaluation, which is crucial for validating the effectiveness of their method. However, the comment could be more helpful if it included specific suggestions on how to incorporate FGT into the main performance evaluation or provided examples of what aspects of FGT should be evaluated. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the model more complex or what specific aspects need improvement. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, such as a particular section, figure, or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the model are considered overly simple or how this simplicity could be a bug. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the model is overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the model is considered overly simple. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the model is overly simple, which is both a feature and a bug. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on how to address the simplicity or what aspects of the model need to be enhanced, the authors are left without a clear understanding of how to improve their draft. This makes the comment barely helpful, as it identifies a potential issue but does not offer any actionable steps for the authors to take.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the work, noting that its focus on a narrow task and a specific language may restrict its broader impact. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might broaden the scope of their work or address the issue of limited impact. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment points out a limitation, it does not provide specific guidance on how to address this issue or improve the broader impact of the work. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work\\'s focus on a narrow task (climate change QA) and a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. While this observation is relevant, the comment lacks specificity and does not provide actionable feedback or suggestions for the authors to address this limitation. It does not offer guidance on how the authors might broaden the scope of their work or discuss potential applications beyond the current focus. As a result, the comment is somewhat helpful, as it identifies a potential issue but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the paper, specifically questioning the contribution of the paper in understanding the winner-take-all property when using extremely simplified settings. It references previous works that have already reported similar findings. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve the originality of their work. The action is implicit, as the authors need to infer that they should clarify their contribution or provide additional context to differentiate their work from previous studies. The lack of concrete guidance makes the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the originality of the paper, specifically questioning the contribution of the paper in understanding the winner-take-all property when using extremely simplified settings. It references previous works that have already reported similar findings, particularly in Section 5. This provides full grounding as it explicitly mentions the section of the paper being addressed, allowing the authors to accurately identify the part of the paper being critiqued. The comment is also specific because it details the issue of originality and the need for clarification on the paper\\'s contribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s contribution to understanding the winner-take-all property is unclear, particularly in the context of extremely simplified settings. The reviewer supports this claim by referencing previous works that have already reported similar findings, specifically mentioning Section 5. This provides a logical basis for the claim, as it highlights the lack of novelty in the paper\\'s approach. However, the comment could be strengthened by providing more specific examples or references to the previous works mentioned, which would make the claim fully verifiable. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the paper, specifically questioning the contribution of the paper in understanding the winner-take-all property when using extremely simplified settings. It references previous works that have already reported similar findings, particularly in Section 5. This feedback is somewhat helpful as it highlights a potential issue with the paper\\'s originality and suggests that the authors should clarify their contribution or differentiate their work from previous studies. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this concern or enhance the originality of their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only discussed in the appendix, in the main paper. It also recommends providing a rough example of run-times in the experiments to help readers interested in applying the method. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as it lacks specific guidance on how to present the computational cost or what specific run-times to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently discussed only in the appendix, in the main paper. It also recommends providing a rough example of run-times in the experiments to help readers interested in applying the method. While the comment does not explicitly mention a specific section or part of the paper, it implies that the appendix is the relevant area. The authors can infer that the computational cost discussion should be moved to the main paper. The comment is specific in suggesting what needs to be addressed, namely, the inclusion of computational cost information and run-time examples. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the computational cost of CHR, which is discussed in the appendix, should be mentioned in the main paper to help motivate the method. It also recommends providing a rough example of run-times in the experiments to aid readers interested in applying the method. However, the comment does not provide specific reasoning or evidence to support why this information is crucial or how it would benefit the paper. The suggestion is logical, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently discussed only in the appendix, in the main paper. This is a logical suggestion as it can help motivate the method and make it more accessible to readers. Additionally, the comment recommends providing a rough example of run-times in the experiments, which could be beneficial for readers interested in applying the method. While the comment is clear and actionable, it could be more helpful if it provided specific guidance on how to present the computational cost or run-time examples. Overall, the feedback is mostly helpful as it offers constructive suggestions for improving the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detailed explanation of the EEG topography plots in Figure 3, specifically addressing whether the spatial arrangement of the EEG sensors played a role in the EEG token quantization process. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to provide more detail but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the ambiguity in interpretation due to the presentation of EEG topography plots for both the input and output during the EEG token quantization process. Additionally, it provides a clear suggestion for improvement by recommending that the authors elucidate the procedure in greater detail, specifically addressing whether the spatial arrangement of the EEG sensors played a role in the process. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 3 presents EEG topography plots for both the input and output during the EEG token quantization process, leading to ambiguity in interpretation. The reviewer recommends that the authors provide more detailed explanation of this procedure, specifically addressing whether the spatial arrangement of the EEG sensors played a role. This claim is somewhat verifiable as it highlights a potential issue with the figure and suggests a specific area for improvement. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the ambiguity and how to address it, which could be challenging without further guidance. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, which presents EEG topography plots for both the input and output during the EEG token quantization process. It points out that this presentation leads to ambiguity in interpretation and suggests that the authors should provide a more detailed explanation of the procedure. Additionally, the comment offers a specific suggestion for improvement by asking whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, as it directs the authors to address a particular aspect of their work that could benefit from further clarification. By providing this detailed guidance, the comment is highly helpful, as it empowers the authors to make significant improvements to their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While the comment implies that the authors might consider merging these distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. The authors can infer that they might need to reconsider the distinction between these distances, but the comment does not provide detailed steps or examples on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or equation where these distances are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what changes, if any, should be made to address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is unnecessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there may be no need to distinguish between the two types of representation distances $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While this observation highlights a potential redundancy in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable feedback or detailed advice on how to improve the clarity or organization of the paper. As a result, the authors are left with a vague understanding of the problem and no clear path to resolution. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors use the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, as a way to address the problem. However, it suggests that this approach is not direct enough. While the comment implies that the authors should find a more direct way to address the problem, it does not provide specific guidance or suggestions on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a more direct solution but without concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the approach, suggesting that it is not direct enough. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors use the complexity of checking on the Witness oracle as a way to address the problem, suggesting that this approach is not direct enough. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the authors' approach, suggesting that using the complexity of checking on the Witness oracle as a way to address the problem may not be direct enough. While the comment identifies a possible weakness, it lacks specificity and does not provide actionable guidance or suggestions for improvement. The authors are left without clear direction on how to address this critique or what alternative approaches might be more direct. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer meaningful feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It implies that the authors should discuss this approach when discussing various DRL methods, even though the paper still uses quantile regression. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate this discussion or what specific aspects should be included. The action is implicit and somewhat vague, as the authors need to infer that they should discuss moment matching and its relevance to DRL. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (22-30) where the discussion on distributional RL is lacking. It also specifies the issue by pointing out the absence of relevant literature on using moment matching instead of quantile regression, as discussed in Nguyen-Tang et al. (AAAI\u201921). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by Nguyen-Tang et al. (AAAI'21), to support this claim. This provides a clear and specific reference that helps verify the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be applied or why it is a relevant approach. Overall, the comment is mostly verifiable, as it provides a solid foundation for the claim but could benefit from additional elaboration.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a particular paper, \"Distributional Reinforcement Learning via Moment Matching\" by Nguyen-Tang et al. (AAAI'21), which could provide valuable insights for the authors. By suggesting the inclusion of this literature, the comment offers a clear and actionable direction for improving the paper. However, the comment could be more helpful if it provided additional context or explanation on why moment matching is a relevant approach or how it could enhance the paper. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback provides a clear and concrete action for the authors to take, specifying both the type of baselines to include and how to test them. The explicit nature of the suggestion and the detailed guidance on implementation make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also recommends testing these baselines on a smaller subset of RepoEval. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results section. The suggestion is specific in terms of what baselines to include and how to test them, providing clear guidance for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. The reviewer provides a logical reasoning for the suggestion, stating that it is essential to compare with state-of-the-art code completion systems. However, the comment lacks specific examples or references to support the claim that Copilot is a relevant baseline or how it should be tested. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the comprehensiveness and validity of their experimental evaluation. By including these additional baselines, the authors can better position their work in relation to current state-of-the-art systems, which is crucial for the credibility and impact of their research. However, the comment could be more helpful if it provided specific guidance on how to implement the comparison or what metrics to use. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on the selection process and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses this evaluation, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in its request for clarification on the selection criteria and potential implications, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. The comment suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that other tasks or datasets might yield different insights. The reasoning is logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the evaluation by questioning the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and justification for their evaluation methodology. By addressing this point, the authors can enhance the transparency and robustness of their results. However, the comment could be more helpful if it offered specific suggestions on how to expand the evaluation or provided examples of alternative datasets or tasks to consider. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity in the introduction, specifically regarding the modelling of curves, which are presumably related to tumour growth. However, it does not provide explicit guidance on how to address this issue or suggest specific changes that could improve the clarity. The action is implicit, as the authors can infer that they need to clarify the context of the modelling, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second paragraph\" of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding what is being modelled, particularly in relation to tumour growth. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second paragraph in the introduction discusses modelling curves but does not make it immediately clear what is being modelled. The reviewer infers that it is related to tumour growth, but this inference is not explicitly stated. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction, noting that the second paragraph discusses modelling curves but does not clarify what is being modelled, presumably tumour growth. This feedback is somewhat helpful as it points out a lack of clarity in the introduction, which is an important section of the paper. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples to clarify the context. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the shifted-MNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It also suggests showing the performance of the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional analysis or results to address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses to address the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"shifted-MNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of shift=0 compared to shift~N(0,\u03c32) and suggesting the inclusion of performance results on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the shifted-MNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the authors should show the performance of the model and baselines on test samples from the observational (in) distribution. While the comment questions the reasoning behind the results, it does not provide specific evidence or references to support the claim that shift=0 is better. The suggestion to show performance on test samples is logical but lacks detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but lacks comprehensive evidence or detailed reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance of the shifted-MNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the authors should provide additional analysis by showing the performance of the model and baselines on test samples from the observational (in) distribution. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for further analysis. By addressing this point, the authors can enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it included additional context or explanation about the significance of this analysis. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experiment description lacks clarity and suggests that it would benefit from increased detail to allow the reader to better judge the results. It also refers to the \"Questions\" section for further details. This provides a clear action for the authors to improve their draft by enhancing the clarity of the experiment description. However, the comment does not specify exactly what aspects of the description need improvement or how to achieve this clarity. While the action is explicit, it lacks concrete guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking detail and suggests that increased clarity is needed to allow the reader to better judge the results. The comment further refers to the \"Questions\" section for additional details, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment description lacks clarity, making it difficult for the reader to judge the results. However, it does not provide specific examples or detailed reasoning to support this claim. The reference to \"Questions\" for further details does not fully address the issue, as it does not provide additional context or evidence to substantiate the claim. As a result, the comment is somewhat verifiable, as it highlights a potential issue but lacks sufficient detail and examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment description, noting that it lacks clarity and detail, which makes it difficult for the reader to judge the results. It suggests that the description would benefit from increased clarity to improve the paper. However, the comment does not provide specific guidance or examples on how to enhance the clarity or what aspects of the description need improvement. While it highlights an important area for improvement, the lack of detailed feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. It also asks for an example of what would happen by minimizing both terms in Eq 3 or only the first term. While the comment explicitly states the need for more explanation and discussion, it does not provide specific guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute the actions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more explanation to clarify the expected results and discussing different optimization strategies and their corresponding results. The comment also includes a specific example of what should be discussed, such as minimizing both terms in Eq 3 or only the first term. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. The reviewer provides a specific example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and the inclusion of a concrete example contribute to the claim\\'s verifiability. However, the comment could be strengthened by referencing similar works or providing additional context to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but lacks comprehensive evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanation to clarify the expected results. It also highlights the importance of discussing different optimization strategies and their corresponding results, particularly in relation to the main contribution of the paper, the CBR. The comment includes a concrete example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and specificity provides the authors with clear guidance on how to enhance their draft, making the comment mostly helpful. However, it could be more comprehensive by suggesting specific ways to present or discuss the optimization strategies. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that the authors should provide this definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the definition should be presented or what level of detail is required. However, the authors can infer that they need to add a definition, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or proof. This makes it weakly grounded, as the authors cannot confidently determine where to make the addition. The comment is specific in suggesting the inclusion of a definition, but without clear grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This is a request for clarification or additional information, not a claim or opinion that requires verification. It is a factual statement that does not need justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional context or clarification. By addressing this suggestion, the authors can enhance the comprehensibility and accessibility of their work for readers. However, the comment could be more helpful if it provided guidance on how to present the definition or where it should be included in the paper. Overall, the comment is mostly helpful as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. While the comment implies that the authors should expand their analysis to include this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific assumptions should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the analysis of the quality of local minima found by Algorithm 1, particularly the approximation ratio under certain assumptions. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. This is a claim that requires further analysis and justification, as it suggests an additional aspect of the paper that could be explored. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim, making it somewhat verifiable. The authors would need to infer the importance and relevance of this analysis themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the analysis of the paper, specifically noting that it only examines the conditions under which Algorithm 1 converges to permutations as local minima. It suggests that the quality of these local minima should also be analyzed, such as the approximation ratio under certain assumptions. This feedback is clear and actionable, providing the authors with a specific direction for expanding their analysis to enhance the comprehensiveness and depth of their work. However, the comment could be more helpful if it offered examples or specific assumptions to consider, which would make it fully actionable. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper is not self-contained and requires the supplementary material to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly states the need for the supplementary material and the release of the source code, it does not provide specific guidance on how to improve the self-containment of the main paper or how to release the source code. The actions are explicit but somewhat vague, as the authors know what needs to be done but may not be entirely clear on the execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper\\'s self-containment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment does not specify which parts of the paper are not self-contained or how the supplementary material is necessary. Additionally, it does not provide specific guidance on how to improve the self-containment or release the source code. While the authors can infer that the comment relates to the overall structure and reproducibility of the paper, the lack of detailed guidance makes it weakly grounded and not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not self-contained. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s self-containment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility, which is a crucial step in ensuring the paper\\'s impact and credibility. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to enhance the self-containment of the main paper or by offering guidance on releasing the source code. Despite this, the feedback is mostly helpful as it directs the authors to address critical aspects of their work that can significantly improve its quality and impact. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms need clarification or improvement, leaving the authors without a clear understanding of how to address the issue. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode\" algorithms and the sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and provides a reference to the sentence where this claim is made. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, which is an important aspect of the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their explanation. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what steps to take to enhance their work. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not offer meaningful guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the model\\'s novel feature, which involves using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice should be ablated to determine its significance. The comment explicitly asks for an evaluation of the added complexity and whether one IN would suffice. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to assess the impact of this feature. The feedback is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper discusses this feature, making it weakly grounded. The comment is specific in its request for an ablation study to determine the added complexity and whether one IN would suffice. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this ablation is necessary or how it might impact the model\\'s performance. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance and asks whether one IN would suffice. This feedback is clear and actionable, as it prompts the authors to conduct an ablation study to evaluate the added complexity and impact of this feature. By addressing this point, the authors can gain a better understanding of the model\\'s performance and make informed decisions about its design. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct the ablation study. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement with actionable feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the opponent in the experiments does not aim to maximize the multi-agent payoff proposed by the authors, which is why the opponent is outperformed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiments, explaining why the opponent is outperformed in terms of the multi-agent payoff. The comment provides a clear rationale for the observed outcome, which helps the authors understand what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the opponent in the experiments is outperformed because they do not aim to maximize the multi-agent payoff proposed by the authors. The reviewer provides a specific example of the opponent maximizing classical SE and AE, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the opponent's strategy differs from the authors' proposed payoff. Overall, the claim is mostly verifiable, as it provides a logical explanation but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiments, noting that the opponent is outperformed because they do not aim to maximize the multi-agent payoff proposed by the authors. The reviewer provides a clear explanation by mentioning that the opponent maximizes classical SE and AE, which is different from the authors' proposed payoff. This feedback is valuable as it highlights a potential weakness in the experimental setup and suggests that the authors should consider how their opponent's strategy aligns with their proposed payoff. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the experimental design. Overall, the comment is mostly helpful as it provides a clear insight into a potential weakness in the experiments, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. While the comment explicitly states that the authors should provide clarification, it does not specify how to do so or what specific aspects of the choice should be explained. The action is explicit but somewhat vague, as the authors know they need to provide clarification but may not be entirely sure of the exact details to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but it does not specify which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a specific section. However, it is specific in suggesting that the authors should clarify their choice of algorithms. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but acknowledges that this is only a presumption. While the comment provides a logical basis for the suggestion, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to infer the reasoning themselves, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. The comment is clear and actionable, as it directs the authors to explain their reasoning behind specific algorithmic choices, which can enhance the transparency and comprehensibility of the paper. However, it could be more helpful if it provided specific guidance on what aspects of the choice should be explained or referenced. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the statement, address the potential disadvantage, or improve the explanation of Theorem 5.1. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion about the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. The comment provides a clear indication of what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, the comment does not provide any further explanation, reasoning, or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any further explanation, reasoning, or suggestions on how the authors might clarify or address this potential disadvantage. Without additional context or guidance, the authors are left without actionable feedback to improve their draft. Therefore, the comment is not helpful at all, as it does not offer any constructive direction for the authors to enhance their work.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains. The comment implies that the paper lacks insight into these aspects and assumes invariance. While the comment identifies areas that need further exploration, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections, where morphologic segmentation is likely discussed. The comment is specific in detailing what is missing or unclear, such as the need for insights into domain adaptation and the assumption of invariance. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks insight into how morphologic segmentation should be conducted differently for different domains and questions whether it is invariant across domains. The comment suggests that this is an important aspect given the task domain adaptation. However, the claim is not fully verifiable as it lacks specific examples, references, or detailed reasoning to support the assertion that morphologic segmentation should be conducted differently for different domains. The authors would need to infer the importance of this aspect based on the general statement provided. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the use of morphologic segmentation across different domains and questions whether it should be conducted differently for different domains. It highlights the importance of this issue given the task domain adaptation and notes that the paper lacks insight into this aspect, assuming invariance instead. This feedback is clear and actionable, as it prompts the authors to address a critical area of their work that could significantly impact its applicability and relevance. By pointing out the need for more detailed discussion and potentially different approaches for different domains, the comment provides the authors with a clear direction for improvement. However, it could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the depth and applicability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments to isolate the effects of the mixup technique. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This claim is based on the observation that the mixup technique is also used in LUMP, which is mentioned in Section 4.2. The reviewer provides a logical reasoning for the suggestion, as it aims to isolate the effects of the proposed method from the mixup technique. However, the comment could be strengthened by providing specific examples or references to support the claim that the mixup technique is a significant factor in the results. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental setup by suggesting that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s experimental rigor and clarity. By following this advice, the authors can better isolate the effects of their proposed method and provide a more comprehensive evaluation of its contribution. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also suggests that the authors clarify if any rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback provides clear and explicit actions for the authors to take, ensuring they know exactly what needs to be clarified and how to address it. The comment is highly actionable as it offers concrete guidance on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"object detection based attention,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: whether the attention is performed on the image or on a convolutional feature map, and if rescaling is done based on the receptive field. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also asks about the rescaling process based on the receptive field. This is a factual request for clarification and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of confusion regarding the object detection based attention. It asks for clarification on whether the attention is performed on the image or on a convolutional feature map, and if rescaling is done based on the receptive field. This feedback prompts the authors to clarify a critical aspect of their methodology, which can help improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as recommending specific methods or approaches for clarification. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly mentions the need for a discussion about the Set Transformer and other related works that use summary tokens. This provides a clear action for the authors to take, which is to include a discussion on these topics. However, the comment does not specify how this discussion should be integrated into the paper or what specific aspects should be covered. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link to the relevant paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. The reference to the Set Transformer is a factual statement, but it does not contribute to the claim itself. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to include a discussion on these topics, which could enhance the context and relevance of their work. However, the comment could be more helpful if it provided suggestions on how to integrate this discussion or why it is important for the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the acceleration of NTK convergence in the high-frequency range using Fourier features. It implies that this aspect is not analyzed or discussed in the paper, which is an important theoretical support for the merits of Fourier features. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the acceleration of NTK convergence in the high-frequency range using Fourier features. It implies that this aspect is not analyzed or discussed in the paper, which is an important theoretical support for the merits of Fourier features. However, the comment does not specify which part of the paper should address this issue, making it weakly grounded. The authors can infer that it relates to the theoretical or experimental sections, but the lack of explicit reference makes it difficult to pinpoint the exact location. The comment is specific in identifying the missing analysis, but without grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the acceleration of NTK convergence in the high-frequency range using Fourier features. It suggests that this aspect may not be analyzed or discussed in the paper, which is an important theoretical support for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that this aspect is essential or missing. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the acceleration of NTK convergence in the high-frequency range using Fourier features. It implies that this aspect is not analyzed or discussed in the paper, which is an important theoretical support for the merits of Fourier features. While the comment identifies a potential gap in the analysis, it lacks specific suggestions or guidance on how the authors might address this issue or what additional information could be included. The feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not provide explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details on this aspect, but it lacks concrete instructions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of fitting the network to the residual rather than directly learning the input-output mapping. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on what aspects of the network fitting process need clarification or improvement. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the details on how the network is made to fit the residual instead of directly learning the input-output mapping. This is a relevant observation that could help the authors improve their draft by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional experiments or analyses to clarify the process. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for details about the experiment setup in Section 3.3, specifically mentioning data augmentation methods, learning rate, etc. This request is clear and direct, providing the authors with a specific action to take. The inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" further supports the need for this information. Therefore, the comment is highly actionable, as it provides a concrete and explicit action for the authors to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely details about the experiment setup, such as data augmentation methods, learning rate, etc. The inclusion of a reference to a relevant paper further supports the need for this information. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods, learning rate, etc. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by asking for details about the experiment setup in Section 3.3. It requests information on data augmentation methods, learning rate, and other relevant aspects, which can help the authors provide a more comprehensive description of their experimental setup. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. By focusing solely on the request for details, the feedback lacks depth and does not fully guide the authors in enhancing their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this possibility, make changes to the calibration steps, or address the issue in the paper. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable feedback or detailed insights into how the authors might improve their draft. As a result, the comment is somewhat helpful, as it points out a potential area for exploration but does not offer clear steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. The reviewer clarifies that this observation does not affect the review given and does not hold the authors accountable. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue or improve their draft. It lacks specific guidance on how the authors might enhance their work to better align with biological networks or address the weight transport problem. As a result, the authors are left without any clear direction on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the resemblance of artificial networks trained using ASAP (and similar methods) to biological networks, specifically mentioning the weight transport problem. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its critique of the lack of resemblance to biological networks, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. However, the reviewer clarifies that this observation does not affect the review given and does not hold the authors accountable. While the comment acknowledges a potential limitation, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or enhance their work. Therefore, the comment is not helpful, as it lacks actionable insights or constructive feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and the baselines. While it implies that the authors should consider conducting a statistical significance test, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the test or what parameters to consider. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and the baselines. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its request for a statistical significance test, but without clear grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and the baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why a statistical significance test is necessary or how it could impact the interpretation of the results. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and the baselines. While it points out a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern. The comment lacks depth and actionable feedback, leaving the authors with only a vague idea of what might be missing or what improvements could be made. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It explicitly asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. This question provides a clear and direct action for the authors to take, as it prompts them to clarify the relationship between the emission distributions and inference tasks. The comment is explicit and provides concrete guidance on what the authors need to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. However, it does not specify which part of the paper this question pertains to, leaving the authors to infer that it relates to the sections discussing inference or modeling. While the comment is specific in its inquiry, it lacks full grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It does not present a claim or opinion but rather seeks clarification through a question. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It specifically asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. This question prompts the authors to clarify an important aspect of their work, which could lead to a more comprehensive understanding of the model\\'s capabilities and limitations. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the feedback is somewhat helpful as it identifies a gap in the paper and encourages the authors to clarify a critical aspect of their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should include an analysis of the reasons behind this outcome, which is an implicit action. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. While the action is clear, it lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis of experimental results\" and the specific issue of the authors only mentioning the poor performance of the scope prompting method on GPT-3.5-turbo without providing an analysis of the underlying reasons. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the analysis, namely, an explanation of the reasons behind the poor performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing an analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or analysis to understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing an analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by providing a deeper analysis of the results. However, the comment could be more helpful if it suggested specific aspects of the analysis that should be explored or offered guidance on how to present the results more effectively. Despite this, the comment provides valuable insight into an area that needs improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why the authors did not compare batch and greedy methods in the remaining 110 datasets, given that only 10 out of 120 datasets were considered in [7,12]. While the comment implies that the authors should consider comparing these methods in the other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include more datasets. However, the comment provides a clear rationale for why this comparison might be beneficial, which could guide the authors in making a decision. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the authors\\' choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the datasets are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment provides a specific suggestion for improvement, it does not specify what is wrong or missing in the current analysis. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the authors\\' decision to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the authors\\' choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or why it is important. The feedback is somewhat helpful as it prompts the authors to consider expanding their analysis, but it does not provide actionable steps or detailed reasoning to support the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation for the low-rank factorization in the introduction is unnecessary, given that the main result is about polytopes. If the result has implications for low-rank matrix factorization, the reviewer requests that these implications be explicitly discussed. While the comment implies that the authors should address the implications of their result for low-rank matrix factorization, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications and determine how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"motivation in the introduction with the low-rank factorization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the discussion of implications for low-rank matrix factorization, if any, should be explicitly included. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the motivation for low-rank factorization in the introduction is unnecessary, given that the main result is about polytopes. The reviewer requests that if the result has implications for low-rank matrix factorization, these implications should be explicitly discussed. However, the comment does not provide specific examples or references to support the claim that the motivation is unnecessary or that the implications should be discussed. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation for the low-rank factorization in the introduction, suggesting that it may be unnecessary given the main focus on polytopes. It also requests that if the result has implications for low-rank matrix factorization, these implications should be explicitly discussed. This feedback is clear and actionable, as it prompts the authors to reconsider the relevance of their motivation and to provide a more direct connection between their work and low-rank matrix factorization, if applicable. However, the comment could be more helpful if it offered specific suggestions on how to integrate this discussion or provided examples of how to make the connection more explicit. Overall, the comment is mostly helpful, as it guides the authors toward a potential improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the labels for each dataset in Section 4.1, specifically questioning whether they are derived from the dataset itself or from other sources. This request is clear and direct, providing the authors with a specific action to take to improve their draft. The comment also suggests that the labels for generated datasets may be straightforward, but it raises a question about the labels for cas-peal-r1 and mugshot. This additional inquiry adds depth to the comment, making it highly actionable. The authors know exactly what information to provide to address the reviewer\\'s concerns, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the labels for each dataset and their origin. The comment asks for clarification on whether the labels are derived from the dataset itself or from other sources, and it raises a question about the labels for specific datasets like cas-peal-r1 and mugshot. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the labels for each dataset in Section 4.1, specifically asking where the labels are coming from. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual question seeking information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of confusion regarding the labels for each dataset in Section 4.1. It raises a question about the origin of the labels, whether they are derived from the dataset itself or from other sources. This feedback prompts the authors to clarify this aspect of their work, which can help improve the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as recommending specific ways to clarify the labeling process. Overall, the comment provides some direction but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the paper is incremental compared to a specific reference, [31], and describes the adaptation of the existing architecture for the multi-person case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived incremental nature of the work or improve upon it. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper as being incremental compared to a specific reference, [31], and describes the adaptation of the existing architecture for the multi-person case. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the adaptation could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental compared to reference [31], noting that the authors adapt the existing architecture for the multi-person case. However, the comment does not provide any specific details or examples to support this claim, such as how the adaptation is incremental or what aspects of the existing architecture are being adapted. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper is incremental compared to a specific reference, [31], and describes the adaptation of the existing architecture for the multi-person case. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or constructive criticism, the authors are left without a clear understanding of how to address the perceived incremental nature of their work or how to enhance it. Therefore, the comment is not helpful at all, as it does not offer any actionable insights or direction for the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameters, the calculation of \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, it does not provide explicit instructions or suggestions for the authors to address these issues. The comment implies that the authors should clarify the calculation of \u03bb and provide a more detailed explanation of the impact of ELLA on sample efficiency, but these actions are not directly stated. As a result, the authors may find it challenging to determine exactly what changes are needed to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages and lines where the issues are discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the calculation of the \u03bb parameter and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, which further enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameters, the calculation of \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, which helps to support the claim and provides context for the questions being raised. However, the comment could be more detailed in explaining how the references relate to the specific issues being discussed. Overall, the claim is mostly verifiable, as it provides a solid foundation for the questions but lacks some depth in the explanation. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameters, the calculation of \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides specific references to relevant literature, which can help the authors better understand the context of their work. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas that need clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the method used to solve the min-min problem, specifically asking which method is being referred to. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how to address the question or improve the clarity of the paper regarding this method. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the method used to solve the min-min problem, but it does not specify which part of the paper this method is mentioned in. This makes it difficult for the authors to pinpoint the exact section where the method is discussed. Additionally, the comment lacks specificity regarding what aspect of the method is unclear or what additional information is needed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the method used to solve the min-min problem. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the method used to solve the min-min problem, specifically asking which method is being referred to. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their draft. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it points out a potential issue but does not offer any actionable steps for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the effectiveness of lower bound double q-learning, specifically mentioning the performance decrease of Clipped DDQN in MsPacman and the convergence of algorithms in certain environments. It also raises concerns about overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The authors are left to infer that they need to provide evidence or justification for the effectiveness of their method, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of lower bound double q-learning, specifically mentioning the performance decrease of Clipped DDQN in MsPacman and the convergence of algorithms in certain environments. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about the algorithm\\'s performance and convergence, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of lower bound double q-learning is doubtful, citing specific examples from Figure 2 and certain environments. However, the comment lacks detailed reasoning or evidence to support the claim that the algorithm causes overestimation of the true maximum value. While it provides some context, the lack of specific examples or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some support but requires more detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the effectiveness of lower bound double q-learning, specifically mentioning the performance decrease of Clipped DDQN in MsPacman and the convergence of algorithms in certain environments. It also points out a potential issue with overestimating the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it highlights potential weaknesses, but it could be more actionable with additional insights or recommendations. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue. It lacks specific guidance on how the authors might enhance the novelty or provide additional insights into their approach. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning the interpretation of deep neural network predictions using a linear model. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what aspects of the novelty are lacking or how the interpretation could be improved. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any specific suggestions or guidance on how the authors might enhance the novelty or originality of their work. Without actionable feedback or constructive criticism, the comment lacks helpfulness, leaving the authors without a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, as shown in figures 3-4. The reviewer suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to clarify the performance trend. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or analysis to clarify the performance trend. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig.3-4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear performance trends for DNN+MMA compared to vanilla DNN when lambda becomes small. The comment provides a clear expectation that the performance should approach the vanilla methods from below, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, as shown in figures 3-4. The reviewer suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. The comment is somewhat verifiable as it identifies a specific observation and a potential expectation, but it lacks detailed reasoning or evidence to fully support the claim. The authors would need to investigate the issue further to understand the basis of the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, as shown in figures 3-4. It suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. This feedback identifies a specific area of confusion in the paper and prompts the authors to provide further explanation or analysis to clarify the performance trend. While the comment highlights a potential issue, it does not offer specific suggestions or guidance on how to address it, leaving the authors with a clear question to answer but without detailed steps for improvement. Therefore, the comment is somewhat helpful, as it provides insight into a potential area of concern but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper does not compare its results with earlier research work from 2020, despite the authors explaining their reasons for not doing so. The comment suggests that the authors should compare their results with earlier systems with worse performances, as they have done with Taghipour and Ng (2016). While the comment implies that the authors should include comparisons with earlier research, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on which earlier systems to compare with or how to present the comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"author response\" and the \"lines of \\\"Those systems are not state-of-the-art\\\"\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not comparing results with earlier research work from 2020, despite the authors' explanation for not doing so. The comment further suggests that the authors should compare their results with earlier systems with worse performances, as they have done with Taghipour and Ng (2016). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not compare its results with earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer provides a specific example of earlier systems with worse performances that the authors have compared their results to, such as Taghipour and Ng (2016). This provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or references to specific aspects of the earlier research that the paper should address. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of comparison with earlier research work from 2020. It acknowledges the authors' explanation for not comparing with state-of-the-art systems but points out that they have compared their results with earlier systems with worse performances. The comment provides a clear suggestion for improvement by recommending that the authors include comparisons with earlier research work, even if it is not state-of-the-art. This feedback is actionable and offers a specific direction for enhancing the paper, making it mostly helpful. However, it could be more helpful if it provided additional guidance on which specific earlier research to consider or how to present the comparisons. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the choice of significance testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed-rank test, instead of the current method. While the comment implies that the authors should reconsider their choice of test, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their test choice and potentially switch to a paired test setting. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the choice of significance testing and suggests that the authors should consider using a paired test setting, such as the Wilcoxon signed-rank test, instead of the current method. However, it does not specify which part of the paper discusses the significance testing or where the authors mention the current method. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting an alternative test setting, but without explicit grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the choice of significance testing might be incorrect and suggests using a paired test setting, such as the Wilcoxon signed-rank test, instead of the current method. However, the comment does not provide any reasoning or evidence to support why the current method is incorrect or why the suggested test is more appropriate. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of significance testing in the paper, suggesting that a paired test setting, such as the Wilcoxon signed-rank test, might be more appropriate. This feedback is somewhat helpful as it points out a specific area for improvement and provides a suggestion for an alternative approach. However, the comment lacks detailed guidance on why the current method might be incorrect or how to implement the suggested test, which could be beneficial for the authors. To be more helpful, the comment could include additional context or examples to support the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to improve the comprehensiveness and generality of the experiments. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the model size and include more diverse baselines. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not specify which sections of the paper these limitations are discussed in, making it difficult for the authors to pinpoint the exact parts that need improvement. The comment is specific in its critique of the experiments, but it lacks grounding as it does not identify the specific sections or experiments being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines for both the language modeling task and image classification task. However, the comment lacks specific examples or references to support why these limitations exist or how they could be addressed. The reasoning is somewhat vague, making it difficult for the authors to understand the basis of the critique and how to improve their work. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the comprehensiveness and generality of the experiments, specifically noting that the model size is limited and the baselines are restrictive. This feedback is somewhat helpful as it points out an area for improvement, suggesting that the authors should consider expanding their experiments to include more diverse model sizes and baselines. However, the comment lacks specific guidance on how to achieve this or what additional baselines or model sizes might be appropriate. To be more helpful, the comment could provide examples or suggestions for expanding the experiments. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to elaborate on a specific aspect of their paper, namely the Hoeffding\\'s bound and its applicability to stochastic algorithms. It provides a clear action for the authors to take, which is to expand on the explanation in the paper. However, the comment does not specify how the authors should elaborate on this topic, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 124-125, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the applicability of Hoeffding\\'s bound to stochastic algorithms. The comment provides a clear direction for the authors to improve their explanation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions, making it a normal statement. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors could provide more elaboration, specifically regarding the applicability of Hoeffding\\'s bound to stochastic algorithms. It points out that the authors should explain how the conditioning on the previous iterate further guarantees the validity of the Hoeffding inequality. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation in the paper. However, the comment could be more helpful if it included suggestions on how to present this information or examples to illustrate the point. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach to Table-1, specifically mentioning MAML or implicit-MAML. This is an explicit suggestion that provides a clear action for the authors to take, namely, to incorporate these approaches into their table. The comment is concrete because it specifies the type of optimization-based meta-learning approach to consider, making it easy for the authors to understand and implement the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach to Table-1, specifically mentioning MAML or implicit-MAML. However, it does not specify which part of Table-1 this suggestion pertains to, nor does it provide details on how this addition would improve the table or the paper. The authors can infer that it relates to the experimental results or methodology section, but the lack of specific guidance makes it difficult to pinpoint the exact area needing improvement. Therefore, the comment is weakly grounded because it does not explicitly mention the section, and it is not specific because it lacks detailed guidance on what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach to Table-1, specifically mentioning MAML or implicit-MAML. However, the comment does not provide any reasoning or evidence to support why this addition would be beneficial or how it would improve the paper. Without further explanation or context, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach to Table-1, specifically mentioning MAML or implicit-MAML. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper by incorporating a particular type of meta-learning approach. However, the comment lacks detailed guidance on how to implement this suggestion or why it would be beneficial, which could be more helpful for the authors. Additionally, it does not address any broader issues or weaknesses in the paper, limiting its impact on improving the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using few-shot examples for CoT to improve performance. This feedback implies that the authors should include an ablation study to address this gap. While the action is clear, it lacks specific guidance on how to conduct the ablation study or what specific aspects to focus on. The authors know they need to add an ablation study but may not be entirely sure of the exact steps to take. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed instructions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using few-shot examples for CoT to improve performance. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to include an ablation study, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using few-shot examples for CoT to improve performance. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s explanation and suggests a specific area for improvement. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain why the authors chose the prompt in a particular way. It provides a clear and actionable suggestion for enhancing the paper\\'s methodology and rationale, which is valuable for the authors. However, the comment could be more helpful if it offered additional guidance on what specific aspects of the prompt should be tested or how the ablation study should be conducted. Despite this, the feedback is mostly helpful as it directs the authors to a meaningful improvement in their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from the term \"temporal relationship.\" This feedback provides a clear and direct action for the authors to take, ensuring they use the terms correctly throughout the paper. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1\" and the specific term \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" pointing out that it should be differentiated from \"temporal relationship.\" This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the use of the term \"causal mechanisms\" on page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of terminology on page 1, where the term \"causal mechanisms\" is used interchangeably with \"temporal relationship.\" It provides a clear and actionable suggestion to use the terms carefully, ensuring clarity and accuracy in the paper. This feedback is valuable as it helps the authors correct a potential misunderstanding in their work, which could lead to improved clarity and understanding for readers. However, the comment could be more helpful if it provided examples or further explanation of how to differentiate between these terms. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the strength of the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any explicit or implicit guidance on how the authors should address this concern or improve their argument. The comment lacks actionable details, such as suggesting alternative ways to demonstrate capability or providing examples of stronger demonstrations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, \"You write: \\\"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\\\"\" allowing the authors to accurately identify the section being addressed. It is also specific because it questions the strength of the claim that \"better than random\" is a strong demonstration of capability. This provides clear guidance on what aspect of the paper needs further elaboration or justification. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the strength of the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate why this claim is weak. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the strength of the claim that \"better than random\" is a sufficient demonstration of capability. However, it does not provide any specific suggestions or guidance on how the authors might strengthen their argument or present a more compelling demonstration. The comment identifies a potential weakness but lacks actionable feedback, leaving the authors without a clear path for improvement. As a result, the comment is barely helpful, as it points out a concern but does not offer constructive advice or direction for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to integrate this information or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in a reference. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results should be discussed in relation to the reference. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in a reference. However, the comment does not provide specific details or examples from the reference to support the claim, nor does it explain why this discussion is important or how it would enhance the paper. Without additional context or references, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in a reference. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting a connection to existing literature. However, the comment lacks specificity and does not provide detailed guidance on how to integrate this discussion into the paper or what aspects of the results should be highlighted. While it identifies a relevant area for expansion, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment implies that the authors should provide more information on the assumptions and their validity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their impact on the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are mentioned, making it weakly grounded. The comment is specific in detailing the concerns about the assumptions and the lack of clarity regarding the significance of the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of using PCA to reduce interaction count is incremental and questions the significance of the paper results. The reviewer provides a reference to a paper by Dombrowski et al. (2022) that discusses robust explanations for deep neural networks, suggesting that PCA is a well-known technique. This reference supports the claim by providing a context for understanding the assumptions and limitations of PCA. However, the comment could be strengthened by further elaborating on how the assumptions impact the results or by providing more specific examples from the paper under review. Overall, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or examples directly from the paper. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve the clarity of their work. The feedback is somewhat helpful as it prompts the authors to consider the assumptions and their impact on the results, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the state-of-the-art models considered in the paper, specifically mentioning that the few-shot RC models are not state-of-the-art. It questions how the performance of these models compares to relation extraction/generation models in few-shot settings. While the comment implies that the authors should compare their models to state-of-the-art models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"few-shot RC models\" considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance of these models compared to relation extraction/generation models in few-shot settings, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the few-shot RC models considered in the paper are not state-of-the-art, providing specific examples of models that are considered state-of-the-art. This claim is supported by references to external works, which provides a clear basis for the assertion. However, the comment could be strengthened by including more detailed comparisons or specific metrics to demonstrate the gap in performance. Overall, the claim is mostly verifiable, as it provides a solid foundation for the assertion but lacks comprehensive evidence or detailed analysis. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the few-shot RC models considered are not state-of-the-art. It provides examples of state-of-the-art models and questions how the performance of the models in the paper compares to relation extraction/generation models in few-shot settings. This feedback is clear and actionable, as it prompts the authors to consider updating their models to align with current state-of-the-art methods. By addressing this point, the authors can enhance the relevance and impact of their work. However, the comment could be more helpful if it included suggestions on how to conduct the comparison or what specific metrics to use. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the results in Section 4 only apply to shallow fully-connected ReLU networks. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this limitation, whether it should be clarified, or if it affects the generalizability of the results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, stating that they only apply to shallow fully-connected ReLU networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results in Section 4 only apply to shallow fully-connected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the validity of their results. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific limitation in the results presented in Section 4, stating that they only apply to shallow fully-connected ReLU networks. While this is a relevant observation, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand the applicability of their results. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, it does not specify how the authors should achieve this improvement or what specific changes should be made. The action is implicit and vague, as the authors are left to infer that they need to reorganize the paper but without detailed guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, it does not specify which part of the paper is currently lacking in these aspects, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is vague and lacks specific guidance, leaving the authors without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the paper. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or explanation to fully substantiate the recommendation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the organization of the paper, suggesting that more background knowledge on the proposed method and a forward placement of related literature descriptions could enhance the paper. While the comment highlights a specific aspect that could be addressed, it lacks detailed guidance or suggestions on how to implement these changes. The feedback is somewhat helpful as it points out a general area for improvement, but it does not provide actionable steps or examples to help the authors make the necessary revisions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some representative panoptic segmentation models, such as PanopticFPN, Mask2Former, etc., are not compared in the paper. While the comment identifies a specific area for improvement, it does not provide explicit guidance on which models should be included or how they should be integrated into the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include these models in their comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue by mentioning that \"Some other representative panoptic segmentation models are not compared, like PanopticFPN, Mask2Former, etc.\" However, it does not specify which part of the paper this comparison should be included in, such as a section or table. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in identifying the missing comparisons, but it lacks full grounding as it does not explicitly mention the relevant sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"Some other representative panoptic segmentation models are not compared, like PanopticFPN, Mask2Former, etc.\" However, it does not provide any reasoning or justification for why these models should be included in the comparison. Without specific examples or explanations of how these models would enhance the study, the claim lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. This feedback is clear and actionable, as it provides the authors with a specific direction for enhancing their work by including additional models in their evaluation. However, the comment could be more helpful if it suggested why these models are relevant or how they might impact the results. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to provide results on the discussion of using sequential MCB vs a single MCT layers for the decision head. This is a clear and direct action for the authors to take, as it specifies what additional information is needed to improve the draft. The comment provides a concrete suggestion on how to enhance the paper by including results related to this discussion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to speak about what was observed in this context, providing clear guidance on what additional information is needed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses an interest in the discussion of using sequential MCB vs a single MCT layers for the decision head and requests additional information on what was observed. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional information, which is factual in nature. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting that the discussion of using sequential MCB vs a single MCT layers for the decision head is interesting but lacks results. It provides a clear and actionable suggestion for the authors to speak about what was observed in this context, which could enhance the paper by providing additional insights or evidence. This feedback is specific and offers a concrete way for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it included suggestions on how to present these results or what specific aspects to focus on. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts: a request for sensitivity analysis regarding other hyper-parameters and a list of minor language issues. The first part is explicit and actionable, as it clearly instructs the authors to conduct a sensitivity analysis on other hyper-parameters. The second part is also explicit, as it provides specific examples of language issues that need to be corrected. However, the second part lacks concrete guidance on how to address the language issues, such as suggesting alternative phrasing or providing examples of correct usage. Overall, the comment is mostly actionable, as it provides clear instructions for both parts, but the lack of detailed guidance on language issues limits its full actionability.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"above of (7),\" \"Theorem 1,\" and \"above of (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear examples of language issues that need to be corrected, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" This level of detail guides the authors on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for sensitivity analysis regarding other hyper-parameters and a list of minor language issues. The first part is a suggestion for additional analysis, which is not a claim and does not require verification. The second part is a request for proofreading and correction of language issues, which is a factual statement and does not contain a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a mix of feedback. It suggests conducting a sensitivity analysis on other hyper-parameters, which is a clear and actionable suggestion for improving the paper. This part of the comment is highly helpful as it guides the authors to explore additional aspects of their work. However, the second part of the comment consists of minor language issues, which are listed without specific guidance on how to correct them. While the authors are instructed to proofread and fix these issues, the lack of detailed feedback on language usage limits the comment\\'s overall helpfulness. Therefore, the comment is rated as somewhat helpful, as it offers valuable insights but could be more comprehensive in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information about the choice of distribution sets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper discusses this choice, making it weakly grounded. The comment is specific in its questions about the choice of distribution sets and the potential impact of selecting fewer sets. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or important. Without additional context or explanation, the authors may find it challenging to understand the significance of these questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it does not provide actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluative framework is limited in scope, considering only three Question-Answering tasks and two language models. It raises concerns about the framework\\'s applicability to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance or suggestions on how the authors might expand the scope of their framework or address these concerns. The action is implicit and vague, as the authors are left to infer that they should consider broader applicability but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the scope of the evaluative framework, specifically mentioning the limited consideration of three Question-Answering tasks and two language models. It raises concerns about the framework\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not specify which part of the paper discusses the evaluative framework, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper. The comment is specific in detailing the limitations and potential areas for expansion, but the lack of grounding reduces its overall clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, considering only three Question-Answering tasks and two language models. It suggests that the framework\\'s applicability to other reasoning or generation tasks or more advanced models, such as vicunna or alpaca, is uncertain. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises concerns about the framework\\'s applicability to other reasoning or generation tasks and more advanced models, such as vicunna or alpaca. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s methodology and suggests areas for expansion or generalization. However, the comment lacks specific guidance or suggestions on how the authors might address these limitations, such as proposing additional tasks or models to include in the evaluation. While it provides some insight into the scope of the work, it could be more helpful with actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should showcase their approach using transformer-based (masked) language models instead of obsolete language models like n-gram HMM and RNN, which are no longer commonly used. This comment explicitly states an action for the authors to take, which is to update their experiments to align with current NLP trends. The suggestion is clear and provides a concrete direction for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the use of \"obsolete language models\" like n-gram HMM and RNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the language models used and suggests an alternative approach using transformer-based (masked) language models to better align with current NLP trends. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the perplexity experiments are conducted on obsolete language models (n-gram HMM and RNN) that are no longer commonly used. The reviewer suggests that the authors should showcase their approach using transformer-based (masked) language models to better align with current NLP trends. While the claim is based on a logical reasoning that the models used are outdated, it lacks specific references or detailed explanations of why these models are no longer relevant. This makes the claim somewhat verifiable, as the authors would need to further substantiate the claim with evidence or references to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on obsolete language models (n-gram HMM and RNN) that are no longer commonly used. It suggests that the authors should showcase their approach using transformer-based (masked) language models to better align with current NLP trends. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the relevance and impact of their work. By addressing this feedback, the authors can enhance the credibility and applicability of their research. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments should be conducted to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the results from Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and referencing relevant literature. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the sufficiency of the experiments, specifically mentioning the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also suggests citing the results from Kaplan et al. 2020. However, the comment does not specify which part of the paper these experiments should be conducted in, making it weakly grounded. The authors can infer that it relates to the experimental sections, but the lack of explicit references makes it challenging to pinpoint the exact areas needing attention. The comment is specific in suggesting additional experiments and referencing external work, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient and suggests conducting more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the results from Kaplan et al. 2020. While the suggestion to conduct additional experiments is logical, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the insufficiency of the experiments. It suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. Additionally, it mentions the importance of citing the results from Kaplan et al. 2020. This feedback is clear and actionable, providing the authors with specific directions for improving the experimental section of their paper. By addressing these points, the authors can strengthen the validity and credibility of their work. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to resolve the problem. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the estimation of mu, which is discussed in the paper. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of mu, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the discussion on the misestimation of mu is unclear, specifically questioning how mu, which represents the proportion of missing observations, can be estimated. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the estimation of mu, which represents the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific way to present the performance of the algorithm by considering the sensitivity to initialization. It provides a clear and concrete action for the authors to take, which is to present the performance as a function of the distance of initialization to the ground-truth. The comment also specifies how to implement this suggestion by providing a range of distances (0.01:0.01:0.1) and a method for sampling matrices. This level of detail ensures that the authors know exactly what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests presenting the performance as a function of the distance of initialization to the ground-truth, which provides a clear and specific direction for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests presenting the performance as a function of the distance of initialization to the ground-truth, which is a logical and reasonable suggestion. The reviewer provides a clear explanation of how this could be done, including a specific method for sampling matrices and reporting performance. This level of detail and reasoning makes the claim fully verifiable, as it provides a concrete and actionable suggestion for improving the paper. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of the paper. It recommends presenting the performance as a function of the distance of initialization to the ground-truth, which could provide valuable insights into the algorithm\\'s sensitivity to initialization. The comment offers a clear and detailed method for implementing this suggestion, including a range of distances and a sampling approach. This level of guidance empowers the authors to make a significant improvement to their draft by enhancing the understanding of their algorithm\\'s performance. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, providing a clear direction for the authors to address the concern. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that the absolute value is not needed for real numbers, which is a common knowledge in mathematics. However, the comment could be strengthened by providing a reference or further explanation to support the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks specific references or detailed reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a minor issue with the definition of the Frobenius norm, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their draft. By addressing this minor detail, the authors can ensure the accuracy and clarity of their mathematical definitions. However, the comment could be more helpful if it provided additional context or explained why this correction is important. Overall, the comment is mostly helpful as it directs the authors to a specific improvement that can enhance the rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that only bounds in expectation are provided and asks for high-probability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment implies that the authors should provide high-probability bounds and consider adding measures of robustness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that only bounds in expectation are provided and asks for high-probability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in detailing what needs to be addressed, such as providing high-probability bounds and adding measures of robustness. However, the lack of explicit section references makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that only bounds in expectation are provided and suggests that high-probability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. The comment provides a logical reasoning for the suggestion, as ensemble methods are known to provide high-probability bounds, and the addition of measures like error bars or standard deviation would enhance the robustness analysis. However, the comment could be strengthened by providing specific examples or references to support the claim about ensemble methods and high-probability bounds. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that only bounds in expectation are provided and suggests that high-probability bounds would be beneficial. It provides a concrete suggestion by recommending the use of ensemble methods as performed in the experiments, which could help achieve these high-probability bounds. Additionally, the comment suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, offering the authors specific ways to enhance their work by addressing the identified limitations. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the comment is mostly helpful as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the reviewer\\'s lack of expertise in the area of pruning and expresses a positive opinion about the motivation of the paper. However, it suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not provide explicit guidance on how to implement these evaluations or what specific metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the reviewer\\'s lack of expertise in the area of pruning and expresses a positive opinion about the motivation of the paper. However, it suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency, memory consumption, and network size. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the results or evaluation sections. The suggestion to consider additional aspects is specific, providing clear guidance on what the authors could address. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the reviewer\\'s lack of expertise in the area of pruning and expresses a positive opinion about the motivation of the paper. However, it suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency, memory consumption, and network size. While the comment provides a logical reasoning for the suggestion to evaluate the results from different perspectives, it lacks specific examples or references to support the claim that the results are less impressive. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or context to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the reviewer\\'s lack of expertise in the area of pruning but provides a positive assessment of the paper\\'s motivation. However, it suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency, memory consumption, and network size. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting additional metrics for evaluation. However, it lacks specific guidance on how to implement these evaluations or what specific changes might be necessary to enhance the results. While it provides some direction, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to incorporate diversity into the model or suggestions for improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the extensive motivation for diversity and the lack of explicit enforcement of diversity in the model. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper extensively motivates \"diversity\" but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity enforcement, suggesting that the authors' efforts to incorporate diversity are not evident. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed justification or evidence, the claim remains somewhat verifiable, as it provides a general critique but lacks the necessary depth to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. This feedback is valuable as it highlights a potential disconnect between the theoretical framework and its practical implementation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate diversity into their model. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides insight but lacks depth and actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their study. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment mentions that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to enhance their study by including these experiments. However, the comment could be more helpful if it explained why these experiments are important or how they would contribute to the overall understanding of the research. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a gap between the lower bound and the upper-bound, specifically mentioning that the existing bound with the independence number may be better for some graphs. It also mentions that this is true for the results on the adaptive adversary and the counterfactual feedback. However, the comment does not provide explicit guidance on how to address this gap or improve the bounds. The authors are left to infer that they should investigate the existing bound with the independence number and potentially explore other methods to improve the bounds. While the action is implicit, it is somewhat vague as it lacks specific instructions on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the bounds, mentioning a gap between the lower bound and the upper-bound, specifically noting the use of \\sqrt(\\beta) instead of \\beta^{1/3}. It also mentions that the existing bound with the independence number may be better for some graphs and that this is true for the results on the adaptive adversary and the counterfactual feedback. However, the comment does not specify which sections or results these issues pertain to, making it weakly grounded. The comment is specific in detailing the issue with the bounds but lacks grounding, as the authors cannot confidently determine which parts of the paper are being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a gap between the lower bound and the upper-bound, specifically mentioning the use of \\sqrt(\\beta) instead of \\beta^{1/3}. It also suggests that the existing bound with the independence number may be better for some graphs and that this is true for the results on the adaptive adversary and the counterfactual feedback. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to invest additional effort to verify the claims themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the bounds, noting a gap between the lower bound and the upper-bound, particularly regarding the use of \\sqrt(\\beta) instead of \\beta^{1/3}. It also suggests that the existing bound with the independence number may be better for some graphs and that this is true for the results on the adaptive adversary and the counterfactual feedback. While the comment highlights a potential issue, it lacks detailed guidance or suggestions on how the authors might address this gap or improve the bounds. The feedback is somewhat helpful as it points out a specific area for improvement, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FIDs\" and \"DinoV2 Frechet Distances,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the use of FIDs and suggests using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that FIDs have clear flaws and suggests using DinoV2 Frechet Distances for comparisons. However, it does not provide specific examples or detailed reasoning to support the claim about the flaws in FIDs. The reference to [C] is not sufficient to fully substantiate the claim, making it somewhat verifiable. The authors would need to investigate the referenced work to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to consider using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is specific and offers a concrete way to improve the evaluation methodology, which is particularly important in the context of image generation. By suggesting an alternative metric, the comment empowers the authors to enhance the rigor and relevance of their comparisons. However, the comment could be more helpful if it included a brief explanation of why DinoV2 Frechet Distances might be a better choice or how it addresses the flaws in FIDs. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the novelty of the paper, questioning whether it is merely an incremental improvement over a previous work. It asks for clarification on how the current paper differs from the referenced work and suggests that it might be applying a similar methodology to a new task. While the comment implies that the authors should provide a clear explanation of their novelty, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of novelty and provide a detailed comparison with the referenced work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the novelty of the paper, specifically questioning whether it is merely an incremental improvement over a previous work. It references a specific paper, \"https://aclanthology.org/2021.findings-acl.57.pdf,\" which provides some grounding by indicating a specific work to compare against. However, the comment does not specify which part of the paper should be revised to address this concern, making it weakly grounded. The comment is specific in its request for clarification on the differences between the current paper and the referenced work, but it lacks detailed guidance on how to address the issue of novelty. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the novelty of the paper, suggesting that it is merely an incremental improvement over a previous work. The reviewer supports this claim by referencing a specific paper, \"https://aclanthology.org/2021.findings-acl.57.pdf,\" and asking for clarification on how the current paper differs. This provides some level of support, as it directs the authors to consider the novelty of their work in relation to a specific reference. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the paper, suggesting that it may be an incremental improvement over a previous work. It questions whether the current paper merely applies a similar methodology to a new task. This feedback is somewhat helpful as it prompts the authors to clarify the novelty and distinctiveness of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this concern, such as recommending a detailed comparison with the referenced work or suggesting ways to highlight the unique contributions. While it identifies an area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results in Table 2, specifically regarding the performance of the complete loss function compared to those with some terms missing. The reviewer questions the logic behind this observation, asking for an explanation. While the comment implies that the authors should provide an explanation for this unexpected result, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reported ablation studies, specifically questioning the performance of the complete loss function compared to those with some terms missing. The comment clearly specifies what needs to be addressed, which is the explanation for this unexpected result. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results in Table 2, specifically the performance of the complete loss function compared to those with some terms missing. The reviewer points out that the complete loss function performed worse than expected, which is a claim that requires justification. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this result is unexpected or how it might be addressed. Without additional context or explanation, the claim remains unverifiable, as the authors are left without guidance on how to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reported ablation studies in Table 2, noting that the complete loss function performed worse than expected for the CUB and SOP datasets. This observation raises a question about the logic behind this result, prompting the authors to provide an explanation. While the comment highlights a potential area of concern, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it points out a potential problem, but it lacks depth and actionable advice, leaving the authors with a clear question to answer but without a clear path to improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data. It provides a clear rationale for why this experiment is important, highlighting its potential to assess the model\\'s long-range inference capacity. The reviewer also indicates that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data. It provides a clear rationale for why this experiment is important, specifically to assess the model\\'s long-range inference capacity. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might infer that it relates to the experimental setup or results, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what the authors should do to improve their draft, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an experiment where the image is occluded to simulate irregularities in neural/behavioral data. The reviewer provides a clear rationale for why this experiment is important, specifically to assess the model\\'s long-range inference capacity. However, the comment lacks specific examples or references to support the claim that such experiments are necessary or beneficial. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable, as the authors may need more information to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending an experiment where the image is occluded to simulate irregularities in neural/behavioral data. This suggestion is based on a logical rationale, as it would allow the authors to assess the model\\'s long-range inference capacity. The comment also emphasizes the importance of including these experiments in the final version, unless the authors can provide a convincing reason otherwise. This feedback is clear and provides the authors with a concrete direction for enhancing their draft, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward because it implies negative rates, which is not the case. The reviewer recommends using a second y-axis or another visualization that is more physically accurate. This feedback is explicit and provides a clear action for the authors to take, which is to revise the visualization to better represent the data. The suggestion is also concrete, as it specifies the use of a second y-axis or another visualization. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when this is not the case, and suggests using a second y-axis or another visualization to make it more physically accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward because it implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization to make it more physically accurate. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a second y-axis or alternative visualization is logical but not thoroughly explained. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when this is not the case. It provides a clear and actionable suggestion to address this issue by recommending the use of a second y-axis or another visualization that is more physically accurate. This feedback is valuable as it directs the authors to a specific area of their draft that requires improvement and offers a concrete solution. By following this advice, the authors can enhance the clarity and accuracy of their presentation, making the comment mostly helpful. However, it could be more helpful if it included additional context or explanation about why the current visualization is problematic or how the suggested changes would improve the figure. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors could introduce inverse triples in other embedding models besides CP and test such cases in their experiments. However, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should test the use of inverse triples in other embedding models but are not given specific details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors could introduce inverse triples in other embedding models besides CP and test such cases in their experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or results section, but this inference is not explicit. Additionally, the comment lacks specificity regarding what aspects of other embedding models should be tested or how to implement the suggestion. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors could introduce inverse triples in other embedding models besides CP and test such cases in their experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this suggestion would be beneficial or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could introduce inverse triples in other embedding models besides CP and test such cases in their experiments. While this feedback identifies a potential area for expansion or exploration, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. The comment highlights a possible improvement but does not offer actionable steps or a clear rationale for the authors to follow. Therefore, it is somewhat helpful, as it provides a direction for further research but lacks depth and detail.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that a statement in the abstract is unclear and suggests that the abstract should be more high-level, avoiding technicalities. However, it does not provide specific guidance on how to rephrase the statement or what aspects of it are unclear. The action is implicit, as the authors need to infer that they should simplify the language in the abstract, but it is vague because it lacks concrete details on how to achieve this simplification. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear in the abstract, namely the statement about ensuring low-rank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more high-level and avoid technicalities. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a statement in the abstract is unclear and suggests that the abstract should be more high-level, avoiding technicalities. However, the comment does not provide any specific reasoning or examples to support why the statement is unclear or how it could be improved. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and should be simplified. It provides a clear suggestion to make the abstract more high-level and avoid technicalities, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of it are unclear. Despite this, the feedback is mostly helpful as it directs the authors to improve the clarity and accessibility of their abstract, which is crucial for readers to understand the paper\\'s main contributions. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any explicit guidance or concrete suggestions on how to achieve this improvement. The authors are left to infer that they should enhance the algorithm\\'s complexity, but without specific details or examples, it is difficult to determine what changes might be necessary. This lack of direction makes the comment vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"Algorithm 2,\" which provides full grounding as it allows the authors to accurately identify the specific part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspects of the algorithm\\'s complexity need improvement or how it could be enhanced. The authors are left to infer the specific areas that require attention, making the comment weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential area for improvement in the complexity of Algorithm 2, suggesting that there is room for enhancement. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might improve the algorithm\\'s complexity. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, as it points out a possible area for improvement but does not offer meaningful guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding results in other modalities, specifically mentioning language-related tasks. It also implies that expected test loss might not be as meaningful for language-related tasks. While the comment provides a general direction for expanding the results, it lacks specific guidance on which modalities to include or how to present the results. The authors can infer that they need to expand their results to other modalities, but the comment does not provide concrete steps or details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding results in other modalities, specifically mentioning language-related tasks. It also implies that expected test loss might not be as meaningful for language-related tasks. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting the inclusion of results in other modalities, particularly language-related tasks, and provides a rationale for why expected test loss might not be as relevant. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding results in other modalities, specifically mentioning language-related tasks. It also implies that expected test loss might not be as meaningful for language-related tasks. However, the comment lacks specific reasoning or references to support why these suggestions are necessary or beneficial. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests expanding the results to include other modalities, particularly language-related tasks. It also implies that expected test loss might not be as meaningful for language-related tasks, suggesting that other metrics or evaluations might be more relevant. While the comment provides a direction for improvement, it lacks specific guidance on which language-related tasks to consider or how to present the results. Additionally, it does not offer detailed suggestions on how to incorporate these changes into the paper. Despite this, the comment identifies a potential area for expansion and improvement, making it somewhat helpful for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the motivation of the work should be further justified, specifically addressing the use of \"few-shot\" in graph link prediction. It highlights the need to explain how the proposed method effectively uses \"few-shot\" and guarantees generalizability to new tasks with 0/few training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the work, specifically the use of \"few-shot\" in graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"few-shot\" and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the issues with generalizability are presented, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the motivation and generalizability of the work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work should be further justified, specifically regarding the use of \"few-shot\" in graph link prediction. The reviewer provides a logical reasoning by explaining that in few-shot learning, the focus is typically on leveraging a few instances to learn a generalizable model. However, the comment lacks specific examples or references to support the claim that the proposed method does not effectively use \"few-shot\" or guarantee generalizability. This makes the claim somewhat verifiable, as it provides a logical framework but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the motivation and justification of the work. It highlights the need to explain how the proposed method effectively uses \"few-shot\" and guarantees generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to provide a more thorough explanation of their approach and its benefits. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their approach. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or methodology where GP is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the GP approach are considered naive or how the authors might improve their use of GP. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the use of GP is \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general direction but requires more information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. While the comment identifies a potential weakness in the paper, it lacks specificity and actionable feedback. It does not provide guidance on how the authors might address this critique or improve their approach to GP modeling. Without detailed suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer suggests that this claim is not supported by their experience and references a study by Zaremba et al. (2014) that trains 1500-dimensional LSTMs on PTB. The comment also questions whether dropout is applied to the hidden states, implying that this information should be clarified. While the comment raises valid questions and points out potential issues, it does not provide explicit instructions on how to address these concerns. The authors can infer that they need to clarify the statement and potentially provide additional details about the regularization methods used, but the action is not directly stated. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs), referencing a study by Zaremba et al. (2014) as a counterexample. Additionally, it raises a question about whether dropout is applied to the hidden states, which further specifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models are not properly regularized. This provides a logical reasoning and a specific reference to support the claim that the statement in the paper is questionable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study. Overall, the claim is mostly verifiable, as it provides a solid foundation for the authors to address the issue but lacks complete evidence or detailed analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a question about a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014) to challenge the claim, suggesting that the baseline models may not be properly regularized. This feedback is valuable as it prompts the authors to reconsider their statement and potentially provide additional evidence or clarification. Additionally, the comment raises a question about whether dropout is applied to the hidden states, which could be a relevant detail for the authors to address. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or provided additional context. Overall, the comment is mostly helpful as it identifies a potential weakness and prompts the authors to clarify their claims, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some ablations mentioned in previous sections are hard to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly difficult to locate. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"some ablations\" that are hard to locate, but it does not specify which ablations or sections are being referred to. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs improvement. Additionally, the comment does not provide specific details on what needs to be addressed or improved in the writing. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some ablations mentioned in previous sections are hard to locate in the following contents. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the specific ablations or sections, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are hard to locate in the following contents. This feedback highlights a potential problem with the organization or presentation of the ablation results, which could impact the clarity and accessibility of the paper. However, the comment lacks specificity and does not provide detailed guidance on how to address this issue or suggest ways to improve the organization or presentation of the ablation results. While it points out a weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. While the comment implies that the authors should improve their work, it does not provide specific guidance on how to enhance the differential privacy application or what aspects need more clarity. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"given2)-5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. Additionally, it provides a suggestion to move the experimental results from the appendix to the main paper. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the differential privacy application is \"half-baked\" and suggests that the authors should think through it more clearly. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides some helpful feedback by suggesting that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which is a positive observation. However, the comment lacks specificity and actionable guidance on how the authors might improve the differential privacy application or what aspects need more clarity. Without detailed suggestions or examples, the authors may find it challenging to effectively address the feedback. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this perceived lack of contribution or improve their work based on this feedback. As a result, the comment lacks actionability, leaving the authors without any direction on how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without actionable feedback or constructive criticism, the authors are left without a clear understanding of how to address this perceived issue or enhance their work. Therefore, the comment is not helpful at all, as it does not provide any value to the authors in terms of improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be applied more broadly to robotic manipulation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the scope of their methodology, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology description. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the methodology\\'s applicability, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation and could be more broadly applicable to robotic manipulation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but requires more detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. This is a relevant point that could help the authors clarify the scope of their work and potentially expand its applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or modifications to the methodology. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide the METEOR results, which is also reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be included in the draft. The comment provides concrete guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to provide METEOR results, which are also reported in recent works. This allows the authors to accurately identify the part of the paper that needs attention, such as the results section. The comment is also specific because it clearly specifies what is missing, namely the METEOR results, and references recent works where these results are reported. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. This is a request for additional information, not a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, instructing the authors to provide METEOR results, which are also reported in recent works. This feedback is specific and provides a direct suggestion for improvement, allowing the authors to enhance their draft by including additional results. However, the comment could be more helpful if it explained why METEOR results are important or how they would contribute to the paper\\'s findings. Despite this, the comment is mostly helpful as it guides the authors toward a concrete improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the comparability of G-effect values across different unlearning objectives and approaches, suggesting that studying each objective in isolation may affect the comparability of results. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the comparability of their results. The comment implies that the authors should consider comparing results across different objectives and approaches, but it lacks concrete details on how to implement this comparison. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4\" and \"separate figures and parts of the paper,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of G-effect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of G-effect values across different unlearning objectives and approaches, suggesting that studying each objective in isolation may affect the comparability of results. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a general concern but lacks the necessary details for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology used in the paper, specifically the examination of G-effects of each unlearning objective in isolation. It raises a concern about the comparability of G-effect values across different unlearning objectives and approaches, which could impact the interpretation of results. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the comparability of their results. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the advantage of the UNIFORM procedure over other methods, particularly in the 1-shot setting. It questions the authors\\' theory for why the method is not as effective in this setting. While the comment implies that the authors should provide a theory or explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the advantage of the UNIFORM procedure over other methods, specifically in the 1-shot setting. It mentions the tables showing inconsistent results and questions the authors\\' theory for why the method is not as effective in this setting. However, the comment does not specify which tables or sections of the paper are being referred to, making it weakly grounded. The comment is specific in its request for a theory or explanation regarding the method\\'s effectiveness in the 1-shot setting. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1-shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage over the results. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim. While it provides some evidence, the lack of detailed reasoning or references makes the claim somewhat verifiable. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the advantage of the UNIFORM procedure over other methods, particularly in the 1-shot setting. It points out that the tables show inconsistent results, questioning the effectiveness of the method in this setting. The comment also suggests that the authors should provide a theory or explanation for why the method is not as effective in the 1-shot setting. This feedback is clear and actionable, as it directs the authors to address a specific concern and potentially improve their understanding of the method\\'s performance. However, the comment could be more helpful if it provided additional guidance on how to develop this theory or explanation. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a critical issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason for the information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. While the comment implies that the authors should explore this further, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate an existing theory. The action is implicit and somewhat vague, as the authors need to infer that they should investigate existing theories and integrate them into their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages (7 and 8) where the issue is discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the reason for the information value being a stronger predictor for dialogue and suggests that including an explanation from an existing linguistic theory would strengthen the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reason for the information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. However, the comment does not provide any specific references or detailed reasoning to support the claim that an existing linguistic theory could explain this phenomenon. The suggestion is somewhat verifiable, as it points to a potential area for improvement, but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the reason for the information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. This feedback is clear and actionable, as it directs the authors to explore existing theories that could provide a deeper understanding of their findings. By addressing this point, the authors can enhance the theoretical foundation and significance of their work. However, the comment could be more helpful if it provided specific examples of relevant linguistic theories or suggested how to integrate them into the paper. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missed opportunity in the paper to discuss the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the potential benefits and takeaways of AutoML approaches. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could inform the design of new network architectures. However, it does not specify which part of the paper should include this discussion or where the authors should focus their efforts. While the authors might infer that this relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in suggesting what the authors should discuss, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should discuss the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could inform the design of new network architectures. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this discussion based on the general idea presented. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the authors should discuss the benefits of using AutoML approaches beyond improving raw performances. It highlights the importance of extracting \"hints\" that could inform the design of new network architectures in the future. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as what aspects of the AutoML approach should be discussed or how to present the \"hints\" effectively. While it points out a relevant area for expansion, the feedback is somewhat vague and incomplete, making it somewhat helpful for the authors to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the definition of T_a(t), noting that it is used in Section 3.1 but is only defined in Section 4. This feedback is explicit and provides a clear action for the authors to take: ensure that T_a(t) is defined before it is used in Section 3.1. The comment is also concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the definition of T_a(t), informing the authors that it is used in Section 3.1 but is only defined in Section 4. This provides clear guidance on what needs to be addressed to ensure consistency and clarity in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the usage and definition of T_a(t) in different sections of the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that T_a(t) is used in Section 3.1 but is only defined in Section 4. This feedback is clear and actionable, as it points out a logical inconsistency that could confuse readers. By highlighting this discrepancy, the comment provides the authors with a direct way to improve the clarity and coherence of their draft. However, it could be more helpful if it suggested a potential solution, such as moving the definition to Section 3.1 or providing a clear explanation of the delay in the definition. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not provide specific guidance on how to achieve this conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without detailed instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the paper is currently too verbose or what specific empirical results should be included. This lack of specificity makes it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment does not provide any grounding by not mentioning specific sections, figures, or tables, making it challenging for the authors to determine which parts of the paper are being addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not provide any specific reasoning, examples, or references to support why the current content is too verbose or how the inclusion of empirical results would improve the paper. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. The feedback is somewhat helpful as it points out a general area for improvement, but it does not offer actionable steps or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the empirical analysis in Figure 3, specifically questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score and their impact on model prediction accuracy. The reviewer also notes the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies specific areas needing clarification, it does not provide explicit instructions on how the authors should address these issues. The authors are left to infer that they need to provide additional explanations and potentially revise the formatting of the equations. However, the lack of concrete guidance on how to improve the clarity or formatting makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the confusion regarding the empirical analysis and the adjustments to the amplitudes, as well as the large spacing between equations. The comment provides clear guidance on what needs to be clarified or improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the empirical analysis in Figure 3, specifically questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. The reviewer also notes the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies areas of confusion, it lacks specific examples or detailed reasoning to support the claim that the adjustments are confusing or ineffective. The reference to Liu et al. (2022) is not directly related to the critique of the empirical analysis, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the empirical analysis in Figure 3, questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. It also points out the large spacing between Equations (9) and (10) and the preceding text. While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to specific areas that require further explanation, but it lacks actionable advice or examples to improve the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the recent related work CoCoOp should be compared in the experiments, even though it is a CVPR\\'22 work that was published after the NeurIPS deadline. The reviewer provides a clear and direct action for the authors to take, which is to include a comparison with CoCoOp in their experiments. This feedback is specific and actionable, as it provides a concrete step for the authors to follow. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the recent related work \"CoCoOp\" and the need to compare it in the experiments. This allows the authors to accurately identify the part of the paper being addressed, specifically the experimental section. The comment is also specific because it clearly specifies what needs to be addressed, which is the comparison with CoCoOp. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent related work CoCoOp should be compared in the experiments, even though it is a CVPR\\'22 work that was published after the NeurIPS deadline. The reviewer provides a logical reasoning by stating that CoCoOp is an extended version of CoOp, which is relevant to the paper. However, the comment lacks specific references or detailed justification for why CoCoOp should be included in the experiments, making it somewhat verifiable. The authors would need to further explore the relevance and significance of CoCoOp to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper\\'s experimental comparison, noting that the recent related work CoCoOp should be included despite being published after the NeurIPS deadline. This feedback is clear and actionable, as it provides a direct suggestion for the authors to enhance the comprehensiveness of their experimental evaluation. By including CoCoOp, the authors can provide a more complete comparison and ensure that their work is accurately positioned within the current literature. However, the comment could be more helpful if it explained why CoCoOp is relevant or how it relates to the paper\\'s findings. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the use of model training to optimize the selection modules. While the comment implies that the authors should make these changes to improve the figure, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed and how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, suggesting that the figure could be drawn better to show the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring, along with showing where model training is being used to optimize the selection modules. This level of detail provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide any specific reasoning or evidence to support why these changes would improve the figure or the paper. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the use of model training to optimize the selection modules. While the comment identifies specific areas for improvement in the figure, it lacks detailed guidance on how to implement these suggestions or what specific changes should be made. The feedback is somewhat helpful as it points out a potential enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not provide specific guidance on which complex problems to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors are left to infer the need for additional experiments without detailed instructions on how to implement them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the need for more complex experiments, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, the comment lacks specific examples or references to support this claim, such as mentioning particular games or experiments that could be conducted. Without detailed evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 3: Somewhat Verifiable, as it provides a general suggestion but lacks the necessary details for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the current experiments may not adequately address more complex scenarios. However, the comment lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific complexities should be considered. While it points out a direction for further exploration, it does not offer actionable steps or detailed suggestions, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that abbreviations like \"MoCo\" should not appear in the section header, as a reader might not know what they mean. This provides a clear and direct action for the authors to take, which is to avoid using abbreviations in section headers. The comment is explicit and provides concrete guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section number (136), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with abbreviations like \"MoCo\" appearing in the section header, explaining that a reader might not know what they mean. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement about the use of abbreviations in section headers, suggesting that abbreviations like \"MoCo\" might not be understood by readers. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations like \"MoCo\" in the section header, suggesting that it might not be clear to readers. This feedback is clear and actionable, as it provides a direct suggestion to avoid using abbreviations in section headers to improve clarity. However, the comment could be more helpful if it offered alternative ways to introduce these abbreviations or provided examples of how to present them more clearly. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how to clarify the technical contribution or what aspects of the analysis could be improved. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of what needs to be done to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that most of the analysis is standard. However, it does not specify which part of the paper is being addressed, nor does it provide details on what aspects of the analysis are considered standard or how they could be improved. Without specific references or examples, the authors cannot effectively identify the areas needing revision. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references to what aspects are unclear or standard, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to improve the clarity or originality of the technical contribution. Without detailed guidance or examples, the authors are left without a clear understanding of what needs to be addressed or how to enhance their work. Therefore, the comment is not helpful at all, as it does not offer any actionable insights for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach. It suggests that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific evidence or arguments are lacking. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more substantial evidence or arguments to support their contribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s primary contribution, which is described as an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for more substantial evidence or arguments to establish the contribution as significant. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s primary contribution is an incremental advancement over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the gaps in the argument themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s primary contribution, suggesting that it is an incremental advancement over the TACTiS approach. It highlights the need for more substantial evidence or arguments to establish this contribution as significant. While the comment points out an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or provide the necessary evidence. The feedback is somewhat helpful as it prompts the authors to consider strengthening their contribution claims, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty and incremental nature of the paper, stating that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not provide any specific guidance or suggestions for improvement. The authors are left without actionable steps to address the concerns raised, such as how to enhance the novelty or differentiate their work from existing literature. Without concrete advice or suggestions, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty and incremental nature of the paper, specifically mentioning that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not specify which parts of the paper are being addressed, such as which datasets or sections are discussed. This lack of explicit reference to specific sections or elements of the paper makes it difficult for the authors to pinpoint the exact areas needing revision. Additionally, the comment lacks specificity in terms of what aspects of the paper are considered trivial or incremental. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, citing that many previous works have focused on the same topic. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or references, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty and incremental nature of the paper, stating that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their work need to be revised or how to enhance the novelty of their contributions. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While it identifies an area that needs further exploration, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a discussion on the theoretical guarantee but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing discussion on the theoretical guarantee, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address by including a discussion on the theoretical guarantee. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what aspects to consider. Despite this, the feedback is mostly helpful as it directs the authors to an important area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measures to evaluate the generated VCEs, noting that evaluation is primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to introduce quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is primarily based on visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of generated VCEs lacks quantitative measures and is primarily based on visual inspection. This claim is somewhat verifiable as it highlights a potential gap in the evaluation process, but it lacks specific examples or references to support the assertion. The comment does not provide detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it is primarily based on visual inspection rather than quantitative measures. This feedback is valuable as it highlights a gap in the evaluation methodology, prompting the authors to consider incorporating quantitative metrics to enhance the rigor and objectivity of their evaluation. However, the comment could be more helpful if it suggested specific quantitative measures or provided examples of how such measures could be implemented. Despite this, the feedback is clear and actionable, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of marginal improvements or how to improve the method\\'s performance. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the method compared to baselines, specifically mentioning the error range and the claim of better performance. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing the issue with the marginal improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. This claim is somewhat verifiable as it provides a logical reasoning based on the error range, suggesting that the performance differences are not substantial. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. It highlights a potential issue with the authors\\' claim of better performance, suggesting that the error range may not accurately reflect the differences between methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method\\'s performance. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights significant artifacts in the generated videos and notes that only some of the beach videos are convincing. It also mentions that the action recognition performance is below the current state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issues with the generated videos or improve the action recognition performance. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions specific issues with the generated videos, noting significant artifacts and the performance of action recognition on the UCF dataset. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the generated videos and the action recognition performance, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the current state-of-the-art on the UCF dataset. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of deeper architectures and optic flow processing in the UCF dataset is a vague reference that does not fully substantiate the claim. Without concrete evidence or detailed analysis, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with the generated videos, noting significant artifacts and the lack of convincing results, particularly in the beach videos. It also points out that the action recognition performance is below the current state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their results. Without specific advice or examples, the authors are left with a general understanding of the problems but without a clear path to resolution. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not provide detailed guidance for addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment identifies a specific area needing clarification, it does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the clarity of their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is unclear, providing a clear direction for the authors to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment highlights an important issue, it lacks detailed guidance or suggestions on how the authors might address these concerns. Without specific recommendations or examples, the authors may find it challenging to make the necessary improvements. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a background section on the basic RL framework, specifically mentioning elements like the MDP, trajectories, and policy, to clarify the RL context. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. These instructions are clear and concrete, giving the authors specific actions to take to improve their draft. The feedback is highly actionable as it provides detailed guidance on what needs to be added to enhance the clarity and comprehensiveness of the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a background section on the basic RL framework, including elements like the MDP, trajectories, and policy, to clarify the RL context. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This provides clear guidance on what needs to be addressed, making it easy for the authors to identify the parts of the paper that require revision. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks a background section on the basic RL framework, including elements like the MDP, trajectories, and policy, which would help clarify the RL context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is logical and provides a clear rationale for why these additions would improve the paper\\'s clarity. However, it does not include specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of a background section on the basic RL framework, including elements like the MDP, trajectories, and policy. This feedback is clear and actionable, as it provides specific guidance on what the authors need to include to improve the clarity and comprehensiveness of their draft. Additionally, the comment suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This additional suggestion is also helpful, as it addresses a potential confusion for readers regarding the context of the modifications. Overall, the comment is highly helpful as it offers detailed and actionable feedback that can significantly enhance the paper\\'s quality and readability.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or improve the method to accommodate such scenarios. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. However, it does not specify which part of the paper discusses the proposed method or where this limitation is addressed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the method are affected by this limitation or how it could be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the proposed method may encounter a limitation if users continuously add new languages due to limited model capacity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the limitation or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. This is a relevant observation that could impact the scalability and applicability of the method. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or improve the method to accommodate such scenarios. Without actionable feedback or detailed advice, the authors are left with a general awareness of the issue but without a clear path to resolution. Therefore, the comment is somewhat helpful, as it points out a potential concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address this question, clarify the relevance, or make any changes to their draft. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" in the context of the work by Doshi-Velez and Kim. This provides clear guidance on what aspect of the paper needs clarification or further discussion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the relevance of the term \"interpretable\" in the context of the work by Doshi-Velez and Kim. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work by Doshi-Velez and Kim. While it identifies a potential area for clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague indication of a possible area for improvement. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on potential additional datasets to include or alternative approaches to consider, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experiments are limited or how this limitation affects the paper\\'s conclusions. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments are limited to MNIST and a single real-world dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is a concern or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. While this observation is relevant, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand their experimental scope. Without actionable feedback or specific recommendations, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer meaningful guidance for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment implies that the authors should provide additional information on the parameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue regarding the number of parameters not changing despite an increase in depth, and it suggests that more details are needed on the parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the parameters. This makes the claim somewhat verifiable, as it requires further elaboration or evidence to fully substantiate the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. This feedback is somewhat helpful as it points out a potential area for improvement and prompts the authors to provide additional information. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this issue, such as recommending a particular approach or analysis. Overall, the comment provides some direction but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should consider incorporating these elements into their work. The comment lacks concrete actions or details on how to implement any changes, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the proposed method are similar or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, the comment does not provide any specific evidence or reasoning to support this claim, such as a detailed comparison of the methods or references to studies that have used similar approaches. Without such support, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not provide specific feedback or suggestions on how the authors might address this similarity or how it could impact their work. The comment lacks actionable guidance and does not offer a clear path for improvement, making it barely helpful. The authors are left with a vague understanding of the issue but without concrete steps to enhance their draft. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, what additional games or baselines to include, or how to improve the interpretability of the results. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the Atari game results, which are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Atari game result (Section 7.2) is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the Atari game results, noting that they are limited to a single game and a single baseline, which makes it difficult to interpret. This feedback is somewhat helpful as it points out a potential weakness in the paper, prompting the authors to consider expanding their results to include more games and baselines. However, the comment lacks actionable suggestions or guidance on how to address this issue, such as recommending specific games or baselines to include. While it highlights an area for improvement, the feedback could be more helpful with additional detail or specific advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation with more tasks. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or implement a sparsity constraint. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding a sparsity constraint but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed, such as the methodology or results sections where this issue might be relevant. The comment is also specific because it clearly specifies the issue of increasing factors and computation with more tasks, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in the number of factors and computation with more tasks. This claim is somewhat verifiable as it provides a logical reasoning for the potential issue, suggesting that without a sparsity constraint, the model may not be incentivized to use fewer factors. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. This observation is relevant and could impact the efficiency and scalability of the model, as it suggests that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or implement a sparsity constraint. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more detailed explanation of why the GPC (benchmark) is performing better than BPC (their method). It implies that the authors should reiterate that the better performance of GPC is due to the bandit feedback and not using information about the form of the cost function. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what specific details to include. The action is explicit but somewhat vague, as the authors know they need to provide more context but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, namely the lack of commentary on why the GPC (benchmark) is performing better than BPC (the authors\\' method). The comment further suggests that the authors should reiterate that the better performance of GPC is due to the bandit feedback and not using information about the form of the cost function. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation of the simulation study does not provide sufficient explanation for why the GPC (benchmark) performs better than BPC (the authors\\' method). The reviewer suggests that the authors should reiterate that this is due to the bandit feedback and not using information about the form of the cost function. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or explanation to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not provide sufficient explanation for why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that this is due to the bandit feedback and not using information about the form of the cost function. This feedback is clear and actionable, as it directs the authors to clarify an important aspect of their results that could impact the interpretation of their findings. By addressing this point, the authors can enhance the comprehensiveness and clarity of their paper. Therefore, the comment is mostly helpful, as it provides a specific area for improvement that could significantly benefit the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might find it helpful to quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. However, the comment does not explicitly instruct the authors to include this information or suggest how to quantify or clarify the claim. The action is implicit and somewhat vague, as the authors can infer that they should provide more context or evidence regarding the claim, but they are not given explicit guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors might find it helpful to quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to clarify and quantify the claim is specific, as it provides a concrete example for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the claim about ReLU not working well in deep or convolutional networks could be clarified by referencing the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This provides a specific example to support the claim, making it somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors might find it helpful to quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback is somewhat helpful as it offers a concrete example that could help the authors better understand and contextualize their claim. However, the comment could be more helpful if it provided additional guidance on how to quantify or clarify the claim further. Overall, the comment is somewhat helpful, as it offers a starting point for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores in the reviewer\\'s experience. It questions how the perplexity was calculated. While the comment identifies a potential issue, it does not provide explicit guidance on what the authors should do to address it. The action is implicit, as the authors need to infer that they should clarify the perplexity calculation or provide additional context. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the high perplexity values reported in the figure, which contradicts better BLEU scores in the reviewer\\'s experience. The comment further asks for clarification on how the perplexity was calculated. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the high perplexity reported in Figure 1, suggesting that it contradicts better BLEU scores in the reviewer\\'s experience. The comment raises a concern about the calculation of perplexity but does not provide specific evidence or references to support the claim. The lack of detailed reasoning or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported perplexity values in Figure 1, suggesting that they are unusually high compared to the better BLEU scores. It questions the calculation of perplexity and asks for clarification. This feedback is somewhat helpful as it points out a discrepancy that the authors should address, but it lacks specific suggestions or guidance on how to resolve the issue. The authors are left with a clear question to answer but without detailed advice on how to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides clear guidance on what the authors need to do to improve their draft. The action is direct and concrete, as it specifies the exact experiments that should be conducted. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this feedback pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in suggesting the need for additional experiments, it is not grounded because it does not indicate where these experiments should be conducted. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the evaluation section of the paper. It suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their evaluation by considering additional scenarios and model sizes. However, the comment could be more helpful if it explained why these experiments are important or how they might impact the paper\\'s conclusions. Overall, the feedback is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide a brief discussion on why rooted patterns are important and how they choose the roots. It also implies that if non-rooted patterns are sufficient, the discussion should be moved to the supplementary material. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the reviewer\\'s concern, which is to either include a discussion on the importance of rooted patterns or move the discussion to the supplementary material if non-rooted patterns are sufficient. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"rooted patterns,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the importance of rooted patterns and how they are chosen. The comment suggests that a brief discussion is expected or that the discussion should be moved to the supplementary material if non-rooted patterns are sufficient. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a discussion on the importance of rooted patterns and how they choose the roots. It implies that this information is missing or insufficiently explained in the paper. However, the comment does not provide specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity and provides actionable feedback. It points out that the authors define rooted patterns but do not explain why they are important or how they choose the roots. The comment suggests that a brief discussion on these points is expected or that the discussion could be moved to the supplementary material if non-rooted patterns are sufficient. This feedback is clear and provides the authors with a direct path to improve their draft by addressing the missing explanation. However, it could be more helpful if it offered specific suggestions on how to present the discussion or examples of how rooted patterns are relevant. Overall, the comment is mostly helpful as it guides the authors toward enhancing the clarity and completeness of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which is implied by the statement that neural models are smooth. While the comment identifies an area for improvement, it does not specify what kind of explanations are needed or how to provide them. The action is implicit and somewhat vague, as the authors are left to infer the specific details of what needs to be explained. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (95-97 and 308-310) where the paper addresses the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that more explanations are needed on the topic of consistency, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper addresses the consistency between training and inference, stating that neural models are smooth and can easily satisfy this consistency. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion for more explanations. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference. It points out that the paper mentions the smoothness of neural models as a reason for this consistency, but it does not provide detailed explanations. This feedback is somewhat helpful as it directs the authors to a particular aspect of their work that could benefit from further elaboration. However, it lacks specific suggestions or examples of what additional explanations might be necessary, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' claim of superior performance with fewer parameters compared to a baseline. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what parameters to test. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the model\\'s superior performance with fewer parameters compared to a baseline, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\\' claim and suggesting that they test their model with larger word embedding and LSTM parameters to backup their claim. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters compared to a baseline, suggesting that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This is a logical claim that requires verification through additional experiments. However, the comment does not provide specific examples or references to support the claim that the baseline model was tested with standard parameter settings, which would strengthen the argument. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the authors\\' claim of superior performance with fewer parameters compared to a baseline. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and substantiate their claim. By addressing this point, the authors can strengthen their argument and improve the credibility of their results. However, the comment could be more helpful if it included suggestions on how to conduct these additional tests or what specific parameters to consider. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the introduction of two hyperparameters, k and \u03b7, which require finetuning. It suggests that this finetuning depends on the availability of the environment or a good OPE method. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what actions the authors should take to resolve the problem or improve the draft. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the introduction of two hyperparameters, k and \u03b7, and their dependence on finetuning, which is contingent on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the issue of finetuning is mentioned. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved, such as suggestions for addressing the dependency on finetuning. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method, suggesting that this could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or further elaboration, the feedback is somewhat helpful as it points out a potential concern but does not offer a clear path for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the regularization applied to the LN model and the GLM model, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. While the comment implies that the authors should consider adjusting their regularization approach, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what needs to be done, but it is not directly stated as an action. Therefore, the comment is mostly actionable, as the authors can infer the need for adjustment but may not be entirely sure of the exact steps to take.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy in the regularization approach between the LN model and the GLM model, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. This claim is somewhat verifiable as it references specific regularization techniques used in the GLM model, providing some context for the comparison. However, the comment lacks detailed references or examples from pillow et al. to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the LN model and the GLM model, noting that the authors apply regularization (in the form of a cropped stimulus) to both models, while the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for how to address it. By pointing out the need for consistency in the comparison, the comment offers valuable guidance that can help the authors enhance the rigor and clarity of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include some failure cases and related discussion in their paper. While the comment implies that the authors should add this information, it does not provide specific guidance on which failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer what specific failure cases to address and how to discuss them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including failure cases and related discussion, but it does not specify which part of the paper this should be added to. The authors might infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of failure cases, but it lacks grounding as it does not identify a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including failure cases and related discussion would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of addressing failure cases. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that including failure cases and related discussion would be beneficial for the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which failure cases to include or how to structure the discussion. The feedback is somewhat helpful as it points out a direction for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the ablation study or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in suggesting an ablation study to address the issue, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, the comment does not provide any specific reasoning, examples, or references to support why this encoding is unclear or why an ablation study would be beneficial. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to determine its importance. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it points the authors in the right direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential clarity issue regarding the use of epsilon in equations (10) and (11). It suggests that introducing epsilon when discussing equation (11) might improve clarity. While the comment implies an action\u2014introducing epsilon in the discussion of equation (11)\u2014it does not explicitly instruct the authors to make this change. The action is somewhat vague, as it does not provide specific guidance on how to introduce epsilon or what specific changes are needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and refers to specific equations (10) and (11), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that introducing epsilon when discussing equation (11) might improve clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that introducing epsilon when discussing equation (11) might improve clarity. However, it does not provide any reasoning or evidence to support why this change would be beneficial or how it would enhance the clarity of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential clarity issue in the paper, specifically regarding the use of epsilon in equations (10) and (11). It suggests that introducing epsilon when discussing equation (11) might improve clarity. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to introduce epsilon or why it would enhance clarity. The feedback is somewhat helpful as it points out a potential issue, but it lacks depth and actionable suggestions, making it more beneficial for the authors to understand the issue rather than directly addressing it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should add an explicit discussion on the upper bounds of counting and potentially elaborate on empirical runtimes related to the computational complexity of counting homomorphisms. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is explicit and provides specific guidance on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L 145\" and the specific topic of \"computational complexity of counting homomorphisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for an explicit discussion on upper bounds of counting and potential elaboration on empirical runtimes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms and suggests that they should add an explicit discussion on upper bounds and potentially elaborate on empirical runtimes. The comment provides a specific example from the paper (\"L 145\") to support the claim, which helps justify the need for additional discussion. However, it lacks detailed reasoning or references to specific methods or studies that could further substantiate the claim. While the comment provides a clear direction for improvement, it could be strengthened with more detailed evidence or examples. Therefore, the comment is mostly verifiable, as it provides a solid basis for the claim but could benefit from additional support.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the discussion on the computational complexity of counting homomorphisms. It points out that the authors make only brief statements about this topic and suggests that the paper would benefit from explicitly adding upper bounds and potentially elaborating on empirical runtimes. This feedback is clear and actionable, providing the authors with a specific direction for improvement that could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it included examples or references to guide the authors in addressing this issue. Overall, the comment is mostly helpful as it effectively directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts: a correction of a typographical error and a question about the convergence of the baseline MCL with deep learning. The first part is explicit and actionable, as it clearly instructs the authors to correct a specific typo. The second part is also explicit but less actionable, as it asks a question about the convergence of the baseline MCL. While the authors are prompted to address this issue, the comment does not provide specific guidance on how to ensure convergence. Overall, the comment is mostly actionable, as it provides clear instructions for a typographical correction and raises a question that requires further exploration.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (108 and 115) where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the corrections required, such as changing \"f\" to \"g\" and removing an extra period. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a correction of a typographical error and a question about the convergence of the baseline MCL with deep learning. The first part is factual and does not contain a claim, as it is a straightforward correction of a typographical error. The second part is a question seeking clarification on the convergence of the baseline MCL, which is a request for information rather than a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific corrections: it points out a typographical error in line 108, where the first \"f\" should be changed to \"g,\" and it notes an extra period in the middle of a sentence in line 115. This level of detail is helpful as it directly guides the authors to make precise corrections in their manuscript. Additionally, the comment raises a question about the convergence of the baseline MCL with deep learning, which prompts the authors to address a potential issue in their methodology. However, the comment could be more helpful if it provided additional context or suggestions on how to ensure convergence. Overall, the feedback is mostly helpful as it offers clear and actionable corrections and a question that encourages further exploration, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a study of inference time, particularly comparing it to previous top-down and bottom-up pose estimation methods. While the comment implies that this is an important aspect to consider, it does not explicitly instruct the authors to conduct this study or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include a study of inference time but are not given detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a study of inference time, particularly comparing it to previous top-down and bottom-up pose estimation methods. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in suggesting a comparison with previous methods, but it is not grounded because it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a study of inference time, particularly comparing it to previous top-down and bottom-up pose estimation methods. The claim is based on the premise that the method is direct and does not require detection or keypoint grouping, implying that it should be faster. However, the comment lacks specific examples or references to previous methods, making it difficult for the authors to fully understand the basis of the suggestion. The lack of detailed justification or evidence makes the claim somewhat verifiable, as it provides a general direction but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper should include a study of inference time, particularly in comparison to previous top-down and bottom-up pose estimation methods. This feedback is somewhat helpful as it points out a specific aspect that could enhance the paper\\'s contribution and provide a competitive advantage over existing methods. However, the comment lacks detailed guidance on how to conduct this study or what specific metrics to consider, which would make it more actionable. Additionally, it does not address other aspects of the paper, such as the methodology or results, limiting its comprehensive value. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the proof of Theorem A.3. First, it questions how the input x has two indices, given that it is a vector and not a matrix. Second, it points out that the summation should be equal to 1/d, not d. These questions are explicit and provide clear guidance on what aspects of the proof need clarification or correction. The authors know exactly what parts of the proof need attention and can address these issues directly. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the input x having two indices, which is a clear indication of a potential issue in the proof. Additionally, it points out a mathematical error in the summation, providing specific details on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the proof of Theorem A.3, specifically questioning the indexing of the input x and the summation expression. These are factual statements that do not contain subjective opinions, claims, or suggestions for improvement. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the proof of Theorem A.3, questioning the indexing of the input x and the summation expression. This feedback is clear and actionable, as it directs the authors to clarify these aspects of their proof. By addressing these questions, the authors can improve the clarity and rigor of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve these issues. Overall, the comment is mostly helpful, as it identifies specific areas for improvement but lacks comprehensive guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in sections 4.3 and 4.4. It questions the effectiveness of beam search, given that only 77% of the result lists contain the ground truth logical forms. The reviewer also asks how the plugged-in entities/relationships would be verified if no ground truth is available. While the comment highlights potential issues and raises questions, it does not provide explicit or concrete actions for the authors to take. The authors can infer that they need to address these concerns, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, and it questions the effectiveness of beam search and the verification of entities/relationships when no ground truth is available. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in sections 4.3 and 4.4. It questions the effectiveness of beam search, given that only 77% of the result lists contain the ground truth logical forms. The reviewer also asks how the plugged-in entities/relationships would be verified if no ground truth is available. While the comment raises valid questions and points out potential issues, it lacks specific evidence or references to support the claim. The authors would need to conduct further analysis to address these concerns, making the comment somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in sections 4.3 and 4.4. It questions the effectiveness of beam search, given that only 77% of the result lists contain the ground truth logical forms. The reviewer also asks how the plugged-in entities/relationships would be verified if no ground truth is available. This feedback is somewhat helpful as it identifies a potential issue with the description of the results and prompts the authors to consider the reliability of their findings. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending alternative methods or analyses. Therefore, it is rated as somewhat helpful, as it provides some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. It further mentions that batch normalization standardizes the variance and centers the activation, and recommends discussing these limitations explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutionary dropout addressing internal covariate shift, suggesting that it is limited in its ability to increase the variance of some low-variance units. It also mentions batch normalization as a more effective method for standardizing variance and centering activations. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. The authors can infer that it relates to the discussion of dropout methods or optimization techniques, but the exact section is not explicitly mentioned. The comment is specific in detailing the limitations of the claim and suggesting a need for explicit discussion, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer contrasts this with batch normalization, which standardizes the variance and centers the activation. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim fully. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, suggesting that it can only increase the variance of some low-variance units. It contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion to discuss these limitations explicitly, which could help the authors refine their understanding and presentation of the dropout method. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in addressing the issue. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the limitations of FedPCL, noting its reliance on pre-trained models and the sensitivity of model accuracy to these models. It also recognizes the authors\\' efforts in developing a lightweight framework and integrating pre-trained models for federated aggregation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the limitations or improve the framework, leaving the authors without a clear path for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of FedPCL, noting its reliance on pre-trained models and the sensitivity of model accuracy to these models. The comment acknowledges the authors\\' efforts in developing a lightweight framework and integrating pre-trained models for federated aggregation, which is a new approach for federated learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the limitations of FedPCL, noting its reliance on pre-trained models and the sensitivity of model accuracy to these models. It also recognizes the authors\\' efforts in developing a lightweight framework and integrating pre-trained models for federated aggregation. However, the comment does not provide specific examples or detailed reasoning to support the claim about the limitations or the authors\\' contributions. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the limitations of FedPCL, specifically its reliance on pre-trained models and the sensitivity of model accuracy to these models. It recognizes the authors\\' efforts in developing a lightweight framework and integrating pre-trained models for federated aggregation, which is a new approach for federated learning. However, the comment does not provide specific suggestions or guidance on how the authors might address these limitations or improve the framework further. While it acknowledges the authors\\' contributions, it lacks depth and actionable feedback, making it somewhat helpful. The authors gain some insight into the limitations of their work but are not provided with a clear path for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should include these additional attention maps, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add these maps but are not given specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including additional attention maps in the qualitative figures, specifically mentioning \"the retrieved and final attentions\" and \"the tentative attention maps.\" However, it does not specify which figures or sections of the paper these maps should be included in, making it weakly grounded. The comment is specific in detailing what additional information should be included, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. However, the comment does not provide any reasoning or justification for why this would be beneficial or how it would enhance the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the visual representation of the paper, which could potentially improve the clarity and comprehensibility of the results. However, the comment lacks depth and does not offer detailed guidance on how to incorporate these additional maps or why they would be beneficial. While it points out a potential area for improvement, it does not fully support the authors in making these changes. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution should be elaborated on or how this description should be incorporated into the paper. The action is explicit but vague, as it lacks concrete guidance on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description or what specific aspects of the contribution need elaboration. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need improvement. This makes the comment weakly grounded, as the authors cannot pinpoint the exact areas needing attention. Additionally, the comment lacks specificity because it does not provide detailed guidance on what aspects of the contribution should be described. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the author should provide more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such supporting evidence or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated upon or how this description should be incorporated into the paper. The feedback is somewhat helpful as it points out a general area for enhancement, but it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. Additionally, it suggests referencing normalization and feature scaling in a separate section. While these suggestions are explicit, they lack concrete details on how to implement them, such as specific sections where these changes should be made. The authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. It also suggests referencing normalization and feature scaling in a separate section. However, the comment does not explicitly mention which sections these changes should be made in, making it weakly grounded. The authors can infer that it relates to sections 2.3 and 2.4, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of minor suggestions and comments, such as recommending a separate section for describing the main contributions and referencing normalization or feature scaling. These suggestions are not claims or opinions that require verification. They are factual statements or requests for clarification, making them \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several specific suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. This would help readers better understand the contributions and their significance. Additionally, it suggests referencing normalization and feature scaling in a separate section, which could enhance the comprehensiveness of the paper. While the comment is actionable and offers clear guidance, it could be more helpful if it included additional details or examples on how to implement these suggestions. Overall, the feedback is mostly helpful as it provides concrete steps for improving the paper\\'s structure and clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates a potential issue with Figure 5, either suggesting that the reviewer does not understand it or that the labels are incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue, such as checking the labels or clarifying the figure\\'s content. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Figure 5,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not explain what is unclear or what is wrong with the labels. It does not provide any guidance on how to address the issue or what needs to be clarified. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of a statement questioning the understanding of Figure 5 or the accuracy of its labels. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and factual, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a concern about either the understanding of Figure 5 or the accuracy of its labels. However, it lacks specificity and does not provide any guidance or suggestions on how to address the issue. Without actionable feedback or detailed explanation, the authors are left without a clear understanding of what needs to be clarified or corrected. This makes the comment barely helpful, as it identifies a potential problem but does not offer any direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include supervised baselines in their experiments, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be an informative baseline to compare self-supervised methods against. The comment is clear and provides concrete guidance on what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be an informative baseline. However, the comment does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. While the authors can infer that it relates to the experimental setup, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion but not fully grounded, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. The reviewer provides a logical reasoning by stating that full annotation is likely available for such datasets and that it would be an informative baseline to compare self-supervised methods against. This reasoning is clear and provides a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or studies that support the need for supervised baselines, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be an informative baseline to compare self-supervised methods against. This feedback is clear and actionable, as it directly suggests a specific improvement that the authors can make to enhance the comprehensiveness and validity of their experiments. By addressing this feedback, the authors can significantly strengthen their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. It also mentions that the benchmarks are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or outdated benchmarks. Without actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the performance differences between methods and the minimal variations across evaluations. It also references the outdated nature of the benchmarks, providing a specific reason for the minimal performance differences. However, the comment lacks specificity in terms of what needs to be addressed or improved. It does not provide guidance on how to address the issue of outdated benchmarks or how to enhance the evaluation process. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point, which may be attributed to random variation. It also mentions that the benchmarks are outdated and likely saturated. The claim is somewhat verifiable as it provides a logical reasoning for the minimal performance differences, suggesting that random variation could be a factor. However, the comment lacks specific examples or references to support the claim about the outdated benchmarks, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the performance differences between methods are minimal across evaluations, with variations less than 1 percentage point. It suggests that this may be due to random variation and that the benchmarks are outdated and likely saturated. While the comment identifies a potential issue with the evaluation methodology, it lacks specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the method\\'s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\\'s benefits. While the comment raises important points for consideration, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions and concerns. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and observations about the method\\'s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\\'s benefits. However, the comment does not specify which part of the paper these questions and observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these issues are discussed, the lack of explicit references makes it weakly grounded. The comment is specific in its questions and observations, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions and observations, each of which requires verification or clarification. The first question about the method\\'s applicability on Hopper, which has deterministic dynamics, is not supported by evidence or reasoning. The second question about evaluating the method on domains with non-deterministic dynamics is a request for further empirical evaluation, but it lacks specific suggestions or references. The third question about the absence of BEAR from the baselines is a request for clarification, not a claim. Overall, the comment consists of factual statements and questions, making it \"No\" for the label \"X\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions and observations about the method\\'s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. This is a valuable suggestion that could help the authors better understand and demonstrate the method\\'s effectiveness. Additionally, the comment points out the absence of BEAR from the baselines, which could be a relevant comparison for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these questions or improve the paper. While it identifies areas for consideration, it does not provide detailed actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a theoretical justification for why co-training and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on how to develop this theoretical justification or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to provide a theoretical explanation but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a theoretical justification for why co-training and weight averaging can improve results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where these methods are discussed. Without explicit references to the paper, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in its request for a theoretical justification but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a theoretical justification for why co-training and weight averaging can improve results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a theoretical justification for why co-training and weight averaging can improve results. This feedback is somewhat helpful as it identifies a gap in the paper and points out an area where the authors could enhance their explanation. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the theoretical justification should be addressed or how to develop it. While it highlights an important area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set, as the histogram needs to represent graphs with repeated vertex or edge labels. The comment provides a clear and explicit action for the authors to take, specifying that the set should be replaced with a multiset. Additionally, it explains the reasoning behind this change, which helps the authors understand the necessity of the action. Therefore, the comment is highly actionable, as it provides a concrete and direct suggestion for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used in section 4, suggesting that \"X\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set, as the histogram needs to represent graphs with repeated vertex or edge labels. The reviewer provides a logical reasoning for this claim, explaining that the multiplicities of labels in the graph need to be included to accurately represent the data. This reasoning is clear and provides a basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential issue with the terminology used in Section 4, suggesting that the term \"X\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and provides a concrete step for the authors to take to enhance the accuracy and clarity of their work. By addressing this suggestion, the authors can ensure that their analysis is more precise and comprehensive. Therefore, the comment is rated as highly helpful, as it offers a detailed and constructive suggestion that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their derivation. The comment lacks actionable details, such as recommending specific Bayesian considerations or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' derivation, which is a specific part of the paper. However, it does not specify which section or part of the derivation is being discussed, making it weakly grounded. The comment provides some specificity by mentioning that the derivation falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. This provides some guidance on what needs to be addressed, but it lacks detailed instructions or examples. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example of Bayesian-PAC based bounds, which suggests that the claim is supported by a logical reasoning and a reference to a specific type of bound. However, the comment could be strengthened by providing more detailed reasoning or examples of how the classical bounds are insufficient or how Bayesian considerations would improve the derivation. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' derivation, noting that it falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. This feedback is somewhat helpful as it points out a potential limitation in the current approach and suggests a direction for improvement by considering Bayesian-PAC based bounds. However, the comment lacks detailed guidance or examples on how to incorporate Bayesian considerations or what specific aspects of the derivation need to be revised. While it provides some insight into a potential area for improvement, it does not offer comprehensive or actionable advice, leaving the authors with a general direction but without clear steps to take. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present these details or what format to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details should be provided about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in detailing what additional information is needed, but without clear grounding, the authors may struggle to identify the exact sections that require revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, reasoning, or references to support why these details are necessary or how they would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these details or how to address them. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide more details about their proposed method. It highlights the need to explain how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it directs the authors to enhance their explanation of a critical aspect of their method. However, the comment could be more helpful if it provided specific suggestions on how to present these details or examples of similar approaches. Overall, the comment is mostly helpful as it guides the authors toward improving their draft by addressing a key area of uncertainty.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in open-ended responses. It provides an example scenario where the prompt \"introduce a sports celebrity to me\" could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to enhance the method\\'s ability to detect hallucinations in open-ended responses. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in open-ended responses. It provides an example scenario involving a prompt about introducing a sports celebrity, which could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not specify which part of the paper discusses the proposed method or where this issue is addressed, making it weakly grounded. The comment is specific in detailing the potential problem with detecting hallucinations in open-ended responses, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, specifically in the context of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a specific example scenario to illustrate the challenge, which helps support the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how this issue might manifest or impact the method\\'s performance. Overall, the claim is somewhat verifiable as it provides a logical basis but lacks comprehensive evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in open-ended responses. It provides a specific example scenario involving a prompt about introducing a sports celebrity, which could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. This feedback is valuable as it highlights a specific area where the method might struggle, prompting the authors to consider ways to address this issue. However, the comment could be more helpful if it offered suggestions or potential solutions for improving the method\\'s ability to detect hallucinations in open-ended responses. Overall, the comment is somewhat helpful as it provides insight into a potential weakness but lacks actionable guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should verify their conclusion about label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how the authors should conduct this verification or what specific aspects of the conclusion need to be verified. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the clarity of how theoretical findings relate to real-world deep learning models, specifically mentioning the conclusion about label noise and model size on MNIST and CNN. This provides full grounding as it explicitly mentions the theoretical findings and the specific models (MNIST and CNN) being discussed. The comment is also specific because it suggests verifying the conclusion by conducting experiments on these models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models, specifically mentioning the conclusion about label noise and model size on MNIST and CNN. The reviewer suggests verifying this conclusion by conducting experiments on these models. However, the comment lacks specific examples or detailed reasoning to support why the current findings are unclear or how the verification would be conducted. This makes the claim somewhat verifiable, as it provides a direction for further investigation but lacks the necessary details to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of how theoretical findings relate to real-world deep learning models, particularly in the context of label noise and model size on MNIST and CNN. It suggests that the authors should verify their conclusions by conducting experiments on these models. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and applicability of their findings. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a mix of positive and constructive feedback. It acknowledges the paper\\'s organization and writing quality but suggests specific improvements. It explicitly recommends drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete action. It also raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequent-error cluster and whether the selection criteria in section 4.2 are reasonable. These questions imply that the authors should provide more detailed explanations or justification for these assumptions. While the comment is mostly actionable, it could be more detailed in explaining how to improve the writing or how to address the questions about assumptions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment provides a mix of positive and constructive feedback. It acknowledges the paper\\'s organization and writing quality but suggests specific improvements. It explicitly recommends drawing a table to compare different CoT prompting methods across different dimensions, which provides clear guidance on how to enhance the presentation of the results. Additionally, it raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequent-error cluster and whether the selection criteria in section 4.2 are reasonable. These questions imply that the authors should provide more detailed explanations or justification for these assumptions. The comment is fully grounded as it explicitly mentions the writing and content, and it is specific in suggesting improvements and raising questions about the assumptions. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a combination of factual statements and suggestions. It acknowledges the paper\\'s organization and writing quality but suggests improvements, such as drawing a table to compare different CoT prompting methods and questioning the assumptions made in the paper. These suggestions are not claims but rather constructive feedback that does not require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a mix of positive and constructive feedback. It acknowledges the paper\\'s organization and writing quality, which is a positive observation. However, it also suggests specific improvements, such as drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete and actionable suggestion. The comment further questions the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequent-error cluster and whether the selection criteria in section 4.2 are reasonable. These questions prompt the authors to provide more detailed explanations or justification for their assumptions. Overall, the comment offers valuable feedback that can guide the authors in enhancing their draft, making it mostly helpful. However, it could be more comprehensive by providing additional suggestions or examples to further improve the paper. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors should mention that p(y|H_f^(tn)) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI are not possible. It also notes that this assumption is later made in the ELBOs. This feedback provides a clear and direct action for the authors to take, specifying what needs to be mentioned and why. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue is addressed, specifically mentioning \"p(y|H_f^(tn))\" and \"ELBOs.\" This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the assumption that p(y|H_f^(tn)) has to be chosen Gaussian to make Kalman Filtering and Smoothing and CVI possible. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"p(y|H_f^(tn)) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI is not possible.\" This claim is supported by logical reasoning, as it explains that the choice of a Gaussian distribution is necessary for the application of Kalman Filtering and Smoothing and CVI. However, the comment could be strengthened by providing more detailed reasoning or references to specific methods or literature that require this assumption. Therefore, the claim is mostly verifiable, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement by pointing out that the paper should mention that p(y|H_f^(tn)) has to be chosen Gaussian to make Kalman Filtering and Smoothing and CVI possible. This feedback is clear and direct, offering the authors a concrete step to enhance the clarity and completeness of their draft. By addressing this point, the authors can ensure that their readers fully understand the assumptions and limitations of their methodology. Therefore, the comment is highly helpful, as it provides valuable guidance that can significantly improve the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve their draft. The suggestion to report cosine similarities for large weight decay strengths is implicit, but the comment lacks concrete details on how to implement this suggestion. As a result, the action is somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the plots end at a weight decay strength where cosine similarities are still close to optimal, suggesting that the authors should report cosine similarities for larger weight decay strengths. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that weight decay applied to all layers would lead to suboptimal training loss and cosine similarities for large weight decay parameters. It further notes that the plots end at a weight decay strength where cosine similarities are still close to optimal, suggesting that the authors should report cosine similarities for larger weight decay strengths. However, the comment lacks specific examples or references to support the claim about the expected impact of weight decay on training loss and cosine similarities. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that it could lead to suboptimal training loss and cosine similarities for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that the authors should report cosine similarities for larger weight decay strengths. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for additional analysis. However, the comment could be more helpful if it offered further guidance on how to interpret or analyze the cosine similarities for larger weight decay strengths. Overall, the comment is mostly helpful, as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant omission in the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is considered a \"fairly serious omission\" that could lead to incorrect conclusions among casual readers. The reviewer emphasizes the importance of fixing this issue for publication, suggesting that it would be straightforward to do so. However, the comment does not provide specific guidance on how to address this omission, such as suggesting changes to the text or providing examples of how to clarify the results. While the action is explicit, it lacks concrete details on how to implement the suggested changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions among casual readers. The comment provides a clear direction for improvement by suggesting that this omission needs to be fixed for publication. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a \"fairly serious omission.\" The reviewer suggests that this omission could lead to incorrect conclusions among casual readers. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the omission and how to address it. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specific issues and how to fix them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a significant issue that could lead to incorrect conclusions among casual readers. The reviewer emphasizes the importance of fixing this omission for publication, acknowledging that it would be straightforward to address. However, the comment does not provide specific suggestions or examples on how to clarify the results or improve the clarity of the paper. While it highlights a crucial area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical issue but lacks actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of qualitative experiments to demonstrate the validity of the conditional independence model and the need for a new test metric. It suggests providing illustrative experimental results to demonstrate the effectiveness of the proposed method and proposes using a toy dataset to show the separability of inlier features and outlier features. Additionally, it recommends providing visualization results or schematic diagrams to aid understanding of the new test metric. These suggestions are explicit and provide concrete guidance on how to address the issues, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"qualitative experiments\" and \"the conditional independence model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as conducting illustrative experiments, using a toy dataset to demonstrate separability, and providing visualization results or schematic diagrams to aid understanding of the new test metric. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results. It also mentions the need for a new test metric and suggests providing visualization results or schematic diagrams to aid understanding. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The suggestion for a toy dataset is a logical step but is not elaborated upon. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement: the lack of qualitative experiments to demonstrate the validity of the conditional independence model and the need for a new test metric. It provides specific suggestions, such as conducting illustrative experiments using a toy dataset to demonstrate the separability of inlier features and outlier features, and recommending the inclusion of visualization results or schematic diagrams to aid understanding of the new test metric. These suggestions are clear and actionable, offering the authors concrete steps to enhance the comprehensibility and validity of their work. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in implementing these suggestions. Overall, the feedback is mostly helpful as it effectively directs the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods. It explicitly asks the authors to compare the computational complexity, which is a direct and concrete action. The comment provides clear guidance on what the authors need to do to address this concern, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of the proposed method compared to other methods. However, it does not specify which part of the paper discusses the online version of the algorithm or where the authors mention the impracticality of training multiple iterations/epochs with large models and datasets. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for a comparison of computational complexity with other methods, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification on the computational complexity of the proposed method compared to other methods. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the computational complexity of the proposed method compared to other methods. It prompts the authors to provide a comparison, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its helpfulness. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects them. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis, leaving some ambiguity. However, the concrete suggestion about analyzing the cost and reward incentives provides a clear direction for the authors to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a specific analysis that would be beneficial, namely studying the impact of the cost of incentivization on performance. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects them. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the analysis or results sections where such an analysis could be included. The suggestion is specific in detailing what kind of analysis would be beneficial. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a hypothetical scenario where the cost to reward the other agent becomes high for cooperators, leading to the emergence of roles between \"winners\" and \"cooperators.\" The comment further suggests that if the cost were lower, roles would be less distinguished, causing the collective return to be much lower. While the comment offers a logical reasoning and a hypothetical scenario, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a logical framework but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a valuable analysis that could be conducted to further explore the impact of the cost of incentivization on performance. It provides a specific example of how this analysis could be structured, such as studying the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects them. This feedback is clear and actionable, as it directs the authors to a specific area for further investigation and improvement. However, it could be more helpful if it included additional guidance on how to conduct this analysis or potential outcomes to expect. Overall, the comment is mostly helpful, as it provides a constructive suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly highlights the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT-4 significantly improve translation quality and discourse awareness. The reviewer points out that the differences between the scores are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is explicit and provides concrete guidance on what needs to be done to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by pointing out the lack of significance testing to support claims about the differences between methods. The reviewer provides a concrete example from line 486, where the authors claim that ChatGPT and GPT-4 significantly improve translation quality and discourse awareness, and suggests that proper testing is needed to determine significance. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make significant claims about the differences between methods without providing significance testing. The reviewer provides a specific example from line 486, where the authors claim that ChatGPT and GPT-4 significantly improve translation quality and discourse awareness, and compares these scores with those of FeedME-2 and PPO. The reviewer points out that the differences are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including references to specific statistical methods or examples of how significance testing should be conducted. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a significant issue with the paper: the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT-4 significantly improve translation quality and discourse awareness, and compares these scores with those of FeedME-2 and PPO. The reviewer points out that the differences are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is actionable and provides clear guidance on how the authors can strengthen their claims and improve the rigor of their analysis. By addressing this issue, the authors can enhance the credibility and impact of their findings. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to revise the approach description in section 3, suggesting that they should use the additional page of the camera-ready version to extend the description rather than adding more experiments. This provides a clear and direct action for the authors to take, making the comment highly actionable. The feedback is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"\u00a7 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the approach description, indicating that it is difficult to follow and suggesting that it should be revised. The comment further provides a clear action for the authors to take, which is to use the additional page of the camera-ready version to extend the approach description rather than adding more experiments. This level of detail and guidance makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description in section 3 is difficult to follow and suggests that it should be revised. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach description in section 3, noting that it is difficult to follow. It provides a clear and actionable suggestion for improvement by recommending that the authors use the additional page of the camera-ready version to extend the approach description rather than adding more experiments. This feedback is valuable as it directs the authors to focus on enhancing the clarity and comprehensiveness of their approach description, which is crucial for readers to understand and evaluate the work. However, the comment could be more helpful if it included specific suggestions on how to improve the clarity or examples of what should be added to the description. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights that would explain why the proposed gyro-structures outperform existing methods. Second, it points out the lack of comparison with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach\\'s performance. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or insights should be included. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion and comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details what is missing in the discussion, namely interpretive insights that would explain the superiority of the proposed gyro-structures over existing methods. Additionally, it points out the lack of comparison with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach\\'s performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related discussion lacks interpretive insights to explain why the proposed gyro-structures outperform existing methods. It also notes the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach\\'s performance. While the comment highlights a gap in the discussion, it does not provide specific examples or references to support the claim that simpler or more commonly used techniques might outperform the proposed approach. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the experiments section. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyro-structures outperform existing methods. Second, it notes the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach\\'s performance. These observations are clear and actionable, as they guide the authors to enhance the interpretability of their results and broaden the scope of their comparisons. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these comparisons or insights. Overall, the feedback is mostly helpful, as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what specific aspects of the dataset or properties need to be addressed or how to present this information. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or analysis. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, while the comment provides a general direction for improvement, it lacks specificity in terms of what evidence or analysis is needed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS over other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS over other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what types of evidence or analysis would be most beneficial. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a difficulty in comprehending Figure 5 and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for English-centric datasets, which is not aligned with the widespread use of text generation APIs for translation across multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the baselines and consider extending CATER to other languages. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the figure, namely more details about the two baselines presented. Additionally, the comment provides a suggestion for future work, which is to extend CATER to other languages. This level of detail and specificity helps the authors understand what needs to be addressed and improved in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 is hard to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for English-centric datasets, which is not aligned with the widespread use of text generation APIs for translation across multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future. While the comment provides some reasoning by highlighting the lack of details in the figure and the limited scope of the study, it lacks specific examples or references to support the claim about the difficulty in understanding Figure 5. The suggestion to extend CATER to other languages is a logical inference but could be strengthened with more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, stating that it is hard to comprehend. It suggests that more details about the two baselines presented in the figure are needed, which is a clear and actionable piece of feedback. Additionally, the comment points out a limitation in the study, noting that the authors only study CATER for English-centric datasets, which is not aligned with the widespread use of text generation APIs for translation across multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future, providing a direction for potential improvement. This feedback is mostly helpful as it highlights a specific area for improvement and offers a suggestion for future work, but it could be more comprehensive by providing more detailed guidance on how to enhance Figure 5 or extend CATER to other languages. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution and distinction from existing work, particularly in relation to GFlowNet for sequence generation. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by clearly articulating the main contribution and distinguishing it from existing work. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"literature review\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details what needs to be improved, namely the clarity of the main contribution and the distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear direction for the authors to enhance their literature review by providing a more explicit and comparative analysis of related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review is unclear regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the literature review, noting that it lacks clarity regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. It provides a clear and actionable suggestion to enhance the literature review by offering a more explicit and comparative analysis of related work. This feedback is valuable as it guides the authors on how to improve the clarity and depth of their literature review, which is crucial for establishing the novelty and significance of their work. However, the comment could be more helpful if it included specific examples or references to existing work that the authors should consider for comparison. Overall, the comment is mostly helpful, as it provides clear guidance for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. However, it does not provide any specific guidance on how to address this suggestion or what content from section 3.2 might be redundant. The action is implicit and lacks concrete details on how to implement the suggested change, making it somewhat actionable. The authors would need to infer that they should remove section 3.2 but would not be provided with detailed instructions on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. However, it does not specify which part of section 3.2 is redundant or why it can be eliminated. The authors can infer that the comment pertains to section 3.2, but the lack of specificity in detailing what needs to be addressed makes it difficult for them to pinpoint the exact issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. However, the comment lacks specific reasoning or evidence to support why this assumption is valid or how it affects the paper. Without additional context or examples, the claim is difficult for the authors to verify or address, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. While this feedback identifies a potential redundancy in the paper, it lacks specific guidance or reasoning on why this assumption is valid or how it affects the overall structure or content of the paper. The comment does not provide actionable suggestions for improvement or alternative ways to address the issue, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential impact of regularization effects rather than distillation on the improvements in the teacher\\'s performance. It suggests that the authors should conduct proper ablation studies to verify their claims. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specifics themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the claim that distilling knowledge from the student to the teacher improves the teacher\\'s performance. It raises a concern about the potential impact of regularization effects rather than distillation, specifically mentioning the use of fine-tuning for 10 epochs without early-stopping. This provides clear guidance on what needs to be addressed, such as conducting proper ablation studies to verify the claims. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements in the teacher\\'s performance could be due to regularization effects rather than distillation, as all fine-tuning is performed for 10 epochs without early-stopping. The reviewer provides a logical reasoning by pointing out that fine-tuning on GLUE without validation early-stopping often leads to high variances, suggesting the need for proper ablation studies to verify the claims. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that distilling knowledge from the student to the teacher improves the teacher\\'s performance. It suggests that the improvements could be due to regularization effects rather than distillation, as all fine-tuning is performed for 10 epochs without early-stopping. The reviewer highlights the high variance in fine-tuning on GLUE without validation early-stopping, which could affect the results. This feedback is clear and actionable, as it prompts the authors to conduct proper ablation studies to verify their claims. However, the comment could be more helpful if it provided specific suggestions on how to design these ablation studies or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to address a critical issue in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\\'s robustness and effectiveness. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments. These suggestions are clear and concrete, giving the authors specific actions to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two distinct suggestions for improvement: (i) adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance credibility, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments. These suggestions are based on logical reasoning, as they aim to provide a more comprehensive evaluation of the framework\\'s robustness and effectiveness. However, the comment could be strengthened by providing specific examples or references to the MUSE paper or other relevant works, which would make it fully verifiable. Therefore, the comment is mostly verifiable, as it provides a clear direction but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two specific suggestions for improving the experiments in the paper. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\\'s robustness and effectiveness. This is a clear and actionable suggestion that could significantly strengthen the paper\\'s claims. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments, which would provide a more comprehensive evaluation of the framework\\'s performance. These suggestions are detailed and offer concrete ways for the authors to enhance their work, making the comment highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of node importance in the 1-shot scenario and the absence of a 1-shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1-shot setting. While the comment highlights areas of potential confusion or inconsistency, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the use of node importance in the 1-shot scenario and the absence of a 1-shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1-shot setting. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the experimental setup and the inclusion of related works, but it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of node importance in the 1-shot scenario and the absence of a 1-shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1-shot setting. The comment provides a logical reasoning by pointing out the inconsistency between the paper\\'s approach and the related works, which is a valid observation. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important questions about the paper. First, it questions the relevance of node importance in the 1-shot scenario, which is a critical aspect of the paper\\'s methodology. Second, it points out the absence of a 1-shot paper setting in the experiments, despite the inclusion of related works like RALE that do have such a setting. These questions highlight potential gaps or inconsistencies in the paper\\'s approach and methodology, which could be addressed to improve the clarity and comprehensiveness of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, leaving the authors with a general understanding of what needs to be improved but without detailed steps to take. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula in the text, specifically mentioning the example of $\\\\ell_{BCE}$. This is a clear and direct action for the authors to take, as it specifies what needs to be added to the draft. The comment is concrete, as it provides a specific example of what details should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the formula in the text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to include more details about the formula, even if it is simple, by giving a specific example of $\\\\ell_{BCE}$. This provides the authors with a concrete action to take to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details should be provided about the formula, even if it is simple, by giving specific details like $\\\\ell_{BCE}$. This is a request for clarification or additional information, which does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by instructing the authors to provide more details about the formula in the text, even if it is simple. It specifically mentions the example of $\\\\ell_{BCE}$, which gives the authors a concrete example of what kind of detail they should include. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it explained why these details are important or how they would benefit the reader. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to do so or what aspects should be included in the expanded discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add more content and determine the specific details themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper should include these discussions, making it weakly grounded. The comment is specific in its request for additional discussion on a particular topic, but without clear grounding, the authors may find it challenging to determine where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that there should be more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. This feedback is clear and actionable, as it provides a direction for the authors to expand their discussion and potentially enhance the depth and relevance of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach this topic. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks insights into why self-supervised learning is needed on 360 video data with spatial audio. However, it does not provide explicit guidance or concrete suggestions on how the authors might address this issue. The comment implies that the authors should provide more justification or explanation, but it does not specify what kind of insights or reasoning should be included. As a result, the action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of insights into why self-supervised learning is needed on 360 video data with spatial audio. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where this insight could be provided. The authors can infer that it relates to the experimental results or the discussion of the proposed approach, but this inference is not explicit. The comment is specific in identifying the need for more insight into the rationale for self-supervised learning on this type of data, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks insights into why self-supervised learning is needed on 360 video data with spatial audio. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific details or references that would help the authors understand the basis of the critique or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the need for self-supervised learning on 360 video data with spatial audio. It points out that while the experimental results suggest the value of the proposed approach, the paper lacks insights into why this type of data requires self-supervised learning. This feedback is somewhat helpful as it highlights an area where the authors could provide more context and justification for their work. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as what additional insights or explanations could be included. To be more helpful, the comment could provide more detailed feedback or examples of what the authors might consider. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear and concrete instruction. Second, it requests that labels be included for subfigures in Figures 3 and 4, rather than just stating them in the captions. These actions are specific and provide clear guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely, the inclusion of labels for subfigures and the need for more explicit explanation of the link between IP and terms/equations. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the link between IP and terms/equations could be explained more explicitly and prominently. It also requests the inclusion of labels for subfigures in Figures 3 and 4. However, the comment does not provide any specific reasoning or examples to support why this explanation is necessary or how it would improve the paper. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the need for these changes.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the link between IP and terms/equations should be explained more explicitly and prominently. It also requests the inclusion of labels for subfigures in Figures 3 and 4, rather than just stating them in the captions. This feedback is clear and direct, offering the authors concrete steps to enhance the clarity and accessibility of their work. By addressing these points, the authors can improve the readability and comprehensibility of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step for the authors to follow, ensuring they know exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests averaging results over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or a specific experiment. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests averaging results over multiple runs to determine statistical significance. This is a logical suggestion based on common practices in experimental analysis. However, the comment does not provide specific examples or references to support why this is necessary or how it would improve the paper. While the suggestion is reasonable, the lack of detailed justification or examples makes it somewhat verifiable, as the authors may need to infer the full rationale themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the paper by recommending that the authors average their results over multiple runs to determine statistical significance. This feedback is specific and offers a concrete step for the authors to take to enhance the robustness and validity of their findings. By addressing this point, the authors can strengthen their results and provide a more comprehensive analysis. However, the comment could be more helpful if it explained why averaging is important or how it would impact the paper\\'s conclusions. Overall, the feedback is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the analysis, noting that only the SimCLR case is covered and suggesting that the projection head, which is an important part of the approach, should be analyzed. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the projection head should be examined. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include the projection head, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the projection head, which is an important aspect of the SimCLR approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only the SimCLR case is covered and suggests that the projection head, an important part of the approach, should be analyzed. However, the comment does not provide specific references or examples of recent papers that show the importance of the projection head, nor does it explain why this aspect is crucial. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to independently investigate the significance of the projection head to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the analysis by noting that only the SimCLR case is covered and suggests that the projection head, an important aspect of the approach, should be analyzed. This feedback is clear and actionable, as it directs the authors to expand their analysis to include a critical component of the SimCLR approach. However, the comment could be more helpful if it provided specific suggestions on how to analyze the projection head or referenced relevant literature on this topic. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft, but it could be more comprehensive with additional guidance or references.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the trade-offs between annotation effort and training performance. While the comment implies that the authors should make these observations and conclusions more prominent, it does not provide specific guidance on how to achieve this, such as suggesting where to place them or what format to use. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the trade-offs between annotation effort and training performance. However, it does not specify which part of the experimental section contains these observations or conclusions, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not explicitly mention a specific section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the observations and conclusions are hidden in the experimental section, suggesting that they should be highlighted for better understanding. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specific issues and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the trade-offs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and impact of their work. However, the comment could be more helpful if it offered suggestions on how to effectively highlight these observations and conclusions, such as through specific sections or figures. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments. However, it does not specify which modifications should be tested or how to conduct the ablation experiments, leaving some room for ambiguity. Therefore, the comment is mostly actionable, as it clearly identifies the need for additional experiments but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. However, it does not specify which modifications are being referred to or where in Section 3.4 they are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting the need for ablation experiments, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation experiments should be conducted to validate the model performance further, given the modifications mentioned in Section 3.4. However, the comment does not provide specific details or examples of these modifications, nor does it explain why ablation experiments are necessary or how they would contribute to validating the model performance. This lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of the suggested experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is clear and actionable, as it identifies a specific area for improvement by recommending additional experiments. However, the comment could be more helpful if it provided more detailed guidance on which modifications to focus on or how to conduct the ablation experiments. Despite this, the suggestion is valuable as it directs the authors to enhance the robustness and validity of their results. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the KDE method when the decision space is beyond binary, as mentioned in Remark 1. It also references an alternative approach by Zhang et al. that does not seem to have this issue. The comment implies that the authors should consider comparing the performance of their method with the alternative approach on datasets with decision spaces beyond binary. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should compare performance but are not given detailed instructions on how to execute this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of the KDE method when the decision space is beyond binary and suggests comparing it with an alternative approach by Zhang et al. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the KDE method when the decision space is beyond binary, as mentioned in Remark 1. It references an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests comparing the performance of the KDE method with the alternative approach on datasets with decision spaces beyond binary. However, the comment lacks specific examples or detailed reasoning to support the claim that the KDE method would require more data in such scenarios. While it provides a logical suggestion for further exploration, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance of the KDE method when the decision space is beyond binary, as mentioned in Remark 1. It references an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests that the authors should consider comparing the performance of their method with the alternative approach on datasets with decision spaces beyond binary. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially improve their work. However, it could be more helpful if it included more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a valuable suggestion for enhancing the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or investigate the potential issues. The authors are left to infer that they need to explore these aspects further, but without concrete guidance on how to do so, the comment lacks actionability. Therefore, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on what aspects of the SR model capacity or the pipelining method are causing the unexpected artifacts. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions: \"How the capacity of the SR model affects the FID\" and \"whether there are unexpected artifacts due to the proposed method being pipelined.\" These are requests for clarification or additional information, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions are relevant and could lead to further exploration and clarification in the paper, the comment lacks specificity and actionable guidance. It does not provide suggestions on how to address these questions or improve the paper, leaving the authors with a general direction but no clear steps to take. Therefore, the comment is barely helpful, as it identifies areas for improvement but does not offer detailed feedback or actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might be meant to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. The comment also notes that the authors\\' so-called \"proof\" is missing. While the comment identifies specific issues and provides some context, it does not explicitly instruct the authors on how to address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should fill in the blank appendix and clarify the purpose of Proposition B.1. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with these sections, such as the blank appendix and the unclear purpose of Proposition B.1. The comment further specifies that the proposition might be meant to illustrate a well-known concept in machine learning, the partitioning principle of K-means, and notes the absence of a proof. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear, suggesting it might be meant to illustrate a well-known concept in machine learning. The reviewer also notes the absence of a proof. While the comment provides some context, it lacks specific examples or references to support the claim that the concept is well-known or that the proof is missing. This makes the claim somewhat verifiable, as the authors would need to investigate the claim further to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the absence of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the proposition might be meant to illustrate a well-known concept in machine learning, the partitioning principle of K-means. Additionally, the comment points out the lack of a proof for the proposition. While the comment highlights important areas for improvement, it does not provide specific guidance on how to address these issues or improve the clarity of the paper. The feedback is somewhat helpful as it directs the authors\\' attention to specific sections that need attention, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments to enhance the paper. The comment is specific and provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the part of the paper being addressed, specifically the sections where these experiments should be included. The comment is also specific because it clearly specifies what is missing and what needs to be addressed, such as conducting comparison experiments, ablation studies, and hyperparameter analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific examples, reasoning, or references to support why these experiments are crucial or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work by conducting these experiments. However, the comment could be more helpful if it offered suggestions on which specific comparisons or ablations should be conducted or how to analyze hyperparameters effectively. Despite this, the comment is mostly helpful as it directs the authors to a critical area for improvement, providing a clear path for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the approximations introduced in the paper, specifically mentioning the vulnerability due to the assumption of attacks being in the feasible set. It suggests that this vulnerability needs to be expanded upon to reassure readers that it is not a real concern. While the comment identifies a potential issue and suggests addressing it, it does not provide specific guidance on how to expand the discussion or what additional information should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (107-110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability in the approximations introduced and suggests expanding the discussion to reassure readers that this is not a real concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approximations introduced in the paper leave loose ends and suggests expanding the discussion to reassure readers that the vulnerability is not a real concern. However, the comment does not provide specific examples or detailed reasoning to support the claim about the vulnerability or the need for expansion. The lack of detailed justification or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approximations introduced in the paper, specifically mentioning a vulnerability due to the assumption of attacks being in the feasible set. It acknowledges the necessity of approximations for deriving clean results but suggests that the authors should expand on this vulnerability to reassure readers that it is not a real concern. This feedback is somewhat helpful as it points out a specific area that needs further clarification or discussion. However, it could be more helpful if it provided suggestions on how to address this vulnerability or expand the discussion. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address the perceived limitations or improve the contribution of their work. Without actionable suggestions or a clear direction for improvement, the authors are left without a path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model are considered incremental. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what aspects of the model are considered incremental or how they compare to existing work, the claim remains unverifiable. The authors would find it challenging to address this feedback without additional context or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their work need to be addressed or how to enhance their contribution. As a result, the comment is not helpful at all, as it does not offer any constructive direction for the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new state-of-the-art (SOTA) scores. However, it implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. The comment also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new state-of-the-art (SOTA) scores. It implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. The comment also recommends providing more details about the evaluation procedures. However, it does not specify which benchmarks are considered \"old\" or how the data might have been indirectly seen, making it weakly grounded. The comment is specific in suggesting the need for more detailed analysis and evaluation procedures, but without explicit references to specific sections or parts of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model demonstrates impressive performance on various benchmarks, setting new state-of-the-art (SOTA) scores. It suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. The comment also recommends providing more details about the evaluation procedures. While the claim about the model\\'s performance is factual, the suggestion regarding the need for a more careful analysis and the potential impact of \"old\" benchmarks is based on logical reasoning and common knowledge about data curation processes. However, the comment lacks specific examples or references to support the claim about the \"old\" benchmarks, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the impressive performance of the proposed model on various benchmarks, setting new state-of-the-art (SOTA) scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. This implies that the authors should provide more details about the evaluation procedures to ensure transparency and robustness of the results. While the comment identifies a potential issue and suggests a direction for improvement, it lacks specific guidance on how to conduct this analysis or what aspects to focus on. Therefore, the feedback is somewhat helpful, as it provides a clear area for improvement but could be more detailed and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the experimental part, specifically noting that the different metrics used for different OPE methods are not consistent across Figure 4 and Figure 5. The reviewer suggests that the authors provide comments on the differences between the two sets of evaluation methods. While the comment implies that the authors should address this inconsistency, it does not explicitly instruct them to do so or provide specific guidance on how to make these comments. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the differences but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the experimental part, noting that the different methods in the two sets of benchmarks proposed in the article are different for different OPE methods. The comment further suggests that the authors provide comments on the differences between these evaluation methods. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods used in Figure 4 and Figure 5. The reviewer suggests that the authors provide comments on the differences between the two sets of evaluation methods. However, the comment lacks specific examples or detailed reasoning to support the claim of inconsistency, making it difficult for the authors to understand the exact nature of the issue. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to invest effort to identify and address the problem. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental part of the paper, noting that the different metrics used for different OPE methods are not consistent across Figure 4 and Figure 5. It suggests that the authors provide comments on the differences between the two sets of evaluation methods, which is a clear and actionable piece of feedback. By pointing out this inconsistency, the reviewer helps the authors recognize an area for improvement and guides them on how to enhance the clarity and consistency of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address the inconsistency or what aspects of the evaluation methods should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the experimental results, noting that the proposed method does not have an advantage over the state-of-the-art (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as it lacks specific suggestions on how to adjust the experiments or present the results. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method lacks an advantage without prior information and that the comparison is unfair due to the additional complexity and cost of using two representation models. The comment provides a clear explanation of what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method lacks an advantage over the state-of-the-art (SOTA) without prior information, and that the advantage only shows when using prior knowledge. The reviewer provides a logical reasoning by pointing out that the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental setup, noting that the proposed method lacks an advantage over the state-of-the-art (SOTA) without prior information. It points out that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This feedback is clear and actionable, as it highlights a critical aspect of the experimental design that could impact the evaluation of the proposed method. By pointing out the need to consider the additional complexity and cost, the comment provides the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered suggestions on how to address this issue or presented alternative ways to evaluate the method. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their experimental setup and analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. While the comment implies that the authors should add collaborative games to their experiments, it does not provide specific guidance on which games to choose or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding collaborative games to the experiments to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or experiments, the authors cannot confidently determine where to incorporate this suggestion. The comment is specific in its request for collaborative games but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this would be interesting or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This feedback is somewhat helpful as it identifies a potential area for improvement in the experimental design. By suggesting the inclusion of collaborative games, the reviewer provides a clear direction for enhancing the paper\\'s scope and depth. However, the comment lacks specific guidance on how to implement this suggestion or which collaborative games might be most relevant. To be more helpful, the comment could include examples or references to specific collaborative games that could be used. Overall, the feedback is somewhat helpful as it points out a meaningful enhancement but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not provide explicit guidance on what specific information should be included or how the authors should present it. The action is implicit, as the authors can infer that they need to provide experimental settings, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not specify which part of the paper discusses these figures, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of missing experimental settings, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes the results less convincing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant issue with the paper, noting the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. This is a critical observation that highlights a gap in the presentation of the experimental results, which is essential for the paper\\'s credibility. However, the comment lacks specific guidance on how the authors might address this issue, such as suggesting what information should be included or how to present it. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical area for improvement but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. While it identifies a gap in the explanation, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to provide more detailed explanation but does not specify how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically questioning how the proposed method avoids impeding the learning of new task knowledge. It mentions the observation that current parameter isolation methods often hinder the acquisition of new task knowledge and suggests that the authors clarify how their method avoids this issue. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its request for clarification on the method\\'s avoidance of impeding new task knowledge. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the rationale behind the work is unclear, specifically questioning how the proposed method avoids impeding the learning of new task knowledge. The comment provides a logical reasoning by pointing out that current parameter isolation methods often hinder the acquisition of new task knowledge, suggesting that the authors clarify how their method avoids this issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. It highlights a gap in the explanation by pointing out that some parameter isolation methods are specifically tailored to leverage sparsity, which could be relevant to the authors\\' work. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it raises an important point, the feedback lacks actionable details, making it somewhat helpful. The authors are given a direction to explore but are not fully supported in addressing the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the ad-hoc nature of the regularization term and suggests that the authors provide theoretical support for it. It also implies that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. While the comment identifies areas for improvement, it does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address the issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical justification and consider alternative statistics, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"regularization term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the ad-hoc nature of the regularization term and suggests alternative statistics, such as the median, that could be used instead of the mean and standard deviation. The comment also raises a question about why these alternatives were not considered, which further specifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the regularization term is ad-hoc and lacks theoretical support, suggesting that other statistics, such as the median, could be used instead of the mean and standard deviation. The comment provides a logical reasoning by pointing out the potential sensitivity of the mean to outliers, which could affect the regularization. However, it lacks specific examples or references to other statistics that could be used, making the claim somewhat verifiable. The authors would need to explore these alternatives themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the regularization term, noting that it appears ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization, which could provide a more robust and theoretically grounded approach. The comment also raises a question about why these alternatives were not considered, which prompts the authors to reflect on their choice of regularization and potentially explore alternative methods. This feedback is clear and actionable, providing the authors with a specific direction for improvement and offering a constructive suggestion. However, it could be more helpful if it included examples or references to support the use of alternative statistics. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should integrate benchmark comparisons against state-of-the-art fairness algorithms in the experimental section. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to enhance the paper. The comment also provides a rationale for why this is important, highlighting the need for tangible evidence of the proposed method\\'s performance and its positioning within the existing FairML research landscape. The action is concrete and explicit, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the integration of benchmark comparisons against state-of-the-art fairness algorithms. This provides clear guidance on how to enhance the paper by offering tangible evidence of the proposed method\\'s performance and positioning it within the existing FairML research landscape. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should include comparisons with existing fairness algorithms in the experimental section. The claim is supported by logical reasoning, as it highlights the importance of benchmarking to demonstrate the proposed method\\'s performance and its positioning within the existing FairML research landscape. However, the comment could be strengthened by providing specific examples of state-of-the-art fairness algorithms or references to relevant literature, which would make the claim fully verifiable. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed references or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against state-of-the-art fairness algorithms, which would enhance the paper\\'s credibility and position the ManyFairHPO framework within the existing FairML research landscape. This feedback is valuable as it guides the authors on how to strengthen their experimental section and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it included specific examples of algorithms to consider or detailed guidance on how to conduct these comparisons. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests including the iteration cost of related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying what needs to be discussed and which methods should be considered. The feedback is concrete and actionable, as it guides the authors on exactly what information to include in their discussion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and related methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This is a request for additional information and does not contain a claim or opinion that requires verification. It is purely a suggestion for improvement, making it a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to include a discussion on the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This feedback is valuable as it highlights an important aspect that could enhance the comprehensiveness and depth of the paper. By addressing this point, the authors can provide a more complete analysis of the computational efficiency of their method compared to others, which is crucial for readers interested in practical applications. However, the comment could be more helpful if it offered specific guidance on how to present this information or suggested potential sources for comparison. Overall, the comment is mostly helpful as it directs the authors to an area that could significantly improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests reporting the average over multiple runs to address the issue of results being close together, which would help in favoring one method. It also recommends discussing the decision boundaries in the toy-dataset, which would be interesting given its nature. Additionally, it asks for clarification on what information is in Figure 9, specifically the middle and right panels. Each of these actions is clear and concrete, giving the authors specific steps to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Experimental section,\" \"Sec. 3.1,\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear and actionable feedback, such as suggesting the reporting of averages over multiple runs, discussing the decision boundaries in the toy-dataset, and asking for clarification on the information in Figure 9. This level of detail guides the authors on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification, such as suggesting the reporting of averages over multiple runs and asking for a discussion on the decision boundaries in the toy-dataset. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback, addressing three distinct areas of the paper. First, it suggests reporting the average over multiple runs to improve the clarity of the experimental results, which is a practical and straightforward recommendation. Second, it recommends discussing the decision boundaries in the toy-dataset, which could provide valuable insights into the methodology. Third, it asks for clarification on the information presented in Figure 9, specifically the middle and right panels. These suggestions are clear and offer concrete ways for the authors to enhance their draft, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed model, stating that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the model\\'s applicability. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to overcome this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed model, specifically mentioning the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper discusses the model or its limitations, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the model\\'s applicability but lacks grounding, as it does not reference a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed model, specifically noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the model\\'s applicability and usefulness. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the model\\'s performance in higher-dimensional scenarios. Without actionable feedback or potential solutions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homo-lumo gap, specifically mentioning the poor performance of Transformer-M on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment suggests that this finding may contradict the claim of the paper being a \"general-purpose neural network model.\" While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this contradiction or improve their model. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the negative transfer and its implications for their model\\'s general-purpose claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the prediction of homo-lumo gap and the performance of Transformer-M on QM9 in downstream experiments, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of negative transfer and provides an example of poor performance on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper being a \"general-purpose neural network model.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, citing an example of poor performance on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment challenges the claim of the paper being a \"general-purpose neural network model,\" suggesting a contradiction. While the example of poor performance on QM9 provides some support, the comment lacks detailed reasoning or references to substantiate the claim fully. The authors would need to further explore the implications of this finding to fully understand the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homo-lumo gap, specifically citing the poor performance of Transformer-M on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This observation challenges the claim of the paper being a \"general-purpose neural network model,\" as it suggests that the model may not be as versatile as claimed. The comment provides a specific example and a logical reasoning for the potential issue, which is valuable for the authors to consider. However, it could be more helpful if it offered suggestions on how to address this concern or improve the model\\'s general-purpose claim. Overall, the comment is mostly helpful as it identifies a potential weakness and provides a clear direction for further exploration, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 80-82. While the comment highlights a potential inconsistency or confusion, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify their reasoning or provide additional context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (80-82) and figures (4 A&B) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the authors\\' use of the center correlation metric, which was previously deemed uninformative, and asking for clarification on why it was found useful in this context. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 80-82. This comment raises a valid point about the inconsistency in the authors\\' reasoning, but it does not provide any additional evidence, references, or detailed reasoning to support the claim. The authors are left to infer the issue and address it themselves. Therefore, the comment is considered borderline verifiable, as it highlights a potential issue but lacks sufficient support or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the authors\\' use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer questions the authors\\' reasoning and asks for clarification on why this metric was found useful in this context. This feedback is somewhat helpful as it points out a specific area of confusion or inconsistency in the paper, prompting the authors to clarify their rationale. However, the comment could be more helpful if it provided suggestions on how to address this inconsistency or offered alternative metrics that might be more appropriate. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a potential issue that needs clarification, but it lacks depth and actionable guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a rationale for this suggestion by explaining that the term implies an ideal scenario where the total variation between test and train distributions of the network\\'s outputs vanishes to zero, which might not be the case. However, the comment does not explicitly instruct the authors to change the term or provide guidance on how to rephrase it. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider the terminology but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the term\\'s appropriateness, explaining that it implies an ideal scenario that might not be accurate based on the empirical evidence presented. The comment suggests that the term might be too strong and offers a rationale for this claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. The reviewer provides a logical reasoning by explaining that the term implies an ideal scenario where the total variation between test and train distributions of the network\\'s outputs vanishes to zero, which might not be the case. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially provide additional evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of the term \"distributional generalization\" used in the paper, suggesting that it might be too strong to accurately describe the empirical phenomenon presented. The reviewer offers a rationale for this claim by explaining that the term implies an ideal scenario where the total variation between test and train distributions of the network\\'s outputs vanishes to zero, which might not be the case. This feedback is clear and actionable, as it prompts the authors to reconsider the terminology used to describe their findings. However, the comment could be more helpful if it suggested alternative terms or provided examples of more appropriate terminology. Overall, the comment is mostly helpful as it directs the authors to a potential improvement in their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a critique of the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to strengthen the theoretical contribution or improve the practicality of the bound. The comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the theoretical contribution are weak or unpractical. Without explicit references to sections, figures, or specific elements of the theoretical contribution, the authors cannot confidently determine which parts of the paper need attention. This lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. It lacks specific examples or detailed explanations of why the theoretical contribution is weak or unpractical, making it difficult for the authors to understand and address the critique. Without sufficient justification or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" It also mentions that the proof does not provide \"particular mathematical novelty.\" However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might strengthen their theoretical contribution or enhance the practicality of the bound. Without actionable advice or detailed critique, the comment does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, such as abating the \"picking\" step and ensuring that the comparison on CIFAR is more convincing by using the same setup as in the DEN paper. These actions are clearly stated and provide concrete guidance on how to improve the draft. The authors know exactly what needs to be done to address the issues raised, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as abating the \"picking\" step and ensuring a more convincing comparison on CIFAR by using the same setup as in the DEN paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions, each of which requires verification. The first claim about the \"picking\" step being not ablated is supported by the explicit mention of the paper\\'s claim, providing a clear basis for the critique. The second claim regarding the comparison on CIFAR is supported by the observation that the paper only compares to one approach (DEN) and lacks a fair comparison with other works. The suggestion to use the same setup as in the DEN paper is logical and provides a clear path for improvement. Overall, the comment is mostly verifiable, as it provides a logical basis for the claims and suggestions, but could be strengthened with more detailed references or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It points out that the \"picking\" step is not ablated, which is a critical aspect of the paper\\'s claims. Additionally, it critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and lacks a fair comparison with other works. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. This feedback is clear and actionable, guiding the authors on how to improve the robustness and validity of their experimental results. Therefore, the comment is highly helpful, as it offers detailed and constructive suggestions for enhancing the paper\\'s experimental section.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative phrasing. The action is implicit and somewhat vague, as the authors are left to infer that they should consider revising the phrasing but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"above/below diagonal\" and \"above/below 45 degree,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree\" to avoid confusion. This specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. The reviewer provides a logical reasoning by explaining that the diagonal reference is more general and less likely to be confused with a local property. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the reasoning fully, which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the phrasing used in the paper, suggesting that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree.\" It provides a logical reasoning for this suggestion, explaining that the diagonal reference is more general and less likely to be confused with a local property. However, the comment does not offer specific guidance on how to address this issue or suggest alternative phrasing. While it highlights a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the wording in lines 240 and 428, suggesting that the phrase \"is sufficient\" needs clarification. It provides a potential correction, indicating that the authors might want to write that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This feedback is explicit and provides a clear direction for the authors to improve their draft by clarifying the intended meaning. The action is concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the phrase \"is sufficient\" should be clarified by writing that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrase \"is sufficient\" in lines 240 and 428, suggesting that it should be clarified. The reviewer provides a potential correction, stating that the sum of the \"optimistic\" hoped-for rewards should be close to the expected actual rewards. However, the comment does not offer any further explanation or evidence to support why this clarification is necessary or how it would improve the paper. The suggestion is logical but lacks detailed justification or references, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in lines 240 and 428, where the phrase \"is sufficient\" is used without clear context. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their writing. However, the comment could be more helpful if it explained why this clarification is important or how it might impact the reader\\'s understanding of the paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scientific insight provided by the model and formalism compared to prior task-optimized approaches. It specifically questions whether the model is a prototype approximation to non-linear RNN models and whether it provides an explanation for their emergent behavior. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The action is implicit, as the authors can infer that they need to provide a clearer explanation of the scientific contribution, but it lacks concrete steps or details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of scientific insight provided by the model and formalism compared to prior task-optimized approaches. The comment questions whether the model is a prototype approximation to non-linear RNN models and whether it provides an explanation for their emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the scientific insight provided by the model and formalism compared to prior task-optimized approaches. It specifically challenges the claim that the model is a prototype approximation to non-linear RNN models and questions whether it provides an explanation for their emergent behavior. The comment provides a logical reasoning by pointing out the lack of evidence or explanation for the claimed scientific contribution. However, it does not include specific references or detailed examples to support the claim, making it somewhat verifiable. The authors would need to address the gaps in the reasoning to fully understand and respond to the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the scientific insight provided by the model and formalism compared to prior task-optimized approaches. It specifically questions whether the model is a prototype approximation to non-linear RNN models and whether it provides an explanation for their emergent behavior. This feedback is valuable as it prompts the authors to clarify the novelty and contribution of their work, which is essential for the scientific community to understand and evaluate the paper. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these concerns. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training of O_{up} in the supplementary material, specifically regarding the offset for keypoints that are not farther than a distance \\textit{r} to the center of the corresponding part. The reviewer asks how the groundtruths are built and whether the network parts can predict all the keypoints of the pose. This comment implies that the authors should clarify the training process and provide details on how the network is structured to address this issue. While the action is implicit, it is concrete in terms of what needs to be clarified and investigated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the training of O_{up}, questioning how the groundtruths are built and whether the network parts can predict all the keypoints of the pose. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training of O_{up} in the supplementary material, specifically regarding the offset for keypoints that are not farther than a distance \\textit{r} to the center of the corresponding part. The reviewer asks how the groundtruths are built and whether the network parts can predict all the keypoints of the pose. This question is based on a logical inference about the training process, but it does not provide specific evidence or references to support the claim. The lack of detailed explanation or references makes the claim somewhat verifiable, as the authors would need to investigate the issue further to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the training process of O_{up}, specifically regarding the offset for keypoints that are not farther than a distance \\textit{r} to the center of the corresponding part. It questions how the groundtruths are built and whether the network parts can predict all the keypoints of the pose. This feedback is valuable as it highlights a potential gap in the explanation of the training process, prompting the authors to clarify and potentially revise their methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how similar problems have been resolved in other works. Overall, the comment is somewhat helpful as it identifies a critical area for clarification but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take, such as making the figures larger and more readable, clarifying the relationship between equations 4 and 5, explaining how theta^{t+1/2} fits into the context, and defining S^{*} and S^{~} properly. Each of these actions is clearly stated and provides concrete guidance on how to improve the draft. The authors know exactly what steps to take to address the issues raised, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the figures being small and almost unreadable, the relationship between equations 4 and 5, the role of theta^{t+1/2}, and the definition of S^{*} and S^{~}. It also specifies what needs to be addressed, such as clarifying the relationship between equations, explaining the role of theta^{t+1/2}, and properly defining S^{*} and S^{~}. This level of detail provides clear guidance for the authors on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims, each of which is supported by specific observations and reasoning. For example, the claim about the figures being small and almost unreadable is substantiated by the observation that they are difficult to read. The claim about the relationship between equations 4 and 5 is supported by the request for clarification. The comment about the definition of S^{*} and S^{~} is further substantiated by pointing out the inconsistency in the definition provided in the paper. Each claim is well-supported by logical reasoning and specific observations, making the review point fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper. It points out that the figures are small and almost unreadable, which is a critical issue that needs to be addressed to improve the clarity and accessibility of the paper. It also highlights a lack of clarity in the explanation of how equation 5 follows from equation 4, suggesting that this needs to be clarified. Additionally, the comment identifies a gap in the definition of S^{*} and S^{~}, which are important parameters in the paper, and provides a specific example of where the definition is incorrect. This feedback is clear and actionable, guiding the authors on how to improve the clarity and accuracy of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It specifies that the texts in legends and axis labels should be larger, corrects the notation for Proposition 1, and suggests increasing the font size for captions and legends in Figures 2 and 3. These instructions are clear and direct, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 6\" and \"Fig. 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear instructions on what needs to be addressed, such as increasing the font size for legends and axis labels and correcting the notation for Proposition 1. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and suggestions for improvement, such as increasing the font size for legends and axis labels. It does not contain any subjective opinions, claims, or suggestions that require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting improvements to the font size of texts in legends and axis labels, as well as correcting the notation for Proposition 1. It also points out a potential confusion between Proposition 1 and Equation 1. These suggestions are clear and direct, offering the authors concrete steps to enhance the readability and clarity of their paper. By addressing these issues, the authors can improve the overall presentation and understanding of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison against Journey TRAK [1] at a particular step of the sampling trajectory for their counterfactual experiments. It specifically mentions Figure 2 from [1], which shows a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback provides a clear and explicit action for the authors to take, along with concrete guidance on how to implement it by referencing a specific figure and method. The authors know exactly what comparison to make and where to focus their efforts, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely a comparison against Journey TRAK at a particular step of the sampling trajectory, and provides a specific reference to Figure 2 in [1] to support the suggestion. This level of detail and explicit guidance makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the counterfactual experiments should include a comparison against Journey TRAK [1] at a particular step of the sampling trajectory. It provides a specific reference to Figure 2 in [1], which shows a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This reference supports the claim by providing a concrete example and evidence for the suggested comparison. The comment is mostly verifiable as it offers a clear rationale and specific reference, but it could be strengthened by further elaborating on the significance of this comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It recommends including a comparison against Journey TRAK [1] at a particular step of the sampling trajectory, referencing Figure 2 in [1] to illustrate the potential benefits of this comparison. This feedback is clear and offers a concrete way for the authors to enhance the depth and relevance of their analysis. By suggesting a specific comparison and referencing a relevant figure, the comment empowers the authors to make a meaningful improvement to their draft. Therefore, it is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation from the experimental results, noting that the placement of adaptive convolutions seems to be important for performance. However, it does not provide any explicit or implicit suggestions for how the authors might address this observation or improve their analysis. The comment lacks actionable guidance, such as recommending additional experiments, further analysis, or a discussion of the implications of this finding. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation from the experimental results regarding the performance of adaptive convolutions and suggests that the placement of these convolutions is important. The comment further notes the absence of analysis or comments on this aspect, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the placement of adaptive convolutions is important based on the observation that ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer). However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why the placement of adaptive convolutions is important or how it affects performance. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some insight but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific observation from the experimental results, noting that the placement of adaptive convolutions seems to be important for performance. It points out that ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is crucial. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might analyze or discuss this finding further. Without actionable feedback or additional context, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights an area for potential exploration but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the trade-off between computation time reduction and the loss of information in the output of the proposed method compared to a previous work. It questions the extent to which the ancestral graphs encode the information of DAGs. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The authors are left to infer that they might need to provide more detailed analysis or discussion on this trade-off, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the comparison with [10], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the trade-off between computation time reduction and the loss of information in the output. The comment raises a question about the extent to which ancestral graphs encode the information of DAGs, which provides a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the trade-off between computation time reduction and the loss of information in the output of the proposed method compared to a previous work. It provides a logical reasoning by explaining that the reduction in computation time is achieved by limiting the search space to ancestral graphs, which results in less information compared to the output of the previous work with a richer search space of DAGs. However, the comment lacks specific references or examples to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a trade-off in the proposed method, specifically the reduction in computation time achieved by limiting the search space to ancestral graphs, which results in a loss of information compared to the output of a previous work with a richer search space of DAGs. This observation is relevant and highlights a potential limitation of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this trade-off or improve their work. While it points out an important consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the theoretical discussions could be improved by providing sample complexity-type results for not returning NSF, given confidence levels. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement these results or what specific aspects of the theoretical discussions need improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical discussions,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting improvements, such as providing sample complexity-type results for not returning NSF. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the theoretical discussions could be improved by providing sample complexity-type results for not returning NSF. The reviewer expects some results related to the sufficient amount of training data points that would not return NSF, given confidence levels. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems follow directly from the algorithm design and the well-known property of mutual information to $\\Delta_{DP}$. It provides a constructive suggestion by expecting sample complexity-type results for not returning NSF, given confidence levels. This feedback is clear and actionable, as it guides the authors to consider additional theoretical aspects that could enhance the paper. However, the comment could be more helpful if it included specific examples or references to guide the authors in implementing these suggestions. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer clarifies that a VAD should look for the presence of speech and is typically defined over time, not frequency. This feedback provides a clear and direct action for the authors to reconsider their VAD description and ensure it aligns with the expected characteristics of a VAD. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Your VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is puzzling about the VAD description and provides a detailed explanation of what a VAD should entail. The comment explains that the VAD is not properly defined and suggests that it should focus on the presence of speech rather than just energy, and should be defined over time rather than frequency. This level of detail provides clear guidance on what needs to be addressed in the VAD description, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should entail, emphasizing that it should focus on the presence of speech and be defined over time, not frequency. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or literature to further substantiate the claim, which would align with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and specific critique of the VAD description, pointing out that it is puzzling and does not align with the expected characteristics of a VAD. The reviewer explains that the VAD is not properly defined, as it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The comment also clarifies that a VAD should focus on the presence of speech and be defined over time, not frequency. This feedback is highly actionable, as it identifies a significant issue with the VAD description and provides clear guidance on how to address it. By highlighting the discrepancy between the current VAD description and its expected characteristics, the comment empowers the authors to make necessary improvements to their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a brief discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what the authors should discuss, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a brief discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion section, where such a discussion could be included. The suggestion is specific, as it provides a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This suggestion is supported by logical reasoning and a clear example, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have explored this aspect. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors include a brief discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is actionable and provides clear guidance on how to enhance the discussion section of the paper. By addressing this suggestion, the authors can improve the comprehensiveness and depth of their analysis, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchor-based regression and the regression in RepPoints. It also mentions that RetinaNet and ATSS use a one-shot regression, which is similar to the method in RepPoints. The reviewer suggests that the authors clarify this issue, as the motivations for the methods may not be solid without a clear distinction. While the comment implies that the authors should clarify the definitions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the doubts about the definitions in Table 1, particularly the distinction between anchor-based regression and the regression in RepPoints. The comment further explains the similarities between RetinaNet, ATSS, and RepPoints, and suggests that the authors clarify the issue to solidify the motivations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchor-based regression and the regression in RepPoints. It references other works like RetinaNet and ATSS, which use a one-shot regression, and suggests that the method of directly regressing [w, h] to the center point is sufficient. The reviewer expresses a lack of clarity regarding the motivations and suggests that the authors clarify the issue. While the comment provides some context and references, it lacks detailed reasoning or specific examples to fully substantiate the claim. The authors would need to explore the referenced works to fully understand the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the definitions in Table 1, specifically questioning the distinction between anchor-based regression and the regression in RepPoints. It references other works like RetinaNet and ATSS, which use a one-shot regression, and suggests that the method of directly regressing [w, h] to the center point is sufficient. The reviewer also expresses doubt about the motivations for using RepPoints, given the similarities with other methods. This feedback is mostly helpful as it identifies a potential confusion in the paper and prompts the authors to clarify the distinctions and motivations. However, it could be more helpful if it provided specific suggestions on how to address the issue or clarify the differences. Overall, the comment is actionable and provides valuable insight for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together, resulting in experiments that are difficult to understand. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of the paper. The comment lacks actionable details, such as recommending specific changes to the presentation or experiments to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper\\'s lack of clarity and difficulty in understanding the pieces that fit together. However, it does not specify which parts of the paper are particularly challenging to follow or what specific aspects need improvement. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what changes or improvements would enhance clarity. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate why the experiments are difficult to understand or how the presentation could be improved. Without specific examples or detailed justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the pieces fit together. This feedback highlights a critical weakness in the paper\\'s presentation and structure, which can impact the understanding and interpretation of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or structure of the paper. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to address it. Therefore, the comment is somewhat helpful, as it points out a significant issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses this training method or where the KID/FID metrics should be included. While the authors might infer that it relates to the methodology or results sections, the lack of explicit references makes it weakly grounded. The comment is specific in its request for metrics, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment lacks specific reasoning or evidence to support the claim that this training method is unfair or how it might impact performance. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network, which could provide valuable insights into the performance of the teacher network. While the comment identifies a potential issue and provides a specific request for additional metrics, it lacks depth and does not offer detailed guidance on how to address the fairness concern or interpret the KID/FID metrics. The feedback is somewhat helpful as it points out an area for improvement but could be more comprehensive with additional suggestions or explanations. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. While the comment implies that the authors should consider this scaling factor, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they should consider the scaling factor but are not given concrete steps on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning the scaling factor and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. The reviewer provides a logical reasoning by explaining the relationship between the attention weight and the scaling factor. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the implications of this scaling to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. This feedback is somewhat helpful as it identifies a potential issue with the scaling of the vector and prompts the authors to consider an alternative approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular scaling method or explaining the potential benefits of introducing a scaling variable. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the LLM\\'s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the LLM\\'s performance or what specific changes should be made to enhance the recovery of formal goal predicates. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the LLM\\'s performance on the ALFRED benchmark, particularly regarding goal misspecification. However, it does not specify which part of the paper discusses the LLM\\'s performance or where the issue of goal misspecification is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\\'s performance, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate. The comment provides a logical explanation by mentioning the challenges posed by ambiguities in human language. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further investigate the issue to fully understand and address the problem. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the LLM\\'s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is somewhat helpful as it highlights a potential weakness in the LLM\\'s performance and provides some insight into the cause of the issue. However, the comment lacks actionable suggestions or guidance on how the authors might address this problem, such as recommending specific techniques or modifications to improve the LLM\\'s performance. Without actionable advice, the authors may find it challenging to implement the necessary changes to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the improvement of the method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. It also questions whether it is difficult for Sampling-Gaussian to significantly improve iterative frameworks similar to IGEV. While the comment implies that the authors should conduct additional analysis and provide comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific analyses required and how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this method\" and \"SOTA methods such as IGEV,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvement of the method over SOTA methods and suggesting an analysis of the distribution of disparities produced by IGEV compared to other baselines. Additionally, it raises a concern about the difficulty of improving iterative frameworks similar to IGEV. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the small improvement of the method over SOTA methods like IGEV and questions whether this implies a lack of multi-peak distribution problems in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the reviewer questions the difficulty of improving iterative frameworks similar to IGEV. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the small improvement or the need for further analysis. This makes the claim somewhat verifiable, as it requires additional evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the small improvement of the method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially address a critical issue in their work. Additionally, the comment raises a question about the difficulty of improving iterative frameworks similar to IGEV, which prompts the authors to consider the broader context of their work. However, the comment could be more helpful if it included suggestions on how to conduct the analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to implement it or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections discussing the models and their performance. The suggestion is specific in detailing what additional analysis could be included, such as comparing FPR between models. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This claim is somewhat verifiable as it provides a specific suggestion for enhancing the paper\\'s analysis, but it lacks detailed reasoning or examples to fully substantiate the need for this additional investigation. The authors would need to infer the potential benefits of this analysis themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should include a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It provides a concrete example of how this could be achieved by comparing false positive rates (FPR) between models with and without ReGuide. This feedback is actionable and offers a clear direction for the authors to enhance their analysis, providing valuable guidance for improving the depth and nuance of their conclusions. However, the comment could be more helpful if it included additional suggestions or examples of other aspects that could be explored. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific and concrete, as it directly instructs the authors on what needs to be clarified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests clarifying whether Fourier modes are real or complex when discussing them as numbers. However, it does not specify which part of the paper this discussion occurs in, making it weakly grounded. The comment is specific in its request for clarification, as it identifies a particular aspect of the paper that needs clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their work. By addressing this suggestion, the authors can enhance the comprehensibility of their paper for readers. However, the comment could be more helpful if it provided additional context or examples to further guide the authors on how to make this clarification. Overall, the comment is somewhat helpful as it identifies a clear area for improvement but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific error in the paper, namely the incorrect reference to Fig. 5.1 instead of Fig. 1. It provides a clear and direct action for the authors to take, which is to correct the reference and ensure that the label is placed after the caption in LaTeX. This feedback is concrete and leaves no ambiguity about what needs to be done to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect reference to Fig. 5.1 instead of Fig. 1, and provides a solution by suggesting the correct placement of the label in LaTeX. This level of detail guides the authors on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding a typographical error in the paper, specifically the incorrect reference to Fig. 5.1 instead of Fig. 1. It provides a clear and specific suggestion for the authors to correct the error by placing the label after the caption in LaTeX. This feedback is factual and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback regarding a typographical error in the paper. It identifies a mistake in the reference to Figure 1, which should be corrected to Figure 5.1. Additionally, it offers a clear solution by suggesting the correct placement of the label in LaTeX, which is a straightforward and effective way to address the issue. This level of detail and guidance empowers the authors to make a precise correction, ensuring the accuracy and clarity of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the input and output domains of the notations $h, g$, and $\\delta$. It suggests that these notations appear without proper context, and while $\\delta$ has a brief description, the others do not. This feedback implies that the authors should provide more detailed explanations for these notations, including their input and output domains. However, the comment does not explicitly instruct the authors to add this information, leaving the action somewhat implicit. While the authors can infer the need for clarification, the comment lacks concrete guidance on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the notations $h, g$, and $\\delta$, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the input and output domains of these notations, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the appearance of notations $h, g$, and $\\delta$ without proper context, specifically asking for clarification on their input and output domains. While the comment highlights a lack of clarity, it does not provide any specific reasoning or evidence to support why this lack of context is problematic or how it affects the understanding of the paper. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, specifically the notations $h, g$, and $\\delta$. It points out that these notations appear without proper context, questioning their input and output domains. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue. It does not provide specific examples or recommendations for clarifying the notation, leaving the authors with a general understanding of the problem but without actionable steps to resolve it. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This is a clear and direct action for the authors to take, providing them with a specific task to enhance their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be supplemented, namely, the result comparison between the two methods. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests supplementing the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by adding additional analysis or results. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\\'s overall impact. Despite this, the feedback is mostly helpful as it guides the authors toward a specific enhancement that could strengthen their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper is missing ablations and suggests that the authors include results using the GCPG model without pre-trained initializations. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is explicit and provides detailed guidance on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely ablations to determine the performance gain due to the task formulation and pre-trained language models. The comment provides a clear and actionable suggestion to include results using the GCPG model without pre-trained initializations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are unclear regarding the contribution of the task formulation and pre-trained language models to the performance gain. It suggests including results using the GCPG model without pre-trained initializations to clarify this. The comment provides a logical reasoning for the need to clarify the contribution of each component, which is a common practice in experimental evaluations. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of this suggestion based on the provided reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s results, specifically the lack of ablations to determine the contribution of the task formulation and pre-trained language models to the performance gain. It provides a clear and actionable suggestion to include results using the GCPG model without pre-trained initializations, which would help clarify the impact of each component. This feedback is valuable as it directs the authors to a specific area for improvement, enhancing the comprehensiveness and clarity of their results. However, the comment could be more helpful if it offered additional context or rationale for why these ablations are important. Overall, the comment is mostly helpful, as it provides actionable guidance that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it recommends adding references next to baseline names in tables, specifying that if a baseline name refers to a paper method, the citation should be placed next to it. This is a clear and concrete suggestion that the authors can follow. Second, it points out that in Corollary 1, the term \"$\\\\Omega$\" is not explicitly defined, but it is not hard to infer what it means. This is also a clear and actionable suggestion, as it directs the authors to clarify the definition of \"$\\\\Omega$\" in the text. Both actions are explicit and provide concrete guidance, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables\" and \"Corollary 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: adding references next to baseline names in tables and defining the term \"$\\\\Omega$\" in Corollary 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim suggests adding references next to baseline names in tables, which is a straightforward recommendation without any subjective opinion or judgment. The second claim points out that \"$\\\\Omega$\" is not explicitly defined in Corollary 1, but it is not hard to infer what it means. This is a factual observation that does not require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific and actionable suggestions for improvement. First, it recommends adding references next to baseline names in tables, which would help readers understand the context of the baselines and their sources. This is a clear and concrete suggestion that can enhance the clarity and completeness of the paper. Second, it points out that the term \"$\\\\Omega$\" is not explicitly defined in Corollary 1, but it is not hard to infer what it means. This feedback prompts the authors to clarify the definition, which is important for the reader's understanding. Both suggestions are clear and actionable, making the comment highly helpful for the authors in improving their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to clarify the axes or what information should be included to make them more understandable. Without any actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the difficulty in understanding the axes of Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is somewhat helpful as it points out a potential area for improvement in the clarity of the figure. However, it lacks actionable guidance or suggestions on how the authors might clarify the axes or improve the figure\\'s readability. Without specific advice or examples, the authors may struggle to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit instructions on how to incorporate these results or what specific aspects of the proposed method should be tested on ImageNet. The action is implicit and somewhat vague, as the authors are left to infer that they should include ImageNet results but without detailed guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper should include these results or how they would enhance the method\\'s credibility. Without explicit references to sections, figures, or specific aspects of the paper, the authors cannot confidently determine where to incorporate these suggestions. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any reasoning, examples, or references to support why ImageNet results would be more convincing or how they would enhance the method\\'s credibility. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate ImageNet results or what specific aspects of the method should be tested on ImageNet. The feedback is somewhat helpful as it points out a direction for enhancement, but it does not offer detailed or actionable advice, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that direct runtime comparisons with existing methods are missing, emphasizing the need for such comparisons to demonstrate the efficiency of the proposed approach. The comment provides a clear and concrete action for the authors to take, which is to include direct runtime comparisons with existing methods. This feedback is highly actionable as it specifies exactly what the authors need to do to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, which allows the authors to identify the specific part of the paper that needs attention. It also specifies the issue by pointing out the absence of such comparisons and the importance of demonstrating the efficiency of the proposed approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by stating that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific existing methods or providing examples of how such comparisons would be beneficial. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of direct runtime comparisons with existing methods. It highlights the importance of such comparisons to demonstrate the efficiency of the proposed approach, particularly given the computational costs associated with implicit differentiation. This feedback is clear and actionable, providing the authors with a concrete step to enhance their draft by including direct runtime comparisons. However, the comment could be more helpful if it suggested specific methods to compare against or provided guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning, and it does not identify any technical contribution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this critique. The comment lacks actionable details, leaving the authors without a clear understanding of what changes, if any, are needed to enhance their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed framework as a simple combination of meta-learning and federated learning, suggesting that it lacks technical contribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the framework are considered simple or how it could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning, suggesting that it lacks technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the framework are considered simple or how they could be improved, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the proposed framework as a simple combination of meta-learning and federated learning, suggesting that it lacks technical contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance their work or address the perceived lack of technical contribution. The comment lacks actionable guidance or constructive criticism, leaving the authors without a clear understanding of what improvements could be made. As a result, the comment is not helpful at all, as it does not offer any value to the authors in terms of improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the insufficient contribution of the paper, specifically noting that while the authors studied the connection between complementary and model robustness, they did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment implies that the authors should expand their work to provide more insights, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more depth to their findings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, specifically critiquing the lack of further studies on how to leverage the connection between complementary and model robustness to improve robustness. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. The authors can infer that it relates to the conclusion or discussion sections, but this inference is not explicit. The comment is specific in detailing what is missing, namely more insightful findings or possible solutions, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper is insufficient, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the conclusion could be easily obtained. This makes the claim somewhat verifiable, as it requires further elaboration or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of contribution beyond the analysis of the connection between complementary and model robustness. It points out that the paper does not explore how to leverage this connection to improve robustness, which is a critical area for further study. The comment provides a clear and actionable suggestion by recommending that the authors should include more insightful findings or possible solutions to enhance the paper\\'s contribution. This feedback is valuable as it guides the authors on how to improve their work by offering a specific direction for future exploration. However, the comment could be more helpful if it provided examples or specific suggestions on what kind of insights or solutions could be explored. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the choice of focusing on which clusters are \"best\" rather than exploring the differences in representation between them, given the paper\\'s motivation. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their focus, but it lacks concrete details on how to make this change or what specific aspects of the representation differences should be explored. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\\'s motivation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the focus on \"best\" clusters, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\\'s motivation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is odd or how it deviates from the paper\\'s motivation. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\\'s motivation. This feedback highlights a potential mismatch between the paper\\'s objectives and its approach, which could be a significant issue. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or what alternative approaches could be considered. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct the caption for Figure 7, specifying that it should be changed from \"Node Dynamics\" to \"Edge Dynamics.\" This is a clear and direct action that the authors can take to improve their draft. The comment provides concrete guidance on what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, indicating that it should be corrected to \"Edge Dynamics\" instead of \"Node Dynamics.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement about the incorrect caption for Figure 7. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely descriptive and factual, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly specific and actionable, as it identifies a clear error in the caption for Figure 7. By pointing out the incorrect label (\"Node Dynamics\" instead of \"Edge Dynamics\"), the comment provides the authors with a precise and straightforward correction to make. This feedback is valuable as it directly addresses a specific issue in the paper, allowing the authors to make a simple but important improvement. However, the comment could be more helpful if it provided context or explained why the correction is necessary. Overall, the comment is mostly helpful, as it guides the authors toward a specific improvement that can enhance the clarity and accuracy of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of how this could be done, mentioning the Element-level Graph Pre-training and suggesting a specific reference for a case study. This feedback is explicit and provides concrete guidance on how to improve the draft by including additional examples and studies. The authors know exactly what needs to be done to enhance the clarity and persuasiveness of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Element-level Graph Pre-training. It provides an example of how this could be done by referencing a specific paper, \"Graph pre-training for AMR parsing and generation.\" This provides clear guidance on what needs to be addressed and offers a concrete example for improvement. The comment is fully grounded as it explicitly mentions the Element-level Graph Pre-training, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular approach and references an external work for further guidance. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies would enhance the paper\\'s effectiveness. It provides a specific example of how the Element-level Graph Pre-training could be better explained by referencing a particular study. This provides a clear and logical reasoning for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by including more detailed examples or references to support the claim fully. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by recommending the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. It offers a concrete example of how this could be done, referencing the Element-level Graph Pre-training and suggesting a specific reference for a case study. This feedback is actionable and provides clear guidance on how the authors can enhance the persuasiveness of their work. However, the comment could be more helpful if it offered additional examples or detailed suggestions on how to conduct these case studies. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in evaluating disentanglement (D). It implies that the authors should clarify the motivation for considering these aspects as additional evaluations. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions to take. The authors can infer that they need to clarify their rationale, but the lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"traditional DCI framework,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with evaluating disentanglement (D) using a fixed capacity of probing (f) and the need to clarify the motivation for considering explicitness (E) and size (S) as extra evaluations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in evaluating disentanglement (D). The reviewer provides a specific example of how changing the capacity of probing (f) or the latent size could affect the DCI evaluation. This reasoning is logical and provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in evaluating disentanglement (D). It provides a specific example of how changing the capacity of probing (f) or the latent size could affect the DCI evaluation, which is a clear and actionable insight. The comment also raises a question about the motivation for considering explicitness and size as additional evaluations, prompting the authors to clarify their rationale. This feedback is valuable as it highlights a potential weakness in the framework and encourages the authors to provide a more comprehensive explanation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue of missing standard deviation after multiple experiments and suggests that the author should clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement brought by SoRA compared to the baseline is limited and may be due to random fluctuations. However, it does not provide specific examples or data to support this claim, nor does it reference any external sources or studies that could substantiate the assertion. The lack of detailed evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experimental section of the paper, where the standard deviation after multiple experiments is not provided. It suggests that the improvement brought by SoRA compared to the baseline may be due to random fluctuations, and it advises the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and actionable, as it directs the authors to provide additional statistical analysis to support their claims and differentiate between random fluctuations and actual improvements. By addressing this point, the authors can enhance the robustness and clarity of their experimental results. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out several issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. While the comment identifies specific problems, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the organization and layout of their paper, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not provide detailed instructions on how to implement those changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, such as the font size of annotations in figures, the placement of figures and tables, and formatting errors. The authors can accurately identify the parts of the paper being addressed, such as Figure 1, Figure 2, and Table 2. Additionally, the comment is specific because it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well organized and provides specific examples of issues with the layout, such as font size, figure placement, and table insertion. However, it lacks detailed reasoning or references to support these claims, such as comparisons to other well-organized papers or guidelines for proper layout. The comment provides some evidence through specific examples, but it does not fully substantiate the claim with comprehensive reasoning or references. Therefore, the comment is somewhat verifiable, as it provides some support but lacks detailed justification or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues with the organization and layout of the paper, such as font size, figure placement, and table insertion. It provides clear and actionable feedback by pointing out specific areas that need improvement, such as the font size of annotations in figures and the placement of figures and tables. This feedback is valuable as it guides the authors on how to enhance the readability and presentation of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of well-organized papers for reference. Overall, the comment is mostly helpful as it effectively directs the authors to improve the organization and layout of their paper, but it could be more comprehensive with additional guidance or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not provide explicit guidance on how to address this concern or what specific steps the authors should take to evaluate or improve the practicality and safety of their interventions. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct additional analysis or testing to ensure the practicality and safety of their interventions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider practicality and safety, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, the comment does not provide specific examples, reasoning, or references to support why these interventions might be impractical or unsafe. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important consideration regarding the practicality and safety of the interventions discussed in the paper. It suggests that the authors should think about whether these interventions are feasible and safe for real-world querying. This is a relevant point that could help the authors refine their work and ensure that their findings are applicable and usable in practical settings. However, the comment lacks specific guidance or suggestions on how the authors might address this concern, such as proposing methods for evaluating practicality or safety. While it identifies a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the notation {\\cal P} with a subscript being used multiple times without being defined. This feedback is explicit and provides clear guidance on what needs to be addressed: defining the notation {\\cal P} with a subscript. The action is concrete, as the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"same section\" where the notation {\\cal P} with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of undefined notation, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the use of notation {\\cal P} with a subscript without being defined. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation {\\cal P} with a subscript being used multiple times without being defined. This feedback is clear and actionable, as it directs the authors to define the notation to ensure clarity and consistency in their paper. By addressing this issue, the authors can improve the readability and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to define the notation or explained its significance in the context of the paper. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment consists of three separate points. The first point is a correction of a spelling error, which is explicit and concrete, providing clear guidance on how to make the correction. The second point is also explicit and concrete, requesting the definition of a specific term, which the authors can easily address. The third point is also explicit and concrete, asking for the meaning of the colors in the figure to be specified in the caption and text. Each of these points provides clear and actionable steps for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (l148 and l156) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear and actionable feedback, such as correcting a spelling error, defining a term, and specifying the meaning of colors in a figure. This level of detail guides the authors on what needs to be addressed in each part of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of three separate comments: a spelling correction, a request for a definition, and a request for clarification on the meaning of colors in a figure. These are factual statements that do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback, addressing three distinct issues in the manuscript. First, it corrects a spelling error at line 148, which is a straightforward and important improvement. Second, it requests a definition for a term, \\gamma_0^{***}, at line 156, which is a clear and helpful suggestion for enhancing clarity. Third, it asks for the meaning of the colors in Figure 1 to be specified in the caption and text, which is a logical request to improve the figure's interpretability. These specific and concrete suggestions are valuable for the authors, as they directly address areas that can be improved in the draft. Therefore, the comment is mostly helpful, as it provides clear guidance on how to enhance the manuscript, but it could be more comprehensive by addressing additional aspects of the paper. Overall, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two specific issues: the definition of \"upper faces\" of the convex hull and the lack of explicit definition for the variable \"p\" in the context of decision boundaries of neural networks. The comment suggests that the dual subdivision and projection \u03c0 need to be explained better, and it recommends defining the variable \"p\" to avoid confusion. These suggestions are explicit and provide clear guidance on what needs to be addressed in the paper. The authors know exactly what actions to take to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper that need clarification, such as the \"upper faces\" of the convex hull and the definition of the variable \"p\" in the context of decision boundaries of neural networks. This allows the authors to accurately identify the sections that require attention. The comment is also specific because it details what needs to be clarified or defined, such as the dual subdivision and projection \u03c0, and the importance of defining the variable \"p\" for clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific issues: the definition of \"upper faces\" of the convex hull and the lack of explicit definition for the variable \"p\" in the context of decision boundaries of neural networks. The comment suggests that these issues need clarification, which is a logical request for improvement. However, it does not provide detailed reasoning or examples to support why these definitions are problematic or how they impact the paper\\'s clarity. The lack of specific evidence or references makes the claim somewhat verifiable, as the authors would need to infer the importance of these clarifications themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas that need clarification: the definition of \"upper faces\" of the convex hull and the lack of explicit definition for the variable \"p\" in the context of decision boundaries of neural networks. By pointing out these issues, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of how to define \"p\" more explicitly. Despite this, the feedback is mostly helpful as it directs the authors to specific areas that require attention, making it a valuable contribution to the review process. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what changes, if any, should be made to the draft. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper need to be revised or clarified. Without explicit references to sections or examples, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\\'s skepticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of how to address this concern or what changes might be beneficial. As a result, the comment is not helpful at all, as it does not provide any actionable insights or direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the proposed method\\'s performance gain by comparing it to baseline detection or parsing techniques separately. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional evaluations to support their claims. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and its two major components, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the contribution of each component to the performance gain and suggests evaluating the proposed approach separately against baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the contribution of each component in the proposed method and suggests evaluating it separately against baseline detection or parsing techniques. This claim is somewhat verifiable as it provides a logical reasoning for the evaluation, suggesting that a more detailed analysis could support the claim. However, the comment lacks specific examples or references to baseline techniques, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the contribution of each component in the proposed method. It suggests that the authors evaluate the performance gain by comparing the proposed approach to baseline detection or parsing techniques separately. This feedback is clear and actionable, providing the authors with a concrete step to take to better support their claims. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be more interesting if the paper did not have this type of manual disentangling and everything was learned. While the comment implies that the authors should reconsider their approach to disentangling, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should explore alternative methods for disentangling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be more interesting if everything was learned rather than manually disentangled. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The reviewer suggests that it would be more interesting if everything was learned rather than manually disentangled. However, the comment lacks specific reasoning or evidence to support why this manual disentangling is problematic or how it could be improved. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the manual disentangling of the semantic segmentation network as the first module in the pipeline. It questions the rationale behind this choice and suggests that it would be more interesting if everything was learned rather than manually disentangled. This feedback is clear and actionable, as it prompts the authors to reconsider their approach and potentially explore alternative methods for disentangling. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this learning-based disentangling. Overall, the comment is mostly helpful as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the connection. The comment implies that the authors should clarify the relationship between the theoretical analysis and the proposed method, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not specify which part of the paper discusses the theoretical analysis or the proposed method, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the connection between theory and application, but it lacks grounding as it does not direct the authors to a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the connection between the theoretical analysis and the proposed method is unclear, specifically questioning how the proposed method enhances generalization for distant nodes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential disconnect between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It highlights a lack of clarity in the connection between theory and application, which is an important area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the clarity of the connection. While it points out a critical area for improvement, the feedback lacks actionable details, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what additional information or analysis should be included to clarify this point. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis where this assumption is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to justify why this assumption is important or how its absence affects the method\\'s behavior. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of concern regarding the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the method\\'s behavior. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, as it does not offer any constructive direction for the authors to enhance their work.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide explicit guidance on how the authors should address this issue or improve the clarity of the presentation. The comment implies that the authors should clarify the methods used, but it lacks concrete suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions specific elements, such as \"equation (12)\" and the \"presentation of these methods,\" which allows the authors to identify the parts of the paper being addressed. However, it does not specify what aspects of the presentation are vague or how they could be improved. The comment lacks detailed guidance on what needs to be clarified or how to enhance the clarity. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim borderline verifiable, as it requires more information to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some of the pieces are using existing methods and that the presentation of these methods is vague. This feedback is somewhat helpful as it points out a potential area for improvement, specifically the clarity of the presentation. However, the comment lacks detailed guidance or suggestions on how the authors might clarify or enhance the presentation of these methods. Without specific advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions regarding the experimental dataset and the design choices in the model architecture. While it highlights specific aspects of the paper that need clarification, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors can infer that they need to provide explanations for these design choices, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the rationale for having a separate timbre encoder module and why SADTW takes outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the paper need further explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification about the experimental dataset and the design choices in the model architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the experimental dataset and the design choices in the model architecture, particularly regarding the timbre encoder module and the input to the SADTW module. This feedback is somewhat helpful as it prompts the authors to clarify these aspects, which could enhance the comprehensibility and justification of their work. However, the comment does not provide suggestions or guidance on how to address these questions or improve the clarity of the paper. To be more helpful, the comment could include suggestions for how the authors might clarify these points or provide additional context. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include the results for all four datasets in Table 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the results for all four datasets. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 4 is incomplete because it lacks results for all four datasets. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the paper\\'s contribution. Without additional context or explanation, the claim remains unverifiable, as the authors may not understand the importance of including all datasets in the table. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 4, noting that it is incomplete because it lacks results for all four datasets. This feedback is clear and actionable, as it provides a direct suggestion for improvement by instructing the authors to include the missing results. By addressing this point, the authors can enhance the completeness and comprehensiveness of their results, which is a valuable contribution to the paper. However, the comment could be more helpful if it explained why including all datasets is important or how it impacts the paper\\'s conclusions. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples or suggestions for improvement. It lacks explicit guidance or concrete actions for the authors to take to address the issue. The comment is vague and does not offer any actionable steps for the authors to enhance the clarity of their draft. As a result, the authors are left without a clear understanding of what needs to be done to improve the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing or presentation is \"jumbled\" at times, but it does not specify which parts of the paper are affected or what aspects are unclear. This makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Without detailed guidance, the authors cannot effectively address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the writing or presentation is \"jumbled\" at times, suggesting that the paper may be difficult to follow. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on what aspects of the writing are unclear or how to improve clarity, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, as it does not offer any actionable insights or constructive feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the stability definition needs better justification, specifically addressing the issue that the left side can be arbitrarily small under some construction of \\\\tilde{g}. It proposes a more reasonable treatment by making it also lower bounded. While the comment identifies a specific issue with the stability definition and provides a suggestion for improvement, it does not explicitly instruct the authors to make the change or provide detailed guidance on how to implement the lower bound. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of the left side being arbitrarily small and make it lower bounded. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the stability definition, specifically mentioning that the left side can be arbitrarily small under some construction of \\\\tilde{g}. This provides a clear indication of the part of the paper being discussed, making it fully grounded. The comment also specifies the issue with the stability definition and suggests a more reasonable treatment by making it lower bounded. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the stability definition needs better justification because the left side can be arbitrarily small under some construction of \\\\tilde{g}. The reviewer suggests a more reasonable treatment by making it also lower bounded. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the left side can be arbitrarily small. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under some construction of \\\\tilde{g}. It suggests a more reasonable treatment by making it also lower bounded. This feedback is clear and actionable, as it points out a potential weakness in the paper and provides a specific suggestion for improvement. By addressing this issue, the authors can enhance the robustness and clarity of their stability definition. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in implementing the suggested change. Overall, the comment is mostly helpful, as it offers valuable insights and actionable advice, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that might outweigh the benefits of using IWAE. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. It lacks concrete details on what actions the authors should take to mitigate the potential bias or improve the annealing scheme. As a result, the authors are left without a clear understanding of how to proceed, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, specifically when $\\\\alpha$ is not decreased to $0$. However, it does not specify which part of the paper discusses this annealing scheme, making it weakly grounded. The comment is specific in questioning the potential bias induced by the annealing scheme and its impact on the overall results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that might outweigh the benefits of using IWAE. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the bias induced by the annealing scheme is significant. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical suggestion but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that might outweigh the benefits of using IWAE. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their methodology. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to calculate or compare computational complexity, nor does it suggest ways to address the potential power demand issue. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context by mentioning \"Woodbury flow\" and \"mobile device,\" it lacks specificity in terms of what aspects of computational complexity or power demand need to be addressed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not provide any specific evidence, examples, or references to support these claims. The comment lacks detailed reasoning or data to substantiate the concerns about computational complexity and power demand, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. While it identifies a potential area of concern, it lacks specificity and actionable guidance. The comment does not provide detailed suggestions on how to address the computational complexity or power demand issues, nor does it offer insights into how the authors might evaluate or improve these aspects. As a result, the feedback is somewhat helpful, as it prompts the authors to consider these aspects but does not fully support them in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads attending to the S2 token. It corrects the authors\\' claim by stating that these heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear correction, allowing the authors to make the necessary changes to their draft. The action is concrete, as it specifies the exact wording that needs to be corrected. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads attending to the S2 token. The comment provides a correction based on the referenced section, which helps the authors understand what needs to be revised. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' statement about the Induction, Duplicate Token, and Previous Token heads attending to the S2 token is incorrect, as it is contradicted by Section 3 of Wang et al., 2023. The comment provides a specific reference to an external source, which is a clear and robust form of evidence to support the claim. This makes the comment fully verifiable, as it offers a direct and credible source for the authors to verify the claim. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads attending to the S2 token. It corrects this claim by referencing Section 3 of Wang et al., 2023, which states that these heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and clarity of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, but rather a collection of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors could improve their work or address these concerns. The comment lacks actionable details, such as recommending specific changes or improvements that could be made to enhance the novelty or impact of the work. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that the proposed pipeline is not impressive or novel but rather a collection of tricks to improve defense evaluation. However, it does not specify which part of the paper this critique is based on, such as a particular section, figure, or experiment. Without explicit references, the authors cannot confidently determine which aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what aspects of the pipeline are considered tricks or how they could be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, but rather a collection of tricks to improve defense evaluation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or detailed justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the work, stating that the proposed pipeline is not impressive or novel but rather a collection of tricks to improve defense evaluation. However, it does not provide specific examples or details of what aspects of the pipeline are considered tricks or how they could be improved. Without actionable feedback or suggestions for enhancement, the authors are left without a clear understanding of how to address the critique or improve their work. Therefore, the comment is not helpful at all, as it lacks depth and specificity, leaving the authors without guidance on how to enhance their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. However, it does not provide explicit guidance on how to address this issue or suggest specific steps for developing a distributed version. The action is implicit and lacks concrete details, leaving the authors to infer that they need to explore scalability and potentially develop a distributed version. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. However, it does not specify which part of the paper discusses the method or its scalability, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of scalability but lacks grounding, as it does not reference a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is not scalable and suggests that a distributed version might be necessary to handle large datasets. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this scalability issue. Without detailed advice or examples, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it identifies a potential limitation but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the rationale behind the choice of a non-central chi-squared distribution for the eta_ri term. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes they should make to clarify the reasoning. The comment lacks actionable details, such as suggesting alternative explanations or methods for justifying the choice. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the choice of a non-central chi-squared distribution for the eta_ri term, but it does not specify which part of the paper discusses this term or where it is introduced. This makes it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the distribution choice, but it lacks grounding as it does not explicitly mention a section or figure. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of a non-central chi-squared distribution for the eta_ri term, but it does not provide any supporting evidence, reasoning, or references to justify why this choice is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the choice of a non-central chi-squared distribution for the eta_ri term, indicating a lack of clarity in the rationale behind this decision. However, it does not provide any suggestions or guidance on how the authors might clarify or justify this choice. Without actionable feedback or additional context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in lines 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard to support this claim. This feedback is explicit and provides concrete examples, making it highly actionable. Second, the comment critiques the reinforcement learning / agent analogy in lines 16-18, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. While the comment identifies an issue, it does not provide specific guidance on how to address it, leaving the authors to infer that they should revise or remove the analogy. Overall, the comment is mostly actionable, as it provides clear guidance on one point but requires more detail on the other.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks and referencing specific literature and a leaderboard. Additionally, it critiques the reinforcement learning / agent analogy in lines 16-18, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two distinct claims. The first claim, regarding the vagueness of the statement in line 15, is supported by a reference to specific literature and a leaderboard, providing a clear basis for the critique. This makes the claim mostly verifiable. The second claim, about the reinforcement learning / agent analogy being out of place, is supported by a logical reasoning that suggests generalization capabilities are better illustrated later in the paper. However, the comment could be strengthened by providing specific examples or references to illustrate this point more effectively. Overall, the comment is mostly verifiable, as it provides a solid foundation for the first claim but could be improved with more detailed support for the second claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard, which is a helpful addition to clarify the point. Second, the comment critiques the reinforcement learning / agent analogy in lines 16-18, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This feedback is clear and actionable, as it identifies specific areas for improvement and provides a direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to better integrate the analogy or provide examples of how generalization is better illustrated later. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: first, it notes that the proposed sensitive-layer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and second, it points out the lack of mathematical or theoretical justification for Algorithm.1. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to provide more detailed analysis or justification for these aspects, but the comment lacks concrete suggestions on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not offer specific steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed sensitive-layer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and that the authors do not further discuss this observation. Additionally, it notes the lack of mathematical or theoretical justification for Algorithm.1. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed sensitive-layer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and that the authors do not further discuss this observation. Additionally, it notes the lack of mathematical or theoretical justification for Algorithm.1. While the comment highlights specific observations and areas for improvement, it lacks detailed reasoning or references to support the claims. The absence of specific examples or detailed explanations makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but requires more detailed justification or evidence to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it points out that the proposed sensitive-layer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and the authors do not further discuss this observation. This feedback highlights a potential gap in the paper that could be addressed by providing additional analysis or discussion. Second, the comment notes the lack of mathematical or theoretical justification for Algorithm.1, which is a critical aspect of the paper. By pointing out these areas, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what a more detailed analysis or justification might entail. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuple-like structure rather than as sets. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be changed in the draft. The comment provides concrete guidance on how to improve the presentation of the data, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of triples, suggesting that they should be shown in a tuple-like structure rather than as sets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the presentation of triples as $(e_1, r, e_2)$ should be changed to a tuple-like structure instead of sets. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or understanding of the data. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of data in the paper. By recommending that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuple-like structure rather than as sets, the reviewer offers a clear and concrete way for the authors to enhance the clarity and readability of their work. This feedback is valuable as it directly addresses a potential source of confusion in the paper, guiding the authors on how to improve their draft. However, the comment could be more helpful if it explained why this change is important or how it might impact the understanding of the data. Overall, the comment is mostly helpful, as it provides actionable guidance but could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of speed analysis in the experiments, specifically noting the absence of comparisons between the proposed network and prior work regarding inference speed. It suggests that the improvement in inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include speed analysis and comparisons, it does not provide explicit instructions on how to conduct these analyses or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the need for speed analysis and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of speed analysis in the experiments, specifically noting the absence of comparisons between the proposed network and prior work regarding inference speed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the comparison of inference speed and the suggestion that such an analysis would be more interesting than reducing FLOPs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of speed analysis in the experiments is a weakness, noting that the experiments only compare GFLOPs of different segmentation networks but not the inference speed. The reviewer suggests that the improvement in inference speed would be more interesting than reducing FLOPs. While the comment highlights a potential gap in the analysis, it lacks specific examples or references to support the claim that inference speed is more important than FLOPs. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that the improvement in inference speed would be more interesting than reducing FLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and potentially highlight a more significant contribution of their work. However, it could be more helpful if it offered suggestions on how to conduct the speed analysis or what metrics to use. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the scalability of optimal quantization, which is mentioned in the paper. It also notes that even with clustering before quantization, the process is costly in terms of both the number of data points and the dimensionality. The reviewer suggests that the paper aims to speed up variational inference (VI) by achieving fast convergence, which is necessary for big data/big model settings, but that quantization is a bottleneck that undermines the method\\'s effectiveness. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their method. The action is implicit and vague, as the authors are left to infer that they need to address the scalability issue but are not given specific steps or strategies to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It also mentions the paper\\'s aim to speed up variational inference (VI) by achieving fast convergence, which is necessary for big data/big model settings. However, the comment does not specify which part of the paper discusses these issues or where the scalability bottleneck is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being addressed. The comment is specific in detailing the scalability issue and its impact on the method\\'s effectiveness, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that optimal quantization is not scalable, even with clustering before quantization, and that it is costly in terms of both the number of data points and the dimension. The reviewer supports this claim by referencing the paper\\'s own mention of scalability issues and the need for fast convergence in big data/big model settings. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the scalability issues and their impact on the method to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential scalability issue with the method, specifically mentioning that optimal quantization is not scalable, even with clustering before quantization. It highlights the costliness of the process in terms of both the number of data points and the dimension. The comment also points out that the paper aims to speed up variational inference (VI) by achieving fast convergence, which is necessary for big data/big model settings, but that quantization is a bottleneck that undermines the method\\'s effectiveness. This feedback is somewhat helpful as it alerts the authors to a critical issue with their method\\'s scalability and suggests that the quantization process may be a bottleneck. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or strategies to improve scalability. Therefore, it is rated as somewhat helpful, as it provides insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare the effectiveness of their methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. It also mentions that issues mentioned earlier should be addressed and suggests that the work should be considered for a more application-oriented venue. The comment provides clear and concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison with existing methods, such as contrastive decoding, and addressing the \"notations issues.\" This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. It mentions that issues mentioned earlier should be addressed and suggests that the work should be considered for a more application-oriented venue. However, the comment does not provide specific examples or references to existing methods or studies that should be compared, making it somewhat verifiable. The authors would need to infer which issues need to be addressed and which existing methods should be considered for comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. This comparison is crucial for evaluating the effectiveness of the proposed method. Additionally, the comment highlights the need to address issues mentioned earlier and suggests that the work should be considered for a more application-oriented venue. The inclusion of \"notations issues\" further specifies the areas that require attention. This feedback is clear and detailed, offering the authors concrete steps to enhance their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the algorithm\\'s effectiveness and problem, specifically regarding the requirement for access to the entire training dataset. It also questions the comprehensiveness of the related validation experiments and the analysis of the algorithm\\'s time complexity and efficiency. Additionally, the reviewer suggests that the authors should further clarify the technical contribution rather than focusing on the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to address these concerns. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses multiple aspects of the paper, including the effectiveness and problem of the algorithm, the comprehensiveness of the validation experiments, and the analysis of time complexity and efficiency. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the algorithm\\'s reliance on the entire training dataset, the comprehensiveness of validation experiments, and the analysis of time complexity and efficiency. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the need for the algorithm to access the entire training dataset, the lack of comprehensive validation experiments, and the absence of a clear analysis of time complexity and efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It points out the algorithm\\'s reliance on access to the entire training dataset, questioning its effectiveness when the dataset is not fully perceptible. It also notes the lack of comprehensive validation experiments and analysis of time complexity and efficiency. Additionally, the comment suggests that the authors should focus more on the technical contribution rather than the form of the attack. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions or examples on how to address these issues. Overall, the feedback is somewhat helpful as it directs the authors\\' attention to critical aspects of their work that need further development.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels. The reviewer suggests that the limitation should be made more clear. While the comment identifies a specific area that needs clarification, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels and neural networks, providing a clear explanation of why the claim is incorrect and suggesting that the limitation should be made more clear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, specifically citing the case of RBF kernels. The reviewer provides a logical reasoning by explaining that the RKHS for RBF kernels is infinite-dimensional, which would require an NN with infinite width to represent it. This reasoning is clear and provides a specific example to support the claim, making it mostly verifiable. However, the comment could be strengthened by referencing additional examples or literature to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels. The reviewer provides a clear and logical explanation of why this claim is incorrect, citing the infinite-dimensionality of the RKHS for RBF kernels. This feedback is valuable as it highlights a potential misconception in the paper and suggests that the limitation should be made more clear. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or improve the clarity of the explanation. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is not well-positioned in the literature and suggests that the authors conduct a thorough literature review to better position their work. It mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known and has been used in various works, such as denoising score matching and score-interpolation. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or which works to consider. The action is implicit and somewhat vague, as the authors know they need to conduct a literature review but may not be sure of the exact steps or scope. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this idea is well-known and has been used in various works, such as denoising score matching and score-interpolation. The comment further suggests that the authors conduct a thorough literature review to better position their work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and suggests that the key idea behind it is well-known. The reviewer supports this claim by referencing specific works, such as denoising score matching and score-interpolation, where this idea has been used. This provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the proposed method is not well-positioned in the literature. It points out that the key idea behind the method, representing the marginal score as the expectation of scores of distributions conditioned on inputs, is well-known and has been used in various works, such as denoising score matching and score-interpolation. The comment suggests that the authors conduct a thorough literature review to better position their work within the existing body of knowledge. While the feedback is clear and actionable, it could be more helpful by providing specific examples or references to guide the authors in their literature review. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the linear attention handles autoregressive decoding during inference, specifically regarding the use of limited tokens for generating the next token. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to clarify or address this issue in their draft, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the linear attention mechanism\\'s handling of autoregressive decoding during inference, specifically regarding the use of limited tokens for generating the next token. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in its inquiry about the benefits of inference, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the linear attention mechanism\\'s handling of autoregressive decoding during inference, specifically regarding the use of limited tokens for generating the next token. The comment is a request for clarification and does not contain a claim or opinion that requires verification. It is purely factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the linear attention mechanism\\'s handling of autoregressive decoding during inference. It points out a potential issue regarding the use of limited tokens for generating the next token, which could impact the benefits of inference. This feedback is valuable as it prompts the authors to consider and address a critical aspect of their methodology. However, the comment could be more helpful if it provided suggestions or guidance on how to address this issue or improve the inference process. Overall, the comment is somewhat helpful as it identifies a potential weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in constraint strength due to their gradient distributions. The comment implies that the authors should provide a gradient comparison between KL and PCC to support their claim. While the action is implicit, it is concrete in suggesting a specific analysis to conduct, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"matching metric,\" specifically the Pearson correlation coefficient (PCC), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption that PCC is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The comment provides a detailed explanation of the constraint strength of loss functions, using examples like KL divergence and MSE loss, and suggests that the authors should provide a gradient comparison between KL and PCC. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by explaining that the constraint strength of a loss function is defined by its gradient distribution, using examples like KL divergence and MSE loss to illustrate this point. However, the comment lacks specific references or detailed examples to fully substantiate the claim about PCC. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It offers a logical explanation of how the constraint strength of a loss function is defined by its gradient distribution, using examples like KL divergence and MSE loss to illustrate the point. The comment suggests that the authors should provide a gradient comparison between KL and PCC to support their claim. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for addressing it. By offering a detailed rationale and a clear direction for further analysis, the comment is highly helpful for the authors in enhancing the rigor and clarity of their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model. It also suggests considering other measures, such as behavioral trajectories or time to goal, to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. While the comment implies that the authors should consider these questions and discussions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the possibility of GPI with noise added reproducing the data similarly well and suggests considering other measures, such as behavioral trajectories or time to goal, to demonstrate the limitations of GPI. Additionally, it suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the effectiveness of Generalized Pattern Inference (GPI) with noise added, suggesting that it might not reproduce the data as well as the original GPI model. It also proposes considering other measures, such as behavioral trajectories or time to goal, to demonstrate the limitations of GPI. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to explore these suggestions themselves to fully understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important questions and suggestions that could enhance the paper. It questions the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model, suggesting that other measures, such as behavioral trajectories or time to goal, could be considered to demonstrate the limitations of GPI. Additionally, it highlights the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and suggests discussing this aspect further. These points provide clear and actionable feedback that could help the authors improve their draft by addressing specific concerns and expanding the discussion. However, the comment could be more helpful if it offered more detailed guidance on how to incorporate these suggestions or addressed potential challenges in implementing them. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. While the comment implies an action, it does not explicitly instruct the authors to perform this benchmark. Additionally, it lacks concrete details on how to implement this suggestion, such as specific parameters or conditions to test. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests conducting an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. However, it does not specify which part of the paper this method is described in, making it weakly grounded. The comment is specific in suggesting a particular benchmark to conduct, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would contribute to the paper. The suggestion is based on the reviewer\\'s personal interest, but it lacks a clear justification or explanation of its relevance to the paper\\'s content. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests conducting an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. While it identifies a potential area for further exploration, it lacks specificity and does not provide detailed guidance on how to conduct this benchmark or what specific aspects to focus on. The suggestion is somewhat helpful as it points out a possible enhancement to the paper, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from information removal. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and suggesting that the distribution might have changed. The comment further highlights specific points of confusion, such as the need for experiments to disentangle changes in distribution from information removal. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from information removal. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the basis of the critique, making it difficult to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from information removal. It also highlights specific points of confusion, such as the need for experiments to clarify these issues. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out areas for clarification, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the proposed method uses AdamW with cosine lr for training, while the comparison methods only use Adam with fixed lr. It suggests that directly comparing with the numbers in the paper is unfair and recommends reproducing the results using the same setting, as most recent methods have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the comparison methods. The suggestion is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness of directly comparing with methods that use Adam with fixed lr. The comment provides a clear suggestion to reproduce the results using the same setting as the comparison methods, which is specific and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that directly comparing the proposed method with other methods using different optimization settings is unfair. The reviewer suggests reproducing the results using the same setting as the comparison methods, as most recent methods have their code released. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action to address it. However, the comment could be strengthened by providing examples of recent methods with released code or by explaining why the specific optimization settings matter. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine lr for training, while the comparison methods only use Adam with fixed lr. The comment suggests that directly comparing with the numbers in the paper is unfair and recommends reproducing the results using the same setting as the comparison methods, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific direction to improve the fairness and validity of their comparisons. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this combination, include it in their analysis, or address it in any way. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or analysis where this combination could be discussed. Additionally, the comment does not provide any guidance on how the authors might address this curiosity or what specific aspects of the SOTA method or adaptive metric should be considered. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present a claim or opinion that requires verification. It is a factual statement or a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it acknowledges that this is not necessary, it prompts the authors to consider this combination, which could be a valuable addition to their analysis. However, the comment lacks specificity and does not provide guidance on how to incorporate this exploration into the paper or what specific aspects to focus on. The feedback is somewhat helpful as it suggests a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the plots are terrible and provides specific reasons for this assessment, such as their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are the main presentation of the experimental results and should be much clearer. This feedback is direct and provides concrete guidance on what needs to be improved, such as increasing plot size, distinguishing colors, labeling axes, and ensuring label clarity. The authors know exactly what changes to make to enhance the clarity of their plots, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the plots,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" due to their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors, and the confusion between \"s-dropout(tr)\" and \"e-dropout(tr)\" labels. This level of detail supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing suggestions on how to improve the plots, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axes, and visually similar labels. By pointing out these specific problems, the comment offers clear guidance on how to improve the clarity and presentation of the experimental results, which are crucial for the paper\\'s impact. This feedback is highly helpful as it directly addresses a critical aspect of the paper\\'s presentation and provides concrete steps for improvement. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue of low performance gains or suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance gains of the paper, specifically noting that the differences between the baseline and the best approach are less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or table that discusses performance metrics. Without explicit references, the authors cannot confidently determine which part of the paper the comment pertains to. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of performance gains. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. However, it does not provide any specific suggestions or guidance on how the authors might improve their results or address this issue. Without actionable feedback or constructive advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. While the questions imply that the authors should consider these aspects, they are not explicitly stated as actions. The authors can infer that they need to conduct additional analyses or experiments to address these questions, but the comment lacks concrete guidance on how to proceed. Therefore, the comment is somewhat actionable, as it identifies areas for exploration but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It also asks for performance metrics with and without these types of information, as well as with just natural language feedback. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the performance metrics with and without certain types of information. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the feedback network. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. This feedback is somewhat helpful as it prompts the authors to consider the impact of different types of information on the performance of the feedback network. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered guidance on potential experiments to conduct. Overall, the comment identifies a gap in the paper and encourages the authors to explore the significance of different types of information, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, it does not provide specific guidance on how to make the experiments more extensive or what additional data or analyses should be included. The comment implies an action but lacks concrete details on how to implement it, making it somewhat actionable. The authors can infer that they need to add standard deviations to Table 1 and potentially expand their experiments, but the lack of specific guidance limits the actionability of the comment.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions \"Table 1\" and suggests that it should include standard deviations, indicating a specific part of the paper that needs attention. However, it does not specify what aspects of the experiments should be more extensive or provide detailed guidance on how to achieve this. While the comment is fully grounded as it explicitly mentions \"Table 1,\" it lacks specificity regarding the improvements needed in the experiments. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, the comment does not provide any specific reasoning, examples, or references to support why the experiments are insufficient or how including standard deviations would enhance the submission. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also suggests that the experiments could be more extensive to strengthen the submission. While the comment points out a clear area for improvement, it lacks detailed guidance on how to make the experiments more extensive or what specific aspects should be included. The feedback is somewhat helpful as it highlights a potential weakness in the paper, but it could be more actionable with additional suggestions or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that using a better Unary baseline could help determine if there is still a performance boost. While the comment implies that the authors should consider using a better baseline for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. The comment raises a specific concern about the performance of the Unary model compared to a different and probably better neural network reported in [14]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that the performance of the Unary model might be worse than reported in [14], where a different and probably better neural network was used. This claim is somewhat verifiable as it provides a logical reasoning based on the comparison with an external reference ([14]). However, the comment lacks specific details or examples from [14] to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that the performance of the Unary model might be worse than reported in a referenced study, which uses a different and probably better neural network. This feedback is valuable as it prompts the authors to reconsider their baseline and potentially improve their analysis by using a more appropriate comparison. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative baselines to consider. Overall, the comment is mostly helpful as it identifies a potential weakness and encourages the authors to refine their approach, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests several actions to improve the paper, including restructuring the sections (introduction->method->experiments) and focusing more on the IEM in Figure 3, which is considered the main figure. It also recommends improving the visualization of Figures 7 and . While the comment provides explicit actions, it lacks specific guidance on how to implement these changes, such as what specific elements to focus on or how to improve the visualization. The authors know what needs to be done but may struggle with the execution details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the paper, such as restructuring the sections (introduction->method->experiments) and focusing more on the IEM in Figure 3, which is considered the main figure. It also recommends improving the visualization of Figures 7 and . However, the comment does not explicitly mention which sections are difficult to follow or where the figures are located, making it weakly grounded. The authors can infer that the issues are related to the structure and figures, but they cannot pinpoint the exact parts of the paper being addressed. The comment is specific in suggesting improvements but lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is difficult to follow and suggests improvements to the structure and focus on specific figures. However, it does not provide any specific examples or detailed reasoning to support why the paper is hard to follow or how the suggested changes would improve it. The comment lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, such as its structure and the focus on specific figures. It suggests restructuring the sections (introduction->method->experiments) and emphasizes the importance of the IEM in Figure 3, which is considered the main figure. Additionally, it recommends improving the visualization of Figures 7 and . While the comment provides actionable feedback, it could be more helpful by offering specific suggestions on how to improve the structure or visualization. Overall, the comment is mostly helpful as it directs the authors to areas that need attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. While the comment implies that the authors should expand their discussion of related work, it does not provide specific guidance on how to achieve this or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of how to implement the suggested improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This level of detail helps the authors understand exactly what needs to be addressed in the related work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is somewhat verifiable as it provides a logical reasoning for why a more detailed discussion would be beneficial, particularly in terms of differentiating the work from existing literature. However, the comment lacks specific examples or references to existing work that could be used to illustrate the differences, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, beyond merely describing the related works. It encourages the authors to discuss the differences between their work and existing literature, which could provide a clearer context for the reader. This feedback is clear and actionable, as it identifies a specific area for improvement and offers a direction for enhancing the paper. However, it could be more helpful if it provided examples of how to structure this discussion or specific aspects to focus on. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which architectures or classification tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for broader experimentation, but without grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a request for additional experiments, which is not a claim but rather a suggestion for improvement. The comment does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. This feedback is somewhat helpful as it identifies a potential limitation in the scope of the experiments and encourages the authors to broaden their evaluation. However, the comment lacks specific guidance on which architectures or classification tasks to consider, leaving the authors with a general direction but no detailed steps to take. To be more helpful, the comment could include suggestions or examples of alternative architectures or tasks that might be relevant. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests information about the final learning rates used for the deep models, particularly for CIFAR-10 and CIFAR-100. It also highlights a concern about the potential impact of the learning rate search interval on the results. While the comment clearly identifies the need for additional information, it does not provide specific guidance on how the authors should address this concern or what steps to take to ensure the learning rate is within the optimal range. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment requests information about the final learning rates used for the deep models, particularly for CIFAR-10 and CIFAR-100. It also raises a concern about the potential impact of the learning rate search interval on the results. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the experimental setup or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its request for learning rates and the potential impact on results, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the learning rates used in the experiments, specifically for CIFAR-10 and CIFAR-100. It suggests that the authors should provide the final learning rates used, as the limited search interval could impact the results. This is a logical claim based on the methodology and potential limitations of the study. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and address the concern themselves, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the learning rates used in the experiments, particularly for CIFAR-10 and CIFAR-100. It highlights the potential impact of the limited search interval on the results, suggesting that the optimal learning rate for the baseline might be outside the tested range. This feedback is clear and actionable, as it prompts the authors to provide the final learning rates used in the experiments. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending a broader search interval or providing guidance on how to determine the optimal learning rate. Overall, the comment is mostly helpful as it identifies a potential weakness and prompts the authors to improve their experimental setup, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the use of a transformer that is free of locality-bias, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. The reviewer requests an explanation from the authors regarding why the absence of locality should not be a concern. While the comment implies that the authors should provide additional justification or evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment expresses skepticism about the use of a transformer that is free of locality-bias, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment does provide some specificity by questioning the rationale behind the choice of a transformer without locality bias and requesting an explanation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses skepticism about the claim that a transformer free of locality-bias is the best option, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. The reviewer questions the rationale behind this choice and requests an explanation. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that locality-bias should be a concern. This makes the claim somewhat verifiable, as it provides a logical basis for questioning the choice but lacks the necessary evidence or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment expresses skepticism about the use of a transformer that is free of locality-bias, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. The reviewer questions the rationale behind this choice and requests an explanation from the authors. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this concern or provide the requested explanation. The feedback is somewhat helpful as it prompts the authors to reconsider their choice and provide additional justification, but it could be more actionable with specific recommendations or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. It explicitly instructs the authors to clarify this aspect, providing a clear and direct action for improvement. The comment is specific and concrete, as it tells the authors exactly what needs to be addressed and how to do so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the output from the algorithm depends on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of data processing order affecting the output, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the algorithm, suggesting that the output may depend on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or clarify the dependency. Without actionable suggestions or examples, the feedback is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or evaluate the impact of these strategies. The comment implies that the authors should consider the potential negative effects of these strategies on the model\\'s utility, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable advice, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies might impair the model\\'s utility. However, it does not specify which part of the paper discusses these mitigation strategies or where the authors should consider their impact. The authors can infer that it relates to the sections discussing model performance or mitigation strategies, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing the concern about the trade-off between reducing a particular behavior and maintaining high performance, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. The comment provides a logical reasoning by stating that if these mitigation strategies significantly impair the model\\'s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the potential trade-offs themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mitigation strategies used in the paper, specifically questioning their impact on the overall performance of the model. It highlights a common trade-off between reducing a particular behavior and maintaining high performance, suggesting that if the mitigation strategies significantly impair the model\\'s utility, it might deter their adoption. This feedback is somewhat helpful as it points out a critical area for consideration and potential consequences, prompting the authors to evaluate the effectiveness of their mitigation strategies. However, the comment lacks specific suggestions or guidance on how to address this concern, such as recommending alternative strategies or ways to balance performance and mitigation. Therefore, while it provides some insight, it could be more helpful with additional detail and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of 6-fold cross-validation in the paper, questioning the necessity of this approach given that other papers in the field do not use cross-validation. While the comment implies that the authors should provide a justification for their choice of cross-validation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the rationale behind their methodological choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of 6-fold cross-validation for each dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of cross-validation, given that other papers in the field do not use it. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, noting that other papers in the field do not use it. This claim is somewhat verifiable as it provides a logical reasoning based on the absence of cross-validation in other papers. However, the comment lacks specific references to these other papers or detailed explanations of why cross-validation is not necessary in this context. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of 6-fold cross-validation in the paper, questioning its necessity given that other papers in the field do not use it. This feedback is somewhat helpful as it prompts the authors to reconsider their methodology and provide a justification for their choice. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative methods that might be more appropriate. Overall, the comment provides a starting point for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The reviewer suggests that additional experiments or more in-depth analysis are needed to better justify the claims in the paper. While the comment implies that the authors should conduct further experiments or analysis, it does not provide explicit instructions on how to proceed or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors can infer the need for additional work but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment further suggests that additional experiments or more in-depth analysis are necessary to better justify the claims in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three, and there is no consistent trend in the results. The reviewer suggests that additional experiments or more in-depth analysis are needed to better justify the claims. This claim is somewhat verifiable as it provides a logical reasoning for the insufficiency of the results, but it lacks specific examples or references to support the need for additional experiments. The authors would need to infer the exact nature of the additional experiments or analysis required. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is clear and actionable, as it highlights a potential weakness in the paper\\'s claims and suggests that additional experiments or more in-depth analysis are necessary to better justify the benefits of the proposed methods. By pointing out this issue, the comment provides the authors with a clear direction for improving the draft, making it mostly helpful. However, it could be more helpful if it offered specific suggestions on what additional experiments or analyses might be beneficial. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the action is explicit, it lacks concrete guidance on how the authors should clarify the impact of these components. The suggestion is somewhat actionable as it directs the authors to provide more information, but it does not specify the exact steps or details needed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Non-Ambiguous Query Generation procedure\" and the \"sophisticated filtering template,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of incorporating heuristic components and suggests that the authors clarify the impact of these components. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. It specifically mentions the Non-Ambiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to clarify the impact is logical but requires more elaboration to be fully verifiable. Therefore, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure and its reliance on a sophisticated filtering template. It suggests that the authors clarify the impact of these heuristic components, which is a relevant and actionable feedback. By addressing this point, the authors can provide more context and justification for the use of these components, potentially enhancing the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to clarify the impact of these components. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises doubts about the feasibility of training the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. The reviewer challenges the logic of the method by asking how the ray's origin is determined without camera information. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or address the issue of camera information in their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without camera information, particularly regarding the determination of ray origins. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the feasibility of the proposed method by challenging the use of camera information. It raises logical concerns about how the method can perform ray marching without knowing the viewpoint and how the ray\\'s origin is determined. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to address these concerns themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. It challenges the logic of the method by asking how ray marching can be performed without knowing the viewpoint and how the ray\\'s origin is determined. This feedback is valuable as it prompts the authors to clarify a fundamental aspect of their method, which could significantly impact its effectiveness. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or offered alternative approaches. Overall, the comment is mostly helpful as it identifies a significant weakness and prompts the authors to address it, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that the authors should include a more detailed comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the comparison themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the discussion of related work, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a detailed comparison, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. This claim is somewhat verifiable as it provides a clear suggestion for improvement, but it lacks specific examples or references to prior work that could be used for comparison. The authors would need to infer which prior works should be included in the comparison and how to conduct it effectively. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that a more detailed comparison with related work, particularly in terms of time complexity and competitiveness, would enhance the paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to expand their analysis and improve the comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or references to prior work that could be used for comparison. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method, ODA, has learned a policy to imitate problem-solving but does not clearly explain how it improves performance and computation speed compared to just using ODA. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation of the method\\'s advantages. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ODA,\" one of the methods for solving the MOIP problem, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method has learned a policy to imitate problem-solving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method, ODA, has learned a policy to imitate problem-solving but does not clearly explain how it improves performance and computation speed compared to just using ODA. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the method, ODA, has learned a policy to imitate problem-solving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This feedback is somewhat helpful as it points out a gap in the explanation of the method\\'s advantages, prompting the authors to clarify their claims. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how other methods have improved performance and computation speed. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an area needing clarification but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some figures, specifically Figure 4, are not self-explanatory due to overlapping lines. It provides a specific example of the issue, which is that the lines for \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback is explicit and provides a clear action for the authors to take, which is to ensure that all lines in the figure are clearly labeled or explained to improve the figure\\'s self-explanatory nature. The comment is highly actionable as it gives precise guidance on how to address the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\\'s self-explanatory nature. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some figures are not self-explanatory, specifically mentioning Figure 4. It provides a specific example of the issue, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This level of detail supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more examples or suggesting how the authors might improve the figure\\'s clarity. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures in the paper, noting that some are not self-explanatory. It provides a concrete example by pointing out that in Figure 4, the lines for \"No adapt\" and \"Finetune\" are covered by other lines, making it difficult for readers to understand the data. This feedback is actionable as it directs the authors to improve the clarity of their figures by ensuring that all lines are clearly labeled or explained. However, the comment could be more helpful if it suggested specific ways to enhance the figure\\'s self-explanatory nature, such as adding legends or annotations. Overall, the comment is mostly helpful as it provides clear guidance on an area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the sampling performed to obtain different initializations x_0 and its importance for convergence to the optimum. It notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct more thorough experiments to evaluate the impact of different initializations on convergence. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of experimental evaluation of the sampling performed to obtain different initializations x_0, particularly on the proposed benchmarks. The comment provides a clear direction for improvement by suggesting that more thorough experimentation is needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum but is not experimentally evaluated carefully on the proposed benchmarks. The reviewer supports this claim by referencing Table 1 in the supplementary material, where the sampling is compared to sampling from a uniform distribution. This provides a specific example and reference point to substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or examples of how the sampling affects convergence. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is clear and actionable, as it highlights a gap in the experimental evaluation and suggests that the authors should conduct more thorough experiments to assess the impact of different initializations on convergence. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what metrics to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the logic behind the comparison of the proposed method with specific references, such as [9] and [16]. It questions the rationale for the order of comparison and the focus on computational cost. The reviewer also expresses confusion about the significance of computational cost in the context of the paper. While the comment highlights areas of confusion, it does not provide explicit instructions or suggestions for the authors to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the logic and rationale behind the comparisons and discuss the significance of computational cost. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the logic behind the comparison of the proposed method with specific references, such as [9] and [16]. It questions the order of comparison and the focus on computational cost, and expresses confusion about the significance of computational cost in the context of the paper. However, the comment does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact location. The comment is specific in detailing the issues with the comparisons and the lack of further discussion, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the logic and rationale behind the comparisons made in the paper, specifically questioning the order of comparison and the focus on computational cost. The reviewer expresses confusion about the significance of computational cost in the context of the paper and the lack of further discussion on this topic. However, the comment does not provide any specific evidence, reasoning, or references to support these questions or claims. Without additional context or justification, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the logic and rationale behind the comparisons made in the paper, specifically regarding the order of comparison and the focus on computational cost. It questions the significance of computational cost in the context of the paper and expresses confusion about the lack of further discussion on this topic. While the comment identifies areas of confusion, it does not provide specific suggestions or guidance on how the authors might address these issues or clarify the logic behind the comparisons. The feedback is somewhat helpful as it prompts the authors to reconsider their approach to comparisons and the significance of computational cost, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the low-resource regime. While the comment implies that the authors should expand their experimental evaluation, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the low-resource regime. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting additional experiments and datasets, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the low-resource regime. This is a request for additional experiments, which is a suggestion rather than a claim. The comment does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the lack of experimental results on more datasets, which could provide a more comprehensive evaluation of the proposed method. It suggests conducting experiments on more datasets and encourages experiments on the full dataset instead of the low-resource regime. This feedback is clear and actionable, as it directs the authors to expand their experimental evaluation, which could significantly enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on which additional datasets to consider or how to conduct these experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\\' claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their work. The feedback lacks actionable details, such as what aspects of the dataset transformation or experimental setup need to be clarified or simplified. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\\' claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. However, the comment does not specify which sections of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact parts that need revision. Additionally, while it highlights specific areas of concern, it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the clarity of how the generic argument task and the random argument task support the authors\\' claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references makes the claim somewhat verifiable, as the authors would need to infer the specific areas of concern and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in how the generic argument task and the random argument task support the authors\\' claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors may struggle to understand exactly what changes are needed to improve the clarity and effectiveness of their work. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not provide sufficient detail or direction for the authors to effectively address the issues.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the PL condition used in the paper compares to the PL conditions proposed in a specific reference, \"Global Convergence of Arbitrary-Block Gradient Methods for Generalized Polyak-\u00c5\u0081ojasiewicz Functions\". However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should address this comparison, how they should do so, or if it is relevant to their work. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference, \"Global Convergence of Arbitrary-Block Gradient Methods for Generalized Polyak-\u00c5\u0081ojasiewicz Functions.\" However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the PL conditions should be compared. This lack of explicit reference to a specific section or element of the paper makes it weakly grounded. Additionally, the comment lacks specificity as it does not detail what aspects of the PL conditions should be compared or why this comparison is important. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question asking for a comparison between the PL condition used in the paper and those proposed in a specific reference. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference. While it identifies a potential area for further exploration or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this comparison or its relevance to their work. The comment is somewhat helpful as it prompts the authors to consider a specific aspect of their methodology, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for the authors to discuss the impact of adding additional parameters and additional computational effort due to the multi-stage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. While the comment implies that the authors should include this analysis, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the idea of \"jointly discovering, hallucinating, and adapting,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. Additionally, it suggests that the authors should provide this analysis for a fair comparison with the baseline [31, 33]. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. The reviewer suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is crucial or how it would impact the comparison. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and validity of their work. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It highlights the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues. It lacks concrete details on what specific analyses or theoretical evidence should be included to improve the draft. As a result, the authors are left with a vague understanding of what needs to be done to enhance their analysis. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, which provides some grounding as it implies a specific part of the paper where this analysis is discussed. However, it does not explicitly mention the section or figure where this analysis is presented, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It questions the generalizability of this trend across different model architectures and the lack of theoretical evidence for the correlation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that is underwhelming, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. This feedback is clear and actionable, as it highlights a gap in the analysis that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to enhance the analysis or what theoretical evidence might be relevant. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to the policy being obtained by supervised training on ImageNet. It also questions the authors\\' conclusion in Section 4.2 regarding the need for pretraining datasets to match the target dataset in terms of being object or scene-centric. The comment implies that this could be a setback for SSL algorithms that aim to learn more generic representations. However, it does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to take. The feedback is implicit and somewhat vague, as it highlights potential issues but does not offer concrete steps for improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\\' conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scene-centric, and whether this could be a setback for SSL algorithms. Additionally, it raises concerns about the use of AutoAugment as a stronger augmentation strategy, suggesting potential information leakage due to the policy being obtained by supervised training on ImageNet. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to the policy being obtained by supervised training on ImageNet. It also questions the authors\\' conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scene-centric, suggesting it could be a setback for SSL algorithms. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to further explore and substantiate the concerns raised to fully understand and address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to the policy being obtained by supervised training on ImageNet. It also questions the authors\\' conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scene-centric, suggesting it could be a setback for SSL algorithms. While the comment identifies potential issues and raises thought-provoking questions, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider these issues, but it could be more actionable with additional detail or direction. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to see how the model works for tabular data, although it is not necessary. While the comment implies that the authors should consider exploring this aspect, it does not provide explicit guidance on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the model\\'s performance on tabular data but without detailed instructions on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the model\\'s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multi-modal data, but this inference is not as direct as it could be. The comment is specific in suggesting an area for exploration, but it lacks full grounding because it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to explore the model\\'s performance on tabular data, which is a form of multi-modal data. However, the comment does not provide any specific reasoning, examples, or references to support why this exploration would be beneficial or how it might impact the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests exploring the model\\'s performance on tabular data, which is a form of multi-modal data. While the suggestion is interesting, it lacks specificity and actionable guidance. The comment does not provide details on how to incorporate this exploration into the paper, such as which aspects of the model should be tested or what specific questions should be addressed. Without these details, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it provides an idea for further exploration but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It explicitly recommends adding more analysis and suggests including visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from low-resourced languages are well aligned with high-resourced ones. This feedback provides clear and concrete actions for the authors to take, including specific suggestions for additional analysis and visualizations. The explicit nature of the recommendations and the detailed guidance on what to include make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the language-agnostic characters of entity representations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the alignment of entity representations, particularly in the context of multilingual alignment. The comment suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types, which adds to the specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types. The comment is mostly verifiable as it provides a clear suggestion for improvement and offers specific examples of what could be included. However, it lacks detailed reasoning or references to existing work on multilingual alignment, which would strengthen the justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks analysis, namely the alignment of entity representations across different languages. It suggests that the authors could enhance their analysis by including more discussion on multilingual alignment and providing visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from low-resourced languages are well aligned with high-resourced ones, which could be a valuable addition to the paper. This feedback is clear and actionable, providing the authors with specific directions for improving their analysis and potentially expanding their work. However, it could be more helpful if it included examples or references to existing work on multilingual alignment, which would further guide the authors in implementing the suggested improvements. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide more details on using attention, possibly as an extra appendix. While it implies that the authors should include additional information, it does not specify what specific details should be added or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add more details on attention and where to include them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding more details on using attention, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the authors should include them. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the addition of more details on attention, but it lacks grounding as it does not pinpoint a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without further explanation or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors provide more details on using attention, possibly as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what additional details should be included or how they might enhance the paper. The feedback is somewhat helpful as it points out a gap in the paper, but it could be more actionable with more detailed suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific issues with the references list: duplicates and missing publication venues and/or years. However, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to check for duplicates and ensure that all references include the correct publication venues and years, but the comment lacks concrete guidance on how to implement these actions. Therefore, the comment is somewhat actionable, as it highlights the issues but does not provide detailed steps for resolution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the references list, namely duplicates and missing publication venues and/or years. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. This is a factual observation that can be verified by checking the references list. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it somewhat verifiable. The authors would need to manually check the references to confirm the issues, which could be time-consuming. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years. This feedback is clear and actionable, as it directs the authors to review and correct these errors in their references. By addressing these issues, the authors can ensure the accuracy and completeness of their references, which is crucial for the credibility and transparency of their work. However, the comment could be more helpful if it provided examples of duplicate references or suggested ways to verify the publication information. Overall, the comment is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it suggests that the authors need to analyze and compare the theoretical results to other comparable methods. This feedback provides a clear action for the authors to take, which is to clarify the meaning of the error bound in Theorem 1 and to compare their results with other methods. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and suggesting that the authors should analyze and compare their results with other comparable methods. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by clarifying the theoretical analysis and enhancing its relevance. However, the comment could be more helpful if it included specific suggestions on how to clarify the error bound or which comparable methods to consider. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their theoretical analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of pseudo-code for the proposed method. It provides two references, [1] and [2], which could help the authors in understanding the context of the question. However, the comment does not explicitly instruct the authors to include the pseudo-code or provide guidance on how to address the question about the performance difference. The action is implicit and somewhat vague, as the authors need to infer that they should include the pseudo-code and address the performance question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance difference between explicit and implicit methods on locomotion tasks and notes the absence of pseudo-code for the proposed method. It provides references to relevant literature, which helps ground the comment in the context of the paper. However, the comment does not specify which part of the paper discusses the explicit and implicit methods, making it weakly grounded. The comment is specific in its request for the inclusion of pseudo-code and the explanation of the performance difference. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance difference between explicit and implicit methods on locomotion tasks and notes the absence of pseudo-code for the proposed method. It provides references to relevant literature, which supports the claim by offering external sources for further understanding. However, the comment does not provide detailed reasoning or examples within the context of the paper, making it somewhat verifiable. The authors would need to refer to the provided references to fully understand the basis of the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance difference between explicit and implicit methods on locomotion tasks, which is an important point for the authors to address. It also notes the absence of pseudo-code for the proposed method, which is a critical omission that the authors need to rectify. The comment provides references to relevant literature, which can help the authors understand the context of the question and potentially guide their response. However, the comment could be more helpful if it offered specific suggestions on how to address the performance question or included more detailed guidance on how to present the pseudo-code. Overall, the comment is somewhat helpful as it identifies key areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the use of low-resource language pairs in finetuning the multilingual model and the method used to maintain generalization. It suggests that the improvement in translation from 1.2 to 2.0 is insignificant in a practical sense. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actions for the authors to take, such as recommending specific changes to the methodology or analysis. As a result, the comment is vague and does not offer actionable steps for the authors to follow. Therefore, it is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the use of low-resource language pairs further finetune the multilingual model and use the method like R3F to maintain the generalization ability of the model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the improvement in translation from 1.2 to 2.0 is insignificant in a practical sense. Additionally, it references a specific work by Aghajanyan et al. (2020) to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement in translation from 1.2 to 2.0 is insignificant in a practical sense. It supports this claim by referencing a specific work by Aghajanyan et al. (2020), which provides a logical basis for the critique. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a solid foundation but lacks comprehensive evidence or detailed analysis. This aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of low-resource language pairs in finetuning the multilingual model, suggesting that the improvement in translation from 1.2 to 2.0 is insignificant in a practical sense. It references a relevant work by Aghajanyan et al. (2020) to support the claim, which provides a basis for the critique. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their methodology. Despite this, the comment does provide valuable insight into a potential weakness in the paper, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This comment implies that the authors should provide an explanation or justification for this choice. However, it does not explicitly instruct the authors to do so, nor does it provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the reason for the limited results shown, but it lacks grounding as it does not explicitly mention a specific section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This is a factual observation that does not contain a subjective claim or opinion. It is a request for clarification, which is not a claim requiring verification. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This is a valid point that prompts the authors to provide a justification or explanation for their choice of experimental setup. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential weakness, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should visualize the effect of the existing PU learning methods\\' performance decline as the dimensionality of the data increases. This is an explicit request for a specific action, and it provides clear guidance on what the authors should do to improve their draft. The comment is concrete because it specifies the exact action needed, which is to visualize the effect. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should visualize the effect of the existing PU learning methods\\' performance decline as the dimensionality of the data increases. It mentions the research motivation of the paper, which provides some context. However, the comment does not specify which part of the paper discusses this claim or where the visualization should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting the need for visualization to support the claim. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should visualize the effect of the existing PU learning methods\\' performance decline as the dimensionality of the data increases. The comment suggests that this visualization is important because it is the research motivation of the paper. However, the comment lacks specific examples, references, or detailed reasoning to support why this visualization is necessary or how it would contribute to the paper\\'s research motivation. Without such evidence or explanation, the claim remains somewhat verifiable, as the authors may need to infer the importance of the visualization themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that the authors should visualize this effect, which is important for the research motivation of the paper. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s presentation and clarity. By visualizing the effect, the authors can better illustrate and substantiate their claim, which is crucial for the paper\\'s impact. However, the comment could be more helpful if it provided additional context or examples of how to visualize the effect. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. While it implies that the authors should consider moving this content, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion or what aspects of the objective should be included in the supplementary materials. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests moving the empirical version of the objective (3) to the supplementary materials. However, it does not specify which part of the paper this objective is currently located in, making it weakly grounded. The comment is specific in suggesting a potential relocation, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. However, it does not provide any reasoning or evidence to support this claim, such as why this content is better suited for the supplementary materials or how it would enhance the main text. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. While it identifies a potential area for improvement, it lacks specificity and does not provide a clear rationale or explanation for why this change would be beneficial. The feedback is somewhat vague, as it does not offer detailed guidance on how to implement this suggestion or what specific aspects of the objective might be better suited for the supplementary materials. Therefore, the comment is barely helpful, as it provides limited value to the authors in terms of actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the result description, noting that it is unnecessarily convoluted. It provides suggestions for improvement, such as referencing a related idea from [1] and checking for useful communication in light of [2]. The comment also mentions that the differences in figures seem too small and that the topography plots indicate something reasonable. While the suggestions are explicit, they are not fully actionable as they do not provide detailed guidance on how to implement the changes or what specific aspects of the result description need to be clarified. The authors have a general direction to follow but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific examples of convoluted result descriptions, such as \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides suggestions for improvement, such as referencing a related idea from [1] and checking for useful communication in light of [2]. Additionally, it points out that the differences in figures seem too small and that the topography plots indicate something reasonable. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the result description is unnecessarily convoluted, providing specific examples such as \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" The reviewer suggests improvements by referencing related work and suggesting checks for useful communication. The references to [1] and [2] provide some support for the claim, but the comment could be strengthened by elaborating on how these references relate to the specific issues identified. Overall, the claim is mostly verifiable, as it provides a basis for the critique but lacks detailed explanation or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the result description, noting that it is unnecessarily convoluted. It provides actionable suggestions for improvement by referencing related work and suggesting checks for useful communication. The comment also points out that the differences in figures seem too small and that the topography plots indicate something reasonable. This feedback is clear and provides the authors with specific guidance on how to enhance the clarity and relevance of their results. However, the comment could be more helpful if it included more detailed suggestions on how to rephrase or present the results. Overall, the comment is mostly helpful as it offers constructive feedback and actionable steps for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the approximation error is defined as the gap between objective values, which is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization to clarify this point. While the comment implies that the authors should include a mathematical definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to mathematically characterize the approximation error. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the definition of approximation error, specifically mentioning the gap between objective values. However, it does not specify which part of the paper discusses this definition, making it weakly grounded. The comment is specific in suggesting a mathematical characterization to clarify the ambiguity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the definition of approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not offer any specific reasoning or examples to support why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the definition of approximation error, noting that it is unclear without seeing the values in the table. It suggests providing a mathematical characterization to clarify this point. While the comment highlights an area for improvement, it lacks specific guidance on how to mathematically characterize the approximation error or what aspects of the definition need clarification. This limits the helpfulness of the feedback, as it provides a general direction but not detailed actionable steps. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully guide the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the explanation of Corollary 10 in lines 180-182, noting that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or improve the explanation, leaving the authors without a clear understanding of what steps to take to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (180-182) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue with Corollary 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out the limitations of the corollary, which is a deductive observation based on the information provided. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially provide additional evidence or clarification to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the explanation of Corollary 10 in lines 180-182, pointing out that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is somewhat helpful as it highlights a potential misunderstanding or misinterpretation in the paper, prompting the authors to clarify or expand their explanation. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or additional evidence. Therefore, while it points out a relevant area for improvement, it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the proposed model: first, that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\\'s dynamics; and second, that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their model. The feedback lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the model\\'s complexity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the proposed model, such as the reassignment probability and the evolution model, allowing the authors to identify the parts of the paper being discussed. However, it does not specify what needs to be addressed or improved in these aspects, making it weakly grounded but specific. The authors can infer that the comment is related to the methodology or results sections, but it lacks detailed guidance on how to address the issues raised. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\\'s dynamics. It also states that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific issues with the proposed model: first, that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\\'s dynamics; and second, that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment highlights important limitations, it does not provide actionable suggestions or guidance on how the authors might address these issues or improve their model. The feedback lacks depth and specificity, leaving the authors with a general understanding of the problems but without clear steps to take for improvement. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add details about the division of the dataset into training and test sets, including the numbers and the method used for division (e.g., random or with other considerations). This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what information to include in their draft. The comment is explicit and provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need for details about the division of the dataset into training and test sets, including the numbers and the method used for division. This provides full grounding as it clearly identifies the specific part of the paper that needs attention, allowing the authors to accurately pinpoint the section. The comment is also specific because it details what is missing and what needs to be added, such as the numbers and the method used for division. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests additional details about the division of the dataset into training and test sets, including the numbers and the method used for division. This is a factual request for clarification, as it does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks details, namely the division of the dataset into training and test sets. It requests information on the numbers and the method used for division, such as whether it was random or involved other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and details on what information is missing. By including this information, the authors can enhance the transparency and rigor of their experimental setup, which is crucial for reproducibility and credibility. However, the comment could be more helpful if it suggested alternative methods for division or provided examples of how this information could be presented. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with long-text input. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks specific guidance on how to address these concerns or improve the draft. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with long-text input. However, the comment does not specify which part of the paper these concerns relate to, making it weakly grounded. The authors might infer that it pertains to the methodology or results sections, but this inference is not direct. Additionally, while the comment highlights specific issues, it does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning. It also mentions the potential scalability issue with long-text input. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The general statements about scalability and the need for human labor are not substantiated with evidence or detailed explanations, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with long-text input. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these concerns or improve their work. Without detailed guidance or examples, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies areas for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance improvement of the proposed methods, as shown in Figure 3, does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. While the comment implies that the authors should consider presenting their results in a more detailed and intuitive manner, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on presenting their results in a more detailed and intuitive way. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. The comment further suggests using tables to directly show key improvements, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, particularly in the bank dataset where the improvement is only ~0.02. The reviewer suggests using tables to directly show key improvements, which could be more intuitive and detailed. However, the comment lacks specific examples or references to support the claim about the lack of significance or the suggestion for using tables. Without detailed evidence or comparisons, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance improvement of the proposed methods, as shown in Figure 3, particularly in the bank dataset where the improvement is only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. This feedback is clear and actionable, as it provides a specific area for improvement and a concrete suggestion for enhancing the presentation of results. By addressing this feedback, the authors can better highlight the significance of their work and improve the clarity of their findings. However, the comment could be more helpful if it provided additional context or examples of how to present the results in tables. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which could be helpful for the authors to consider. However, the feedback is somewhat vague as it does not explicitly instruct the authors on how to address these issues or improve their experimental validation. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which helps ground the comment by providing a clear direction for the authors to consider. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the consideration of deeper networks and the optimization strategy. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental validation is not convincing due to the lack of consideration for deeper networks and the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which supports the claim about the positioning of the work. However, the claim about the experimental validation lacks detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed justification for the authors to fully understand and address the issues raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the experimental validation and positioning of the work. It points out that only shallow networks (2 or 3 layers) are considered, which limits the generalizability of the results. Additionally, it notes the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. The comment also highlights a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. While the comment effectively identifies these weaknesses, it could be more helpful by providing specific suggestions on how to address these issues or improve the experimental setup. Overall, the feedback is somewhat helpful as it directs the authors to areas that need attention but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. The comment lacks explicit guidance or suggestions for the authors to address this issue, such as proposing new theoretical results or providing a rationale for the novelty of the loss function. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. The comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. It does not specify which part of the paper this claim pertains to, nor does it detail what theoretical results are lacking or how they could be improved. Without specific references or guidance, the authors cannot effectively address the feedback. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples, references, or detailed justification to substantiate the claim that no new theoretical results are proven. Without such evidence, the claim remains unverifiable, as it does not provide the authors with a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. It also states that the work does not prove any new theoretical results, which could be a valid concern. However, the comment lacks specificity and actionable feedback, such as suggesting how the authors might demonstrate the novelty of their approach or what theoretical results could be explored. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the feedback. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a hypothesis about the relationship between the trivial and impossible parts of the dataset, proposing that the trivial part might consist of images with highly consistent labels or typical object poses, while the impossible part could include images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to gather or present this evidence. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a hypothesis about the relationship between the trivial and impossible parts of the dataset, proposing that the trivial part might consist of images with highly consistent labels or typical object poses, while the impossible part could include images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. However, the comment does not explicitly mention which part of the paper this hypothesis is based on, making it weakly grounded. The suggestion to provide more evidence is specific, as it directs the authors to either prove or disprove the hypothesis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a hypothesis about the relationship between the trivial and impossible parts of the dataset, proposing that the trivial part might consist of images with highly consistent labels or typical object poses, while the impossible part could include images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. However, the comment lacks specific examples or references to support the hypothesis, making it somewhat verifiable. The authors would need to provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a hypothesis about the relationship between the trivial and impossible parts of the dataset, proposing that the trivial part might consist of images with highly consistent labels or typical object poses, while the impossible part could include images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. This feedback is somewhat helpful as it provides a potential direction for the authors to explore and offers a specific area for further investigation. However, it lacks detailed guidance on how to conduct this analysis or what specific evidence to gather, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do in response to this question, such as suggesting additional testing or analysis on other tasks. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its question about the testing on other tasks, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). This is a factual question seeking clarification, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). While this is a valid question, the comment lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this issue or expand their testing to other tasks, leaving the authors without a clear path for enhancing their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance to be actionable.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 is difficult to follow and recommends that the author improve it by providing more illustrations and examples. While the comment explicitly states that the author should improve the section, it does not provide specific guidance on how to enhance it or what kind of illustrations or examples would be most beneficial. The action is explicit but vague, as the authors are left to infer the exact changes needed without detailed guidance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, namely that it is difficult to follow, and suggests improvements by recommending the addition of more illustrations and examples. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 3.2 is difficult to follow and suggests that the author improve it by providing more illustrations and examples. However, the comment does not provide any specific reasoning or examples to support why the section is challenging to follow. Without detailed justification or examples, the authors may find it difficult to understand and address the issue effectively. Therefore, the claim is considered unverifiable, as it lacks sufficient evidence or explanation to substantiate the critique.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the author improve the section by adding more illustrations and examples. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete way to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included more detailed guidance on what kind of illustrations or examples would be most beneficial. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the technical contribution is limited, as there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical contribution or what specific changes could be made to improve the paper. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this critique is based on, such as a particular section, experiment, or methodology. Without explicit references to specific parts of the paper, the authors cannot confidently determine where to address the feedback. Additionally, the comment lacks specificity regarding what aspects of the technical contribution are considered limited or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any specific examples or suggestions on how the authors could enhance their technical contribution or what aspects of the paper could be improved. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their work. Therefore, the comment is not helpful at all, as it does not offer any constructive direction for the authors to follow.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This is an explicit suggestion that provides a clear action for the authors to take. The comment specifies what needs to be added, namely fully-supervised baselines for small models, and where it should be included, in Table 1. This level of detail makes the action concrete, ensuring the authors know exactly what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. However, it does not specify which part of the paper discusses Table 1, making it weakly grounded. The comment is specific in suggesting what needs to be added to the table, which provides clear guidance on how to improve the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. The comment provides a logical reasoning for why this addition would be beneficial, as it would help clarify the performance gap between different supervision methods. However, it does not provide specific examples or references to support the claim, which could strengthen the argument. Therefore, the comment is somewhat verifiable, as it lacks detailed evidence but provides a clear rationale for the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by including additional baselines. By doing so, the authors can gain a more comprehensive understanding of the performance gap between different supervision methods, which is valuable for the overall analysis. However, the comment could be more helpful if it explained why these baselines are important or how they would contribute to the understanding of the gap. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be time-consuming for problems with many objectives, potentially making LaMOO impractical for such problems. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the time complexity of the proposed algorithm, particularly in relation to the calculation of hypervolume for problems with many objectives. The comment provides a clear question about the practicality of the algorithm for such problems, which gives the authors a clear direction for addressing the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be time-consuming for problems with many objectives, potentially making LaMOO impractical for such problems. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\\'s scalability, which is a valid concern. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It points out a potential issue with the algorithm\\'s scalability, particularly for problems with many objectives, which could make LaMOO impractical for such problems. This feedback is valuable as it highlights a potential limitation of the algorithm and prompts the authors to consider its practicality in real-world scenarios. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as alternative methods for calculating hypervolume or ways to optimize the algorithm for scalability. Overall, the comment is mostly helpful as it identifies a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges a minor issue regarding the dataset used in the experiments, noting that they are all small. It suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback lacks concrete details on what experiments should be conducted or how to incorporate larger datasets, leaving the authors uncertain about how to implement the suggested improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the dataset used in the experiments, noting that they are all small and suggesting that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not specify which part of the paper discusses the dataset or where the results are presented, making it weakly grounded. The comment is specific in identifying the issue with the dataset and suggesting a potential improvement, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide specific examples or references to support the claim that the current dataset is insufficient or that results on larger datasets would be more convincing. Without detailed evidence or reasoning, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but lacks specific examples or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges a minor issue with the dataset used in the experiments, noting that they are all small. It suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide specific guidance on how to address this issue or suggest alternative datasets or experiments that could be conducted. While it identifies a potential area for improvement, the feedback lacks actionable details or suggestions, making it somewhat helpful. The authors are given a general direction but without concrete steps to take, limiting the comment\\'s usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, suggesting that the title is too generic and vague. The reviewer questions the meaning of \"brittle convergence properties\" and suggests considering the landscape 10 years ago. While the comment implies that the authors should provide more detailed analysis and critique, it does not explicitly instruct them on how to address these points. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods, allowing the authors to identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as delving deeper into state, reactiveness, and learning during an episode, and being more precise in their critique. The comment further questions the meaning of \"brittle convergence properties\" and suggests considering the landscape 10 years ago. This level of detail and specificity helps the authors understand what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a combination of factual statements and suggestions. It mentions the limitations of evolutionary methods and suggests that the authors should delve deeper into specific aspects like state, reactiveness, and learning during an episode. The comment also critiques the title as being too generic and vague, suggesting that the authors should be more precise in their critique. However, it does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the specific issues and how to address them based on the suggestions provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement, including the need to delve deeper into the limitations of evolutionary methods, particularly regarding state, reactiveness, and learning during an episode. It also suggests being more precise in the critique and questioning the meaning of \"brittle convergence properties.\" Additionally, the comment advises being honest and direct in the critique, noting that the title is too generic and vague. While the feedback provides clear directions for improvement, it could be more helpful by offering specific examples or references to support the suggestions. Overall, the comment is mostly helpful as it guides the authors toward enhancing the depth and precision of their critique, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the synthesis of the focal stack, the forward model for using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. These questions imply that the authors need to provide more detailed explanations or methods in these areas. While the comment does not explicitly instruct the authors to address these points, it does suggest that additional information is needed. The action is implicit but concrete, as the authors can infer that they need to provide more detailed explanations in these areas. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the synthesis of the focal stack, the forward model for using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. While it does not explicitly mention specific sections or figures, the authors can infer that these questions pertain to the methodology or results sections. The comment is specific in detailing what aspects need clarification, such as the synthesis process and handling of depth discontinuities. However, it lacks full grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification on specific aspects of the methodology, such as the synthesis of the focal stack, the forward model, and the handling of edges with depth discontinuities. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the methodology and implementation of the focal stack synthesis, specifically asking for clarification on the forward model and how edges with depth discontinuities are handled. These questions are relevant and could help the authors improve the clarity and comprehensiveness of their paper. However, the comment does not provide specific suggestions or guidance on how to address these questions, leaving the authors with a clear understanding of what needs to be clarified but without detailed instructions on how to do so. While the feedback is somewhat helpful in identifying areas for improvement, it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide empirical justification for their claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. While the comment implies that the authors should include empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact type of empirical evidence needed or how to present it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the first claimed contribution of the paper, specifically questioning the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for empirical justification, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s first claimed contribution, which is that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. It suggests that the authors provide empirical justification for this claim, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct the empirical evaluation or what aspects to focus on. Despite this, the feedback provides a valuable direction for the authors to improve their draft, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the specific components of the approach, such as the weak predictor and sampling strategy, by comparing them to existing methods. It highlights that the weak predictor is not novel, as it consists of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. Additionally, it notes that the sampling strategy is similar to epsilon-greedy and exactly the same as that in BRP-NAS. The comment also points out that the results of WeakNAS are almost identical to BRP-NAS, as shown in Table 2 in Appendix C. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these issues or improve the novelty of their approach. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor and the sampling strategy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these components, noting that they are not novel and are similar to existing methods, such as MLP, Regression Tree, or Random Forest, and that the sampling strategy is the same as that in BRP-NAS. Additionally, it points out that the results of WeakNAS are almost identical to BRP-NAS, as shown in Table 2 in Appendix C. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and are similar to existing methods. It supports this claim by referencing previous works [2,3,7] that have used MLP, Regression Tree, or Random Forest for NAS performance prediction and by comparing the sampling strategy to epsilon-greedy and BRP-NAS. Additionally, it points out that the results of WeakNAS are almost identical to BRP-NAS, as shown in Table 2 in Appendix C. This provides a clear and logical basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a detailed critique of the novelty of the specific components of the approach, such as the weak predictor and the sampling strategy. It compares these components to existing methods, noting that they are not novel and are similar to epsilon-greedy and BRP-NAS. Additionally, it points out that the results of WeakNAS are almost identical to BRP-NAS, as shown in Table 2 in Appendix C. This feedback is valuable as it highlights areas where the authors might need to differentiate their work from existing approaches. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues or improve the novelty of their approach. Overall, the comment is somewhat helpful, as it identifies areas for improvement but lacks specific guidance on how to enhance the novelty of the work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al., 2015), limiting its novelty. It explicitly instructs the authors to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed S1DB-ED algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of similarity to RMED (Komiyama et al., 2015) and the need for a sufficient discussion on the comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al., 2015), limiting its novelty. The reviewer provides a specific reference to RMED, which supports the claim by offering a point of comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of the similarities between the two algorithms. Despite this, the reference to RMED is a solid starting point for the authors to understand the basis of the claim. Therefore, the comment is mostly verifiable, as it provides a foundation for the authors to further explore and substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed S1DB-ED algorithm, suggesting that it is too similar to RMED (Komiyama et al., 2015). It provides a specific reference to RMED, which is helpful for the authors to understand the basis of the comparison. The comment also offers actionable feedback by recommending that the paper includes a sufficient discussion on the comparison with RMED. This feedback is clear and constructive, guiding the authors on how to enhance the novelty and clarity of their work. Therefore, the comment is mostly helpful, as it provides specific and actionable advice, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a more comprehensive discussion of previous work on the topic. However, it does not specify which aspects of the previous work should be discussed or how the authors should structure this discussion. The action is implicit and vague, as it lacks concrete guidance on what specific aspects of the previous work should be included or how to present them. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a more comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper lacks this discussion or what specific aspects of previous work should be included. This makes it difficult for the authors to pinpoint the exact area that needs improvement. The comment is not grounded as it does not identify a specific section or part of the paper, and it is also not specific because it lacks detailed guidance on what should be discussed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical area for improvement, as it can help establish the novelty and context of the current work. However, the comment lacks specificity and does not provide guidance on what aspects of previous work should be discussed or how to structure this discussion. Without detailed suggestions or examples, the authors may struggle to determine how to address this feedback effectively. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not offer actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the OT sample selection process in Section 2.4.3, specifically whether it runs once or iteratively, and whether the optimization of the loss and solving the OT problem are conducted by turns. It also requests additional details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the OT sample selection. These questions and requests are explicit and provide clear guidance on what the authors need to address to improve the clarity and comprehensiveness of their draft. The feedback is actionable as it specifies what information is missing and how to provide it, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the iterative nature of the OT sample selection process, the relationship between the optimization of the loss and the solution of the OT problem, and the need for additional details and a flow chart. Additionally, it requests information about the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. This level of detail provides clear guidance on what the authors need to address to improve the clarity and comprehensiveness of their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the OT sample selection process and the relationship between the optimization of the loss and the solution of the OT problem. It suggests that more details and a flow chart would help clarify the process. However, the comment does not provide any specific evidence, reasoning, or references to support these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several important questions and requests for clarification regarding the OT sample selection process in Section 2.4.3. It questions whether the process runs once or iteratively, and whether the optimization of the loss and the solution of the OT problem are conducted by turns. The comment also suggests that adding more details and a flow chart would make the process easier for readers to understand. Additionally, it requests information about the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These questions and requests are clear and actionable, providing the authors with specific areas to address and improve the clarity and comprehensiveness of their draft. The feedback is highly helpful as it offers detailed guidance on how to enhance the paper, making it a valuable resource for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two points: first, it notes that the paper discusses how KG handles continuous tasks but lacks experiments with continuous tasks, and second, it questions why entropy methods for conditional optimization derived in Section 7 are not included in the experiments and how their performance compares to ConBO. Both points imply that the authors should include experiments with continuous tasks and consider including the entropy methods in their experiments. However, the comment does not explicitly instruct the authors to do so, leaving the action implicit. Additionally, while the comment suggests comparing the performance of the entropy methods to ConBO, it does not provide specific guidance on how to conduct this comparison. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7 in the appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of experiments with continuous tasks and the comparison of entropy methods to ConBO. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the lack of experiments with continuous tasks, despite the discussion of how KG handles continuous tasks. It also questions the absence of entropy methods for conditional optimization in the experiments and suggests comparing their performance to ConBO. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that while the authors discuss how KG handles continuous tasks, there are no experiments with continuous tasks included. This feedback is clear and actionable, as it prompts the authors to include such experiments to validate their claims. Second, the comment questions the absence of entropy methods for conditional optimization derived in Section 7 of the appendix in the experiments. It suggests comparing the empirical performance of these methods to ConBO, which is a relevant and constructive suggestion. By highlighting these gaps and offering specific recommendations, the comment provides valuable guidance for the authors to enhance the comprehensiveness and validity of their work. Therefore, the comment is mostly helpful, as it effectively directs the authors to address important areas for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a comparison of their approach\\'s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action that provides a clear direction for the authors to follow. However, the comment also mentions a minor point about the low jailbreaking percentage for certain LLMs, which is not directly actionable. Overall, the comment is mostly actionable as it provides a concrete suggestion for improvement but lacks detailed guidance on the minor point.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of a comparison of the approach\\'s transferability to other LLMs. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should include a comparison of their approach\\'s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion. The mention of a low jailbreaking percentage for certain LLMs is also a claim that requires further explanation or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by recommending that the authors include a comparison of their approach\\'s transferability to other LLMs. This suggestion is specific and could help the authors demonstrate the versatility and applicability of their method. Additionally, the comment points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed to enhance the paper\\'s robustness claims. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or addressed other potential weaknesses. Overall, the feedback is mostly helpful as it provides actionable insights for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It explicitly requests a more detailed explanation from the authors to understand the difference. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The request for a detailed explanation leaves no ambiguity about what the authors need to do, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the difference between similarity and exit times in nature. The comment requests a more detailed explanation, which provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification, which is factual and does not necessitate verification. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses confusion about the distinction between these concepts. The comment is somewhat helpful as it identifies a specific area of uncertainty that the authors need to address. However, it lacks detailed guidance or suggestions on how the authors might clarify this distinction in their paper. To be more helpful, the comment could include examples or explanations to assist the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. While the comment implies that the authors should address this limitation, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the framework\\'s applicability to different POMDP formulations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the framework\\'s applicability to different POMDP formulations, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification on the limitations of the unified framework. It does not express an opinion, judgment, or suggestion that requires verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. This is a relevant inquiry that prompts the authors to consider the applicability and limitations of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their framework to accommodate these scenarios. While it identifies a potential area for improvement, it lacks actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a clear question to explore but without specific guidance on how to proceed. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density and suggests reporting AUC results for breast cancer detection. While the comment implies that the authors should provide more detailed information on their methodology and results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional information. However, the comment does provide a concrete suggestion on what specific metrics to report, which could guide the authors in improving their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"precision/recall/F1-score for 4-class classification of breast density\" and \"AUC results for comparisons,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as calculating and reporting AUC results for breast cancer detection. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density, and suggests reporting AUC results for breast cancer detection. The comment provides a logical reasoning for why AUC results might be more informative, as they allow for comparisons at different operating points. However, it does not provide specific examples or references to support the claim that AUC is the preferred metric for breast cancer detection. While the suggestion is reasonable, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density, which is a critical aspect of the paper\\'s methodology. It also suggests that reporting AUC results for breast cancer detection would be more informative, providing a specific and actionable suggestion for improving the paper\\'s presentation of results. By addressing these points, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included additional guidance on how to calculate AUC or provided examples of how to present AUC results. Overall, the feedback is mostly helpful as it identifies specific areas for improvement and offers a constructive suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the comment implies that the authors should consider using the Kialo dataset instead of creating their own, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate the Kialo dataset or what to do with the existing dataset. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the creation of the dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset, noting that the Kialo dataset, which is well-studied in the community, provides what the authors need\u2014pairs of short claims and their counters. The comment further specifies that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. Additionally, it suggests that the dataset created in the paper could serve as additional data for learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the creation of the dataset is optional, as the Kialo dataset provides what the authors need. It supports this claim by comparing the Kialo dataset to the one created in the paper, noting that the former is cleaner since it does not rely on automatic processes. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by pointing out that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It highlights that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This feedback is valuable as it offers a practical alternative to the authors, allowing them to consider using an existing dataset rather than creating a new one. However, the comment could be more helpful if it provided specific guidance on how to integrate the Kialo dataset or what aspects of the existing dataset could be improved. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the proposed modification to the transformer, specifically the cross-layer approach, and questions its significance in terms of machine learning insights. It also suggests that the improvements over other methods come from using a na\u00efve transformer rather than the proposed modification. While the comment highlights potential issues with the novelty and significance of the work, it does not provide explicit guidance or suggestions for improvement. The authors are left to infer that they might need to clarify the novelty and significance of their approach or address the critique regarding the improvements. However, the lack of concrete advice or specific actions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the novelty of the proposed modification to the transformer, the limited improvement brought by the self-cross attention, and the main improvements coming from using a na\u00efve transformer. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed modification to the transformer, specifically the cross-layer approach, does not bring much insight in the field of machine learning and that the improvements over other methods come from using a na\u00efve transformer rather than the proposed modification. The reviewer supports this claim by referencing the ablation study (table 4 and 5), which shows limited improvement (<1%) from the self-cross attention. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the ablation study provides some support, but the lack of additional evidence or detailed analysis makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical evaluation of the novelty and significance of the proposed modification to the transformer, specifically the cross-layer approach. It questions the extent to which this modification brings new insights to the field of machine learning, noting that the improvements over other methods come from using a na\u00efve transformer rather than the proposed modification. The comment also points out the limited improvement (<1%) from the self-cross attention in the ablation study, suggesting that this may not be considered a significant improvement. While the comment identifies areas of concern and provides some insight into the limitations of the work, it lacks specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their approach. Therefore, the comment is somewhat helpful, as it highlights important areas for improvement but does not offer detailed actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include more tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. While the comment explicitly states the need for more tasks and sequential results, it does not provide specific guidance on how to achieve this or what specific tasks should be included. The authors are given a clear direction but lack detailed instructions on execution. Therefore, the comment is mostly actionable, as it provides a concrete action but lacks detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the experiments, specifically mentioning the limited number of tasks and the desire for more tasks and sequential results. However, it does not specify which part of the experiments this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for more tasks and sequential results, but without explicit grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of tasks in the experiments is limited and suggests that more tasks (at least 10) should be included. The reviewer also requests sequential results in terms of tasks learned rather than epochs. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that 10 tasks are necessary or how the current number of tasks is insufficient. Without these elements, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiments, noting that the number of tasks is limited and suggesting that more tasks (at least 10) should be included. It also requests sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a larger number of tasks and a different presentation of results. However, the comment could be more helpful if it offered examples of tasks that could be included or provided guidance on how to present the sequential results. Overall, the comment is mostly helpful as it directs the authors to enhance their experimental section, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and direct action for the authors to take, specifying the types of tasks they should consider. The comment is explicit and concrete, giving the authors a specific direction for expanding their experiments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, specifically noting the limitation of conducting evaluations only on sentence similarity tasks and open domain QA tasks. It also provides a clear suggestion to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This specificity guides the authors on what additional tasks to consider for their experiments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited because they only evaluate on sentence similarity tasks and open domain QA tasks, suggesting that there are many other tasks involving sentence pairs. The reviewer provides an example of sentence inference tasks like MNLI and RTE, which are common in the NLP field. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific studies or works that support the need for broader experimentation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental scope. By suggesting additional tasks, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their experiments. However, it could be more helpful if it included specific suggestions on how to implement these additional tasks or what metrics to consider. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include the prompt in the appendix or supplement, if it was not already included. This provides a clear and direct action for the authors to take. However, the comment does not specify whether the prompt should be included in the main text or only in the appendix, which could be considered a minor oversight. Overall, the comment is mostly actionable as it clearly identifies the action but lacks some details on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the prompt should be included in the appendix or supplement. However, the comment does not provide specific guidance on how to improve the clarity of the abstract or what changes should be made to Figure 2. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the prompt should be included in the appendix or supplement, but it does not provide any reasoning or evidence to support why this is necessary or beneficial. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification for the authors to address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to include the prompt in the appendix or supplement, which is important for transparency and reproducibility. This feedback is valuable as it directs the authors to a specific area that could enhance the quality of their work. Additionally, the comment includes minor comments about the abstract and Figure 2, which are helpful for the authors to consider improving the clarity and presentation of their work. However, the comment could be more helpful if it provided specific suggestions for rephrasing the abstract or labeled the y-axes in Figure 2. Overall, the feedback is mostly helpful as it offers actionable guidance and identifies areas for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. While it implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their rationale. However, the comment does provide a concrete suggestion on what aspect to clarify, which makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment is specific in its critique of the motivation for the analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity should appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid. Without additional context or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity should appear in earlier layers. This feedback is somewhat helpful as it prompts the authors to reconsider their analysis and provide a clearer explanation for their choice. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or providing examples of how numerosity might appear in earlier layers. While it identifies a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a problem with setting the parameter \"S,\" but it does not provide any explicit or implicit guidance on how to address this issue. It lacks specific suggestions or actions for the authors to take, such as recommending alternative methods or providing examples of how to set the parameter. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a problem with setting the parameter \"S,\" but it does not specify which part of the paper this issue is discussed in, nor does it provide details on what aspect of setting \"S\" is problematic. Without explicit references to sections, figures, or specific discussions, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the parameter \"S.\" Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"How to set the parameter S remains a problem.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the problem of setting the parameter \"S.\" However, it does not provide any further details, suggestions, or guidance on how to address this problem. Without additional context or actionable advice, the authors are left without a clear understanding of what needs to be improved or how to proceed. This lack of specificity and direction makes the comment barely helpful, as it does not offer meaningful insights or actionable steps for the authors to take. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a human evaluation but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections where caption generation is discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the human evaluation would be more convincing or how it should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate why human evaluation would be more reliable or how it could be conducted. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. This feedback highlights a potential weakness in the current evaluation approach and provides a clear suggestion for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects to focus on, which limits its helpfulness. While it identifies a critical area for enhancement, it does not offer detailed actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or revise their claim regarding the absence of free parameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the introduction regarding the absence of free parameters in the shape constraints. It provides a critique by pointing out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is specific in identifying the issue with the claim and suggests a potential area for clarification or revision. However, it does not explicitly mention which part of the introduction this claim is made in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that while it is technically true that the shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. The comment provides a logical reasoning by pointing out that the choice of constraints is not entirely free but rather a parameter that requires consideration. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially provide additional context or evidence to fully understand and address the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is somewhat helpful as it highlights a potential misinterpretation or oversimplification in the paper, prompting the authors to reconsider their claim and potentially clarify or revise it. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to present the constraints more accurately. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the theoretical proof for convergence, claiming it is trivial due to the non-i.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. It suggests that previous theorems can be adapted with straightforward modifications, implying that the authors should provide a more substantial proof or explain the novelty of their approach. However, the comment does not explicitly instruct the authors to revise the proof or provide specific guidance on how to enhance its rigor. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the convergence proof, explaining why it is considered trivial and lacking novelty. The comment provides a clear rationale for the critique, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical proof for convergence is trivial due to the non-i.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. The reviewer supports this claim by referencing \"Modification 1 in Appendix C,\" suggesting that previous theorems can be adapted with straightforward modifications. This provides a logical reasoning and specific reference, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the theoretical proof for convergence, specifically addressing the issue of its triviality due to the non-i.i.d. nature of $Z$ and the i.i.d. nature of $X$. It explains that this leads to a clear covariance matrix for $Z$, which can be used to adapt previous theorems with straightforward modifications. This feedback is valuable as it highlights a potential weakness in the paper\\'s theoretical foundation and suggests a direction for improvement by requiring a more substantial proof or explanation of the novelty of the approach. However, the comment could be more helpful if it offered specific suggestions on how to enhance the proof\\'s rigor or novelty. Overall, the comment is mostly helpful, as it provides clear insights into the paper\\'s theoretical weaknesses and guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experimental setup borrowed from a previous study is only semi-real, as multi-node seed cascades are artificially created by merging single-node seed cascades. It suggests that this should be clearly mentioned in the paper. This feedback provides a direct and concrete action for the authors to take, which is to clarify the experimental setup in the paper. The comment is explicit and provides clear guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their experimental setup in the paper. By addressing this point, the authors can enhance the transparency and credibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the experimental setup to make it more realistic. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the limited datasets and models used in the study, and the absence of assessments on state-of-the-art generative models like GPT. It also notes that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are not measured. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific datasets or models should be included. The authors are left to infer that they should expand their dataset and model selection to include more diverse biases and state-of-the-art generative models. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limited datasets and models used in the study, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, such as assessments on other important biases and datasets, and the need for evaluations on state-of-the-art generative models. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the datasets and models used are limited, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also notes the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights specific areas where the study could be improved, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific biases and datasets that should be included, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement: the limited datasets and models used in the study, and the lack of assessment on state-of-the-art generative models like GPT. It also points out that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases are not measured. This feedback is clear and actionable, as it highlights specific areas where the authors can expand their study to include more diverse datasets and models, and to address a broader range of biases. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments on state-of-the-art generative models. Overall, the comment is mostly helpful as it directs the authors to areas that need further exploration and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential contradiction in the paper regarding the performance of the multi-env model compared to the single-env model. It explicitly requests clarification on this issue, which is a direct and concrete action for the authors to take. The comment clearly specifies what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-env model\" and \"single-env model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a potential contradiction in the paper regarding the performance of these models and requests clarification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a potential contradiction in the paper regarding the performance of the multi-env model compared to the single-env model. It highlights a discrepancy between the claim that the multi-env model has an inevitable performance loss and the claim that it outperforms the single-env model due to knowledge sharing. This observation is logical and based on the information provided in the paper, making it somewhat verifiable. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim, which would make it more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential contradiction in the paper regarding the performance of the multi-env model compared to the single-env model. It highlights a discrepancy between the claim that the multi-env model has an inevitable performance loss and the claim that it outperforms the single-env model due to knowledge sharing. This feedback is clear and actionable, as it prompts the authors to clarify the contradiction and ensure consistency in their claims. By addressing this issue, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided suggestions on how to resolve the contradiction or offered additional context for understanding the issue. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the method\\'s sensitivity to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find a suitable value for $\\\\alpha$. While the comment identifies a concern, it does not provide explicit guidance on how the authors should address this issue or suggest specific steps to improve the method\\'s robustness to hyperparameters. The action is implicit and somewhat vague, as the authors are left to infer that they should focus on improving the method\\'s robustness to hyperparameters but without concrete steps or suggestions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the method to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find a suitable $\\\\alpha$. However, it does not specify which part of the paper discusses the method or where this sensitivity is mentioned, making it weakly grounded. The comment is specific in detailing the issue with the method\\'s sensitivity to hyperparameters, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find a suitable $\\\\alpha$. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method\\'s sensitivity to hyperparameters, specifically mentioning the need for a careful hyperparameter search to find a suitable $\\\\alpha$. This feedback is somewhat helpful as it highlights a critical area for improvement, suggesting that the method may not be robust to variations in hyperparameters. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending techniques for hyperparameter tuning or providing examples of similar methods that have successfully addressed this challenge. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. While the comment implies that the authors should either explain the metrics or cite them, it does not specify which metrics need clarification or how to present this information. The action is implicit and somewhat vague, as the authors are left to infer which metrics require attention and how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of metrics used in the paper, suggesting that it is limited and recommends providing an explanation or citing the metrics. However, it does not specify which part of the paper discusses the metrics, making it weakly grounded. The comment is specific in suggesting that an explanation or citation would be beneficial, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the description of the metrics used in the paper is limited and suggests that an explanation or citation would be beneficial. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the description of the metrics used in the paper is limited. It suggests that an explanation of the metrics or a citation to the metrics would be beneficial. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it specified which metrics are unclear or provided examples of how to explain or cite them. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, it does not provide explicit guidance or suggestions on how to improve the figure or clarify the issues. The authors are left to infer that they need to revise the figure and its captions, but without concrete instructions on what changes to make, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure\\'s clarity. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, the comment does not provide any specific examples or detailed reasoning to support why the figure is confusing. Without additional context or explanation, the authors may find it difficult to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their figure. However, the comment could be more helpful if it provided specific suggestions on how to enhance the figure\\'s clarity, such as recommending additional labels or explanations. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. While it identifies a specific area of confusion, it does not provide any guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks explicit instructions or concrete steps for the authors to follow, leaving them without a clear understanding of what actions to take to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the issue of unclear terminology but lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage. However, it does not provide any supporting evidence, reasoning, or references to justify why this term is unclear or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. This is a clear and actionable feedback that prompts the authors to clarify a term that may be unclear to readers. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending alternative terminology or explaining the concept in more detail. While it highlights a critical area for improvement, the lack of additional guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a specific issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the reported results are partially derivative, as they extend to hyper-networks of results already presented in the literature for standard networks. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve their draft. There is no suggestion of what specific aspects of the results need to be revised or how the authors might differentiate their work from existing literature. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, as they extend to hyper-networks of results already presented in the literature for standard networks. However, it does not specify which part of the paper this observation is based on, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the results are derivative or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, as they extend to hyper-networks of results already presented in the literature for standard networks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the reported results are partially derivative, as they extend to hyper-networks of results already presented in the literature for standard networks. However, it does not provide specific examples or details about which results are derivative or how they could be improved. Without actionable guidance or suggestions for differentiation, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of motivation for the problem considered in the paper, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should spend more time motivating the applications where such algorithms are needed. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects should be included to motivate the problem. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context and motivation for the problem. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s objective of designing fast label aggregation algorithms for a streaming setting and questions the lack of motivation for such algorithms. It also points out that the datasets used in the empirical analysis are static, which contradicts the paper\\'s objective. However, the comment does not specify which part of the paper lacks motivation or where the datasets are discussed, making it weakly grounded. The comment is specific in its critique of the lack of motivation and the use of static datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for the problem considered, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the paper\\'s objective. However, the comment does not provide specific examples or references to support the claim that the problem is not well-motivated or that the datasets are inappropriate. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that while it aims to design fast label aggregation algorithms for a streaming setting, it lacks motivation for the problem and does not provide examples of applications where such algorithms are needed. This is a critical issue that the authors need to address to make their work more relevant and impactful. The comment highlights the importance of motivating the problem and suggests that the paper should include examples of real-world scenarios where fast label aggregation is necessary. However, it does not provide specific guidance on how to achieve this or what types of examples would be most relevant. While the feedback is clear in its critique, it could be more helpful with actionable suggestions or examples. Therefore, the comment is rated as somewhat helpful, as it provides insight into a significant weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of specificity in the study\\'s scope, suggesting that the work focuses on injecting a CoT-based approach into small-scale Language Models. It implies that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. While the comment identifies a potential issue, it does not explicitly instruct the authors to include these baselines or specify how to address the lack of specificity in the study\\'s scope. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines and clarify the scope of their study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach into small-scale Language Models. It further implies that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. However, the comment lacks specific examples or references to support the claim about the missing baselines, making it somewhat verifiable. The authors would need to infer the missing information themselves, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scope of the study, noting that it is under-specified and that the work seems to focus on injecting a CoT-based approach into small-scale Language Models. It suggests that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. This feedback is clear and actionable, as it directs the authors to clarify the scope of their study and potentially include additional baselines to enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these baselines or addressed the implications of this omission. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and depth of their study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the readability of the figure, such as suggesting ways to enhance the visual clarity or providing specific examples of what needs to be addressed. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in reading the figure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement describing the difficulty in reading Figure 3. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment points out a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any actionable feedback or suggestions on how to improve the figure\\'s readability. Without guidance on what aspects of the figure are causing the difficulty or how to address it, the authors are left without a clear path to enhance their draft. This makes the comment somewhat helpful, as it identifies an issue but does not provide actionable advice, leaving the authors with limited guidance on how to improve their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the mentioned fact in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should take to clarify the connection. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the mentioned fact and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim. The lack of specific examples or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the connection. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as barely helpful, as it points out a potential area for improvement but does not offer detailed guidance for the authors to follow.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the GAT (Graph Attention Network) is trained with the whole model and that the text needs to be reviewed by an English native speaker for clarity. However, it does not provide specific guidance on how to improve the clarity or what parts of the text need rewriting. The action is implicit and vague, as the authors are left to infer that they need to revise the text but without concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the GAT (Graph Attention Network) is trained with the whole model and that the text needs to be reviewed by an English native speaker for clarity. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the GAT is discussed. Additionally, while it mentions the need for rewriting, it does not provide specific examples or details on what needs to be rewritten. This lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the GAT (Graph Attention Network) is trained with the whole model and that the text needs to be reviewed by an English native speaker for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify these claims. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two issues: the need for a native English speaker to review the text for clarity and the suggestion that the GAT (Graph Attention Network) is trained with the whole model. While it highlights areas for improvement, the comment lacks specificity and actionable guidance. It does not provide detailed feedback on which parts of the text need rewriting or how to improve the clarity, nor does it explain why the GAT is trained with the whole model. This limits the usefulness of the comment for the authors, as it does not offer clear steps for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first concern is explicit, as it directly instructs the authors to clarify the reasoning behind the replacement. The second concern is also explicit, as it questions the justification for the learning rate choice. Both points provide clear actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119-121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the replacement of a mathematical expression with an arbitrary parameter and the lack of justification for the learning rate choice. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first claim is supported by referencing specific lines in the paper (lines 119-121), which provides a clear basis for the critique. The second claim questions the justification for the learning rate choice, but it lacks specific examples or references to support why the Adam default value is more appropriate. This makes the claim somewhat verifiable, as it highlights a potential issue but requires further elaboration or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter, which could potentially affect the accuracy or interpretation of the results. Second, it questions the choice of a specific learning rate for SGD, noting that it differs from the default value used in Adam. This feedback is clear and actionable, as it prompts the authors to provide a justification for these choices or consider alternative approaches. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar choices have been made in other works. Overall, the comment is mostly helpful, as it directs the authors to important areas that need clarification or justification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly encourages the authors to conduct error analysis in their paper and provide detailed explanations of the model\\'s performance under different scenarios. This suggestion is clear and direct, giving the authors a specific action to take. The comment also explains the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. The feedback is concrete and provides a clear path for the authors to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting error analysis and providing detailed explanations of the model\\'s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results sections, but the comment lacks full grounding. It is specific in suggesting the need for error analysis and detailed explanations, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. The comment highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. However, it does not provide specific examples or references to support the claim that error analysis is necessary or how it would benefit the paper. The suggestion is logical but lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by providing insights into the model\\'s strengths and weaknesses. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would further empower the authors in implementing this suggestion. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should analyze the domain gap between datasets and discuss the potential issues with adaptation. It also implies that if the method can finetune a pre-trained model on synthetic data, the value of the approach would be higher. While the comment provides a clear direction for analysis and discussion, it does not specify how the authors should conduct this analysis or what specific aspects of the domain gap should be addressed. The action is explicit but somewhat vague, as it lacks concrete guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap between datasets and discussing the potential issues with adaptation. It also mentions the value of the approach if it can finetune a pre-trained model on synthetic data. However, the comment does not specify which part of the paper should address these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting what needs to be addressed, such as discussing the domain gap and the value of the approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap between datasets and discussing the potential issues with adaptation. It also mentions the value of the approach if it can finetune a pre-trained model on synthetic data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the domain gap or the potential benefits of finetuning on synthetic data. Without these elements, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests analyzing the domain gap between datasets and discussing the potential issues with adaptation. It also highlights the value of the approach if it can finetune a pre-trained model on synthetic data, which could enhance the method\\'s applicability. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to conduct the analysis or discuss the domain gap. Additionally, it does not provide detailed suggestions on how to address the issues or enhance the method\\'s value. Therefore, the comment is somewhat helpful as it points out areas for improvement but does not offer comprehensive guidance or actionable steps. It aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the model, specifically noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions how the authors might scale up without compromising performance. While the comment identifies a potential issue and suggests a possible solution, it does not provide explicit instructions on how to address the scalability problem or how to implement the suggested solution. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve scalability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with scalability, noting that performance worsens with an increase in the maximum number of identities and suggesting a preset capacity. The comment further questions how the authors might scale up without compromising performance, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance worsens with an increase in the maximum number of identities, as shown in Table 3 (a). It suggests that the capacity should be preset to a small number, such as 10, to maintain performance. The comment raises a valid concern about scalability and provides a logical reasoning for the suggestion. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the issue and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scalability of the model, noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, to maintain performance. The comment also raises a practical concern about real-world scenarios where the number of objects can vary, questioning how the authors might scale up without compromising performance. This feedback is clear and actionable, providing the authors with a specific area for improvement and a potential solution to consider. However, it could be more helpful if it included additional suggestions or examples on how to address the scalability issue. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the scalability of their model.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not appear to be specific to NLP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific changes should be made to improve the draft. As a result, the comment lacks actionability and provides no direction for the authors to follow.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLP-specific elements. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment does not provide specific details on what aspects of the work are not NLP-specific, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLP-specific elements. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLP-specific elements. However, it does not provide specific feedback or suggestions on how the authors might address this issue or improve the relevance of their work to NLP. Without actionable guidance or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include at least one NCE-based method for comparison. It provides a specific action by referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, giving the authors a direct and detailed instruction on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a study that shows the feasibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of an NCE-based method and referencing a study, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including at least one NCE-based method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This claim is somewhat verifiable as it provides a reference to a specific study that supports the feasibility of the suggestion. However, the comment lacks detailed explanation or examples of how this comparison would benefit the paper, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including at least one NCE-based method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by including a relevant comparison method. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment implies that these actions should be taken, it does not provide explicit instructions on how to conduct the significance tests or which recent LLMs should be compared. The authors can infer the need for these actions but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically mentioning the need for significance tests on human evaluation results and comparisons with recent LLMs. However, it does not specify which part of the experiment section this feedback pertains to, such as a particular table or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in suggesting improvements, it is not grounded because it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to recent LLMs that could be used for comparison. This makes the claim somewhat verifiable, as the authors would need to infer which LLMs are most relevant and how to conduct the significance tests. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the experiment section, suggesting that significance tests should be conducted on the human evaluation results and that the proposed method should be compared with recent LLMs. This feedback is clear and actionable, providing the authors with concrete steps to enhance the rigor and relevance of their experimental analysis. However, the comment could be more helpful if it included suggestions on which specific LLMs to compare with or how to conduct the significance tests. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements in their experimental section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" and to illustrate the relationship between that work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the lack of research focusing on the joint error for UDA, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by referencing a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" and suggesting that the authors should discuss the relationship between this work and their proposed method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem of arbitrarily increased joint error has already been studied in a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" in ICML2019. The reviewer provides a specific reference to support this claim, which is a clear and explicit form of evidence. This makes the claim fully verifiable, as it provides a direct link to the relevant literature, allowing the authors to understand the basis of the critique and address it effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors' claim that there is no existing research focusing on the joint error for UDA. It points out that this problem has already been studied in a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" in ICML2019. The comment provides a specific reference to a relevant work, which is valuable for the authors to consider when discussing the novelty of their approach. Additionally, it suggests that the authors should directly illustrate the relationship between their work and the previous one, and explain why their method is better. This feedback is clear and actionable, offering a specific direction for the authors to enhance their draft by addressing the critique and positioning their work effectively. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison to state-of-the-art (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data. This feedback implies that the authors should consider the impact of dataset scale on their results and potentially adjust their claims or comparisons. However, the comment does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and potentially adjust their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset compared to existing methods using smaller datasets. It provides an example of GEM using only 20M unlabeled data, which highlights the potential impact of dataset scale on the results. However, the comment does not explicitly mention which part of the paper discusses these comparisons, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the comparison and the potential impact of dataset scale, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data, suggesting that the scale of datasets can significantly impact accuracy. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific SOTA methods or providing more detailed examples of how the dataset scale affects performance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison to state-of-the-art (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data, which highlights the impact of dataset scale on accuracy. This feedback is valuable as it prompts the authors to consider the fairness of their comparisons and potentially adjust their claims or methodology. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how to account for dataset scale in the analysis. Overall, the comment is somewhat helpful as it directs the authors to a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs and points out that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The authors are left to infer that they need to provide a justification for the need for a new method and discuss the limitations of existing approaches. However, the lack of concrete suggestions or detailed guidance makes the action vague and difficult for the authors to implement effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to existing methods that could be applied or detailed reasoning on why the current methods are insufficient. This makes the claim somewhat verifiable, as it highlights a potential gap but does not provide sufficient evidence or justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is clear and actionable, as it prompts the authors to address the lack of justification and provide a rationale for their approach. However, the comment could be more helpful if it offered specific suggestions on how to frame the discussion or what aspects of existing methods should be considered. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models, such as BERT and XLNet, as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using n-gram features. This comment provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to improve their draft. The suggestion is concrete, as it outlines a specific approach to enhance the paper\\'s methodology. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks full grounding as it does not explicitly mention a particular section. It is specific in suggesting a change in the methodology, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that powerful pre-trained language models, such as BERT and XLNet, can overcome the domain-shift problem to some extent. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific examples or detailed reasoning, the authors may find it challenging to understand the basis of the suggestion or to determine how to implement it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a significant improvement to the methodology by recommending the use of powerful pre-trained language models, such as BERT and XLNet, as the base encoder for all methods. It proposes a more effective approach to address the domain-shift problem, which is a critical aspect of the paper. This feedback is clear and actionable, providing the authors with a specific direction to enhance their work. However, the comment could be more helpful if it included additional details or examples on how to implement this suggestion effectively. Overall, the comment is mostly helpful as it offers a constructive and actionable suggestion for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the complexity of the proposed method and its parameters, questioning whether the performance gain is due to specific modules or simply from having more parameters. The reviewer notes that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit, as the authors need to infer that they should conduct a more comprehensive ablation study to clarify the source of the performance gain. However, the comment lacks concrete details on how to conduct this study or what specific modules to focus on. Therefore, the comment is somewhat actionable, as it points out an area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method and its parameters, questioning whether the performance gain is due to specific modules or simply from having more parameters. It also critiques the current ablation study for not providing definitive answers to these questions. However, the comment does not specify which part of the paper discusses the ablation study or the modules in question, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact parts. The comment is specific in detailing the issue with the ablation study, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of the proposed method and its parameters, questioning whether the performance gain is due to specific modules or simply from having more parameters. The comment critiques the current ablation study for not providing definitive answers to these questions. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how to address it. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or evidence to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, specifically its complexity and the number of parameters compared to the baselines. It questions whether the performance gain is due to specific modules or simply from having more parameters, highlighting the need for a more comprehensive ablation study to clarify this. While the comment points out a significant weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or conduct the ablation study. The feedback is somewhat helpful as it directs the authors' attention to an important area for improvement, but it lacks actionable details, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion to improve the draft by requesting more explanation for the difference between two quantities and why it captures the difference in learning settings. While the comment explicitly states the need for additional explanation, it does not provide detailed guidance on how to present this explanation or what specific aspects should be highlighted. The action is explicit but somewhat vague, as the authors know they need to provide more explanation but may not be entirely sure of the exact content or format of the additional information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 196-197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the difference between two quantities and why it captures the difference in learning settings. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the explanation of the difference between two quantities and why it captures the difference in learning settings. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further explanation, specifically lines 196-197. It points out the need for more detailed explanation regarding the difference between two quantities and why it captures the difference in learning settings. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation in the draft. However, the comment could be more helpful if it provided suggestions on how to present this explanation or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and provides a direct action for the authors to take, which is to include a discussion on the sensitivity of these parameters. The feedback is specific and actionable, as it guides the authors on what aspect of their work needs further elaboration. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly asks for a discussion on the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is specific and provides clear guidance on what the authors should address. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is not fully grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for additional discussion, specifically asking the authors to address the sensitivity of fixed tuning parameters in the model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or expansion, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of fixed tuning parameters in their model. This feedback prompts the authors to consider an important aspect of their methodology that may not have been fully explored or discussed in the draft. However, the comment lacks depth and does not provide specific guidance on how to approach this discussion or what aspects to focus on. While it points out a potential area for enhancement, it does not offer detailed suggestions or examples, leaving the authors with a general direction but limited actionable steps. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). While the suggestion to explore different policy gradient approaches is explicit, it lacks concrete guidance on how to implement this exploration or which specific approaches to consider. The question about random seeds is explicit and provides a clear action for the authors to take. However, the overall comment is somewhat actionable as it provides a direction for further exploration but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not specify which part of the paper this suggestion or question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its request for clarification on the number of random seeds used, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not provide any supporting evidence, reasoning, or references to justify why exploring different policy gradient approaches would be interesting or beneficial. The request for clarification on random seeds is a factual question that does not require verification. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. This is a valuable suggestion that could enhance the applicability and robustness of the framework. Additionally, the comment asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG), which is a specific and actionable request. However, the comment could be more helpful if it provided guidance on how to conduct this exploration or suggested specific policy gradient approaches to consider. Overall, the comment is mostly helpful as it offers a clear direction for further exploration and provides a specific question for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper\\'s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This feedback is explicit and provides a clear action for the authors to take, which is to expand the analysis to include multiple datasets and tasks. However, it does not specify which datasets or tasks should be considered or how to conduct the analysis on these additional datasets. While the action is explicit, the lack of concrete details on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. However, it does not specify which part of the paper this critique is based on, such as a particular section or analysis that could be expanded. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. The comment is specific in suggesting the need for broader analysis, but it is not grounded because it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This claim is based on a logical reasoning that broader analysis would provide a more comprehensive understanding of the results. However, the comment lacks specific examples or references to support the claim, such as suggesting which additional datasets or tasks could be included. This makes the claim somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it evaluates only on one dataset and one task. It suggests that the results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered suggestions on which additional datasets or tasks might be relevant or provided guidance on how to conduct the analysis on multiple datasets. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved in some places, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. While the comment identifies a potential issue, it does not provide explicit guidance on how to improve the writing or clarify the definition. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the definition but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the interpretation of the \"relevant\" auxiliary model weights, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could be improved, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. However, the comment does not provide any further explanation or reasoning to support why the definition is difficult to interpret or how it could be improved. Without additional context or examples, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the writing could be improved, pointing out a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. This feedback is somewhat helpful as it directs the authors to a particular section of the paper that needs clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the definition. While it highlights an area for improvement, it does not offer detailed actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper\\'s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It recommends using U-LiRA [1] instead. While the comment implies that the authors should consider an alternative method for evaluating unlearning effectiveness, it does not provide specific guidance on how to implement this change or why U-LiRA is preferable. The action is implicit and somewhat vague, as the authors need to infer the need for a change and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MIA (Membership Inference Attack) Testing via Ulira,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the robustness of MIA testing for privacy guarantees and recommending the use of U-LiRA [1]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s reliance on MIA testing as a metric for unlearning effectiveness is not robust for privacy guarantees. It supports this claim by suggesting that the use of U-LiRA [1] is recommended. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the robustness of MIA testing. While it provides a suggestion for improvement, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s reliance on MIA testing as a metric for unlearning effectiveness, questioning its robustness for privacy guarantees. It provides a specific recommendation to use U-LiRA [1] as an alternative, which could be a valuable suggestion for the authors to consider. However, the comment could be more helpful if it explained why U-LiRA is a better choice or provided additional context on the limitations of MIA testing. Overall, the feedback is mostly helpful as it directs the authors to a potential improvement area and offers a concrete suggestion, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the paper could also be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate the suggestion or address the question about applicability. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question or suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider kernel regression and present the paper in a different context, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the paper\\'s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this should be the case. It lacks specific examples or detailed explanations that would help the authors understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the paper\\'s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for expansion or clarification, the comment lacks specificity and actionable guidance. It does not provide detailed suggestions on how to incorporate kernel regression or what aspects of the paper might benefit from this perspective. As a result, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It also mentions that Figure 4 illustrates the comparison of final results with a single data sample, questioning the validity of the current evaluations. The reviewer implicitly suggests that a quantitative comparison on the final outputs would be more convincing. While the action is clear, it lacks explicit guidance on how to conduct this comparison or what specific metrics to use. The authors can infer that they need to provide a more comprehensive evaluation of the final outputs, but the comment does not provide concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the quantitative evaluation results in Figure 3 only reflect middle outputs, while Figure 4 illustrates the comparison of final results with a single data sample. The comment further questions the validity of the current evaluations and suggests a quantitative comparison on the final outputs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, while Figure 4 illustrates the comparison of final results with a single data sample. The reviewer questions the validity of the current evaluations and suggests a quantitative comparison on the final outputs. This claim is somewhat verifiable as it provides a logical reasoning for the issue, noting that the evaluations are not comprehensive due to the focus on middle outputs. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It also points out that Figure 4 illustrates the comparison of final results with a single data sample, questioning the validity of the current evaluations. The reviewer suggests that a quantitative comparison on the final outputs would be more convincing. This feedback is clear and actionable, as it highlights a critical gap in the evaluation process and provides a specific suggestion for improvement. By addressing this issue, the authors can strengthen their claims about ModelAngelo\u2019s superiority over competitors. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the explanations and presentation of the paper, including the lack of detailed procedures and confusing figures. It suggests adding more details to the paper and/or supplementary information to improve clarity. Additionally, it recommends including error bars and p-values for statistical inferences. While the comment provides explicit actions, such as adding more details and including specific elements like error bars, it does not specify how to implement these changes or provide detailed guidance on what specific information should be added. The actions are concrete but not fully detailed, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the explanations, noting that they are qualitative and lack detailed procedures or descriptions. The comment further suggests adding more details to the paper and/or supplementary information to clarify the simulations. Additionally, it provides specific feedback on the need for error bars and p-values for statistical inferences. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations are qualitative and lacks detailed procedures, which is supported by the observation that figures are confusing and lack clear descriptions. The reviewer suggests adding more details to the paper and/or supplementary information to improve clarity. This claim is somewhat verifiable as it provides a logical reasoning for the need for more detailed explanations, but it lacks specific examples or references to support the claim fully. The suggestion to include error bars and p-values for statistical inferences is also a logical request but could be more robust with examples or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the lack of detailed explanations and the confusion caused by minimal descriptions of procedures and figures. It suggests adding more details to the paper and/or supplementary information to enhance clarity and understanding. Additionally, it recommends including error bars and p-values for statistical inferences, which would provide a more robust analysis. The feedback is clear and actionable, offering specific suggestions for enhancing the paper\\'s quality. However, it could be more helpful if it provided examples of what additional details or explanations would be beneficial. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some claims in the paper may be inspired by existing studies and recommends adding supportive references. It provides an example by referencing lines 55-64, where it identifies four critical factors affecting chain-of-thought prompting. The reviewer implies that these factors have been discussed in existing studies, but does not specify which studies or provide detailed guidance on how to incorporate these references. While the comment highlights an area for improvement, it lacks concrete instructions on how to implement the suggested action, such as identifying specific references or studies to include. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 55-64,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the need to add supportive references for claims that may be inspired by existing studies. The comment provides a clear example of the factors discussed in the paper that have been covered in existing studies, which helps the authors understand the specific areas that require further referencing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims in the paper may be inspired by existing studies and suggests adding supportive references. It provides an example by referencing lines 55-64, where it identifies four critical factors affecting chain-of-thought prompting. The reviewer implies that these factors have been discussed in existing studies, but does not specify which studies or provide detailed references to support this claim. This lack of specific references or detailed evidence makes the claim somewhat verifiable, as the authors would need to invest time and effort to identify the relevant studies themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references should be added. It provides a specific example by referencing lines 55-64, where it highlights four critical factors affecting chain-of-thought prompting. The reviewer implies that these factors have been discussed in existing studies, which is a valuable observation for the authors to consider. However, the comment could be more helpful if it included specific references or examples of existing studies that the authors should consider. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a clear direction for enhancing the paper by incorporating relevant references. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This feedback provides a clear and explicit action for the authors to take, which is to include these settings in their paper. The comment also explains why this is important, as it would help the community by providing a comprehensive review of the advances in this area. The suggestion is concrete and direct, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these settings could be included. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This claim is somewhat verifiable as it provides a logical reasoning for improvement by referencing specific prior works. However, the comment lacks detailed examples or references to these prior works, which would strengthen the justification. The authors would need to infer the specific settings or knobs that should be included, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including these settings. By doing so, the paper would contribute to a comprehensive review of the advances in this area, benefiting the broader community. However, the comment could be more helpful if it provided examples of how these settings might be presented or suggested specific sections where they could be included. Overall, the feedback is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the generalizability of these examples, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents specific examples of biases of target statistics and prediction shift of gradient values, but it does not specify how these examples are unclear or how they affect the generalizability of the results. The comment lacks detailed reasoning or examples to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the paper, particularly in relation to the generalizability of specific examples presented in the paper. It points out that while the paper provides examples of biases of target statistics and prediction shift of gradient values, it does not clarify how general these situations are. This feedback is somewhat helpful as it highlights a potential gap in the paper that the authors need to address. However, it lacks detailed guidance or suggestions on how to improve the clarity or provide additional context to address this issue. To be more helpful, the comment could include specific recommendations or examples of how to enhance the clarity of the examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating cross-task transferability. However, it does not specify which datasets should be included or how they would contribute to the evaluation of cross-task transferability. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating cross-task transferability. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in suggesting the inclusion of additional datasets for a particular purpose, but without clear grounding, the authors may struggle to identify the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating cross-task transferability. However, the comment does not provide any specific reasoning or examples to support why additional datasets are necessary or how they would enhance the evaluation of cross-task transferability. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating cross-task transferability. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on which datasets should be included or how they would contribute to the evaluation. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is barely helpful, as it points out a general area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks used in the paper are somewhat standard and proposes that the authors consider creating unique tasks from the dataset to showcase the diversity of images and plots. It specifically mentions that tasks like Question Answering from images could be considered. While the comment implies that the authors should explore unique tasks, it does not provide explicit instructions on how to implement these suggestions or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. It mentions specific examples, such as Question Answering from images, which provides some guidance on what could be considered. However, the comment does not explicitly mention which part of the paper discusses the tasks, making it weakly grounded. The authors can infer that it relates to the task description or methodology sections, but this inference is not as direct as it could be. The comment is specific in suggesting unique tasks but lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. The reviewer provides a specific example of a task that could be considered, such as Question Answering from images. This suggestion is somewhat verifiable as it offers a concrete example of how the tasks could be expanded, but it lacks detailed reasoning or references to support the claim that the current tasks are not innovative. The authors would need to consider the suggestion and determine its feasibility, which requires some effort to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by noting that the tasks used are somewhat standard, such as figure captioning and matching figures to captions. It suggests that the authors could enhance their work by creating unique tasks from the dataset to showcase the diversity of images and plots. The comment provides a specific example of a task that could be considered, such as Question Answering from images, which offers a concrete suggestion for improvement. While the comment highlights a valuable area for expansion, it could be more helpful if it provided additional guidance on how to develop these unique tasks or what specific aspects of the dataset could be leveraged. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to clarify whether there is any additional novel effort in Section 3.1 for 3D Gaussian generation, given that it appears to follow the previous work, Luciddreamer. This is a clear and direct action for the authors to take, as it specifies what needs to be addressed in the draft. The comment provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on whether there is any additional novel effort in this section, given that it appears to follow the previous work, Luciddreamer. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the section on 3D Gaussian generation in Section 3.1 is original or merely follows the previous work, Luciddreamer. However, it does not provide any specific reasoning, examples, or references to support the claim that the section is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the section on 3D Gaussian generation in Section 3.1, suggesting that it may not be original and merely follows the previous work, Luciddreamer. This feedback is somewhat helpful as it prompts the authors to clarify whether there is any additional novel effort in this section. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the originality of their work. To be more helpful, the comment could include suggestions for potential novel contributions or ways to differentiate the work from existing literature. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the MMD DRO method, specifically noting the lack of a tractable exact equivalent reformulation and the crudeness of the upper bound provided in Theorem 3.1. It also points out that the nonnegative constraint on the distribution is dropped, requiring further approximation even for a simple kernel ridge regression problem. Additionally, the comment suggests that assuming the loss function belongs to the RKHS is restrictive. While the comment identifies several areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MMD DRO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the tractability of the exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. Additionally, it points out the restrictive assumption of the loss function belonging to the RKHS. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that MMD DRO lacks a tractable exact equivalent reformulation, which is a severe drawback. It supports this claim by pointing out the crudeness of the upper bound provided in Theorem 3.1, which drops the nonnegative constraint on the distribution and requires further approximation even for a simple kernel ridge regression problem. Additionally, it mentions the restrictive assumption that the loss function belongs to the RKHS, as already noted by the authors. While the comment provides some reasoning and references to specific issues, it lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical issues with the MMD DRO method, specifically its lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. It also points out the restrictive assumption that the loss function belongs to the RKHS, as already noted by the authors. While the comment highlights important weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it directs the authors' attention to areas needing further exploration or refinement, but it lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relevance of the framework to problems involving non-convex losses and non-norm type defenses. It asks whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints would make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment raises important questions, it does not provide explicit instructions or concrete suggestions for the authors to address these concerns. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the relevance of the framework to problems involving non-convex losses and non-norm type defenses, specifically mentioning the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints. It also asks about the potential use of covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of the framework and its applicability. The questions are specific, as they address the relevance and potential limitations of the framework. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions and requests for clarification, such as the relevance of the framework to non-convex losses and non-norm type defenses, and whether the non-vanishing duality gap and difficulty of maximization over non-norm type constraints make the algorithm irrelevant. It also asks about the potential use of covariance or other statistics to design a better defense if the true mean is known through an oracle. These questions are not claims or opinions but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions and points of clarification regarding the relevance of the framework to problems involving non-convex losses and non-norm type defenses. It asks whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints would make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment identifies important areas for clarification, it lacks specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more actionable with additional detail or direction. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion or what specific features to consider. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular experiment to conduct, which is to sparsify the trained models and compare accuracy to the proposed model. This provides clear guidance on what the authors could do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the baselines in Figure 3. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. This is a somewhat helpful comment as it prompts the authors to consider an additional experiment or analysis that could enhance the paper. However, it lacks specific guidance or suggestions on how to implement this idea or what specific features to consider. While it provides a direction for potential improvement, it does not offer detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper lacks detail, making it difficult to reproduce the results. It explicitly lists specific questions about the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. These questions provide clear guidance on what aspects of the paper need further elaboration. The comment is explicit and concrete, giving the authors a direct path to improve their draft by addressing these specific questions. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific areas of concern, such as the sparsification process, the generation of landmarks, and the number of landmarks used. It also specifies what is unclear or missing, such as the type of image features, the fixed radius with different scales, and achieving shape invariance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific questions about the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. These questions are logical and provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections of the paper where these details are lacking or by providing examples of how these details would improve reproducibility. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of detail about the techniques used, which makes it difficult to reproduce the results. It provides a comprehensive list of questions that need to be addressed, such as the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This feedback is clear and actionable, as it guides the authors on what specific details are missing and need to be clarified to improve the reproducibility and comprehensibility of their work. By addressing these questions, the authors can significantly enhance the quality and transparency of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific guidance on how to reorganize the section or what changes should be made to improve its clarity. The action is explicit in terms of the need for reorganization, but it lacks concrete details on how to implement this change. As a result, the comment is somewhat actionable, as the authors know they need to reorganize the section but may struggle to determine the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not specify which part of the section is problematic or what specific issues need to be addressed for reorganization. This lack of detail makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide any context or examples to support the claim that the section is difficult to follow. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the Appendix H section should be reorganized because it is difficult to follow. However, the comment does not provide any specific reasoning, examples, or evidence to support why the section is challenging to follow. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and make necessary improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. However, it does not provide any suggestions or guidance on how to reorganize the section or what specific changes could be made to improve its clarity. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, as it does not offer any meaningful direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity and detail in the paper, specifically regarding the reproduction of the work. It suggests that while the pseudocode in the supplementary material provides an intuitive understanding, it lacks the necessary details for actual reproduction. The reviewer explicitly mentions the need for more details about the RNN implementation, such as the number of units, and other technical details. This feedback provides a clear and concrete action for the authors to take, which is to include these details in the paper or supplementary material. The comment is explicit and provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the pseudocode in the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely detailed information about the RNN implementation (such as the number of units) and other technical details. This provides clear guidance on what needs to be addressed to improve the paper\\'s reproducibility. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient detail for reproduction, even with the pseudocode provided in the supplementary material. The reviewer suggests that more technical details, such as those related to the RNN implementation, are needed for actual reproduction. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. The lack of detailed justification or examples makes the claim somewhat verifiable, as it requires the authors to infer the specific details needed for reproduction. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that while the pseudocode in the supplementary material provides an intuitive understanding, it lacks the necessary details for actual reproduction. The reviewer points out specific areas that need more detail, such as the RNN implementation and other technical details. This feedback is clear and actionable, as it provides the authors with a specific direction for improving the paper\\'s reproducibility. By addressing these concerns, the authors can enhance the transparency and utility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 would be strengthened by including error bars and more random trials to reduce random fluctuations in the results. While the comment implies that these additions would improve the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars and more random trials. However, the suggestion is concrete, as it provides a clear idea of what could be done to enhance the figure. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of error bars and more random trials to reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 would be strengthened by including error bars and more random trials to reduce random fluctuations. This claim is somewhat verifiable as it provides a logical reasoning for why these additions could improve the figure\\'s strength. However, the comment lacks specific examples or references to support the claim that more random trials would effectively reduce fluctuations. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that Figure 1 would be strengthened by including error bars and more random trials. This feedback is clear and offers a concrete way for the authors to enhance the visual representation of their results, which could improve the clarity and robustness of their findings. However, the comment could be more helpful if it explained why error bars and more random trials are important or how they would address potential issues with the current figure. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, providing them with a clear path to enhance their draft. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a brief introduction to energy models in the related work section. It also points out that Figure 1 lacks information about which points correspond to different learning rates in the left graph and different steps in the right graph. The comment provides specific actions for the authors to take, such as introducing energy models and clarifying the figure. However, it does not specify how the authors should introduce energy models or what specific information should be included in the figure. While the actions are explicit, the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of information about which points correspond to different learning rates in the left graph and different steps in the right graph. Additionally, it suggests that the authors provide a brief introduction to energy models in the related work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a brief introduction to energy models in the related work section. It also points out that Figure 1 lacks information about which points correspond to different learning rates in the left graph and different steps in the right graph. The comment provides specific suggestions for improvement, which are mostly verifiable. However, it could be strengthened by including references or examples to support the claim about the need for an introduction to energy models. Therefore, the comment is categorized as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors should include a brief introduction to energy models in the related work section, which is a clear and actionable recommendation that can help readers better understand the context of the paper. Second, it points out a specific issue with Figure 1, noting that it lacks information about which points correspond to different learning rates in the left graph and different steps in the right graph. This feedback is helpful as it directs the authors to clarify an important aspect of their figure, which can enhance the paper\\'s clarity and accessibility. However, the comment could be more helpful if it provided specific suggestions on how to introduce energy models or how to clarify the figure. Overall, the feedback is mostly helpful, as it identifies areas for improvement and offers actionable guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED for determining chunk significance, suggesting that basing eviction decisions solely on utility scores might introduce biases. It provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative methods or additional criteria for eviction decisions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FIITED,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the utility-based approach to determining chunk significance and the potential biases introduced by basing eviction decisions solely on utility scores. The comment provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for premature evictions of valuable chunks due to recent chunks gaining a temporary high utility. This claim is somewhat verifiable as it provides a logical reasoning for the potential bias, but it lacks specific examples or references to support the assertion fully. The authors would need to consider this possibility and address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the utility-based approach used in FIITED for determining chunk significance. It highlights a concern that basing eviction decisions solely on utility scores might introduce biases, such as premature evictions of valuable chunks due to temporary high utility scores of recent chunks. This feedback is somewhat helpful as it points out a specific area that could be improved in the paper, prompting the authors to consider alternative methods or additional criteria for eviction decisions. However, the comment could be more helpful if it provided suggestions or examples of how to address this issue or offered a more detailed analysis of the potential biases. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the first paragraph of the Introduction for being overly focused on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this paragraph provides little value to readers and is not central to the paper. However, the comment does not provide explicit guidance on what the authors should do to address this issue. It lacks concrete suggestions or actions, such as recommending a reorganization of the Introduction or suggesting specific content to include. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paragraph, namely that it is overly focused on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The comment further explains that this paragraph provides little value to readers. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is overly focused on a general introduction of DNNs, without mentioning drift, which is the core focus of the paper. The reviewer suggests that this paragraph provides little value to readers. However, the comment lacks specific examples or detailed reasoning to support why the introduction is not relevant or how it could be improved. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is overly focused on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This feedback is clear and actionable, as it highlights a potential disconnect between the content of the paragraph and the paper's main focus. However, the comment could be more helpful if it suggested ways to restructure the paragraph or included specific examples of how to integrate drift-related content. Despite this, the comment provides valuable insight into a potential area for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms, as well as more detailed explanations of the presented algorithms. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The feedback is somewhat actionable as it provides a clear direction for improvement, but it lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It mentions the experimental aspect and the result section, providing some grounding by referencing specific sections of the paper. However, it does not specify which parts of the framework are unclear or which algorithms need more detailed explanations, making it weakly grounded. The comment is specific in its request for quantitative experiments and comparisons between algorithms, as well as more detailed explanations. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance of different parts of the framework and their contribution to the final result are unclear. It supports this claim by noting the lack of quantitative experiments and comparisons between algorithms, as well as a lack of detailed explanations for the presented algorithms. This provides a logical reasoning for the claim, as it highlights specific areas where the paper could be improved to provide more clarity. However, the comment could be strengthened by providing examples or references to similar works that do include such comparisons or explanations. Overall, the claim is mostly verifiable, as it provides a clear direction for improvement but lacks detailed evidence or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the clarity of the framework\\'s performance and contribution to the final result. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments and comparisons between different algorithms, as well as detailed explanations of the presented algorithms. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the comprehensiveness and clarity of their work. By suggesting the inclusion of quantitative experiments and detailed explanations, the comment offers valuable guidance for the authors to strengthen their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps should be taken to clarify the model\\'s capabilities. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment lacks specificity as it does not provide details on what aspects of the model or methodology are unclear or how the authors might address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any supporting evidence, reasoning, or examples to justify why this question is relevant or how it relates to the paper\\'s content. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses regarding neuron data. While it identifies a potential area of concern, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or what steps to take to clarify the model\\'s capabilities. Without actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors present a simplified version of Theorem 2 for the general audience, similar to how Theorem 1 is presented. This is an explicit request for a specific action, as it clearly instructs the authors to simplify Theorem 2 for better understanding. The comment provides a concrete suggestion on how to improve the clarity of the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests simplifying Theorem 2 for the general audience, similar to how Theorem 1 is presented. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the presentation of Theorem 2, but this inference is not as direct as it could be. The comment is specific in suggesting a simplification for better understanding, but it lacks grounding because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Theorem 2 is difficult to understand and proposes simplifying it for a general audience, similar to how Theorem 1 is presented. However, the comment does not provide specific reasoning or examples to support why Theorem 2 is challenging or how it could be simplified. Without detailed justification or examples, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity and accessibility of Theorem 2, suggesting that it might be challenging for a general audience to understand. It proposes a specific action for improvement by recommending a simplified version of Theorem 2, similar to how Theorem 1 is presented. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance on how to simplify Theorem 2 or specific areas that need clarification. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting experiments with a larger image resolution to evaluate performance. While it implies that the authors should perform additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what parameters to test. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with a larger image resolution, implying that the current experiments are limited to a resolution of 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by testing with a larger resolution, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments with a larger image resolution to evaluate performance. However, it does not provide any reasoning, evidence, or references to support why this would be interesting or beneficial. The suggestion is based on a logical inference that larger resolutions might impact performance, but without further justification or examples, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments with a larger image resolution to evaluate performance. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific resolutions to test. The suggestion is somewhat helpful as it points out a possible enhancement, but it does not offer actionable steps or detailed advice for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the keypoint mask averaged feature vector and whether it is obtained by multiplying each feature map element-wise by H_psi. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the clarity of the section. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to obtain the keypoint mask averaged feature vector, asking whether it is obtained by multiplying each feature map element-wise by H_psi. This provides clear guidance on what needs to be clarified or explained in the section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the method used to obtain the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the method used to obtain the keypoint mask averaged feature vector, specifically asking whether it is obtained by multiplying each feature map element-wise by H_psi. While this question identifies a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might clarify or address this issue in their draft. As a result, the comment is barely helpful, as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve this. While the comment explicitly states an action, it does not provide specific guidance on which curves should be differentiated or how to implement the suggested changes. The authors know they need to make the curves more distinguishable, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to improve the figure by recommending the use of styles (e.g., dashed lines) or adding color to distinguish between the different curves. This level of detail guides the authors on what changes to make to enhance the figure\\'s clarity. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve this. However, the comment does not provide any specific examples or detailed reasoning to support why these changes would be beneficial or how they would improve the figure\\'s clarity. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification or examples to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between the different curves. It provides a clear and actionable suggestion to improve the figure by recommending the use of styles (e.g., dashed lines) or adding color to enhance clarity. This feedback is valuable as it directly addresses a visual aspect of the paper that could impact its readability and understanding. By suggesting specific changes, the comment empowers the authors to make improvements that can significantly enhance the figure\\'s effectiveness. However, the comment could be more helpful if it included examples of how to implement these suggestions or discussed potential alternatives. Overall, the comment is mostly helpful, as it provides actionable guidance but could be further enhanced for maximum impact.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should tone down the introduction and not call the task \"language learning\" because it is more accurately described as a feedback-driven question-answering task in the form of a dialog. While the comment explicitly states the action to take, it does not provide specific guidance on how to reframe the introduction or what aspects to focus on. The authors are given a clear direction but lack detailed instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claims made in the introduction, specifically questioning the labeling of the task as \"language learning\" when it is more accurately described as a feedback-driven question-answering task in the form of a dialog. However, it does not specify which part of the introduction is being referred to, making it weakly grounded. The comment is specific in its critique of the terminology used and suggests a reframe of the task, but without explicit references to sections or examples, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claims made in the introduction are not consistent with the tasks and models evaluated, specifically questioning the labeling of the task as \"language learning\" when it is more accurately described as a feedback-driven question-answering task in the form of a dialog. The reviewer provides a logical reasoning by contrasting the claims with the actual nature of the task, suggesting that the terminology is misleading. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the claims made in the introduction, specifically questioning the labeling of the task as \"language learning\" when it is more accurately described as a feedback-driven question-answering task in the form of a dialog. This feedback is valuable as it points out a potential misalignment between the claims and the actual nature of the task, which could lead to confusion or misinterpretation among readers. The comment provides a clear suggestion to tone down the introduction and reframe the task, offering actionable guidance for the authors to improve the clarity and accuracy of their work. However, it could be more helpful if it included specific examples or references to support the claim or provide a more detailed explanation of how to reframe the introduction. Overall, the comment is mostly helpful, as it directs the authors toward a critical area for improvement but could be further enhanced with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the central contribution of the paper, specifically the use of ODEs to model weight evolution. It suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy when recomputing activations. While the comment implies that the authors should provide such evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the issue of inaccuracy in neural ODEs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the central contribution of the paper, which is modeling weight evolution using ODEs. It mentions a specific issue with neural ODEs, namely their inaccuracy when recomputing activations, and suggests that this problem was first reported in a previous paper. However, the comment does not specify which part of the paper discusses this issue or where the authors should address it. While it provides some context, it lacks full grounding as it does not explicitly mention a section or figure. The comment is specific in detailing the issue with neural ODEs and the need for analytical or empirical evidence, but it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not provide a convincing analytical argument or empirical evidence to support the central contribution of modeling weight evolution using ODEs. The reviewer suggests that a previous paper first reported the issue of neural ODEs exhibiting inaccuracy when recomputing activations. However, the comment does not provide a reference to this previous paper, making it difficult for the authors to verify the claim. The lack of specific evidence or references leaves the claim somewhat verifiable, as the authors would need to investigate further to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s central contribution, which is the use of ODEs to model weight evolution. It points out that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy when recomputing activations. This feedback is valuable as it highlights a significant gap in the paper\\'s justification of its main contribution. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what evidence could be included to strengthen their argument. Despite this, the comment is mostly helpful as it directs the authors\\' attention to a critical area that needs further development. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is an explicit suggestion that provides a clear action for the authors to take. The comment is specific and provides a concrete direction on what needs to be added to the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a request for clarification or additional information, not a claim or opinion that requires verification. It is a factual statement that does not need justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is a specific and actionable piece of feedback that can help the authors clarify their methodology and improve the clarity of their draft. By addressing this suggestion, the authors can enhance the comprehensiveness and accuracy of their paper. However, the comment could be more helpful if it provided additional context or explained why this information is important. Overall, the feedback is mostly helpful as it directs the authors to a specific improvement that can enhance the quality of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of the collaborative ranking results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their work based on the information provided. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the major chunk of work involved in proving results for batched ranking problems, specifically the lower bounds for round complexity. It mentions that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the theoretical analysis or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with the lower bounds and their relation to collaborative ranking, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It further states that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of these collaborative ranking results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the ease of the reduction or the implications of the lower bound results. Without these details, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a significant aspect of the paper, namely the major chunk of work involved in proving results for batched ranking problems, which is proving lower bounds for round complexity. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, making the lower bound results follow as an easy corollary. While the comment identifies a key contribution of the paper, it does not provide specific suggestions or guidance on how the authors might address this observation or improve their work. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the prompting technique used in the study is basic and suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, it does not provide specific guidance on how to curate these prompts or what aspects of the current technique need improvement. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more advanced prompting techniques but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the prompting technique used in the study, suggesting that it is basic and does not fully leverage the potential of LLMs. It implies that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. Additionally, while it provides a general suggestion for improvement, it lacks specificity in terms of what aspects of the prompting technique need to be addressed or how to curate better prompts. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks evidence or justification for why carefully curated prompts would lead to better results, making it difficult for the authors to understand and address the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and may not fully leverage the potential of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specificity and does not provide detailed guidance or examples on how to curate these prompts or what aspects of the current technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat vague and incomplete, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer actionable advice on how to handle it. The feedback is somewhat actionable as it identifies a potential area for improvement but lacks concrete steps for execution. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting additional experiments and acknowledging the potential issue of compute, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would contribute to the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. While it provides a clear suggestion for improvement, it lacks specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment also acknowledges that this aspect is not critical, which could be seen as a limitation in terms of actionable feedback. Overall, the comment offers a somewhat helpful direction for improvement but could be more detailed and actionable to be fully beneficial to the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the performance of Table 4, noting that it is behind more recent models. It provides examples of models, GLaMM and UNINEXT, that have achieved better results on specific metrics. However, the comment does not explicitly instruct the authors to improve their results or suggest ways to address this issue. The action is implicit, as the authors can infer that they need to improve their performance, but it lacks concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of the model, noting that it is behind more recent models and provides examples of models that have achieved better results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance in Table 4 is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by providing specific metrics and results from these models, which helps verify the assertion. However, the comment could be strengthened by including more detailed comparisons or references to other relevant works. Overall, the claim is mostly verifiable, as it provides sufficient evidence to support the assertion but lacks comprehensive references or additional context. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the model, as evidenced by the results in Table 4. It highlights that the performance on REC and RES is behind more recent models, such as GLaMM and UNINEXT, which have achieved better results on specific metrics. This feedback is clear and actionable, as it provides the authors with a direct comparison to recent models, allowing them to assess their own performance and potentially identify areas for improvement. However, the comment could be more helpful if it included suggestions on how to address this issue or provided additional context or references to guide the authors in making improvements. Overall, the comment is mostly helpful, as it effectively points out a weakness and offers a starting point for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"evidence\" may be too strong in the context of the statement about Figure 5, and proposes an alternative phrasing. However, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should modify the wording but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, such as a specific section, figure, or table. It also lacks specificity because it does not provide details on what aspect of the evidence is considered too strong or what the alternative phrasing should be. Without clear references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the term \"evidence\" may be too strong in the context of Figure 5, proposing an alternative phrasing. However, the comment does not provide any reasoning or examples to support why \"evidence\" is too strong or how the alternative phrasing would be more appropriate. Without additional context or justification, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the term \"evidence\" may be too strong in the context of Figure 5, proposing an alternative phrasing. While this feedback identifies a potential issue with the language used, it lacks depth and does not provide specific guidance on how to improve the phrasing or what alternative wording might be more appropriate. The comment is somewhat helpful as it points out a minor issue, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on frame-wise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of cross-attention. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or enhance the novelty of their approach. The action is implicit and vague, as the authors are left to infer that they should explore ways to differentiate their method from existing approaches or provide additional justification for the novelty of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning the reliance on frame-wise SDSA, which mirrors the approach used in ConsiStory. It also notes the use of CLIPseg and OTSU segmentation as mask sources instead of cross-attention. However, the comment does not specify which part of the paper discusses these methods or their comparison to ConsiStory, making it weakly grounded. The comment is specific in detailing the limitations of novelty, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed video storyboarding approach is limited, specifically noting that the primary method relies on frame-wise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of cross-attention. While the comment provides some reasoning by comparing the method to ConsiStory, it lacks specific examples or detailed analysis to fully substantiate the claim. The reference to ConsiStory is a starting point, but more detailed comparison or evidence would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on frame-wise SDSA, which mirrors the approach used in ConsiStory. The comment highlights the use of CLIPseg and OTSU segmentation as mask sources as a minor difference compared to cross-attention. While the comment points out a specific area for improvement, it lacks actionable suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing methods. The feedback is somewhat helpful as it prompts the authors to consider the uniqueness of their work, but it could be more beneficial with additional direction or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method\\'s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for comparison but are not given detailed instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method\\'s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Additionally, it lacks specificity regarding what aspects of the method should be compared or how the comparison should be conducted. As a result, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the method\\'s weakness would be more prominent in images with multiple objects or cluttered scenes. It proposes a comparison with previous methods on a dataset with such images, which would be interesting. However, the comment lacks specific examples or references to support the claim that the method\\'s weakness is more pronounced in such scenarios. Without detailed evidence or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a logical suggestion but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method\\'s applicability, suggesting that it may be more effective in images with multiple objects or cluttered scenes. It offers a constructive suggestion to compare the approach with previous methods on such datasets, which could provide valuable insights into the method\\'s strengths and limitations. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its actionable nature. While it highlights an area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it implies that the authors should provide additional explanation, it does not explicitly instruct them to do so or specify how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more explanation but are not given detailed guidance on what specific aspects to focus on or how to present the additional information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper currently lacks this explanation, making it weakly grounded. The comment is specific in suggesting that additional explanation could be beneficial, but it does not provide detailed guidance on what aspects of the bounds need clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning or examples to support why this additional explanation is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the space limitations but suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the bounds need further explanation or how to present this information in the appendix. The feedback is somewhat helpful as it points out a gap in the paper but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that a full-page explanation of the implementation of kernels with OpenAI\\'s Triton instead of CUDA is unnecessary because of well-known engineering improvements. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific aspects of the explanation are unnecessary. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors without a clear understanding of what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"kernels\" and \"OpenAI\\'s Triton,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that a full-page explanation of the implementation is unnecessary due to well-known engineering improvements. This provides clear guidance on what aspect of the paper should be revised or omitted. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a full-page explanation of the implementation of kernels with OpenAI\\'s Triton instead of CUDA is unnecessary due to well-known engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper uses OpenAI\\'s Triton for kernel implementation instead of CUDA, suggesting that a full-page explanation is unnecessary due to well-known engineering improvements. While the comment identifies a potential area for improvement by suggesting that the explanation could be condensed, it lacks depth and does not provide specific guidance on how to address this issue or what aspects of the explanation could be simplified. The feedback is somewhat helpful as it highlights a potential area for streamlining the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the zero-shot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides specific examples to support the claim, such as the difference between the \"walker-run\" and \"walker-walk\" tasks and the complexity of the manipulation scenario. The comment explicitly states that the authors need to clarify these points in the paper to avoid misleading readers. The feedback is clear and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises questions about the zero-shot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walker-run\" and \"walker-walk\" tasks and the complexity of the manipulation scenario, to support its claims. However, it does not explicitly mention which part of the paper these examples are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the difficulty of policy transfer and the need for clear explanations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the zero-shot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between the \"walker-run\" and \"walker-walk\" tasks and the complexity of the manipulation scenario, to support their claim. This level of detail and reasoning makes the claim mostly verifiable, as it provides a logical basis for the critique. However, the comment could be strengthened by referencing specific literature or studies that support the idea of limited transferability in similar scenarios. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical question about the zero-shot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walker-run\" and \"walker-walk\" tasks and the complexity of the manipulation scenario, to support its claim. The comment also highlights the need for the authors to clarify these points in the paper to avoid misleading readers. This feedback is clear and actionable, as it identifies a potential weakness in the study and offers specific suggestions for improvement. By addressing these issues, the authors can enhance the clarity and validity of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method achieves only a modest improvement over baselines, particularly on a small backbone like ResNet-50. It suggests that the method might struggle on larger backbone models like Swin-B or Swin-L due to the introduction of global pooling. While the comment implies that the authors should test their method on larger models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what specific tests to conduct. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"relative gains\" achieved on different frameworks and tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method only achieves a modest improvement over baselines, particularly on a small backbone like ResNet-50. The comment further suggests that the method might struggle on larger backbone models like Swin-B or Swin-L due to the introduction of global pooling. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method achieves only modest improvements over baselines, particularly on a small backbone like ResNet-50. It suggests that the method might struggle on larger backbone models due to the introduction of global pooling. The comment provides a logical reasoning by pointing out the potential limitations of the method on larger models, which is a reasonable inference based on the described characteristics. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the proposed method, noting that the relative gains are not very strong, especially on a small backbone like ResNet-50. It suggests that the method might struggle on larger backbone models due to the introduction of global pooling, which could limit its effectiveness on larger receptive fields. This feedback is somewhat helpful as it points out a specific area for improvement and provides a logical reasoning for why the method might not perform as well on larger models. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches that could be explored. Overall, the comment is somewhat helpful, as it prompts the authors to consider the scalability of their method and its potential limitations.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fully-connected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these criticisms or improve their analysis. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions sections 3.2 and 3.3, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the critique of the analysis of neural networks, explaining that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fully-connected neural networks is trivial. It also suggests that the work bypasses the core problem of overparametrized neural networks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but requires more detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fully-connected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fully-connected neural networks. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that the authors should consider adding more datasets or providing a repository for reproducing experiments. While the comment implies an action, it does not explicitly instruct the authors to take specific steps, such as identifying additional datasets or creating a repository. The suggestion is somewhat vague, as it lacks concrete details on how to implement the proposed changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sufficiency of the datasets for a rigorous evaluation, particularly in relation to the number of datasets available for each task. It mentions that having 5, 6, and 4 datasets for the three tasks, respectively, might not be sufficient. However, the comment does not specify which sections or parts of the paper discuss these datasets, making it weakly grounded. The comment is specific in its critique of the dataset selection and its impact on evaluation rigor. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. The reviewer suggests that having fewer datasets for each task might not provide a comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that the datasets are insufficient. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to address the concern effectively. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for each task might not provide a comprehensive evaluation. The comment is somewhat helpful as it identifies a potential weakness in the dataset selection and evaluation process. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or providing a rationale for the current dataset selection. To be more helpful, the comment could include actionable advice or examples of how to improve the dataset selection process. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the results presented, noting that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This comment implies that the authors should include results with larger models to provide a more comprehensive evaluation of their work. However, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate these results. The action is implicit and somewhat vague, as the authors can infer that they need to include larger model results but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a gap in the results presented, noting that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. However, it does not specify which part of the paper this observation is based on, such as a specific section or table where results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the absence of results with larger models, but without explicit grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This claim is based on the observation that the paper does not include results with larger models, which is a logical inference. However, the comment lacks specific references or detailed reasoning to support why the inclusion of results with larger models would be beneficial or necessary. While the claim is somewhat verifiable due to the logical reasoning, it could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the results presented, noting that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback is somewhat helpful as it points out an area where the authors could expand their evaluation to provide a more comprehensive understanding of their model's performance. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or why it is important to include results with larger models. While it provides some insight into an area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific reference to a related work, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multi-fidelity Approach (Stroh et al. 2017),\" which the authors should consider incorporating into their paper. This suggests a concrete action for the authors to take. However, the comment also points out a potential inconsistency in the paper, noting that \"relatively inexpensive\" is used in the abstract and \"expensive to evaluate\" in the introduction. While this highlights a specific issue, it does not provide explicit guidance on how to resolve it. The action is mostly concrete but lacks detailed instructions, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the multi-fidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance),\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific reference to a related work, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multi-fidelity Approach (Stroh et al. 2017),\" which further grounds the comment. The comment is specific because it points out a potential inconsistency in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a claim about the relevance of a specific reference and a factual observation regarding a potential inconsistency in the paper. The first part is verifiable as it provides a specific reference to a related work, which can be easily verified by the authors. The second part is a factual observation about the language used in the abstract and introduction, which does not require verification. Therefore, the overall comment is mostly verifiable, as it combines a verifiable claim with a factual observation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific reference to a related work, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multi-fidelity Approach (Stroh et al. 2017),\" which the authors should consider incorporating into their paper. This suggestion is valuable as it can help the authors contextualize their work within the existing literature and potentially enhance the relevance and impact of their study. Additionally, the comment points out a potential inconsistency in the paper, noting the use of \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This observation highlights a specific area for clarification or consistency, which can help the authors improve the clarity and coherence of their draft. However, the comment could be more helpful if it provided further guidance on how to address the inconsistency or integrate the reference into the paper. Overall, the comment is mostly helpful as it offers actionable feedback and relevant references, but it could be more comprehensive with additional suggestions or explanations.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the method\\'s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The comment lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the method\\'s effectiveness and the comparison with Qmix, but it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the method\\'s ability to address sparse reward problems and compares it to other methods like Qmix. However, the comment lacks specific evidence or examples to support the claim that the method does not address sparse reward problems effectively. It also does not provide references or detailed reasoning to substantiate the comparison with Qmix. Without these elements, the claim remains vague and difficult for the authors to address, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the method\\'s ability to address sparse reward problems, specifically questioning whether it offers a better solution compared to other methods like Qmix. It also points out a potential issue with the proposed method requiring sub-task-specific rewards, which could be seen as providing a dense reward signal. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns or improve their method. While it identifies an area for improvement, the feedback is vague and does not offer actionable steps, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the curated AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN had access to this data during training for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training for a fair comparison. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the use of the dataset and the fairness of comparisons, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the curated AH36M dataset for training and whether other methods had access to it during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training. This is a relevant concern for ensuring a fair comparison among different methods. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or what steps they should take to clarify the use of the dataset. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more helpful with additional direction. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or comparison need clarification. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"confusing mistakes in the proof of the main results\" and \"a lack of detailed discussion and comparison with previous work,\" which provides some grounding as it implies specific sections of the paper that need attention. However, it does not specify which parts of the proof are confusing or which previous work should be discussed, making it weakly grounded. The comment is specific in identifying the lack of detailed discussion and comparison with previous work, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are \"confusing mistakes in the proof of the main results\" and that the paper lacks a detailed discussion and comparison with previous work. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed justification or evidence makes the claims unverifiable, as the authors are left without clear guidance on how to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide new insights. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without specific steps to take. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not provide actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pre-trained models. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the motivation and potentially revise the experimental setup, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also mentions the addition of CAT and GAN, which makes the proposed model larger than others. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the concerns about the motivation and experimental fairness, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pre-trained models. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of evidence or detailed explanation makes the claims somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas of concern, including the lack of clarity in the motivation for using an adversarial network and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pre-trained models. While the comment highlights important issues, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it directs the authors to areas that need clarification or improvement, but it lacks actionable advice, making it difficult for the authors to fully understand and implement the necessary changes. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare their results on the official COOC leader board on the blind test set, referencing a specific link to the competition results. It also suggests comparing to other approaches that have been proposed since the paper was published, mentioning specific examples of approaches that have won the challenge. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The explicit nature of the instructions and the specific examples make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board on the blind test set,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results on the official test set and the inclusion of comparisons to other approaches that have been proposed since the paper was published. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should compare its results on the official COOC leader board on the blind test set, referencing specific examples of approaches that have won the challenge and have been evaluated on the blind challenge set. The reviewer provides a link to the competition results, which supports the claim by offering a clear reference for the authors to follow. This level of detail and specific references make the claim mostly verifiable, as it provides a clear path for the authors to address the feedback. However, the comment could be strengthened by including more detailed reasoning or examples of how the current comparison is insufficient. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out that the paper only compares its results on a not official test set or dev set, rather than the official COOC leader board on the blind test set. It references a link to the competition results and suggests that the authors should compare their results to those of other approaches that have won the challenge and have been evaluated on the blind challenge set. Additionally, the comment highlights the need to compare to other approaches that have been proposed since the paper was published, as several have significantly improved. This feedback is clear and detailed, offering the authors specific guidance on how to improve the validity and comprehensiveness of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reliability of the experimental results, specifically in Table 1 where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve the reliability of their results. There is no suggestion on what steps to take to resolve the concern or how to ensure the validity of the results. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the concern about the reliability of the results due to the significant difference between the MSE and MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are unreliable, specifically in Table 1 where the MSE is significantly smaller than the MAE. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discrepancy raises concerns about the validity of the results. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the reliability of the results. This is a clear and actionable feedback that highlights a potential problem with the experimental methodology or analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. While it points out a critical area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed meta algorithm is a direct extension of existing methods, suggesting that there is little novelty in the methodology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of novelty or improve the methodology, nor are there suggestions for potential modifications or enhancements. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the methodology, specifically mentioning that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology description. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what aspects of the methodology are considered extensions or how they could be improved. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed meta algorithm is a direct extension of existing methods, suggesting a lack of novelty in the methodology. However, the comment does not provide specific examples or references to existing methods that the proposed algorithm is based on, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or references, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a lack of novelty in the methodology, specifically noting that the proposed meta algorithm is a direct extension of existing methods. While this feedback identifies a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without specific advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of an adversarial loss to ensure that perturbed data remains similar to authentic data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this concern or suggest specific methods or techniques that could be used to implement an adversarial loss. The action is implicit and somewhat vague, as the authors are left to infer that they need to add an adversarial loss but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the absence of an adversarial loss to ensure the perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment where this loss is expected. Without explicit references or context, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. The comment is specific in identifying the issue but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no adversarial loss to ensure the perturbed data is similar to the authentic data. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper\\'s results. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of an adversarial loss to ensure the perturbed data remains similar to authentic data. This is a relevant observation that could impact the robustness and validity of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific adversarial loss techniques could be employed. While it highlights a potential weakness, the feedback is somewhat vague and incomplete, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides a clear and direct action for the authors to take, which is to clarify the terminology used in the paper. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line 248, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"wrong\" and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific point in the paper where the term \"wrong\" is used without clarification, suggesting that the authors should clarify the concepts of good, bad, and wrong explanations before using them. This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their terminology, which can improve the overall understanding of the paper. However, the comment could be more helpful if it provided examples or further guidance on how to clarify these concepts. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a sample-by-sample basis. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending specific methods for tuning hyperparameters or discussing potential strategies to mitigate the variation. Without concrete advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a sample-by-sample basis. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the issue with hyperparameter tuning, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a sample-by-sample basis. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a sample-by-sample basis. This is a relevant concern that could impact the robustness and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods for hyperparameter tuning or discussing potential strategies to mitigate the variation. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of the proposed method should be compared with more methods and that analysis should be provided for inferior results that violate the motivation. While the comment implies that the authors should expand their comparisons and provide additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more comparisons and analysis. However, the comment does provide a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison of performance with other methods and the consistency of the proposed method\\'s superiority. It suggests that analysis should be provided for inferior results that violate the motivation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional analysis, but without clear grounding, it is challenging for the authors to determine where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. However, the comment lacks specific examples or references to support the claim about the limited comparison or the inconsistency in performance. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but requires more detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s performance evaluation, noting that it is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. This feedback is clear and actionable, as it directs the authors to expand their comparisons and provide additional analysis to address the inconsistency. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or which methods to include in the comparison. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. The comment implies that the authors should include this comparison to prove the superiority of their method over MVF. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to address the issue: include a comparison with MVF. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely the comparison with MVF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of its contribution points. It specifically notes the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF, which is necessary to prove the superiority of the schema searched by the author\\'s method over MVF. This claim is somewhat verifiable as it highlights a specific gap in the experimental section that could be addressed to strengthen the paper\\'s claims. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental section of the paper, noting that it lacks sufficient demonstration of the contribution points. It points out that the paper only compares the author\\'s method (ELF) with the baseline without Mid Vision Feedback (MVF), but does not include a comparison with the image classification result of MVF. This omission is crucial for proving the superiority of the schema searched by ELF over MVF. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of this comparison. However, it could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand their discussion on these aspects, but it lacks concrete details on what specific information should be included or how to present it. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a specific section or chapter. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in identifying the missing content but lacks grounding, as it does not indicate where in the paper this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks coverage on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the gap or how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is somewhat helpful as it points out an area where the authors could provide more depth and context to their work. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending additional data sources or analysis methods. While it highlights an area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, it does not provide specific guidance on what alternative notation to use or how to implement this change. The action is explicit in suggesting a change but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure where \"D\" is used. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment specifies the issue of confusion, it does not provide detailed guidance on how to address it or suggest alternative notations. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, the comment does not provide any reasoning or examples to support why this confusion exists or how it could be resolved. Without specific evidence or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion in the paper, noting that the letter \"D\" is used to represent both dimensionality of points and dilation factor. It suggests using different notation to avoid this confusion, which is a clear and actionable piece of feedback. However, the comment lacks depth and does not provide specific guidance on how to implement this change or what alternative notation might be more appropriate. While it highlights an important issue, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. It questions whether \"elements\" in lines 186-187 are equivalent to \"states\" or \"actions\" and recommends further elaboration. While the comment identifies a specific area of confusion and suggests a potential clarification, it does not provide explicit instructions on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the concept of \"state\" and potentially rephrase \"elements\" to align with the intended meaning. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 186-line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether \"elements\" are equivalent to \"states\" or \"actions\" and suggests that more elaboration is needed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. The reviewer questions whether \"elements\" in lines 186-187 are equivalent to \"states\" or \"actions\" and recommends further elaboration. While the comment identifies a potential area of confusion, it lacks specific examples or references to support the claim. The suggestion for clarification is logical but requires more detailed explanation or evidence to be fully verifiable. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the concept of \"state\" in the paper. It questions whether \"elements\" in lines 186-187 are equivalent to \"states\" or \"actions,\" suggesting that more elaboration is needed to clarify this point. This feedback is clear and actionable, as it directs the authors to address a particular aspect of their work that may be unclear to readers. By providing a specific line reference, the comment helps the authors pinpoint the exact location where clarification is needed. However, the comment could be more helpful if it offered suggestions on how to clarify the concept or provided examples of how to differentiate between \"states\" and \"elements.\" Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity and comprehensibility of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular comparison method, but without clear grounding, the authors may struggle to identify the exact section where this comparison should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper by adding a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct this comparison or what specific metrics to use. While it points out a potential area for improvement, it does not fully support the authors in implementing the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue in Section 5.3, where a generator equipped with a standard R-GCN as a discriminator tends to collapse after a certain number of iterations. The reviewer suggests that the reason behind this fact is essential to understand the mechanism by which the proposed method differs from previous ones. The comment implies that the authors should include an explanation for this observation, but it does not explicitly instruct them to do so. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be addressed: the reason for the proposed module\\'s ability to prevent generator collapse. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of a generator equipped with a standard R-GCN as a discriminator collapsing after a certain number of iterations, and it suggests that the reason behind this fact is essential to understand the proposed method\\'s differences. The comment further specifies that this part is missing in the current submission and requests an explanation for why the proposed module can prevent generator collapse. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed module prevents a generator from collapsing, while a generator equipped with a standard R-GCN as a discriminator tends to collapse after a certain number of iterations. The reviewer suggests that understanding the reason behind this difference is essential to demonstrate the mechanism by which the proposed method differs from previous ones. However, the comment lacks specific evidence or detailed reasoning to support the claim that the proposed module prevents collapse. It does not provide examples, references, or a clear explanation of how the proposed module achieves this prevention. As a result, the claim is somewhat verifiable, as it provides a logical basis but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that a generator equipped with a standard R-GCN as a discriminator tends to collapse after a certain number of iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is crucial to demonstrate the mechanism by which the proposed method differs from previous ones. However, the comment points out that this explanation is missing in the current submission. By highlighting this gap and suggesting that the authors include an explanation, the comment provides clear and actionable feedback that can help the authors improve their draft. The comment is mostly helpful as it directs the authors to a specific area for enhancement, but it could be more comprehensive by offering additional guidance on how to present the explanation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The action is implicit and vague, as the authors are left to infer that they need to clarify the originality of their work but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the article, noting similarities to another work. However, it does not specify which parts of the article are similar or how they relate to the previous study. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention or improvement. Additionally, the comment does not provide explicit references to the previous study, making it challenging for the authors to pinpoint the specific similarities. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the originality of the article, noting similarities to another work. However, it does not provide specific examples or detailed comparisons to substantiate the claim. The comment lacks explicit references or detailed reasoning to support the assertion that the current work is merely an extension of the previous study. This makes the claim somewhat verifiable, as it highlights a potential issue but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. This feedback is somewhat helpful as it prompts the authors to consider the uniqueness and novelty of their work, potentially leading to a more thorough examination of their contributions. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or differentiate their work from the previous study. To be more helpful, the comment could include examples of similarities or suggest ways to highlight the novelty of the current work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific aspects need clarification. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Without concrete steps or examples, the authors are unable to make meaningful changes to their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue pertains to. The authors can infer that it might be related to the theoretical sections or discussions, but without explicit references, it is weakly grounded. The comment is specific in pointing out the lack of clarity in the theoretical comparisons, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of concern regarding the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve this aspect of their paper. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is barely helpful, as it points out a problem but does not offer any direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. While the comment implies that the authors should consider alternative methods or provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore other methods or provide additional analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of measuring object hallucination through only yes/no responses, suggesting that a yes response does not necessarily indicate comprehension. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is discussed. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while the comment provides a specific critique about the limitations of yes/no responses, it does not offer guidance on how to address this issue or suggest alternative methods. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. This claim is somewhat verifiable as it provides a logical reasoning for why yes/no responses alone might not be sufficient. However, the comment lacks specific examples or references to support the claim, which would strengthen its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. This feedback is somewhat helpful as it prompts the authors to consider alternative methods or provide more detailed analysis to better assess the model\\'s understanding of object presence. However, the comment could be more helpful if it offered specific suggestions or examples of alternative approaches to address this issue. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited practical significance of the very-long-term forecasting task and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment implies that these actions are necessary, it does not explicitly instruct the authors to do so. The authors can infer the need for these improvements, but the comment lacks concrete guidance on how to implement them. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the discussion section of the paper, specifically mentioning the need for improvement in the context of the very-long-term forecasting task. It suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. However, the comment does not explicitly mention which part of the discussion is lacking or what specific aspects need improvement. While the authors can infer that it relates to the discussion section, the lack of explicit references makes it weakly grounded. The comment is specific in suggesting improvements, such as conducting additional experiments and training baseline models, but it does not specify which parts of the discussion are problematic. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the very-long-term forecasting task is of limited practical significance and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. However, the comment lacks specific reasoning or evidence to support the claim about the limited practical significance of the task. It also does not provide examples or references to justify the need for additional experiments or training with the \"correct\" forecast horizon. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practical significance of the very-long-term forecasting task, suggesting that the discussion could be improved by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for enhancing the discussion. However, the comment lacks detailed guidance on how to conduct these experiments or what specific datasets or forecast horizons should be considered. While it offers a clear direction, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that experiments and explanations regarding the different queries used in spatio-temporal representation are missing. It suggests that experiments should be conducted to explore the impact of using only spatial, temporal, or summary queries. This feedback provides a clear and concrete action for the authors to take, as it specifies what needs to be done to address the issue. The comment is highly actionable as it gives direct instructions on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments - Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: experiments and explanations regarding the different queries used in spatio-temporal representation, such as spatial, temporal, and summary queries. The comment also provides a suggestion for what should be explored, which is the key difference to VideoChatGPT and other works. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that experiments and explanations regarding the different queries used in spatio-temporal representation are missing. It suggests that experiments should be conducted to explore the impact of using only spatial, temporal, or summary queries. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these experiments are necessary or how they would contribute to the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks experiments and explanations regarding the different queries used in spatio-temporal representation. It suggests that experiments should be conducted to explore the impact of using only spatial, temporal, or summary queries, which is a key difference from VideoChatGPT and other works. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by conducting additional experiments. However, the comment could be more helpful if it offered specific guidance on how to design these experiments or what outcomes to expect. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not provide specific guidance on what aspects of the FRM should be elaborated or how the authors should present this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on what to include. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not specify which part of the paper this description should be added to, making it weakly grounded. The comment is specific in its request for more detailed explanation of the innovative aspects of the FRM. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. However, the comment does not provide any specific reasoning or evidence to support why this description is lacking or how it could be improved. Without additional context or examples, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. This feedback is somewhat helpful as it points out a potential weakness in the paper and encourages the authors to provide a more comprehensive explanation of their innovative approach. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the FRM should be elaborated or how to present them. To be more helpful, the comment could include suggestions on what specific details should be included or how to better explain the innovation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors could mention the social impact of increased automation or the risks from the dual use of their method, even though the reviewer does not believe the work has significant negative social impact. While the comment implies that the authors should address these potential impacts, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss these aspects but are not given specific guidance on how to integrate them into their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could mention the social impact of increased automation or the risks from the dual use of their method. This provides clear guidance on what the authors could include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual statement about the authors' claim regarding the lack of negative social impact and a suggestion to address potential social impacts. The reviewer does not express an opinion or make a claim that requires verification. It is a request for clarification or additional discussion, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the authors' claim that their work has no negative social impact and suggests that they could address potential social impacts, such as increased automation or dual-use risks. While the comment identifies a potential area for improvement, it lacks specificity and actionable guidance on how the authors might address these concerns. It does not provide detailed suggestions or examples of how to incorporate discussions on social impact into the paper. As a result, the feedback is somewhat helpful, as it points out an area for consideration but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a potential restructuring of the paper by moving the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. While the comment implies an action, it does not provide explicit instructions on how to implement this restructuring or why it would improve the paper. The authors can infer that they need to rearrange the sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable, as it provides an idea but lacks detailed execution steps.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a potential restructuring of these sections, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Sections 3 and 4 are slightly redundant and proposes a restructuring to improve clarity. However, it does not provide any specific examples or detailed reasoning to support why the sections are redundant or how the proposed restructuring would benefit the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with redundancy in Sections 3 and 4 of the paper, suggesting a restructuring that could improve clarity. It provides a specific suggestion for rearranging the content, which is actionable and could help the authors enhance the organization and flow of their draft. However, the comment could be more helpful if it explained why the current structure is redundant or how the proposed restructuring would benefit the paper. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, making it a 4 on the scale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, it does not provide explicit guidance or suggestions on how the authors might clarify this connection or improve the clarity of their work. The comment highlights an issue but lacks actionable advice, leaving the authors uncertain about how to address the problem. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by pointing out the lack of clarity, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and not specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there is a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or establish a clearer connection between these concepts. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issue but without a clear path to resolution. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the notation used for \\hat v^*_t, suggesting that it seems like strange notation. It notes that elsewhere, the \\hat is used for empirical estimates, but here it refers to something else. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or clarify the notation. The action is implicit and vague, as the authors are left to infer that they need to clarify the notation but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L434,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the notation used for \\hat v^*_t, explaining that it seems like strange notation and that elsewhere, the \\hat is used for empirical estimates. This provides clear guidance on what needs to be addressed regarding the notation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \\hat v^*_t seems strange and suggests that it is used differently from its standard usage elsewhere in the paper. However, the comment does not provide any further explanation or justification for why this notation is problematic or how it deviates from the standard usage. Without additional context or examples, the claim remains vague and lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the notation used in the paper, specifically the notation \\hat v^*_t. It notes that this notation seems strange and suggests that it might be used differently from its standard usage elsewhere in the paper. This feedback is somewhat helpful as it alerts the authors to a potential inconsistency or confusion in their notation, which could be clarified or corrected. However, the comment lacks depth and does not provide specific guidance on how to address the issue or what alternative notation might be more appropriate. To be more helpful, the comment could suggest alternative notations or explain why the current notation is problematic. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide explicit instructions or concrete steps on how to conduct these analyses or experiments. While the authors can infer that they need to perform additional research, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It mentions specific aspects that could be explored, such as the performance of simple greedy selection versus more principled acquisition functions and the superiority of deterministic MLP predictors over probabilistic predictors. However, the comment does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical results of the proposed method are strong and that a more novel contribution would be to explore theoretical analyses or extensive experiments to understand the reasons behind the performance of simple greedy selection and deterministic MLP predictors. The comment highlights a gap in the paper regarding rigorous analyses to support these findings. However, it does not provide specific examples, references, or detailed reasoning to substantiate the claim that the current analyses are insufficient. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the need for additional analyses based on the general suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It specifically mentions the superiority of simple greedy selection over more principled acquisition functions and the performance of deterministic MLP predictors over probabilistic predictors. While the comment highlights an interesting direction for further exploration, it lacks specific guidance or detailed suggestions on how to conduct these analyses or experiments. The authors are left with a general idea of what could be explored but without concrete steps to follow. Therefore, the comment is somewhat helpful, as it provides some direction but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a citation for the discussion of the \"k-max problem\" elsewhere. This is a clear and direct action that the authors can take to address the comment. The instruction is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"the k-max problem,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the need for a citation, providing clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, specifically asking for a citation regarding the discussion of the \"k-max problem\" elsewhere. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific in its request for a citation regarding the discussion of the \"k-max problem\" elsewhere. This feedback is actionable and provides a direct way for the authors to improve their draft by addressing a potential gap in their literature review. However, the comment could be more helpful if it provided context or explained why this information is important or relevant to the paper. Despite this, the comment is mostly helpful as it guides the authors toward a specific improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include this information, but it lacks concrete details on how to estimate the function or what specific aspects of reliability should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. This provides full grounding as it explicitly mentions a specific equation and a specific aspect of the model\\'s reliability. The comment is also specific because it clearly identifies what information is missing and what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reliability of the model by noting the absence of information on how the function for the optimal sequence length was estimated (Equation 1). This is a claim that requires verification, as it suggests a potential weakness in the paper\\'s methodology. However, the comment lacks specific details or references to support the claim, such as examples of how this estimation could impact the model\\'s reliability. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the significance of this omission themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out the absence of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is valuable as it highlights a specific area where the authors need to provide more detail and justification. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending specific methods or analyses to include. Despite this, the comment provides a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the applicability of the methods to real-world problems due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to relax these assumptions or improve the applicability of the methods. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods to real-world problems, specifically mentioning the strong assumptions about the availability of camera parameters and object segmentation. However, it does not specify which part of the paper discusses these assumptions or how they impact the applicability of the methods. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. It is specific in identifying the issue with the assumptions, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the applicability of the methods to real-world problems is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the limitation. Without detailed justification or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the applicability of the methods to real-world problems due to strong assumptions about the availability of camera parameters and object segmentation. This feedback is relevant and highlights a potential weakness in the paper that the authors need to address. However, the comment does not provide specific suggestions or guidance on how to relax these assumptions or improve the applicability of the methods. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific issue with the use of the word \"thousands\" in line 006, suggesting that it may not be accurate and recommending the addition of \"on the subword level.\" This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in their draft. The comment is explicit and concrete, giving the authors a precise direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the use of \"thousands\" is not accurate and suggests adding \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"thousands\" in line 006 is not accurate and suggests adding \"on the subword level.\" However, the comment does not provide any supporting evidence or reasoning to justify why \"thousands\" is incorrect or how the addition of \"on the subword level\" would improve the accuracy. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the word \"thousands\" in line 006, suggesting that it may not be accurate and recommending the addition of \"on the subword level.\" This feedback is clear and actionable, providing the authors with a precise suggestion for improvement. By addressing this point, the authors can enhance the accuracy and clarity of their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the addition would improve the draft. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or reasoning. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues. First, it notes that some hyperparameters, such as regularization, are not given. Second, it questions why the y value at x=0 is always 0 in the latent path figures, suggesting that this might be due to normalization. The reviewer also requests clarification in the description and suggests further analysis using the interpolations themselves. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises multiple issues, including the lack of information on hyperparameters and the behavior of the y value at x=0 in the latent path figures. It also suggests further analysis using interpolations. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the sections discussing hyperparameters and the latent path figures, such as Figure 3. The comment is specific in detailing what needs to be addressed, namely the lack of hyperparameter information and the behavior of the y value at x=0. However, it lacks full grounding as it does not explicitly mention the sections or figures being addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, each of which requires verification. First, it claims that \"a number of hyperparameters are not given,\" which is a subjective opinion that lacks specific examples or references to support the claim. Second, it questions why the y value at x=0 is always 0 in the latent path figures, suggesting that it might be due to normalization. This claim is somewhat verifiable as it provides a logical reasoning but lacks specific evidence or references to fully substantiate the claim. Third, the reviewer suggests further analysis using interpolations, which is a request for additional work rather than a claim. Overall, the comment contains a mix of claims and requests, with some elements being somewhat verifiable and others requiring more detailed justification. Therefore, the overall score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It points out the lack of information on hyperparameters, such as regularization, which is important for reproducibility and understanding the model's behavior. It also questions the behavior of the y value at x=0 in the latent path figures, suggesting that it might be due to normalization and asking for clarification. Additionally, the reviewer suggests further analysis using interpolations, which could provide valuable insights into the model's performance. While the comment highlights specific issues and offers suggestions for improvement, it could be more helpful by providing more detailed guidance on how to address these points. Overall, the feedback is mostly helpful as it directs the authors to areas that need clarification and additional analysis, but it could be more comprehensive with specific suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues: forward referencing and the need for clearer explanations of contributions in the introduction. It also points out that material supporting the main contributions is in the appendix rather than the main sections. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the contributions in the introduction and ensure that the main contributions are discussed in the main sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for clearer explanations of contributions and the placement of material supporting the main contributions in the appendix rather than the main sections. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, with material being introduced without proper explanation and then explained later. It also mentions that the main contributions are not clearly written in the introduction and that supporting material is in the appendix rather than the main sections. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to invest effort to identify and address the issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: forward referencing and the need for clearer explanations of contributions in the introduction. It also points out that material supporting the main contributions is in the appendix rather than the main sections. This feedback is clear and actionable, as it directs the authors to improve the clarity and organization of their paper by ensuring that contributions are properly introduced and explained in the main sections. However, the comment could be more helpful if it provided specific suggestions on how to reorganize the content or what aspects of the contributions need more detailed explanation. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and organization of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, specifically asking for an error bound in terms of epsilon. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address this gap in their explanation. The action is implicit but concrete, as the authors know exactly what information is missing and how to address it by providing an error bound in terms of epsilon. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue is discussed, specifically the mention of rounding core tensors to smaller ranks with a given accuracy. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue of the theoretical effect on the approximation in the full tensor error and asks for an error bound in terms of epsilon. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, specifically asking for an error bound in terms of epsilon. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, particularly regarding the full tensor error. It asks for an error bound in terms of epsilon, which is a clear and actionable suggestion for the authors to address. By prompting the authors to provide this information, the comment offers a constructive way to enhance the theoretical foundation of their work. However, the comment could be more helpful if it provided additional context or examples to guide the authors in understanding the implications of this question. Overall, the comment is mostly helpful as it identifies a gap in the paper and suggests a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. While the comment implies that the authors should provide results for the generative setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the test settings in visual dialog and the results presented in Table 1, and it raises a question about the results on the generative setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer asks for clarification on the results for the generative setting. While the comment raises a valid point about the limitations of the presented results, it lacks specific evidence or references to support the claim that the discriminative setting does not apply to real applications. The authors would need to verify this claim themselves, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. This feedback is clear and actionable, as it highlights a gap in the results presented and prompts the authors to address this issue by providing results for the generative setting. By doing so, the authors can enhance the comprehensiveness and applicability of their findings. However, the comment could be more helpful if it provided additional context or suggestions on how to present the results for the generative setting. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional evidence or examples should be included or how to present them. The comment is explicit in stating that more should be done, but it lacks concrete guidance on how to implement this suggestion. As a result, the action is somewhat actionable, as the authors know they need to provide more convincing evidence but are not given specific instructions on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional evidence, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. This feedback is somewhat helpful as it points out an area where the paper might lack clarity or evidence, prompting the authors to consider how to strengthen their argument. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing additional examples or experiments that could be included. While it provides some direction, it could be more helpful with additional detail or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to evaluate the approach for other language families or what specific steps should be taken to determine its effectiveness. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how to evaluate the approach for other language families. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant gap in the evaluation of the proposed approach, noting that its effectiveness for other language families remains unknown. This is a critical observation that highlights an important area for further exploration and validation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it points out a significant weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have not analyzed the security of their proposed framework, specifically the protection of privacy. This provides a clear and direct action for the authors to take: they should include an analysis of the security aspects of their framework, particularly focusing on privacy protection. The comment is explicit and provides a concrete direction for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: an analysis of the security aspects, particularly the protection of privacy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not analyzed the security (i.e., protection of privacy) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This is a critical area that authors should address to ensure the robustness and reliability of their work. However, the comment does not provide specific suggestions or guidance on how to conduct this analysis or what aspects to focus on. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the form of p should be described near line 135, as it is currently not explicitly stated. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly mentioned. This provides a clear and direct action for the authors to take, which is to clarify the form of p in the manuscript. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the description of the form of p. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly stated. This provides clear guidance on what needs to be clarified in the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the form of p should be described near line 135, as it is currently not explicitly stated. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly mentioned. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the form of p should be described near line 135. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly stated. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and completeness of the manuscript. By addressing this point, the authors can improve the readability and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples on how to describe the form of p. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific guidance on how to achieve this improvement or which works need more detailed descriptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the related works but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not specify which part of the related work section is lacking in clarity or which works need more detailed descriptions. This makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is not grounded as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to illustrate which works are insufficiently described or how their differences could be better explained. Without this additional information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement in the related work section, noting that some works are mentioned but their differences are not described in detail. This feedback is somewhat helpful as it points out a potential weakness in the paper and suggests a direction for enhancement. However, it lacks specificity and actionable guidance on how to improve the descriptions of the related works, such as which aspects should be highlighted or how to differentiate them. To be more helpful, the comment could provide examples or suggestions on how to enhance the related work section. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. This request is explicit and provides clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies the exact information that needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the authors\\' statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. However, it does not specify which part of the paper this statement is made in, making it weakly grounded. The comment is specific in its request for the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It notes that while the point is intriguing, the article does not provide an explicit explanation or understanding of this concept. The reviewer asks for clarification by requesting an explanation of what type of understanding one reaches by looking at PPP maps. However, the comment does not provide any specific reasoning or evidence to support the claim that the explanation is lacking. This makes the claim somewhat verifiable, as it highlights a gap in the paper but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It points out that while the authors mention the importance of these metrics, they do not provide an explicit understanding or explanation of what type of understanding one reaches by looking at PPP maps. This feedback is clear and actionable, as it prompts the authors to clarify and expand their explanation, which could significantly enhance the comprehensibility and impact of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this explanation or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison with other state-of-the-art methods, such as SpanBERT, which could impact the credibility of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include in the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional comparisons but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of comparison with other state-of-the-art methods, specifically mentioning SpanBERT. However, it does not specify which part of the paper this comparison should be included in, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for comparison with SpanBERT, but it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors lack credibility due to not comparing their methods with other state-of-the-art methods, specifically mentioning SpanBERT. However, the comment does not provide any specific examples or detailed reasoning to support why this comparison is necessary or how it would impact the credibility of the paper. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of comparisons with other state-of-the-art methods, specifically mentioning SpanBERT. This feedback is valuable as it highlights an area where the paper could be strengthened by including such comparisons, which would enhance its credibility and relevance. However, the comment does not provide specific suggestions on which methods to compare or how to conduct these comparisons, leaving the authors with a general direction but without detailed guidance. While the feedback is clear about the need for comparison, it could be more helpful with additional details or examples. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion in the paper regarding the discussion of sublinear regret and the proof of achieving T^{1/2} regret. It asks for clarification on whether the prediction error over the entire horizon T cannot be sublinear. This comment explicitly identifies a specific section of the paper (lines 32-37) and poses a question that requires clarification. The action is clear and direct, as it prompts the authors to clarify their statement about sublinear regret. However, the comment does not provide specific guidance on how to address the issue or what additional information might be needed. Therefore, the comment is mostly actionable, as it directs the authors to clarify a specific point but lacks detailed instructions on how to do so.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lines \"32-37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential confusion regarding the discussion of sublinear regret and the proof of achieving T^{1/2} regret. The comment clearly specifies the issue by asking for clarification on whether the prediction error over the entire horizon T cannot be sublinear. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' statement about sublinear regret, suggesting that there might be a misunderstanding regarding the prediction error over the entire horizon T. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the question. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the discussion of sublinear regret and the proof of achieving T^{1/2} regret. It questions whether the prediction error over the entire horizon T cannot be sublinear, which could be a critical misunderstanding in the paper. This feedback is clear and actionable, as it prompts the authors to clarify their statement and potentially revise their proof to ensure consistency. However, the comment could be more helpful if it provided additional context or suggestions on how to address the issue. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the details of the forward-prediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic representation of the forward prediction model. It also notes that it was difficult to connect the text with the figure and equations. This feedback provides a clear and explicit action for the authors to take, which is to redraw Figure 2(b) to improve the clarity of the forward-prediction model. The comment is specific and actionable, as it guides the authors on exactly what needs to be done to enhance the clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that it does not provide a clear schematic representation of the forward prediction model and that it is difficult to connect the text with the figure and equations. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details of the forward-prediction model are not well explained, specifically mentioning that Figure 2(b) does not provide a clear schematic representation. The reviewer suggests that the figure should be redrawn to improve clarity. While the comment identifies a specific issue with the figure, it lacks detailed reasoning or examples to support why the current representation is inadequate. The suggestion to redraw the figure is logical but could be strengthened with more detailed justification or references to similar practices in the field. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the forward-prediction model, noting that Figure 2(b) does not provide a clear schematic representation and that it is difficult to connect the text with the figure and equations. This feedback is clear and actionable, as it suggests that the authors should redraw Figure 2(b) to improve its representation and clarity. By addressing this issue, the authors can enhance the comprehensibility of their work, making the comment highly helpful. However, the comment could be more helpful if it provided additional guidance on how to improve the figure or suggested alternative ways to present the information. Overall, the comment is highly helpful as it directly points out a critical area for improvement and offers a specific action for the authors to take.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for a stronger baseline but are not given concrete steps on how to achieve it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not specify which part of the paper discusses RBI or FP, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this discussion is located, the lack of explicit reference makes the comment weakly grounded. The comment is specific in identifying the issue with the training process and suggesting a potential improvement, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment lacks specific examples or references to support the claim that rewardless actions are ignored, making it somewhat verifiable. The authors would need to further explore and substantiate the claim to fully understand its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve their baseline. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of the term \"multi-scale\" in the context of the slow and fast RNNs, suggesting that the statement is misleading because the RNNs operate on a logical time scale rather than a physical one. The reviewer highlights that the only benefit seems to be the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the terminology, it does not provide explicit guidance on how to address this issue or suggest alternative wording. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the terminology or provide additional context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of the term \"multi-scale\" in the context of the slow and fast RNNs, suggesting that it is misleading because the RNNs operate on a logical time scale rather than a physical one. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the terminology and the potential benefit of the slow RNN, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of the term \"multi-scale\" is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical reasoning by explaining that the RNNs operate on a logical time scale when the stacks are sequentialized in the graph. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"multi-scale,\" which the reviewer suggests is misleading. The reviewer explains that the slow and fast RNNs operate on a logical time scale rather than a physical one, and that the only benefit seems to be the reduction of gradient path by the slow RNN. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their terminology or provide additional context to avoid confusion. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the terminology. Overall, the comment is mostly helpful as it provides valuable insight into a potential misunderstanding in the paper, prompting the authors to consider revising their terminology for clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the baseline methods are weak and not state-of-the-art, and it suggests that the authors should discuss limitations. It also raises questions about the differences between the work and reinforcement learning and suggests discussing similarities and differences in the conclusion. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss limitations and similarities to reinforcement learning. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the baseline methods, noting that they are weak and not state-of-the-art, and suggests discussing limitations. It also raises questions about the differences between the work and reinforcement learning and suggests discussing similarities and differences in the conclusion. However, the comment does not specify which part of the paper discusses the baseline methods or where the discussion of limitations should be included. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a direction for the conclusion, but it lacks detailed guidance on how to address the issues with the baseline methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the baseline methods are weak and not state-of-the-art, and it suggests that the paper lacks a discussion of limitations. The reviewer also raises questions about the differences between the work and reinforcement learning, suggesting a possible direction for the conclusion. However, the comment does not provide specific examples or references to support the claim about the baseline methods being weak, nor does it offer detailed reasoning or evidence for the suggestion regarding the conclusion. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and develop their own justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the baseline methods are weak and not state-of-the-art. It also points out the absence of a discussion on limitations, which is crucial for understanding the work\\'s scope and applicability. Additionally, the comment raises questions about the differences between the work and reinforcement learning, suggesting that the authors discuss similarities and differences in the conclusion. This feedback is clear and actionable, as it provides specific areas for improvement and offers a direction for the authors to enhance their draft. However, it could be more helpful if it included suggestions on how to address the limitations or discuss the differences with reinforcement learning in more detail. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify the distinction between the decision-maker\\'s interest in the true objective function and the noise, which is currently not represented clearly. It implies that the authors should make this distinction clearer upfront, but it does not provide specific guidance on how to achieve this. The action is explicit but somewhat vague, as it lacks detailed instructions on how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to clarify the distinction between the decision-maker\\'s interest in the true objective function and the noise. The comment suggests that the authors should make this distinction clearer upfront, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected performance under observation noise is typically used for evaluation because the decision-maker is interested in the true objective function and the noise is assumed to be noise. It contrasts this with the formulation in the paper, where the decision-maker does care about the noise and the objective function of interest is the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront. While the claim is based on a logical reasoning about the typical evaluation process and the paper\\'s formulation, it lacks specific examples or references to support the assertion fully. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the decision-maker\\'s interest in the true objective function versus the noise. It points out that the typical approach is to evaluate expected performance under observation noise, assuming the noise is misleading and not representative. However, the paper\\'s formulation suggests that the decision-maker does care about the noise, with the objective function of interest being the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront, which is a valuable observation that could help the authors clarify their work. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to present this distinction or examples of how to address it. Overall, the comment is mostly helpful, as it highlights an important area for clarification and improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It suggests that this could help determine whether the benefits are coming from a better generative model or better inference due to doubly-semi implicit variational inference. Additionally, it provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part of the model could help compare representations. While the comment implies an action by questioning the use of VGAE with a vamp prior, it does not explicitly instruct the authors to conduct this experiment or provide detailed guidance on how to implement it. The suggestion about Figure 3 is more explicit but still lacks concrete details on how to execute the proposed comparison. Therefore, the comment is somewhat actionable, as it provides a direction for exploration but lacks detailed instructions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as running VGAE with a vamp prior to better match the doubly stochastic construction and comparing representations by keeping the generative model fixed. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It suggests that this could help determine whether the benefits are coming from a better generative model or better inference due to doubly-semi implicit variational inference. The comment also provides a minor point about Figure 3, suggesting a comparison of representations by keeping the generative model fixed. While the first part of the comment raises a valid question, it lacks specific examples or references to support the claim about the benefits of VGAE with a vamp prior. The second part is more factual, describing a potential comparison method. Therefore, the overall comment is somewhat verifiable, as it provides a logical basis for the suggestion but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the paper by questioning the use of VGAE with a vamp prior to better match the doubly stochastic construction. This could help determine whether the benefits are coming from a better generative model or better inference due to doubly-semi implicit variational inference. Additionally, it offers a minor point about Figure 3, suggesting a comparison of representations by keeping the generative model fixed and optimizing only the inference part of the model. This feedback is clear and actionable, as it guides the authors on potential experiments or analyses that could enhance their work. However, the comment could be more helpful if it provided specific guidance on how to implement these suggestions or detailed examples of similar approaches. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It highlights that the main contribution is a new network design drawing inspiration from prior work for the sound source localization task. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or how to enhance the contribution of the work. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the method, particularly in Table 2, and questions the novelty and contribution of the method. However, it does not specify which part of the paper discusses the performance or contribution, making it weakly grounded. The comment is specific in questioning the novelty and contribution of the method, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method\\'s performance is good, especially in Table 2, but questions the novelty and contribution of the method. The reviewer suggests that the main contribution is a new network design drawing inspiration from prior work for the sound source localization task. However, the comment lacks specific examples or references to support the claim about the method\\'s incremental nature or the prior work that inspired the network design. Without detailed evidence or references, the claim remains somewhat verifiable, as the authors would need to investigate the basis of the critique to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It highlights that the main contribution is a new network design drawing inspiration from prior work for the sound source localization task. While the comment identifies a potential weakness in the novelty of the work, it lacks specific suggestions or guidance on how the authors might enhance the contribution or address the critique. The feedback is somewhat helpful as it points out an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s claim that learning long-range dependencies is crucial for powerful predictors. It points out that while the example of semantic segmentation shows that this is happening, the comment suggests that the requirement might not be as absolute as claimed. The reviewer implies that there could be a middle ground between full dependency and no dependency, and questions whether the paper discusses this aspect. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific discussion points should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the middle ground and its implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of learning long-range dependencies and suggesting that the paper should discuss the middle ground between full dependency and no dependency. Additionally, the comment raises a concern about the impact of image size on prediction, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the necessity of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer provides a logical reasoning by pointing out that while the example of semantic segmentation shows that long-range dependencies are being learned, the claim is not fully substantiated. The comment suggests that there might be a middle ground between full dependency and no dependency, and questions whether the paper discusses this aspect. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that learning long-range dependencies is crucial for powerful predictors. It points out that while the example of semantic segmentation shows that long-range dependencies are being learned, the comment questions whether this requirement is absolute. The reviewer suggests that there might be a middle ground between full dependency and no dependency, and implies that the paper should discuss this aspect. Additionally, the comment raises a concern about the impact of image size on prediction, which could be an important consideration for the authors to address. However, the comment lacks specific suggestions or detailed guidance on how the authors might explore or discuss this issue further. While it highlights an area for potential improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the notation used in Equation (3) and points out the exponential dependence of corollaries and theorems on the domain data\\'s diameter, $M$. It also notes that the performance is worse than expected, suggesting a potential weakness in the proposed approaches. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their work. The authors are left to infer that they need to clarify the notation and potentially investigate the performance issues, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Eq. (3)) and results (Corollaries 1, 2, and 3, Theorem 4), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the domain data\\'s diameter, $M$, and the impact on the required feature size. Additionally, it discusses the performance in Figure 1, which provides further context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the notation in Equation (3) and the exponential dependence of corollaries and theorems on the domain data\\'s diameter, $M$. It also notes that the performance is worse than expected, suggesting a potential weakness in the proposed approaches. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim about the exponential dependence and its impact on performance. The mention of Figure 1 provides some context but does not fully support the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several points that could be helpful for the authors to address. It questions the notation used in Equation (3), which could help clarify the terminology in the paper. Additionally, it points out the exponential dependence of corollaries and theorems on the domain data\\'s diameter, $M$, which is a critical observation that could impact the required feature size. The comment also notes that the performance is worse than expected, suggesting a potential weakness in the proposed approaches. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it identifies areas for improvement, it does not provide detailed actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The mention of a specific paper provides some context but does not offer actionable steps for the authors. As a result, the comment is vague and lacks concrete details on how to implement any changes, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the long-range modelling ability of DGNs, attributing the issue to oversquashing and vanishing/exploding gradients. It also mentions oversmoothing as a potential factor, referencing a specific paper for context. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The mention of a specific paper provides some specificity, as it suggests a potential direction for further exploration. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modelling ability of DGNs could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The reviewer supports this claim by referencing a specific paper, \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning, In AAAI'18,\" which provides a logical basis for the claim. This reference adds credibility to the argument, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper, which would align with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance, referencing a specific paper for context. This feedback is somewhat helpful as it points out a specific area of concern and provides a reference for further exploration. However, the comment lacks detailed guidance or suggestions on how the authors might address these issues or improve their draft. To be more helpful, it could include specific recommendations or examples of how to mitigate the effects of oversquashing, vanishing/exploding gradients, or oversmoothing. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also inquires about the occurrence of gradients becoming 0 and collapsing, as mentioned in line 159. While the comment implies that the authors should address these points, it does not explicitly instruct them to include specific demonstrations or results. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the demonstration or results related to the model collapsing less than other methods, and it seeks clarification on whether this phenomenon is commonly encountered and observed in the experiments. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the demonstration or results related to the model collapsing less than other methods. It references a specific line in the paper (line 159) where the authors mention gradients becoming 0 and collapsing, and asks whether this is a commonly encountered issue and if it was observed in the experiments. This feedback is somewhat helpful as it prompts the authors to clarify or expand on this aspect of their work, potentially leading to a more comprehensive understanding of their model\\'s behavior. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on potential experiments to conduct. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any explicit or implicit guidance on how to clarify the problem formulation or what specific aspects are unclear. Without additional details or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, nor does it provide details on what aspects need clarification. This lack of specificity and lack of explicit references to sections or examples make it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples of what needs to be clarified, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment barely helpful, as it points out a problem but does not offer a path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\\'s applicability and generalizability. This feedback is clear and provides a concrete action for the authors to take, which is to conduct additional experiments. The suggestion is specific and actionable, as it outlines exactly what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\\'s applicability and generalizability. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\\'s applicability and generalizability. The claim is based on a logical reasoning that additional experiments could enhance the understanding of the method\\'s applicability across various LLM families. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of these experiments and their potential impact on the paper\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the experimental scope of the paper. By conducting additional experiments with various LLM families, the authors can gain valuable insights into the method\\'s applicability and generalizability, which could enhance the paper\\'s contribution and impact. However, the comment could be more helpful if it offered guidance on how to design these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation, whether it should be clarified, or if it should be expanded to include other types of models. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not specify which part of the paper this claim is based on, such as a particular section, experiment, or methodology. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. While this observation highlights a potential limitation of the method, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this limitation or expand the applicability of their method. As a result, the comment is not particularly helpful for the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. The reviewer suggests that the connection between these two parts is weak and that the initial expectation of the first part was not met. However, the comment does not provide explicit guidance or suggestions on how the authors might strengthen the connection or address the perceived disconnect. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it difficult for the authors to pinpoint the exact areas needing revision. The comment provides some specific feedback about the expectations of the first part and the actual content, but it lacks detailed guidance on how to address the perceived disconnect. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the connection between the curve finding (the first part) and FGE (the second part) is weak. However, the comment does not provide any specific examples, reasoning, or references to support this claim. It also lacks detailed explanation or evidence to justify why the connection is weak or how it could be strengthened. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. It suggests that the initial expectation of the first part was not met, as the reviewer had imagined a different approach. However, the comment does not provide specific guidance or suggestions on how the authors might address this disconnect or improve the clarity of the paper. While it highlights an area for improvement, the feedback lacks actionable details, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the results for linear scalarization with Concorde, a heuristic-based solver, for a better comparison. This is an explicit action with concrete details on how to implement it, as it specifies the exact method and comparison to be included. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the need to include the results for linear scalarization with Concorde for a better comparison. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the learning-based solvers are better than the heuristic-based solvers, except for the single objective TSP where the SOTA heuristic-solver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison. The claim is somewhat verifiable as it is based on the experimental results presented in the paper, but it lacks specific references or detailed reasoning to fully substantiate the claim. The suggestion to include additional results is logical, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the learning-based solvers are generally better than the heuristic-based solvers, except for the single objective TSP where the SOTA heuristic-solver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison, which is a clear and actionable piece of feedback. This guidance helps the authors enhance the comprehensiveness and validity of their experimental analysis, making the comment mostly helpful. However, the comment could be more helpful if it provided additional context or explanation on why this comparison is important or how it might impact the overall conclusions. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the proposed method in relation to existing methods that capture similar general ideas, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. While the comment implies that the authors should make these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to make these comparisons or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and the \"general ideas\" that are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, discussing the proposed method in relation to these existing methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. The reviewer provides a detailed explanation of how these existing methods capture similar ideas, such as reasoning topologically and long-term storage through pose graphs. This reasoning is supported by references to specific methods and concepts, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from these existing approaches. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas proposed are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could provide a more comprehensive understanding of its novelty and contribution. This feedback is clear and actionable, as it directs the authors to consider how their work fits within the existing literature and to highlight its unique aspects. However, the comment could be more helpful if it provided specific examples or references to guide the authors in making these comparisons. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests moving some details from the appendix back into the main text and moving some background from Section 2 to the appendix instead. This feedback is explicit and provides a clear action for the authors to take, offering a concrete suggestion on how to improve the organization and clarity of the paper. The authors know exactly what changes to make to enhance the readability and interpretability of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of moving experimental setup, tasks, and other details to the appendix, which makes it hard to interpret the paper. It suggests moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the appendix and possibly Section 2. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit references to sections makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that moving experimental setup, tasks, and other details to the appendix makes it hard to interpret the paper. The reviewer suggests moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. However, the comment does not provide specific examples or detailed reasoning to support why this change would improve interpretability. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the paper, noting that moving experimental setup, tasks, and other details to the appendix makes it hard to interpret the paper. It suggests a solution by recommending moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the readability and accessibility of their work. However, the comment could be more helpful if it explained why this change would benefit the paper or if it offered additional suggestions for enhancing the clarity of the experimental setup. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide glosses in Figure 2. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete instruction on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding glosses to Figure 2, which provides full grounding as it explicitly mentions a specific figure in the paper. However, it lacks specificity because it does not detail what the glosses should include or how they would enhance the figure. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that providing glosses in Figure 2 would be helpful. However, it does not provide any reasoning, examples, or references to support why glosses are necessary or how they would enhance the figure. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide glosses in Figure 2. While this feedback is clear and actionable, it lacks depth and does not explain why glosses are necessary or how they would enhance the figure. The comment provides a specific suggestion for improvement but could be more helpful if it included additional context or rationale. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that \"Memb\" is apparently the previous state-of-the-art but lacks a reference. This implies that the authors should include a reference to support this claim. However, the comment does not explicitly instruct the authors to do so, leaving it as an implicit action. Additionally, it does not provide specific guidance on which reference to include or how to integrate it into the text. The action is inferred and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"Memb,\" implying that it is a previous state-of-the-art method. However, it does not specify which part of the paper this claim pertains to, such as a section or a discussion of related work. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the lack of a reference for \"Memb,\" but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"Memb\" is the previous state-of-the-art but lacks a reference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the paper, noting that \"Memb\" is apparently the previous state-of-the-art but lacks a reference. This feedback is somewhat helpful as it highlights a potential gap in the paper, suggesting that the authors should include a reference to support their claim about \"Memb.\" However, the comment does not provide detailed guidance on how to integrate this reference or why it is important, leaving the authors with a general direction but without comprehensive actionable steps. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why the authors did not consider finer grouping for quantization instead of per-tensor and per-channel. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or what specific actions they should take. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of quantization grouping, specifically asking why finer grouping was not considered instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where quantization is discussed. Without explicit references to the paper, the authors may find it challenging to determine the exact context of the comment. The comment is specific in its question about the choice of quantization grouping but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking why the authors did not consider finer grouping for quantization instead of per-tensor and per-channel. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization grouping, specifically asking why finer grouping was not considered instead of per-tensor and per-channel. While it identifies a potential area for improvement, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights into why finer grouping might be beneficial or how it could be implemented. As a result, the comment is barely helpful, as it points out a potential area for improvement but does not provide enough detail or direction for the authors to effectively address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. This comment explicitly states an action for the authors to take, which is to investigate the impact of the ratio of unseen classes. The suggestion is clear and provides a concrete example of what the authors should explore, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting a particular aspect to explore, but it lacks grounding because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes, providing an example of how performance varies with different ratios of unseen classes. This suggestion is based on logical reasoning, as it proposes an additional aspect of the study that could provide valuable insights. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the potential benefits of this analysis and how it could impact their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an additional aspect of the study that could be explored, specifically the impact of the ratio of unseen classes on performance. It provides a concrete example of how the performance varies with different ratios of unseen classes, which is a valuable suggestion for the authors to consider. This feedback is clear and actionable, offering a specific direction for the authors to enhance their work. However, it could be more helpful if it included additional context or examples of how this analysis might be conducted. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential area of interest, it does not provide explicit guidance or suggestions for the authors to address this question or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they might need to provide a rationale or justification for their architectural choices. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. However, it does not specify which part of the paper discusses these architectural choices, making it weakly grounded. The comment is specific in its inquiry about the rationale behind the architectural choices, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the choice of using GRU for the Pyramid and LSTM for the sequential part. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential area of interest, it does not provide specific guidance or suggestions on how the authors might address this question or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for improvement. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the definition of \"active vertices\" in the context of line 135. While it does not explicitly instruct the authors to clarify the definition, it implies that they should provide a clear explanation of this term. The action is implicit but concrete, as the authors can infer that they need to clarify the definition of \"active vertices\" in their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices,\" providing a clear direction for the authors to clarify this term. Therefore, this comment is labeled as fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the definition of \"active vertices\" in the context of line 135. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition of \"active vertices\" in the context of line 135, which is a specific and relevant point that could help clarify the paper. By asking for clarification, the reviewer prompts the authors to provide a clear definition of this term, which could enhance the understanding of the paper for readers. However, the comment does not offer any suggestions or guidance on how to address this issue or improve the clarity of the paper. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of mention of the inapplicability of the theory to the used model in the limitations section and the vague nature of the structural assumptions given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the limitations and provide more detailed information on the structural assumptions, as well as consider the societal impact of graph neural networks. However, the lack of concrete guidance on how to implement these changes makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the inapplicability of the theory to the used model, the vagueness of the structural assumptions given in the appendix, and the need for more elaboration on potential negative societal impacts of graph neural networks. This provides clear guidance on what needs to be addressed in the limitations section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not mention the inapplicability of its theory to the used model in the limitations section, which is a subjective opinion. The reviewer also suggests that the structural assumptions are vague and not clearly stated, which could be a valid observation. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The suggestion to provide more elaboration on potential negative societal impacts of graph neural networks is a logical request but again lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper, identifying several areas for improvement. It points out that the theory's applicability to the used model is not mentioned in the limitations section, which is a significant oversight. The comment also highlights the vagueness of the structural assumptions given in the appendix, making it difficult for readers to understand the limitations. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. This feedback is clear and actionable, offering specific areas for the authors to address and improve their draft. However, it could be more helpful if it included suggestions on how to clarify the structural assumptions or address the societal impact concerns. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"For training we used an epsilon-greedy ...\" and asks for clarification regarding the use of epsilon-greedy exploration in addition to the proposed strategy. While the comment does not explicitly instruct the authors to clarify this point, it implies that they should provide additional explanation or clarification. The action is implicit but clear, as the authors can infer that they need to address the confusion regarding the use of epsilon-greedy exploration. However, the comment lacks specific guidance on how to clarify this point, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilon-greedy ...\" and asks for clarification regarding the use of epsilon-greedy exploration in addition to the proposed strategy. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the meaning of \"For training we used an epsilon-greedy ...\" and whether it refers to an additional exploration strategy. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"For training we used an epsilon-greedy ...\" and asks for clarification regarding the use of epsilon-greedy exploration in addition to the proposed strategy. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper and prompts the authors to clarify their methodology. However, the comment does not provide specific guidance on how to address this issue or suggest ways to improve the clarity of the explanation. While it points out a specific area needing clarification, it lacks depth and actionable advice, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the critique, improve the method, or provide additional context or justification. As a result, the comment lacks actionability and does not offer any direction for the authors to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment provides some insight into the method\\'s novelty, it lacks specificity in terms of what aspects need improvement or clarification. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. The comment suggests that this approach lacks novelty, but it does not provide specific examples or references to support this claim. The reasoning is somewhat vague, as it does not elaborate on why the combination of GCN and normalizing flow is not innovative or how the use of a Gaussian mixture distribution impacts the method\\'s novelty. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claim but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. It suggests that this approach lacks novelty, but it does not provide specific feedback or suggestions on how the authors could improve their work or address the critique. The comment lacks actionable guidance or detailed analysis, leaving the authors without a clear understanding of what aspects need improvement or how to enhance the novelty of their method. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the impact of the projection head (CNN layers) and the classification head (FCN layer). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what changes, if any, should be made to improve the draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"projection head (CNN layers)\" and the \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular observation about the impact of these heads, which provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the impact of the projection head (CNN layers) and the classification head (FCN layer). It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a specific observation regarding the impact of the projection head (CNN layers) and the classification head (FCN layers). It notes that only the projection head is affected, while the classification head remains unchanged. However, the comment does not provide any context, explanation, or suggestions for why this observation is relevant or how it might impact the paper. Without additional information or guidance, the authors are left without a clear understanding of the significance of this observation or how to address it. As a result, the comment is not helpful at all, as it lacks actionable feedback or insight that could assist the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the framework need further discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a discussion on the importance of different parts of the framework. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not specify which part of the paper it addresses, making it weakly grounded. The authors can infer that it relates to the discussion section, but this inference is not explicit. The comment is specific in suggesting that a discussion on the importance of different parts of the framework is needed, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide any specific reasoning, examples, or references to support the claim that a discussion is needed or how it would distinguish the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or detailed feedback on what aspects of the framework should be discussed or how to distinguish the paper from related work. As a result, the comment is somewhat helpful, as it points out a gap in the discussion but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analogy between HOI analysis and Harmonic analysis is interesting but weak, noting that the problem contexts have only two \"basis\" (human and object) to form an HOI, and the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance or suggestions on how the authors might strengthen the link or improve the analogy. The action is implicit and vague, as the authors are left to infer what changes might be necessary without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the analogy between HOI analysis and Harmonic analysis, specifically critiquing the weak link between the two. It mentions the problem context, which has only two \"basis\" (human and object) to form an HOI, and the lack of a close connection with Fourier analysis as claimed. However, the comment does not specify which part of the paper discusses this analogy, making it weakly grounded. The comment is specific in detailing the issue with the analogy, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, noting that the problem contexts have only two \"basis\" (human and object) to form an HOI, and the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. The comment provides a logical reasoning by pointing out the limited basis and lack of connection with Fourier analysis, which helps support the claim. However, it could be strengthened by providing specific examples or references to illustrate the disconnect more clearly. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the analogy between HOI analysis and Harmonic analysis. It points out that the link between the two is weak, noting that the problem contexts have only two \"basis\" (human and object) to form an HOI, and the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. This feedback is somewhat helpful as it highlights an area where the paper may need further development or clarification. However, the comment lacks specific suggestions or guidance on how the authors might strengthen the analogy or improve the connection. To be more helpful, the comment could include actionable advice or examples of how to enhance the link between the two analyses. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, while most existing ML accelerators use bit-parallel fixed-point numbers. This implies that the proposed methodology might be limited in its applicability. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or explore alternative applications. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning its applicability to bit-serial accelerators. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the potential restriction due to the use of bit-parallel fixed-point numbers in most existing ML accelerators. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, while most existing ML accelerators use bit-parallel fixed-point numbers. This claim is somewhat verifiable as it provides a logical reasoning based on the current state of ML accelerators, suggesting a potential limitation of the proposed methodology. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, specifically noting that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators. It also points out that most existing ML accelerators use bit-parallel fixed-point numbers, which could restrict the implications of the proposed methodology. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative applications. The feedback is somewhat helpful as it prompts the authors to consider the broader applicability of their work, but it could be more actionable with additional insights or recommendations. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalization of the model to focusing distances not present in the training data. It explicitly asks for an explanation of how the model performs on these distances and suggests that the authors should address this issue. The comment provides a clear and direct action for the authors to take, which is to investigate and report on the model\\'s performance on focusing distances not present in the training data. This feedback is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalization of the model to focusing distances not present in the training data, and it asks for an explanation of how the model performs on these distances. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalization of the model to focusing distances not present in the training data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the generalization of the model to focusing distances not present in the training data. It points out a potential limitation in the experimental setup, which could impact the model\\'s performance and applicability. By asking for an explanation of how the model performs on these distances, the comment prompts the authors to consider and address a critical aspect of their work. This feedback is clear and actionable, providing the authors with a specific area to investigate and improve upon. However, it could be more helpful if it suggested ways to address this issue or provided guidance on how to evaluate the model\\'s generalization. Overall, the comment is mostly helpful as it directs the authors\\' attention to an important aspect of their work that requires further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instance-specific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment implies that the authors should clarify these concepts, it does not provide explicit instructions on how to define or clarify them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take, such as defining terms or providing additional context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instance-specific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of content and style in the context of their neural application. The comment is specific in its request for clarification on the definition of style and content, but it lacks full grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instance-specific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the reference to Gabbay & Hosehn (2018) provides some context, the comment lacks detailed explanation or examples from the authors' work to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a starting point for the authors to consider but requires further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instance-specific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. This feedback is somewhat helpful as it prompts the authors to clarify their terminology and provides a reference for considering broader definitions. However, the comment could be more helpful if it offered specific suggestions on how to define or clarify these concepts within the context of the paper. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It also points out the large loss of precision introduced by the quantization of MHSA, which has been observed in transformer quantization in NLP. The comment highlights specific examples and references to support its claims, providing concrete evidence for the authors to consider. However, while it identifies issues, it does not explicitly instruct the authors on how to address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors can infer that they need to provide a more detailed explanation or address the issues raised, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed critiques and examples, such as the comparison of quantization methods in Line 45 and the figures (1(b) and 5(b)) for Block.3, as well as references to transformer quantization in NLP. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two main claims: (1) that the analysis of vit quantification could be explained in more depth, specifically regarding the information distortion caused by direct quantization methods, and (2) that the quantization of MHSA introduces a large loss of precision, which has been observed in transformer quantization in NLP. The first claim is supported by a specific example from the paper (Line 45) and a comparison of figures (1(b) and 5(b) for Block.3), providing a clear basis for the critique. The second claim is supported by references to transformer quantization in NLP, such as Q-BERT, Q8BERT, BinaryBERT, and FullyBinaryBert, which are well-known works in the field. This provides a solid foundation for the claim, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It supports this claim with specific examples from the paper, such as the comparison of figures 1(b) and 5(b) for Block.3, and references to transformer quantization in NLP. This level of detail is valuable as it helps the authors understand the specific issues with their analysis and provides a clear basis for improvement. However, while the comment identifies weaknesses, it does not offer specific suggestions or guidance on how to address these issues or improve the analysis. Therefore, the comment is mostly helpful, as it provides clear insights but lacks actionable advice, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a main weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed X-transformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. Additionally, it points out the lack of empirical or conceptual comparisons to STN, which is considered important. While the comment identifies the issue and provides some context, it does not explicitly instruct the authors on how to address these concerns or improve the draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the technical novelty and include comparisons to STN. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"spatial transformer networks (STN)\" and \"X-transformation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the absence of comparisons to STN, which are important aspects of the work. The comment provides specific examples of existing works that apply STN in a local pixel neighborhood and mentions PointNet\\'s use of a variant of STN. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited due to its similarity to existing work, specifically spatial transformer networks (STN). It provides specific examples of existing works that apply STN in a local pixel neighborhood and mentions PointNet\\'s use of a variant of STN. This detailed comparison and reference to existing literature provide a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed comparisons or references to specific aspects of the proposed X-transformation that are similar to STN. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed X-transformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. The comment also notes the absence of empirical or conceptual comparisons to STN, which is considered important. This feedback is clear and actionable, as it directs the authors to address the lack of novelty and comparisons, which are crucial for the paper\\'s impact. However, it could be more helpful if it provided specific suggestions on how to enhance the novelty or conduct comparisons. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by highlighting critical areas for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment consists of two separate points. The first point suggests that the authors should clarify their notation by mentioning that |Y_t - Y_{t-1}| \\leq c_t is meant to be almost surely. This is an explicit suggestion that provides clear guidance on how to improve the draft. The second point is also explicit, suggesting that \\mu_t should be \\tilde \\mu_t. Both points are concrete and provide direct actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L384 and L431) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvements, such as clarifying the notation and correcting a typographical error. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims: the first suggests clarifying notation, and the second points out a typographical error. Neither claim requires verification as they are factual statements or suggestions for improvement. The comment does not present opinions, judgments, or subjective claims that need to be substantiated. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out two areas where the authors can improve their draft. At line 384, it suggests clarifying the notation by mentioning that |Y_t - Y_{t-1}| \\leq c_t is meant to be almost surely. This is a clear and direct suggestion that can help the authors avoid potential confusion among readers. Additionally, the comment corrects a typographical error at line 431, suggesting that \\mu_t should be \\tilde \\mu_t. These specific suggestions are valuable for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it explained why these corrections are important or how they impact the paper\\'s content. Overall, the feedback is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the confusion regarding Eq. 12 and suggests that explaining the network model in Section 4.2 with equations would improve clarity. It also provides three references that could be useful for further clarification. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to implement these suggestions or what specific aspects of the network model should be explained. The authors are given a clear direction but lack concrete steps on how to execute the changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the source of the reward in Eq. 12 and suggesting that explaining the network model with equations would improve clarity. The comment provides specific references to external works that could be useful for further clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Eq. 12 is confusing and suggests that explaining the network model in Section 4.2 with equations would improve clarity. The comment provides three references, which could be used to support the claim that the current explanation is insufficient. However, the references are not directly integrated into the reasoning, making the claim somewhat verifiable. The authors would need to explore the references to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Eq. 12, questioning the source of the reward and suggesting that explaining the network model in Section 4.2 with equations would improve clarity. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology. The inclusion of references to related works further supports the suggestion, providing additional context and potential solutions. However, the comment could be more helpful if it offered specific guidance on how to explain the network model or which aspects of Eq. 12 need clarification. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is explicit and actionable, as it clearly instructs the authors to correct the figure reference. The second part is also explicit and actionable, as it provides a specific action for the authors to take to improve the paper\\'s readability. However, the comment does not provide detailed guidance on how to link the theorems and corollaries to their proofs, which could be more concrete. Overall, the comment is mostly actionable, as it provides clear actions but could be more detailed in some aspects.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a typographical error (\"Fig.7\" should be \"Fig.12\") and suggests linking theorems and corollaries to their corresponding proofs to improve readability. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is factual and does not contain a claim, while the second part is a suggestion for improvement. The suggestion is logical and straightforward, aiming to enhance the paper\\'s readability. However, it lacks specific examples or references to support the claim that this improvement is necessary or beneficial. Therefore, the comment is mostly verifiable, as it provides a clear suggestion but lacks detailed justification or evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two specific pieces of feedback. First, it corrects a typographical error by pointing out that \"Fig.7\" should be \"Fig.12\" in a specific row of the supplementary material. This is a clear and actionable suggestion that helps the authors improve the accuracy of their paper. Second, it suggests linking theorems and corollaries to their corresponding proofs, which would enhance the paper\\'s readability and make it easier for readers to follow the logical flow. This is a constructive and actionable piece of feedback that could significantly improve the paper\\'s clarity. However, the comment does not address broader issues or provide suggestions for improving the paper\\'s motivation, methodology, or experimental results, which would make it more comprehensive. Overall, the comment is mostly helpful as it offers specific and actionable feedback, but it could be more comprehensive to fully support the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the absence of a determiner in the definition at line 248 and questions about the selection of action verbs, classes, and action frames. While the comment highlights specific areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors can infer that they need to clarify these points but are not given concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (248 and 306ff) and terms (\"action verbs,\" \"50 classes,\" and \"action frames\") that allow the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the missing determiner in the definition, the selection of action verbs and classes, and the explanation of \"action frames.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and observations, such as the absence of a determiner in the definition at line 248 and inquiries about the selection of action verbs, classes, and action frames. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several specific areas where the paper lacks clarity or needs further explanation. It points out the absence of a determiner in the definition at line 248, questions the selection of action verbs and classes, and seeks clarification on the concept of \"action frames.\" These questions and observations are clear and actionable, as they guide the authors to address specific gaps in their draft. However, the comment could be more helpful if it provided suggestions on how to clarify these points or offered examples of how to improve the explanations. Overall, the feedback is mostly helpful as it directs the authors to areas that need further elaboration, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a minor typographical error, specifically correcting the spelling of \"Empiically\" to \"Empirically\" on line 32 of page 1. This feedback is explicit and provides a clear action for the authors to take, ensuring the accuracy of the manuscript. The comment is concrete because it specifies the exact line and page where the correction is needed, making it highly actionable. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and actionable correction for the spelling of \"Empiically\" to \"Empirically.\" This level of detail guides the authors on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual correction regarding the spelling of \"Empiically\" on line 32 of page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor typographical error, specifically correcting the spelling of \"Empiically\" to \"Empirically\" on line 32 of page 1. While this feedback is accurate and actionable, it does not provide any broader context or suggestions for improvement beyond correcting the spelling. The comment is limited in scope and does not offer insights into the paper's content or structure, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed invariant learning module, specifically regarding the focus on mask selection and raw-level features. It points out that the framework discussed in Section 4.2 is not limited to raw-level selection and suggests that representation learning could be considered for further improvement. However, the comment does not provide explicit guidance on how to incorporate representation learning or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the proposed invariant learning module, focusing on mask selection and raw-level features, and suggests that representation learning could be considered for further improvement. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed invariant learning module focuses on mask selection and raw-level features, and suggests that the framework discussed in Section 4.2 is not limited to raw-level selection. It also mentions a discussion about representation learning in the appendix. However, the comment lacks specific examples or detailed reasoning to support the claim that representation learning could be further improved. While it identifies potential areas for improvement, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed invariant learning module, noting that it focuses on mask selection and raw-level features. It points out that the framework discussed in Section 4.2 is not limited to raw-level selection and suggests that representation learning could be considered for further improvement. This feedback is clear and actionable, as it highlights a potential area for enhancement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered specific suggestions or examples on how to incorporate representation learning into the feature selection process. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some details are missing, specifically mentioning the design of rewards. However, it does not provide explicit guidance on what details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors uncertain about how to improve their draft. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions that \"some details are missing,\" specifically regarding the design of rewards. However, it does not specify which part of the paper this pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing detail about the design of rewards, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some details are missing,\" specifically mentioning the design of rewards. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand which details are missing or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper lacks detail, namely the design of rewards. This is a clear and actionable piece of feedback that can guide the authors in improving their draft by providing more information on this critical aspect. However, the comment could be more helpful if it offered suggestions on what specific details should be included or how the authors might approach the design of rewards. Despite this, the feedback is still somewhat helpful as it directs the authors to a specific area needing attention. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of entities is fixed and questions how to generalize the model to different numbers of entities, as shown in figure 3 of INs. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should explore ways to generalize the model, but it is not concrete, as there is no specific direction on how to achieve this generalization. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the number of entities being fixed and the generalization of the model, as shown in figure 3 of INs. This provides full grounding as it explicitly mentions a figure and a reference to external work (INs), allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of generalization and the need for flexibility in the number of entities. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the generalizability of the model due to the fixed number of entities, as illustrated in Figure 3 of INs. This claim is somewhat verifiable as it highlights a potential limitation in the model\\'s design, but it lacks specific examples or references to support the assertion. The mention of INs provides some context, but without detailed explanation or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the model\\'s design, specifically the fixed number of entities, which may hinder its generalizability. It raises a valid concern about the model\\'s applicability to different scenarios, as shown in figure 3 of INs. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore ways to generalize the model. While it points out a critical area for improvement, the feedback could be more actionable and helpful by offering potential solutions or directions for further exploration. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the incremental nature of the improvement over K-NN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also highlights the good experimental design. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived weakness or improve the paper, nor are there suggestions for enhancing the novelty or experimental design. As a result, the authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the incremental nature of the improvement over K-NN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the good experimental design. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section being addressed. Additionally, while it provides some insight into the perceived weaknesses, it lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work is an incremental improvement over K-NN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the good experimental design. However, the comment lacks specific examples or references to support the claim of incremental improvement or the lack of novelty. Without detailed evidence or comparisons to other works, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 3: Somewhat Verifiable, as it provides some justification but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the incremental nature of the improvement over K-NN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the good experimental design. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not offer guidance on how the authors might enhance the novelty or experimental design to address the perceived weakness. As a result, the comment is not helpful at all, as it does not provide the authors with any direction for improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to discuss the runtime or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its suggestion to address the runtime as a limitation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selling point of ML-based emulators is their computational cheapness, and it suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count. The comment provides a logical reasoning for why the runtime is important, as it could be a limitation for applications requiring computational cheapness. However, it lacks specific examples or references to support the claim about the large parameter count or the potential impact on runtime. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the point.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the Prithvi WxC model, specifically its large parameter count, which could impact its computational cheapness. It suggests that the authors should discuss the runtime of Prithvi WxC as a limitation for applications that require computational efficiency. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for the authors to address in their draft. However, it could be more helpful if it offered suggestions on how to discuss or mitigate the runtime issue. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing their draft by addressing a critical aspect of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to enhance the novelty or improve the straightforwardness of the metric and method. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the idea and mentions the limitations of the new metric and method, but it does not specify which part of the paper these issues are discussed in. The authors cannot confidently determine which sections or aspects of the paper are being referred to, making the comment weakly grounded. Additionally, while it points out the limitations of the new metric and method, it does not provide specific guidance on how to address these issues or improve the novelty. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a perceived lack of novelty in the idea presented, noting that both the new metric and method are relatively straightforward. However, it does not provide specific examples or detailed feedback on how the authors could enhance the novelty or complexity of their approach. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to implement the feedback. As a result, the action is vague and not actionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not specify which part of the paper is being referred to, such as a particular section, figure, or table, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the framing are considered overselling or how to address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper may be overselling its method, which could make the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific examples or details on how the method is being oversold or what aspects of the contribution are unclear. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of what needs to be addressed. This lack of specificity and guidance makes the comment barely helpful, as it does not offer meaningful direction for enhancing the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps and by using a notation table. While it implies that these changes would enhance understanding, the comment does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to restructure the model description and consider adding a notation table, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning the need for better presentation of the generative process in separate steps and the use of a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where the model description is presented. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing revision. The comment is specific in suggesting improvements to the model description, but without clear grounding, it aligns with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and by using a notation table. However, it does not provide specific examples or detailed reasoning to support why these changes would enhance understanding or improve the model description. The comment lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be better understood if presented in separate steps. It also mentions the use of too many symbols and the potential benefit of a notation table. While the comment highlights a potential issue and offers a suggestion for improvement, it lacks detailed guidance or examples on how to implement these changes. The feedback is somewhat helpful as it points out a specific area for enhancement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It suggests that this could impact the subsequent steps, as the model relies on the quality of these paraphrases. The comment implies that the authors should ensure the paraphrases are sufficiently different from the original sentences to maintain the quality of the training data. However, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of paraphrase quality but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the generation of paraphrases for the training data, questioning the difference between the paraphrases and the original sentences. It highlights the impact of this on the subsequent steps, particularly the quality of the final training data. However, the comment does not explicitly mention which part of the paper discusses this process, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in detailing the issue with the paraphrases and their impact on the training data, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases used in the training data, suggesting that the difference between the paraphrases and the original sentences is unclear. It argues that this could impact the subsequent steps, as the model relies on the quality of these paraphrases. The comment provides a logical reasoning by explaining how the quality of the paraphrases affects the training data and, consequently, the model's performance. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It highlights the potential impact of this on the subsequent steps, as the model relies on the quality of these paraphrases. The comment provides a clear and actionable suggestion by pointing out that if the difference is not large enough, the quality of the final training data will be low, which could affect the overall performance of the model. This feedback is valuable as it directs the authors to address a specific aspect of their methodology that could significantly impact the effectiveness of their work. However, the comment could be more helpful if it offered specific guidance on how to ensure the quality of the paraphrases or provided examples of what constitutes a sufficient difference. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that identifying rationales is a complex task, particularly for more complicated NLP tasks like machine translation. It commends the paper for its organization and ease of following, but notes that Figure 2 is cluttered and the \"bold\" text is hard to see. The reviewer suggests using another color or a bigger font to improve the visibility of the human-identified rationales. While the comment provides a specific suggestion for improving the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the figure\\'s clarity. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is cluttered and the \"bold\" text is hard to see, suggesting improvements like using another color or a bigger font to enhance the visibility of the human-identified rationales. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that identifying rationales is a complex task, particularly for more complicated NLP tasks like machine translation. It commends the paper for its organization and ease of following, but notes that Figure 2 is cluttered and the \"bold\" text is hard to see. The suggestion to use another color or a bigger font to improve the visibility of the human-identified rationales is logical and provides a clear direction for improvement. However, the comment lacks specific examples or references to support the claim about the complexity of identifying rationales in machine translation. While the suggestion is reasonable, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the complexity of identifying rationales, particularly for more complicated NLP tasks like machine translation. It commends the paper for its organization and ease of following, but points out that Figure 2 is cluttered and the \"bold\" text is hard to see. The reviewer provides a specific suggestion to improve the figure by using another color or a bigger font to enhance the visibility of the human-identified rationales. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and effectiveness of their presentation. However, the comment could be more helpful if it also addressed the complexity of identifying rationales or provided additional suggestions for improving the paper\\'s content. Overall, the comment is mostly helpful as it offers constructive feedback on a specific aspect of the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework beyond LLM-based models, such as HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or evaluations, it does not provide specific guidance on how to implement this verification or what specific tests to perform. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the Flipped-QA framework should be further verified for its effectiveness and universality beyond LLM-based models, specifically mentioning HiTeA and InternVideo. However, it does not specify which part of the paper discusses the application of Flipped-QA to LLM-based models, making it weakly grounded. The comment is specific in suggesting the need for further verification and mentions specific models, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Flipped-QA framework should be further verified for its effectiveness and universality beyond LLM-based models, specifically mentioning HiTeA and InternVideo. The comment provides a logical reasoning by suggesting that the framework should be tested on non-LLM-based models to establish its universality. However, it lacks specific examples or references to support the claim that HiTeA and InternVideo are relevant models for testing. This makes the claim somewhat verifiable, as it provides a direction for further testing but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by suggesting that the Flipped-QA framework should be further verified for its effectiveness and universality beyond LLM-based models. It specifically mentions HiTeA and InternVideo as examples of non-LLM-based models that could be tested. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to include a broader range of models. However, the comment could be more helpful if it offered guidance on how to conduct these additional tests or what specific aspects of the framework should be evaluated. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The action is implicit and vague, as the authors are left without clear direction on how to enhance the clarity of their writing. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not specify which parts of the paper are particularly challenging or what aspects of the writing need improvement. Without explicit references to sections, figures, or specific issues, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what improvements are needed, such as clarity, organization, or coherence. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear or confusing, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it lacks specificity and does not provide actionable feedback or suggestions on how to improve the writing. Without detailed guidance or examples of what aspects need improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or enhance the theoretical novelty of their work. The action is implicit and vague, as the authors are left to infer what changes might be necessary without concrete direction. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and its reliance on existing methods, such as Clopper-Pearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the lack of theoretical novelty and suggests that the authors address this concern to improve the reviewer\\'s score. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer supports this claim by referencing specific existing methods, such as Clopper-Pearson intervals and Gaussian elimination, which are cited in the text. This provides a clear basis for the claim, making it fully verifiable. The inclusion of references to these methods allows the authors to understand the basis of the critique and potentially address it in their response. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This feedback is somewhat helpful as it points out an area where the authors might need to enhance their work to differentiate it from existing approaches. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the theoretical novelty of their method. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability, as the authors are not given any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not provide any context or details about the issue being raised. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the text input can be concatenated by the four text elements of an object. While it highlights a potential area of confusion or misunderstanding, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or clarify the text input process. As a result, the comment is not helpful at all, as it does not offer any constructive feedback or direction for the authors to enhance their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not provide specific guidance on how to achieve this motivation or what aspects of the paper should be revised to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the motivation section but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not specify which part of the paper lacks this motivation or how it could be improved. The authors might infer that it relates to the introduction or the motivation section, but this inference is not explicit. Therefore, the comment is weakly grounded as it does not pinpoint a specific part of the paper, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, the comment does not provide any specific reasoning, examples, or references to support why this motivation is lacking or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the paper, noting that it lacks motivation for the \"Why\" aspect of the presented topic. This feedback is somewhat helpful as it points out an area where the paper could be improved by providing a clearer rationale for the importance of the topic. However, the comment does not offer specific suggestions or guidance on how to enhance the motivation section, leaving the authors with a general direction but without detailed actionable steps. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the sentence in lines 12-17 of the abstract, noting that it is cumbersome and can be made clearer. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes that could be made. The action is implicit, as the authors can infer that they need to simplify the sentence, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable, as it points out an area for improvement but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific sentence in lines 12-17 of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in lines 12-17 of the abstract is cumbersome and can be made clearer. However, it does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the sentence in lines 12-17 of the abstract, noting that it is cumbersome and could be made clearer. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks detailed guidance or suggestions on how to clarify the sentence. The authors are given a general direction to simplify the sentence, but without specific advice on what changes to make, the comment does not fully support them in enhancing their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the unfairness of comparing the domain-specific model trained on Pix3D with zero-shot single-image 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their comparisons. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the domain-specific model\" and \"Pix3D,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, noting that it is unfair due to the use of Pix3D for both training and testing. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between the domain-specific model and zero-shot single-image 3D reconstruction models is unfair due to the use of Pix3D for both training and testing. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of how the comparison is unfair or how it differs from standard practices. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the domain-specific model and zero-shot single-image 3D reconstruction models, noting that both are trained and tested on Pix3D. This observation highlights a concern about the validity of the experiments and suggests that the comparisons may not be fair. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the fairness of their comparisons. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a trade-off between head and tail categories, but this trade-off has not been fully investigated for the baselines. The reviewer suggests that by changing the hyper-parameters in Decouple [Kang et al.], it could also significantly improve the tail accuracy while slightly decreasing the head accuracy. This feedback provides a clear and explicit action for the authors to take, which is to investigate the trade-off for the baselines and potentially improve their performance. The comment is highly actionable as it offers a specific direction for the authors to enhance their work.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proposed approach not outperforming or being worse than Decouple [Kang et al.] for overall performance, and it suggests investigating the trade-off for the baselines by changing hyper-parameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a trade-off between head and tail categories, but this trade-off has not been fully investigated for the baselines. The reviewer suggests that by changing the hyper-parameters in Decouple [Kang et al.], it could also significantly improve the tail accuracy while slightly decreasing the head accuracy. This claim is somewhat verifiable as it provides a logical reasoning for the potential improvement in the baselines, but it lacks specific examples or references to substantiate the claim fully. The authors would need to explore the suggested changes to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially improve their work. However, the comment could be more helpful by suggesting specific changes or experiments to conduct to address these issues. Overall, the comment is mostly helpful, as it offers valuable insights but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact nature of the experiments or how they should be conducted. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to support the claims made in the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular type of experiment that could be conducted to strengthen the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the claims made in the paper. This feedback is somewhat helpful as it identifies a specific area for improvement and suggests a potential direction for enhancing the paper. However, the comment lacks detailed guidance on how to conduct these experiments or what specific aspects of the dataset would be most beneficial. While it provides a clear suggestion, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the proposed E2W algorithm, specifically questioning the intuition behind the choice of $\\\\lambda_t$ for encouraging exploration and why $\\\\sum_a N(s, a)$ (but not $N(s, a)$) is used for $\\\\lambda_s$ in Equation (7). These questions imply that the authors should provide explanations or justifications for these choices. While the questions are explicit, they do not offer concrete guidance on how to address them, such as suggesting specific ways to explain the intuition or rationale behind these decisions. Therefore, the comment is somewhat actionable, as it identifies areas for clarification but lacks detailed instructions on how to implement the suggested actions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the specific choices made in the proposed E2W algorithm, specifically questioning the intuition behind the choice of $\\\\lambda_t$ for encouraging exploration and why $\\\\sum_a N(s, a)$ (but not $N(s, a)$) is used for $\\\\lambda_s$ in Equation (7). However, it does not specify which part of the paper these questions pertain to, such as a particular section or equation where these choices are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its questions but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and justification for specific choices in the proposed E2W algorithm. It does not contain subjective opinions, suggestions, or claims that require verification. The questions are factual and aim to gather additional information, making them \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the proposed E2W algorithm, specifically questioning the intuition behind the choice of $\\\\lambda_t$ for encouraging exploration and why $\\\\sum_a N(s, a)$ (but not $N(s, a)$) is used for $\\\\lambda_s$ in Equation (7). These questions are relevant and could help the authors clarify their methodology and provide a more comprehensive explanation of their approach. However, the comment does not offer suggestions or guidance on how to address these questions or improve the clarity of the paper. While it identifies areas for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not provide specific guidance on which datasets to consider or how to incorporate them into the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the need for additional datasets and how to integrate them effectively. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited evaluation, relying on only four OCR QA datasets, and suggests the inclusion of more scenarios like the LLaVA benchmark, especially in ablation studies. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included. The comment references Figure 4(5), which the authors admit may be unreliable, providing some justification for the claim. However, the comment lacks specific examples or detailed reasoning about why the LLaVA benchmark would be beneficial or how it could improve the evaluation. This makes the claim somewhat verifiable, as it provides a starting point for the authors to consider additional datasets but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation section, noting that it primarily relies on four OCR QA datasets. It acknowledges the authors' admission that this evaluation may be unreliable, as seen in Figure 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, providing the authors with a specific direction for expanding their evaluation to include additional datasets and scenarios. By addressing this limitation, the authors can enhance the robustness and comprehensiveness of their evaluation, which is crucial for the credibility of their findings. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two explicit actions for the authors to consider. First, it suggests that the authors should clarify that \"pi\" is a function from R^m to Delta^{K+1}, which is a specific and concrete suggestion. Second, it questions the dimensions of X pi(X) in (2) and suggests assuming the first column of X_t is always 0. This is also a specific and concrete suggestion. Both actions are clear and provide the authors with direct guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L75\" and \"(2),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a suggestion to clarify the definition of \"pi\" and questions the dimensions of X pi(X) in (2), offering a potential solution by assuming the first column of X_t is always 0. This level of detail helps the authors understand what needs to be addressed and how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and suggestions, such as clarifying the definition of \"pi\" and questioning the dimensions of X pi(X). These are factual statements that do not contain subjective opinions, claims, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting a clarification on the definition of \"pi\" and questioning the dimensions of X pi(X) in (2). It also offers a potential solution by suggesting that the first column of X_t could be assumed to be always 0. This level of detail and guidance is valuable for the authors, as it helps them address potential misunderstandings and improve the clarity and accuracy of their work. However, the comment could be more helpful if it explained why the dimensions do not match or provided additional context on the implications of this issue. Overall, the feedback is mostly helpful, as it directs the authors toward specific improvements that can enhance the comprehensibility of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\\' learning. However, the comment does not provide explicit guidance or suggestions on how to address these concerns or improve the tasks. The authors are left without a clear understanding of what changes, if any, are needed to enhance the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"abstract visual reasoning tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with these tasks, such as their unintuitiveness, difficulty, and potential for confusion due to multiple rows and changing factors. The comment further questions the necessity of these tasks and suggests simpler alternatives. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. The reviewer expresses difficulty in solving the tasks and questions the interpretation of the models\\' learning. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to consider simpler tasks is not fully substantiated, as the reviewer does not provide evidence or reasoning for why simpler tasks would be more effective. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully support the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises significant concerns about the abstract visual reasoning tasks used in the paper, describing them as unintuitive and overly difficult. The reviewer expresses difficulty in solving these tasks and questions the interpretation of the models\\' learning. The comment also suggests that simpler visual reasoning tasks might be more effective and questions the necessity of the current formulation. While the comment identifies a critical issue with the tasks, it lacks specific suggestions or guidance on how to address these concerns or improve the tasks. The authors are left with a general understanding of the problem but without actionable steps to resolve it. Therefore, the comment is somewhat helpful, as it highlights a significant issue but does not provide detailed feedback for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"[author] embeddings\" is not realistic. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes. The action is implicit and somewhat vague, as the authors can infer that they need to improve the realism of the evaluation but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the prompt, as well as critiquing the generation of authors. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that weak supervision could be better evaluated, specifically questioning the realism of the evaluated tweets and the prompt. It provides a detailed critique of the prompt, noting that it requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, stating that the use of \"[author] embeddings\" is not realistic. While the comment provides specific examples and reasoning, it could be strengthened by referencing similar studies or practices that support the claim. Overall, the claim is mostly verifiable, as it provides a logical and detailed critique but lacks comprehensive references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by questioning the realism of the evaluated tweets and the prompt used for weak supervision. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"[author] embeddings\" is not realistic. This feedback is clear and actionable, as it directs the authors to reconsider the realism of their evaluation and prompts them to make improvements in this area. However, the comment could be more helpful if it offered suggestions on how to enhance the realism of the evaluation or provided examples of more realistic approaches. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by identifying specific areas for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of essential visualizations of intermediate processes and comparisons, suggesting that these are necessary for the paper. However, it does not provide specific guidance on what these visualizations should include or how they should be presented. The action is implicit, as the authors can infer that they need to add visualizations, but it is vague because it lacks concrete details on what exactly should be visualized or compared. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of essential visualizations of intermediate processes and comparisons, but it does not specify which part of the paper lacks these visualizations. This makes it difficult for the authors to identify the exact sections that need improvement. Additionally, the comment lacks specificity regarding what kind of visualizations are needed or how they should be presented. Without detailed guidance, the authors may struggle to address the issue effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement by pointing out the lack of essential visualizations of intermediate processes and comparisons. This feedback is valuable as it highlights a potential gap in the paper that could enhance its clarity and comprehensibility. However, the comment lacks specificity and does not provide suggestions on what types of visualizations might be beneficial or how they could be integrated into the paper. While it directs the authors' attention to an important aspect, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. However, it does not provide any guidance or suggestions on how the authors should address this issue or what changes need to be made to resolve it. The comment lacks explicit instructions or concrete details on how to fix the problem, leaving the authors uncertain about the necessary steps to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific condition, $\\mathcal{P}_2$, stated in Definition 1, which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment does not specify what aspect of $\\mathcal{P}_2$ is violated or how this violation affects the expected counterfactual. This lack of specificity makes it difficult for the authors to understand the exact issue and how to address it. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any further explanation, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. This is a clear and actionable feedback that highlights a potential error or inconsistency in the paper. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what changes need to be made to resolve it. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a specific problem but lacks detailed guidance for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the importance of the result and suggests that it is not surprising given the findings in [15]. It also points out that the iteration complexity is no longer dimension-free in Theorem 3. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they should clarify the importance of their result or address the iteration complexity issue, but without concrete steps or details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment expresses concern about the importance of the result and suggests that it is not surprising given the findings in [15]. It also mentions a change in iteration complexity in Theorem 3. However, the comment does not specify which part of the paper these concerns relate to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, while the comment provides some specific details about the iteration complexity, it lacks specificity regarding the importance of the result or how it relates to the findings in [15]. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses concern about the importance of the result, suggesting that it is not surprising given the findings in [15]. It also mentions a change in iteration complexity in Theorem 3. However, the comment lacks specific examples or detailed reasoning to support the claim that the result is not surprising or to explain the impact of the iteration complexity change. This makes the claim somewhat verifiable, as it provides a general context but requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment expresses concern about the importance of the result, suggesting that it is not surprising given the findings in [15]. It also points out a change in iteration complexity in Theorem 3, noting that it is no longer dimension-free. While the comment identifies potential issues with the result and its implications, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it highlights areas for consideration, but it does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step for the authors to follow, ensuring they know exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly instructs the authors to include keypoint detection results in the experiments section, providing clear guidance on what needs to be addressed. This makes the comment fully grounded, as the authors can accurately identify the part of the paper being addressed. Additionally, the comment is specific because it clearly specifies what needs to be included, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for the inclusion of keypoint detection results in the experiments section. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and specific suggestion for improvement by requesting the inclusion of keypoint detection results in the experiments section. This feedback is actionable and directly addresses a gap in the paper, offering a concrete step for the authors to take to enhance their draft. By including these results, the authors can provide a more comprehensive evaluation of their work, which is beneficial for both the paper and the readers. However, the comment could be more helpful if it explained why these results are important or how they would contribute to the paper\\'s overall impact. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement that can enhance the paper\\'s content. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This is an explicit request for the authors to conduct a specific comparison, which is clear and actionable. The comment provides a concrete suggestion by specifying the model to be compared against, making it easy for the authors to understand and implement the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a comparison with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This provides a clear and specific suggestion for the authors to consider, indicating where the comparison should be made. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the performance evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This claim is somewhat verifiable as it provides a specific reference to an existing work that could be used for comparison. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the ternary potential being the main factor. The authors would need to explore the referenced work to understand the basis of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This is a clear and actionable suggestion that could help the authors further validate the performance improvement of their proposed model. By comparing it with a similar model, the authors can gain insights into the effectiveness of their approach and potentially identify areas for improvement. However, the comment could be more helpful if it provided additional context or reasoning behind the suggestion, such as why this comparison is important or how it might impact the results. Overall, the comment is mostly helpful as it offers a concrete direction for enhancing the paper, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what steps to take to clarify this aspect of the methodology. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. This is a factual inquiry that does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. While this is a relevant inquiry, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or additional context, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential area of concern but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is a concern that needs to be addressed. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This provides clear guidance on what aspect of the paper needs further clarification or investigation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This is a relevant observation that could help the authors understand the nature of their data and potentially improve the accuracy of their analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what steps they could take to clarify the classification of relations. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. While it implies that the authors should consider these aspects, it does not explicitly instruct them to include or address these issues in their draft. The action is implicit and somewhat vague, as the authors can infer that they should consider these factors but are not given specific guidance on how to incorporate them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. This provides clear guidance on what aspects need to be considered or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they might impact the results. The comment is more of a suggestion for the authors to consider these factors rather than a claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. This is a relevant concern that could impact the validity and applicability of the findings. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure inclusivity in their sample. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the output quality is reasonable but notes that it is still far from realistic. It references recent GAN works that have achieved amazing quality in synthesized results, suggesting that the bar has risen significantly in recent years. The reviewer implies that there is still room for improvement in result quality, but does not provide specific guidance on how to achieve this improvement. The comment also mentions the limited novelty, low resolution output, and high hardware requirement, which could be considered as reasons for rejection. However, the feedback lacks actionable advice or suggestions for the authors to address these issues. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive results, suggesting that the bar has risen significantly. However, the comment does not specify which part of the paper discusses the output quality, making it weakly grounded. It does provide some specificity by mentioning the limited novelty, low resolution output, and high hardware requirement, which could be considered reasons for rejection. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive results. The reviewer suggests that the bar for output quality has risen significantly in recent years, implying that the current results are not up to par. However, the comment lacks specific examples or references to these recent GAN works, making it difficult for the authors to fully understand and address the critique. The claim is somewhat verifiable as it provides a general context but lacks detailed evidence or examples to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the output quality is reasonable but notes that it is still far from realistic, particularly in comparison to recent GAN works that have achieved impressive results. The reviewer suggests that the bar for output quality has risen significantly in recent years, implying that there is still room for improvement. However, the comment does not provide specific guidance or suggestions on how the authors might enhance the output quality or address the identified issues. It also mentions the limited novelty, low resolution output, and high hardware requirement as reasons for potential rejection, but again lacks actionable advice. As a result, the feedback is somewhat helpful, as it highlights areas for improvement but does not offer detailed guidance or actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment does not specify which part of the paper these concerns relate to, such as a specific section, figure, or table. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, while the comment provides some specific feedback on the use of soft labels and hyperparameters, it does not specify what needs to be addressed or improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. While the comment identifies potential issues, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out areas that need clarification or improvement, but it does not provide actionable steps or detailed advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction, specifically on classifying unseen words. It also suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides explicit actions, it lacks concrete details on how to implement these suggestions, such as specific evaluation metrics or methods to add translations. The authors know what needs to be done but may struggle with the execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding translations to Figure 6 for readers who do not speak Chinese, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction. It also suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the experiment is underdeveloped or that translations would enhance understanding. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the idea of a simple/traditional experiment for unseen characters as a nice addition but notes that it is presented as an afterthought. It suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. Additionally, the comment recommends adding translations to Figure 6 for readers who do not speak Chinese, which could enhance the paper\\'s accessibility. While the comment provides actionable feedback, it could be more helpful by offering specific suggestions on how to conduct the additional evaluation or what metrics to use. Overall, the comment is mostly helpful as it identifies areas for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the small number of images in the VioT dataset, questioning its ability to validate the approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether additional images should be included, how the dataset could be expanded, or what specific changes would improve the dataset\\'s validity. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images in each category, which the reviewer feels is insufficient to validate the approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of images in the VioT dataset is insufficient to validate the approach. However, it does not provide any supporting evidence, reasoning, or references to justify why 20 images per category is inadequate. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the VioT dataset, specifically noting that the number of images provided (20 per category) may be insufficient to validate the approach. This is a relevant observation that could impact the robustness and generalizability of the results. However, the comment lacks specificity and does not provide actionable advice or suggestions on how the authors might address this issue. Without guidance on whether additional images are needed, how many would be sufficient, or how to improve the dataset, the feedback is limited in its usefulness. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study on the number of layers versus performance, which could be an interesting addition to the paper. However, it does not provide explicit instructions on how to conduct this study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study and determine the details themselves. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the number of layers versus performance, which could be an interesting addition to the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. Additionally, the comment lacks specificity regarding what aspects of the ablation study should be focused on or how it would contribute to the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the number of layers versus performance, which could be an interesting addition to the paper. However, the comment does not provide any reasoning or evidence to support why this study would be beneficial or how it would contribute to the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study on the number of layers versus performance, which could provide valuable insights into the relationship between model architecture and performance. This feedback is somewhat helpful as it identifies a potential area for improvement and suggests a specific type of analysis that could enhance the paper. However, the comment lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it offers a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including its lack of intuitive explanations for mathematical derivations, insufficient figure captions, and the need for additional explanations and legends. The reviewer also mentions that Figures 1 and 2 did not contribute much to their understanding and required multiple readings. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The actions are implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the mathematical derivations, figure captions, and figures 1 and 2. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details what is lacking, such as intuitive explanations for mathematical derivations, better figure captions, and additional explanations for the colors in Figure 2. The feedback provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is hard to follow due to a lack of intuitive explanations for mathematical derivations and insufficient figure captions. The reviewer provides specific examples, such as the need for additional explanations and legends for Figure 2, which helps support the claim. However, the comment lacks detailed reasoning or references to specific sections where these issues are most apparent, making it somewhat verifiable. The authors would need to infer the exact areas that need improvement, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, including the lack of intuitive explanations for mathematical derivations and insufficient figure captions. It provides specific examples, such as the need for additional explanations and legends for Figure 2, which helps the authors understand what changes are necessary. However, the comment could be more helpful if it offered suggestions on how to enhance the explanations or provided examples of how to improve the figure captions. Despite this, the feedback is mostly helpful as it directs the authors to specific areas that need attention, allowing them to make targeted improvements to their draft. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could potentially negate any improvement gained from the method. The reviewer expresses willingness to reconsider their rating if this issue is addressed. While the comment highlights an important area for consideration, it does not provide explicit guidance on how the authors should investigate or address this sensitivity. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of hyperparameter choices on their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing the importance of this issue. However, it does not specify which part of the paper discusses the empirical results or hyperparameter choices, making it weakly grounded. The comment is specific in its request for clarification on the sensitivity of the results to hyperparameter choices, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could potentially negate any improvement gained from the method. The reviewer expresses willingness to reconsider their rating if this issue is resolved. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the sensitivity of the results to hyperparameter choices. Without such evidence or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a general concern but lacks the necessary details for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could potentially negate any improvement gained from the method. This is an important point that highlights a potential weakness in the paper\\'s methodology and results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending a sensitivity analysis or suggesting alternative approaches to mitigate the impact of hyperparameter choices. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, given that it utilizes existing attack methods on a surrogate model. While the comment implies that the authors should provide a justification for the novelty of their approach, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty and contribution of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty and contribution of the proposed method, specifically mentioning that it utilizes existing attack methods on a surrogate model. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its request for further clarification on the novelty and contribution, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work utilizes existing attack methods on a surrogate model, which is similar to using the transferability of adversarial examples directly. The reviewer suggests that the authors need to further claim the novelty and contribution of their proposed method. However, the comment lacks specific examples or references to support the claim that the work is not novel or lacks contribution. Without detailed justification or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model. It suggests that the authors should further clarify the novelty and contribution of their approach. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. Without detailed feedback or examples, the authors may find it challenging to effectively enhance their draft. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not provide comprehensive guidance for addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of multiple observations and suggestions. It explicitly states that the text in Table 1 is too small and hard to read, providing a clear action for the authors to improve the readability of their tables. Additionally, it points out that Algorithm 1 is missing a gradient symbol in line 4, which is also an explicit action for the authors to take. The comment further suggests referencing specific works related to private stochastic convex optimization, providing concrete examples of relevant literature. This level of detail and specificity makes the comment highly actionable, as it clearly guides the authors on what changes to make to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and \"algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the text size in table 1 and the missing gradient symbol in algorithm 1, providing clear guidance on what needs to be addressed. Additionally, it suggests referencing specific works related to private stochastic convex optimization, which adds further specificity to the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple factual observations and suggestions, such as the text in Table 1 being too small and hard to read, the missing gradient symbol in Algorithm 1, and the recommendation to reference specific works related to private stochastic convex optimization. These observations are factual and do not require verification or justification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out two issues: the small and hard-to-read text in Table 1, and the missing gradient symbol in Algorithm 1. It also suggests referencing specific works related to private stochastic convex optimization, which could help the authors improve the context and relevance of their work. This feedback is clear and direct, offering the authors concrete steps to enhance the readability and accuracy of their draft. However, the comment could be more helpful if it included suggestions on how to address the issues with the text size or gradient symbol. Overall, the comment is mostly helpful as it provides actionable guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should render the reference to Wright et al. (1934) and Figure 1 more naturally by using the bracketed arguments in \\citep. However, it does not provide specific guidance on how to implement this suggestion or what the bracketed arguments should contain. The comment also mentions a potential issue with hyperref but does not elaborate on how it might affect the rendering. While the action is explicit, it lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Wright et al., 1934\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a way to render the reference more naturally using bracketed arguments in \\citep. However, the comment lacks specificity regarding the exact nature of the issue with hyperref and how it might affect the rendering. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should render the reference to Wright et al. (1934) and Figure 1 more naturally by using the bracketed arguments in \\citep. However, it does not provide any specific reasoning or examples to support why this would be beneficial or how it would improve the paper. The mention of \"hyperref\" adds a layer of complexity without further explanation, making it difficult for the authors to understand the issue or how to address it. As a result, the comment lacks sufficient justification and is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement to the rendering of references, recommending the use of bracketed arguments in \\citep to make the reference to Wright et al. (1934) and Figure 1 more natural. While this feedback is clear and actionable, it could be more helpful if it provided additional context or examples on how to implement this suggestion effectively. Additionally, the mention of \"hyperref\" adds a layer of complexity without further explanation, which could be confusing for the authors. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks depth and detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not discuss computational aspects in detail, particularly in high dimensions, and questions the practical usefulness of their proposed methods. It highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets. While the comment identifies a concern about the computational aspects and the scalability of the methods, it does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed discussions and potentially conduct experiments on larger datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions the requirement to solve several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets. While the comment does not explicitly mention specific sections or parts of the paper, the authors can infer that it relates to the methodology and results sections, where computational aspects and experimental details are typically discussed. The comment is specific in detailing the issue with computational aspects and the scalability of the methods, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not discuss computational aspects in detail, particularly in high dimensions, and questions the practical usefulness of their proposed methods. It highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets. While the claim is based on logical reasoning and observations from the paper, it lacks specific examples or references to support the assertion about the difficulty of calculating parameters in high dimensions. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the authors do not provide sufficient detail on the practical usefulness of their proposed methods, especially in terms of scalability. The comment highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. This observation is relevant and important, as it raises concerns about the applicability and scalability of the proposed methods. However, the comment could be more helpful if it provided suggestions on how the authors might address these issues, such as recommending additional experiments or analyses to demonstrate scalability. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks specific guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific errors in the equations, suggesting corrections to the signs in the equations. It provides clear and concrete instructions on what changes need to be made, such as replacing \"+\" signs with \"-\" signs and vice versa. This level of detail ensures that the authors know exactly what corrections to make, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (Line 502, 503, and 504), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the errors in the equations, including the incorrect signs and the need for corrections. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and corrections to specific equations, such as the suggestion to change \"+\" signs to \"-\" signs and vice versa. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying errors in the equations, suggesting corrections to the signs in the equations and the summation term. This level of detail is valuable for the authors, as it directly points out where the equations are incorrect and how to correct them. By addressing these minor but critical errors, the authors can ensure the accuracy and clarity of their work. However, the comment could be more helpful if it also explained the significance of these corrections or how they might impact the overall understanding of the paper. Overall, the feedback is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests that a potentially interesting baseline would be to compare to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed time-step Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether the ResNet in the experiments shares parameters between residual blocks and suggests a potentially interesting baseline for comparison. The comment provides a clear suggestion for improvement by recommending a deeper ResNet with parameter sharing as a baseline. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests a potentially interesting baseline for comparison, which is a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed time-step Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support the claim that this comparison would be beneficial or necessary. The suggestion is based on logical reasoning but lacks specific examples or detailed justification, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests that a potentially interesting baseline for comparison would be a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed time-step Euler integrator. This feedback is somewhat helpful as it provides a potential direction for further exploration and comparison, which could enhance the depth and comprehensiveness of the experiments. However, the comment lacks specific guidance on how to implement this comparison or what specific aspects to focus on, which limits its full usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation behind the cross-encoder architecture, specifically addressing the claim that it \"ignores cross-entity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as fine-grained as claimed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the motivation, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation behind the cross-encoder architecture, specifically challenging the claim that it \"ignores cross-entity comparison\" and \"attends to all candidates at once.\" However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the motivation but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the motivation behind the cross-encoder architecture, specifically challenging the claim that it \"ignores cross-entity comparison\" and \"attends to all candidates at once.\" The reviewer provides a logical reasoning by explaining that the architecture does not ignore cross-entity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support this reasoning, which would strengthen the argument. As a result, the claim is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the motivation behind the cross-encoder architecture, specifically challenging the claim that it \"ignores cross-entity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as fine-grained as claimed. However, the comment does not provide specific suggestions or guidance on how the authors might improve the motivation or clarify the architecture\\'s functionality. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, as it identifies a potential weakness but lacks depth and actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, especially since the question model is a bag of words, which is not expensive to encode longer sequences. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their design. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10, providing a clear rationale for why this might be an odd choice, especially since the question model is a bag of words. This specificity helps the authors understand what aspect of their work needs attention and potential improvement. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. The comment provides a logical reasoning based on the nature of the question model, which is a factual observation. However, it does not include specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially provide additional evidence or context to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. This feedback highlights a potential inconsistency or inefficiency in the design, prompting the authors to reconsider their approach. However, the comment does not provide specific suggestions or alternatives for improving the design, nor does it offer detailed guidance on how to address this issue. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement or action. It lacks specific guidance on what the authors should do to address these issues, such as recommending the use of more modern models or methods or suggesting alternative approaches. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment criticizes the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights the issue of antiquated models, it does not provide specific suggestions or examples of modern alternatives that could be considered. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the use of an \"antiquated\" GNN model and method negatively impacts the performance of the framework. However, it does not provide specific examples or references to support this claim, such as comparing the performance with more modern models or methods. The lack of detailed evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, the comment is barely helpful, as it highlights a problem but does not offer meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity in Figure 1 regarding how the proposed method produces the type of explanation shown, which mentions \"mutagens contain the NO2 group.\" The reviewer suggests that this requires \"additional ad-hoc post-analysis\" to extract shared motifs, implying that the authors should provide more detailed explanations or analysis to clarify this aspect. While the comment identifies a potential issue, it does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanation but are not given concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unclear methodology in producing the explanation shown in the figure, specifically mentioning the need for \"additional ad-hoc post-analysis\" to extract shared motifs. The comment provides a clear direction for improvement by suggesting that the authors clarify the analysis process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanation in Figure 1 is unclear and suggests that it requires additional analysis to extract shared motifs. The reviewer provides a specific reference to Line 48, which supports the claim by indicating the need for further analysis. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method might facilitate this analysis. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks comprehensive evidence or detailed examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the explanation provided in Figure 1, specifically regarding how the proposed method produces the type of explanation shown. It suggests that additional analysis, such as extracting shared motifs, may be necessary to fully understand the method. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a weakness but lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a concern about the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large perturbation value to ensure the correctness of the pseudo feature importance. The comment suggests that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two ways to strengthen the experiment: by using true feature importance or by providing a more detailed analysis of the perturbation value. These suggestions are explicit and provide concrete guidance on how to improve the experiment. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, namely the use of pseudo feature importance due to the lack of true feature importance, and the reliance on Proposition 3.2 and a large perturbation value. The comment further suggests ways to strengthen the experiment, such as using true feature importance or providing a more detailed analysis of the perturbation value. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment using pseudo feature importance is difficult to trust because it relies on Proposition 3.2 and a large perturbation value. The reviewer suggests that the experiment could be strengthened by using true feature importance or providing a more detailed analysis of the perturbation value. While the comment provides a logical reasoning for the claim, it lacks specific references or detailed examples to fully substantiate the critique. The suggestion for improvement is clear, but the initial claim could be more robust with additional evidence or references. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large perturbation value to ensure the correctness of the pseudo feature importance. The comment points out that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two actionable suggestions for improvement: using true feature importance or providing a more detailed analysis of the perturbation value. This feedback is clear and constructive, offering the authors specific ways to enhance the robustness and credibility of their experiment. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the non-convexity of the function Z and suggests that it may not be a problem for the SGD to converge if the function has certain properties. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific properties of the function Z should be considered. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (182-184) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it highlights a potential issue with non-convexity and suggests that it may not be a problem for the SGD to converge if the function Z has certain properties. This provides clear guidance on what aspect of the paper needs attention and clarification. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge, if the function Z has some good properties. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the non-convexity of the function Z, suggesting that it may not be a problem for the SGD to converge if the function has certain properties. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what properties of the function Z should be considered. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues, including the lack of comparison with other models besides GPT2, confusion in sections of the paper, a missing citation or reference in Line 99, and an unreferenced notation in Line 165. The comment acknowledges the authors\\' effort to address limitations but does not provide specific guidance on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses multiple issues, including the lack of comparison with other models, confusion in sections of the paper, a missing citation or reference in Line 99, and an unreferenced notation in Line 165. While it does not explicitly mention specific sections or lines, the authors can infer that these issues are related to sections 3.1 and 3.4, respectively. The comment is specific in detailing what is missing or unclear, such as the need for additional comparisons and references. However, the lack of explicit section references makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the lack of comparison with other models, confusion in sections of the paper, and missing citations or references. The claim about the lack of comparison with other models is somewhat verifiable, as it highlights a potential limitation in the paper\\'s methodology. The claim about confusion in sections of the paper is somewhat verifiable, as it points out specific issues but lacks detailed examples or references to support the claim fully. The claim about missing citations or references is verifiable, as it provides specific line numbers where these issues occur. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claims. Therefore, the overall assessment is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of comparison with other models besides GPT2, confusion in sections of the paper, and missing citations or references. It also acknowledges the authors\\' effort to address limitations. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left to infer what changes are needed, such as adding comparisons or references, without detailed instructions. This limits the comment\\'s usefulness, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of a specific expression in Equation (2), \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\". This is an explicit question that the authors need to address to clarify the notation or provide an explanation. However, the comment does not provide any guidance on how to address this question or what specific information should be included in the explanation. The action is explicit but lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of a particular expression in the equation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the meaning of a specific expression in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific expression in Equation (2), which is a direct and actionable request for clarification. By asking for an explanation of the notation, the reviewer provides a clear direction for the authors to improve their draft. This feedback is specific and actionable, as it prompts the authors to address a potential ambiguity in their work. However, the comment could be more helpful if it provided additional context or suggested potential interpretations of the notation. Overall, the comment is mostly helpful, as it directs the authors to clarify a specific aspect of their work, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit instructions for changes, specifying that two lines in red should be in green in the Supplementary Material. It also provides specific line numbers and references to equations, tables, and algorithms that need to be updated. This feedback is clear and actionable, as it directly tells the authors what changes need to be made and where. The authors know exactly what to do to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the Supplementary Material that need to be updated, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the colors of certain lines and references to equations, tables, and algorithms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two lines in red that should be in green in the Supplementary Material. It specifies the exact line numbers and references to equations, tables, and algorithms that need to be updated. This level of detail is highly beneficial for the authors, as it directly guides them on what changes to make to improve the clarity and accuracy of their draft. The comment is clear and actionable, making it highly helpful for the authors to address the identified issues. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a more comprehensive and data-intensive analysis would significantly improve the paper, but acknowledges that it is a short paper and therefore not a strong negative against what the authors have done. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to conduct a more comprehensive analysis or what specific aspects of the paper could benefit from such an analysis. Without actionable steps or suggestions, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not specify which part of the paper this analysis should focus on. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the analysis should be more comprehensive or what specific data should be included. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that a more comprehensive and data-intensive analysis would improve the paper, but it acknowledges that it is a short paper and therefore not a strong negative against what the authors have done. However, the comment does not provide any specific examples, reasoning, or references to support the claim that a more comprehensive analysis would significantly enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is short and suggests that a more comprehensive and data-intensive analysis would significantly improve it. However, it does not provide specific guidance or suggestions on how to achieve this improvement, nor does it identify any particular areas that could benefit from such an analysis. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to address the suggestion. Therefore, the comment is not helpful at all, as it lacks specificity and actionable guidance.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of proper mention of experimental settings and the absence of code for result reproducibility. While the comment implies that the authors should provide more detailed information about the experimental settings and include the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these issues. However, the comment provides a clear direction on what needs to be improved, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of proper mention of experimental settings and the absence of code for result reproducibility. However, it does not specify which part of the paper discusses the experimental settings or where the code should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being referred to. The comment is specific in identifying the issues with experimental settings and result reproducibility, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly, which affects result reproducibility. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the lack of code further complicates the verifiability, as it is not clear how this impacts the reproducibility issue. Without specific examples or detailed justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two critical issues with the paper: the lack of proper mention of experimental settings and the absence of code for result reproducibility. These are important considerations for ensuring the validity and replicability of the research. However, the comment does not provide specific guidance on how to address these issues or suggest ways to improve the experimental setup or code availability. While it highlights significant areas for improvement, the feedback lacks actionable details, making it somewhat helpful. The authors are given a general direction but need more detailed guidance to fully benefit from the comment. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the evaluation results, specifically noting the absence of a proper comparison against online learning approaches and RL. It raises questions about the reasons for discarding online learning and the challenges of including it in the evaluation. While the comment identifies areas that need clarification and comparison, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should include a comparison and provide explanations for the decisions made. However, the lack of specific guidance on how to conduct the comparison or what aspects to focus on makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors discuss the limitations of online learning. It also specifies the issue of missing comparisons with online learning approaches and RL, which would help clarify why online learning cannot be used. The comment raises specific questions about the reasons for discarding online learning and the challenges of including it in the evaluation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of a proper comparison between the proposed method and online learning approaches, as well as RL, which is mentioned in the abstract. The reviewer questions the reasons for discarding online learning and suggests that the authors should clarify why it is not considered. However, the comment does not provide specific examples or references to support the claim that online learning is overlooked or that a comparison is necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the paper, specifically noting the absence of a proper comparison against online learning approaches and RL, as mentioned in the abstract. It raises important questions about the reasons for discarding online learning and the challenges of including it in the evaluation. By asking for clarification on the retraining cost and incremental updates, the comment prompts the authors to provide a more comprehensive analysis of their approach. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance its credibility and impact. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should cite works on meta-learning, even though they do not directly target continual learning. It also implies that the authors should distinguish these approaches and link them more heavily to the work on RL for architecture search and/or as optimizers for learning, which are already cited. While the comment provides a clear direction for the authors to expand their citations and make connections, it does not specify which specific works should be cited or how to distinguish the approaches. The action is explicit but somewhat vague, as the authors know they need to expand their citations but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite works on meta-learning, even though they do not directly target continual learning. It also implies that the authors should distinguish these approaches and link them more heavily to the work on RL for architecture search and/or as optimizers for learning, which are already cited. While the comment does not explicitly mention specific sections or parts of the paper, it provides a clear direction for the authors to expand their citations and make connections. The authors can infer that this pertains to the sections discussing related work or literature review. However, the comment lacks specificity in terms of which specific works should be cited or how to distinguish the approaches. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should cite works on meta-learning, even though they do not directly target continual learning. It also implies that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work. However, the comment lacks specific examples or references to support the claim that these works should be cited or linked more heavily. Without detailed evidence or examples, the authors may find it challenging to understand the exact nature of the connection or the relevance of these works to their own. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper\\'s citation and connection to related works, specifically mentioning meta-learning approaches and their relevance to continual learning. It suggests that the authors should cite works on meta-learning, even though they do not directly target continual learning, and should distinguish these approaches. Additionally, the comment highlights the need to link the work on RL for architecture search and/or as optimizers for learning more heavily to the current work, as it seems to directly follow as an application to continual learning. This feedback is clear and actionable, providing the authors with specific directions to enhance the comprehensiveness and relevance of their citations. However, it could be more helpful if it included examples of specific works to cite or more detailed guidance on how to distinguish the approaches. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the depth and context of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be auto-generated. It asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the lack of lexical and syntactic diversity in the teacher feedback, assuming it is auto-generated. It raises a question about whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue of diversity and suggesting potential solutions, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be auto-generated. The reviewer asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the feedback is auto-generated or that diversity is lacking. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the teacher feedback, noting a lack of lexical and syntactic diversity. It raises a question about whether the feedback is auto-generated and suggests that using human turkers or generating different types of feedback could make it more realistic. This feedback is somewhat helpful as it points out a potential weakness in the methodology and provides a direction for improvement by suggesting ways to enhance the diversity and realism of the feedback. However, the comment could be more helpful if it offered specific guidance on how to implement these suggestions or provided examples of what constitutes diverse feedback. Overall, the comment is somewhat helpful, as it prompts the authors to consider an important aspect of their methodology but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. While the comment implies that the authors should include a summary of the supplementary experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary and where it should be placed. However, the comment provides a clear direction on what needs to be addressed, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. However, it does not specify which part of the main text this issue pertains to, making it weakly grounded. The comment is specific in its request for summarizing the results of the supplementary experiments, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. However, the comment does not provide any reasoning, examples, or references to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper. By addressing this point, the authors can ensure that readers are aware of the additional experiments and their results, which can improve the overall understanding and impact of the paper. However, the comment could be more helpful if it included specific guidance on how to summarize the results or examples of what should be included. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a comprehensive comparison with the GFF[1] and EfficientFCN[2] works, both of which aim to implement the fast semantic segmentation method in the encode-decoder architecture. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment also includes specific references to the works that should be included in the comparison, providing concrete guidance on how to implement the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"societal impact\" shown on the last page of the manuscript, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the missing references, GFF[1] and EfficientFCN[2], and suggests a comprehensive comparison with these works. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing and suggests a comprehensive comparison with the GFF[1] and EfficientFCN[2] works. The reviewer provides specific references to these works, which helps to verify the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the paper\\'s contributions. Overall, the claim is mostly verifiable as it provides sufficient evidence but lacks detailed reasoning or examples to fully substantiate the need for comparison. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning the GFF[1] and EfficientFCN[2] works. It provides specific suggestions for improvement by encouraging the authors to include a comprehensive comparison with these works, which are relevant to the topic of fast semantic segmentation in the encode-decoder architecture. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft by addressing a critical omission. However, the comment could be more helpful if it provided additional context or explanation on why these references are important or how they relate to the paper\\'s contributions. Overall, the comment is mostly helpful as it effectively guides the authors toward improving their work, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the discrepancy between the claim and the results, nor are there suggestions for further analysis or experimentation to support the claim. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment does not provide specific details on what aspects of the claim are questionable or how the slight improvement undermines the effectiveness claim. Without explicit references to sections or detailed feedback, the authors cannot effectively address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the slight improvement is insufficient to support the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment identifies a potential weakness but lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, the comment is rated as barely helpful, as it points out a concern but does not offer constructive advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" This provides a clear and direct action for the authors to take, as it specifies which works to compare their method with. The suggestion is concrete, as it outlines a specific task and references two relevant studies. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to compare the performance with specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" This allows the authors to accurately identify the part of the paper that needs attention, specifically the performance evaluation section. The comment is also specific because it clearly specifies what needs to be addressed, namely, the comparison with these two works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" This recommendation is based on the premise that these works are relevant and could provide a useful comparison. However, the comment does not provide detailed reasoning or evidence to support why these particular works should be included in the comparison. While the suggestion is logical, it lacks specific justification or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending a comparison of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" This recommendation is clear and could significantly enhance the paper by providing a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it included a rationale for why these particular works should be compared or how they relate to the current study. Overall, the feedback is mostly helpful as it offers a concrete step for the authors to take, but it could be more comprehensive with additional context or explanation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel, is insufficient. It suggests that there could be many different designs of this process and recommends conducting experiments or analysis with different sampling intervals and sample sizes. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment suggests conducting experiments or analysis with different sampling intervals and sample sizes, which provides some specificity regarding what could be improved. However, the lack of explicit reference to a specific section or part of the paper limits the authors\\' ability to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of the Cycle FC is insufficient and suggests conducting experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or detailed reasoning to support why these additional experiments or analyses are necessary. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that could be improved, namely the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. It suggests that the analysis is insufficient and proposes conducting experiments or analysis with different sampling intervals and sample sizes. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their work. However, the comment could be more helpful if it included examples or detailed suggestions on how to conduct these experiments or analyses. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of the Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer suggests that the paper would be more convincing if it included experimental results for the proposed algorithms. While the comment implies that the authors should conduct experiments to validate the practicality of their algorithms, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the experiments or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and the use of the Vandermonde matrix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the practical performance of the algorithm, particularly regarding the ill-conditioned nature of the Vandermonde matrix and the potential instability for large $n$ and small $\\alpha$. The comment further suggests that the paper would be more convincing with experimental results for the proposed algorithms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of the Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a specific example of how this instability could affect the algorithm, particularly for large $n$ and small $\\alpha$. This reasoning is logical and based on common knowledge about the properties of the Vandermonde matrix. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the practical performance of the proposed algorithms, specifically highlighting the use of the Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer points out that this instability could be problematic, especially for large $n$ and small $\\alpha$, and suggests that the paper would be more convincing if it included experimental results for the proposed algorithms. This feedback is clear and actionable, as it identifies a potential issue with the algorithms and provides a specific suggestion for improvement. By addressing this concern, the authors can enhance the credibility and practicality of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of standard deviations in the paper, which makes it difficult to determine if the best method is truly the best or if other RF configurations have similar performance. While the comment implies that the authors should include standard deviations to provide a more comprehensive evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but are not given specific guidance on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of standard deviations in the paper, which affects the evaluation of the best method\\'s performance. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures where standard deviations should be included. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in identifying the issue, it is not grounded because it does not specify where in the paper this issue occurs. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the absence of standard deviations makes it difficult to determine the true performance of the best method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it challenging for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, namely the absence of standard deviations, which is crucial for evaluating the performance of the best method. By pointing out this gap, the comment highlights a critical area that needs attention and improvement. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which standard deviations should be included or how to present them effectively. While it directs the authors\\' attention to an important aspect of their work, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their approach and determine how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for an extension to more general settings, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension might be beneficial or challenging. Without additional context or explanation, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While it identifies a potential limitation and provides a direction for improvement, it lacks specific guidance or suggestions on how to achieve this extension. The comment is somewhat helpful as it prompts the authors to think about the generalizability of their approach, but it does not offer detailed advice or actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the dimensionality of each region and asks which feature extractor is used. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern or how it should be addressed in the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the dimensionality of each region and asks which feature extractor is used. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the dimensionality of each region and asks which feature extractor is used. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the information. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it points out a potential issue but does not offer any actionable steps for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors are left to infer that they need to add these details but are not guided on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in suggesting what kind of details should be added, but without clear grounding, the authors may struggle to determine where these details should be incorporated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on which details should be included or how they should be presented. The feedback is somewhat helpful as it points out a general area for enhancement, but it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the choice of p < 0.4 in Algorithm 1. This is a direct and concrete question that the authors can address by providing an explanation or justification for their selection. The action is clear and specific, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4, which is a clear and direct question. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual question seeking clarification on the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly specific and actionable, as it directly questions the choice of p < 0.4 in Algorithm 1. This prompts the authors to provide an explanation or justification for their selection, which is crucial for the clarity and reproducibility of their work. By addressing this point, the authors can enhance the transparency and credibility of their methodology. However, the comment could be more helpful if it provided additional context or suggested alternative approaches for selecting p. Overall, the comment is mostly helpful, as it directs the authors to a specific area that requires clarification, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide explanations and analysis for Figures 1, 2, and 3 in Section 5. It also specifies the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5\" and refers to specific figures (1, 2, and 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014explanations and analysis for the figures, as well as clarification on the negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have failed to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It specifically mentions the need for clarification regarding negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any reasoning or examples to support why these explanations or analyses are necessary or how they would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically noting the absence of explanations or analysis for Figures 1, 2, and 3 in Section 5. It also highlights the need for clarification regarding negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, providing the authors with specific areas to address in order to enhance the comprehensibility and impact of their work. By suggesting the inclusion of explanations and analyses, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it provided examples or suggestions on how to approach these explanations or analyses. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation behind applying CMD (Command and Data Manipulation) in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify how to achieve this or what aspects of the motivation need further elaboration. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to improve the clarity of the motivation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation behind applying CMD in federated learning, suggesting that it is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper discusses this motivation, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the motivation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that it could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the motivation behind applying CMD (Command and Data Manipulation) in federated learning is unclear. It suggests that the authors could improve their draft by providing a more explicit demonstration or explanation of this motivation. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the clarity of the motivation. This limits the helpfulness of the feedback, as it provides a general direction but does not offer detailed actionable steps for the authors to follow. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. It suggests that references to specific works, such as [1] and [2], could provide additional context. While the comment implies that the authors should conduct a more comprehensive analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of analysis on the effectiveness of each data augmentation method, allowing the authors to identify the specific part of the paper being addressed. It also specifies the need for a comparison with other paraphrasing methods, such as EDA or LLM-based paraphrasing, to clarify the unique advantages of their method. The comment provides specific suggestions for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. The reviewer supports this claim by referencing specific works, including [1] and [2], which provide context and evidence for the need for a more comprehensive analysis. This additional information enhances the verifiability of the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis on the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, would clarify the unique advantages of the method. The comment provides specific references to relevant works, which can help the authors understand the context and potential improvements needed. This feedback is clear and actionable, offering a concrete direction for enhancing the analysis and comparison in the paper. However, it could be more helpful if it included more detailed guidance on how to conduct the analysis or comparison. Overall, the comment is mostly helpful, as it provides valuable insights and direction for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is explicit and provides concrete guidance on how to improve the draft by conducting additional experiments. The authors know exactly what actions to take to enhance their study, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study to evaluate the net effect of each component in the proposed model, specifically mentioning \"learning with MMD\" and \"typical knowledge distillation loss\" as examples. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the need for an ablation study and provides examples of experiments to consider, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not provide any supporting evidence or reasoning to justify why an ablation study is necessary or how it would improve the paper. The suggestion is logical but lacks detailed justification or examples, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by providing a more comprehensive evaluation of their model. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would enhance the understanding of the model\\'s components. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider this scenario, it does not explicitly instruct them to do so or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they should consider this scenario but are not given specific instructions on how to evaluate or incorporate it into their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, experiment, or analysis. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance are being questioned or how this scenario relates to the overall study. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the performance of a specific model scenario. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting scenario that the authors might not have considered, it lacks depth and does not provide any guidance or suggestions on how to address this issue or its implications. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is barely helpful, as it prompts the authors to consider a specific scenario but does not provide meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a trend in the performance of RLCD compared to RLAIF, noting that the advantage shrinks as the model size increases. It raises a question about the scalability of RLCD to larger language models, suggesting that it remains to be seen whether RLCD can differentiate responses near the decision boundary. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the shrinking advantage of RLCD over RLAIF as the model size increases. Additionally, it raises a question about the scalability of RLCD to larger language models, suggesting that it remains to be seen whether RLCD can differentiate responses near the decision boundary. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, referencing Table 2. It also raises a question about the scalability of RLCD to larger language models, suggesting that it remains to be seen whether RLCD can differentiate responses near the decision boundary. However, the comment lacks specific examples or detailed reasoning to support the claim about the shrinking advantage or the scalability issue. The reference to Table 2 is not sufficient to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional evidence or analysis to fully understand and address the concerns raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a trend in the performance of RLCD compared to RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about the scalability of RLCD to larger language models, suggesting that it remains to be seen whether RLCD can differentiate responses near the decision boundary. While the comment identifies an important observation and raises a relevant question, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it points out a potential limitation, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions whether this method can be applied to large-scale datasets like ImageNet and suggests that the practical contribution of the paper could be reduced without a solution to address the scalability issue. While the comment implies that the authors should address the scalability concern, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the scalability issue but are not given specific steps or methods to consider. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scalability of the proposed NC measure, specifically questioning how it can be applied to large-scale datasets like ImageNet. However, it does not explicitly mention which part of the paper discusses the NC measure, making it weakly grounded. The comment is specific in its concern about scalability and suggests a potential solution by asking for an address to this issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. The reviewer questions whether this method can be applied to large-scale datasets like ImageNet and suggests that the practical contribution of the paper could be reduced without a solution to address the scalability issue. However, the comment lacks specific examples or references to support the claim about the scalability issue or the potential impact on practical contributions. The reasoning is somewhat logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions whether this method can be applied to large-scale datasets like ImageNet and suggests that the practical contribution of the paper could be reduced without a solution to address the scalability issue. This feedback is somewhat helpful as it identifies a potential limitation of the proposed method and prompts the authors to consider scalability issues. However, the comment could be more helpful if it provided suggestions or examples of how the authors might address this scalability concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a lack of quantitative analysis on computational gains, specifically mentioning the need for specific measurements or comparisons to substantiate the claimed benefits. It suggests that including quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements in DQ V2. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, specifically referring to the claim of computational benefits from replacing the MAE model with a CNN-based data augmentation strategy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely specific measurements or comparisons to substantiate the claimed gains. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks specific measurements or comparisons to substantiate the claimed computational gains from replacing the MAE model with a CNN-based data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is mostly verifiable as it provides a clear suggestion for what type of analysis would be beneficial. However, it lacks specific examples or references to existing studies that have used similar analyses, which would strengthen the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It specifically mentions the need for specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNN-based data augmentation strategy. The comment provides a clear and actionable suggestion by recommending the inclusion of quantitative analysis, such as GPU hours, memory usage, or training time, to provide stronger evidence of the efficiency improvements in DQ V2. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete way to enhance the credibility and robustness of their claims. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time taken by COLMAP and scene-by-scene fine-tuning should be considered when comparing the method, as it renders the method less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should account for this time or how it affects the efficiency comparison. The action is implicit and lacks concrete details on how to address the issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the time taken by COLMAP and scene-by-scene fine-tuning should be considered when comparing the method, which implies that the efficiency of the method is being discussed. However, the comment does not specify which part of the paper this comparison is made in, nor does it provide details on what specific aspects of efficiency are being addressed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of efficiency. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the time taken by COLMAP and scene-by-scene fine-tuning should be considered when comparing the method, implying that this factor affects the efficiency of the method. However, the comment does not provide any specific data, examples, or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of the method being evaluated, specifically mentioning the time taken by COLMAP and scene-by-scene fine-tuning. This is a relevant observation that could impact the overall efficiency comparison of the method. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve the efficiency comparison. Without detailed suggestions or examples, the feedback is somewhat helpful as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which forms the main part of the technique. It asks whether the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions the scalability of FMN when the number of input and output channels is large. These questions imply that the authors should provide more detailed analysis and discussion on the FMN, potentially including experiments with different architectures and scalability tests. While the comment does not explicitly instruct the authors to conduct these analyses, it provides clear guidance on what aspects need further exploration. The action is implicit but concrete, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the lack of discussion or analysis on FMN, asking about experiments with other architectures, and inquiring about the scalability of adaptive convolutions with varying filter parameters. The comment provides clear guidance on what aspects need further exploration, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which forms the main part of the technique. It questions the lack of discussion or analysis on FMN, asks about experiments with other architectures, and inquires about the scalability of adaptive convolutions with varying filter parameters. While the comment highlights important areas for further exploration, it does not provide specific evidence or references to support these questions. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to conduct additional research to address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which forms the main part of the technique. It raises important questions about the scalability of FMN with varying filter parameters and the potential for experimenting with other architectures. By highlighting these areas, the comment provides clear and actionable feedback that encourages the authors to expand their analysis and experimentation. This feedback is valuable as it directs the authors to areas that could significantly enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or conduct additional experiments. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by identifying critical areas for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer implies that comparisons to UNets are necessary to clarify this point. While the comment identifies a need for additional comparisons, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons but are not given detailed instructions on how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment further references relevant literature, such as Raonic et al and Gupta et al, to support its claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the source of the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible. The reviewer implies that comparisons to UNets are necessary to clarify this point. The comment references relevant literature, such as Raonic et al and Gupta et al, to support the claim that UNets have shown strong performance on regular gridded domains. This provides some justification for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced literature to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical question about the source of the performance boost claimed by the proposed CoNO model. It questions whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement, suggesting that comparisons to UNets are necessary to clarify this point. The comment also references relevant literature, such as Raonic et al and Gupta et al, to support the claim that UNets have shown strong performance on regular gridded domains. This feedback is clear and actionable, as it directs the authors to conduct comparisons with UNets to better understand the source of the performance boost. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and provides relevant references, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed PSA method, noting that it requires more computation than baselines. It specifically mentions that in Algorithm 1, when feeding forward, the PSA requires the calculation of all the flipped previous layer outputs into the current layer. The reviewer suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the comparison or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the computation complexity of the proposed PSA method and the need for a comparison in the experiment part. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines. It provides a specific example by explaining that in Algorithm 1, when feeding forward, the PSA method requires the calculation of all the flipped previous layer outputs into the current layer. This reasoning is logical and provides a clear basis for the claim. However, the comment could be strengthened by including references or examples from the literature to support the comparison of computation complexity. Overall, the claim is mostly verifiable, as it provides a logical explanation but lacks detailed references or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity, specifically mentioning that in Algorithm 1, the PSA method requires the calculation of all the flipped previous layer outputs into the current layer. This feedback is clear and actionable, as it directs the authors to include a comparison of computation complexity in the experiment part. By addressing this point, the authors can provide a more comprehensive evaluation of their method, which is crucial for readers to understand its practicality and efficiency. However, the comment could be more helpful if it suggested specific metrics or methods for comparing computation complexity. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a comparison of the proposed model\\'s performance with and without each of the two factors mentioned: noise and keeping an exponential moving average. It also implies that the authors should investigate the contribution of the noise part, captured by the \\Pi model, and the gain from using a noise-free exponential moving average. While the comment explicitly states the need for a comparison, it does not provide specific guidance on how to conduct this analysis or what metrics to use. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a comparison of the proposed model\\'s performance with and without each of the two factors mentioned: noise and keeping an exponential moving average. It also implies that the authors should investigate the contribution of the noise part, captured by the \\Pi model, and the gain from using a noise-free exponential moving average. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It claims that it would be beneficial to understand the contribution of each factor individually. The reviewer provides a logical reasoning by suggesting that the \\Pi model captures just the noise part, implying that the gain from using a noise-free exponential moving average should be investigated. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the contribution from the suggestion, which could be challenging without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide a comparison of the proposed model\\'s performance with and without each of the two factors mentioned: noise and keeping an exponential moving average. It also highlights the importance of understanding the contribution of the noise part, captured by the \\Pi model, and the gain from using a noise-free exponential moving average. This feedback is clear and actionable, as it directs the authors to conduct a detailed analysis to better understand the model\\'s components and their individual contributions. By following this advice, the authors can enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what metrics to use. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the figures, such as increasing the font size for certain elements and making the font in Figure 2 larger. It also suggests adding details for comparison with other state-of-the-art Transformer designs, such as epochs and number of parameters, and proposes a \"table\" manner to emphasize the data. These suggestions are explicit and provide concrete guidance on how to enhance the figures and improve the comparison with other designs. The authors know exactly what changes to make to address the feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 1 and 2) and provides detailed suggestions for improvements, such as increasing font sizes and adding details for comparison. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, such as enlarging fonts, adding explanations, and including details for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of suggestions and observations about the figures, including font size, clarity, and comparison with other state-of-the-art designs. These are factual statements and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing font sizes, making certain elements more legible, and adding details for comparison with other state-of-the-art Transformer designs. It also proposes a \"table\" manner to emphasize the data, which could help readers understand the improved accuracy. This feedback is clear and offers concrete suggestions for enhancing the figures and the overall presentation of the paper. However, it could be more helpful if it included additional context or rationale for why these changes are necessary or beneficial. Overall, the comment is mostly helpful as it guides the authors on specific improvements that can be made to enhance the clarity and effectiveness of their figures.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. The reviewer wonders if the CNN could perform reasonably well with less data. While the comment implies that the authors should consider reporting results at different stages of training and potentially explore the performance of the CNN with less data, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. The reviewer also wonders if the CNN could perform reasonably well with less data. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as specific sections or figures where results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about the timing of results reporting and the potential impact of early training, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. The reviewer speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. This is a subjective claim based on the reviewer\\'s assumptions and observations, as it lacks specific evidence or references to support the assertion that the CNN could perform reasonably well with less data. The comment provides some logical reasoning but lacks detailed justification or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. The reviewer also wonders if the CNN could perform reasonably well with less data. While the comment identifies a potential issue with the timing of results reporting and suggests exploring the performance of the CNN with less data, it lacks specific guidance or actionable steps for the authors to address these concerns. The feedback is somewhat helpful as it prompts the authors to consider alternative reporting methods and the impact of early training, but it could be more beneficial with additional detail or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite a sentence that is unclear, providing a specific line number for reference. This is a direct and concrete action, leaving no ambiguity about what needs to be done. The authors know exactly what part of the paper to revise and how to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific line number (\"p. 5, p. 3, l.\") where the sentence is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, namely its lack of clarity, and requests a rewrite. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the meaning of a specific sentence. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific sentence that is unclear and requests the authors to rewrite it. This feedback is clear and actionable, as it directs the authors to a particular part of the paper that needs improvement. By addressing this issue, the authors can enhance the clarity and readability of their work. However, the comment could be more helpful if it provided additional context or explanation about what makes the sentence unclear, which would give the authors a better understanding of the issue. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the context of DocRED, specifically whether the documents are considered as an entire sentence. The comment highlights a gap in the manuscript by noting that this information is missing. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their manuscript. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the context of DocRED, specifically whether the documents are considered as an entire sentence. It points out that this information is missing from the manuscript. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where these concepts are discussed. The comment is specific in detailing what is missing, namely the handling of concepts and the consideration of documents as entire sentences. However, it lacks full grounding as it does not explicitly mention the sections, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the handling of concepts (multiple entity mentions referring to the same entity) in the context of DocRED, specifically whether the documents are considered as an entire sentence. The comment points out that this information is missing from the manuscript, indicating a gap in the explanation or methodology. However, it does not provide any specific reasoning, examples, or references to support the claim that this information is crucial or how it impacts the study. Without additional context or evidence, the authors may find it challenging to understand the significance of this omission. Therefore, the comment is considered borderline verifiable, as it highlights an area for improvement but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises an important question about how the authors handle concepts (multiple entity mentions referring to the same entity) in the context of DocRED, specifically whether the documents are considered as an entire sentence. It points out that this information is currently missing from the manuscript, which is a significant gap that could impact the clarity and comprehensiveness of the paper. By highlighting this omission, the comment provides the authors with a clear direction for improvement, encouraging them to address this issue in their draft. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this information or provided examples of how other studies have handled similar situations. Overall, the comment is mostly helpful as it identifies a critical area for improvement and guides the authors toward enhancing their manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are well-designed and demonstrated, and that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their contribution. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are well-designed and demonstrated, and that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to sections, figures, or specific contributions, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are deemed marginal or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal because the methods used in different stages are well-designed and demonstrated, and that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment lacks specific examples or references to support this claim, such as comparing the contribution to similar work or discussing the novelty of the methods. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are well-designed and demonstrated, and that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not identify particular weaknesses or areas that could be enhanced to strengthen the contribution. Without guidance on how the authors might address this concern or improve their work, the comment is not helpful at all. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It suggests that the performance gain is mostly attributed to PBSD, which is a component related to supervised contrastive learning (DSCL). The reviewer asks for additional motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue or clarify the contribution. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or motivations for the PBSD component. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically questioning the motivation behind the PBSD component. It references the ablation study, which suggests that the performance gain is mostly from PBSD, and asks for additional motivations beyond improving the discriminative power of the learned representation on tail classes. However, the comment does not explicitly mention which section of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the motivation for PBSD. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. The reviewer points out that the performance gain is mostly attributed to PBSD, which is related to supervised contrastive learning (DSCL). The comment suggests that the paper is mostly motivated by DSCL and asks for additional motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. This claim is somewhat verifiable as it provides a logical reasoning based on the ablation study results and the focus on DSCL. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It points out that the performance gain is mostly attributed to PBSD, which is related to supervised contrastive learning (DSCL), but the paper is mostly motivated by DSCL. The reviewer asks for additional motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. This feedback is somewhat helpful as it highlights a specific area of confusion and prompts the authors to clarify their contribution. However, it could be more helpful if it provided suggestions on how to address this issue or offered examples of potential motivations for PBSD. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)-identity tester as well. It specifically mentions a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification on the tester\\'s capabilities. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)-identity tester and provides a specific example of how it might not handle (\u03c0,\u03d5) pairs where \u03d5=\u03d50 but dK(\u03c00,\u03c0) is large. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the tester for the spread parameter, specifically asking if it immediately yields an (\u03f5,\u03b4)-identity tester. It provides a specific example of a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment raises a valid point, it lacks detailed reasoning or references to support the claim. The authors would need to infer the potential issue and address it themselves. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the tester for the spread parameter, specifically asking whether it immediately yields an (\u03f5,\u03b4)-identity tester. It provides a specific example of a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. This feedback is somewhat helpful as it identifies a potential gap in the paper\\'s explanation or testing methodology. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their testing framework. To be more helpful, the comment could include specific recommendations or examples of how to handle such scenarios. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the clarity of the Appendix. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This provides some specificity regarding the parts of the Appendix that were not fully reviewed, but it does not specify what aspects of the Brusselator experiments need further attention or improvement. The comment is fully grounded as it explicitly mentions the Appendix and the Brusselator, allowing the authors to accurately identify the parts of the paper being addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This is a factual statement describing the reviewer\\'s experience and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive Appendix, which is appreciated for providing additional detail about parts of the paper. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback is somewhat helpful as it highlights an area where the authors might want to consider revising or clarifying their Appendix to ensure that all experiments are thoroughly explained. However, the comment lacks specific suggestions or guidance on how to improve the Appendix or which aspects of the Brusselator experiments need further attention. Therefore, it provides some insight but is incomplete, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' claim regarding the use of active learning in step 2. It asks whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This implies that the authors should clarify the distinction between the two methods and ensure that their description does not mislead readers. While the comment identifies an area for clarification, it does not provide explicit instructions on how to address the issue or what specific information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction and potentially revise their description. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This provides clear guidance on what needs to be clarified or corrected in the paper. However, the comment does not explicitly mention which part of the paper discusses this claim, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about using active learning in step 2, suggesting that the \"active learning pipeline\" method might not be the same as traditional active learning. The comment raises a concern about potential misinterpretation by readers and prompts the authors to clarify the distinction. However, it does not provide specific examples or references to support the claim that the methods are different, making it somewhat verifiable. The authors would need to investigate the claim themselves to fully address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This is a valid point that could lead to confusion among readers if not clarified. The comment provides a clear direction for the authors to address by asking for clarification on the distinction between the two methods. However, it could be more helpful if it offered suggestions on how to clarify the description or provided examples of how the methods differ. Overall, the comment is somewhat helpful as it identifies a potential issue and prompts the authors to clarify their description, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific information should be included or how the authors might clarify the distribution. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the distribution is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or what additional information is needed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of concern regarding the detailed distribution of the proposed dataset, which is an important aspect of the paper. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect of their work. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, the comment is barely helpful, as it points out a problem but does not offer a path to resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a self-supervised pretraining approach without annotations could be more appealing. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors are left to infer that they should explore a self-supervised approach but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a self-supervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or where the limitation is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while it provides a suggestion for improvement, it lacks specificity in detailing how the authors might implement a self-supervised approach. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It suggests that a self-supervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that a self-supervised approach would be more appealing. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby restricting its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might implement a self-supervised approach or address the limitation. The feedback is somewhat helpful as it points out a weakness but does not provide actionable steps for improvement, leaving the authors with a general direction but no detailed guidance. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit suggestion that provides a clear direction for the authors to expand their experiments. However, the comment does not specify how the authors should implement this suggestion, such as which specific tasks to consider or how to evaluate the scalability. While the action is explicit, the lack of concrete guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the types of tasks that could be used to demonstrate scalability, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to incorporate this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that continuous control experiments are typically performed on simple and low-dimensional tasks, such as cartpole or mountain car, and recommends demonstrating the scalability of LFF by solving more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, noting the current limitations of the experiments and proposing a way to address them. However, the comment lacks specific examples or references to support the claim about the challenges of higher input dimensionality tasks, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and low-dimensional tasks. It suggests that to fully demonstrate the scalability of the proposed method, LFF, the authors should show its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the credibility of their results. However, the comment could be more helpful if it offered additional guidance on how to design or conduct these more complex experiments. Overall, the comment is mostly helpful as it effectively points out a gap in the current work and offers a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two specific changes: first, to include a statement about the change in linear regions in output space after a citation in the abstract, and second, to provide learning curves for all experiments in an appendix. Both suggestions are explicit and provide clear guidance on what the authors need to do to improve their draft. The feedback is concrete and actionable, as it specifies exactly what needs to be added or included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the abstract by including a statement about the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments in an appendix. This level of detail and specificity helps the authors understand exactly what needs to be addressed and how to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a change in the abstract by recommending the inclusion of a specific statement about the change in linear regions in output space after a citation. It also suggests providing learning curves for all experiments in an appendix. While the comment provides a clear suggestion for improvement, it lacks detailed reasoning or evidence to support why these changes are necessary or beneficial. The claim is somewhat verifiable as it offers a specific suggestion but lacks comprehensive justification or references to substantiate the need for these changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting a change in the abstract to include a statement about the change in linear regions in output space after a citation. This recommendation would help clarify the paper\\'s contribution and enhance its clarity. Additionally, the comment suggests including learning curves for all experiments in an appendix, which would provide a more comprehensive view of the results. This feedback is clear and actionable, offering the authors concrete steps to improve their draft. However, it could be more helpful if it explained why these changes are important or how they would benefit the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the paper\\'s motivation and the applicability of the proposed method. It questions the need for domain adaptation and suggests that demonstrating the methodology on actual tasks involving domain adaptation would be more beneficial. While the comment implies that the authors should provide examples or applications to clarify the motivation and utility of their work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or examples, but the comment lacks specific guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s motivation and the applicability of the proposed method, specifically questioning the need for domain adaptation and suggesting that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. However, it does not explicitly mention which part of the paper this critique is based on, such as a specific section or experiment. The authors can infer that it relates to the introduction or discussion sections, but this inference is not as direct as it could be. The comment is specific in detailing what the authors could do to improve their paper, such as providing examples or applications. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation and applicability of the proposed method, specifically noting the lack of a clear application for domain adaptation. The reviewer suggests that demonstrating the methodology on actual tasks involving domain adaptation would be more beneficial. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the current application is insufficient. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, specifically questioning the motivation and applicability of the proposed method. It points out that the paper demonstrates results mapping one RGB image to another RGB image with a different style, but it does not clarify the need for domain adaptation or how this would be useful in real-world scenarios. The reviewer suggests that demonstrating the methodology on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset, would be more beneficial. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by illustrating the methodology\\'s practical applications. However, the comment could be more helpful if it included examples or references to existing tasks that could benefit from the proposed method. Overall, the comment is mostly helpful as it guides the authors toward enhancing the relevance and applicability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper considers MULT as the only deep learning-based baseline that considers cross-sensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest whether the authors should update their baseline selection, include additional baselines, or address the issue of outdated baselines in their discussion. Without actionable guidance, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper \"MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper considers MULT as the only deep learning-based baseline that considers cross-sensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" This provides clear guidance on what needs to be addressed in the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper considers MULT as the only deep learning-based baseline that considers cross-sensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" The comment provides a reference to MULT, which supports the claim that it is an outdated baseline. However, the comment lacks specific reasoning or evidence to fully substantiate why MULT is no longer relevant or how it impacts the paper\\'s analysis. This makes the claim somewhat verifiable, as it provides some context but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the paper considers MULT as the only deep learning-based baseline that considers cross-sensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" This feedback highlights a potential weakness in the paper\\'s analysis, as it suggests that the authors may be overlooking more recent and relevant baselines. However, the comment does not provide specific suggestions on how the authors might address this issue or improve their analysis by considering newer baselines. While it identifies a gap in the paper, it lacks actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. It provides a clear action for the authors to take, which is to compare the tensor completion results for all the models with the same number of model parameters. The reviewer suggests a method for computing the number of model parameters, which is a concrete step for the authors to follow. This feedback is explicit and provides detailed guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and \"tensor completion results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, namely the omission of the value of the used ranks for all the models, which makes it difficult to make a fair comparison. The comment further suggests a method for computing the number of model parameters, providing a concrete step for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. The reviewer suggests that to show the superiority of TW over TT and TR, the authors should compare the tensor completion results for all the models with the same number of model parameters. This claim is somewhat verifiable as it provides a logical reasoning for the need to include the value of the used ranks and suggests a method for fair comparison. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental comparison, noting that the value of the used ranks for all the models is omitted, making it difficult to make a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all the models with the same number of model parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and fairness of their experimental results. However, the comment could be more helpful if it included specific examples or detailed guidance on how to compute the number of model parameters. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, under the leave-one-out setting. This is an explicit action, as it clearly instructs the authors to include an additional comparison in their analysis. However, the comment does not provide specific guidance on how to implement this comparison or what specific aspects of \"ATA\" should be considered. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison between the proposed method and \"ATA\" in Table 2. The comment suggests that including \"ATA\" in the comparison would make the results more convincing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, under the leave-one-out setting. The reviewer provides a logical reasoning by stating that \"ATA\" is a bit better than \"FP\" according to the results in Table 1, implying that including \"ATA\" in the comparison would make the results more convincing. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the reasoning and potentially conduct additional analyses to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave-one-out setting. It suggests that including \"ATA\" in the comparison would make the results more convincing, given that \"ATA\" is a bit better than \"FP\" according to the results in Table 1. This feedback is clear and actionable, as it provides a specific suggestion for improving the analysis and presentation of results. By addressing this point, the authors can enhance the comprehensiveness and validity of their comparisons, which is valuable for improving the draft. However, the comment could be more helpful if it provided additional context or rationale for why including \"ATA\" would be beneficial. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the normalization module appearing different in the two versions, despite the text suggesting it is the same, and the need for standardization of pictograms in figures. It also mentions a confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE, where the chosen symbols overlap. Additionally, it notes minor textual issues on page 4. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting ways to standardize the pictograms or clarify the text. The actions are implicit and somewhat vague, as the authors need to infer what changes are needed and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4\" and \"pag. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the normalization module, the need for standardization of pictograms, and the confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE. Additionally, it points out minor textual issues on page 4. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and observations. It claims that the normalization module appears different in the two versions but is described as the same in the text. It also suggests that figures are valuable for understanding systems but need standardization of pictograms, and it points out a confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE. Additionally, it mentions minor textual issues on page 4. While the comment provides some logical reasoning and observations, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to infer the exact issues and how to address them, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including a discrepancy between the normalization module in the two versions, the need for standardization of pictograms in figures, and confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE. It also mentions minor textual issues on page 4. While the comment highlights specific areas for improvement, it lacks detailed guidance or suggestions on how to address these issues, such as proposing specific changes to the normalization module or providing examples of how to standardize pictograms. The feedback is somewhat helpful as it points out areas that need attention, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the author\\'s claim regarding the removal of subdivision splines and the potential extra computation cost involved. It questions whether the proposed algorithm is detailed enough to remove these splines and addresses a specific aspect of the theoretical part of the paper. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as it points out a gap in the explanation but does not offer concrete steps for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"theoretical part\" of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it questions the detailed explanation of the proposed algorithm and its potential impact on computation cost. The comment clearly specifies what needs to be addressed, namely, the lack of detailed explanation regarding the removal of subdivision splines and the potential extra computation cost. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the author\\'s claim about the removal of subdivision splines and the potential extra computation cost involved. It highlights a gap in the theoretical explanation of the proposed algorithm, suggesting that the authors should provide more details on how the algorithm removes subdivision splines. The comment is somewhat verifiable as it identifies a specific area where the paper lacks clarity, but it does not provide detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for additional explanation and potential computational implications, which could be clarified with more detailed feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the author\\'s claim about the removal of subdivision splines and the potential extra computation cost involved. It points out a gap in the theoretical explanation of the proposed algorithm, which is a critical area for improvement. By highlighting this concern, the comment provides the authors with a clear direction for enhancing the clarity and comprehensiveness of their theoretical section. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to explain the algorithm\\'s details. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that certain terms, such as W1, W2, W, and V, are not defined in the paper. It suggests that these terms might refer to the Encoder and Decoder networks, but this inference is not explicitly stated. The comment provides a clear indication of what needs to be addressed, which is the definition of these terms. However, it lacks specific guidance on how to define them or where to include the definitions in the paper. While the action is implicit, it is concrete once the authors understand the issue. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper where terms are not defined, such as \"p.3, A4, eq.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the definitions of W1, W2, W, and V. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the absence of definitions for certain terms (W1, W2, W, and V) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a significant issue by pointing out that certain terms, such as W1, W2, W, and V, are not defined in the paper. This lack of definition can lead to confusion for readers and hinder understanding of the paper. The comment is specific in its identification of the terms and provides clear guidance by suggesting that these terms might refer to the Encoder and Decoder networks. However, it could be more helpful if it included suggestions on where to define these terms or how to clarify their meaning within the context of the paper. Despite this, the comment is mostly helpful as it directs the authors to a critical area that needs attention and improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparison with certain baselines is unfair because they lack the prior knowledge of users or any language embedding computation. It implies that a better comparison should be considered. However, the comment does not specify which baselines are being referred to or how to make a better comparison. The action is implicit and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the comparison with certain baselines is unfair because they lack prior knowledge of users or language embedding computation. However, it does not specify which baselines are being referred to or where in the paper these comparisons are made. This lack of explicit reference to specific sections or baselines makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what constitutes a \"better comparison\" or how to achieve it. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison with certain baselines is unfair because they lack prior knowledge of users or any language embedding computation. However, the comment does not provide specific examples of these baselines or detailed reasoning to support why they are unfair. Without such examples or detailed justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the proposed method with certain baselines, suggesting that the baselines lack prior knowledge of users or any language embedding computation. This feedback highlights a possible weakness in the evaluation methodology and suggests that a better comparison should be considered. However, the comment lacks specificity and does not provide detailed guidance on how to make a better comparison or which baselines might be more appropriate. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the paper, including the lack of benefits from output-side layers, unclear illustrations in Figure 4, and the absence of details on Pixel-shuffle. It also questions the use of pixel-shuffle in Figure 2 and the lack of discussion on limitations and societal impact. While the comment identifies areas that need clarification or elaboration, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and observations about the paper, including the lack of benefits from output-side layers, unclear illustrations in Figure 4, and the absence of details on Pixel-shuffle. It also questions the use of pixel-shuffle in Figure 2 and the lack of discussion on limitations and societal impact. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the methodology and results sections, as these are where such details would typically be discussed. The comment is specific in detailing what is unclear or missing, providing a clear direction for the authors to address these issues. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of multiple claims and questions, each requiring verification. The first claim questions the lack of benefits from output-side layers, but it does not provide any reasoning or evidence to support this assertion. The second claim points out that Figure 4 is not clearly illustrated, but it does not specify what aspects are unclear or how they could be improved. The third claim questions the details of Pixel-shuffle and its relation to the super-resolution field, but again lacks specific examples or references to support the critique. The final claim regarding the lack of discussion on limitations and societal impact is a request for additional information, not a claim. Overall, the comment lacks detailed justification or evidence for each claim, making it difficult for the authors to address the issues effectively. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several important points that could help the authors improve their draft. It questions the lack of benefits from output-side layers, which prompts the authors to consider whether this aspect is adequately addressed in their work. Additionally, it points out that Figure 4 is not clearly illustrated, suggesting that the authors should clarify the details of Pixel-shuffle and its relation to the super-resolution field. The comment also questions the use of pixel-shuffle in Figure 2 and the lack of discussion on limitations and societal impact, which are important considerations for any research. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity of the illustrations. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during training. It also asks if alternating between generating negative chips and training the network would improve performance. While the comment highlights an area of uncertainty, it does not provide explicit instructions or suggestions for the authors to address this issue. The authors can infer that they need to clarify the process and potentially experiment with the suggested approach, but the comment lacks concrete guidance on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking if they are fixed or updated during training. It also suggests that alternating between generating negative chips and training the network might improve performance. However, the comment does not specify which part of the paper this process is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but the lack of explicit reference makes it challenging to pinpoint the exact section. The comment is specific in its inquiry about the process and potential impact on performance, but without grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during training. It also asks if alternating between generating negative chips and training the network would improve performance. This is a request for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the process of generating negative chips from a lightweight RPN, specifically asking whether they are fixed or updated during training. It also suggests that alternating between generating negative chips and training the network might improve performance. This feedback is somewhat helpful as it prompts the authors to clarify a critical aspect of their methodology and potentially explore a new approach to enhance performance. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address the issue or conduct the suggested experiment. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct these evaluations or what metrics to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting a particular evaluation, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the study. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients, which is a logical and relevant point for consideration. However, the comment lacks depth and does not provide specific guidance or suggestions on how to conduct these evaluations or what metrics to focus on. While it identifies a potential area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether this dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. While the comment highlights a potential issue, it does not explicitly instruct the authors to clarify or address this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental methodology and address the potential unfair advantage. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental methodology\" and the use of the 300W-LP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the experimental methodology and raises a concern about the potential unfair advantage provided by the use of the 300W-LP dataset. The comment clearly specifies what needs to be clarified or addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether this dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. The comment provides a logical reasoning by pointing out the inconsistency in the experimental setup and its potential impact on the results. However, it lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental methodology, questioning the clarity of the use of the 300W-LP dataset. It points out a potential inconsistency in the experimental setup, as the paper claims to use the same procedure as for the baselines, but most baselines do not use the 300W-LP dataset in their training. This raises a concern about whether the proposed method has an unfair advantage due to the use of this dataset. The comment is clear and actionable, as it prompts the authors to clarify the experimental methodology and address the potential bias. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to ensure a fair comparison. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their techniques. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide details on why these techniques might not be novel or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or improve the novelty of their techniques. Without actionable feedback or guidance, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging, such as summation or population-weighted average. It also mentions that disease incident data are often available in counts or rates per number of residents. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific changes to their formulation. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods and discuss the implications of different data types. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support, but this might not always be the case, as other aggregation methods like summation or population-weighted average could be used. Additionally, it provides context by mentioning that disease incident data are often available in counts or rates per number of residents. This level of detail and specificity helps the authors understand the issue and potential improvements needed in their formulation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the formulation in Equation (1) assumes observations are obtained by averaging over the support, but this might not always be the case. The reviewer provides a logical reasoning by suggesting alternative aggregation methods, such as summation or population-weighted average, and references the availability of disease incident data in counts or rates per number of residents. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific studies or examples where these alternative aggregation methods are used, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging, such as summation or population-weighted average. It also mentions that disease incident data are often available in counts or rates per number of residents, which could impact the formulation. This feedback is somewhat helpful as it points out a specific area where the authors might need to consider alternative aggregation methods or discuss the implications of different data types. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how other studies have handled similar situations. Overall, the comment is somewhat helpful as it prompts the authors to consider potential improvements in their formulation, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks an in-depth analysis of why inverse scaling occurs over compute. It implies that the authors should provide an analysis to explain this training dynamic, which would strengthen the paper. While the comment explicitly states the need for an analysis, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an in-depth analysis of why inverse scaling occurs over compute. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an analysis to explain the training dynamics, which would enhance the paper\\'s solidity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an in-depth analysis of why inverse scaling occurs over compute. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment suggests that an analysis would strengthen the paper, but it lacks specific guidance or examples on how to conduct such an analysis. Without detailed justification or examples, the claim remains unverifiable, as the authors are left without a clear path to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of an in-depth analysis to explain why inverse scaling occurs over compute. It suggests that providing such an analysis would strengthen the paper\\'s solidity. While the comment highlights an important area for improvement, it does not offer specific guidance or suggestions on how the authors might conduct this analysis or what aspects to focus on. This limits the comment\\'s usefulness, as it provides insight but lacks actionable steps for the authors to follow. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a lack of mathematical definition for architectural details, such as multi-head attention, and questions the split arrow in Figure 2. It suggests that the authors provide a formal definition to help readers understand the model better. The comment is explicit in its request for clarification and provides a clear direction for the authors to improve their draft by defining the architectural details. The feedback is concrete and actionable, as it specifies what needs to be addressed and how to do so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right, bottom right,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the split arrow and asking for a formal definition of the architectural details, such as multi-head attention. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of mathematical definition for architectural details, specifically multi-head attention, and asks for clarification regarding the split arrow in Figure 2. The reviewer provides a logical reasoning by suggesting that the split arrow might represent inputs for the attention layer, namely query, keys, and values. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including specific references or examples from the literature to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks mathematical definition, particularly in the architectural details of the model, such as multi-head attention. It questions the split arrow in Figure 2 and suggests that it might represent inputs for the attention layer, asking whether the same vectors are used for keys and values. This feedback is clear and actionable, as it provides a specific area for improvement and offers a logical explanation for what the authors could clarify. By addressing these points, the authors can enhance the comprehensibility of their work for readers. Therefore, the comment is rated as mostly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that each individual\\'s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the validity of this assumption and the application of Theorem 6 to prove Theorem 7. While the comment highlights a potential issue with the proposed algorithm, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or revise the assumption or the application of the theorems. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6\" and \"Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed algorithm, namely the assumption that each individual\\'s data is iid drawn from the same distribution, and questions how Theorem 6 can be applied to prove Theorem 7 without this assumption. The comment provides a clear and detailed critique, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the assumption that each individual\\'s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the validity of this assumption and the application of Theorem 6 to prove Theorem 7. The comment provides a logical reasoning by pointing out the inconsistency between the assumption and the practical reality of users\\' preferences for emojis being different. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to further explore and justify the assumption to address the concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed algorithm, specifically questioning the assumption that each individual\\'s data is iid drawn from the same distribution. It highlights a specific section (Section 5.1) and theorems (Theorem 6 and Theorem 7) where this assumption is crucial for the algorithm to work. The reviewer also provides a rationale for why this assumption might be unjustifiable in practice, noting that users\\' preferences for emojis are likely to be different. This feedback is clear and actionable, as it prompts the authors to reconsider and justify this assumption or explore alternative approaches. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative assumptions or methods. Overall, the comment is mostly helpful, as it directs the authors\\' attention to a critical aspect of their work that requires further justification or revision.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider making the policy non-fixed, which would allow for more complex tasks. It also suggests comparing the results with a reinforcement learning algorithm baseline. While the comment implies an action, it does not provide explicit instructions on how to implement these suggestions, such as which tasks to consider or which reinforcement learning algorithm to use as a baseline. The authors can infer the actions but may find it challenging to execute them without further guidance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It also suggests comparing the results with a reinforcement learning algorithm baseline. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors might infer that it relates to the sections discussing the policy or the experimental setup, but this inference is not direct. The comment is specific in suggesting a way to enhance the complexity of the tasks and the need for a reinforcement learning baseline, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It also suggests comparing the results with a reinforcement learning algorithm baseline. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the tasks could be made more complex or how a reinforcement learning baseline would be beneficial. The suggestion is somewhat verifiable as it provides a logical direction for improvement, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It also recommends comparing the results with a reinforcement learning algorithm baseline. While the comment identifies a potential area for improvement by suggesting a more complex setting, it lacks specific guidance on how to implement this change or which reinforcement learning algorithm to use as a baseline. The feedback is somewhat helpful as it provides a direction for enhancing the study, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments focus primarily on presenting results, with insufficient analysis of the method itself and the experimental outcomes. It also questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more comprehensive analyses and justify their claims. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the focus of the experiments, which is primarily on presenting results, and questions the comprehensiveness of the analysis of the method itself and the experimental outcomes. It also raises concerns about the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in its critique of the analysis and the attribution of performance improvement, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments focus primarily on presenting results, with insufficient analysis of the method itself and the experimental outcomes. It also questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the experiments primarily focus on presenting results rather than comprehensively analyzing the method and its outcomes. It questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. This feedback is valuable as it highlights a potential weakness in the paper\\'s analysis and suggests that the authors should provide more detailed and comprehensive analyses to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions on how to improve the analysis or what additional information should be included. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper primarily focuses on explaining multi-task models, which limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the applicability or what specific changes should be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper primarily focuses on explaining multi-task models, which limits its applicability. However, it does not specify which part of the paper this focus is discussed in, nor does it provide details on how the applicability could be broadened. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of applicability are limited or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper primarily focuses on explaining multi-task models, which limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of applicability are limited or how the focus could be broadened, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper primarily focuses on explaining multi-task models, which limits its applicability. However, it does not provide any specific suggestions or guidance on how the authors might broaden the applicability or address this limitation. Without actionable feedback or detailed advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It suggests that the authors should consider including papers like VR-MARINA and DASHA-MVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. While the comment implies that the authors should expand their literature review to include these papers, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to their literature review. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"next section\" and the \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the literature review, namely the omission of relevant papers like VR-MARINA and DASHA-MVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review ignores several papers that are relevant to the topic, specifically mentioning VR-MARINA and DASHA-MVR. The reviewer provides a specific example of how these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This level of detail supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or references to these papers, which would further enhance the verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It provides examples of papers, VR-MARINA and DASHA-MVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to expand their literature review to include these relevant papers. By doing so, the authors can ensure their work is more comprehensive and up-to-date. However, the comment could be more helpful if it explained why these papers are relevant or how they relate to the current literature. Overall, the comment is mostly helpful as it provides specific guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation of the paper is difficult to follow for the reviewer, but it does not provide any specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined to address the issue. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which parts of the paper are challenging or what aspects need clarification. Without explicit references to sections, figures, or specific content, the authors cannot confidently determine which parts of the paper are problematic. Additionally, the comment lacks specificity regarding what needs to be improved or clarified. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is difficult to follow, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what makes the presentation challenging, the authors may find it difficult to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific details or suggestions on how to improve the clarity or structure of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what needs to be addressed or how to enhance the readability of their work. This lack of specificity and direction makes the comment unhelpful, as it does not offer any meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions: the first asks for additional insights into modest performance gains on Clothing1M, and the second inquires about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix. Both questions are explicit and seek specific information from the authors. However, they do not provide any guidance or suggestions on how the authors should address these questions or what additional information might be relevant. The lack of actionable advice or concrete steps makes it difficult for the authors to know how to respond to these inquiries. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment consists of two questions, each of which seeks additional information or clarification. The first question asks for insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in their requests for additional information, but without clear grounding, the authors may struggle to determine where these inquiries fit into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions seeking additional insights or information. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions seeking additional insights or information. The first question asks for additional insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix. These questions are relevant and could provide valuable context for the authors to enhance their understanding of the performance and applicability of their algorithm. However, the comment lacks actionable feedback or suggestions on how the authors might address these questions or improve their draft. While it prompts the authors to consider these areas, it does not offer guidance on how to incorporate the requested information or insights. Therefore, the comment is somewhat helpful, as it provides some direction but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM and DVBF. It also asks for a comment on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what details should be included or how to present them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM and DVBF. Additionally, it asks for a comment on the computation requirements of the three methods compared in Table 1. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the reviewer is not familiar with the compared models DMM and DVBF but understands their differences with KVAE. The reviewer requests a more detailed presentation of the compared models and asks for a comment on the computation requirements of the three methods in Table 1. While the comment highlights a lack of understanding and requests additional information, it does not provide specific reasoning or evidence to support the claim that a more detailed presentation is necessary. The request for computation requirements is more specific but still lacks detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a clear request for additional information but lacks comprehensive support for the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors provide a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM and DVBF. It also requests a comment on the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their presentation, which can help readers better understand the models and their differences. However, the comment could be more helpful if it provided specific suggestions on how to present the additional details or what aspects of computation should be highlighted. Overall, the comment is mostly helpful as it guides the authors toward improving the comprehensiveness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. While the comment implies that the authors should expand their experimental scope, it does not provide specific guidance on which LLMs to focus on, how to conduct the experiments, or what specific aspects to test. The action is implicit and somewhat vague, as the authors need to infer the details of the suggested experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for additional experiments on specific LLMs, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. The comment provides a logical reasoning for this suggestion, as it highlights the importance of including a broader range of LLMs to ensure comprehensive evaluation. However, it lacks specific examples or references to support the claim that these additional LLMs are necessary or relevant. This makes the claim somewhat verifiable, as the authors would need to further justify the inclusion of these specific LLMs in their experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s experimental scope by suggesting that the authors should include additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. This feedback is somewhat helpful as it points out an area for improvement, encouraging the authors to broaden their experimental evaluation. However, the comment lacks specific guidance on how to conduct these additional experiments or what specific aspects to focus on, which could be more beneficial for the authors. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper should describe the hyperparameters used by each defense and how they are derived. It also suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the description of hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation of defenses, which involves optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on what additional information is needed to enhance the comprehensiveness and rigor of their analysis. By addressing these points, the authors can significantly improve the transparency and robustness of their defense evaluations. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical results\\' lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate these take-away points or whether this observation is indeed novel. The action is implicit and somewhat vague, as the authors are left to infer that they should include more practical implications and clarify the novelty of their findings. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and their practical implications, acknowledging the novelty of the work. It suggests that the paper should include more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not specify which part of the paper discusses these theoretical results or where the authors should include more practical implications. While the authors might infer that it relates to the theoretical sections, the comment lacks full grounding as it does not explicitly mention specific sections or figures. The suggestion is specific in terms of what the authors should consider, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the theoretical nature of the results and their lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific examples or references to support the claim that this observation is novel or lacks practical implications. The reasoning is somewhat logical but lacks detailed evidence or references, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the theoretical nature of the results and their lack of immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper should include more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific guidance on how to incorporate these take-away points or how to make them more practical. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. The authors gain some insight into the need for more practical implications but are left without detailed guidance on how to achieve this. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the purpose of the separators but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for introducing separators and asks for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. However, the comment does not provide any reasoning, examples, or references to support why the introduction of separators is questionable. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the rationale behind the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This feedback is somewhat helpful as it prompts the authors to reconsider the necessity and purpose of the separators, encouraging them to provide a clearer explanation or justification. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. While it identifies a potential area for improvement, it does not provide detailed actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of mean pooling for tokens and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to explore or evaluate other pooling strategies. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling for tokens and suggests considering other pooling strategies. The comment provides a clear direction for the authors to explore alternative approaches, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of mean pooling for tokens and suggests considering other pooling strategies. However, it does not provide any specific reasoning, examples, or references to support why mean pooling might not be the best choice or how other pooling strategies could be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of mean pooling for tokens, suggesting that other pooling strategies could be considered. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples of alternative pooling strategies that could be explored. The comment is somewhat helpful as it prompts the authors to consider other options, but it does not offer detailed suggestions or actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that, in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This comment explicitly states an action for the authors to take, which is to include the real search cost in their comparison. However, it does not provide specific guidance on how to calculate or present this information, leaving some room for interpretation. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost (e.g., in terms of GPU days) in addition to the number of queries. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that, in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is a suggestion for improvement, not a claim or opinion that requires verification. It is a request for additional information to be included in the table, which is a factual statement. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It identifies a particular table (Table 3) and suggests comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This feedback is clear and offers a concrete way for the authors to enhance the comprehensiveness and depth of their analysis. By addressing this suggestion, the authors can provide a more detailed and informative comparison, which is beneficial for the readers. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the understanding of the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information. However, the comment does provide a clear direction on what details are missing, which makes it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the training details of the VQGAN, specifically whether it is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. While the comment is specific in its inquiry, it is not grounded because it does not indicate where in the paper this information should be included. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is consistent with the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the training details of the VQGAN, asking whether it is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a relevant inquiry that could help clarify the methodology and provide important context for the reader. However, the comment does not offer any suggestions or guidance on how the authors might address this question or improve their draft. While it identifies a potential area of concern, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include works such as Li et al. (2017) and He et al. (2015) in their discussion, as these works are relevant to the task-oriented recommendation perspective. It also recommends discussing how the current work differs from other chatbox research works. While the comment implies that the authors should include these references and discussions, it does not provide explicit instructions on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take, such as where to include the references and how to structure the discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the perspective of task-oriented recommendation, allowing the authors to identify the relevant part of the paper. It also specifies what needs to be addressed, which is the inclusion of relevant works such as Li et al. (2017) and He et al. (2015), as well as a discussion on how the current work differs from other chatbox research works. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that works such as Li et al. (2017) and He et al. (2015) are important to include and compare to, as they relate to the task-oriented recommendation perspective. The comment provides specific references to external works, which is a clear and direct way to support the claim. This makes the claim mostly verifiable, as it provides a solid basis for the authors to consider these references in their work. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works relate to the current study, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should include relevant works, such as Li et al. (2017) and He et al. (2015), in their discussion. It also recommends discussing how the current work differs from other chatbox research works, which would help the authors contextualize their contribution within the broader literature. This feedback is clear and provides a concrete direction for the authors to enhance their draft by incorporating relevant references and comparisons. However, the comment could be more helpful if it offered suggestions on how to structure the discussion or integrate these references into the paper. Overall, the comment is mostly helpful as it guides the authors toward improving the comprehensiveness and context of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting ways to improve the methods or explaining why the performance is not generic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS\" and \"MSVD (Table 3),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out that the proposed methods do not perform well on some cross-model retrieval tasks, as evidenced by the performance in MSVD. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, citing the performance in MSVD (Table 3) as evidence. However, the comment does not provide specific details or examples of how the performance is lacking or what aspects of the methods are not generic. This lack of detailed explanation or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3). This feedback is somewhat helpful as it points out a potential weakness in the methods, allowing the authors to consider ways to improve their performance on these tasks. However, the comment lacks depth and does not provide suggestions or guidance on how to address this issue, such as recommending specific changes or improvements to the methods. Therefore, while it highlights a relevant area for improvement, it does not offer actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. While the comment implies that the authors should reconsider their experimental approach, it does not explicitly instruct them to make changes or provide detailed guidance on how to implement the suggested alternative. The action is implicit and somewhat vague, as the authors can infer that they should reconsider their experimental design but are not given specific steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not explicitly mention which part of the paper discusses the experimental setup or results, making it weakly grounded. The authors can infer that it relates to the experimental methodology or results section, but this inference is not direct. The comment is specific in detailing the alternative method and the reasoning behind it, providing clear guidance on how to improve the experimental approach. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the experimental strengths of the proposed approach by suggesting an alternative method that could potentially reach the global minimum. The reviewer provides a logical reasoning by comparing the proposed algorithm to running vanilla Adam on the final network with 40 random initial points. This comparison is based on common knowledge about optimization methods and their properties, such as the ability to reach the global minimum. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct additional analysis to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is somewhat helpful as it provides a different perspective on the experimental design and suggests a potential improvement. However, the comment lacks specific guidance on how to implement the suggested alternative or how to address the concern about the experimental strengths. While it identifies a potential issue, it does not offer detailed actionable steps for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an incomplete study, specifically noting that the relationship between the top selected patches and the disease has not been established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship, what specific steps to take, or what additional analysis or experiments might be needed. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights an issue with the study, specifically noting that the relationship between the top selected patches and the disease has not been established. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how to establish this relationship. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease has not been established. This is a critical observation that highlights a fundamental weakness in the paper, as understanding this relationship is crucial for the validity and applicability of the study. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or suggestions for improvement, the authors are left with a general understanding of the problem but without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point is explicit and provides a clear action for the authors to take: they need to correct the quotation marks in the phrase \"for 'in-between' uncertainty\" to ensure they are forward marks rather than backward marks. This feedback is concrete and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"for \\'in-between\\' uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the quotation marks, providing a precise correction that needs to be made. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding the use of quotation marks in the phrase \"for \\'in-between\\' uncertainty.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly specific and actionable, as it identifies a precise error in the use of quotation marks in the phrase \"for \\'in-between\\' uncertainty.\" By pointing out this error, the comment provides clear guidance on how to correct it, which is crucial for maintaining the accuracy and professionalism of the paper. This level of detail and specificity makes the comment highly helpful, as it empowers the authors to make a direct and immediate improvement to their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to improve the performance of FedSP or explaining why this is relevant to the theme of the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out that the performance of FedSP is not the best on some datasets, providing a clear indication of what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific data or comparisons to other methods, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the performance of FedSP, as it is not the best performer on some datasets, as shown in Tables 1 and 2. However, the comment does not provide any further analysis, suggestions, or guidance on how the authors might address this issue or improve the performance of FedSP. Without actionable feedback or suggestions for improvement, the comment lacks depth and does not offer much value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and suggestions regarding specific aspects of the paper. It explicitly asks why the authors did not specify what Omega is at line 178 and suggests being more explicit about the OMD algorithm and the link function. Additionally, it inquires about the specific theorem in reference [32] that is being referred to for the regret guarantee. These questions and suggestions provide clear and explicit actions for the authors to take, such as specifying Omega, being more explicit about OMD, and clarifying the link function and theorem reference. The feedback is concrete and direct, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the need to specify what Omega is, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to for the regret guarantee. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, such as asking for the definition of Omega, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to. These are factual requests for information or clarification, not subjective claims or opinions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by questioning the lack of clarity in the paper regarding the definition of Omega, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to for the regret guarantee. By asking for clarification on these points, the comment directs the authors to enhance the clarity and specificity of their work. This feedback is clear and constructive, offering the authors a direct path to improve the comprehensibility of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the models are learned directly from pixels without a Markovian state, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this observation should impact the paper or what changes, if any, should be made. Without any actionable suggestions or questions, the authors are left without a clear understanding of how to address this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the models are learned directly from pixels without a Markovian state, but it does not specify which part of the paper this observation is based on. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on why this observation is important or how it affects the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim remains unverifiable, as the authors would not know how to address or understand the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the models are learned directly from pixels without a Markovian state, which is a relevant observation. However, it lacks specificity and does not provide any context or explanation as to why this observation is important or how it affects the paper. Without additional guidance or suggestions for improvement, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer actionable advice or insight into how to improve the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that the authors should provide references to support this claim, which is an explicit and concrete action. By asking for specific references, the authors are given a clear direction on how to address the concern, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular practice mentioned in Example 2, namely the use of the Hamming distance over entire parts of the sequence, which the reviewer claims is not a common approach. The comment further suggests that the authors should provide references to support this claim. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer questions the validity of this approach, suggesting that it is not commonly used and asking for references to support the claim. This request for clarification and references is a logical step to verify the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of why this approach is unusual or problematic. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer questions the validity of this approach and suggests that the authors should provide references to support this claim. This feedback is clear and actionable, as it identifies a potential area of confusion or inaccuracy in the paper and provides a specific request for references to substantiate the claim. By addressing this point, the authors can enhance the credibility and accuracy of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general term \"evaluation.\" It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. While the comment provides a clear action to change the name, it lacks specific guidance on how to integrate the metrics into the text or what specific metrics should be mentioned. The authors know they need to make these changes but may struggle with the execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and implies that the corresponding sections can be removed. It also mentions that the metrics can be briefly mentioned along with the datasets or in the captions of the tables. However, the comment does not specify which sections or tables are being referred to, making it weakly grounded. The suggestion to change the name and remove sections is specific, but without clear references to the parts of the paper being addressed, the authors may find it challenging to implement the changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general term \"evaluation.\" It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. The comment provides a logical reasoning for the change, suggesting that the metrics are well-known and used as standard practice. However, it lacks specific examples or references to support the claim that the metrics are indeed well-known and used as standard practice. This makes the claim somewhat verifiable, as it provides a logical basis but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a change in the name of the \"Evaluation\" element to \"Metrics,\" arguing that \"evaluation\" can have a more general meaning. It also implies that the corresponding sections can be removed and the metrics can be briefly mentioned along with the datasets or in the captions of the tables, as most of the metrics are well-known and used as standard practice. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the clarity and organization of their paper. However, it could be more helpful if it included examples of how the metrics should be integrated into the text or specific references to standard practices. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any explicit or implicit guidance on how the authors should explore this dataset further. There is no indication of what specific aspects of the dataset should be discussed, analyzed, or compared. Without concrete suggestions or examples, the authors are left without a clear understanding of how to address this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should have been included in, such as a specific section or analysis. This lack of explicit reference to a particular part of the paper makes it weakly grounded. The comment is specific in suggesting that the dataset could have been explored more, but without clear guidance on where or how to do so, it remains vague. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could have been integrated into the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on how the authors might explore this dataset further or what aspects of it could be discussed. Without actionable suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement. It provides a specific example of the term \"remarkable\" and offers a suggestion to characterize the improvement more objectively. While the comment explicitly states the action to take, it does not provide detailed guidance on how to achieve this objective, such as suggesting alternative terms or a more detailed explanation of the improvement. Therefore, the comment is mostly actionable, as it clearly identifies the issue but lacks concrete steps for execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific line number, \"[218],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms instead of \"remarkable\" to describe the accuracy improvement. The comment further specifies the issue by pointing out that the improvement is evident but not necessarily remarkable, given the squished axes. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement. The reviewer provides a specific example of the term \"remarkable\" and offers a logical reasoning by pointing out that the improvement is evident but not necessarily remarkable, given the squished axes. This reasoning is clear and provides a basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing examples of more objective terms or references to established practices in the field. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It offers a clear and actionable recommendation by pointing out that the improvement is evident but not necessarily remarkable, given the squished axes. This feedback is valuable as it helps the authors refine their language and presentation of results, making the comment mostly helpful. However, the comment could be more helpful if it included examples of more objective terms or suggestions for how to characterize the improvement more accurately. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the paper\\'s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous state-of-the-art. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"UCF-101\" and \"synthesized results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the paper\\'s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous state-of-the-art. It also highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. However, the comment does not provide detailed reasoning or examples to support these claims, making it somewhat verifiable. The authors would need to further investigate these issues themselves to fully understand and address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the paper\\'s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous state-of-the-art. It highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. However, the comment lacks depth and does not provide specific guidance or suggestions on how to improve the results or address the identified issues. While it points out areas for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that, like most work on pruning, it is not yet possible to realize efficiency gains on GPU. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue or improve the efficiency gains on GPU. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"most work on pruning\" without specifying which part of the paper it addresses, making it difficult for the authors to identify the exact section being referred to. Additionally, it does not provide specific details or examples of what needs to be addressed regarding the realization of efficiency gains on GPU. This lack of grounding and specificity makes it challenging for the authors to understand the basis of the comment and how to address it. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"it is not yet possible to realize efficiency gains on GPU,\" which is a subjective opinion based on the current state of pruning research. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation in the work, noting that, like most work on pruning, it may not yet be possible to realize efficiency gains on GPU. However, the comment lacks specificity and does not provide any actionable advice or suggestions for the authors to address this issue. Without guidance on how to improve the efficiency gains or what specific aspects of the work might be hindering this progress, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the different complexity of the problem. However, the comment does not provide explicit guidance on how the authors should address these issues. It lacks concrete suggestions or actions for improving the evaluation or making it more fair. The authors are left to infer that they need to expand the evaluation to real-world data and consider the complexity of the problem, but without specific instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the numerical evaluation and the comparison with a specific reference, [5], which is mentioned as being designed for a more complex problem. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison with [5], making it weakly grounded. The comment is specific in detailing the issue with the evaluation, namely that it is only on synthetic data and that the comparison is not fair due to the different problem complexity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the different complexity of the problem. The comment provides a logical reasoning for the claim by pointing out the limitations of the evaluation setup and the unfair comparison. However, it lacks specific examples or references to support the claim further, such as detailed comparisons or analyses of the differences in complexity. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the numerical evaluation of the method, noting that it is only evaluated on synthetic data and that the comparison with [5] is not fair due to the different complexity of the problem. This feedback is valuable as it highlights a potential weakness in the paper\\'s evaluation and suggests that the authors should consider expanding their evaluation to real-world data and addressing the unfair comparison. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending additional datasets or methods for comparison. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether studying the number of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32-bit logit should improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to conduct it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this aspect. However, the comment does provide a concrete suggestion about the potential impact of the experiment on strengthening the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does provide some specificity by suggesting that having a 32-bit logit might improve robustness, but it lacks detailed guidance on how to address this question or where to incorporate it into the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. The comment suggests that having a 32-bit logit might improve robustness, but it does not provide any evidence or references to support this claim. The reasoning is based on intuition, which is not sufficient to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it lacks detailed justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises an interesting question about the potential impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32-bit logit might improve robustness, which is a logical inference based on the authors' work. However, the comment does not provide specific guidance or suggestions on how the authors might explore this question or incorporate it into their study. While it identifies a potential area for further investigation, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are left with a general idea but no clear direction on how to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or what specific information should be included in the paper to answer it. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of the method on insurance costs for men and women. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspect of the method or results should be examined regarding insurance costs. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on a specific aspect of the paper, specifically the impact of the method on insurance costs for men and women. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their paper. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential area of interest but does not provide enough direction for the authors to make meaningful improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides a specific example from Foester et al. (2016) to guide the authors in making this distinction. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking for clarification on the difference between meta solvers and centralized RL, where agents share weights. Additionally, it provides a specific reference to Foester et al. (2016) to guide the authors in making this distinction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers are centralized controllers and suggests that the authors clarify the difference between these solvers and centralized RL where agents share weights. The reviewer supports this claim by referencing Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016, which provides a specific example of a related work. This reference helps substantiate the claim and provides a clear basis for the authors to understand and address the issue. Therefore, the comment is mostly verifiable, as it offers a logical reasoning and a specific reference to support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this difference, providing a specific reference to Foester et al. (2016) as an example of related work. This feedback is clear and actionable, offering a concrete suggestion for improvement that can help the authors clarify their work and enhance its clarity. By providing a specific reference, the comment guides the authors on how to address the issue, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s methodology, specifically the use of publication years from the ACL anthology to categorize papers. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for categorization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their categorization method but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with categorizing papers based on their publication years on the ACL anthology, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the problem by pointing out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s categorization of papers based on their publication years on the ACL anthology is problematic because many papers are available on arXiv much earlier. It provides a specific example, such as the BERT paper, to support this claim. This level of detail and reference to a specific example makes the claim mostly verifiable, as it provides a clear basis for the critique. However, the comment could be strengthened by providing more examples or additional context to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s categorization method, specifically the use of publication years from the ACL anthology to categorize papers. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. This feedback is somewhat helpful as it highlights a specific area where the categorization might be misleading, prompting the authors to reconsider their methodology. However, the comment could be more helpful if it provided suggestions on alternative categorization methods or how to address this issue. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a potential flaw in their categorization approach but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the notation used for M_T is not clear and recommends providing examples to explain it. This feedback is explicit and provides a clear action for the authors to take, which is to include examples to clarify the concept of M_T. The suggestion is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the notation used for M_T is not clear and suggests providing examples to explain it. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation used for M_T is not clear and suggests providing examples to explain it. However, the comment does not provide any specific reasoning or examples to support why the notation is unclear or how examples would clarify the concept. Without additional context or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used for M_T, suggesting that it is not clear and could be improved by providing examples. This feedback is actionable as it directs the authors to clarify their notation and potentially enhance the comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to present the examples or what aspects of M_T need clarification. Despite this, the comment is mostly helpful as it points out a clear area for improvement and offers a direction for the authors to enhance their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main issues. First, it questions the authors\\' choice of using a relaxation of rejection sampling instead of directly using Importance sampling. This implies that the authors should provide a justification for their approach. Second, it points out a lack of understanding regarding the difference between QRS and RS in Algorithm 1, suggesting that the authors should clarify how these methods differ and provide an example where they behave differently. Both comments are explicit in their requests for clarification and justification, and they provide concrete guidance on how the authors can address these issues. Therefore, the comments are highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the reviewer\\'s lack of understanding regarding the difference between QRS and RS and the need for an example where they behave differently. Therefore, this comment is labeled as fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions the authors\\' choice of using a relaxation of rejection sampling instead of directly using Importance sampling, without providing any justification or evidence for why this choice is problematic. The second part raises a question about the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide an example where these methods behave differently. However, the comment lacks specific reasoning or references to support the claim that Importance sampling should be used instead of the proposed relaxation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two distinct points. First, it questions the authors\\' choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their approach. This feedback is somewhat helpful as it prompts the authors to clarify their reasoning, but it lacks specific guidance on how to improve the explanation. Second, the comment points out a lack of understanding regarding the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide an example where these methods behave differently. This is a clear and actionable suggestion that could help the authors clarify their methodology. Overall, the comment provides some helpful feedback but could be more comprehensive and detailed to fully support the authors in improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this observation. There is no guidance on how to refine the work or what specific aspects could be improved upon. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects could be refined or improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how to improve the performance enhancements. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the observed performance enhancements are modest, suggesting that there is room for further refinement. However, the comment lacks specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the modest performance enhancements observed in the paper, suggesting that there is room for further refinement in the future. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might improve their work. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their draft need refinement or how to achieve better performance enhancements. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide references for specific passages in Section 3.2 and to clarify what \"MLP\" stands for in Figure 2. These are clear and direct actions that the authors can take to improve their draft. The feedback is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections (3.2, lines 230-234 and 234-235) and a figure (Figure 2), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for references and clarification of \"MLP.\" Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification, such as asking for references and clarification of \"MLP.\" It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback. It identifies two areas where references are needed, which is crucial for establishing the credibility and context of the paper. Additionally, it asks for clarification on the term \"MLP,\" which could be a critical concept in the paper. By addressing these points, the authors can enhance the clarity and rigor of their work. The comment is clear and direct, offering concrete steps for improvement, making it highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experimental results on the last two datasets, suggesting that the performance is similar to IRM and questioning whether this is due to the issues mentioned earlier. However, it does not provide explicit guidance on how the authors should address these concerns or improve their experimental results. The comment lacks actionable details, such as suggesting specific analyses or modifications to enhance the experimental validation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the last two datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that they are not convincing enough to validate the effectiveness of the proposed method due to similarities with IRM. The comment raises a question about whether this similarity is caused by the issues mentioned earlier. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. The reviewer questions whether this similarity is due to the issues mentioned earlier. However, the comment lacks specific examples or detailed reasoning to support the claim that the performance is similar to IRM or to explain why the results are not convincing. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the performance on the last two datasets is not convincing enough to validate the effectiveness of the proposed method. It suggests that the performance is similar to IRM, which raises questions about whether this similarity is due to the issues mentioned earlier. However, the comment lacks actionable guidance or suggestions on how the authors might address this concern or improve their experimental validation. Without specific advice or examples, the feedback is somewhat helpful as it points out a potential issue but does not provide a clear path for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this question, modify their approach, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to respond. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between detecting both entities and just knowing the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the necessity of detecting both entities in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. This is a valid point that prompts the authors to reconsider the relevance and importance of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks empirical validation and suggests that experiments validating the bounds should be included. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks empirical validation and requests experiments to validate the bounds. However, it does not specify which part of the paper this lack of validation pertains to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its request for empirical validation, but without clear grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks empirical validation and suggests that experiments validating the bounds should be included. However, the comment does not provide any specific examples, reasoning, or references to support why empirical validation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of empirical validation. It suggests that the authors should include experiments to validate the bounds, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on what types of experiments or validation methods might be appropriate. Despite this, the feedback is still valuable as it directs the authors to a critical area for improvement in their draft. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This comment is explicit in its request for clarification, as it directly asks for an explanation of the phrase. However, it does not provide any guidance on how the authors should address this confusion or clarify the terminology. The action is explicit but lacks concrete details on how to implement the clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"non-sequential information such as chunks\" and asks for clarification on whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks,\" specifically asking whether \"chunk\" is still considered sequential information. This is a clear and direct question that prompts the authors to clarify a potential ambiguity in their work. By addressing this question, the authors can ensure that their terminology is consistent and understandable to readers. However, the comment does not provide any additional context or suggestions for improvement beyond the clarification request. While it is a useful prompt for the authors to clarify their terminology, it lacks depth and does not offer broader guidance on how to enhance the draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a discrepancy between Equation 9 and Figure 1, suggesting that the output patches are not cropped parts of the input image but masked versions of the input image with most pixels being black. It questions the correctness of this interpretation and points out that Figure 1 might be misleading. The reviewer also poses a question about whether bilinear sampling could provide better results. While the comment highlights an issue and raises questions, it does not provide explicit instructions or concrete suggestions for the authors to address the discrepancy or improve the figure. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and potentially revise the figure. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the equation and the figure, questioning whether the output patches are cropped parts of the input image or masked versions. Additionally, it raises a question about the effectiveness of bilinear sampling for zooming on the region of interest. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between Equation 9 and Figure 1, suggesting that the output patches are not cropped parts of the input image but masked versions of the input image where most pixels are black. The reviewer questions the correctness of this interpretation and points out that Figure 1 might be misleading. The comment also poses a question about whether bilinear sampling could provide better results. While the comment identifies a potential issue, it lacks specific evidence or references to support the claim about the discrepancy or the suggestion regarding bilinear sampling. This makes the claim somewhat verifiable, as it provides a logical basis for the concern but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Equation 9 and Figure 1, suggesting that the output patches are not cropped parts of the input image but masked versions of the input image where most pixels are black. This observation raises a concern about the accuracy and clarity of the figure, which could be misleading. The comment also poses a question about whether bilinear sampling could provide better results, offering a potential direction for improvement. While the comment highlights an important issue and provides some guidance, it lacks specific suggestions or detailed instructions on how to address the discrepancy or improve the figure. Therefore, it is somewhat helpful, as it points out a problem but does not fully guide the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or clarify the exception. The action is implicit, as the authors need to infer that they should provide an explanation for this exception, but it is vague because it lacks concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound when there is a separate node with 0 neighbors, and it seeks an explanation for this exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the upper bound is not true. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. This feedback is somewhat helpful as it identifies a potential issue with the theorem and prompts the authors to consider and address this exception. However, the comment lacks depth and does not provide specific guidance on how to resolve the issue or explain the exception. To be more helpful, the comment could include suggestions on how to clarify or refine the theorem to account for this exception. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graph-based approaches, the idea, co-attention mechanism, and architecture of the current paper are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty of their work but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of limited technical novelty by comparing the current paper with two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graph-based approaches, the idea, co-attention mechanism, and architecture of the current paper are similar. However, the comment does not specify which sections of the paper these comparisons should be made in, making it difficult for the authors to pinpoint the exact parts that need revision. The comment is specific in identifying the issue of limited novelty but lacks grounding as it does not explicitly mention the sections of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graph-based approaches, the idea, co-attention mechanism, and architecture of the current paper are similar. This claim is somewhat verifiable as it provides a basis for comparison with specific references, allowing the authors to understand the context of the critique. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current paper lacks novelty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s technical novelty, noting that it is similar to two previous works (Xing and Tsang, 2022a, b) despite focusing on graph-based approaches. This feedback is somewhat helpful as it alerts the authors to a possible lack of originality in their work. However, the comment lacks specific guidance on how the authors might address this issue or differentiate their work from the previous studies. Without actionable suggestions or detailed feedback, the authors may struggle to effectively improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the statement about the training time reduction on page 5 should be deleted because it is not revisited in the Discussion section. The comment explicitly instructs the authors to delete the word \"Discussion,\" providing a clear and direct action. This makes the comment highly actionable, as the authors know exactly what to do to address the feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pg.5\" and the specific phrase \"The training time reduction is less drastic than the parameter reduction because most gradients are still computed for early down-sampling layers (Discussion).\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies that the statement about the training time reduction should be deleted because it is not revisited in the Discussion section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a statement on page 5 regarding training time reduction should be deleted because it is not revisited in the Discussion section. The comment provides a specific reference to the text on page 5, which allows the authors to verify the claim. However, it does not offer additional reasoning or evidence to support why the statement should be deleted or how it affects the overall discussion. This makes the claim somewhat verifiable, as it lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that a statement on page 5 regarding training time reduction is not revisited in the Discussion section. It suggests that the word \"Discussion\" should be deleted, providing a clear and actionable piece of feedback. This feedback is valuable as it helps the authors refine their draft by ensuring that all statements are relevant and consistent throughout the paper. However, the comment could be more helpful if it provided additional context or explanation about why the statement is not relevant in the Discussion section. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction. It also asks for an explanation if the problem is specific to binding affinity prediction. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what additional information should be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspect of the problem needs clarification or why it is relevant. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. This is a valid point that could lead to a deeper understanding of the paper\\'s scope and relevance. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this question or improve their draft. Without actionable feedback or additional context, the comment offers limited value to the authors in terms of improving their work. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a gap in the analysis regarding the detection of rumors generated by GPT, suggesting that further analysis or solutions should be proposed. It questions why GPT-generated rumors are as difficult to detect as natural rumors, given that both are written by humans. However, the comment does not provide explicit guidance on how to conduct this analysis or propose solutions. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this aspect further but without concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by questioning the analysis of why GPT-generated rumors are as difficult to detect as natural rumors, and it suggests that further analysis or solutions should be proposed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks analysis on why GPT-generated rumors are as difficult to detect as natural rumors, despite both being written by humans. The reviewer questions the experimental results that show natural rumors being the easiest to detect. This claim is somewhat verifiable as it highlights a gap in the analysis and suggests a potential area for further exploration. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the analysis regarding the detection of rumors generated by GPT, specifically questioning why GPT-generated rumors are as difficult to detect as natural rumors. It points out that the paper lacks an analysis of why this is the case, despite both being written by humans. This feedback is clear and actionable, as it prompts the authors to explore this aspect further and potentially propose solutions or additional analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this analysis. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or additions are needed to enhance the technical contribution. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, it does not specify which part of Section 4 is being referred to, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the lack of formal and principled solutions, but it lacks grounding as it does not explicitly mention the section or subsection being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. While it identifies a potential weakness in the paper, it lacks actionable feedback or suggestions for improvement. The comment does not provide guidance on how the authors might enhance the technical contribution or address the issue of relying on heuristics. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the font size in Figure 6 is a bit small, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the font size should be increased, how much it should be increased, or if there are any specific considerations for the figure. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the font size in Figure 6 being small. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective elements. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment points out a specific issue with the font size in Figure 6, indicating that it is a bit small. While this feedback is relevant and identifies a potential issue with the figure's readability, it lacks depth and does not provide any suggestions or guidance on how to address the issue. The comment does not offer actionable advice, such as recommending a specific font size or providing context on why this might be a problem. As a result, the feedback is somewhat helpful, as it highlights a concern but does not fully support the authors in making improvements to their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses regret that the probability mass function is not fully exploited in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific probability mass functions should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions but without concrete steps or examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is not fully exploited and suggests considering various probability mass functions to add depth to the experimental setting. However, the comment lacks specific examples or detailed guidance on how to implement this suggestion, making it somewhat specific. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the quasi-uniform distribution used in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that different probability mass functions would be beneficial. The suggestion is somewhat verifiable, as it provides a logical reasoning for considering different distributions, but it lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the probability mass function is not fully exploited. It points out that the quasi-uniform distribution used in MixBoost is based on a single parameter, which may limit the depth of the experimental setting. The reviewer provides a logical suggestion to consider various probability mass functions, which could add depth to the analysis. However, the comment lacks detailed guidance on how to implement this suggestion or specific examples of alternative probability mass functions that could be considered. While it highlights a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in the comparison or what steps to take to improve the draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what aspect of the comparison is unfair or how it should be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. The comment lacks specific examples or detailed analysis to substantiate the claim, making it difficult for the authors to understand the basis of the question. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. While it identifies a potential issue with the comparison, it does not provide any actionable guidance or suggestions for the authors to address this concern. The comment lacks depth and does not offer any specific advice on how the authors might improve their draft to resolve the issue of fairness in the comparison. As a result, the feedback is barely helpful, as it points out a potential problem but does not assist the authors in making meaningful improvements to their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include references to specific works, particularly [a], which uses supervised learning in QBF solving. It also suggests discussing connections between the paper and [a], which uses QBF to generalize SMT. The comment provides clear and concrete actions for the authors to take, such as discussing the relevance of [a] and its implications for the paper. This level of detail ensures that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the references that are missing, allowing the authors to accurately identify the part of the paper that needs attention. It also specifies what is missing by suggesting the inclusion of references to [a], which uses supervised learning in QBF solving. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain references are relevant to the topic and suggests discussing connections with a specific reference, [a]. However, it does not provide detailed reasoning or examples to support why these references are relevant or how they should be integrated into the paper. The mention of [a] and its use of supervised learning in QBF solving is a vague reference that lacks specific details or context. Without further explanation or examples, the claim is difficult for the authors to understand and act upon, making it barely verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic. It suggests discussing connections with a particular reference, [a], which uses supervised learning in QBF solving. This feedback is clear and actionable, as it provides a concrete step for the authors to take to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included a brief explanation of why these references are important or how they relate to the paper\\'s content. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement but could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors need to infer that they should investigate other relationships and explain their findings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"mono tonic relationship\" and \"the degree of a single-task predictor participation,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific suggestion to explore alternative relationships and explains the potential benefit of doing so. However, the comment could be more specific by elaborating on why the mono tonic relationship is important or how it affects the results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss can be replaced by other relationships. The reviewer suggests that explaining this point may be beneficial. However, the comment lacks specific examples or references to support the claim that other relationships could be explored. The inclusion of a reference to a paper by Navon et al. provides some context but does not directly address the question posed. Therefore, the claim is somewhat verifiable, as it provides a basis for exploration but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and encourages the authors to explain this point further. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might explore alternative relationships or what specific aspects of the explanation could be improved. The feedback is somewhat helpful as it prompts the authors to consider a different approach, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to focus on. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison should be included in or what specific aspects need to be addressed. The authors cannot confidently determine which section of the paper this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on what aspects of computation cost or running time should be compared or how this comparison should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the comparison of computation cost or running time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect of the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific comparisons should be made. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms such as Hogwild. This is an explicit suggestion that provides a clear direction for the authors to improve their draft. However, the comment does not specify how the authors should implement this suggestion or provide detailed guidance on which specific problems to focus on. While the action is explicit, it lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the examples chosen do not convincingly demonstrate the need for inter-process communication, particularly regarding sampling-based Bayesian methods. The comment further provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the examples in the paper do not convincingly demonstrate the need for inter-process communication, particularly regarding sampling-based Bayesian methods. The reviewer suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion. This makes the claim somewhat verifiable, as the authors would need to further develop the reasoning to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction, noting that the examples provided do not convincingly demonstrate the need for inter-process communication, particularly regarding sampling-based Bayesian methods. It suggests that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by selecting more relevant examples and focusing on specific problem areas. However, the comment could be more helpful if it included additional suggestions or examples of how to address the issue. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the privacy preservation of the proposed approach compared to other federated learning approaches and questions the relevance of using traffic signal control as an example. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these questions or improve their draft. Without actionable suggestions or a clear direction for revision, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the privacy preservation of the proposed approach compared to other federated learning approaches and questions the relevance of using traffic signal control as an example. However, it does not specify which part of the paper discusses these issues, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not refer to specific sections, figures, or tables. Additionally, while it raises specific questions about the approach and its application, it does not provide detailed guidance on how to address these concerns. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of questions and observations about the privacy preservation of the proposed approach and the relevance of using traffic signal control as an example. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions the relevance of using traffic signal control as an example, suggesting that it might not be a suitable application for federated learning. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It identifies potential weaknesses but does not guide the authors on how to address them or enhance their draft. As a result, the comment is barely helpful, as it points out areas for consideration but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of the innovative pre-training module design of CPEF. This feedback provides a clear and direct action for the authors to take, ensuring fairness in the comparison. The suggestion is concrete, as it specifies which model should be used for comparison, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529-lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely the unfairness of comparing CPEF with PMEF, and provides a recommendation to compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Figure 3 is unfair because PMEF lacks a pre-training module, which is a key advantage of CPEF. The reviewer suggests comparing CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of the innovative pre-training module design. This claim is mostly verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a specific alternative model for a fairer comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the pre-training module design of CPEF is innovative. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison in Figure 3, where the authors compare CPEF with PMEF to demonstrate the advantages of the pre-trained question representation model under data scarcity conditions. The reviewer points out that this comparison is unfair because PMEF lacks a pre-training module, which is a key advantage of CPEF. The comment provides a clear and actionable suggestion to address this issue by recommending a comparison with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This feedback is highly helpful as it not only identifies a weakness in the current comparison but also offers a concrete solution to improve the fairness and clarity of the analysis. By following this advice, the authors can enhance the validity and impact of their findings.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is an explicit statement that clearly directs the authors to check and fix the hyperlinks. The action is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue of broken hyperlinks, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the functionality of hyperlinks in the paper, specifically noting that footnotes 3 and 4 do not seem to work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is straightforward and identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address by checking and fixing the hyperlinks. However, the comment does not provide any additional context or suggestions on how to troubleshoot or prevent similar issues in the future. While it is a useful observation, it lacks depth and does not offer comprehensive guidance for improvement. Therefore, the comment is somewhat helpful, as it provides a clear direction for the authors to take action but lacks broader insights or suggestions for enhancement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. However, the concrete suggestions on what needs to be improved provide a clear direction for the authors to follow. Therefore, the comment is mostly actionable, as it provides a concrete action but does not explicitly instruct the authors to make the changes.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. This provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the modeling section is unclear, making it weakly grounded. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding regarding the role of Label Embeddings, which is addressed by suggesting a revision. This feedback is mostly verifiable as it provides clear and specific suggestions for improvement, but it could be strengthened with additional examples or references to support the claim about the current clarity of the discussion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of the discussion in the modeling section. It provides a concrete suggestion to revise the discussion, particularly in section 2, by formalizing the architecture and clarifying the role of Label Embeddings. This feedback is actionable and offers a clear direction for the authors to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included additional details or examples on how to improve the formalization or clarification. Overall, the comment is mostly helpful as it provides valuable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the neural network in Section 528 is hard to understand and recommends starting the section with the final paragraph, which is clearer. This feedback provides a clear and explicit action for the authors to take, which is to restructure the section to improve clarity. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the readability of the section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, noting that it is hard to understand but becomes clearer in the final paragraph. The comment provides a clear suggestion to start the section with the final paragraph, which offers a concrete way to improve the clarity of the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network in Section 528 is hard to understand but becomes clearer in the final paragraph. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable, as it lacks sufficient evidence or justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network in Section 528, noting that it becomes clearer in the final paragraph. It provides a clear and actionable suggestion to improve the draft by recommending that the authors start the section with the final paragraph, which is clearer. This feedback is valuable as it directs the authors to a specific area for improvement and offers a concrete solution to enhance the readability of their work. However, the comment could be more helpful if it provided additional context or examples of what makes the final paragraph clearer. Overall, the comment is mostly helpful, as it offers actionable guidance that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attention-based encoder-decoder training. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance or suggestions on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attention-based encoder-decoder training. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its suggestion to explore attention-based training, but without clear grounding, it is challenging for the authors to determine where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attention-based encoder-decoder training. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or how it might impact the model\\'s performance. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attention-based encoder-decoder training. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might explore this possibility or what specific changes could be made to the model. The comment is somewhat helpful as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the division of tables into three types in Section 3, specifically questioning whether the column header should suffice as one type. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should clarify the division, revise the table structure, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the division of tables into three types and suggests that the column header should suffice as one type. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the division of tables into three types, specifically questioning whether the column header should suffice as one type. However, it does not provide any supporting evidence, reasoning, or examples to justify why the column header should be sufficient. The comment lacks detailed explanation or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the division of tables into three types, specifically questioning whether the column header should suffice as one type. While it identifies a potential area of confusion or inconsistency in the paper, it lacks depth and does not provide any actionable suggestions or guidance for the authors to address this issue. The comment does not offer specific advice on how to clarify or improve the table structure, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the attack methods used in the paper are considered naive and suggests that other classical attack methods in NLP should be considered. However, it does not provide specific guidance on which classical attack methods should be used or how to incorporate them into the paper. The comment implies that the authors should explore additional attack methods, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the attack methods used in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the attack methods are considered naive and suggests that other classical attack methods in NLP should be considered. The comment provides specific examples of papers that could be referenced for alternative attack methods, which adds further clarity and specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of papers that could be referenced for alternative attack methods, which helps to substantiate the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current attack methods are insufficient or ineffective. Overall, the claim is mostly verifiable, as it provides some support but lacks comprehensive evidence or detailed justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper by pointing out that the attack methods used are considered naive. It suggests that other classical attack methods in NLP should be considered, particularly in the context of the toy setting with classification tasks. The comment provides specific examples of papers that could be referenced for alternative attack methods, which is a valuable contribution. However, the comment could be more helpful if it offered a more detailed analysis of why the current attack methods are insufficient or how the suggested methods might improve the paper. Despite this, the feedback is mostly helpful as it directs the authors to consider broader attack methods and provides a starting point for further exploration. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue, such as suggesting ways to mitigate the impact or improve the image quality. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"mitigation methods\" and \"image generation capabilities of diffusion models,\" but it does not specify which part of the paper these issues are discussed in. This makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the image generation capabilities are affected or how the mitigation methods lead to lower image quality. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.\" However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they may affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue or improve the image quality. Without detailed guidance or examples, the authors are left without a clear understanding of what steps to take to resolve the problem. Therefore, the comment is barely helpful, as it highlights a potential concern but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to mitigate the potential issues. The feedback is implicit and lacks concrete details on how to implement changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper discusses this issue or where the prior knowledge is incorporated, making it weakly grounded. The comment is specific in detailing the potential issue of unfairness due to the leakage of additional information from the pretrained visual model and target dataset. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered borderline verifiable, as it provides a general concern but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue of unfairness resulting from the leakage of additional information from the pretrained visual model and target dataset. This feedback is somewhat helpful as it identifies a critical area that the authors need to address to ensure the integrity of their comparisons. However, the comment lacks specific suggestions or guidance on how the authors might mitigate these concerns or ensure fairness in their comparisons. To be more helpful, the comment could include recommendations or examples of how to address this issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further analysis, clarification, or improvement. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps, if any, they should take in response to this observation. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise at the dominance of function words over content words in a Japanese sentence. However, the comment does not provide further details or suggestions on how to address this observation, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this observation. The comment lacks specific examples or explanations that would help the authors understand the basis of the surprise or how this observation relates to the paper\\'s content. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issue or improve their work.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any further context, analysis, or suggestions for improvement. It lacks depth and does not offer actionable feedback or guidance for the authors to address this observation or its implications. As a result, the comment is not helpful at all, as it does not provide any value to the authors in terms of improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use the minimal k-means objective over multiple seeds as a baseline instead of the average of k-means objectives with multiple seeds. The comment provides specific references to support this suggestion, which is a concrete action for the authors to take. The references offer a clear direction on how to implement the suggested change, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the average of k-means objectives with multiple seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using the minimal k-means objective over multiple seeds as a more reasonable baseline, providing a clear and actionable suggestion. The comment further supports this suggestion with references to relevant literature, which enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the average of k-means objectives with multiple seeds is not a suitable baseline and proposes using the minimal k-means objective instead. This claim is supported by references to two external works that provide evidence and reasoning for the suggestion. The references offer specific examples and arguments, making the claim fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by proposing a more reasonable baseline for the k-means objectives. It references two external works that support the suggestion, offering a clear and actionable direction for the authors to enhance their draft. The inclusion of references adds credibility to the suggestion, making it highly helpful for the authors to consider and implement. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the task is closer to Argument Mining rather than Summarization and recommends that the paper should clarify the differences against Argument Mining/Discussion Summarization. While the comment implies that the authors should clarify the task\\'s distinction from these related areas, it does not provide specific guidance on how to make these clarifications or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the task is closer to Argument Mining rather than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its suggestion to clarify the differences, but it lacks grounding as it does not identify a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the task is closer to Argument Mining rather than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the task is closer to Argument Mining rather than Summarization and recommends that the paper should clarify the differences against Argument Mining/Discussion Summarization. This feedback is somewhat helpful as it points out a potential misalignment between the task and its categorization, which could lead to confusion for readers. However, the comment lacks specific guidance on how to clarify these differences or what aspects of the paper need to be revised. While it provides a direction for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It suggests that the authors clarify this point by explaining the role of H in uncertainty calibration and how it relates to temperature calibration. Additionally, it points out a potential contradiction in the paper regarding the effect of reducing entropy, which is against the paper\\'s motivation to calibrate networks. While the comment identifies specific areas for clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the relationship between uncertainty and temperature calibration and reconcile the contradiction regarding entropy reduction. However, the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (155-160) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relationship between uncertainty and temperature calibration, particularly regarding the regularization term H. The comment further clarifies the confusion by pointing out a potential contradiction in the paper regarding the effect of reducing entropy. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. The reviewer provides a detailed explanation of the apparent contradiction, referencing specific lines in the paper (155-160) to support their claim. This level of detail and reference to specific sections of the paper makes the claim mostly verifiable, as it provides a clear basis for the authors to address the issue. However, the comment could be strengthened by including additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It points out a contradiction in the paper, where reducing entropy is suggested to make predictions more confident, which is against the paper\\'s motivation to calibrate networks. The comment provides clear and actionable feedback by asking the authors to clarify this point and reconcile the apparent contradiction. This guidance is valuable as it directs the authors to address a specific issue that could impact the clarity and coherence of their work. However, the comment could be more helpful if it offered suggestions on how to resolve the contradiction or provided additional context. Overall, the comment is mostly helpful, as it effectively highlights a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of including a reference to the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, and place itself in an appropriate context. While the comment implies that the authors should include this reference and discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to integrate this reference or discussion into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the idea of unrolling, which is closely related to the paper, and references the work of Lista by Yann LeCun. This allows the authors to accurately identify the part of the paper being addressed, specifically the context and positioning of their work. The comment is also specific because it clearly specifies what is missing, namely a reference to the idea of unrolling and a discussion of the similarities and differences between the proposed work and Lista. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. The reviewer provides a direct reference to the Lista paper, which supports the claim by offering a specific source for the idea of unrolling. This level of detail and reference makes the claim fully verifiable, as it provides a clear and direct link to the missing reference. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, namely the lack of reference to the idea of unrolling, which was first proposed in the Lista paper by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and Lista, as well as placing the paper in an appropriate context. This feedback is clear and actionable, as it directs the authors to include a reference to Lista and to discuss the context of their work. By addressing this omission, the authors can enhance the comprehensiveness and context of their paper. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference or discussion into the paper. Overall, the comment is mostly helpful, as it identifies a critical gap and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain the linear program in Theorem 3 intuitively, noting that it would be beneficial for the reader. The comment provides a clear and direct action for the authors to take, which is to explain the objective and constraints in (3). This feedback is specific and actionable, as it guides the authors on what aspect of their work needs further clarification. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for an intuitive explanation of the linear program in Theorem 3, including the objective and constraints in (3). This provides clear guidance on what the authors should focus on to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the linear program in Theorem 3 should be explained intuitively, noting that it would help the reader understand the objective and constraints. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by requesting an intuitive explanation of the linear program in Theorem 3. It highlights the importance of clarifying the objective and constraints in (3), which would enhance the reader\\'s understanding of the theorem. This feedback is specific and constructive, offering a direct way for the authors to improve the clarity and accessibility of their work. However, it could be more helpful if it included additional guidance on how to present this explanation or suggested specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined, providing a clear and direct action for the authors to take. The comment specifies exactly what needs to be addressed, which is the definition of the FLOT cost matrix in Algorithm 1. This makes the action highly actionable, as the authors know precisely what step to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of definition for the FLOT cost matrix. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement that the FLOT cost matrix in Algorithm 1 is not defined. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and direct, pointing out a specific issue with the paper: the FLOT cost matrix in Algorithm 1 is not defined. This feedback is actionable as it identifies a clear gap in the paper that needs to be addressed. By specifying the exact element that is missing, the comment provides the authors with a concrete step to take to improve their draft. However, it could be more helpful if it suggested how the authors might define the FLOT cost matrix or provided examples of similar definitions in related work. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), when T goes to infinity. It compares this bound to a similar bound in [Grunewalder et al, 2010], noting that the latter converges to 0. The reviewer suggests that the first term in Eq. (30) converges to 0, but it is not trivial to derive that the second term also converges to 0. The comment explicitly asks the authors to prove this, providing a clear and concrete action for the authors to take. The reviewer also indicates a willingness to increase their score if the authors address the question satisfactorily. This level of detail and explicit request for proof make the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the convergence of the bound in Theorem 2, Eq. (30), and compares it to a similar bound in [Grunewalder et al, 2010]. The comment further specifies the issue by noting that the first term in Eq. (30) converges to 0 but that it is not trivial to derive that the second term also converges to 0. The reviewer explicitly asks the authors to prove this, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), when T goes to infinity. It compares this bound to a similar bound in [Grunewalder et al, 2010], noting that the latter converges to 0. The reviewer provides a logical reasoning by pointing out that the first term in Eq. (30) converges to 0, but it is not trivial to derive that the second term also converges to 0. The comment suggests that the authors should prove this, which is a clear and logical request. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a solid basis for the claim but lacks complete evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a specific question about the convergence of the bound in Theorem 2, Eq. (30), when T goes to infinity. It compares this bound to a similar bound in [Grunewalder et al, 2010], noting that the latter converges to 0. The reviewer points out that while the first term in Eq. (30) converges to 0, it is not trivial to derive that the second term also converges to 0. This feedback is clear and actionable, as it prompts the authors to address a potential gap in their proof or analysis. The reviewer's willingness to increase their score if the authors can satisfactorily address the question adds a sense of urgency and importance to the feedback. Overall, the comment is highly helpful as it provides a specific area for improvement and offers a clear path for the authors to enhance their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the meaning of \"j\" and \"i'\". It also suggests updating one node based on results from multiple connected nodes, which is an implicit action. However, the comment does not provide explicit guidance on how to address these issues or clarify the algorithm. The authors can infer that they need to provide more detailed explanations or updates, but the action is not directly stated, and the feedback lacks concrete steps for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the algorithm, noting that \"avg\" is computed but not used, and questions the meaning of \"j\" and \"i'.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the meaning of \"j\" and \"i'.\" The reviewer suggests that the authors update their response to address these concerns. However, the comment does not provide any additional context, reasoning, or examples to support the claim that the algorithm is unclear. Without further explanation or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with Algorithm 2, noting that \"avg\" is computed but not used, and questions the meaning of \"j\" and \"i'.\" It also suggests that the authors update their response to address these concerns. While the comment points out clear areas for improvement, it lacks depth and does not provide detailed guidance on how to address these issues or improve the algorithm. The feedback is somewhat helpful as it directs the authors to specific areas needing clarification, but it could be more actionable with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the lack of clarity in the specific definition of the sparsity of the residual term and the need for evidence supporting the sparsity assumption across various noisy cases. It also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of sparsity and provide evidence or examples to support the sparsity assumption, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not provide detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of clarity in the definition and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, it requests a comparison of the proposed method\\'s assumptions with existing methods. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the lack of clarity in the specific definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. The comment also implies that the authors should demonstrate the advantages of their assumptions compared to existing methods. However, the comment lacks specific examples, references, or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed justification or evidence makes the claim somewhat verifiable, as it provides a general direction but requires more detailed support to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also highlights the need to demonstrate the advantages of the proposed method\\'s assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work and provides a specific suggestion for improvement. By addressing these points, the authors can enhance the comprehensibility and robustness of their paper. Therefore, the comment is rated as highly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or suggest alternative terminology. The action is explicit but lacks concrete details on how to implement the change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"connectivity,\" explaining that it does not refer to structural connections between the brain and body. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the claim remains unverifiable, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the term \"connectivity\" used in the paper, pointing out that it does not accurately reflect the structural connections between the brain and body. This feedback is somewhat helpful as it highlights a potential misinterpretation or misunderstanding in the paper, prompting the authors to reconsider their terminology. However, the comment lacks actionable suggestions or guidance on how to address this issue, such as proposing alternative terminology or explaining the correct usage of \"connectivity.\" To be more helpful, the comment could include specific recommendations or examples of how to improve the clarity of the paper. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers to another section for more details, but without explicit instructions or concrete suggestions, the authors are left without a clear path for improvement. This lack of specificity and actionable advice makes the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are lacking in detail or what specific aspects need improvement. Additionally, it does not provide any references or examples to support the claim, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is not grounded as it does not identify specific sections or elements of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, such as mentioning which aspects of the related work are missing or how the experiments could be improved. The reference to \"Clarity, Quality, Novelty And Reproducibility\" does not provide sufficient detail or context to substantiate the claim. As a result, the comment lacks verifiability, as it does not offer a clear basis for the reviewer\\'s assertion. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or guidance on what details are missing or how the authors could improve these areas. The reference to \"Clarity, Quality, Novelty And Reproducibility\" suggests that more detailed feedback can be found in those sections, but without elaboration, the comment lacks actionable advice. This makes it barely helpful, as it identifies areas for improvement but does not offer sufficient guidance for the authors to address them effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should study the essentialness of using orthogonal matrices rather than just following the form that connects local and beyond local windows. It implies that the authors should investigate the significance of this choice, but it does not provide explicit instructions on how to conduct this study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of orthogonal matrices but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should study the essentialness of using orthogonal matrices rather than just following the form that connects local and beyond local windows. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Step 3 is the vital part that only orthogonal matrix weight can perform,\" suggesting that the authors should study the essentialness of using orthogonal matrices. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples, references, or detailed explanations of why orthogonal matrices are crucial for Step 3 or how they differ from other weight matrices. Without this supporting information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, suggesting that the authors should study the essentialness of using orthogonal matrices rather than just following the form that connects local and beyond local windows. It highlights the importance of Step 3, which is the vital part that can only be performed with orthogonal matrix weights. This feedback is clear and actionable, as it directs the authors to investigate the significance of this choice and its impact on the paper\\'s validation. However, the comment could be more helpful if it provided additional guidance on how to conduct this study or what specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the accuracy drop in Figure 5 after a certain order of around 4-5, asking whether it is due to overfitting. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the accuracy drop after a certain order and asks for an explanation, specifically whether it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the accuracy drop in Figure 5 after a certain order. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the accuracy drop in Figure 5 after a certain order, specifically asking whether it is due to overfitting. This is a relevant and important question that could help the authors understand the behavior of their model and potentially identify areas for improvement. However, the comment does not provide any suggestions or guidance on how the authors might investigate this issue or address it in their paper. While it prompts the authors to consider a potential explanation, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the models and datasets used are too toy-like and proposes specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small, to improve the complexity and difficulty of the experiments. It also asks whether there is a foreseeable challenge to experiment on language tasks. While the comment provides explicit suggestions for improvement, it does not specify how the authors should address these suggestions or what specific changes should be made to the experiments. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely clear on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the complexity and difficulty of the experiments by recommending specific models and datasets, such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small. Additionally, it raises a question about the feasibility of experimenting on language tasks, which further specifies the areas needing attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models and datasets are too toy-like and suggests specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small, to improve the complexity and difficulty of the experiments. The reviewer also questions the feasibility of experimenting on language tasks. While the comment provides some reasoning by suggesting more challenging datasets and models, it lacks specific examples or references to support the claim that the current models and datasets are insufficient. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or justification to fully address the concerns raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the models and datasets used in the paper, describing them as \"toy-like\" and suggesting that CIFAR100, ResNet 34 or 50, and ViT-tiny or small would be more appropriate. It also raises a question about the feasibility of experimenting on language tasks, which could be an interesting direction for future work. The comment provides clear and actionable feedback by suggesting specific improvements to the models and datasets, as well as offering a potential avenue for expansion. However, it could be more helpful if it included additional guidance on how to implement these suggestions or addressed the feasibility of language tasks in more detail. Overall, the comment is mostly helpful as it directs the authors toward enhancing the complexity and relevance of their experiments, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining is included. It highlights the importance of this baseline, especially in light of the central argument against pretraining. While the comment implies that the authors should include these studies, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct these ablation studies or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining is included. It highlights the importance of this baseline, especially in light of the central argument against pretraining. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion for additional studies but lacks grounding, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining is included. It highlights the importance of this baseline, especially in light of the central argument against pretraining. However, the comment does not provide specific examples, detailed reasoning, or references to support why these ablation studies are crucial or how they would impact the central argument. The lack of detailed justification makes it difficult for the authors to understand the significance of these studies and how they might address the central argument. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that natural ablation studies are missing. It questions how scratchGAN would perform if pretraining is included, which is a crucial baseline to have, especially in light of the central argument against pretraining. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by conducting these ablation studies. However, the comment could be more helpful if it offered additional guidance on how to conduct these studies or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also suggests that the authors should explain their decision to pad the shorter sequence by replicating its last state and the lack of a normalization factor of 1/T, which can affect the distance calculation. The comment provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the equation, namely the handling of comparisons between episodes with different lengths and the lack of a normalization factor, which affects the distance calculation. The comment also provides a suggestion for how the authors could address this issue by explaining their decision to pad shorter sequences and the impact of the normalization factor. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the equation between lines 282 and 283, specifically regarding how the authors handle comparisons between episodes with different lengths. The reviewer provides a detailed explanation of the issue, noting that the authors pad the shorter sequence by replicating its last state and that this approach can lead to an increase in distance with T, favoring longer trajectories. The comment also suggests that this decision should be explained to readers without needing to check the code. This reasoning is clear and provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or literature to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the equation between lines 282 and 283, where the authors should clarify how they handle comparisons between episodes with different lengths. It provides a detailed explanation of the issue, noting that the authors pad the shorter sequence by replicating its last state and that this approach can lead to an increase in distance with T, favoring longer trajectories. The comment also suggests that this decision should be explained to readers without needing to check the code. This feedback is clear and actionable, offering the authors a specific area for improvement and guidance on how to address it. By providing a detailed explanation and suggesting a potential solution, the comment is highly helpful, as it empowers the authors to enhance the clarity and transparency of their work. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the absence of Vision Transformer (ViT) in the experiment, noting its importance as a state-of-the-art (SOTA) model in image classification. It also questions whether the pruning strategy would be different in self-attention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the experimental setup, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider including ViT in their experiments and explore its impact on pruning strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment\" and the absence of Vision Transformer (ViT), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the importance of considering ViT as a state-of-the-art model in image classification and questions whether the pruning strategy would be different for larger datasets like ImageNet. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the absence of Vision Transformer (ViT) in the experiment, noting its importance as a state-of-the-art model in image classification. It also questions whether the pruning strategy would be different for larger datasets like ImageNet. However, the comment lacks specific reasoning or evidence to support why considering ViT is crucial or how its absence affects the experiment. The claim is somewhat verifiable as it highlights a potential gap in the experimental setup, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental setup by noting the absence of Vision Transformer (ViT), an important state-of-the-art model in image classification. It questions whether the pruning strategy would be different for larger datasets like ImageNet, which is a relevant and important point for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what experiments they could conduct to explore the impact of ViT. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a comparison against baselines in the study, specifically noting that only accuracy across optimization levels of binaries is reported without considering baselines. The reviewer suggests that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or reported it as code search, which is a similar task. While the comment implies that the authors should include baselines in their comparison, it does not explicitly instruct them to do so or provide specific guidance on which baselines to consider. The action is implicit and somewhat vague, as the authors need to infer that they should include baselines and determine which ones are relevant. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the \"accuracy across optimization levels of binaries,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking baselines in the comparison and references similar work in the field. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines, specifically noting the absence of baselines in the functionality similarity comparison study. The reviewer supports this claim by stating that many papers have developed architecture-agnostic similarity comparison or reported it as code search, which is a similar task. This provides a logical reasoning and reference to common practices in the field, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples of papers that have included baselines or by elaborating on the importance of baselines in the context of the study. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against baselines. It highlights that the study only reports accuracy across optimization levels of binaries without considering baselines, which is a widely-understood binary analysis application. The comment provides a clear and actionable suggestion by referencing similar work in the field that has developed architecture-agnostic similarity comparison or reported it as code search, which is a similar task. This feedback empowers the authors to address a critical weakness in their draft by suggesting a comparison against established baselines, which would enhance the validity and relevance of their findings. However, the comment could be more helpful if it provided specific examples of baselines or detailed guidance on how to incorporate them into the study. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention a specific detail regarding the preprocessing and evaluation in SI 6.5. It provides clear guidance on what needs to be added to the draft, making the action concrete and direct. The authors know exactly what needs to be done to address the comment, ensuring a high level of actionability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the preprocessing and evaluation, which is different from Mnih et al. [7]. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should mention a specific difference in preprocessing and evaluation compared to Mnih et al. [7]. However, it does not provide any further explanation or evidence to support why this difference is significant or how it affects the evaluation. The comment lacks detailed reasoning or references, making it difficult for the authors to understand the importance of this distinction. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to include a mention of a difference in preprocessing and evaluation compared to Mnih et al. [7]. By pointing out this detail, the comment helps the authors clarify and improve the transparency of their work, which is valuable for readers. However, the comment could be more helpful if it explained why this difference is important or how it affects the evaluation. Despite this, the feedback is clear and actionable, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights issues with the figures, specifically mentioning that the text is too small and that the inputs and outputs for each task are not clearly explained. It also notes that the captions are not self-contained and difficult to link to the main text. While the comment identifies specific problems, it does not provide explicit guidance on how to address these issues or suggest concrete actions for improvement. The authors are left to infer that they need to make the text larger, clarify the inputs and outputs, and improve the captions. However, the lack of explicit instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issues with the figures, such as the small text, unclear inputs and outputs, and the lack of self-contained captions. This provides clear guidance on what needs to be addressed to improve the figures. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figures 1 to 3 are difficult to parse due to small text and unclear inputs and outputs. It also notes that the captions are not self-contained and difficult to link to the main text. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references to similar issues in other papers makes the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the figures, noting that they are difficult to parse due to small text and unclear inputs and outputs. It also points out that the captions are not self-contained and are challenging to link to the main text. This feedback is clear and actionable, as it provides the authors with a direct way to improve the clarity and accessibility of their figures. By addressing these issues, the authors can enhance the readability and comprehensibility of their work, which is crucial for effective communication of their findings. However, the comment could be more helpful if it offered suggestions on how to increase the text size or improve the captions. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their figures, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what metrics should be included or how to measure efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should include metrics to demonstrate efficiency. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. However, it does not specify which part of the paper discusses the advantages over previous work, making it weakly grounded. The comment is specific in pointing out the absence of efficiency metrics, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method compared to previous work. However, it does not provide specific examples of what metrics should be included or how the current metrics are insufficient. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the specific metrics needed to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks evidence to support its claim of efficiency over previous work. It points out the absence of metrics that demonstrate the efficiency of the proposed method, which is a critical gap in the paper. This feedback is clear and actionable, as it directs the authors to include specific metrics to substantiate their claims. However, the comment could be more helpful if it suggested which metrics might be relevant or provided examples of how efficiency could be measured. Overall, the comment is mostly helpful as it highlights a significant gap in the paper and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It lacks specific suggestions or guidance on how to enhance the contribution or address the limitations mentioned. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution of the paper, specifically addressing the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not specify which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in its critique of the contribution, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific examples or detailed reasoning to support why the contribution is insufficient or limited. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide specific feedback or suggestions on how the authors could enhance their contribution or address the limitations mentioned. It lacks actionable guidance or detailed critique, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is not helpful at all, as it does not offer any constructive feedback or direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more details on the state-space, actions, and the space where theta lies. It suggests that the authors should be precise in their descriptions rather than leaving the reader to guess. This feedback provides a clear and direct action for the authors to take, which is to provide more detailed information in the manuscript. The comment is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more details about the state-space, actions, and the space where theta lies. The comment provides a clear direction for improvement by suggesting that the authors should be precise in their descriptions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the nature of the state-space, actions, and the space where theta lies. The reviewer acknowledges that they can guess the answers but suggests that the authors should be precise in their descriptions. This comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where the paper lacks clarity and precision. It points out the need for more detailed information about the state-space, actions, and the space where theta lies. By suggesting that the authors should be precise in their descriptions, the comment provides a clear direction for improvement. However, it could be more helpful if it offered specific suggestions on how to present this information or provided examples of what level of detail would be appropriate. Overall, the feedback is actionable but incomplete, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. There is no indication of what specific aspects of the method need to be revised or how the authors could enhance its effectiveness on general reasoning tasks. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this claim is based on, such as a particular section or experiment, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the method are ineffective or how it could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it lacks specific examples, evidence, or references to support this claim. Without detailed justification or comparison to other methods or results, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation of the method, noting that it does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the method need to be addressed or how to enhance its effectiveness on general reasoning tasks. This lack of actionable feedback makes the comment somewhat helpful, as it identifies a potential issue but does not offer a path for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their proof technique. The action is implicit and vague, as the authors are left without clear direction on how to resolve the problem. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. This level of detail provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. The comment provides a logical explanation of the issue and references the authors\\' acknowledgment of it, which is sufficient to support the claim. However, it could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the proof technique, it does not provide any suggestions or guidance on how the authors might address this issue or improve their proof. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks actionable advice, making it incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, despite not explicitly presenting a conditional framework. The reviewer provides a reference to recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This comment explicitly states the action to be taken, which is to include GDSS as a baseline in Table 3, and provides a concrete suggestion by referencing recent work. The authors know exactly what needs to be done and how to implement the change, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of comparing the continuous diffusion model (GDSS) as a baseline in Table 3, despite GDSS not explicitly presenting a conditional framework. The comment further provides a reference to recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, despite not explicitly presenting a conditional framework. The reviewer supports this claim by referencing recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This external reference provides a logical basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed information about the specific aspects of the recent work that support the claim, such as how it relates to the conditional generation task. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It identifies a potential weakness in the comparison of models in Table 2, where the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress). The comment suggests that GDSS should be compared as a baseline in Table 3, despite not explicitly presenting a conditional framework. The reviewer supports this suggestion by referencing recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This feedback is valuable as it not only points out a gap in the comparison but also offers a specific direction for improvement by suggesting a relevant baseline. The comment is clear, actionable, and provides a constructive way for the authors to enhance their draft, making it highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. While the comment implies a change in the choice of downstream task, it does not provide explicit guidance on how to implement this change or why LiDAR-based segmentation is the preferred choice. The authors can infer that they should consider this suggestion, but the lack of concrete details or rationale makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. However, it does not specify which part of the paper discusses the choice of downstream task, making it weakly grounded. The comment is specific in its suggestion to use LiDAR-based segmentation and provides a rationale for why it is a better choice. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that LiDAR-based segmentation is a better choice for the downstream task compared to object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. The claim is somewhat verifiable as it provides a logical reasoning for the preference of LiDAR-based segmentation, particularly in the context of benchmark metrics. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. This feedback is somewhat helpful as it provides a specific suggestion for improvement, offering a potential alternative approach that could enhance the paper\\'s results. However, the comment lacks detailed reasoning or examples to fully support the claim that LiDAR-based segmentation is the best choice, which would make it more actionable. Additionally, it does not address other aspects of the paper, such as the methodology or results, limiting its overall helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential contradiction between the objective of Eq (12) and the IPO (Infinite Population Optimality). However, it does not provide any explicit or implicit guidance on how the authors should address this contradiction or what specific changes are needed to resolve it. The comment lacks actionable details, such as suggesting ways to reconcile the objectives or explaining how the authors might clarify the contradiction. Without concrete instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Eq (12)\" and the \"objective,\" which provides some grounding as the authors can infer that it relates to a specific equation or section of the paper. However, it does not specify which part of the paper discusses the IPO (Infinite Population Optimality), making it weakly grounded. The comment is specific in pointing out a potential contradiction between the objective of Eq (12) and the IPO, but it lacks detailed guidance on how to address this contradiction. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a contradiction between the objective of Eq (12) and the Infinite Population Optimality (IPO). However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the objective of Eq (12) and the Infinite Population Optimality (IPO). This is a relevant observation that could impact the validity of the paper\\'s claims. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this contradiction or clarify the issue. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer meaningful guidance for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It implies that allowing \"t\" to be arbitrary does not provide any added value. While the comment explicitly states the action of replacing \"t\" with the size of T, it does not provide detailed guidance on how to implement this change or why it would improve clarity. The action is explicit but somewhat vague, as the authors know what needs to be done but may not fully understand the rationale behind the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of T for clarity, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. The reviewer provides a logical reasoning by stating that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific examples or references to support why this change would improve clarity or how it would impact the kernel\\'s functionality. While the reasoning is clear, the lack of detailed justification or examples makes the claim somewhat verifiable, as the authors may need more context to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the paper by recommending a change in notation. It suggests replacing \"t\" with the size of T in the histogram intersection kernel, which could help clarify the meaning and avoid potential confusion. This feedback is clear and actionable, offering a concrete step the authors can take to enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why allowing \"t\" to be arbitrary is problematic or how this change would benefit the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a rationale for this concern, suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the adaptation capacity. The action is implicit and somewhat vague, as the authors are left to infer that they should explore or address the issue of adapting to new concepts, but without concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. It provides a rationale for this concern by discussing the potential limitations for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion of the visual memory or adaptation capacity, but without explicit references, it is challenging to pinpoint the exact section. The comment is specific in detailing the concern about adaptation capacity and the potential limitations, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This reasoning is based on a logical inference and common knowledge about the nature of DINO representations. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can effectively accommodate new concepts. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This feedback is somewhat helpful as it highlights a potential limitation in the paper and prompts the authors to consider this aspect further. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern or improve the adaptation capacity. Overall, the comment provides a valuable insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the paper should include a comparison against state-of-the-art loss functions widely used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This provides a clear and direct action for the authors to take, as it specifies the type of comparison that should be added to the paper. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions widely used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the types of loss functions to consider, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions widely used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This claim is somewhat verifiable as it provides a specific list of loss functions that could be included in the comparison. However, the comment lacks detailed reasoning or examples of how these loss functions are relevant or how they would enhance the paper. Providing more context or explanation would strengthen the justification for the suggestion, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions widely used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that could be included in the comparison. By suggesting this addition, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it explained why these specific loss functions are relevant or how they relate to the paper\\'s focus. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of specific corrections and clarifications that need to be made in the paper. It explicitly mentions the need to correct transcription norms, grammar errors, and formatting issues, such as the incorrect use of \"as it\" instead of \"as in,\" the abbreviation \"PLN\" instead of \"NLP,\" repeated words, and incorrect formatting in Table 3. Additionally, it points out a duplicate DOI number and a link issue. These explicit and concrete actions provide clear guidance on what needs to be corrected, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, figures, and tables in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed corrections and clarifications, such as correcting transcription norms, grammar errors, and formatting issues. This level of detail helps the authors understand exactly what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of factual corrections and clarifications, such as grammar errors, formatting issues, and incorrect references. These are not subjective claims or opinions but rather factual statements that require no verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a list of specific corrections and clarifications that need to be made in the paper. It identifies errors in grammar, formatting, and references, such as the incorrect use of \"as it\" instead of \"as in,\" the abbreviation \"PLN\" instead of \"NLP,\" repeated words, and incorrect formatting in Table 3. Additionally, it points out a duplicate DOI number and a link issue. These detailed corrections and clarifications are highly actionable, as they directly guide the authors on how to improve the clarity and accuracy of their draft. The comment is thorough and provides clear guidance, making it highly helpful for the authors to enhance the quality of their manuscript. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the clarity of the notation and figures. It specifies that M and N should be defined and suggests spelling out F.L.T.R in figure 4. Additionally, it recommends improving the legibility of figure 1 by making the text larger and cross-referencing notation with figures. These actions are concrete and direct, giving the authors clear guidance on how to address the issues identified. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"figure 4\" and \"figure 1,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with notation, suggesting that M and N should be defined and recommending improvements to figure 1, such as making the text larger and cross-referencing notation with figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and suggestions for improvement, such as clarifying notation and improving figure legibility. It does not contain subjective opinions, claims, or suggestions that require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper, making it highly helpful for the authors. It identifies issues with notation, suggesting that M and N are used without definition, and recommends spelling out F.L.T.R in figure 4. Additionally, it points out that the text in figure 1 is too small to be legible and suggests cross-referencing notation with figures. These detailed suggestions guide the authors on how to improve the clarity and readability of their work, making the comment highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential source of confusion in Algorithm 1, specifically regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. While the comment identifies a specific issue, it does not provide explicit guidance on how to address this confusion or suggest alternative terminology or explanations. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation or terminology, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of potential confusion regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be addressed to improve the clarity of the algorithm description. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about potential confusion in the notation used in Algorithm 1. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically regarding the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify their notation or terminology to improve the clarity of their algorithm description. However, the comment does not provide specific suggestions or guidance on how to resolve this issue, such as recommending alternative notation or explaining the purpose of each variable. While it highlights a potential problem, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improvement, such as including a more detailed (e.g., mathematical) formulation in the appendix and suggesting changes to the figure to better align with the main contribution of the paper. The reviewer offers specific actions, like adding more text labels to the figure, which provides concrete guidance for the authors. This level of detail and explicitness makes the comment highly actionable, as it clearly outlines what the authors need to do to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"high-level description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the figure, such as its abstractness and lack of alignment with the main contribution, and suggests ways to improve it, such as adding more text labels or reworking the figure to depict the WiC task. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a more detailed mathematical formulation, for example in the appendix, would be beneficial. It also critiques the figure, stating that it is too abstract and does not align well with the main contribution of the paper. The reviewer provides specific suggestions for improving the figure, such as adding more text labels or reworking it to depict the WiC task. While the comment offers logical reasoning and specific suggestions for improvement, it lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could benefit from more detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting that a more detailed mathematical formulation, for example in the appendix, would enhance the understanding of the approach. It also critiques the figure, noting that it is too abstract and does not align well with the main contribution of the paper. The reviewer offers specific suggestions for improving the figure, such as adding more text labels or reworking it to depict the WiC task. This feedback is clear and provides concrete steps for the authors to take to improve their draft, making it highly helpful. The authors are given a clear path to enhance the clarity and relevance of their work, which is a valuable contribution to the review process.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not specify which specific tasks should be included or how they would contribute to the paper. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to consider adding more benchmarking tasks, but without specific guidance, they may struggle to determine which tasks to include and how to integrate them effectively.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding which additional benchmarking tasks should be included or why they are necessary. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why these additional tasks are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on which specific tasks should be included or how they might enhance the paper. The feedback is somewhat helpful as it points out a direction for expansion, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for additional information regarding the experiments. It explicitly asks for the comparison results of YOSO with linformer on iteration-wise convergence and for an explanation of the performance difference between linformer and YOSO in downstream tasks like SST-2. These requests are clear and direct, providing the authors with specific actions to take to improve their draft. The comment is highly actionable as it offers concrete steps for the authors to follow, ensuring they know exactly what information to include or address in their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the pre-training experiment part, namely the steps vs ppl of linformer with YOSO and the comparison result of YOSO with linformer on iteration-wise convergence. Additionally, it requests an explanation for the performance difference between linformer and YOSO in downstream tasks like SST-2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and requests for additional information regarding the experiments. It asks for the comparison results of YOSO with linformer on iteration-wise convergence and for an explanation of the performance difference between linformer and YOSO in downstream tasks like SST-2. These requests are logical and reasonable, but they do not contain any specific claims or opinions that require verification. The comment is primarily factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific gaps in the experimental section of the paper, particularly regarding the comparison between YOSO and linformer. It points out the absence of steps vs ppl of linformer with YOSO in Figure 4 and requests the comparison result of YOSO with linformer on iteration-wise convergence. Additionally, it questions the performance difference between linformer and YOSO in downstream tasks like SST-2 and suggests an explanation for this difference. These requests for additional information and analysis are clear and actionable, providing the authors with specific directions to enhance their experimental section. The comment is highly helpful as it offers detailed guidance on how to improve the clarity and comprehensiveness of the experimental results, allowing the authors to better address the concerns raised by the reviewer. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point points out a specific issue with the abstract, where the authors claim that the proposal distribution upper bounds the target everywhere, which is not true as the authors themselves clarify in the text. However, the comment does not provide any explicit or implicit action for the authors to take. It does not suggest how the authors should address this issue or clarify the discrepancy in the abstract. Without guidance on how to resolve the contradiction or improve the clarity of the abstract, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the abstract, namely that the authors require the proposal distribution to upper bound the target everywhere, which is not true as the authors themselves clarify in the text. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors require the proposal distribution to upper bound the target everywhere, which is not true as the authors themselves clarify in the text. This claim is based on a specific observation within the paper, which provides a clear and direct contradiction to the authors\\' claim. The reasoning is logical and straightforward, making the claim fully verifiable. The authors can easily verify the claim by referring to the text where the clarification is made. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, where the authors claim that the proposal distribution upper bounds the target everywhere, which is not true as the authors themselves clarify in the text. This feedback is valuable as it points out a contradiction in the abstract, which can lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the discrepancy. While it highlights a critical problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a confusion in the reference to \"PointNet\" in Figure 1, noting that this name does not appear anywhere in the paper and that there exists another paper with the same name. The reviewer provides a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is clear and actionable, as it directs the authors to correct the reference to avoid confusion and ensure accurate attribution. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a suggestion to correct it by referencing the original paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear anywhere in the paper and there exists another paper with the same name. The reviewer supports this claim by providing a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This detailed reference and explanation provide a clear basis for the claim, making it fully verifiable. The authors can easily understand and address the issue by correcting the reference to avoid confusion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that the name does not appear anywhere in the paper and that there exists another paper with the same name. The reviewer provides a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which helps the authors correct the reference and avoid confusion. This feedback is clear and actionable, offering a precise suggestion for improvement that can enhance the accuracy and clarity of the paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the policy gradient in Equation 6 and its relationship to the optimal solution in Equation 5. It suggests that the authors clarify these points to ensure clarity. Additionally, it points out a minor grammatical error in Line 78 and a potential typo in Line 132. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address the questions or correct the errors. The actions are explicit but somewhat vague, as the authors know what needs to be clarified but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Eq. 6 and Eq. 5) and lines (78 and 132), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the policy gradient and its relationship to the optimal solution, suggesting that clarification is needed. Additionally, it points out minor grammatical errors, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and suggestions, such as clarifying the relationship between equations and correcting grammatical errors. These are factual statements or requests for clarification, not claims that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several specific questions and points out potential areas for clarification. It questions the relationship between the policy gradient in Equation 6 and the optimal solution in Equation 5, suggesting that the authors clarify this connection. Additionally, it identifies minor grammatical errors and suggests corrections, which can help improve the clarity and accuracy of the manuscript. While the comment provides valuable feedback, it could be more helpful if it offered additional context or suggestions on how to address the questions or errors. Overall, the comment is somewhat helpful as it directs the authors\\' attention to specific areas that need clarification or correction, but it lacks depth and comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two distributions. While the comment implies that the authors should consider this assumption, it does not explicitly instruct them to do so or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors need to infer that they should consider the assumption and provide a response to the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or algorithm description. This lack of grounding makes it difficult for the authors to determine where to address the issue. The comment is specific in its inquiry about the difference between the two distributions, but without clear grounding, it is challenging for the authors to know where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm and inquiring about the difference between the two distributions. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumption of a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two distributions. While the comment identifies a potential area for improvement or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, which is a risky choice that makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to address the limitations of this approach. The comment is explicit and concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment further suggests that the authors should discuss the limitations of this approach. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is risky or what specific assumptions are being made. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology, specifically the choice to freeze the partitioning in the first iteration. It points out that this approach makes strong assumptions about the coverage of the initial data, which could be a risky choice. The comment suggests that the authors should discuss the limitations of this approach, providing a clear and actionable piece of feedback. By addressing this concern, the authors can enhance the robustness and transparency of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to discuss these limitations or alternative approaches to consider. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the intent of Section 5.2, implying that the authors should clarify the purpose of this section. However, it does not provide any guidance on how to address this question or what specific aspects of the section need clarification. The action is implicit and vague, as the authors are left to infer that they need to provide more context or explanation for the section. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. However, it does not specify what aspect of the section is unclear or what specific information is missing. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the intent of Section 5.2. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. While it identifies a potential area of confusion, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights into what aspects of the section need clarification or improvement. As a result, it is barely helpful, as it points out a potential issue but does not assist the authors in resolving it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for clarification on several aspects of the approach, particularly regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, it does not provide explicit instructions or concrete suggestions on how to address these issues. The comment implies that the authors should clarify the approach, but it lacks specific guidance on what aspects need clarification or how to improve the explanation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many aspects of the approach\" that need clarification, allowing the authors to identify the parts of the paper that require attention. It also specifies the concern about understanding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. This provides clear guidance on what needs to be clarified. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"many aspects of the approach need to be clarified\" and specifically mentions the lack of understanding regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, the comment does not provide specific examples or detailed reasoning to support this claim. The reference to \"detailed comments below\" suggests that more information might be provided, but without access to those comments, the current statement lacks sufficient evidence or explanation. Therefore, the claim is considered borderline verifiable, as it provides some basis for the need for clarification but lacks detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically highlights the lack of understanding regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. This is a critical point that the authors need to address to improve the clarity and comprehensibility of their work. However, the comment does not provide specific suggestions or guidance on how to clarify these aspects, leaving the authors with a general direction but without detailed actionable steps. While it points out a significant weakness, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the threat model by defining the assumed threat model more explicitly, specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. It also suggests including this information in a dedicated section to enhance clarity, particularly regarding the assumed white-box access to the victim model. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the assumed threat model, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly. The comment provides a clear and logical reasoning for this request, as it highlights the importance of specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This reasoning is based on the need for clarity, particularly regarding the assumed white-box access to the victim model. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides a clear and actionable suggestion by asking the authors to define the assumed threat model more explicitly, specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their threat model section. However, the comment could be more helpful if it included examples or references to illustrate how other works have addressed similar issues. Overall, the comment is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the decision to use early stopping based only on link prediction accuracy should be explained, specifically questioning why not averaging with type accuracy. This comment implies that the authors should provide a rationale for their choice, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should explain their decision. However, the authors can infer that they need to provide a justification for their choice, which makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use early stopping only by link prediction accuracy and suggests an alternative approach by questioning why not averaging with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the decision to use early stopping based only on link prediction accuracy should be explained, specifically questioning why not averaging with type accuracy. This is a claim that requires justification, as it implies that the current approach may be insufficient or incomplete. However, the comment does not provide any reasoning or evidence to support this claim, such as why averaging with type accuracy might be beneficial or how it could improve the results. Without additional context or explanation, the claim remains unverifiable, as the authors would need to infer the rationale themselves. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the decision to use early stopping only based on link prediction accuracy. It suggests that this choice should be explained, particularly by considering the potential benefits of averaging with type accuracy. This feedback is clear and actionable, as it prompts the authors to provide a rationale for their decision-making process, which could enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it offered additional suggestions or examples on how to incorporate type accuracy into the early stopping criteria. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the feasibility of setting a reasonable class-imbalanced task in the context of few-shot learning, where there are only a few examples for each class. It explicitly asks the authors to explain this with concrete details. This provides a clear and direct action for the authors to take, which is to provide a detailed explanation of how they set up their class-imbalanced tasks. The comment is explicit and concrete, giving the authors a specific task to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"sampling class-imbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the feasibility of setting a reasonable class-imbalanced task in the context of few-shot learning and asks for concrete details on how this is achieved. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the feasibility of setting a class-imbalanced task in the context of few-shot learning, where there are only a few examples for each class. It does not contain a claim or opinion but rather seeks clarification from the authors. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the feasibility of setting a reasonable class-imbalanced task in the context of few-shot learning, where there are only a few examples for each class. It prompts the authors to provide concrete details on how they set up their class-imbalanced tasks, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered specific guidance or examples on how to address this issue. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that requires further explanation. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the chat-gpt baseline as rudimentary and suggests that testing a few-shot approach and incorporating discourse relation information in the prompts might yield better results. However, it does not provide explicit instructions or concrete steps for the authors to follow. The comment implies that these additions could enhance the paper\\'s evaluation, but it lacks specific guidance on how to implement these suggestions. As a result, the authors are left with a general idea of what could be improved but without detailed instructions on how to execute these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"chat-gpt baseline\" and the \"few-shot approach,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the rudimentary nature of the chat-gpt baseline and suggesting that testing a few-shot approach and incorporating discourse relation information in the prompts could yield better results. The comment further explains that these additions would enhance the paper\\'s evaluation but are extraneous to the current line of evaluation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the chat-gpt baseline is rudimentary and suggests that testing a few-shot approach and incorporating discourse relation information in the prompts might yield better results. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion to include discourse relation information is not fully explained, and the claim about the rudimentary nature of the chat-gpt baseline is not substantiated with evidence or comparisons. This makes the comment somewhat verifiable, as it provides a general direction for improvement but lacks the necessary details to fully substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the chat-gpt baseline, noting that it is rudimentary and lacks testing of a few-shot approach. It suggests that incorporating discourse relation information in the prompts, possibly through a Chain-of-Thought style approach, could yield better results. The comment also acknowledges that while this addition might enhance the paper\\'s evaluation, it is extraneous to the current line of evaluation. This feedback is somewhat helpful as it points out a potential area for improvement and offers a suggestion for enhancing the paper\\'s evaluation. However, it could be more helpful if it provided more detailed guidance on how to implement the suggested changes or why the current evaluation approach is insufficient. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. While the comment highlights a gap in the explanation, it does not provide explicit guidance on what additional information should be included or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the pruning process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 238-239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detailed explanation on how the ground truth of sensitivity is achieved, particularly regarding the process of pruning. The comment provides a clear direction for the authors to improve their draft by detailing the pruning process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed explanation or examples, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detailed explanation, namely the process of achieving the ground truth of sensitivity. It points out that the authors mention \"pruning\" but do not provide details on how this is done. This feedback is clear and actionable, as it directs the authors to include more detailed information on the methodology used to estimate sensitivity. However, the comment could be more helpful if it suggested specific aspects of the pruning process that need to be explained or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain parts of the text could be written more clearly. It provides specific examples by asking for an explicit explanation of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105-106. These requests are explicit and provide clear guidance on what the authors need to clarify in their draft. The feedback is actionable because it specifies exactly what needs to be addressed, making it easy for the authors to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that some parts of the text could be written more clearly, specifically mentioning the need for explicit explanations of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105-106. While the comment does not explicitly mention sections or lines, the authors can infer that these issues pertain to specific parts of the text. The comment is specific in detailing what needs to be clarified, providing clear guidance on how to improve the draft. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that certain parts of the text could be written more clearly, specifically mentioning the need for explicit explanations of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105-106. However, the comment does not provide any reasoning or examples to support why these parts are unclear or how they could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the text could be improved by suggesting that certain parts are unclear. It provides explicit examples by asking for an explanation of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105-106. This feedback is clear and actionable, as it directs the authors to clarify these points in their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context for these concepts. Overall, the comment is mostly helpful as it guides the authors toward enhancing the clarity of their text, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider not calling the \"g\" activation function but rather a binary operator, similar to the approach taken by Cohen and Shashua in 2016. The comment provides a specific reference to a similar work that introduces an \"activation-pooling operator\" that meets the required conditions. This feedback is explicit and provides a concrete suggestion for the authors to consider, making it highly actionable. The authors know exactly what change to make and can refer to the cited work for guidance. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a change in terminology, providing a reference to a similar work by Cohen and Shashua, 2016, and explaining how their approach introduces an \"activation-pooling operator\" that meets the required conditions. This level of detail guides the authors on what specific change to consider, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a change in terminology, stating that it might make sense to not call \"g\" an activation function but rather a binary operator, similar to Cohen and Shashua, 2016. The comment provides a reference to a similar work that introduces an \"activation-pooling operator\" that meets the required conditions. This reference supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the terminology used in the paper, recommending that the authors consider not calling the \"g\" activation function but rather a binary operator. It references a similar work by Cohen and Shashua, 2016, which introduces an \"activation-pooling operator\" that meets the required conditions. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and precision of their work. By suggesting a change in terminology and referencing a relevant study, the comment provides valuable guidance for the authors to consider. Therefore, it is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the captions of Figures 1 and 2 have large overlaps with the content, and it recommends shrinking the captions to leave more space for the methods or related work sections. This feedback is explicit and provides a clear action for the authors to take, which is to reduce the size of the captions. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, namely their large overlap with the content, and suggests a solution to address this by shrinking the captions. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the captions of Figures 1 and 2 have large overlaps with the content, suggesting that the authors should consider shrinking the captions to leave more space for the methods or related work sections. However, the comment does not provide specific examples or detailed reasoning to support this claim, such as comparing the captions with the content or explaining why the overlap is problematic. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the captions of Figures 1 and 2, noting that they have large overlaps with the content. It suggests a potential solution by recommending that the authors consider shrinking the captions to leave more space for the methods or related work sections. This feedback is clear and actionable, providing the authors with a concrete step to improve the layout and organization of their paper. However, the comment could be more helpful if it included additional suggestions or examples on how to effectively reduce the overlap without compromising the clarity of the captions. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the omission of Vidgen et al., 2021 from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. While the comment implies that the authors should consider including Vidgen et al., 2021 as a benchmark, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this dataset as a benchmark. However, the comment provides a clear rationale for why this addition might be beneficial, which makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the omission of Vidgen et al., 2021 from the table and questions why this dataset is not used as a potential benchmark for evaluation. The comment provides a clear rationale for why this omission might be significant, particularly in the context of investigating the role of context in hate detection. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the omission of Vidgen et al., 2021 from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer provides a rationale for why this dataset could be relevant as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim that Vidgen et al., 2021 is similar to the dataset in the paper. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2, noting the omission of Vidgen et al., 2021, which might be similar to the dataset presented in the work. It questions why this dataset is not used as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. This feedback is clear and actionable, as it prompts the authors to consider including Vidgen et al., 2021 as a benchmark, which could enhance the robustness and relevance of their evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this dataset effectively. Overall, the comment is mostly helpful as it directs the authors to a potential improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs (at least 10), ideally with error-bars. It also notes that the plotted curves are from single runs and might be subject to significant fluctuations, suggesting that the models are small and should not be an excuse for not providing statistics. This feedback is clear and provides concrete steps for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with error-bars, and explaining why the current presentation might be subject to significant fluctuations. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs, ideally with error-bars, to account for potential fluctuations. The reviewer provides a logical reasoning by noting that the plotted curves are from single runs, which could lead to significant fluctuations due to the small size of the models. This reasoning is clear and provides a basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim about the need for statistical analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over multiple runs, ideally with error-bars, to account for potential fluctuations. This recommendation is important for ensuring the robustness and reliability of the results, particularly given the small size of the models. The comment is specific and offers a concrete suggestion for improvement, making it highly helpful for the authors. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also notes that current operator learning methods may not achieve the same accuracy as specialized numerical solvers but are more universal and do not need to be adapted to specific PDEs. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues or improve their approach. The feedback lacks actionable details, leaving the authors uncertain about how to respond or make improvements. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also compares current operator learning methods to specialized numerical solvers, noting their limitations and advantages. However, the comment does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the critique of the approach, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also compares current operator learning methods to specialized numerical solvers, noting their limitations and advantages. While the comment provides a logical critique and comparison, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also compares current operator learning methods to specialized numerical solvers, noting their limitations and advantages. While the comment identifies a potential weakness in the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it provides insight into the limitations of the approach, but it could be more beneficial with actionable advice or examples of how to enhance the methodology. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA version and the PyTorch version. This is a clear and direct action that the authors can take to improve their draft. The comment also explains the importance of this information by highlighting its potential impact on training and inference speed. The action is explicit and provides concrete guidance on what needs to be included, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA version and the PyTorch version. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA version and the PyTorch version. The claim is based on the potential impact of different versions on training and inference speed, which is a logical and reasonable assumption. However, the comment does not provide specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to infer the importance of this information based on the reasoning provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should include more detailed information about the experimental environment, such as the CUDA version and the PyTorch version. This is important because different versions can impact training and inference speed, which is a critical aspect of the experimental setup. By addressing this feedback, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it explained why this information is crucial or how it might affect the results. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the difficulty of controlling multiple aspects of variation with fully realistic datasets and agrees with the authors\\' assessment that there is no immediate societal impact. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of controlling variation or how to improve the paper\\'s impact. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the difficulty of controlling multiple aspects of variation with fully realistic datasets and agrees with the authors\\' assessment of no immediate societal impact. However, it does not specify which part of the paper this observation is based on, nor does it provide any guidance or suggestions for improvement. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or how to address the issues raised. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two separate claims: \"fully realistic datasets will make it hard to control multiple aspects of variation with precision\" and \"there is no immediate societal impact.\" The first claim is supported by logical reasoning, as it explains how fully realistic datasets can complicate controlling variation. The second claim is a subjective opinion, but it is not supported by evidence or references. While the first claim is somewhat verifiable due to the logical reasoning, the second claim lacks sufficient justification, making it borderline verifiable. Therefore, the overall comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the difficulty of controlling multiple aspects of variation with fully realistic datasets and agrees with the authors\\' assessment of no immediate societal impact. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how the authors might address the challenges posed by fully realistic datasets or enhance the societal impact of their work. As a result, the comment is not helpful at all, as it does not provide the authors with any actionable insights or direction for improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on specific sections of the paper, indicating that the reviewer has difficulty understanding the content and suggests that the authors clarify their explanations. The comment explicitly states that the paragraph from lines 156 to 166 is unclear and that the figure is hard to understand. It also provides a concrete suggestion to clarify the explanation of the dashed lines in the figure. This feedback is clear and actionable, as it directs the authors to specific parts of the paper that need improvement and offers a concrete way to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (L156-166) that are unclear, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the paragraph, noting that the reviewer has difficulty understanding it and suggesting that the authors clarify their explanation. Additionally, the comment provides specific feedback on the figure, stating that the dashed lines are vague and need clarification. This level of detail and explicit reference to the specific parts of the paper make the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paragraph from lines 156 to 166 is unclear and that the figure is hard to understand. The reviewer provides specific examples of what is unclear, such as the use of \"bandit algorithms that plan to explore\" and the explanation of the dashed lines in the figure. This level of detail supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or references to clarify the issues further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two distinct issues within the paper. First, it identifies a paragraph (lines 156-166) as being unclear, suggesting that the authors clarify their explanation. Second, it points out that the figure is hard to understand, specifically mentioning the vague explanation of the dashed lines. This feedback is clear and directs the authors to specific parts of the paper that need improvement, offering a concrete way to enhance the clarity and comprehensibility of their work. By addressing these issues, the authors can significantly improve the readability and effectiveness of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It also points out the specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to clarify the evaluation metric. This feedback is explicit and provides concrete guidance on what needs to be done, making it highly actionable. The authors know exactly what needs to be added to improve the clarity and comparability of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lines (078-079 / Line 08) where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. Additionally, it provides a specific example of the expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to clarify the evaluation metric. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to clarify the evaluation metric. This provides a clear and specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the evaluation metric impacts the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to clarify the evaluation metric, which is a concrete example that can guide the authors in improving the clarity and comprehensibility of their results. This feedback is clear and actionable, offering the authors a direct path to enhance the clarity and comparability of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the stated standard deviation of the noise in the simulation study and the observations in the plot, suggesting that the noise level is not as high as claimed. It implies that the authors should study the behavior of the model under higher noise levels. While the comment identifies an issue and suggests a potential action, it does not provide specific guidance on how to implement this study or what specific noise levels to consider. The action is explicit but somewhat vague, as the authors know they need to investigate higher noise levels but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"plot,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the stated standard deviation of the noise and the observations in the plot, suggesting that the noise level is not as high as claimed. The comment further suggests studying the behavior of the model under higher noise levels. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the standard deviation of the noise in the simulation study is not as high as stated, based on observations in the plot compared to the true trajectories. This claim is somewhat verifiable as it provides a logical reasoning by comparing the observations with the stated noise level. However, the comment lacks specific examples or references to support the claim fully, such as detailed comparisons or data points that demonstrate the discrepancy. This makes the claim somewhat verifiable, as it requires additional evidence or explanation to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the stated standard deviation of the noise in the simulation study and the observations in the plot, suggesting that the noise level is not as high as claimed. It provides a specific observation that the authors can use to improve their draft by suggesting that they study the behavior of the model under higher noise levels. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it included suggestions on how to implement this study or what specific noise levels to consider. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific guidance on how the authors should address this issue or what actions they should take to improve the applicability of their approach. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounds and their improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds or where the authors should focus their attention to address this issue. The comment lacks grounding as it does not mention specific sections, figures, or tables, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while it raises a concern about the applicability of the approach, it does not provide specific guidance on how to address this limitation. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific examples or references to support the claim that these inputs would seriously limit the applications of the approach. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. It suggests that this might limit the applications of the approach. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue or improve the applicability of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting question about how DVP performs on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this further, include additional analysis, or address this issue in their paper. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises an interesting question about how DVP performs on videos of different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of DVP\\'s performance on different-length videos is being questioned. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about how DVP performs on videos of different lengths. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about how DVP performs on videos of different lengths. However, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this question. Without guidance on how to explore this aspect further or what specific aspects of DVP\\'s performance should be investigated, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not explicitly instruct the authors to clarify this point or suggest how to do so. The action is implicit, as the authors can infer that they need to clarify the target of their study, but it lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not specify which part of the paper lacks this clarification, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is weakly grounded as it does not identify a specific part of the paper, but it is specific in detailing the issue of unclear target queries. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that a clear clarification is not provided until the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the target of the paper, whether it focuses on single-token or multi-token cloze queries. It points out that a clear clarification is not provided until the conclusion, which is a relevant observation that could help the authors improve the clarity and readability of their paper. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a clearer explanation or restructuring the paper to clarify the target. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to evaluate the approximation error of the proposed training objective by calculating the actual KL-divergence and checking whether it indeed approaches zero. This is a clear and direct action for the authors to take, providing specific guidance on how to address the issue. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, namely the omission of the KL-divergence term in equation (3). The comment further suggests evaluating the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed training objective has ignored the KL-divergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KL-divergence. This is a logical claim that requires verification through calculations or experiments to determine the accuracy of the approximation. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct additional analysis to fully substantiate the claim, which is a reasonable expectation given the nature of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed training objective, noting that the KL-divergence term in equation (3) has been ignored. It provides a clear and actionable suggestion for the authors to evaluate the approximation error by calculating the actual KL-divergence and checking whether it indeed approaches zero. This feedback is valuable as it directs the authors to a potential area of improvement in their methodology, offering a concrete step to enhance the rigor and accuracy of their work. However, the comment could be more helpful if it provided additional context or examples on how to conduct this evaluation or the potential implications of the approximation error. Overall, the comment is mostly helpful, as it effectively guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, it does not provide explicit guidance on how the authors should address these issues or improve the connection between the sections. The comment implies that the authors should enhance the theoretical analysis and its connection to the methodology, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited connection with the methodology section and the simplistic nature of the theoretical analysis, which is closely related to a specific reference, [1]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, the comment does not provide any further explanation or examples to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or specific examples makes the claim unverifiable, as the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of connection between Section 2 and the methodology section, and the simplistic nature of the theoretical analysis, which is closely related to a specific reference. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out weaknesses, but it lacks actionable advice or examples to help the authors make meaningful improvements. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to further discuss the situations where the losses are helpful, specifically mentioning specular areas. While the comment implies that the authors should expand their discussion on this topic, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add more discussion but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be interesting to further discuss the situations where the losses are helpful, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the situations where the losses are helpful, particularly in specular areas. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to further discuss the situations where the losses are helpful, specifically mentioning specular areas. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion would be beneficial or how it could enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be interesting to further discuss the situations where the losses are helpful, specifically mentioning specular areas. While it identifies a potential area for expansion, it lacks specificity and does not provide detailed guidance on how to incorporate this discussion into the paper. The comment points out a possible enhancement but does not offer actionable steps or suggestions for the authors to follow. As a result, the feedback is somewhat helpful, as it provides a direction for improvement but lacks depth and detail.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the strength of the paper as it stands, suggesting that it might not be suitable for ICLR. However, it does not provide any specific guidance or suggestions on how the authors could strengthen their contribution or improve the paper to meet the standards of ICLR. The comment lacks actionable details, leaving the authors uncertain about what steps to take to address the concern. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses doubt about the paper\\'s strength and suitability for ICLR, but it does not specify which aspects of the paper are lacking or what specific contributions are insufficient. Without detailed guidance or references to particular sections or elements of the paper, the authors cannot effectively address the concern. The comment is not grounded as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed feedback on what needs improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses doubt about the paper\\'s strength and suitability for ICLR, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what aspects of the paper are lacking, the authors may find it challenging to understand the basis of the reviewer\\'s concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses doubt about the paper\\'s strength and suitability for ICLR, but it lacks specificity and actionable feedback. It does not identify what aspects of the paper are lacking or what specific improvements are needed to enhance its contribution. Without detailed guidance or suggestions, the authors are left without a clear understanding of how to address the concern or improve their draft. Therefore, the comment is not helpful at all, as it does not provide any actionable insights or direction for the authors to enhance their work.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the major contributions of the paper are unclear and that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify their contributions. There is no suggestion on what specific aspects of the paper should be highlighted as contributions or how the authors might reframe their work to better articulate its contributions. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the paper\\'s major contributions, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion, making it weakly grounded. The comment is specific in its critique of the contributions, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the major contributions of the paper are unclear and that analyzing previous work does not constitute a contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of clarity regarding its major contributions. It points out that analyzing previous work alone does not constitute a contribution, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or enhance their contributions. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Algorithm 2 does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. It also mentions that the answer is not found in reference [30]. This feedback provides clear and direct actions for the authors to take: they need to clarify how n_t is determined and explain the meaning of \"appropriate number\" in line 225. The comment is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation for how to determine n_t and the meaning of \"appropriate number\" in line 225. The comment also references a specific reference, [30], which further grounds the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of Algorithm 2, specifically regarding the determination of n_t and the meaning of \"appropriate number\" in line 225. The reviewer references a specific reference, [30], suggesting that the answer might be found there. This provides some support for the claim, as it directs the authors to a potential source of information. However, the comment lacks detailed reasoning or explanation of why the issue is significant or how it impacts the paper. Therefore, the claim is somewhat verifiable, as it provides a starting point for the authors to investigate but requires more detailed justification or evidence to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Algorithm 2, noting that it does not specify how to determine n_t and questioning the meaning of \"appropriate number\" in line 225. It also references a potential source of information, [30], which could help clarify the issue. This feedback is clear and actionable, as it directs the authors to address a critical gap in their explanation and provides a starting point for further investigation. By highlighting these specific areas for improvement, the comment is highly helpful, as it empowers the authors to enhance the clarity and comprehensiveness of their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. While the comment implies that the authors should make their code publicly available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make their code accessible. However, the comment does provide a clear direction on what needs to be done to address the issue of reproducibility. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where reproducibility is an issue. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its request for code availability, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. This is a factual statement that does not contain an opinion, claim, or suggestion requiring verification. It is purely descriptive and does not need to be verified. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty in reproducing the results, which is an important issue for the authors to address. It also asks whether the code will be made publicly available, which is a relevant question for transparency and reproducibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve the reproducibility of their results or make their code accessible. While it identifies an area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claims about the mixing time being \"even better\" in practice, stating that the evidence provided is insufficient and limits the usefulness for practitioners. However, it does not provide explicit guidance or suggestions on how the authors could improve the evidence or support for these claims. The comment lacks actionable details, such as recommending specific experiments or analyses that could strengthen the evidence. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims about the mixing time being \"even better\" in practice, suggesting that the evidence provided is insufficient. However, it does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence is lacking or how it could be improved. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need revision. This lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evidence provided to support the claim that \"in practice the mixing time is even better\" is insufficient. However, the comment does not provide specific examples or detailed reasoning to substantiate this claim. Without additional context or references to the experiments or data that support the claim, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claims made in the paper regarding the mixing time being \"even better\" in practice. It points out that the evidence provided is insufficient, limiting the usefulness of the claims for practitioners. However, the comment does not provide specific suggestions or guidance on how the authors could improve the evidence or support for these claims. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issue but without a clear path to address it. Therefore, the comment is somewhat helpful, as it highlights a critical area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not provide explicit instructions on how to implement this suggestion or what specific attributes should be included in the vector form. The action is implicit and somewhat vague, as the authors can infer that they need to expand the feature representation but lack detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the protected feature is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides a specific suggestion for improvement, it does not specify why this change is necessary or how it would benefit the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or how it might improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. This feedback is somewhat helpful as it provides a potential direction for improvement by suggesting a more comprehensive representation of the feature. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what specific attributes should be included in the vector form. Without additional context or examples, the authors may find it challenging to fully understand and execute the proposed change. Therefore, the comment is rated as somewhat helpful, as it offers a general direction for improvement but lacks depth and actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the notation and computation details in the paper. It explicitly asks for clarification on how the vectors are represented and suggests denoting this explicitly. Additionally, it inquires about the normalization of vectors and the method used for computing nearest neighbors. These questions and suggestions provide clear and concrete actions for the authors to take, such as clarifying the notation and sharing computation details. The feedback is explicit and provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for clarification, such as denoting the vector representations of words, asking about normalization, and specifying the method used for computing nearest neighbors. The comment details what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and suggestions for clarification, such as denoting the vector representations of words and specifying the method used for computing nearest neighbors. It does not contain subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by questioning the notation and computation details in the paper. It explicitly asks for clarification on how the vectors are represented and suggests denoting this explicitly. Additionally, it inquires about the normalization of vectors and the method used for computing nearest neighbors, which are important details that can impact the understanding and reproducibility of the work. By addressing these questions, the authors can enhance the clarity and comprehensiveness of their draft. The comment is clear and provides concrete suggestions, making it highly helpful for the authors to improve their manuscript. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to improve reproducibility and significance. It references a recent suggestion by Henderson et al. (2018) that a community effort towards reproducibility is needed. The comment implies that the authors should consider this suggestion in their paper, but it does not explicitly instruct them to do so. While the action is implicit, it is concrete because it provides a specific suggestion about running multiple experiments and reporting statistics. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments\" and \"deep RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to run multiple experiments and report statistics, referencing a recent suggestion by Henderson et al. (2018) regarding the importance of reproducibility in deep RL. This provides a clear direction for the authors to improve their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to improve reproducibility and significance. It references a recent suggestion by Henderson et al. (2018) that a community effort towards reproducibility is needed. The comment provides a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how running multiple experiments would improve reproducibility and significance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue in deep reinforcement learning (RL) experiments, specifically the lack of reproducibility and the significance of improvements. It references a recent suggestion by Henderson et al. (2018) that a community effort towards reproducibility is needed, which should also be considered in the paper. The comment provides a clear and actionable suggestion by emphasizing the importance of running multiple experiments and reporting statistics. This feedback is valuable as it directs the authors to address a significant concern in their field and provides a specific direction for improvement. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or specific examples of what to report. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for consistency in the use of periods and commas at the end of equations. This provides a clear and direct action for the authors to take, ensuring that the feedback is actionable. The comment is specific and concrete, as it identifies the exact parts of the paper that need attention and specifies the issue to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, including Figure 2, Line 433, and Line 468, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue of inconsistent punctuation at the end of equations, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the consistency of punctuation in equations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor issue with the consistency of punctuation in equations, specifically pointing out that some equations end with a period while others end with a comma. This feedback is clear and actionable, as it directs the authors to ensure consistency in their writing style. By addressing this minor detail, the authors can improve the professionalism and clarity of their manuscript. However, the comment could be more helpful if it provided additional context or explained why consistency in punctuation is important. Overall, the feedback is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with further explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that $kNN-ECD$ is very similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve the paper\\'s contribution. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that $kNN-ECD$ is very similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses these methods or how the similarity affects the contribution. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered similar or how the similarity impacts the contribution. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that $kNN-ECD$ is very similar to $kNN-MT$, which limits the technical contribution of the paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that $kNN-ECD$ is very similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or differentiate their work. Without actionable feedback or detailed insights, the comment lacks helpfulness, as it does not offer a clear path for the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It also suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon observed in the figures. This feedback is explicit in its request for clarification and suggests a specific action for the authors to take, which is to conduct real-world experiments. The comment provides clear guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the origin of the figures and suggesting that real-world experiments should be conducted to support the phenomenon observed in the figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon observed in the figures. This is a request for clarification and additional evidence, rather than a claim or opinion that requires verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon observed in the figures. This feedback is highly actionable as it provides a clear direction for the authors to enhance the credibility and validity of their work by conducting real-world experiments. By addressing this feedback, the authors can significantly strengthen their paper\\'s empirical foundation. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates a lack of clarity regarding the number of parameters used in each approach discussed in Section B.3. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the authors should clarify the number of parameters, provide additional details, or make any changes to the section. Without actionable advice or specific instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the number of parameters used in each approach. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement requesting clarification on the number of parameters used in each approach. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the number of parameters used in each approach discussed in Section B.3. This feedback is somewhat helpful as it points out a potential issue that the authors need to address to improve the clarity and comprehensiveness of their paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this information, such as recommending additional details or examples. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including an example and a figure would be beneficial for explaining the definition of uniform shattering. While the comment implies that the authors should add these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to create the example or figure. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or subsection where the definition is discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it is challenging for the authors to implement the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning or evidence to support why this would be beneficial or how it would improve the clarity of the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including an example and a figure would be beneficial for explaining the definition of uniform shattering. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the clarity and comprehensibility of the paper. By offering a concrete way to improve the draft, the comment is highly helpful for the authors, as it guides them on how to enhance the reader's understanding of a critical concept. However, it could be more helpful if it also explained why the current explanation is insufficient or how the example and figure would contribute to a better understanding. Overall, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semi-supervised methods. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. It lacks explicit instructions or concrete details on what the authors should do to enhance the novelty of their approach. As a result, the comment is vague and does not offer actionable steps for the authors to take. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed transductive method is not very novel, as it is related to a common way to incorporate unlabeled data in semi-supervised methods. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology discussion. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while the comment provides some insight into the potential lack of novelty, it does not specify what aspects of the method are not novel or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semi-supervised methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\\'s assertion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semi-supervised methods. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. It does not offer actionable feedback or suggestions for the authors to address the perceived lack of novelty. Without additional context or guidance, the authors are left without a clear understanding of what aspects of their method might be considered non-novel or how they could improve their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the assumption among classes is not a common practice but notes that the formulation or definition in the manuscript is somewhat trivial. It suggests that the highlight lies in the optimization and theoretical property analysis, from which conclusions or insights can be gained. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the manuscript or what specific aspects of the optimization or theoretical property analysis should be emphasized. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption among classes, which is not a common practice, and mentions the formulation or definition in the manuscript. However, it does not specify which part of the paper discusses this assumption or formulation, making it weakly grounded. The comment is specific in noting that the highlight lies in optimization and theoretical property analysis, suggesting that insights can be gained from these aspects. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption among classes is not a common practice, but it acknowledges that the formulation or definition in the manuscript is somewhat trivial. The comment suggests that the highlight lies in the optimization and theoretical property analysis, from which conclusions or insights can be gained. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the optimization and theoretical property analysis are significant. Without these elements, the claim remains somewhat verifiable, as the authors may need to infer the importance of these aspects based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the assumption among classes is not a common practice but notes that the formulation or definition in the manuscript is somewhat trivial. It suggests that the highlight lies in the optimization and theoretical property analysis, from which some conclusions or insights can be gained. While the comment identifies a potential area of interest, it lacks specific guidance or suggestions on how the authors might enhance their analysis or present their findings more effectively. The feedback is somewhat helpful as it points out a potential area of interest, but it does not provide actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It suggests that this lack of statistical significance may be the reason why the deviations are often reported as zero. The comment also critiques the statement about performance being \"at least two standard deviation better than the next best baseline,\" arguing that this claim is not supported by the data. While the comment identifies a potential issue with the statistical significance of the results and the validity of certain claims, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct more trials or provide additional statistical analysis to support their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting the lack of statistical significance due to only three trials per case and the resulting zero deviations. The comment further critiques the statement about performance being \"at least two standard deviation better than the next best baseline,\" explaining why this claim is not supported by the data. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation results in Table 1 are not statistically significant due to the limited number of trials (three per case). It argues that this lack of statistical significance is the reason why deviations are often reported as zero, and it questions the validity of claims about performance being \"at least two standard deviation better than the next best baseline.\" The comment provides a logical reasoning for the claim, noting the limited number of trials as the cause of the issue. However, it could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It explains that this lack of statistical significance may be the reason why deviations are often reported as zero, which undermines the validity of claims about performance being \"at least two standard deviation better than the next best baseline.\" This feedback is clear and actionable, as it highlights a critical flaw in the experimental design and suggests that the authors should conduct more trials to ensure statistical significance. By addressing this issue, the authors can improve the robustness and credibility of their results. Therefore, the comment is rated as highly helpful, as it provides specific and actionable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not provide explicit guidance on how to address this issue or suggest which specific features should be compared or how to incorporate the missing papers. The action is implicit, as the authors can infer that they need to expand the feature comparison to include these papers, but the comment lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely the inclusion of two relevant papers in the feature comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the feature comparison in the paper is shallow and missing two relevant papers. However, it does not provide any specific examples or references to these two papers, making it difficult for the authors to understand which papers are being referred to or why they are relevant. Without detailed information or reasoning, the claim lacks sufficient support, making it borderline verifiable. The authors would need to invest effort to identify the missing papers and understand their relevance, which is a barrier to the claim\\'s verifiability.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. This feedback is somewhat helpful as it points out a gap in the analysis that the authors need to address. However, the comment lacks detailed guidance on which features should be compared or how to incorporate the missing papers into the comparison. While it highlights an area for improvement, it does not provide actionable steps or suggestions for the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should use the word \"equivalent\" more cautiously, particularly if the equivalence is not verified. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the draft. The comment provides a concrete suggestion that the authors can follow to enhance the clarity and accuracy of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (8, 56, 70, and 93) where the word \"equivalent\" is used. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" particularly if the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the usage of the word \"equivalent\" should be more cautious, particularly if the equivalence is not verified. This is a subjective claim that requires justification or evidence to support the need for caution. The comment does not provide specific examples or references to substantiate why the usage of \"equivalent\" is problematic or how it could be improved. Without additional context or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific instances where the word \"equivalent\" is used and suggests that its usage should be more cautious, particularly if the equivalence is not verified. This feedback is clear and actionable, as it provides the authors with a specific area to review and potentially revise their draft. By suggesting a more cautious approach, the comment offers a constructive way for the authors to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it provided examples or further explanation of why the usage of \"equivalent\" might be problematic. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer suggests that a more detailed analysis of the differences and similarities between these views is needed to draw solid conclusions. While the comment implies that the authors should conduct a more thorough analysis, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-view clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of the other views and suggesting that a more detailed analysis is needed to understand the differences and similarities between these views. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the effectiveness of the multi-view clustering approach, specifically the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but notes that there is no further analysis of how these views differ. This suggests that the claim is based on a lack of detailed analysis, which is a valid observation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct additional analysis to address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the effectiveness of the multi-view clustering approach when the paraphrase similarity view consistently outperforms the others. It points out that there is limited analysis on how the different views differ, except for the task directly. The comment provides a clear direction for improvement by suggesting that a more detailed analysis of the differences and similarities between these views is needed to draw solid conclusions about the different views. This feedback is actionable and offers a specific area for the authors to focus on, making it mostly helpful. However, it could be more helpful if it included suggestions on how to conduct this analysis or what specific aspects to consider. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to an external source for details. This feedback implies that the authors should provide a clear explanation of the architecture within the paper, rather than relying solely on external references. However, the comment does not specify how the authors should present this information or what specific details should be included. While the action is implicit, it is clear that the authors need to improve the clarity of the architecture explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the architecture used for the experiments not being clearly explained in the paper. It mentions that the authors refer to Jiang et al. (2019) for details, which implies that the paper is not self-contained. However, the comment does not specify which part of the paper lacks clarity or where the reference to Jiang et al. (2019) is made. This makes it difficult for the authors to pinpoint the exact sections that need improvement. While the comment provides some insight into the issue, it lacks specificity and grounding, as it does not direct the authors to specific parts of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to an external source for details. This claim is somewhat verifiable as it highlights a potential issue with the paper\\'s self-containedness. However, the comment lacks specific examples or references to the external source, which would provide more context and justification for the claim. The authors might need to investigate the referenced source to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained within the paper. Instead, the authors rely on an external reference, which makes the paper less self-contained. This feedback is clear and actionable, as it highlights a critical area for improvement that directly impacts the comprehensibility and self-sufficiency of the paper. By suggesting that the authors should provide a clear explanation of the architecture within the paper, the comment offers a specific direction for enhancing the draft. However, it could be more helpful if it provided guidance on how to present this information or what specific details should be included. Overall, the comment is mostly helpful, as it effectively directs the authors to a key area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that consistency should be maintained. This provides a clear and direct action for the authors to take, which is to ensure that these terms are consistently typeset across the paper. The comment is specific and provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BertScore and BLEURT,\" allowing the authors to accurately identify the parts of the paper where these terms are inconsistently typeset. It is also specific because it clearly specifies the issue of inconsistency in typesetting and suggests maintaining consistency. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the inconsistent typesetting of \"BertScore\" and \"BLEURT\" throughout the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that BertScore and BLEURT are inconsistently typeset throughout the text. It suggests maintaining consistency in the typesetting, which is a straightforward and actionable piece of feedback. By addressing this inconsistency, the authors can improve the clarity and professionalism of their paper. However, the comment could be more helpful if it provided examples of where the inconsistency occurs or suggested a preferred style for typesetting these terms. Overall, the feedback is somewhat helpful as it directs the authors to a specific area for improvement but lacks depth and detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide detailed experimental results on Wikipedia regarding the impact of model size on performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. This feedback is explicit in its request for additional experimental results, providing a clear action for the authors to take. However, it does not specify how the authors should present these results or what specific aspects of the model size should be examined. While the action is explicit, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide detailed experimental results on Wikipedia regarding the impact of model size on performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for additional experimental results, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that increasing the model size should not hurt performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. However, the comment does not provide a direct reference to the work by Ni et al., making it difficult for the authors to verify the claim independently. The lack of specific references or detailed reasoning leaves the authors without a clear understanding of the basis for the claim, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential contradiction in the paper regarding the impact of model size on performance. It suggests that the authors should provide detailed experimental results on Wikipedia to support their claim that increasing model size can hurt performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. This feedback is clear and actionable, as it directs the authors to address a specific issue in their experimental results. However, the comment could be more helpful if it provided additional context or examples from the Ni et al. work to guide the authors in conducting the necessary experiments. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several specific issues with the presentation quality of the paper, such as the use of \"-\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the presentation quality, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as Figures 1&2, tables with a \"-\" for the method, the \"Dataset\" columns in the tables, the management of Figure 3 and Table 2, and a \"*\" appearing in Table 1 with no indication of meaning. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what aspects of the presentation quality are considered weaknesses, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific issues with the presentation quality of the paper, such as the use of \"-\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide detailed reasoning or examples to support why these aspects are considered weaknesses. The comment lacks specific references or evidence to substantiate the claim that these issues are detrimental to the paper\\'s quality. As a result, the claim is somewhat verifiable, as it highlights potential issues but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the presentation quality of the paper, such as the use of \"-\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. It also points out the appearance of a \"*\" in Table 1 without explanation. While the comment highlights these weaknesses, it does not provide detailed suggestions or guidance on how to address them. The authors are left with a general understanding of what needs improvement but without actionable steps to enhance the presentation quality. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include related experiments that demonstrate the effectiveness of the \"information axis\" tool. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on what kind of experiments should be conducted or how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include related experiments that demonstrate the effectiveness of the \"information axis\" tool. However, it does not specify which part of the paper this suggestion pertains to, such as the conclusion or a specific section where the tool is discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of related experiments, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper uses much analysis to justify the effectiveness of the \"information axis\" tool but lacks related experiments demonstrating its utility. The comment is based on the reviewer\\'s observation that the conclusion does not include such experiments. However, it does not provide specific examples or references to support the claim that the analysis is insufficient or that related experiments are necessary. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the need for additional experiments based on the reviewer\\'s observation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the effectiveness of the \"information axis\" tool. This feedback is somewhat helpful as it points out an area where the paper could be strengthened by providing empirical evidence to support the claims made about the tool. However, the comment lacks specificity and does not provide detailed guidance on what kind of experiments should be conducted or how they should be designed. To be more helpful, the comment could include suggestions on the types of experiments or data that would be most relevant to the tool\\'s application. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what aspect of Greek is problematic or how it relates to the paper\\'s content. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper this comment addresses. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a request for information, asking if other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a question seeking clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their draft. The comment lacks depth and does not offer any guidance on how the authors might explore or respond to this question. As a result, it does not contribute meaningfully to the authors\\' understanding of their work or its potential improvements. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the text in lines 293-295 makes the above point unclear and difficult for readers to understand. It suggests that the results are acceptable, but it does not provide specific guidance on how to clarify the text or improve its clarity. The action is implicit, as the authors need to infer that they should revise the text to make it clearer. Additionally, the comment lacks concrete details on how to achieve this clarity, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (293-295) where the issue is identified, allowing the authors to accurately pinpoint the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the text and the difficulty for readers to understand and evaluate the results. The comment provides a clear direction for improvement by suggesting that the text should be clarified to make the point more understandable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 makes the point unclear and difficult for readers to understand. However, it does not provide any specific examples or detailed reasoning to support this claim. The comment lacks evidence or explanation, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the claim is not verifiable, as it does not provide sufficient information for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text in lines 293-295, suggesting that it makes the point unclear and difficult for readers to understand. This feedback is somewhat helpful as it points out a potential area for improvement, allowing the authors to revise their draft to enhance clarity. However, the comment lacks specific suggestions or guidance on how to improve the clarity, such as proposing alternative phrasing or additional explanations. While it highlights a problem, it does not provide comprehensive or actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It specifically mentions Lemma 3 and questions whether the result holds for any polynomial function. This feedback provides a clear and explicit action for the authors to improve the organization and clarity of their proofs, as well as to address the specific concern about Lemma 3. The comment is highly actionable as it identifies a specific area for improvement and provides a concrete question to consider, giving the authors clear guidance on how to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of poor organization and clarity in the proofs, providing a concrete example with the question about Lemma 3. This level of detail helps the authors understand what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is not well organized and difficult to follow, providing a specific example with Lemma 3. The reviewer questions whether the result holds for any polynomial function, which is a logical and relevant concern. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the overall organization and clarity of the proofs. While it provides a specific question, it does not offer a comprehensive analysis or evidence to support the broader claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It provides a specific example by questioning whether the result in Lemma 3 holds for any polynomial function. This feedback is clear and actionable, as it highlights a specific area for improvement and prompts the authors to reconsider the organization and logic of their proofs. By addressing these issues, the authors can enhance the rigor and clarity of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. This is an explicit suggestion that provides a clear action for the authors to take. However, the comment does not specify which real-world datasets should be used or how to conduct the experiments, leaving some room for ambiguity. While the action is explicit, the lack of concrete details makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of real-world datasets, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. This claim is based on the premise that the paper claims to address realistic scenarios, which is a logical reasoning. However, the comment lacks specific examples or references to support why real-world datasets are more appropriate or how they would better address the claim of disentangled representation learning. This makes the claim somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by aligning it with the claim of addressing realistic scenarios. However, the comment could be more helpful if it offered examples of real-world datasets or suggested how to integrate them into the experimental setup. Despite this, the feedback is mostly helpful as it guides the authors toward a more relevant and impactful evaluation of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207-210) on the single image case. However, it does not provide explicit guidance on how to clarify these explanations or what specific aspects need to be addressed. The comment consists of questions and comments, which are implicit actions that the authors can infer, but they lack concrete details on how to improve the clarity. As a result, the authors may not be entirely sure of the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the explanation in the last paragraph of Section 3 (lines 207-210), which is fully grounded as it provides a clear reference to the part of the paper being addressed. However, it does not specify what is vague or unclear about the explanation, making it under-specific. The authors are informed of the issue but not given detailed guidance on how to address it. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207-210) on the single image case. However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the vagueness. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where explanations are considered vague, pointing out the last paragraph of Section 3 (lines 207-210) on the single image case. This feedback is somewhat helpful as it directs the authors\\' attention to a particular section that may need clarification. However, the comment lacks detailed guidance or suggestions on how to improve the clarity of the explanations, leaving the authors with a general direction but not a comprehensive plan for revision. To be more helpful, the comment could include specific questions or examples of what needs to be clarified. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the study, suggesting that it only considers one truck and one drone and asks if it would be easy to extend to multiple trucks and drones. While the comment implies that the authors should consider a more practical setting with multiple trucks and drones, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they should consider a broader scope but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the study, specifically mentioning that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not explicit. The comment is specific in suggesting a broader scope, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment lacks specific reasoning or evidence to support why this extension would be beneficial or how it would impact the study. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. While the comment points out a potential area for improvement, it lacks specific guidance or suggestions on how the authors might achieve this extension or what specific aspects of the study would benefit from it. The feedback is somewhat helpful as it prompts the authors to consider a broader scope, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their approach. The comment lacks actionable details, such as recommending alternative strategies or suggesting ways to differentiate the approach from ELECTRA. As a result, the authors are left without a clear understanding of what steps to take to enhance the novelty of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the proposed approach to pretraining, stating that it \"more or less just follows the strategies used in ELECTRA.\" However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology discussion. Without explicit references to the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the approach are similar to ELECTRA or how the authors could differentiate their work. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed approach to pretraining has limited novelty because it \"more or less just follows the strategies used in ELECTRA.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not provide any specific suggestions or guidance on how the authors could enhance the novelty of their approach or differentiate it from ELECTRA. Without actionable feedback or constructive criticism, the comment lacks helpfulness, leaving the authors without a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation for using the Newton algorithm in Section 4 is lacking and proposes that a bisecting line search would suffice for a 1-dimensional line search on a convex function. It questions the impact of quadratic convergence on the algorithm\\'s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. While the comment implies that the authors should provide more motivation and conduct experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the experiments or what exactly should be tested. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for using the Newton algorithm, questioning its necessity and suggesting that a bisecting line search would suffice. The comment further specifies that experiments could help motivate the need for the analysis/algorithm. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation for using the Newton algorithm in Section 4 is lacking and suggests that a bisecting line search would suffice for a 1-dimensional line search on a convex function. The reviewer questions the impact of quadratic convergence on the algorithm\\'s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the impact of quadratic convergence on runtime. This makes the claim somewhat verifiable, as it requires further elaboration or evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s motivation for using the Newton algorithm in Section 4. It points out that a bisecting line search would suffice for a 1-dimensional line search on a convex function, questioning the need for the more complex Newton algorithm. The comment suggests that experiments could help demonstrate the impact of quadratic convergence on the algorithm\\'s runtime, which would provide a stronger motivation for the analysis and algorithm. While the comment highlights an important area for improvement, it could be more helpful by offering specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the feedback is mostly helpful as it provides a clear direction for enhancing the paper\\'s motivation and justification of the analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed upweighing and KNN methods, suggesting that they do not appear to be idiom-specific based on the results shown in Figure 3. The comment implies that the methods are not effective in distinguishing between idiomatic and random data, and it concludes that the results merely indicate that better NMT systems are also better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The action is implicit and vague, as the authors are left without clear direction on how to enhance their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic versus random data is similar for most language and score combinations, leading to the conclusion that the methods are not idiom-specific. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed upweighing and KNN methods do not appear to be idiom-specific, as the impact on idiomatic versus random data is similar for most language and score combinations. The reviewer supports this claim by referencing Figure 3, which provides a visual representation of the results. This visual evidence helps substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or examples from Figure 3 to fully support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critical analysis of the proposed upweighing and KNN methods, suggesting that they do not appear to be idiom-specific based on the results shown in Figure 3. The comment highlights a potential limitation of the methods, noting that the impact on idiomatic versus random data is similar for most language and score combinations. This feedback is valuable as it points out a specific area where the methods may not be effective, prompting the authors to consider whether their methods are truly idiom-specific. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the methods to better distinguish between idiomatic and random data. Overall, the comment is somewhat helpful as it identifies a weakness but lacks actionable guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion regarding the number of biases and kernels in the model. It suggests that the resulting volume should be WxHx1 and the bias should be a scalar, but the authors have only found a hyper-parameter for feed-forward models in section 3.4. The comment implies that the authors should clarify this aspect of their model, but it does not provide explicit instructions on how to do so. While the action is implicit, it is somewhat actionable as it points out a specific area for clarification. However, the lack of concrete guidance on how to address the issue limits its actionability.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the number of biases and kernels in the model, suggesting that the resulting volume should be WxHx1 and the bias should be a scalar. The comment clarifies that the authors have only found a hyper-parameter for feed-forward models in section 3.4, which is confusing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the resulting volume should be WxHx1 and the bias should be a scalar, suggesting that the authors have only found a hyper-parameter for feed-forward models in section 3.4. The comment provides a logical reasoning for the claim, explaining that the authors most likely want multiple kernels and biases, which is not consistent with the current description. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the number of biases and kernels in the model. It suggests that the resulting volume should be WxHx1 and the bias should be a scalar, which is consistent with the authors' likely intention of having multiple kernels and biases. The comment also points out that the authors have only found a hyper-parameter for feed-forward models in section 3.4, which is confusing. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their model and potentially revise their description to align with their intended design. However, the comment could be more helpful if it provided specific suggestions on how to address the confusion or offered examples of how to clarify the model architecture. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and accuracy of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with Equation 8, specifically mentioning that subtracting \"s\" from the dynamic information may result in the loss of some dynamic information. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the equation. The comment lacks actionable guidance, such as recommending alternative methods or suggesting ways to mitigate the potential loss of dynamic information. As a result, the authors are left without a clear understanding of what steps to take to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with subtracting \"s\" from the dynamic information, explaining how it might result in the loss of dynamic information and affect the LSTM module\\'s ability to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that subtracting \"s\" from the dynamic information in Equation 8 may result in the loss of some dynamic information, making it difficult for the LSTM module to capture complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically noting that subtracting \"s\" from the dynamic information may result in the loss of some dynamic information, which could affect the LSTM module\\'s ability to capture complete dynamic changes. This is a relevant observation that could impact the accuracy and effectiveness of the model. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the equation. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is somewhat helpful, as it highlights a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While the questions imply that the authors should investigate these aspects, they do not provide explicit instructions or suggestions on how to address them. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional analysis or experiments, but they are not given specific guidance on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. However, it does not specify which part of the paper these questions pertain to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to determine where to address these questions. The comment is specific in its inquiry about the effects of MC samples and network structure, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking empirical evidence and analysis regarding the impact of the number of Monte Carlo (MC) samples and the network structure on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. By asking for empirical evidence and analysis, the comment prompts the authors to consider these factors and potentially conduct additional experiments or analyses to better understand their influence. This feedback is somewhat helpful as it directs the authors to areas that could enhance the robustness and comprehensiveness of their study. However, it lacks specific suggestions or guidance on how to address these questions, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as whether the smoothed GT shapes should be added as an overlay or as a separate figure. The comment also mentions a \"minor concern,\" but this is not elaborated upon, leaving the authors uncertain about its nature and importance. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in suggesting a particular change to improve the clarity of the figures, but without explicit references to the figures, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a request for clarification or enhancement, not a claim or opinion that requires verification. It is a factual statement that does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests a specific improvement to the paper by recommending the inclusion of smoothed GT shapes in Figures 3 and 5. This suggestion is clear and actionable, as it provides a concrete way for the authors to enhance the clarity and understanding of their results. By showing the smoothed GT shapes, the authors can better demonstrate the quality of the reconstruction, which is a valuable addition to the paper. However, the comment could be more helpful if it explained why this enhancement is important or how it would benefit the readers. Overall, the feedback is mostly helpful as it offers a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, specifically in terms of test accuracy. It suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline. The comment implies that the authors should include direct comparisons to demonstrate the effectiveness of their approach. However, it does not provide specific guidance on how to conduct these comparisons or what metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to add comparisons but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, which is a clear and specific concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach lacks direct comparisons with the prior approach PRANC, specifically in terms of test accuracy. The reviewer highlights that while there are comparisons of training loss and the rank of possible solutions, a direct comparison of test accuracy is missing. This claim is somewhat verifiable as it provides a logical reasoning for the need for a direct comparison of test accuracy to assess the improvement over the baseline. However, the comment could be strengthened by providing specific examples or references to similar studies that include such comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of direct comparisons between the proposed approach and the prior approach PRANC in terms of test accuracy. This is a critical aspect that could impact the evaluation and understanding of the proposed method\\'s effectiveness. The comment highlights the need for such comparisons to determine if the proposed approach is indeed an improvement over the baseline. However, it does not provide specific suggestions or guidance on how to conduct these comparisons or what metrics to use. While it points out a crucial area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It explicitly asks for clarification on how the event types were selected and what the coverage is on the 33 event types in the ACE data. These questions provide clear and direct actions for the authors to take, such as providing more information on the selection process and coverage. The feedback is explicit and concrete, giving the authors specific steps to address the concerns. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises concerns about the generalizability of the method and questions the selection of event types from Freebase. It specifically mentions Section 2, line 262, which provides some grounding by indicating the part of the paper where the issue is discussed. However, it does not specify what needs to be addressed in this part, such as how the event types were selected or what the coverage is on the 33 event types in the ACE data. This makes the comment weakly grounded but specific, as it highlights a particular area of concern without detailed guidance on how to address it. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the generalizability of the method and questions the selection of event types from Freebase. It specifically asks for clarification on how the event types were selected and what the coverage is on the 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these concerns. Without additional context or justification, the authors may find it challenging to address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This feedback is clear and actionable, as it prompts the authors to provide more information on the selection process and coverage, which could enhance the transparency and applicability of their method. However, the comment could be more helpful if it suggested specific ways to address these concerns or provided examples of how to improve generalizability. Overall, the comment is mostly helpful as it identifies a critical area for improvement and guides the authors toward enhancing the clarity and applicability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider including experiments on tasks like language modeling, machine translation, or text summarization to strengthen their claim about the importance of language modeling capability in pre-trained models. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design or implement these experiments. The action is explicit but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments in section 5.3, namely that they do not adequately reflect the language modeling capability of pre-trained models. The comment further suggests including tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s focus on the importance of language modeling capability is not adequately supported by the experiments conducted, specifically those on word similarity and SQuAD in Section 5.3. The reviewer suggests that tasks like language modeling, machine translation, or text summarization would better reflect this capability. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that these tasks are more relevant for evaluating language modeling capabilities. This makes the claim somewhat verifiable, as it requires additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim about the importance of language modeling capability in pre-trained models. It points out that the experiments conducted in section 5.3, focusing on word similarity and SQuAD, may not adequately reflect this capability. The reviewer suggests that the authors should consider including tasks like language modeling, machine translation, or text summarization to strengthen their argument. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments that better align with their claim. However, the comment could be more helpful if it offered guidance on how to design or interpret these additional experiments. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the relevance and validity of their claims.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a notational inconsistency in Section 2, where both $\\hat{Y}$ and $Y$ are used in a mixed way. However, it does not provide any guidance on how to resolve this inconsistency or suggest a specific action for the authors to take. The comment lacks explicit instructions or concrete details on how to address the issue, leaving the authors uncertain about what steps to take to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a notational inconsistency involving $\\hat{Y}$ and $Y$, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the inconsistent use of notations in Section 2, specifically mentioning the use of $\\hat{Y}$ and $Y$. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the inconsistent use of notations in Section 2, where both $\\hat{Y}$ and $Y$ are used in a mixed way. This feedback is valuable as it points out a potential source of confusion for readers and highlights an area that needs clarification. However, the comment does not provide suggestions on how to resolve this inconsistency or offer guidance on which notation should be used consistently. While it directs the authors\\' attention to a specific issue, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include important references for domain adaptation and to discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or where in the paper these references should be included. This makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. The comment is specific in its request for references but lacks grounding as it does not identify a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should include them. However, the comment does not provide specific examples of the missing references or explain why they are crucial. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of a gap but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include these references and discuss them in the revised manuscript. This feedback is valuable as it directs the authors to a specific area for improvement, ensuring that their work is more comprehensive and aligned with current literature. However, the comment could be more helpful if it provided specific examples of the missing references or discussed how these references would enhance the paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks whether EMA-weighting is used for other baseline models in Table 3. It suggests that to ensure a fair comparison, it would be beneficial to know that all models being compared use EMA benefits. This feedback provides a clear and direct action for the authors to take, which is to clarify whether EMA-weighting is used for all models in the comparison. The comment is explicit and concrete, giving the authors a specific task to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning whether EMA-weighting is used for other baseline models and suggests that it would be beneficial to know that all models being compared use EMA benefits. This provides clear guidance on what needs to be addressed to ensure a fair comparison. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether EMA-weighting is used for other baseline models in Table 3 and suggests that it would be beneficial to know that all models being compared use EMA benefits. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a potential issue with the fairness of the comparison in Table 3. It questions whether EMA-weighting is used for all baseline models, which could impact the validity of the results. However, the comment does not provide specific guidance on how to address this issue or suggest alternative methods for ensuring a fair comparison. While it highlights an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range. It also questions the distance to the next best model, implying that this could be a result of luck rather than a robust performance. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The suggestion to present the hyperparameters and their distances to the next best models is implicit and lacks concrete details on how to implement this. Therefore, the comment is somewhat actionable, as it identifies an issue but does not provide clear steps for the authors to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range. It also questions the distance to the next best model, implying that this could be a result of luck rather than a robust performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to present the hyperparameters and their distances to the next best models is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range. It questions the distance to the next best model, implying that this could be a result of luck rather than a robust performance. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. The suggestion to present the hyperparameters and their distances to the next best models is a logical step, but it does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range. It questions the distance to the next best model, implying that this could be a result of luck rather than a robust performance. The comment provides a specific suggestion to present the hyperparameters and their distances to the next best models, which could help the authors better understand and address the issue. However, the comment could be more helpful if it included additional guidance on how to interpret these results or suggestions for alternative analyses. Overall, the feedback is somewhat helpful as it identifies a potential issue and offers a clear direction for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or improved. The authors can infer that they need to provide more detailed information about the corpora and datasets used in the experiments, but the comment lacks concrete suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions \"some aspects of the experimental setup\" as being unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in identifying the issue with corpora and datasets, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. This feedback is somewhat helpful as it points out a potential area for improvement, prompting the authors to clarify and motivate their experimental choices. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as specific questions to consider or examples of how to improve the clarity. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors could improve their method to make it more impressive. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes or additions might be necessary to address the reviewer\\'s concern. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this critique is based on. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the proposed method are not impressive or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific comparisons or references to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions or guidance on how the authors might improve their method to make it more impressive. Without actionable feedback or constructive criticism, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This feedback implies that the authors should provide more detailed information about the model\\'s size, which is an implicit action. However, the comment does not explicitly instruct the authors to include this information, and it lacks concrete guidance on how to present this data. Therefore, the comment is somewhat actionable, as the authors can infer the need for additional information but are not given specific instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This provides a clear indication of what needs to be addressed, namely the size of the model and its components. However, the comment does not explicitly mention which part of the paper this information should be included in, such as the methodology or results sections. While the authors can infer that it relates to the methodology or results, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what is missing, so it is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This is a factual observation that does not contain a claim or opinion requiring verification. It is a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This feedback is valuable as it highlights a gap in the paper that could be addressed to provide a more comprehensive understanding of the model\\'s architecture. However, the comment could be more helpful if it suggested ways to present this information or offered examples of how other papers have addressed similar issues. Despite this, the comment is mostly helpful as it directs the authors\\' attention to an important aspect of their work that needs clarification. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the dimensions of the projection matrices should be written as $A_i \\in \\\\mathbb{R}^{d_i \\\\times m_i}$ instead of $A_i \\in \\\\mathbb{R}^{m_i \\\\times d_i}$, providing a clear and direct action for the authors to take. The reviewer also offers a logical explanation for why this change is necessary, which helps the authors understand the reasoning behind the suggestion. This feedback is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dimensions of the projection matrices, suggesting a correction to ensure the projection of a tensor is possible. The reviewer provides a logical reasoning for the correction, which further enhances the specificity of the comment. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a correction to the dimensions of the projection matrices, stating that $A_i \\in \\\\mathbb{R}^{d_i \\\\times m_i}$ is more appropriate than $A_i \\in \\\\mathbb{R}^{m_i \\\\times d_i}$. The reviewer provides a logical reasoning for this suggestion, explaining that the current formulation would not allow projecting a tensor $T \\in \\\\mathbb{R}^{d_1 \\\\times d_2 \\\\times \\\\ldots d_p}$ on those matrices. This reasoning is clear and logical, making the claim mostly verifiable. However, the comment could be strengthened by providing additional examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft by correcting the dimensions of the projection matrices. It clearly identifies the issue with the current formulation, explaining that the dimensions should be $A_i \\in \\\\mathbb{R}^{d_i \\\\times m_i}$ instead of $A_i \\in \\\\mathbb{R}^{m_i \\\\times d_i}$ to allow for the projection of a tensor. The reviewer also acknowledges that they might be wrong about this, which adds a level of humility to the feedback. This level of detail and clarity makes the comment highly helpful, as it empowers the authors to make a precise correction that could significantly impact the accuracy and clarity of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostic-type prediction, noting that prior work (e.g., ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the claim. It lacks concrete suggestions on how to revise the claim or what additional information should be included to make it clearer. As a result, the authors are left with an implicit action to clarify the claim but without detailed guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim that \"To address this gap, we propose PACE, which treats climate emulation as a diagnostic-type prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that prior work (e.g., ClimateBench or ClimateSet) already addresses this gap, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostic-type prediction\" is misleading because prior work (e.g., ClimateBench or ClimateSet) already addresses this gap. The comment provides a specific example of prior work that contradicts the claim, which is a clear and logical reasoning supporting the claim. This makes the comment fully verifiable, as it provides a direct and specific reference to external work that challenges the claim. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostic-type prediction. It points out that prior work, such as ClimateBench or ClimateSet, already addresses this gap, making the claim misleading. This feedback is clear and actionable, as it prompts the authors to clarify their claim or provide a more nuanced explanation of how PACE differs from existing work. However, the comment could be more helpful if it suggested ways to address this issue or offered examples of how PACE might contribute to the field. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. However, it does not offer any specific guidance or suggestions on how the authors might improve their work or address the critique. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the metric learning theory. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also mentions that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment does not specify which part of the paper discusses the metric learning theory or where the analysis is presented, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in its critique of the metric learning theory, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results and that the metric perspective analysis does not seem to work. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also claims that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specific details or suggestions on how the authors might improve their work or address the critique. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes or enhancements are needed to improve their draft. Therefore, the comment is not helpful at all, as it does not provide any actionable insights or constructive feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for visual results. While the comment provides a clear action to improve the paper by adding visual results, it does not specify which specific visual results should be included or how to present them. The authors know they need to add visual results but may struggle with the execution details. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks concrete guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"visual results\" and \"crowd density estimation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of visual results on crowd density estimation and the suggestion to condense the figures illustrating the proposed network architecture. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests moving visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. The comment provides a logical reasoning for this suggestion, noting that the current paper lacks visual results despite having figures for the proposed network architecture. However, it does not provide specific examples or references to support the claim that visual results are necessary or beneficial for the main experiment. While the reasoning is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors may need to further justify the importance of visual results in their context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. This feedback is specific and offers a concrete way for the authors to enhance the clarity and impact of their work by presenting visual evidence of their findings. However, the comment could be more helpful if it provided examples of how these visual results might be presented or discussed in the main text. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential confusion in the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit or implicit guidance on how to address this issue. The authors are left without a clear understanding of what needs to be done to resolve the confusion. Without specific suggestions or examples, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not specify which part of the paper this issue occurs in, such as a particular section or equation where this notation is used. Without explicit references to the sections or equations, the authors cannot confidently determine where to address the issue. The comment is specific in pointing out the confusion but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion in the paper, specifically the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and specific observation that could lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how to resolve this issue or clarify the notation. Without actionable feedback or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it highlights a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. The question is posed in a way that requires the authors to infer the need for additional analysis or clarification, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure where this discussion is relevant. Additionally, while it raises a concern, it does not provide specific guidance on how to address this issue or what changes should be made. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. This is a relevant concern that could affect the validity and applicability of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure the robustness of their analysis. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the choice of dataset, specifically the WebQuestionsSP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for why the authors should consider using the more popular WebQuestions benchmark set instead, explaining that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, facilitating direct comparison with mainstream QA research. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. The reviewer provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This reasoning is logical and provides a clear basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or examples that support the claim about the advantages of using WebQuestions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This feedback is clear and actionable, as it offers a specific alternative dataset that could enhance the paper\\'s relevance and comparability. However, the comment could be more helpful if it included additional guidance on how to implement this change or addressed potential challenges in switching datasets. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. While the comment implies that the authors should provide evidence for their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to demonstrate the benefits or what evidence is needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the need for certain claims regarding sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment lacks specificity as it does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not lead to actual cost savings unless it can be shown to result in practical implementation benefits. However, the comment lacks specific examples or references to support the claim that sparsity is not desirable or that the benefits are not significant. This makes the claim somewhat verifiable, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the necessity of making claims about the desirability of sparsity in training, suggesting that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer points out that in the age of parallelized computation, the reduction in FLOPs may not lead to actual cost savings unless it can be shown to result in practical implementation benefits. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or provide the necessary evidence. The feedback is somewhat helpful as it prompts the authors to consider the practical implications of their claims, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the design is limited because attention for motion learning has been widely used in video understanding. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the design, specifically mentioning that attention for motion learning has been widely used in video understanding. However, it does not specify which part of the paper this claim pertains to, such as a particular section or experiment where the novelty is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a potential issue with novelty, it does not provide specific guidance on how to address it or improve the novelty of the design. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the design is limited because attention for motion learning has been widely used in video understanding. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation in the novelty of the design, suggesting that attention for motion learning has been widely used in video understanding. However, it does not provide specific examples or references to support this claim, nor does it offer suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed guidance, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the paper should include analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives such as ImageNet-1k or ImageNet-100. It provides a clear and concrete action for the authors to take, which is to present these results in the main paper. The comment is explicit and provides specific guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for analysis or results on datasets other than CIFAR derivatives, specifically suggesting ImageNet derivatives like ImageNet-1k or ImageNet-100. This allows the authors to accurately identify the part of the paper being addressed, which is the lack of analysis on these datasets. The comment is also specific because it clearly specifies what is missing and provides a clear direction for improvement by suggesting the inclusion of results on these datasets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives like ImageNet-1k or ImageNet-100. The reviewer provides a logical reasoning for the importance of this analysis, stating that verifying the effectiveness of the framework on these datasets is crucial. However, the comment does not provide specific examples or references to support the claim that ImageNet derivatives are important or that the paper should include results on them. This makes the claim somewhat verifiable, as it lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of analysis or results on datasets other than CIFAR derivatives. It suggests that verifying the effectiveness of the framework on ImageNet-1k or ImageNet-100 is important and provides a clear direction for the authors to include these results in the main paper. This feedback is actionable and provides a specific suggestion for enhancing the paper, making it mostly helpful. However, it could be more helpful if it offered additional guidance on how to conduct the analysis or present the results on these datasets. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a lack of clarity in the model design, specifically mentioning the fragmentation or absence of model architecture and learning details. It suggests that the authors could provide a plot of the model illustration, pseudo-code table, or code repository to improve clarity. Additionally, the comment emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a well-known method. This feedback is explicit and provides concrete suggestions on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"model design\" and \"learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the fragmentation or absence of model architecture and learning details, suggesting that the authors provide a plot of the model illustration, pseudo-code table, or code repository. Additionally, the comment highlights the importance of demonstrating integrated details, especially since Neurochaos Learning is not a well-known method. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details, suggesting that the authors provide a plot of the model illustration, pseudo-code table, or code repository. The comment also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a well-known method. This claim is somewhat verifiable as it provides a logical reasoning for the need to clarify the model design, but it lacks specific examples or references to support the assertion that the current design is unclear. The suggestion to provide additional details is reasonable, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides specific suggestions for improvement, such as including a plot of the model illustration, pseudo-code table, or code repository. This feedback is actionable and constructive, as it guides the authors on how to enhance the transparency and reproducibility of their work, particularly given the unfamiliarity of the Neurochaos Learning method. By addressing these points, the authors can significantly improve the comprehensibility and utility of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consistently refer to BigFive and MBTI as datasets throughout the paper, rather than treating them as models to be extended. The comment provides a clear and explicit action for the authors to take, specifying that they should either treat them as datasets or provide an extended explanation for their current approach. This feedback is concrete and direct, giving the authors a clear understanding of what needs to be changed in their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in referring to BigFive and MBTI as models to be extended in the abstract and introduction, while they are used as datasets in the experiments. The comment provides clear guidance on how to address this inconsistency, either by treating them as datasets throughout or providing an extended explanation for their current approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that BigFive and MBTI are inconsistently referred to as models to be extended in the abstract and introduction, while they are used as datasets in the experiments. The reviewer provides a clear and logical reasoning for this inconsistency, suggesting that the authors should either treat them as datasets throughout or provide an extended explanation for their current approach. This reasoning is based on a logical expectation that models and datasets should be consistently categorized. However, the comment does not provide specific examples or references to support the claim, which could strengthen the argument. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the paper, noting that BigFive and MBTI are initially presented as models to be extended in the abstract and introduction, while they are used as datasets in the experiments. The reviewer suggests that the authors should either treat them as datasets throughout or provide an extended explanation for their current approach. This feedback is clear and actionable, as it points out a potential confusion in the paper and offers a straightforward solution. By addressing this inconsistency, the authors can improve the clarity and consistency of their work. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in making this change. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include rejection rates in their experiments or to view them as misclassifications in the results. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to address the feedback. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"any experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of rejection rates or viewing them as misclassifications in the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that rejection rates should be included in the experiments or viewed as misclassifications. The comment provides a logical reasoning by stating that one could view a misclassification as a rejection, which is a valid point. However, it does not provide specific examples or references to support why this is important or how it would impact the results. While the reasoning is clear, the lack of detailed justification or references makes the claim somewhat verifiable, as the authors may need to further explore the implications of including rejection rates. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the presentation of results by noting that rejection rates are not shown in any experiments. It provides a clear suggestion for improvement by recommending that rejection rates be included or viewed as misclassifications in the results. This feedback is actionable and offers a concrete way for the authors to enhance the comprehensiveness of their results, which is valuable for readers and reviewers. However, the comment could be more helpful if it explained why rejection rates are important or how they might impact the interpretation of the results. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for clearer clarification of the advantages of DIMES, specifically its ability to overcome generalization gaps in the fine-tuning step. It also suggests comparing DIMES with other methods on TSP100, both with and without meta-learning. While the comment implies that the authors should provide more detailed explanations and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"generalization to the specific TSP instances (the fine-tuning step in DIMES),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the advantages of DIMES in overcoming generalization gaps and the need for a comparison with other methods on TSP100. This provides clear guidance on what the authors should address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should clarify the advantages of DIMES in overcoming generalization gaps and provides a specific suggestion for comparison with other methods on TSP100. However, the comment lacks detailed reasoning or evidence to support the claim that DIMES has unique advantages or that a comparison with other methods is necessary. The suggestion is somewhat verifiable as it highlights a potential area for improvement, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should clarify the advantages of DIMES in overcoming generalization gaps, particularly in the fine-tuning step. It also proposes a comparison of DIMES with other methods on TSP100, both with and without meta-learning, to further demonstrate the paper\\'s contributions. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the clarity and depth of the paper. However, it could be more helpful if it included specific examples or references to guide the authors in making these comparisons. Overall, the comment is mostly helpful, as it directs the authors to enhance the paper\\'s clarity and comparative analysis, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. This feedback provides clear and direct actions for the authors to take, ensuring that they know exactly what information to include in their draft. The request for final thresholds and hyperparameters is specific and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"the final thresholds that were used for the results\" and \"the full set of hyperparameters,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is also specific because it clearly specifies what information is missing and why it is important for reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. These are factual requests for additional information, which do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests specific information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. This feedback is clear and actionable, as it directly addresses a potential gap in the paper\\'s methodology and transparency. By providing this information, the authors can enhance the reproducibility and credibility of their work. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important for reproducibility. Overall, the comment is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential limitation in the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to their methodology. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of different methods or features on their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the dataset analysis suggesting that readability does not directly affect question difficulty. It also specifies the issue by pointing out that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this depends on the method or features used for answer detection, such as POS/dependency parse features. The comment provides a logical reasoning by pointing out a potential limitation in the claim, which is based on the specific method used. However, it does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this aspect in their analysis, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is somewhat helpful as it points out a specific area where the authors might need to consider the impact of their methodology on their findings. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested alternative methods or features to consider. Overall, the comment is somewhat helpful as it prompts the authors to reconsider their claim and its implications, but it lacks depth and actionable suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific guidance on how to achieve this optimization or what aspects of the figure could be improved. The action is implicit and vague, as the authors are left to infer that they should reduce the amount of whitespace in the figure but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a clear improvement by recommending the use of less whitespace in the figure. This provides clear guidance on what the authors should focus on to enhance their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 could be optimized by using less whitespace. However, it does not provide any reasoning, examples, or references to support why this optimization is necessary or how it would improve the figure. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that Figure 1 could be optimized by using less whitespace. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this optimization or what specific aspects of the figure could be improved. The feedback is somewhat helpful as it points out a possible enhancement, but it does not offer actionable steps or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the geometry of the vector space used in the paper and suggests that the authors provide evidence that the space is meaningful. It also asks whether specific morphological variants can be assigned specific semantics. While the comment implies that the authors should provide evidence or analysis to support the meaningfulness of the vector space, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the analysis or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"geometry of the space\" and \"morphfitting results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear request for evidence or analysis that suggests the morphfitting results in a more meaningful space, not just better embeddings. The comment specifies what kind of analysis would be beneficial, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the geometry of the vector space used in the paper, suggesting that specific morphological variants should be close together and have specific semantics. It also asks for evidence that the geometry of the space is meaningful, such as whether \"looking\" - \"look\" + \"walk\" = \"walking.\" The comment is somewhat verifiable as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the suggestion that the morphfitting results in a more meaningful space. The authors would need to provide additional evidence or analysis to fully address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an important question about the geometry of the vector space used in the paper, specifically whether it allows for the assignment of specific semantics to morphological variants. It suggests that the authors provide evidence or analysis to support the meaningfulness of the vector space, such as whether specific morphological variants can be related to each other in a meaningful way. This feedback is clear and actionable, as it prompts the authors to consider the semantic implications of their vector space and to provide evidence or analysis to support its meaningfulness. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or what specific changes should be made to address the issues with the related work section. The action is implicit and somewhat vague, as the authors are left to infer what specific improvements are needed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment provides a general observation about the writing quality of the paper, suggesting that it should be improved. It mentions specific issues, such as the authors spending the same space on explaining basic memory networks and then the forward model, and the missing pieces in the related work section regarding more reinforcement learning tasks in the literature. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the writing quality and related work sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references makes the claim somewhat verifiable, as it requires more information to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and then the forward model, suggesting that this could be improved by focusing on more relevant content. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature, which is an important area for the paper to address. However, the comment does not provide detailed suggestions or examples on how to enhance the writing quality or what specific tasks should be included in the related work section. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the first column of Qo being replaced by vo to form P\\'o, which makes the first state unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or which assumption should be revised. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise the assumptions, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the first column of Qo is replaced by vo to form P\\'o, which makes the first state unreachable but from a terminating state. The comment further assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the first column of Qo being replaced by vo to form P\\'o, which makes the first state unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. However, the comment does not provide specific reasoning or examples to support this assumption, making it difficult for the authors to understand the basis of the claim. The lack of detailed explanation or references leaves the claim somewhat verifiable, as the authors would need to infer the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the first column of Qo being replaced by vo to form P\\'o, which makes the first state unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. While the comment highlights a specific concern, it does not provide detailed guidance on how the authors should address this issue or clarify which assumption is affected. The feedback is somewhat helpful as it points out a potential problem, but it lacks actionable suggestions or detailed instructions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of how this could be done, such as examining whether the sequential relationship is easier to model with a recurrent model. This feedback is explicit and provides concrete guidance on what the authors should explore, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should explore, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. The reviewer provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This suggestion is based on logical reasoning and a clear understanding of the paper\\'s focus on recurrent models. However, the comment could be strengthened by providing more detailed examples or references to support the claim that accuracy or specific properties might be improved. Therefore, the comment is mostly verifiable, as it provides a solid basis for the suggestion but lacks comprehensive evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This feedback is actionable and offers a clear direction for the authors to explore, which can help them refine their work. However, the comment could be more helpful if it included additional suggestions or examples of specific properties to consider. Overall, the comment is mostly helpful as it provides a constructive and actionable suggestion for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should test this assumption, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to test this assumption or what specific tests should be conducted. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about the testing of this assumption, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper. Without additional context or explanation, the claim remains unverifiable, as the authors are left without clear guidance on how to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. This is an important point that the authors should address to ensure the validity and robustness of their work. However, the comment lacks specificity and does not provide guidance on how to test this assumption or what specific tests should be conducted. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is unclear how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify these aspects, and it is somewhat vague because it does not specify what information should be included or how to present it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the clarity of the \"scoring function\" and the different threshold values/ranges. However, it does not specify which part of the paper discusses these components, making it weakly grounded. The comment is specific in detailing what is unclear, providing a clear indication of what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unclear how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the \"scoring function\" and the different threshold values/ranges. It points out that the authors have not adequately explained how they arrived at these components, which is crucial for understanding the methodology and results. This feedback is clear and actionable, as it directs the authors to clarify these aspects in their draft. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that making factors in a table does not help convey more messages than pure text and that there is no additional information provided. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the draft or what specific changes should be made to enhance the clarity or effectiveness of the information. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of a table to convey information, suggesting that it does not provide additional value compared to pure text. However, it does not specify which table or section of the paper is being referred to, making it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the table are problematic or how it could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that making factors in a table does not help convey more messages than pure text and that there is no additional information provided. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific examples or references to compare the effectiveness of tables versus pure text, the claim remains unverifiable. The authors are left without a clear understanding of why this assertion is valid, making it difficult for them to address the feedback effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the use of a table to convey information, suggesting that it does not provide additional value compared to pure text. However, it lacks specificity and does not offer any actionable suggestions or guidance on how the authors might improve the clarity or effectiveness of their presentation. Without detailed feedback or constructive advice, the authors are left without a clear understanding of what changes to make to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability, as the authors are not provided with any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references to the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide guidance on what aspects of the simulation are being questioned or how to address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the number of different kinds of physical interactions that can be present in a simulation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. While it highlights an area of potential interest or complexity, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this question or what implications it might have for their work. As a result, the comment is not helpful, as it does not offer any actionable insights or direction for the authors to enhance their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific issues with the model comparison, noting that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features and the use of one-hot encoding. The comment provides a clear and explicit action for the authors to take, which is to expand the dataset selection to include more diverse features and consider using one-hot encoding for categorical features. The feedback is concrete and directly guides the authors on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"key contribution\" of the paper, which is the \"thorough comparison of models on a wide range of datasets.\" It also specifies the issue with the dataset selection, noting that only one dataset has categorical features, while all others have exclusively numerical features. This is a clear indication of where the issue lies. The comment is also specific because it details the reasons for the inadequacy of the dataset selection, such as the omission of categorical features and the potential impact on conclusions due to the lack of one-hot encoding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the chosen dataset selection is inadequate for a thorough comparison due to the absence of categorical features and the use of one-hot encoding. The reviewer provides a logical reasoning by explaining that categorical features are generally more challenging for deep learning models, which could affect the conclusions drawn from the comparison. However, the comment lacks specific examples or references to support the claim that the chosen datasets are insufficient. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the model comparison section, highlighting specific issues with the dataset selection. It points out that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features, which are generally more challenging for deep learning models. The comment also notes that the authors do not employ one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it identifies specific areas for improvement and suggests ways to enhance the dataset selection and analysis. By addressing these issues, the authors can significantly strengthen their model comparison and contribute to a more comprehensive evaluation of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the choice of IoT datasets, FlatCam Face [26] and Head-pose detection [11], is unusual and suggests that better options should have been chosen. It provides specific examples of more popular datasets, such as wearable health or mobile activity recognition data, or even sets from UCI. This feedback is clear and actionable, as it directs the authors to consider alternative datasets that might be more relevant and widely used in the field. The authors know exactly what needs to be done to improve their draft by selecting more appropriate datasets for benchmarking. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the two IoT datasets, FlatCam Face [26] and Head-pose detection [11], as unpopular and strange choices. The reviewer provides specific examples of more popular datasets that could have been used, such as wearable health or mobile activity recognition data, or even sets from UCI. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of IoT datasets, FlatCam Face [26] and Head-pose detection [11], is unusual and suggests that better options should have been chosen. The reviewer provides a logical reasoning by stating that the first dataset is relatively recent but not widely followed, and the second is outdated and no longer used. This reasoning is based on common knowledge about the popularity and relevance of datasets in the field. However, the comment could be strengthened by providing specific examples of more popular or relevant datasets that could have been used instead. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks detailed references or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by questioning the choice of two IoT datasets, FlatCam Face [26] and Head-pose detection [11], as unusual and potentially less relevant for benchmarking. The reviewer suggests that more popular or widely used datasets, such as wearable health or mobile activity recognition data, or even sets from UCI, would be better options. This feedback is clear and constructive, offering the authors a specific direction for improving their dataset selection and benchmarking results. By suggesting alternative datasets, the comment empowers the authors to make more informed decisions and enhance the credibility and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the authors\\' approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect of their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to pruning, mentioning that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment does not explicitly mention which part of the paper discusses pruning or where this issue should be addressed, making it weakly grounded. The comment is specific in detailing the potential issue and suggesting a solution, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that pruning primarily works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that finding global top Q values is necessary or how it would impact acceleration techniques. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This feedback is somewhat helpful as it points out a specific area for improvement and provides a suggestion for addressing it. However, the comment could be more helpful if it offered additional context or examples on how to implement this suggestion or why it is important. Overall, the comment provides some direction for the authors to enhance their work, but it could be more comprehensive and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential swapping of subfigures in Figures 1 and 2. While it implies that the authors should check for this mistake, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to verify or correct the issue. The authors can infer that they need to check the figures for consistency, but the comment does not provide detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it raises a question about the potential swapping of subfigures, which provides clear guidance on what needs to be checked for accuracy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking about the potential swapping of subfigures in Figures 1 and 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the potential swapping of subfigures in Figures 1 and 2. While it identifies a potential issue, it lacks depth and does not provide any guidance or suggestions on how the authors might address this concern. The comment does not offer actionable feedback or insights into how the authors might verify or correct the issue, leaving the authors with only a vague indication of a possible problem. Therefore, the comment is barely helpful, as it points out a potential issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the positive impact of the dropout probe, noting that it improves sensitivity and finds a causal role for syntactic representations. However, it also raises a concern about the potential increase in false positives. The reviewer suggests that this should be a substantial part of the discussion, implying that the authors should address this issue in their paper. While the comment highlights a potential concern, it does not provide explicit guidance on how to address it or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the trade-off between sensitivity and false positives. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the positive impact of the dropout probe in finding a causal role for syntactic representations and raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the positive impact of the dropout probe in improving sensitivity and finding a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. The comment provides a logical reasoning by pointing out the trade-off between sensitivity and false positives, which is a common concern in machine learning. However, it does not provide specific examples or references to support the claim about the risk of false positives, making it somewhat verifiable. The authors would need to further explore and substantiate this claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the positive impact of the dropout probe in improving sensitivity and finding a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is somewhat helpful as it identifies a potential trade-off that the authors should consider and address in their paper. However, the comment lacks specific suggestions or guidance on how to balance sensitivity and false positives, or how to discuss this trade-off effectively. While it points out an important area for consideration, it does not provide detailed actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors\\' claim and the actual content of the paper. It points out that the regret bound for the proposed mini-batch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the authors to address the issue. However, the comment does not explicitly instruct the authors to include the regret bound or provide specific guidance on how to address the discrepancy. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or include the regret bound in the appendix. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed mini-batch method being in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the reviewer could not find the regret bound in the supplementary material, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have stated that the regret bound for the proposed mini-batch method is in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the claim. However, the comment does not explicitly state how the referenced work supports the claim or how it relates to the authors\\' work. This lack of detailed explanation or specific references makes the claim somewhat verifiable, as the authors would need to investigate further to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the authors claim the regret bound for the proposed mini-batch method is in the appendix, but the reviewer could not find it in the supplementary material. This is a critical observation that highlights a potential discrepancy or error in the paper. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the authors to address the issue. However, the comment could be more helpful if it included specific suggestions on how to resolve the discrepancy or clarify the location of the regret bound. Despite this, the comment provides valuable insight into a potential flaw in the paper, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper formatting is off and does not follow the NeurIPS formatting style. It specifies that the abstract font is too large and the bottom page margins seem to be altered. The reviewer suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically the non-compliance with the NeurIPS formatting style, the large abstract font, and the altered bottom page margins. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, namely fixing the formatting to gain space and include the NLP experiments in the main body of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style. It provides specific details about the issues, such as the abstract font being too large and the bottom page margins being altered. This level of detail supports the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific NeurIPS formatting guidelines or providing examples of how the formatting should be corrected. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out specific problems, such as the abstract font being too large and the bottom page margins being altered. The comment provides a clear and actionable suggestion for improvement by recommending that the authors fix the formatting to gain space and include the NLP experiments in the main body of the paper. This feedback is valuable as it directly addresses a technical issue that could impact the presentation and readability of the paper. However, the comment could be more helpful if it provided examples or detailed guidance on how to correct the formatting issues. Overall, the comment is mostly helpful, as it offers actionable advice but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the paper for not discussing and comparing various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should include a discussion of these methods, compare them to their approach, or address the critique in any way. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion on exploration methods, but it lacks grounding as it does not point to a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these methods and their relevance to the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting that it does not discuss and compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\\'s contribution and relevance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending which methods to include or how to structure the comparison. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the annotations in Figure 4 should be enlarged for better visibility. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment specifies exactly what needs to be done, making it highly actionable. The authors know exactly how to implement this suggestion by enlarging the annotations in Figure 4, ensuring that the feedback is concrete and actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the annotations in Figure 4 should be enlarged for better visibility. This provides clear guidance on how to improve the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification or improvement regarding the visibility of annotations in Figure 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual statement about the figure, making it a normal statement and fitting the label \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It identifies a particular issue with the visibility of annotations in Figure 4 and recommends enlarging them for better clarity. This feedback is clear and direct, offering the authors a concrete step to enhance the presentation of their results. By addressing this suggestion, the authors can improve the readability and effectiveness of their figure, which is crucial for conveying their findings to the reader. However, the comment could be more helpful if it explained why the annotations are currently difficult to see or provided additional context on how this improvement would benefit the paper. Overall, the comment is mostly helpful as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to document-level RE or joint entity and relation extraction. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion for improvement, clarification, or additional information that the authors should include. As a result, the comment lacks any actionable guidance, leaving the authors without a clear understanding of how to address the issue. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 26-27, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to document-level RE or joint entity and relation extraction. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement describing the existence of multiple entities in both sentences and documents, even in relation classification tasks. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a factual observation about the existence of multiple entities in both sentences and documents, even in relation classification tasks. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how this observation might impact the paper or how the authors could address it. As a result, the comment is not helpful at all, as it does not provide any value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to modify the label on the color bar in Fig. 4, specifying that one of the labels should say \"worse.\" This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, indicating that one of the labels should say \"worse.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement that describes an observation about the color bar in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, pointing out a minor error in the labeling of Figure 4. It provides clear guidance by suggesting that one of the labels on the color bar should say \"worse.\" This feedback is valuable as it directly addresses a specific issue in the figure, allowing the authors to make a precise correction. However, the comment does not offer broader insights or suggestions for improving the overall presentation or interpretation of the figure. Therefore, while it is helpful in addressing a particular issue, it could be more comprehensive if it included additional feedback or context. Overall, the comment is rated as mostly helpful, as it provides clear and actionable feedback but lacks depth in terms of broader improvement suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific error in the manuscript, namely the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets.\" This feedback is clear and direct, providing the authors with a precise action to take to correct the error. The comment is highly actionable as it specifies exactly what needs to be changed, leaving no ambiguity about the necessary action. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction of a typographical error in the manuscript, specifically pointing out the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific typographical error in the manuscript, pointing out that \"training/validation/test\" should be corrected to \"training/validation/test sets.\" This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can ensure the accuracy and clarity of their work. However, the comment does not provide any additional context or explanation about the potential impact of this error on the paper\\'s content or methodology. While it is a useful correction, it could be more helpful if it offered insights into the significance of the error or its potential implications. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and potentially conduct additional analyses, but the feedback lacks specificity and actionable steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique but lacks grounding, as it does not provide clear references to specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies specific areas that need clarification or improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several important questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While it identifies specific areas that need clarification or improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The comment highlights potential weaknesses but lacks actionable advice, making it somewhat helpful. The authors are given some direction but are left to figure out the specifics of how to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. While the comment provides explicit actions, it does not specify which option the authors should choose or how to implement either solution. The lack of detailed guidance makes the comment somewhat actionable, as the authors know what needs to be done but not how to execute it effectively.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential improvement by proposing the addition of an extra pair of brackets or defining the bracketed term separately, if space allows. This provides clear guidance on what needs to be addressed to improve the clarity of the definition. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of the quantile is confusing and suggests potential improvements, such as adding extra brackets or defining the bracketed term separately. However, the comment does not provide any specific reasoning or examples to support why the current definition is confusing or how the suggested changes would improve clarity. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of the quantile, suggesting that it might be confusing. It provides a concrete suggestion for improvement by proposing the addition of an extra pair of brackets or defining the bracketed term separately, if space allows. This feedback is clear and actionable, offering the authors a direct way to enhance the clarity and readability of their work. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on how the suggested changes would benefit the paper. Overall, the comment is mostly helpful as it provides specific guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing the term \"state-of-the-art\" with \"very high performing model\" or a similar phrase in line 152. This is an explicit action that provides a clear direction for the authors to make a specific change in their draft. The comment is concrete because it specifies what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the term \"state-of-the-art\" with \"very high performing model\" or a similar phrase, providing clear guidance on what needs to be changed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model by Dozat and Manning (2016) is no longer state-of-the-art, and it recommends replacing the term \"state-of-the-art\" with \"very high performing model\" or a similar phrase. However, the comment does not provide any supporting evidence or reasoning to justify why the model is no longer state-of-the-art. Without additional context or references, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the terminology used in the paper, suggesting that the term \"state-of-the-art\" may no longer be accurate for the model mentioned. It provides a clear and actionable suggestion to replace it with a more appropriate term, such as \"very high performing model.\" This feedback is valuable as it helps the authors update their language to reflect the current state of the model, ensuring clarity and accuracy in their work. However, the comment could be more helpful if it included additional context or justification for why the term \"state-of-the-art\" is no longer appropriate. Overall, the comment is mostly helpful, as it provides a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific weakness of the proposed method, namely that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this weakness. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this method or where the comparison with PQ is made. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is presented as a main weakness of the method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data to support the assertion, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed method, noting that it performs worse than PQ when a small code length is allowed. This is presented as a main weakness of the method, which is a valuable observation for the authors to consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several subjective statements that need to be supported with proofs and references. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it points out the need for a detailed explanation regarding the use of multi-scale features and when to fuse them. While the comment implies that the authors should provide additional evidence and explanations, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some subjective statements\" and \"proofs and references,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing detailed explanations and references to support subjective statements. Additionally, it highlights specific issues related to the choice of neural architecture and the use of multi-scale features, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some subjective statements in the paper are inappropriate and need to be supported with proofs and references. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment further mentions the need for a detailed explanation regarding the use of multi-scale features and when to fuse them. While the comment identifies areas that require clarification or evidence, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to provide additional information to fully substantiate the claims, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically regarding subjective statements that lack supporting evidence or references. It highlights the need for proofs and references to substantiate claims, particularly in relation to the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, the comment points out the need for a detailed explanation regarding the use of multi-scale features and when to fuse them. While the comment provides clear guidance on what needs to be addressed, it could be more helpful by offering specific suggestions on how to provide the necessary evidence or explanations. Overall, the feedback is mostly helpful as it directs the authors to enhance the rigor and clarity of their claims, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for a comparison of the proposed method with prior art, but it does not provide any guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and vague, as the authors are left to infer that they need to provide a comparison but without concrete details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment asks for a comparison of the proposed method with prior art, but it does not specify which part of the paper this comparison should be included in. The authors cannot confidently determine which section or subsection this comment pertains to, making it weakly grounded. However, the comment is specific in its request for a comparison with prior art, which provides some guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on how the proposed method compares with prior art. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment asks for a comparison of the proposed method with prior art, which is a relevant and important aspect of any research paper. However, it lacks specificity and does not provide guidance on how to conduct this comparison or what specific aspects should be considered. Without detailed suggestions or examples, the authors may find it challenging to address this feedback effectively. Therefore, the comment is barely helpful, as it identifies an area for improvement but does not offer actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data that includes various languages and nationalities. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. While the comment implies that the authors should expand their analysis to include more detailed comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more detailed analyses and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the different languages and nationalities included. It expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. However, the comment does not specify which part of the paper this analysis is currently presented in, making it weakly grounded. The suggestion for more detailed analysis is specific, as it highlights a particular aspect of the data that could be explored further. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the different languages and nationalities included. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses could be more detailed or to justify the need for such comparisons. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for the claim but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the analyses could be more detailed. It highlights the \"language/nationality\" data, which includes various languages and nationalities, and points out that biases towards different languages/nationalities might be of interest. The comment expresses curiosity about potential observations that could be made by comparing these different languages/nationalities. While it provides a clear direction for further analysis, it lacks specific suggestions or examples on how to conduct these comparisons or what aspects to focus on. This limits the comment's usefulness, as it offers a general idea but does not fully guide the authors in implementing the suggested improvements. Therefore, the comment is somewhat helpful, as it provides some direction but could be more comprehensive and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there are other properties of features that could be used besides norm. It implies that the authors should consider exploring additional properties to enhance their approach design. However, the comment does not provide explicit guidance on how to identify or evaluate these properties or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore other properties and determine how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for consideration of other properties, but without clear grounding, the authors may struggle to determine where this feedback fits into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the approach. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. This is a relevant point that could prompt the authors to consider expanding their analysis to include other properties, potentially leading to a more comprehensive understanding of their approach. However, the comment lacks specificity and does not provide detailed guidance on how to explore or evaluate these additional properties. While it identifies a potential area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is somewhat helpful, as it provides some direction but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the behavior of the learning F^\\dagger in terms of maintaining certain mathematical properties, such as mass or charge conservation. It explicitly asks whether it is possible to train the model in a way that preserves these properties and requests an illustration of the conservation properties in Hamiltonian systems. These questions provide clear and explicit actions for the authors to take, including conducting numerical experiments to demonstrate the conservation properties. The feedback is highly actionable as it specifies exactly what the authors need to do to address the concerns raised.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises questions about the behavior of the learning F^\\dagger in terms of maintaining certain mathematical properties, such as mass or charge conservation. It explicitly mentions \"symplectic integrators\" and \"Hamiltonian systems,\" which provides a clear context for the authors to identify the relevant parts of the paper being addressed. However, the comment does not specify which section or subsection it pertains to, making it weakly grounded. The comment is specific in its request for an illustration of the conservation properties, providing clear guidance on what the authors should address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the behavior of the learning F^\\dagger in terms of maintaining certain mathematical properties, such as mass or charge conservation. It suggests that some solvers' algorithms can guarantee the preservation of these properties and asks whether the learning F^\\dagger can do the same. The comment provides a logical reasoning by referencing the use of symplectic integrators and Hamiltonian systems, which are known to preserve certain properties. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct further research or experiments to fully address the questions raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an important question about the behavior of the learning F^\\dagger in terms of maintaining certain mathematical properties, such as mass or charge conservation. It suggests that some solvers' algorithms can guarantee the preservation of these properties and asks whether the learning F^\\dagger can do the same. The comment also requests an illustration, at least numerically, of how well or not these properties are conserved in Hamiltonian systems. This feedback is highly actionable as it provides clear guidance on an area for further investigation and improvement, offering a specific direction for the authors to explore. By addressing these questions, the authors can enhance the rigor and applicability of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several weaknesses in the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what changes are needed and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the weaknesses, such as the method being constructed on top of previous methods and the lack of network changes or losses. Additionally, it questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the method being constructed on top of previous methods, questioning the novelty of the approach. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the concerns. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires more information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the method, specifically noting that it is mostly constructed on top of previous methods and lacks network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. While the comment highlights areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their approach. The feedback is somewhat helpful as it points out potential weaknesses, but it lacks actionable advice, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the redundancy of RQ1 and suggests an alternative analysis that could be more interesting, specifically focusing on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 t-sne plots. While the comment implies that the authors should consider this alternative analysis, it does not explicitly instruct them to do so. The suggestion is concrete, but the action is implicit, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the redundancy of RQ1 and suggesting an alternative analysis that could be more interesting. The reference to an external work provides additional context and specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that RQ1 is redundant and suggests an alternative analysis that could be more interesting. The reviewer provides a specific suggestion for an alternative analysis, which is supported by a reference to an external work. This external reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples within the paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the paper, specifically questioning the need for RQ1, which is expected to show performance variations across multiple hate speech datasets. It suggests an alternative analysis that could be more interesting, focusing on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 t-sne plots. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their analysis and potentially improving the relevance and depth of their work. However, the comment could be more helpful if it included additional guidance on how to implement this alternative analysis or why it would be more beneficial. Overall, the comment is mostly helpful, as it offers a constructive suggestion for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include tasks beyond link prediction where PE (Positional Encoding) is important. However, it does not provide any explicit or implicit guidance on how to identify or implement these additional tasks. The comment lacks concrete details or suggestions on what specific tasks should be included or how to incorporate them into the paper. As a result, the authors are left without a clear understanding of what actions to take to address this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper should include tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what specific tasks should be included or how they would be relevant. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs revision. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it is expected to see a variety of tasks beyond link prediction where PE (Positional Encoding) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this expectation. Without additional context or references, the claim remains vague and difficult for the authors to understand or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper should include tasks beyond link prediction where Positional Encoding (PE) is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on how to incorporate these additional tasks or why they are relevant. The feedback is somewhat vague and does not offer actionable advice, leaving the authors with a general idea of what could be improved but without a clear path forward. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to elaborate on the differences between their work and other papers focusing on semantic face editing, specifically mentioning a reference paper. This request is clear and provides a direct action for the authors to take, which is to explain the distinctiveness of their work compared to the referenced paper. The comment is specific and provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"other works focusing on semantic face editing\" and references a specific paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: elaborating on the differences between the authors\\' work and the referenced papers. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the existence of other works focusing on semantic face editing and their ability to achieve continuous control over different attributes. The reviewer supports this claim by referencing a specific paper, \"[1],\" which provides a basis for the claim. However, the comment does not elaborate on the specific differences between the referenced work and the authors\\' work, leaving some gaps in the justification. While the reference to \"[1]\" is a step towards verification, the comment could be strengthened by providing more detailed comparisons or examples. Therefore, the claim is mostly verifiable, as it requires additional information to fully substantiate the differences.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that there are other works focusing on semantic face editing that demonstrate the ability to achieve continuous control over different attributes. It specifically references a paper, \"[1],\" which the authors are asked to elaborate on. This feedback is clear and actionable, as it prompts the authors to clarify the differences between their work and these other papers, providing a specific direction for improvement. By addressing this point, the authors can enhance the comprehensiveness and originality of their work. Therefore, the comment is rated as mostly helpful, as it offers a clear path for improvement but could be more comprehensive with additional guidance or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the quality of the set of policies, \\\\overline{\\\\Pi}, with the performance in the worst MDP rather than using a summation. The reviewer provides a clear rationale for this suggestion, explaining that using a summation might hide the performance of policies that are very good for most MDPs but very bad for the remaining ones. This feedback is explicit and provides concrete guidance on how to improve the evaluation methodology. The authors know exactly what action to take to address this issue, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"intuitive goal\" and the evaluation of \\\\overline{\\\\Pi} with the performance in the worst MDP, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to evaluate the quality of \\\\overline{\\\\Pi} using the performance in the worst MDP rather than a summation, and it explains why this approach would be more appropriate. This level of detail and specificity helps the authors understand what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests evaluating the quality of the set of policies, \\\\overline{\\\\Pi}, with the performance in the worst MDP rather than using a summation. The reviewer provides a logical reasoning for this suggestion, explaining that using a summation might hide the performance of policies that are very good for most MDPs but very bad for the remaining ones. This reasoning is clear and provides a rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the set of policies, \\\\overline{\\\\Pi}. It suggests evaluating the quality of \\\\overline{\\\\Pi} with the performance in the worst MDP rather than using a summation, which could potentially hide the performance of policies that are very good for most MDPs but very bad for the remaining ones. This feedback is specific and offers a concrete alternative approach that could enhance the robustness of the evaluation. By addressing this point, the authors can significantly improve the comprehensiveness and accuracy of their analysis. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. It provides a specific example of where this could be done, suggesting that details around parameter settings could be moved to the appendix. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the excessive use of footnotes and suggests moving content into the main body of the paper. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that footnotes are used excessively, which is distracting and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting that details around parameter settings could be moved to the appendix. This reasoning is logical and provides a clear suggestion for improvement, making the claim mostly verifiable. However, the comment could be strengthened by providing more examples or specific instances of excessive footnote usage, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the excessive use of footnotes in the paper, which is distracting and should be addressed. It provides a clear and actionable suggestion to move content from footnotes into the main body of the paper, particularly mentioning details around parameter settings that could be moved to the appendix. This feedback is valuable as it directs the authors to a concrete improvement that can enhance the readability and organization of their paper. However, the comment could be more helpful if it provided additional context or examples of how to effectively integrate the content into the main body. Overall, the comment is mostly helpful, as it offers actionable guidance but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a set of few-shot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. It also questions the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks relevance. However, the comment does not provide explicit guidance on how to implement the suggestion for few-shot demonstrations or how to address the concern about zero-shot generation results. The actions are implicit and somewhat vague, as the authors are left to infer what specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the inclusion of zero-shot generation results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The comment further suggests that a set of few-shot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The reviewer provides a logical reasoning by questioning the relevance of zero-shot results in the context of the paper, which is a valid critique. However, the comment does not provide specific examples or references to support why zero-shot results are unnecessary or how they could be improved. This makes the claim somewhat verifiable, as it lacks detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks relevance in the context of the paper. It also suggests that a set of few-shot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This feedback is somewhat helpful as it points out a specific area for improvement and provides a suggestion for enhancing the paper. However, the comment could be more helpful if it offered more detailed guidance on how to implement the suggestion for few-shot demonstrations or why the zero-shot results are not relevant. Overall, the comment provides some direction but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text and suggesting that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific issue, it does not provide explicit instructions on how to address it. The authors can infer that they need to either update the caption or include a reference to \"OAA\" in the body text, but the comment lacks concrete guidance on which action to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of \"OAA\" not being referenced in the body text and suggests that there might be more content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about Figure 3, specifically noting that \"OAA\" is not referenced in the body text. The reviewer suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to investigate the issue themselves to determine its validity. Therefore, the comment is somewhat verifiable, as it provides a basis for further investigation but requires more detailed evidence or explanation to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment points out a specific issue, it lacks depth and does not provide actionable guidance on how to address the problem. The authors are left with a vague understanding of what needs to be corrected, making the feedback somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify in the introduction that their proposed solution is a \"fix\" of a previous work, rather than a new PIC approach. It provides specific guidance by suggesting how to rephrase the introduction to address this issue. The comment is clear and direct, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and lines 29-30, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the distinction between the proposed solution being a \"fix\" of a previous work rather than a new PIC approach. The comment also provides a suggestion for how to rephrase the introduction to address this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors need to clarify that their proposed solution is a \"fix\" of a previous work, rather than a new PIC approach. The comment provides a specific reference to lines 29-30, where the authors introduce their framework, and suggests that this framework has already been proposed by [12]. This provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including a direct reference to [12] or providing more detailed reasoning about why the distinction is important. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by pointing out a potential confusion in the introduction regarding the nature of the proposed solution. It suggests that the authors clarify that their approach is a \"fix\" of a previous work, rather than a new PIC approach, as introduced in lines 29-30. This feedback is valuable as it helps the authors avoid misinterpretations and ensures that their work is accurately represented. However, the comment could be more helpful if it included specific suggestions on how to rephrase the introduction to address this issue. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference, which is not specified in the comment. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions on how to compute the effective receptive field or what specific method to use. The action is implicit and somewhat vague, as the authors need to infer the need for computation and determine the method themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effective receptive field and suggests that it could be computed from a reference, which is not specified in the comment. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference, which is not specified in the comment. While the comment implies that the authors should investigate this aspect, it lacks specific references or detailed reasoning to support the claim. The suggestion is somewhat verifiable, as it points to a potential area for improvement but does not provide sufficient evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference, which is not specified in the comment. This feedback is somewhat helpful as it identifies a potential area for further exploration and analysis, prompting the authors to consider the impact of the GS module on the receptive field. However, the comment lacks specific guidance or suggestions on how to conduct this analysis or what metrics to use, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the objective for the LSTM part would be the same for pre-training and finetuning, as it involves computing the probabilities of actions. It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. While the comment provides some guidance on potential changes, it does not explicitly instruct the authors to make these modifications. The action is implicit and somewhat vague, as it lacks specific instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the objective for the LSTM part, specifically mentioning the probabilities of actions and the potential addition of a head for computing value functions in the finetuning stage. However, it does not specify which part of the paper this discussion is located in, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the potential changes to the LSTM part, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the objective for the LSTM part would be the same for pre-training and finetuning, as it involves computing the probabilities of actions. It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this approach is appropriate or effective. The suggestion is somewhat verifiable, as it provides a logical rationale but lacks concrete evidence or detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion regarding the objective for the LSTM part, noting that it would be the same for pre-training and finetuning (computing the probabilities of actions). It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. This feedback is clear and actionable, offering a concrete suggestion for improving the draft by clarifying the objectives and potential modifications to the network architecture. However, it could be more helpful if it included additional context or rationale for why this suggestion would enhance the paper. Overall, the comment is mostly helpful as it provides valuable guidance for the authors to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind combining G4RL with HRAC (HRAC-G4RL) and whether G4RL requires HRAC\\'s regularization in the latent space. While it does not explicitly instruct the authors to provide an explanation or address these questions, the comment implies that the authors should clarify these points. The action is implicit but clear, as the authors can infer that they need to provide an explanation or clarification. However, the comment lacks concrete guidance on how to address these questions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the rationale behind combining G4RL with HRAC (HRAC-G4RL) and whether G4RL requires HRAC\\'s regularization in the latent space. However, it does not specify which part of the paper discusses this combination or where the authors should address these questions. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in its questions about the rationale and requirements, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC (HRAC-G4RL) and whether G4RL requires HRAC\\'s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the rationale behind combining G4RL with HRAC (HRAC-G4RL) and whether G4RL requires HRAC\\'s regularization in the latent space. This feedback prompts the authors to clarify the reasoning behind their approach, which is crucial for understanding the methodology and its implications. However, the comment does not provide specific suggestions or guidance on how to address these questions or improve the clarity of the explanation. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should acknowledge older works in addition to the \"long line of work\" mentioned in the related works section. While the comment implies that the authors should include these older works, it does not specify which specific works should be acknowledged or how to integrate them into the text. The action is implicit and somewhat vague, as the authors need to infer which works to include and how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in addition to the \"long line of work\" mentioned, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge older works in addition to the \"long line of work\" mentioned in the related works section. However, the comment does not provide specific examples or references to the older works that should be acknowledged, making it difficult for the authors to understand which works are being referred to. Without detailed guidance or examples, the claim lacks sufficient support, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that the authors should acknowledge older works in addition to the \"long line of work\" mentioned in the related works section. This feedback is clear and actionable, as it provides a specific direction for improvement by encouraging the authors to include a broader range of references. However, the comment could be more helpful if it offered examples of specific older works that should be acknowledged or provided guidance on how to integrate them into the text. Despite this, the suggestion is valuable and can help the authors enhance the comprehensiveness and historical context of their work. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results in Table 2, specifically the comparison between linear-/exponential-decay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for top-performing predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to clarify or further explore the results in Table 2. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, questioning the logic behind the comparison between linear-/exponential-decay sampling and uniform sampling. The comment provides a clear rationale for why the results are confusing and suggests a potential explanation for the observed underperformance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results in Table 2, specifically the comparison between linear-/exponential-decay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for top-performing predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the results in Table 2, specifically the comparison between linear-/exponential-decay sampling and uniform sampling. It suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for top-performing predicted architectures should lead to better performance than uniform sampling. This feedback is somewhat helpful as it points out a potential inconsistency or misunderstanding in the results, prompting the authors to reconsider their analysis or provide further explanation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses. Therefore, while it identifies a potential area for improvement, it does not provide comprehensive or actionable feedback, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights concerns about the time complexity of the method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the time complexity. The comment lacks actionable details, such as recommending optimizations or alternative approaches, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concerns about time complexity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity seems high, providing three reasons: the use of an item-oriented autoencoder, the elementwise function, and the large number of hidden units. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed explanation makes the claim somewhat verifiable, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the large number of hidden units. This feedback is somewhat helpful as it points out areas that might contribute to the time complexity, prompting the authors to consider optimizations or alternatives. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending specific optimizations or providing examples of alternative approaches. While it highlights a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a clear and explicit action for the authors to take, which is to modify the figures to include this information. The suggestion is concrete, as it specifies exactly what needs to be changed to improve the clarity of the figures. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the figures should specify \"pre-trained solution encoders & solution decoders\" to clarify the types of autoencoders used. This level of detail guides the authors on what changes to make to enhance the clarity of their figures. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion that the current figures are unclear. The authors would need to infer the exact nature of the confusion based on the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the figures by recommending that they specify \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and comprehensibility of their figures. By addressing this suggestion, the authors can improve the readability and understanding of their work for both reviewers and readers. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment implies that the authors should make these comparisons, it does not provide explicit instructions on how to implement them or why these comparisons are necessary. The action is implicit and somewhat vague, as the authors need to infer the specific comparisons and improvements needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion to include comparisons with specific methods is specific, but the comment lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides some context by mentioning specific methods, it lacks detailed reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. The claim is somewhat verifiable, as it highlights potential areas for improvement but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It suggests that the authors should include comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e,\" which could provide a more comprehensive evaluation of the method. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment highlights important areas for improvement, it could be more helpful by providing specific guidance on how to incorporate these comparisons or by explaining why the occlusion experiment is not relevant. Overall, the feedback is somewhat helpful as it points out potential enhancements but lacks detailed suggestions for implementation. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment consists of two parts. The first part suggests that a brief explanation of \"multi-aspect\" would be helpful, which is an explicit request for clarification. The second part provides a specific correction regarding the subscripts in Figure 1, which is also explicit. Both parts are clear and provide concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as explaining \"multi-aspect\" and correcting the subscripts in Figure 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for clarification regarding the term \"multi-aspect\" and a suggestion to correct the subscripts in Figure 1. Neither part contains subjective opinions, judgments, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback, addressing two distinct issues in the paper. First, it suggests that a brief explanation of the term \"multi-aspect\" would be helpful, which is a clear and direct request for clarification. Second, it points out a typographical error in Figure 1, specifically regarding the subscripts s and t, which should be 1 and 2, respectively. This feedback is valuable as it helps the authors improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or explanation for why the clarification or correction is important. Overall, the feedback is mostly helpful, as it directs the authors to specific areas that need attention, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. It explicitly requests a more detailed analysis. While the comment does not provide specific instructions on how to conduct this analysis, it clearly identifies the areas that need further exploration. The authors know that they need to provide a more detailed analysis of the extraction process and its effects on the experiment. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for a more detailed analysis, which provides some guidance on what the authors should address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the extraction process and its potential impact on the experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the extraction process and its potential impact on the experiment. It specifically asks how the parts of sentences and documents are extracted and whether the extraction rules have any effect on the experiment. This feedback is valuable as it prompts the authors to provide a more detailed analysis of their methodology, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of what a detailed analysis might entail. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request provides a clear and direct action for the authors to take, as it specifies exactly what information is needed. The authors know exactly what to include in their draft to address this feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request is specific and provides clear guidance on what the authors need to address. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for additional information about the computation required to implement the experiments and the duration and hardware used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests additional information about the computation required to implement the experiments, including the duration and hardware used. This feedback is somewhat helpful as it prompts the authors to provide more detailed information about the experimental setup, which can be beneficial for readers interested in replicating or understanding the experiments. However, the comment does not offer specific suggestions on how to present this information or why it is important, leaving the authors with a general direction but without detailed guidance. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled manner and when it is applied. It explicitly asks for more discussion on this aspect and when the meta sampler is started. This provides clear and direct guidance for the authors, as they know exactly what information is missing and what they need to address in their paper. The comment is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the meta sampler,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for more discussion on the application of the meta sampler and when it is started, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on the application of the meta sampler. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the application of the meta sampler, asking whether it is used in a decoupled manner and when it is applied. It requests additional discussion on this aspect, which is a clear and actionable suggestion for the authors to enhance their paper. By addressing this point, the authors can provide more context and clarity to their readers, potentially improving the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered additional guidance or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it identifies a gap in the paper and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Consumption. It also encourages the authors to follow a specific AAAI paper that they have cited. While the comment implies that the authors should incorporate these suggestions, it does not provide explicit instructions on how to implement them or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a \"vanilla metric\" and the lack of related fairness-aware metrics like Equality odds (EO). It also suggests conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper. This provides clear guidance on what needs to be addressed and where, making it easy for the authors to identify the relevant parts of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors use their own defined \"vanilla metric\" and lack related fairness-aware metrics like Equality odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper. The comment provides a clear suggestion for improvement by recommending the use of specific fairness-aware metrics and datasets, which is supported by the reference to the AAAI paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how these metrics or datasets would enhance the study. Overall, the claim is mostly verifiable, as it provides a solid basis for improvement but lacks comprehensive justification or detailed examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the use of a \"vanilla metric\" without considering related fairness-aware metrics like Equality odds (EO). It suggests that the authors conduct more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper for guidance. This feedback is clear and actionable, providing the authors with a concrete direction for improving their work by incorporating fairness-aware metrics and expanding their dataset analysis. However, the comment could be more helpful if it included specific suggestions on how to implement these fairness-aware metrics or detailed guidance on using the referenced paper. Overall, the comment is mostly helpful as it offers valuable insights and a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rephrase a section of the paper (lines 107-114) as a remark, an aside in the Discussion section, or to remove it entirely. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 107-114, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the content is speculative or overly opinionated and suggests that it should be rephrased as a remark or an aside in the Discussion section or removed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 107-114 are speculative or overly opinionated, suggesting that they should be rephrased as a remark or an aside in the Discussion section or removed. However, the comment does not provide any specific examples or detailed reasoning to support why these lines are problematic. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (lines 107-114) as being speculative or overly opinionated. It provides a clear and actionable suggestion to rephrase this section as a remark or an aside in the Discussion section or to remove it entirely. This feedback is valuable as it guides the authors on how to improve the clarity and focus of their work by either rephrasing or removing content that may be perceived as subjective or unnecessary. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement resulting from the changes proposed in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of these baselines, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, the comment does not provide any reasoning or evidence to support why these specific baselines are relevant or how they would contribute to the verification process. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the experimental validation of the paper. However, the comment could be more helpful if it explained why these particular baselines are relevant or how they would contribute to the verification process. Additionally, it does not offer guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two missing elements in the paper: the value of neighborhood size h and an analysis of its influence on the model\\'s performance, as well as the use of different hyperparameter sets per dataset. It suggests that the authors provide insights into how performance varies with a constant set of parameters. These actions are clear and concrete, giving the authors specific tasks to address in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\\'s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely an analysis of the influence of h and the use of different hyperparameter sets per dataset. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an analysis of the value of neighborhood size h and its influence on the model\\'s performance, which is considered a key parameter of the proposed strategy. It also notes the use of different hyperparameter sets per dataset, suggesting that this is not ideal. The comment provides a logical reasoning for the importance of analyzing the neighborhood size and its impact on performance, as well as the need for consistency in hyperparameter sets. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of these elements based on the provided reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two important areas for improvement in the paper. First, it points out the absence of an analysis of the value of neighborhood size h and its influence on the model\\'s performance, which is a key parameter of the proposed strategy. This feedback is actionable as it suggests that the authors should include an analysis of the impact of h on the model\\'s performance, providing readers with a better understanding of the method\\'s robustness. Second, the comment highlights the use of different hyperparameter sets per dataset, which is not ideal, and asks for insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, offering the authors specific directions for enhancing their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. While it does not explicitly instruct the authors to address this issue, it implies that the authors should consider and discuss this aspect in their paper. The question is somewhat vague, as it does not provide specific guidance on how to investigate or address the issue. However, the authors can infer that they need to explore the effects of missing data on the model and its ability to infer missing modalities. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the effects of missing data and the model\\'s ability to infer missing modalities, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. The comment does not present a claim or opinion but rather poses a question seeking clarification. It is purely factual and does not require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. It prompts the authors to consider the potential compounding effects of missing data and how the model might leverage additional modalities to infer missing ones. This feedback is somewhat helpful as it identifies a potential area for further exploration and discussion in the paper. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as proposing methods or experiments to investigate the impact. To be more helpful, the comment could include actionable steps or examples to guide the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the SST dataset, specifically asking for statistics on the times negation or intensity words take effect. It suggests showing the frequency of words like \"nothing\" and how often they change the polarity of the context. While the comment implies that the authors should provide these statistics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these statistics and how to present them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the SST dataset and suggests showing statistics on the times negation or intensity words take effect, such as the frequency of words like \"nothing\" and their impact on polarity. This provides clear guidance on what additional information could be included to enhance the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion regarding the SST dataset. It asks for statistics on the times negation or intensity words take effect, such as the frequency of words like \"nothing\" and their impact on polarity. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the SST dataset, suggesting that the authors provide statistics on the times negation or intensity words take effect. It specifically mentions the word \"nothing\" and its impact on polarity, which is a clear and actionable suggestion for enhancing the paper. By addressing this point, the authors can provide more detailed insights into the dataset, which could be valuable for readers and reviewers. However, the comment could be more helpful if it provided additional context or examples of how these statistics might be presented or analyzed. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the stability of the OGE-Aug on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability of their method on these benchmarks, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the stability of the OGE-Aug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. However, it does not specify which part of the paper discusses these benchmarks or how the authors should address the issue. The authors can infer that it relates to the experimental results or methodology sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the issue with the stability of the method on the DrugOOD dataset, but it does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not verified the stability of the OGE-Aug method on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific concern about the stability of the OGE-Aug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. This feedback highlights a potential gap in the evaluation of the method, which is important for ensuring the robustness and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. While it points out a relevant area for improvement, the comment could be more helpful if it included actionable advice or examples of how to verify stability on these benchmarks. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider alternative methods, such as freezing layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. While the comment implies that the authors should explore these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement these suggestions. However, the authors can infer that they should consider these methods and potentially include them in their experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering alternative methods, such as freezing layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative methods for comparison, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering alternative methods, such as freezing layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. The comment provides a logical reasoning by suggesting that these methods are natural to think about and could provide a valuable basis for comparison. However, it lacks specific examples or references to support the claim that these methods are relevant or beneficial in the context of the paper. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors consider alternative methods, such as freezing layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. This feedback is somewhat helpful as it provides a direction for the authors to explore additional approaches that could enhance their study. However, the comment lacks specific guidance on how to implement these suggestions or why they are relevant to the current work. While it offers a potential avenue for improvement, the lack of detailed advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides clear guidance on what needs to be addressed, making the comment fully grounded. However, it does not specify which part of the related work section needs expansion or which baselines should be compared, leaving some room for ambiguity. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. The lack of supporting evidence or detailed justification makes the claim difficult for the authors to understand and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to expand the related work section by comparing the work to strong baselines that use coordinates. This feedback is valuable as it directs the authors to enhance the context and relevance of their work by highlighting its relationship to existing strong baselines. However, the comment could be more helpful if it specified which baselines should be considered or provided examples of how to make these comparisons. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement that can strengthen their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and provides a direct action for the authors to take, which is to conduct additional experiments with multiple seeds. The suggestion is concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of single-seed experiments, which limits the assessment of performance differences and the impact of the proposed cycle consistency loss. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is somewhat verifiable as it provides a logical reasoning for the need for multiple seed experiments to ensure the robustness of the results. However, the comment lacks specific examples or references to support the claim that single-seed experiments are insufficient. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper\\'s experimental setup, specifically the use of a single seed for training. It highlights the difficulty in assessing the significance of performance differences and the impact of the proposed cycle consistency loss on convergence due to this limitation. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and actionable, offering a specific improvement that the authors can implement to enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided guidance on how to conduct these multiple seed experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While the comment implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify their rationale but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice of distributions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. The comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The comment highlights a gap in the paper but lacks actionable feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, noting that it requires an entire multi-GPU setup for optimizations, which may limit its accessibility to potential users. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or suggestions for alternative approaches that could make the method more accessible. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed method, specifically mentioning that it requires an entire multi-GPU setup for optimizations, which may limit its accessibility to potential users. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. The authors can infer that it relates to the methodology or experimental setup sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it identifies a potential limitation, it does not provide specific guidance on how to address it or suggest alternative approaches. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method requires an entire multi-GPU setup for optimizations, which limits its accessibility to potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the need for a multi-GPU setup, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, noting that it requires an entire multi-GPU setup for optimizations, which may limit its accessibility to potential users. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or explore alternative approaches to make the method more accessible. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing citation for the public skip-gram data set in line 425. This provides a clear and direct action for the authors to take, which is to include the missing citation. The comment is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing a citation for the public skip-gram data set. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement requesting a citation for a specific data set mentioned in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, pointing out a missing citation for a public skip-gram data set in line 425. This feedback is valuable as it directs the authors to a particular area where they need to make a correction, ensuring the integrity of their references. However, the comment could be more helpful if it provided context or explained why this citation is important. Despite this, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It implies that the authors should consider Ref-[2] as a strong baseline for comparison. While the comment provides a clear action to compare the current system with another system that captures semantics, it does not specify which aspects of the current system should be compared or how to implement the comparison. The suggestion to use Ref-[2] as a baseline is also vague, as it does not provide specific guidance on how to incorporate this reference into the comparison. Therefore, the comment is mostly actionable, as it identifies a clear action but lacks concrete details on how to execute it.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It implies that Ref-[2] could be a strong baseline for comparison. However, the comment does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to implement the comparison. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It implies that Ref-[2] could be a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why Ref-[2] is a suitable baseline or how it would provide a meaningful comparison. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors would need to infer the relevance of Ref-[2] themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It implies that this comparison could provide valuable insights into the performance of the current system. Additionally, the comment suggests using Ref-[2] as a strong baseline for comparison, which could help the authors benchmark their work effectively. While the comment identifies a potential area for improvement and provides a specific suggestion, it lacks detailed guidance on how to implement the comparison or what specific aspects should be focused on. This limits the comment\\'s helpfulness, as it provides a general direction but not a comprehensive plan for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the quantitative results, specifically asking how the data is used for training, validation, and testing. While the comment implies that the authors should provide more detailed information on the data used, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the data usage but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these results are presented. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification on the data usage, but without grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This is a factual inquiry that does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the data used in their analysis. By addressing this point, the authors can enhance the transparency and reproducibility of their results, which is crucial for the credibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or offered examples of best practices in data reporting. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset. It questions whether one of the assumptions is not satisfied or if there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the model\\'s performance. The comment lacks actionable details, such as recommending specific tests or analyses to determine the cause of the problem. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the model\\'s performance in identifying true sources in the triangle dataset, but it does not specify which part of the paper discusses this issue. The authors cannot confidently determine which section or subsection this comment pertains to, making it weakly grounded. However, the comment is specific in questioning whether one of the assumptions is not satisfied or if there are learning difficulties. This provides some guidance on what might be causing the issue, even though it does not specify where in the paper these assumptions or difficulties are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the model\\'s performance in identifying true sources in the triangle dataset, questioning whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the model\\'s performance in identifying true sources in the triangle dataset, questioning whether one of the assumptions is not satisfied or if there are learning difficulties. This is a relevant observation that could help the authors identify potential issues with their model. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address these concerns. It does not offer insights into what assumptions might be problematic or how to improve the model\\'s performance. As a result, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explain why and how their SE framework can help improve, similar to the feedback provided in comment 2. It also suggests that the authors should not just show what they have achieved but should explain the reasoning behind their achievements. This feedback is clear and provides a direct action for the authors to take, which is to provide a detailed explanation of the benefits and mechanisms of their framework. The reference to a similar comment in point 2 further clarifies the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation of how the SE framework helps improve and why it is beneficial. The comment provides a reference to a similar issue in point 2, which further clarifies the expectation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification and a suggestion for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely a request for additional information and guidance, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by asking the authors to explain why and how their SE framework can help improve, similar to the feedback given in comment 2. It emphasizes the importance of not only showing what has been achieved but also explaining the reasoning and methodology behind the achievements. This feedback is specific and constructive, offering the authors a clear direction for improving their draft by providing a more comprehensive explanation of their work. However, the comment could be more helpful if it included suggestions on how to present this explanation or examples of what might be included. Overall, the comment is mostly helpful as it guides the authors toward enhancing the clarity and depth of their manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or improve the generalizability of the approach. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper discusses the limitation or how the authors could address this issue. The comment is not grounded as it does not refer to a specific section, figure, or table, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, it lacks specificity regarding what aspects of the approach should be improved or how to generalize to more views. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation exists or how it could be addressed. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this limitation. The comment is somewhat helpful as it prompts the authors to consider expanding the generalizability of their approach, but it does not offer detailed advice or examples on how to achieve this. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It suggests that these metrics might not be applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that could be more suitable. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative metrics or adapt their evaluation approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in detailing the limitations of these metrics in certain settings, such as when task boundaries are unknown or not clearly defined. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in settings where task boundaries are unknown or not clearly defined. The comment provides a logical reasoning by explaining that these metrics are specific to the datasets provided and may not be suitable for other settings. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the broader applicability of these metrics and potentially explore alternative evaluation methods, which could be a challenge without detailed guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the \"loss after switch\" and \"recovery time after switch.\" It points out that these metrics may not be applicable in settings where task boundaries are unknown or not clearly defined. This feedback is somewhat helpful as it highlights a specific area where the evaluation methodology might need refinement. However, the comment lacks actionable suggestions or guidance on how the authors could address this issue or explore alternative metrics. To be more helpful, the comment could include recommendations for alternative evaluation approaches or specific metrics that might be more suitable in different settings. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder rather than using information from all time steps. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the rationale behind this choice or potentially revise the approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the user decoder\\'s information usage, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder. This is a relevant observation that could lead to a clearer understanding of the methodology and its limitations. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to take, which is to include this discussion in their paper. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion on the arbitrary hyperparameter \u03b3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice for a given graph and the analysis of its sensitivity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This is a subjective claim that requires justification or evidence to support the assertion that such a discussion is necessary or beneficial. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion of the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a specific area where the authors can enhance their paper by providing additional context and analysis. By addressing these points, the authors can improve the comprehensibility and utility of their work for researchers. However, the comment could be more helpful if it provided suggestions on how to approach these discussions or examples of similar analyses in related works. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. It implies that a controlled baseline should be included, which ablates heads at different locations in the model. While the comment identifies a potential confounding factor and suggests a way to address it, it does not provide specific instructions on how to implement this controlled baseline. The action is explicit but somewhat vague, as the authors know they need to include a controlled baseline but may not be entirely sure of the exact methodology. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"induction heads and FV heads\" and their \"location\" within the model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. The comment further suggests a controlled baseline that ablates heads at different locations in the model. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. The reviewer provides a logical reasoning by pointing out that induction heads and FV heads are located at different layers, which could be a confounding factor. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confounding factor in the analysis of induction heads and FV heads, specifically the \"location\" of these heads within the model. It suggests that a controlled baseline should be included, which ablates heads at different locations in the model to isolate the effect of head location on ICL performance. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their analysis by controlling for this confounding factor. However, the comment could be more helpful if it offered additional guidance on how to implement this controlled baseline or suggested specific locations to consider. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their analysis, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that a section on synonym identification is missing under similarity measurement, suggesting that the authors should include this section to describe how the multiple-choice task is approached. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to their draft. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions a missing section on synonym identification under similarity measurement, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies what is missing, namely a description of how the multiple-choice task is approached, which adds clarity to the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiple-choice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this section or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks a section on synonym identification under similarity measurement, which would describe how the multiple-choice task is approached. This feedback is clear and actionable, as it provides a direct suggestion for improvement by specifying what the authors should include in their draft. However, the comment could be more helpful if it offered additional guidance on how to approach this section or what specific aspects should be covered. Despite this, the comment is mostly helpful as it directs the authors to a clear area for enhancement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the Methodology section, noting that the model architecture description is confusing and uses inconsistent notation. It points out a particular inconsistency with the notation $v^p_{t-1}$, which does not appear in the equations, and clarifies that the notation initially suggests a sequence of tokens is being generated as the label, which is not the case. While the comment highlights specific issues, it does not provide explicit guidance on how to address these inconsistencies or improve the clarity of the methodology section. The authors can infer that they need to clarify the notation and ensure consistency throughout the section, but the comment lacks concrete steps or suggestions for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Methodology section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the model architecture description, noting inconsistencies in notation and providing specific examples, such as the absence of $v^p_{t-1}$ in the equations and the initial impression that a sequence of tokens is being generated as the label. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Methodology section is confusing and uses inconsistent notation. It provides specific examples, such as the absence of $v^p_{t-1}$ in the equations and the initial impression that a sequence of tokens is being generated as the label, which are clear and verifiable. However, the comment could be strengthened by providing more detailed explanations or references to specific sections where these issues occur. Overall, the claim is mostly verifiable, as it provides sufficient evidence to support the critique but lacks comprehensive detail. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the Methodology section, noting that the model architecture description is confusing and uses inconsistent notation. It provides concrete examples, such as the absence of $v^p_{t-1}$ in the equations and the initial impression that a sequence of tokens is being generated as the label, which is not the case. This feedback is clear and actionable, as it directs the authors to clarify and standardize their notation, ensuring consistency and clarity in the methodology section. By addressing these issues, the authors can significantly improve the readability and comprehensibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide explicit guidance on how to create this overview or what specific elements should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide an overview but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not specify which part of the paper lacks this overview or where it should be included. The authors can infer that it might be in the introduction or the methodology section, but this inference is not explicit. The comment is specific in suggesting what is needed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a more comprehensive introduction. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this overview or what specific elements should be included. While it points out a general area for enhancement, it does not offer actionable steps or detailed suggestions, leaving the authors with a vague idea of what needs to be addressed. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential bias in the sketch due to the need to compute the statistical dimension d_lambda of the design matrix A. It suggests that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment implies that the authors should address this issue by discussing it in the paper, but it does not provide explicit instructions on how to do so. While the action is implicit, it is somewhat actionable as it points out a potential issue that the authors should consider. However, the lack of concrete guidance on how to address the issue limits its actionability.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the computation of the statistical dimension d_lambda of the design matrix A, which is crucial for debiasing the sketch. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue and its potential impact on the approach, but the lack of explicit grounding limits the score to 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the statistical dimension d_lambda of the design matrix A is necessary for debiasing the sketch, but this computation requires the same runtime as solving the ridge regression problem, potentially defeating the purpose of the approach. The reviewer supports this claim by providing a logical reasoning that the computation is challenging and could introduce bias. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially seek additional evidence to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the debiasing of the sketch, specifically the need to compute the statistical dimension d_lambda of the design matrix A. It points out that this computation requires the same runtime as solving the ridge regression problem, which could introduce bias and potentially defeat the purpose of the approach. The comment also mentions a similar issue when computing the surrogate sketch. While the comment highlights a critical concern, it does not provide specific suggestions or guidance on how the authors might address these issues or mitigate the potential bias. This limits the comment\\'s helpfulness, as it identifies a problem but lacks actionable advice. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to redefine the figure in Figure 3, as the expected quantities are scalars but are shown as a vector. This is a clear and direct action for the authors to take, providing specific guidance on how to improve the draft. The comment is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure-3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the redefinition of the figure to show scalar quantities instead of vectors. This provides clear guidance on how to improve the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the presentation of data in Figure 3, specifically suggesting that the expected quantities should be shown as scalars rather than vectors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of data in Figure 3. It points out that the expected quantities are shown as vectors, which is incorrect, and requests that they be redefined as scalars. This feedback is clear and direct, offering the authors a concrete way to enhance the clarity and accuracy of their figures. By addressing this issue, the authors can improve the readability and understanding of their results. However, the comment could be more helpful if it explained why the quantities should be shown as scalars or provided additional context on the implications of this change. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup due to the questions that arise. However, it does not provide specific guidance on how to improve the setup or what questions need to be addressed. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup due to the questions that arise. However, it does not specify which ablation experiments are being referred to or what specific questions need to be addressed. This lack of detail makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment does not provide specific guidance on how to improve the experiment setup or what aspects need to be clarified. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup due to the questions that arise. However, the comment does not provide specific examples of these questions or how the current setup is inadequate. Without detailed reasoning or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup due to the questions that arise. However, it does not provide specific details or examples of these questions, nor does it offer guidance on how to improve the experiment setup. Without actionable suggestions or detailed feedback, the authors are left without a clear understanding of what needs to be addressed or how to improve their work. This lack of specificity and guidance makes the comment barely helpful, as it does not provide meaningful direction for the authors to enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed models are useful for learning representations for low-frequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. While the comment implies that the authors should conduct additional experiments or analyses to substantiate their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what metrics to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the aspect of the paper being addressed, namely the proposed models\\' usefulness for learning representations for low-frequency words. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and the need for deeper exploration. However, it does not provide specific guidance on how to address these issues or what additional evidence or analysis would be beneficial. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the proposed models are useful for learning representations for low-frequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request. However, the comment does not provide specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional experiments to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks empirical evidence to support its claims about the usefulness of the proposed models for learning representations of low-frequency words. It suggests that the authors should explore this aspect further by providing empirical evidence, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what metrics to use. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the resolution of the 3D voxel and its impact on the network\\'s computational and memory costs. It suggests that studying the importance of the global feature in Section 4.2 by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the suggested comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the resolution of the 3D voxel and its impact on the network\\'s computational and memory costs. The comment suggests studying the importance of the global feature by comparing with different resolutions of voxel features, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the resolution of the 3D voxel and its impact on the network\\'s computational and memory costs. It suggests that studying the importance of the global feature by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the computational and memory costs. This makes the claim somewhat verifiable, as the authors would need to conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the resolution of the 3D voxel and its impact on the network\\'s computational and memory costs. It suggests that studying the importance of the global feature by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature, which could be a valuable insight for the authors. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what specific resolutions to consider. This limits the comment\\'s helpfulness, as it provides a direction but not a detailed roadmap for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the error analysis on the movie dataset is missing, and it highlights the importance of understanding the cases where the model fails. This provides a clear and direct action for the authors to include an error analysis in their draft. The comment is specific about what needs to be addressed, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to conduct an error analysis on the movie dataset. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the absence of an error analysis on the movie dataset, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses the movie dataset, making it weakly grounded. The comment is specific in its request for an error analysis to help other researchers continue the task, but it lacks detailed guidance on how to conduct this analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the importance of the error analysis or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. This is a critical aspect that other researchers would need to understand in order to continue working on the task. The comment provides a clear and actionable suggestion for improvement by highlighting the importance of understanding the cases where the model fails. However, it could be more helpful if it offered specific guidance on how to conduct the error analysis or what aspects to focus on. Despite this, the comment is mostly helpful as it directs the authors to a crucial area that needs attention, providing a clear path for improvement. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It also suggests that it would be interesting to see development set trends with respect to these hyper-parameters. While the comment implies that the authors should provide additional analysis or trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add more analysis but are not given specific guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular trend that is difficult to see and suggests that the development set trends should be analyzed with respect to the hyper-parameters. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer also suggests that it would be interesting to see development set trends with respect to these hyper-parameters. However, the comment lacks specific examples or detailed reasoning to support why these trends are not apparent or how they could be analyzed further. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends in the behavior of PM+CL compared to PM or CL alone. It suggests that it would be interesting to see development set trends with respect to these hyper-parameters. This feedback is clear and actionable, as it points out a potential area for improvement in the analysis and presentation of results. By suggesting a specific aspect to focus on, the comment provides the authors with a clear direction for enhancing their draft. However, it could be more helpful if it included additional guidance on how to analyze or present these trends. Overall, the comment is mostly helpful, as it effectively directs the authors to improve their draft by addressing a specific issue in the results section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a difficulty in understanding Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could report flops or model size to make the metrics more concrete. While the comment implies that the authors should include additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to report flops or model size. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely the difficulty in understanding due to the overlapping lines, and suggests that reporting flops or model size would make the metrics more concrete. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is difficult to understand Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could report flops or model size to make the metrics more concrete. However, the comment lacks specific examples or detailed reasoning to support why these additional metrics would improve understanding or make the figure more concrete. Without such evidence or explanation, the claim is somewhat verifiable, as it provides a suggestion but lacks sufficient justification or examples to fully substantiate the need for these additional metrics. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the presence of many lines on top of each other. It suggests that the authors could improve the figure by reporting flops or model size, which would make the metrics more concrete. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the clarity and comprehensibility of their figures. However, the comment could be more helpful if it included additional guidance on how to report these metrics or examples of how they might be presented. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or how the authors should address this issue. The comment lacks explicit guidance or concrete suggestions on what needs to be added or clarified, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which part of the paper these questions are from, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding which details are missing, leaving the authors without clear guidance on what needs to be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references to what details are missing, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or provide any guidance on how the authors might address this issue. Without specific feedback or suggestions, the authors are left without actionable insights to improve their draft. The comment lacks depth and clarity, making it barely helpful at best. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper is dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It explicitly recommends simplifying the description and explaining the architecture and computations better, specifically mentioning Figure 7, Section 8, and lines 39-64 as areas that could be reduced to gain more space. This feedback provides clear and actionable guidance on how to improve the clarity and readability of the paper, making it highly actionable. The authors know exactly what needs to be done to address the issue, which is to simplify the description and explanations, and they are given specific sections to focus on. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figure 7, Section 8, and lines 39-64, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by noting that the paper is dense and difficult to follow, suggesting simplification and better explanations of the architecture and computations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The reviewer suggests simplifying the description and explaining the architecture and computations better. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is dense or how it could be simplified. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s readability, noting that it is dense and difficult to follow, requiring multiple reads to understand the concepts and contribution. It provides a clear and actionable suggestion to simplify the description and explain the architecture and computations better, specifically mentioning Figure 7, Section 8, and lines 39-64 as areas that could be reduced to gain more space. This feedback is valuable as it directs the authors to specific sections that need improvement, offering a concrete way to enhance the clarity and accessibility of the paper. However, the comment could be more helpful if it included additional suggestions or examples of how to simplify the content. Overall, the comment is mostly helpful, as it provides clear guidance for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the performance of EIGNN with respect to over-smoothing under standard settings on real-world datasets, particularly in comparison with variants that focus on dealing with over-smoothing, such as GCNII. This comment explicitly states an action for the authors to take, which is to conduct additional evaluations and comparisons. However, it does not provide specific guidance on how to implement these evaluations or which datasets to use. While the action is clear, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the performance of EIGNN with respect to over-smoothing under standard settings on real-world datasets, particularly in comparison with variants that focus on dealing with over-smoothing, such as GCNII. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in suggesting a particular area of interest and a comparison with existing work, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to evaluate the performance of EIGNN with respect to over-smoothing under standard settings on real-world datasets, particularly in comparison with variants focusing on dealing with over-smoothing, such as GCNII. The comment provides a logical reasoning for the suggestion, as it highlights the importance of evaluating the model's performance in a standard setting and in comparison with existing work. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting direction for further evaluation of the EIGNN model, specifically in terms of its performance with respect to over-smoothing under standard settings on real-world datasets. It highlights the importance of comparing EIGNN with variants that focus on dealing with over-smoothing, such as GCNII. This feedback is clear and actionable, as it provides a specific area for the authors to explore and potentially improve their work. However, the comment could be more helpful if it included suggestions on how to conduct these evaluations or which datasets to use. Overall, the comment is mostly helpful as it offers a valuable direction for enhancing the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing part in the approach method, specifically the lack of a separate section or subsection to introduce the inference strategy. It clearly states that the authors should include a part or subsection to explain how to use the multiple prompts in the test stage. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be added to their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the absence of a separate part or subsection to introduce the inference strategy. It highlights the need to explain how multiple prompts are used in the test stage, which is a critical aspect of the approach method. This feedback is clear and actionable, as it provides a direct suggestion for improvement by specifying what the authors should include in their draft. However, it could be more helpful if it offered additional guidance on how to structure this section or provided examples of similar approaches. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance the clarity and completeness of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 4 is confusing and that the columns are not explained in the text or caption. This provides a clear action for the authors to take, which is to clarify the meaning of the columns in the figure by either adding an explanation in the text or updating the caption. The feedback is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure. The comment highlights the lack of explanation in the text or caption, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 is confusing because the columns are not explained in the text or caption. However, it does not provide any further explanation or reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the columns are confusing and not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure by either adding an explanation in the text or updating the caption. By addressing this feedback, the authors can enhance the clarity and accessibility of their work, making the comment mostly helpful. However, the comment could be more helpful if it provided suggestions on how to clarify the figure or offered examples of how to improve the explanation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the experiment results and the real-world applications of the proposed problem setting. It suggests that the authors should discuss the results more thoroughly, particularly regarding the conclusion that MaxGapTop2UCB is better than other methods. Additionally, it questions the applicability of the new problem setting to sorting/ranking and the computational complexity of the proposed algorithms. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The feedback is somewhat actionable as it highlights important aspects that need further discussion or clarification, but it lacks specific guidance on how to address these issues. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"the real-world applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing the results more thoroughly and clarifying the applicability to sorting/ranking. The comment provides specific examples and questions, making it clear and actionable. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims and questions, making it a combination of factual statements and claims. The first claim about the experiment results suggests that the authors should discuss the results more thoroughly, particularly regarding the conclusion that MaxGapTop2UCB is better than other methods. This claim is somewhat verifiable as it highlights a potential area for improvement but lacks specific examples or detailed reasoning to fully substantiate the claim. The second claim questions the real-world applications of the new problem setting, specifically the applicability to sorting/ranking and the computational complexity of the proposed algorithms. This part of the comment is more factual, as it describes the current state of the discussion and raises questions for further exploration. Overall, the comment is a mix of factual statements and claims, with some elements being somewhat verifiable and others being more factual. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of factual observations and suggestions for improvement. It highlights the need for more discussion on the experiment results, specifically questioning whether the conclusion that MaxGapTop2UCB is better than other methods is justified. It also raises concerns about the real-world applications of the new problem setting, questioning the applicability to sorting/ranking and the computational complexity of the proposed algorithms. While the comment identifies important areas for clarification and improvement, it lacks specific guidance or detailed suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need further exploration, but it could be more actionable with additional guidance or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations, it does not explicitly instruct them to do so or offer specific guidance on what aspects of the results or explanations should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment does provide some specificity by suggesting that more explanations are needed, but it lacks detailed guidance on what aspects of the results or explanations should be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. However, the comment lacks specific examples or references to the early methods mentioned, such as f-CLSWGAN [4] and f-VAEGAN-D2 [5], which would help substantiate the claim. Without these details, the authors may find it challenging to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed, which could provide valuable insights into the performance differences. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the results or explanations should be addressed. While it identifies a potential area for improvement, the feedback is somewhat vague, making it somewhat helpful. The authors are given a direction to explore but without clear steps to take, limiting the comment\\'s usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation analysis in the main paper, which makes it challenging to identify the source of a small performance gain. While the comment implies that an ablation analysis should be included, it does not explicitly instruct the authors to conduct one. The action is implicit and somewhat vague, as the authors can infer that they need to add an ablation analysis but are not provided with specific guidance on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of ablation analysis in the main paper, which makes it difficult to identify the source of a small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or methodology sections, but this inference is not explicit. The comment is specific in pointing out the need for an ablation analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis makes it difficult to pinpoint the source of a small performance gain. This is a subjective opinion based on the reviewer\\'s expectation of what should be included in the paper. However, the comment does not provide specific examples or detailed reasoning to support why an ablation analysis is necessary or how it would improve the paper. Without such evidence or justification, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a significant gap in the paper by pointing out the absence of an ablation analysis, which is crucial for understanding the source of a small performance gain. This feedback is clear and actionable, as it highlights a specific area where the authors can improve their draft by conducting an ablation analysis. By addressing this issue, the authors can provide a more comprehensive understanding of their results and enhance the clarity and robustness of their findings. However, the comment could be more helpful if it suggested specific components to analyze or provided examples of how an ablation analysis might be conducted. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a finding from Figure 2, stating that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. It also mentions the use of \"Th.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this finding should be addressed, whether it requires further explanation, or if it has any implications for the paper. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to Figure 2, which allows the authors to identify the specific part of the paper being addressed. It specifies that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. However, it does not provide any further details or suggestions on how this finding should be addressed or what implications it has for the paper. The comment lacks specificity regarding what needs to be done to improve the paper based on this observation. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point makes a factual observation about the noise rate of similarity labels compared to class labels, as shown in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. The statement is purely descriptive and does not contain any claims or requests for changes. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment makes a factual observation about the noise rate of similarity labels compared to class labels, as shown in Figure 2. It notes that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. However, the comment does not provide any context, analysis, or suggestions for how this observation might impact the paper or what implications it has for the authors. Without additional guidance or actionable feedback, the authors are left without a clear understanding of how to address this finding or its significance. Therefore, the comment is barely helpful, as it identifies a potential observation but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the hypothesis is interesting but not well verified by the designed experiment. It highlights a specific issue with the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer recommends comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve the experiment and its motivation, which is to make it more convincing. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental setup, suggesting a comparison between the model trained on the original dataset and that trained on the mixture to highlight the impact of the augmented adversarial examples. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the hypothesis is interesting but not well verified by the designed experiment. It provides a specific critique of the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer suggests comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is supported by logical reasoning and a clear explanation of the issue, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer suggests comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, providing the authors with a specific direction to improve the validity and persuasiveness of their experimental results. By addressing this critique, the authors can strengthen the motivation and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined to enhance the credibility of the experiments. As a result, the comment lacks actionability, leaving the authors without guidance on how to address the issue. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in, nor does it provide details on what aspects of the experiments are not convincing. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. Without additional context or suggestions for improvement, the authors are left without actionable feedback on how to enhance the credibility of their experiments. The comment lacks depth and specificity, making it barely helpful at best. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention that the results for model (3) (Chung et al. 2016) for Cs-En were computed by themselves, as they are not reported in the papers. This provides a clear and direct action for the authors to take, ensuring that the comment is highly actionable. The feedback is specific and leaves no ambiguity about what needs to be done, making it easy for the authors to implement the suggested change.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results for model (3) (Chung et al. 2016) for Cs-En, noting that these results were not taken from the papers and suggesting that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for model (3) (Chung et al. 2016) for Cs-En were not taken from the papers, as they are not reported. The reviewer suggests that if the authors computed these results themselves, they should mention it. This claim is somewhat verifiable as it is based on the observation that the results are not reported in the papers, which is a factual statement. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, such as why the authors should mention their own computations. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 1, noting that the results for model (3) (Chung et al. 2016) for Cs-En were not taken from the papers, as they are not reported. The comment suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, providing the authors with a direct way to improve the transparency and accuracy of their results. By addressing this issue, the authors can enhance the credibility and completeness of their work. Therefore, the comment is rated as mostly helpful, as it offers specific guidance that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should place more emphasis on prompt design, given that different prompts can lead to varying performance outcomes. However, it does not provide specific guidance on how to effectively design prompts or what aspects of prompt design should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss prompt design in more detail but without concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, specifically mentioning the introduction of several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper should focus more on prompt design or where the discussion on different prompts and their performance outcomes should be included. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in its suggestion to discuss prompt design effectively, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, given the potential impact of different prompts on performance outcomes. However, the comment does not provide specific examples, references, or detailed reasoning to support why this emphasis is necessary or how it could be achieved. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of prompt design based on the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should place more emphasis on prompt design. It acknowledges the introduction of several prompting methods to address issues in MenatQA and highlights the importance of discussing how to design prompts effectively. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that could benefit from further exploration and discussion. However, the comment could be more helpful if it provided specific suggestions or examples on how to effectively design prompts. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. This is an explicit action that provides a clear direction for the authors to follow. The suggestion is concrete, as it specifies a particular model to compare with, making it easy for the authors to understand and implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the results with state-of-the-art approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be made in, such as the results section or a specific experiment. This lack of explicit reference to a particular section makes it weakly grounded. The comment is specific in suggesting a comparison with HateXplain models, which provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. This is a request for additional analysis or comparison, but it does not contain a claim or opinion that requires verification. It is a suggestion for improvement, which is factual and does not necessitate verification. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. This feedback is somewhat helpful as it provides a clear direction for the authors to enhance their work by benchmarking against established models. However, the comment lacks depth and does not offer specific guidance on how to conduct the comparison or what aspects to focus on. While it identifies a potential area for improvement, it does not provide detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it implies that the authors should provide a clearer explanation for their choice of freezing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what additional information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, it does not specify which part of the paper discusses the freezing method or where the MLS selection process is described. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the freezing method but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why freezing is not a suitable choice or why an adaptive method would be better. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. The comment points out a potential weakness but does not offer actionable advice or examples to help the authors improve their draft. Therefore, the feedback is somewhat helpful, as it prompts the authors to reconsider their approach but does not fully support them in making those changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper in their future work. While the comment explicitly states that the authors should include a detailed plan, it does not specify what aspects of the limitations should be addressed or how to structure the plan. The action is explicit but lacks concrete guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which limitations or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is specific in its request for a detailed plan but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not provide any specific examples or reasoning to support why the current plan is insufficient or how a more detailed plan would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the authors have mentioned limitations in their paper but suggests that they should provide a more detailed plan on how they plan to address these drawbacks in their future work. This feedback is somewhat helpful as it encourages the authors to be more specific and transparent about their plans for improvement. However, it lacks depth and does not provide detailed guidance on what aspects of the limitations should be addressed or how to structure the plan. While it points out an area for improvement, it does not offer actionable steps or suggestions, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the issue addressed in the existing work is also solved in the proposed knowledge-CLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KG-augmented method can robustly handle these changes. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the issue addressed in existing work is also solved in the proposed knowledge-CLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KG-augmented method can robustly handle these changes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting a particular analysis that could be conducted, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the issue addressed in existing work is also solved in the proposed knowledge-CLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KG-augmented method can robustly handle these changes. The comment references an external work (https://arxiv.org/abs/2104.06378) that has done closely-related analyses, providing some support for the suggestion. However, the comment lacks specific examples or detailed reasoning from the authors' work, making it somewhat verifiable. The authors would need to further develop the claim with their own analysis to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an interesting question about whether the issue addressed in existing work is also solved in the proposed knowledge-CLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KG-augmented method can robustly handle these changes. This feedback is somewhat helpful as it provides a specific suggestion for further analysis that could enhance the paper. However, the comment could be more helpful if it offered more detailed guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is somewhat helpful as it prompts the authors to consider an additional analysis that could strengthen their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues with the paper. First, it questions the use of p m in the numerator and p c in the denominator in Eq. 3, asking for clarification on the reason for this choice. Second, it suggests that the authors consider adding the variance for further improvement in Alg. 2, and it recommends replacing \u03bc f with \u03bc g to maintain consistency with Eq. The comment provides explicit actions for the authors to take, such as clarifying the reasoning behind the equation and considering the addition of variance. The suggestions are concrete and direct, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the confusion regarding the use of p m and p c in Eq. 3 and suggests adding the variance for further improvement in Alg. 2. Additionally, it provides a suggestion to replace \u03bc f with \u03bc g to maintain consistency with Eq. This level of detail and specificity helps the authors understand exactly what needs to be addressed and improved in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific issue with the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reasoning behind this choice. It also suggests that the authors consider adding the variance for further improvement in Alg. 2 and recommends replacing \u03bc f with \u03bc g to maintain consistency with Eq. These suggestions are based on logical reasoning and a desire for clarity and consistency in the paper. However, the comment lacks specific references or detailed explanations to fully substantiate the claims, making it somewhat verifiable. The authors would need to provide additional context or justification to fully understand and address the points raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, including the confusion in Eq. 3 regarding the use of p m and p c in the numerator and denominator, respectively. It also suggests that the authors consider adding the variance for further improvement in Alg. 2 and recommends replacing \u03bc f with \u03bc g to maintain consistency with Eq. These suggestions are clear and actionable, providing the authors with concrete steps to improve the clarity and consistency of their work. By addressing these points, the authors can enhance the comprehensibility and rigor of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the computational cost of the proposed approach and suggests that the paper should provide a more comprehensive discussion on the computational complexity. It also questions whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so or provide specific guidance on how to conduct the additional discussion or analysis. The action is implicit and somewhat vague, as the authors need to infer that they should expand the discussion on computational complexity and consider prohibitive settings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of computational cost, specifically questioning the lack of a comprehensive discussion on the computational complexity of the proposal. It also raises a concern about whether the approach becomes prohibitive in certain settings. However, the comment does not specify which part of the paper discusses the computational cost, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in its request for a more comprehensive discussion and consideration of prohibitive settings, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the computational cost of the proposed approach, questioning the lack of a comprehensive discussion on the computational complexity. The reviewer suggests that the paper should provide more details on this aspect, particularly regarding whether the approach becomes prohibitive in certain settings. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the concern and how to address it. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the discussion of computational cost. It points out that while the paper mentions the additional cost not leading to significant delays in computation, it lacks a comprehensive discussion on the computational complexity of the proposal. The reviewer also raises a question about whether the approach becomes prohibitive in certain settings. This feedback is clear and actionable, as it prompts the authors to expand their discussion on computational complexity and consider potential limitations or prohibitive factors. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of what a comprehensive discussion might entail. Overall, the comment is mostly helpful, as it directs the authors to an important area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is an explicit request for additional clarification, which is clear and actionable. The authors know exactly what needs to be done to improve their draft by adding more explanation on this topic. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line 97, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more explanation about how novel values in the test set are handled. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors clarify an aspect of their methodology that may be unclear to readers. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or examples of what specific information should be included. Overall, the feedback is mostly helpful as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that similar methods for multi-task learning have already been proposed and have not been discussed in the paper. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should address this issue, discuss the existing methods, or incorporate them into their work. Without any actionable steps or suggestions, the authors are left without a clear understanding of what they should do to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that similar methods for multi-task learning have already been proposed and have not been discussed in the paper. However, it does not specify which part of the paper should address this issue, such as a specific section or discussion. Additionally, it does not provide details on what aspects of these methods should be discussed or how they relate to the current work. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs revision. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that similar methods for multi-task learning have already been proposed and have not been discussed in the paper. However, it does not provide any references or examples of these existing methods, making it difficult for the authors to verify the claim. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the claim or how to address it in their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that similar methods for multi-task learning have already been proposed and have not been discussed in the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or incorporate these existing methods into their work. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an expectation that the amount of computation for FedMITR is higher than other methods and asks for a comparison. While the comment implies that the authors should compare the computation of FedMITR with other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to perform a comparison but are not given specific guidance on how to conduct it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of FedMITR compared to other methods, but it does not specify which part of the paper this comparison should be made in. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for a comparison, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is expected or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to conduct the comparison or what aspects to focus on. The comment is somewhat helpful as it prompts the authors to consider an important aspect of their work, but it does not offer detailed suggestions or actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors can avoid using \"1) and2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify which parts of the paper should be revised or how to implement the suggestion of using a generic external knowledge base. Additionally, the comment mentions that the writing is confusing, but it does not provide specific guidance on how to clarify it. As a result, the action is implicit and lacks concrete details, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, it does not specify which parts of the paper these references are from, making it weakly grounded. The comment also mentions that the writing is confusing, but it does not provide specific details on what is confusing or how to clarify it. This lack of specificity and grounding makes it difficult for the authors to identify and address the issues effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations of how using a generic external knowledge base would address the issues mentioned. Without additional context or justification, the claim remains unverifiable, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what exactly \"1) and2)\" refer to. Additionally, the comment mentions that the writing is confusing, but it does not offer any specific feedback or suggestions on how to clarify it. This lack of actionable advice and detailed guidance makes the comment barely helpful, as it provides only a general direction without concrete steps for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions, such as replacing the min with a mean or NDCG. While the comment implies that the authors should provide more details on their methodology and consider alternative loss functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions. However, it does not specify which part of the paper discusses this methodology or where the authors should address these questions. The authors might infer that it relates to the experimental setup or methodology sections, but this is not explicitly mentioned. The comment is specific in suggesting alternative loss functions but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they might impact the paper. The comment consists of a series of questions without any elaboration or justification, making it difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the methodology used in the paper, specifically regarding the selection of 0.6 for glove embedding similarity and the potential impact of using alternative loss functions. It also suggests exploring other influential loss functions, such as replacing the min with a mean or NDCG. While the comment identifies areas for improvement and provides some direction, it lacks specific guidance on how to address these questions or suggestions. The authors are left with a general understanding of what needs to be explored but without detailed instructions on how to implement these changes. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing in-depth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be included. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a missing in-depth analysis and provides a concrete example of what is lacking, namely the analysis of why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. This level of detail guides the authors on what specific aspect of the analysis needs further exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing in-depth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the analysis of experimental results. It points out a gap in understanding why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is clear and actionable, as it prompts the authors to conduct a more in-depth analysis to explain these findings. However, the comment could be more helpful if it provided suggestions on how to approach this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several actions for the authors to consider, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines for feature extraction. The reviewer also expresses skepticism about the effectiveness of the proposed method, noting that similar interventions have failed in the past. While the comment provides explicit suggestions, it lacks concrete guidance on how to implement these changes or address the skepticism. The authors are given a clear direction but may need to infer the specific steps to take, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests several changes, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing the changes that need to be made, such as the number of examples for input mask explanation annotations and the recommendation for modern backbone baselines. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method of training on labeled data and incorporating input mask explanation annotations might not be effective, citing the failure of similar interventions in the past. However, the comment lacks specific examples or references to these failed interventions, making it difficult for the authors to fully understand and address the critique. The claim is somewhat verifiable as it provides a general rationale but lacks detailed evidence or examples to substantiate the skepticism. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper, such as training on labeled data and incorporating input mask explanation annotations. It also recommends using modern backbone baselines for feature extraction, which is a clear and actionable piece of feedback. However, the comment is somewhat vague in its skepticism about the effectiveness of the proposed method, as it does not provide detailed reasoning or evidence to support this claim. While the suggestions are helpful, the lack of detailed critique or evidence regarding the skepticism limits the comment\\'s overall helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method to ensure a fair comparison. This is an explicit action, as it directly instructs the authors to address a specific issue related to the hyperparameter tuning of the baseline. However, the comment does not provide concrete guidance on how to implement this action, such as which hyperparameters to focus on or how to conduct the tuning. While the action is clear, the lack of detailed instructions makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of multiple hyperparameters and the extensive hyperparameter search, specifically mentioning \"temperature, penalty, and threshold.\" However, it does not specify which part of the paper discusses these hyperparameters or the hyperparameter search, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, which could impact the fairness of the comparison with the proposed method. The reviewer recommends ensuring that the baseline is fully tuned with similar resources as the proposed method. However, the comment lacks specific examples or references to support the claim about the impact of hyperparameters on the comparison. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a logical suggestion but lacks sufficient justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and the baseline due to the extensive hyperparameter search. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method could improve the fairness of the comparison. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it offered guidance on how to conduct the hyperparameter tuning or provided examples of similar resources. Overall, the comment is mostly helpful, as it directs the authors to a critical aspect of their work that requires attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a mistake in the definition of perplexity and provides a correction. It also points out that the equation presented does not look like perplexity but rather like cross-entropy. This feedback is clear and provides direct guidance on what needs to be corrected in the draft. The authors know exactly what needs to be changed to ensure accuracy in their definitions and equations. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and provides a correction, stating that it is not what perplexity is and that the equation presented does not look like perplexity but rather like cross-entropy. This level of detail guides the authors on what needs to be corrected in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of perplexity at line 259 is incorrect and that the equation presented (Eq1) does not look like perplexity but rather like cross-entropy. This claim is verifiable as it provides a clear and specific correction to the definition of perplexity, which is a well-established concept in natural language processing. The comment also references the equation, which allows the authors to verify the claim and make necessary corrections. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the definition of perplexity, pointing out that the explanation provided in the paper is incorrect. It also corrects the equation presented, stating that it does not look like perplexity but rather like cross-entropy. This feedback is clear and actionable, as it directly addresses a misunderstanding in the paper and provides a correction. By pointing out these errors, the comment empowers the authors to make necessary changes to improve the accuracy and clarity of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors clarify the condition \\\\eta \\\\ge C_0 for some constant C_0 in Proposition 6.1, noting that the signal-to-noise ratio \\\\eta is typically a small value. It also recommends comparing this condition with that in Section 4 (correct model case). This feedback provides clear and specific actions for the authors to take, including further clarification and comparison. The concrete guidance on what needs to be done and how to implement it makes this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Proposition 6.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the condition \\\\eta \\\\ge C_0 for some constant C_0, noting that the signal-to-noise ratio \\\\eta is typically a small value. The comment further suggests that the authors clarify this condition and compare it with the condition in Section 4 (correct model case). This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition \\\\eta \\\\ge C_0 for some constant C_0 in Proposition 6.1 is strong, given that the signal-to-noise ratio \\\\eta is typically a small value. The comment suggests that the authors clarify this condition and compare it with the condition in Section 4 (correct model case). While the claim is based on a logical reasoning that the condition might be too stringent, it lacks specific examples or references to support the assertion. The suggestion to clarify and compare the conditions is reasonable, but the comment could be strengthened with more detailed justification or evidence. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires additional support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the condition \\\\eta \\\\ge C_0 for some constant C_0 in Proposition 6.1, noting that the signal-to-noise ratio \\\\eta is typically a small value. It suggests that the authors clarify this condition and compare it with the condition in Section 4 (correct model case). This feedback is clear and actionable, as it points out a specific area that may need further explanation or justification. By suggesting a comparison with another section, the comment provides a concrete step for the authors to take to improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included specific suggestions on how to clarify or compare the conditions. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should add more baselines for graph classification tasks, specifically mentioning MVGRL[4] and gpt-gnn[5] as examples. It also requests that these baselines be tested on common datasets. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"graph classification task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the baselines MVGRL[4] and gpt-gnn[5], and requests the addition of more baselines from graph contrastive learning and their testing on common datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gpt-gnn[5]. The reviewer suggests adding more baselines from graph contrastive learning and testing them on common datasets. However, the comment lacks specific reasoning or evidence to support why these particular baselines are necessary or how they would improve the study. The suggestion is somewhat verifiable as it provides a direction for improvement but lacks detailed justification or examples, making it difficult for the authors to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the insufficient comparison of baselines in the graph classification task. It points out the absence of MVGRL[4] and gpt-gnn[5] as potential baselines, suggesting that the authors should include more baselines from graph contrastive learning and test them on common datasets. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by expanding the baseline comparisons. However, the comment could be more helpful if it offered additional context or rationale for why these specific baselines are important or how they might enhance the study. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct this evaluation to strengthen their defense strategies. The suggestion is concrete and actionable, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of the proposed strategies, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need to evaluate the proposed defense against an adversarial attack that minimally alters the edge map while misleading model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the defense against a specific type of adversarial attack. However, it lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the evaluation of the proposed strategies. It highlights the need to evaluate the defense against an adversarial attack that minimally alters the edge map while misleading model predictions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their defense strategies by considering a more robust evaluation method. However, the comment could be more helpful if it offered suggestions on how to implement this evaluation or provided examples of similar approaches in the literature. Overall, the comment is mostly helpful as it effectively guides the authors toward a significant improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the legends in Tables 1, 2, and 3 longer and to clarify whether the numbers represent % errors or % correct. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers represent % errors or % correct. This provides clear guidance on how to improve the clarity of the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct. This is a request for clarification and does not contain a claim or opinion that requires verification. It is purely a suggestion for improvement, making it a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct. This is a clear and direct suggestion that can help the authors improve the clarity and comprehensibility of their results. By addressing this feedback, the authors can enhance the readability and interpretability of their work, making the comment mostly helpful. However, the comment could be more helpful if it included additional guidance on how to achieve these improvements, such as suggesting specific wording or formatting changes. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This comment provides a clear and explicit action for the authors to take: they should include standard deviations in their experimental results to allow for a more accurate evaluation of the results\\' significance. The feedback is direct and provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, namely the absence of standard deviations, which makes it difficult to judge the significance of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual statement that does not require verification or justification. It is a request for clarification or improvement, not an opinion or suggestion that needs to be substantiated. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the lack of standard deviations makes it challenging to assess the significance of the results. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations. By addressing this point, the authors can enhance the clarity and robustness of their experimental findings, which is crucial for the credibility of their work. However, the comment could be more helpful if it provided additional context or examples on how standard deviations can be incorporated or why they are important. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement that can enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a perceived weakness in the analysis, noting that the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space) are not provided. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to improve the analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide these guarantees or analyses, but without concrete instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"SDE (2a)-(2d),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis, namely the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the provided analysis is weak in light of theoretical work on sampling and particle-based optimization methods. It specifically mentions the lack of evidence for the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need further explanation or evidence, it does not provide specific references or detailed reasoning to support the claim. The authors would need to infer the gaps in the analysis and address them accordingly. Therefore, the comment is somewhat verifiable, as it highlights important aspects that need clarification but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the analysis seems weak, particularly in the context of theoretical work on sampling and particle-based optimization methods. It points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it highlights a critical gap in the analysis that the authors need to address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to address these gaps or offered examples of how similar analyses have been conducted in the literature. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific suggestions or guidance on how to improve the quality of the generated images or what aspects of the realism need to be enhanced. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the realism of the generated images, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the lack of realism in the results shown in the paper and supplemental material. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is somewhat helpful as it points out a potential weakness in the paper, prompting the authors to consider ways to improve the realism of their generated images. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending techniques or methods to enhance realism. Without actionable advice, the authors may find it challenging to know where to focus their efforts for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit instructions on what needs to be improved in the paper. It explicitly states that the authors should describe the size and elements of G, as well as the dimensions of G, X, and W to better understand what DGCN is doing. This feedback is clear and actionable, giving the authors specific tasks to address in their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the description of how G is built using the human skeleton, the size and elements of G, and the dimensions of G, X, and W to better understand what DGCN is doing. This provides clear guidance on what the authors need to include or clarify in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements requesting additional information, such as describing the size and elements of G and adding the dimensions of G, X, and W to better understand what DGCN is doing. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying a gap in the description of the model architecture in Section 3.3. It suggests that the authors should clarify how the model, G, is built using the human skeleton and should include the size and elements of G, as well as the dimensions of G, X, and W to better understand what DGCN is doing. This feedback is clear and directs the authors to enhance the clarity and comprehensiveness of their model description, which is crucial for readers to understand the methodology. However, the comment could be more helpful if it offered additional context or examples on how to present this information effectively. Overall, the feedback is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the statement in lines 559-560 is not entirely true and provides a correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is clear and provides a direct action for the authors to correct the misrepresentation in their draft. The comment is explicit and concrete, giving the authors precise guidance on how to improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 559-560, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it corrects a statement by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This provides clear guidance on what needs to be corrected in the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in lines 559-560 is not entirely true. It provides a specific correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This detailed explanation supports the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the correction. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific error in the paper, pointing out that the statement in lines 559-560 is not entirely true. It provides a clear and actionable correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is valuable as it corrects a misrepresentation in the draft, helping the authors to improve the accuracy and clarity of their work. However, the comment could be more helpful if it also suggested how this correction might impact the overall understanding of the methodology or results. Overall, the comment is mostly helpful, as it provides clear guidance for improvement but could be more comprehensive with additional context or suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the term \"hyper-spectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyper-spectral\" and instead use \"hyperspectral imaging,\" which is the correct terminology. The comment provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"hyper-spectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"hyper-spectral\" and provides a correct definition of \"hyperspectral imaging.\" This level of detail guides the authors on what needs to be corrected, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"hyper-spectral\" is confusing and provides a definition of hyperspectral imaging. This claim is fully verifiable as it is supported by a clear explanation of what hyperspectral imaging is and why the term \"hyper-spectral\" might be confusing. The comment provides a logical reasoning and a precise definition, making it easy for the authors to understand and address the issue. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific terminology issue, clarifying that the term \"hyper-spectral\" is confusing and provides a correct definition of \"hyperspectral imaging.\" This feedback is actionable and helpful as it guides the authors to use the correct terminology, which can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it also suggested alternative ways to describe the imaging technique or provided context on why the terminology is important. Overall, the comment is mostly helpful as it directs the authors to a clear improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the paper. It recommends refreshing the idea of energy in Section 5.2, where it is used several times, and provides a hint about how to interpret it. Additionally, it points out that the concept of peak in Figure 5 is not described. These suggestions are clear and concrete, giving the authors specific actions to take to enhance their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as refreshing the idea of energy and providing hints about its interpretation, as well as describing the concept of peak in Figure 5. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and recommends refreshing the idea of energy in Section 5.2, where it is used several times. It also points out that the concept of peak in Figure 5 is not described. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to provide hints about interpreting energy is vague, and the comment does not reference any external sources or literature to support the need for clarification. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two areas for improvement. First, it suggests refreshing the idea of energy in Section 5.2, where it is used several times, and offers a hint about how to interpret it. Second, it points out that the concept of peak in Figure 5 is not described, which could be important for understanding the results. These suggestions are clear and offer concrete steps for the authors to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it included specific examples or further elaboration on how to interpret energy or describe the peak concept. Overall, the feedback is mostly helpful as it directs the authors to specific areas that need attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. It specifically mentions the need to explain how the performance of combining the Linformer and the window attention in Big Bird using contrition affects the overall results. While the comment implies an action, it does not provide explicit instructions on how to conduct these ablation studies or what specific components should be analyzed. The authors can infer the need for additional analysis, but the lack of concrete guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions sections 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a detailed explanation of how each component contributes to the final performance improvements. The suggestion to provide an example of how the performance of combining the Linformer and the window attention in Big Bird using contrition affects the overall results adds further clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that while some ablation studies are provided in Sections 3 and 4, the authors should further explain how each component contributes to the final performance improvements. The comment provides a specific example of how the performance of combining the Linformer and the window attention in Big Bird using contrition affects the overall results. This level of detail and suggestion is well-supported and provides a clear direction for the authors to enhance their analysis. Therefore, the comment is considered fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide more detailed ablation studies to explain how each component contributes to the final performance improvements. It specifically mentions the need to demonstrate how the performance of combining the Linformer and the window attention in Big Bird using contrition affects the overall results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s analysis and clarity. However, the comment could be more helpful if it offered additional guidance on how to conduct these ablation studies or what specific components to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some details of the models are missing, specifically the grammar over kernels, which is not explained in detail. It also raises questions about the probabilities associated with the grammar and how inference is performed. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks specific guidance on what aspects to focus on or how to present the information. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not provide detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the grammar over kernels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, namely the explanation of how this approach is applied in practice and the probabilities associated with the grammar. The comment also raises questions about inference, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some details of the models are missing, specifically the grammar over kernels, which is not explained in detail. It questions how inference is performed and whether probabilities are associated with the grammar. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the missing details and how they impact the understanding of the models. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the explanation of the grammar over kernels and the associated probabilities. It highlights the importance of understanding how this approach is applied in practice, which is crucial for the reader to grasp the methodology. The comment also raises questions about inference and probabilities, prompting the authors to provide more detailed information. This feedback is clear and actionable, as it directs the authors to specific areas that need clarification, offering a constructive path for improving the draft. However, it could be more helpful if it provided suggestions on how to present this information or examples of similar approaches. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the role of visual information in the paper and questions the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it suggests that the improvements are not significant given the sample size of 1000 users. While the comment identifies areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The authors are left to infer that they need to clarify the role of visual information, conduct a more thorough ablation study, and perhaps provide additional analysis or discussion to support their claims. However, the lack of concrete suggestions or detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ablation study, questioning the effectiveness of the visual information and the similarity in performance between models with and without the perception module. The comment also raises concerns about the significance of the improvements given the sample size of 1000 users. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific examples from Table 10, where the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it suggests that the improvements are not significant given the sample size of 1000 users. While the comment provides some evidence and reasoning, it lacks specific references or detailed analysis to fully substantiate the claim. The authors would need to conduct further investigation to fully understand and address the concerns raised. Therefore, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it raises concerns about the significance of the improvements given the sample size of 1000 users. This feedback is clear and actionable, as it highlights specific areas that need clarification or further investigation. By addressing these points, the authors can enhance the robustness and clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or conduct additional analyses. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the end of Section 4.2 claims that Transfer Lasso shows the best accuracy in feature screening, but it does not cite or compare previous works on Lasso screening, such as the work by Ren et al. The comment explicitly instructs the authors to include these previous works in their comparison, providing a clear and concrete action to take. By specifying the exact works to be included, the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out that Transfer Lasso is claimed to have the best accuracy in feature screening but does not cite or compare previous works on Lasso screening, such as the work by Ren et al. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not cite or compare previous works on Lasso screening, specifically mentioning the work by Ren et al. This claim is verifiable as it provides a specific reference to an external work that should be included in the comparison. The mention of Ren et al. provides a clear basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims that Transfer Lasso shows the best accuracy in feature screening but does not cite or compare previous works on Lasso screening, such as the work by Ren et al. This feedback is clear and actionable, as it directs the authors to include relevant references and comparisons in their work. By addressing this omission, the authors can enhance the credibility and completeness of their analysis. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references into the discussion. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by ensuring a comprehensive literature review.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. While the comment implies that the authors should provide more detailed information about the hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where these components are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of missing hyperparameter information, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which components or hyperparameters are missing. Without detailed information or evidence, the claim is not verifiable, as it does not provide sufficient context or justification for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This feedback is somewhat helpful as it points out a potential weakness in the presentation of the model, which could impact reproducibility and understanding. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which hyperparameters should be included or how to present them more clearly. While it highlights an area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity in the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR-10. While the comment identifies an issue with the notation, it does not provide explicit guidance on how to address it or suggest alternative ways to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR-10. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation for results is unclear, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR-10. This is a factual observation about the clarity of the notation, which requires no verification or justification. The comment does not contain subjective opinions, suggestions, or judgments that would necessitate verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the notation used in the results section, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR-10. This feedback is clear and actionable, as it directs the authors to clarify the notation used in their results to ensure that readers understand the reported improvements. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the notation or offered examples of how to present the results more effectively. Despite this, the comment is mostly helpful as it highlights a critical area for improvement and guides the authors toward enhancing the clarity of their results presentation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for what the authors should do, it does not specify how to present these results or analyze the limitations. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also recommends showing failure cases and analyzing limitations. However, it does not specify which part of the paper these suggestions should be applied to, making it weakly grounded. The comment is specific in detailing what kind of results and analysis should be included, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also recommends showing failure cases and analyzing limitations. However, the comment lacks specific examples or references to support the claim that such results would be beneficial or necessary. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also suggests showing failure cases and analyzing limitations, which can help the authors better understand and communicate the strengths and weaknesses of their approach. However, the comment could be more helpful if it offered specific guidance on how to present these results or analyze the limitations. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests clarifying the title to specify that it pertains to machine comprehension of text rather than human reading comprehension. This is an explicit action, as it directly instructs the authors to make a specific change to their title. The comment provides clear guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and needs clarification regarding whether it refers to machine comprehension of text or human reading comprehension. The comment provides a clear direction for improvement by recommending a specific change to the title. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text rather than human reading comprehension. The comment provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" are often associated with human reading comprehension, which is different from the context of machine comprehension. This reasoning is clear and provides a basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the distinction between machine and human comprehension, which would align with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it pertains to machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improving the title to avoid confusion. By addressing this issue, the authors can enhance the clarity and accuracy of their work, making the comment mostly helpful. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between machine and human comprehension. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies an incorrect assertion made by the authors regarding the Central Limit Theorem (CLT) on line 238. It clarifies that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. However, the comment does not provide explicit guidance on how the authors should correct this assertion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to revise their statement, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the authors\\' claim about the Central Limit Theorem (CLT), pointing out that it makes multiple incorrect assertions. The comment provides a detailed explanation of why the claim is incorrect, which helps the authors understand what needs to be revised. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' statement regarding the Central Limit Theorem (CLT) is incorrect. It provides a detailed explanation of why the claim is invalid, specifically noting that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is clear and logical, providing a robust basis for the claim. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' claim regarding the Central Limit Theorem (CLT) on line 238. It points out that the statement is incorrect, as the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a precise correction to their claim, which is crucial for the accuracy and validity of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context or references to support the correction. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical error in their draft and guides them toward a necessary correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that needs to be addressed, making it highly actionable. The authors know exactly what needs to be done to enhance their paper, and the feedback is concrete in its guidance. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the time complexity analysis are required or how it should be conducted. The authors are given a general direction but not specific guidance on what needs to be addressed. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point is a request for additional analysis, specifically asking for the time complexity of the proposed policies to be analyzed. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is clear and actionable, as it provides a direct direction for the authors to enhance their draft by conducting a time complexity analysis. However, the comment could be more helpful if it offered guidance on how to conduct this analysis or what aspects to focus on. Despite this, the suggestion is valuable and provides the authors with a clear path to improve their work. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should reconsider their choice of metric for human evaluation. Additionally, the comment lacks concrete details on how to implement this change or what specific human metric should be used. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. However, it does not specify which part of the paper discusses the human evaluation or where the use of TSS is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the choice of metric but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. The reviewer claims that this choice weakens the convincingness of the human evaluation. However, the comment lacks specific reasoning or examples to support why a human metric would be more appropriate or how the use of TSS affects the evaluation. Without detailed justification or references, the claim remains somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the choice of using an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It highlights a potential weakness in the methodology, suggesting that the use of an automatic metric may weaken the convincingness of the human evaluation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what alternative human metrics could be considered. While it identifies a potential problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including experiments across more diverse domains would strengthen the paper. While it implies that the authors should expand their experiments, it does not provide specific guidance on which domains to consider or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that including experiments across more diverse domains would strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or a specific table or figure. Additionally, it does not provide details on which domains should be considered or why they would strengthen the paper. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas needing improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments \"succinctly prove the point that the authors try to make\" and suggests that including experiments across more diverse domains would strengthen the paper. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that additional domains would provide valuable insights. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the experiments successfully prove the point the authors aim to make. However, it suggests that including experiments across more diverse domains, such as those in TD-MPC 2, would strengthen the paper. This feedback is somewhat helpful as it provides a direction for potential improvement by suggesting a specific area for expansion. However, it lacks detailed guidance on how to implement this suggestion or which specific domains to consider, which could be beneficial for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of confidence intervals for the results, which makes it unclear whether the performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The reviewer provides specific references to external works that could be relevant to the authors, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, [2] Controlling Selection Bias in Causal Inference, [3] An empirical study on robustness to spurious correlations using pre-trained language models, and [4] On Feature Learning in the Presence of Spurious Correlations. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of confidence intervals for results, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of statistical significance in performance gains and the limited evaluation on only two datasets. Additionally, the comment provides specific references to external works that could be relevant to the authors, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, [2] Controlling Selection Bias in Causal Inference, [3] An empirical study on robustness to spurious correlations using pre-trained language models, and [4] On Feature Learning in the Presence of Spurious Correlations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of confidence intervals makes it unclear whether performance gains are statistically significant. It also notes the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be relevant to the authors, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, [2] Controlling Selection Bias in Causal Inference, [3] An empirical study on robustness to spurious correlations using pre-trained language models, and [4] On Feature Learning in the Presence of Spurious Correlations. These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the absence of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be relevant to the authors, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, [2] Controlling Selection Bias in Causal Inference, [3] An empirical study on robustness to spurious correlations using pre-trained language models, and [4] On Feature Learning in the Presence of Spurious Correlations. This feedback is clear and actionable, as it highlights specific areas for improvement and provides references that could guide the authors in addressing these issues. However, the comment could be more helpful if it included suggestions on how to incorporate confidence intervals or additional datasets into the evaluation. Overall, the comment is mostly helpful, as it provides valuable insights and resources for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing evaluation of the magnitude of interpretability tax associated with the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what aspects of the interpretability tax should be evaluated or how to conduct this evaluation. Without specific instructions or examples, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the evaluation of the magnitude of interpretability tax associated with the method. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in identifying the missing evaluation of the interpretability tax, but without clear grounding, the authors may struggle to determine where this feedback applies. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the magnitude of interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would impact the paper. Without additional context or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the importance or relevance of this evaluation. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks evaluation, namely the magnitude of interpretability tax associated with the method. This is a valuable observation that could help the authors enhance their work by providing a more comprehensive analysis. However, the comment does not offer any suggestions or guidance on how to evaluate this aspect or what specific metrics or approaches could be used. While it highlights a potential improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a gap but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the paper or what specific aspects need attention. Without actionable suggestions or feedback, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the design of the LUQ and the approaches in Section 5, suggesting that they are straightforward and standard. However, it does not specify which part of the paper discusses the LUQ or the approaches in Section 5, making it weakly grounded. The comment is specific in its critique of the paper\\'s contribution, suggesting that the main contribution is showing the effectiveness of existing techniques rather than proposing novel ones. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. However, the comment lacks specific references or examples to support the claim that the approaches are standard or explored in previous literature. This makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks detailed evidence or references.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. While the comment provides some insight into the paper\\'s contribution, it lacks specific suggestions or guidance on how the authors might enhance their work or address the reviewer\\'s concerns. The feedback is somewhat helpful as it highlights the paper\\'s focus on existing techniques, but it does not offer actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment implies that the authors should include training losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present the training losses or what metrics to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method and suggests including training losses. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this method is discussed. Without explicit references, the authors may find it challenging to determine the exact part of the paper being addressed. The comment is specific in its request for training losses but lacks grounding, as it does not clearly identify the part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. However, the comment does not provide any supporting evidence, reasoning, or references to justify why training losses are necessary or how they would demonstrate stability. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific metric that could be included to enhance the paper\\'s transparency and robustness. However, the comment lacks depth and does not provide detailed guidance on how to present or interpret the training losses, which could be beneficial for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability, that are claimed to be the same thing. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to clarify or revise their claims. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their claims but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It specifically mentions the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability, suggesting that these are all the same thing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which part of the paper these aspects are discussed in, making it weakly grounded. The authors can infer that it relates to the theoretical analysis section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are all the same thing. The reviewer provides a logical explanation by stating that these aspects are different viewpoints of applying stronger constraints for samples with higher popularity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It points out that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are all the same thing, which is a critical observation that could help the authors clarify their claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their claims. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena may not be suitable for evaluating a single dialogue system, such as providing fluency scores. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they should reconsider the relevance of their method and possibly explore alternative evaluation approaches. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also discusses the limitations of the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena in evaluating a single dialogue system. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the abstract or methodology sections, but this inference is not direct. The comment is specific in detailing the concerns about the relevance and limitations of the proposed method, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena may not be suitable for evaluating a single dialogue system. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena may not be suitable for evaluating a single dialogue system, such as providing fluency scores. While the comment identifies a potential limitation in the proposed method, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the training process. The action is implicit and somewhat vague, as the authors are left to infer that they need to ensure a fair comparison by adjusting the training process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of RegMixup seeing 2x samples per iteration, which could lead to unfair comparisons with other methods. The comment provides a clear explanation of the problem and suggests a potential solution, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as specific examples or references, to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This is a relevant observation that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure a fair comparison. While it highlights a potential problem, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a potential error in the equation at lines 81-82, suggesting that the authors may have written \"t_R^m\" instead of \"t_R^{m-1}.\" It also requests clarification on the meaning of \"t_R^m,\" as it is used subsequently in the paper. This feedback provides clear and direct actions for the authors to take, such as checking the equation for accuracy and defining \"t_R^m\" if it is indeed correct. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 81-82, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential error in the equation and requests clarification on the meaning of \"t_R^m,\" which is used subsequently. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the correctness of an equation and requests clarification on the meaning of a term used in the equation. It does not contain subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, making it a normal statement and fitting the label \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential error in the equation at lines 81-82, suggesting that the authors may have written \"t_R^m\" instead of \"t_R^{m-1}.\" It also requests clarification on the meaning of \"t_R^m,\" as it is used subsequently in the paper. This feedback is clear and actionable, as it directs the authors to check the equation for accuracy and define \"t_R^m\" if it is indeed correct. By addressing these points, the authors can ensure the clarity and correctness of their work. However, the comment could be more helpful if it provided additional context or examples of how the term is used in the paper. Overall, the comment is mostly helpful, as it provides specific guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer implies that the authors may have chosen focal loss for a unified form without considering the differences between classification and regression tasks. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their choice of loss function and its implications for regression tasks. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning for why focal loss might not be suitable for regression tasks, particularly in the context of regressing the IoU. However, the comment does not specify which part of the paper discusses the use of focal loss, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but the exact location is not explicitly mentioned. The comment is specific in detailing the potential issue with focal loss in regression tasks, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning by explaining that focal loss has lower gradients on easy samples, which could be problematic for regressing the IoU. However, the comment lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks. This makes the claim somewhat verifiable, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning by explaining that focal loss has lower gradients on easy samples, which could be problematic for regressing the IoU. The comment also implies that the authors may have chosen focal loss for a unified form without considering the differences between classification and regression tasks. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. The feedback is somewhat helpful as it prompts the authors to reconsider their choice of loss function and its implications for regression tasks, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this question or what specific aspects of scalability need to be considered. Without any actionable steps or suggestions, the comment lacks direction for the authors, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific guidance on what aspects of scalability need to be addressed or improved. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights into how the authors might improve the scalability of their method. As a result, the comment is barely helpful, as it points out a potential weakness but does not assist the authors in making meaningful improvements to their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should verify whether the improvements of the proposed model over the RL without feedback model are statistically significant, given that the improvements are not as high as expected (as shown in row 3 versus row 4 in Table 6). While the comment implies that the authors should conduct a statistical analysis, it does not provide specific guidance on how to perform this analysis or what metrics to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a statistical analysis and determine how to conduct it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the proposed model\\'s improvements over the RL without feedback model not being statistically significant, as evidenced by the BLEU-1 score. The comment provides a clear direction for the authors to verify the statistical significance of the improvements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvements of the proposed model over the RL without feedback model are not significant, as evidenced by the comparison in Table 6 (row 3 vs. row 4). The reviewer suggests that the authors should verify whether these improvements are statistically significant. However, the comment lacks specific reasoning or examples to support the claim that the improvements are not significant. Without detailed analysis or references, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the improvements of the proposed model over the RL without feedback model, as indicated by the comparison in Table 6. It points out that the improvements are not as significant as expected, particularly for BLEU-1, and suggests that the authors should verify whether these improvements are statistically significant. This feedback is clear and actionable, as it directs the authors to conduct a statistical analysis to substantiate their claims. However, the comment could be more helpful if it provided guidance on how to conduct this analysis or what specific metrics to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about relaxing the need to visit all ball-action pairs with each iteration. It suggests considering minimal assumptions or exploring what would happen if only some ball-action pairs are covered. While the comment implies that the authors should consider these possibilities, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it directly addresses the previous remark about relaxing the need to visit all ball-action pairs with each iteration. This allows the authors to accurately identify the part of the paper being discussed. However, the comment is under-specific because it does not provide detailed guidance on what assumptions or partial coverage could be considered or how to explore these options. It raises questions but does not specify the exact steps or changes needed to address the issue. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point is a question seeking clarification on how to relax the need to visit all ball-action pairs with each iteration. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment builds upon a previous remark by asking for clarification on how to relax the need to visit all ball-action pairs with each iteration. It suggests exploring minimal assumptions or partial coverage of ball-action pairs. While the comment raises an interesting question, it lacks specific guidance or actionable suggestions on how the authors might approach this issue. The feedback is somewhat helpful as it prompts the authors to consider alternative methods, but it does not provide detailed instructions or examples to help them implement these ideas. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTa-base, instead of BERT. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should test with RoBERTa-base, why this might be beneficial, or how to incorporate this suggestion into their work. Without any actionable steps or concrete details, the authors are left without a clear understanding of what to do with this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTa-base, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what improvements are expected or how to implement the suggestion. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTa-base, instead of BERT. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change might be beneficial or necessary. The comment lacks specific details or references that would help the authors understand the basis of the suggestion, making it difficult for them to address the claim effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTa-base, instead of BERT. While it identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or conduct further experiments. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is barely helpful, as it provides only a vague suggestion without concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. While the comment implies that the authors should expand their dataset selection, it does not provide specific guidance on which datasets to include or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or evaluation, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets, but without clear grounding, it aligns with a weakly grounded and specific label.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any reasoning, examples, or references to support why these specific datasets are necessary or how they would contribute to the study. Without additional context or justification, the claim remains vague and unverifiable, as the authors may not fully understand the rationale behind the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting additional datasets that could strengthen the evaluation of the technique. However, the comment lacks specific guidance on which datasets to include or how to integrate them into the study, which would make it more actionable. The authors are given a direction to expand their dataset selection, but the feedback could be more detailed to fully support their efforts in enhancing the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It provides specific examples of baseline methods that could be used, such as Ref-NeRF and MipNerf, for different scenarios. This feedback is clear and provides concrete guidance on how to enhance the evaluation by including additional baselines. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"choice of baseline methods\" and provides specific suggestions for improvement, such as comparing to Ref-NeRF and MipNerf for different scenarios. This allows the authors to accurately identify the part of the paper being addressed and what needs to be addressed. The comment is also specific because it provides clear examples of baseline methods that could be used for evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It provides specific examples of baseline methods that could be used, such as Ref-NeRF and MipNerf, for different scenarios. This level of detail and the inclusion of references to existing methods provide a clear and logical basis for the claim, making it fully verifiable. The authors can easily understand the reasoning behind the suggestion and how it would enhance their evaluation. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting improvements to the choice of baseline methods for evaluating the appearance decomposition part of the paper. It offers concrete examples of baseline methods, such as Ref-NeRF and MipNerf, that could be used for different scenarios, which is a clear and helpful suggestion for the authors to consider. By including these additional baselines, the authors can better evaluate and compare their results, leading to a more comprehensive analysis. The comment is mostly helpful as it provides clear guidance on how to enhance the evaluation, but it could be more helpful if it also explained why these specific baselines are relevant or how they would contribute to the study. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. This is an explicit request for the authors to provide additional evidence or examples to support their claims. However, the comment does not specify how the authors should present this information or what specific aspects of the method should be highlighted. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify what aspects of the method should be highlighted or how to present the evidence. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. This is a clear and actionable suggestion that could help the authors improve their draft by providing additional evidence or examples to support their claims. However, the comment could be more helpful if it offered specific guidance on how to present this information or what aspects of the method should be highlighted. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, providing a clear path for enhancing their work. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the biggest concern during reading is the lack of implementation details of the proposed methods, which should have been described in Section 4.1. This provides a clear and direct action for the authors to take, which is to include the implementation details in the specified section. The comment is explicit and concrete, as it specifies exactly what needs to be done to address the concern. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the biggest concern during reading is the lack of implementation details of the proposed methods. It suggests that these details should have been described in Section 4.1. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details or how they could be addressed. Without detailed justification or examples, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, which is dedicated to implementation details. This feedback is clear and actionable, as it directs the authors to a specific section where they can address the issue. By providing this guidance, the comment is mostly helpful, as it empowers the authors to make a targeted improvement to their draft. However, it could be more helpful if it offered suggestions on what specific implementation details should be included or how to present them effectively. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of empirical evaluation and comparison with other methods, which is a significant concern for a paper submitted to NeurIPS. It also notes the lack of practical value and theoretical argumentation, suggesting that the paper is not suitable for publication in its current form. While the comment identifies the need for empirical evaluation and comparison, it does not provide specific guidance on how to address these issues or what kind of evaluation or comparison would be appropriate. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of empirical evaluation, comparison with other methods, and the absence of a theoretical argument for the practical value of the contribution. However, it does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is missing, such as empirical evaluation and comparison with other methods, as well as the need for a theoretical argument for practical value. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation, comparison with other methods, and a theoretical argument for practical value. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment suggests that the theoretical contributions may be significant but does not elaborate on how this could be demonstrated. Without detailed justification or evidence, the claim remains somewhat verifiable, as the authors would need to invest significant effort to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, including the lack of empirical evaluation, comparison with other methods, and a theoretical argument for practical value. It highlights the importance of these elements, especially in the context of a submission to NeurIPS, where rigorous evaluation and comparison are expected. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending particular methods for comparison or suggesting ways to enhance the theoretical argument. While it points out significant weaknesses, the feedback lacks actionable details, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (3) and (4) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed to avoid confusion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the symbol \"P\" is used inconsistently in the manuscript, representing both a probability and a cumulative distribution function. The reviewer provides specific examples, such as equations (3) and (4) and line 44 in the appendix, which helps verify the claim. However, the comment could be strengthened by explaining why this inconsistency leads to confusion or suggesting how it might be resolved. Overall, the claim is mostly verifiable, as it provides specific examples but lacks detailed reasoning or suggestions for improvement. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the symbol \"P\" is used inconsistently to represent both a probability and a cumulative distribution function. This inconsistency leads to confusion, as evidenced by the examples provided (e.g., Eqs. (3) and (4) and L44 in the appendix). The comment highlights a clear area for improvement by pointing out the need for clarity in the use of symbols. However, it does not provide detailed guidance on how to resolve this issue or suggest alternative approaches. While it offers a valuable insight into a potential source of confusion, the feedback could be more helpful if it included specific recommendations or examples of how to address the inconsistency. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method discussed in the paper can be applied to general MDPs but is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRM-RL~[1] and suggests exploring the application of such algorithms in more general tasks. While the comment implies that the authors should consider expanding the applicability of their method, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications and may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it is limited to navigation problems. It also references PRM-RL~[1], suggesting that combining RL and planning has already been discussed in this context. However, the comment does not specify which part of the paper discusses the method or where the limitation to navigation problems is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the exploration of broader applications, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method discussed in the paper is limited to navigation problems and suggests exploring its application in more general tasks. The comment references PRM-RL~[1], which provides some context for the claim. However, the comment lacks specific examples or detailed reasoning about why the method is limited to navigation problems or how it could be applied to more general tasks. This makes the claim somewhat verifiable, as it provides a starting point for exploration but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that the method discussed is primarily applicable to navigation problems. It suggests that combining RL and planning, as discussed in PRM-RL~[1], could be explored in more general tasks. This feedback is somewhat helpful as it points out a potential area for expansion and improvement in the paper. However, it lacks specific guidance or suggestions on how the authors might explore these broader applications or integrate the existing literature. While it provides a direction for further research, it does not offer detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the suitability of feature spaces for 1-NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. While the comment identifies a potential problem and provides a solution, it does not explicitly instruct the authors to make the suggested change. The action is implicit and somewhat vague, as the authors need to infer that they should standardize the feature dimensions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces and suggests a potential solution by recommending individual standardization of feature dimensions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the suitability of feature spaces for 1-NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. The comment provides a logical reasoning by explaining that feature spaces that are not close to a spherical Gaussian may perform poorly. This reasoning is based on a common understanding of the properties of 1-NN classification and the potential impact of feature space characteristics. However, the comment does not provide specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the suitability of feature spaces for 1-NN classification, specifically mentioning that feature spaces that are not close to a spherical Gaussian may perform poorly. It provides a suggestion to address this issue by recommending individual standardization of feature dimensions. This feedback is clear and actionable, offering the authors a specific way to improve their draft by enhancing the robustness of their feature spaces. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is mostly helpful as it provides valuable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the paper. It notes that while an intuitive example was provided, the setting of this example is less convincing, and a formal definition is still needed. The comment provides a clear and explicit action for the authors to define the contrastive gap formally, which is a concrete step to improve the clarity of the paper. However, it does not specify how to formalize the definition, leaving some room for ambiguity. Overall, the comment is mostly actionable as it identifies a specific issue and provides a clear direction for improvement, but it could be more detailed in guiding the authors on how to formalize the definition.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a central concept in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a clear definition for the contrastive gap, even though an intuitive example was provided. The comment further details the problem by noting that the setting of the example is less convincing and that a formal definition is still lacking. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"contrastive gap\" is a central concept in the paper but has not been defined clearly. It provides a logical reasoning by noting that while an intuitive example was given, the setting of this example is less convincing, and a formal definition is still lacking. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections where the definition is needed or by providing examples of how the concept could be better defined. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, namely the lack of a clear definition for the \"contrastive gap,\" which is a central concept. It acknowledges that an intuitive example was provided but points out that the setting of this example is less convincing and that a formal definition is still needed. This feedback is clear and actionable, as it directs the authors to clarify and formalize the definition of the contrastive gap, which is essential for the understanding and reproducibility of the work. However, the comment could be more helpful if it provided specific suggestions on how to formalize the definition or examples of what a clear definition might entail. Overall, the comment is mostly helpful as it highlights a significant gap in the paper and guides the authors toward improving its clarity and comprehensibility.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on specific lines in section 3.1, pointing out that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations. It also notes that it is unclear whether each action is a single feature or the power set. The comment suggests making the description more clear, which is a direct and concrete action for the authors to take. The feedback is clear and actionable, as it specifies exactly what needs to be addressed and how to improve the clarity of the description. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in section 3.1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is incorrect in the statement about rewards and clarifies the confusion regarding whether each action is a single feature or the power set. This provides clear guidance on what needs to be addressed to improve the clarity of the description. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations and suggests that it may not be clear whether each action is a single feature or the power set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out inaccuracies in the description of the MDP formulation in section 3.1. It highlights that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations, suggesting that this may lead to confusion. Additionally, it clarifies the ambiguity regarding whether each action is a single feature or the power set. The comment offers clear guidance on how to improve the clarity of the description, making it highly helpful for the authors to enhance the accuracy and comprehensibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including other baselines, such as those discussed in related work [29, 5, 6], and recommends adding an explanation for the chosen baseline in the final version of the paper. While the comment implies that the authors should include additional baselines, it does not explicitly instruct them to do so. The suggestion to add an explanation for the chosen baseline is more concrete, but it still lacks specific guidance on how to provide this explanation. Overall, the comment is somewhat actionable as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including other baselines, such as those discussed in related work, and recommends adding an explanation for the chosen baseline in the final version of the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional baselines and an explanation for the chosen baseline, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including other baselines, such as those discussed in related work, and recommends adding an explanation for the chosen baseline. The comment provides a logical reasoning for including additional baselines, as it would enhance the comprehensiveness of the evaluation. However, it lacks specific references or examples of the other works mentioned, which would strengthen the justification. This makes the claim somewhat verifiable, as the authors would need to infer the specific works being suggested and their relevance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including other baselines, such as those discussed in related work, to enhance the comprehensiveness of the evaluation. It also recommends adding an explanation for the chosen baseline in the final version of the paper. This feedback is clear and actionable, providing the authors with specific suggestions to improve the rigor and clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to select and incorporate these additional baselines or provided specific examples of what an explanation for the chosen baseline might entail. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the meaning of \\\\delta in the statement of Lemma 5. This is a direct and concrete action for the authors to take, as it clearly identifies what needs to be clarified. The authors know exactly what to address in their draft to improve its clarity. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly asks about the meaning of \\\\delta in the statement of Lemma 5, providing full grounding as it clearly identifies the specific part of the paper being addressed. It is also specific because it directly questions the meaning of a particular term, which is a clear indication of what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual question seeking clarification about the meaning of \\\\delta in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly specific and actionable, as it directly questions the meaning of \\\\delta in the statement of Lemma 5. This type of feedback is valuable because it prompts the authors to clarify an important aspect of their work, which can lead to improved understanding and clarity in the paper. By addressing this question, the authors can ensure that their readers fully comprehend the content of Lemma 5. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the setting of \\\\alpha_m uniformly to 1/M, implying that all modalities contribute equally. It suggests that dynamically weighting the modalities might be more appropriate based on works in multimodal fusion. However, the comment does not provide specific guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider dynamic weighting but without concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the setting of \\\\alpha_m uniformly to 1/M, suggesting that dynamically weighting the modalities might be more appropriate based on works in multimodal fusion. The comment provides a clear direction for improvement by referencing relevant literature, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that setting \\\\alpha_m uniformly to 1/M implies equal contributions from all modalities, which is not supported by works in multimodal fusion. The reviewer provides a logical reasoning by suggesting that dynamically weighting the modalities is important, referencing works in multimodal fusion. However, the comment lacks specific references or detailed examples from these works, which would strengthen the justification. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the uniform setting of \\\\alpha_m to 1/M, suggesting that this implies equal contributions from all modalities. It points out that works in multimodal fusion have shown that dynamically weighting the modalities is important. This feedback is somewhat helpful as it highlights a specific area for improvement in the paper, suggesting that the authors consider dynamic weighting to better capture the contributions of different modalities. However, the comment could be more helpful if it provided specific examples or references to support the claim about the importance of dynamic weighting, or if it offered guidance on how to implement this change in the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the use of the phrase \"to meet\" in the paper, stating that it is difficult to understand. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or suggest alternative phrasing. The comment lacks actionable details, such as recommending a different way to express the concept or explaining why the current phrasing is problematic. As a result, the authors are left without a clear understanding of what needs to be changed or improved. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (\"line 280\") where the issue with the phrase \"to meet\" is observed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the phrase \"to meet,\" indicating that it is difficult to understand. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the phrase \"to meet\" is difficult to understand, specifically mentioning its use on line 280. However, the comment does not provide any further explanation or context to support why this phrase is problematic or how it could be improved. Without additional details or examples, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. However, it does not provide any suggestions or guidance on how to improve the clarity or rephrase the sentence to make it more understandable. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a potential issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a discrepancy between the task loss being referred to as \"L_task\" in the text and \"L_class\" in Figure 1. This is a clear and explicit observation that the authors need to address by ensuring consistency in the naming of the task loss across the paper. The comment provides a specific action for the authors to take, which is to correct the inconsistency in the naming. This makes the comment highly actionable, as it clearly instructs the authors on what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the naming of the task loss, which is clearly identified as \"L_task\" in the text but \"L_class\" in Figure 1. This provides clear guidance on what needs to be corrected to ensure consistency in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about a discrepancy in the naming of the task loss in the text and in Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the naming of the task loss, noting that it is referred to as \"L_task\" in the text but \"L_class\" in Figure 1. This is a clear and actionable observation that the authors can address by ensuring consistency in the naming across the paper. By pointing out this discrepancy, the comment provides a straightforward way for the authors to improve the clarity and consistency of their work. However, the comment could be more helpful if it explained why this inconsistency matters or how it might impact the reader\\'s understanding of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. This implies that the authors should consider discussing additional limitations, but it does not provide explicit guidance on how to address this or what specific limitations to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should discuss additional limitations and determine which ones are relevant. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional information on limitations, but without clear grounding, the authors may struggle to determine where to address this point. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification on other limitations of the method, specifically asking if the network is shallow in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. While it identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or explore other limitations. The comment is somewhat helpful as it prompts the authors to consider additional limitations, but it does not offer actionable advice or detailed feedback on how to enhance their work. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. While the comment implies that the authors should consider adding machine translation evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"answer generation and summarization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. This provides clear guidance on what the authors need to address to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. The reviewer provides a logical reasoning by contrasting the tasks used in the paper (answer generation and summarization) with machine translation, suggesting that the latter would provide a more rigorous evaluation. However, the comment lacks specific references or examples to support the claim about the differences in uncertainties between the tasks. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are closer to \"open domain\" generation rather than \"close domain\" tasks like machine translation. The reviewer suggests that the work would be more convincing if it included evaluations in machine translation, which exhibits lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation of the proposed method. By addressing this point, the authors can enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered additional guidance on how to conduct the machine translation evaluation or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address these questions by including the requested details in their response. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the dropout process. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the dropout\" and \"the reading of the response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the dropping rate and the number of masks generated. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the dropout process, specifically asking for the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the dropout process, seeking clarification on the dropping rate and the number of masks generated. While it identifies a gap in the explanation of the dropout method, it does not provide suggestions or guidance on how the authors might address these questions or improve their explanation. The comment is somewhat helpful as it points out an area that needs clarification, but it lacks actionable advice or depth to fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that showing the performance drop on fusion models is not sufficient and that comparisons with other single-stage attacks are needed to demonstrate effectiveness. The comment also highlights the importance of proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms to justify the technical contributions. This feedback provides clear and concrete actions for the authors to take, such as conducting additional comparisons and benchmarks, which makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the proposed two-stage optimization approach, specifically mentioning the need for further justification and comparisons with other single-stage attacks. However, it does not specify which part of the paper discusses the two-stage optimization approach, making it weakly grounded. The comment is specific in detailing what is missing, such as comparisons with other SOTA algorithms and benchmarks, which would help justify the effectiveness of the technical contributions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification. It argues that showing the performance drop on fusion models is not sufficient and suggests that comparisons with other single-stage attacks are needed. The comment also highlights the importance of proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms to justify the technical contributions. While the comment provides a logical reasoning for the need for additional comparisons, it lacks specific examples or references to other SOTA algorithms or benchmarks, which would strengthen the argument. Therefore, the claim is somewhat verifiable, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the effectiveness of the proposed two-stage optimization approach. It points out that merely showing the performance drop on fusion models is insufficient and suggests that comparisons with other single-stage attacks are necessary to demonstrate the approach\\'s effectiveness. Additionally, the comment highlights the importance of proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific directions to enhance their draft by conducting additional comparisons and justifications. However, it could be more helpful if it offered suggestions on which specific benchmarks or comparisons to consider. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and justification of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks information about the type of GPUs used and the inference time during testing. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of information about the type of GPUs used and the inference time during testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: the type of GPUs and inference time during testing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks information about the type of GPUs used and the inference time during testing. This is a factual statement that does not require verification or justification. It is a request for additional information to be included in the paper, which is a normal statement and not a claim. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a clear and actionable piece of feedback that can help the authors improve their draft by providing crucial details that could impact the reproducibility and understanding of their results. However, the comment could be more helpful if it suggested where this information should be included or how it might affect the interpretation of the results. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of several observations and corrections. It notes that the overall performance of RS-D4PG in Table 1 appears to increase monotonically with \u03bb values, and expresses curiosity about what happens when \u03bb is even smaller. Additionally, it points out missing elements in the equations on page 3, specifically the missing terms \"J o b j \u03c0 ( \u03b8 ) -> \u03c4 and \u03b7\" in the bracket on line 2, and the missing \"s'\" in the equation on line 4. While these observations and corrections are explicit, they do not provide specific guidance on how the authors should address these issues or improve their draft. The feedback is somewhat actionable as it identifies specific errors and areas for improvement, but it lacks detailed instructions on how to correct them. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"table 1\" and \"page 3, line 2,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues, such as the monotonic increase in performance with \u03bb values and the missing terms in equations, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple observations and corrections, each of which is factual and does not contain subjective claims or opinions. It describes the performance trend in Table 1, notes the missing terms in equations on page 3, and points out a missing character in the equation on line 4. These are all factual statements that do not require verification or justification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several specific observations and corrections regarding the paper. It notes that the overall performance of RS-D4PG in Table 1 appears to increase monotonically with \u03bb values, and expresses curiosity about what happens when \u03bb is even smaller. This feedback is actionable as it prompts the authors to consider exploring a smaller range of \u03bb values to better understand the performance trend. Additionally, the comment points out missing elements in the equations on page 3, specifically the terms \"J o b j \u03c0 ( \u03b8 ) -> \u03c4 and \u03b7\" in the bracket on line 2, and the missing \"s'\" in the equation on line 4. These corrections are clear and actionable, helping the authors improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how these observations might impact the overall analysis or interpretation of the results. Overall, the feedback is mostly helpful as it identifies specific areas for improvement and provides actionable guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is explicit and provides a clear action for the authors to take, which is to correct the connection in the figure. The comment is also concrete, as it specifies exactly what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the connection between the Second Inpainted Images and the Inpainted Image in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Perceptual Metric in Figure 2, pointing out that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for correcting an error in their figure. By addressing this issue, the authors can improve the clarity and accuracy of their presentation, which is crucial for the understanding of their results. However, the comment could be more helpful if it included an explanation of why this connection is important or how it affects the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a specific improvement that can enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific sentence that is confusing and suggests that the authors re-read it to understand its meaning. While the comment identifies a potential issue, it does not provide explicit guidance on how to clarify the sentence or improve its clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to revise the sentence for better clarity. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific sentence range (93-95) that is confusing, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the sentence and suggesting that it is not immediately clear what is meant. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a specific sentence is confusing and suggests that the reviewer had to re-read it to understand it. However, the comment does not provide any specific reasoning or examples to support why the sentence is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific sentence (93-95) as confusing and suggests that the authors re-read it to understand its meaning. While it points out a potential issue, it lacks depth and does not provide specific suggestions or guidance on how to clarify the sentence or improve its clarity. The feedback is somewhat helpful as it alerts the authors to a potential problem, but it does not offer actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of specific issues that need to be addressed, including the need for citations in various parts of the paper. Each issue is clearly stated, providing the authors with explicit actions to take. The comments are also concrete, as they specify the exact lines where citations are needed. This level of detail ensures that the authors know exactly what needs to be done to improve their draft. Therefore, the comments are highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (78-79, 129-130, 156-158, and 217-218) where citations are needed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014citations for claims or evidence. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of requests for citations to support claims made in the paper. Each request is clear and specific, indicating that the authors need to provide evidence or references to substantiate their claims. However, the comment does not provide any additional context or reasoning beyond the need for citations, which limits its verifiability. Therefore, the comment is mostly verifiable, as it highlights the necessity of citations but lacks detailed justification or examples. This aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying several instances where citations are needed to support claims or evidence presented in the paper. This is particularly helpful as it directs the authors to specific lines where citations are required, ensuring that the paper is more robust and credible. However, the comment could be more helpful if it included suggestions on which specific references to consider or how the citations might enhance the paper\\'s argument. Overall, the feedback is mostly helpful as it guides the authors toward improving the credibility and rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an inconsistency between Figures 1 and 2, specifically noting that Figure 2 shows one encoder-decoder per auxiliary task, while Figure 1 shows a single shared encoder-decoder for multiple tasks. This feedback is explicit and provides a clear action for the authors to take, which is to ensure consistency between the figures. The comment is also concrete, as it specifies the exact inconsistency and guides the authors on how to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency between the figures, noting that Figure 2 shows one encoder-decoder per auxiliary task, while Figure 1 shows a single shared encoder-decoder for multiple tasks. This provides clear guidance on what needs to be addressed to ensure consistency. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 is inconsistent with Figure 2, specifically noting that Figure 2 shows one encoder-decoder per auxiliary task, while Figure 1 shows a single shared encoder-decoder for multiple tasks. This claim is based on a direct observation of the figures, which is a factual statement. However, the comment does not provide any additional reasoning or context to support why this inconsistency is significant or how it affects the paper\\'s conclusions. Therefore, the claim is somewhat verifiable, as it requires further explanation or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency between Figures 1 and 2, noting that Figure 2 shows one encoder-decoder per auxiliary task, while Figure 1 shows a single shared encoder-decoder for multiple tasks. This feedback is clear and actionable, as it points out a critical inconsistency that the authors need to address to ensure the figures are consistent and accurate. By highlighting this issue, the comment provides the authors with a clear direction for improvement, making it mostly helpful. However, it could be more helpful if it included suggestions on how to resolve the inconsistency or why it is important for the paper\\'s clarity. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether each node can attend to its own lower-level representation, suggesting that it may only attend to neighboring nodes based on the description of N_l^(s) in equation 2. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or clarify the issue, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether each node can attend to its own lower-level representation, based on the description of N_l^(s) in equation 2. However, it does not specify which part of the paper this question pertains to, such as a specific section or equation. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the attention mechanism, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether each node can attend to its own lower-level representation, based on the description of N_l^(s) in equation 2. This is a claim that requires verification, as it suggests a limitation or misunderstanding in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lower-level representation. It references equation 2 and the description of N_l^(s) to suggest that the attention might only be limited to neighboring nodes. While the comment identifies a potential limitation or misunderstanding in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the attention mechanism. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable advice, making it difficult for the authors to fully benefit from the comment. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on how the inequality after line 433 follows from Lemma 7. It suggests that the authors should facilitate the reading by stating how Lemma 7 is used in this context. This feedback provides a clear and direct action for the authors to take, which is to include an explanation of the connection between Lemma 7 and the subsequent inequality. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the connection between the inequality after line 433 and Lemma 7. The comment suggests that the authors should clarify how Lemma 7 is used to derive the inequality, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the logical connection between an inequality after line 433 and Lemma 7, suggesting that the authors should clarify how Lemma 7 is used to derive the inequality. However, the comment does not provide any specific reasoning or evidence to support why the connection is unclear or how it should be clarified. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the logical flow of the paper, questioning how an inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify the connection between these elements, which is a valuable observation that could help improve the clarity and coherence of the paper. However, the comment could be more helpful if it provided additional guidance on how to make this connection clearer or offered specific suggestions for restructuring the text. Despite this, the feedback is somewhat helpful as it directs the authors to a potential area of improvement, prompting them to enhance the logical structure of their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity regarding the main contribution and the novelty of the proposed method. It points out that the claims of the method\\'s properties are either overstated or not well-supported. Additionally, it highlights the unclear aspects of how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. While the comment clearly identifies areas that need clarification or improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what specific changes are needed to improve the clarity and support of their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, which is unclear, and points out that the claims of the proposed method\\'s properties are either overstated or not well-supported. It also highlights the lack of clarity regarding how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the introduction and methodology sections, but this inference is not explicit. The comment is specific in detailing what is unclear or overstated, providing some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear and that the claims about the proposed method\\'s properties are either overstated or not well-supported. It also points out the lack of clarity regarding how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to substantiate the claims. The authors would need to infer the specific issues and how to address them, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical areas where the paper lacks clarity and support for its claims. It points out that the main contribution of the paper is unclear, questioning the novelty and applicability of the proposed method. Additionally, it highlights the lack of clarity regarding how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. This feedback is valuable as it directs the authors to specific areas that need further elaboration and justification. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or examples of how to better support the claims. Overall, the comment is mostly helpful as it identifies key areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the bottom-up method [9] in the tables, as it has reported results on the crowdpose dataset outperforming all methods, including the paper\\'s method, with a ResNet-50. Additionally, the reviewer suggests evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (non-occluded) settings. Both suggestions are explicit and provide concrete guidance on what the authors should do to improve their draft. The reviewers clearly specify which methods to include and what additional evaluations to conduct, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including the bottom-up method [9] in the tables and evaluating the performance of the method on the standard MS coco dataset. However, it does not specify which part of the paper these suggestions pertain to, such as which tables or sections should be updated. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in suggesting the inclusion of the bottom-up method and the evaluation on the MS coco dataset, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including the bottom-up method [9] in the tables and evaluating the performance of the method on the standard MS coco dataset. The claim is somewhat verifiable as it provides a specific reference to the bottom-up method [9] and its reported results on the crowdpose dataset. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the inclusion of this method would be beneficial or necessary. The suggestion to evaluate performance on the MS coco dataset is also somewhat vague, as it does not specify how this evaluation would contribute to the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the inclusion of the bottom-up method [9] in the tables, as it has reported results on the crowdpose dataset outperforming all methods, including the paper\\'s method, with a ResNet-50. This recommendation is clear and could help the authors enhance the comprehensiveness and accuracy of their results. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (non-occluded) settings. This second suggestion is also specific and actionable, offering a way to further validate and compare the method\\'s performance. Both suggestions are constructive and provide the authors with clear steps to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim of using \"annotation guidelines\" in the paper, suggesting that the paper only considers label names, descriptions, and few-shot examples, which are not as comprehensive as the guidelines developed by linguists. The reviewer provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines. While the comment highlights a potential issue with the paper\\'s claim, it does not provide explicit guidance on how the authors should address this critique or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their discussion on annotation guidelines or provide a more comprehensive analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"claim of making use of \\\"annotation guideline\\\"\" and provides a specific example from the TACRED slot filling guidelines (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), which allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the paper\\'s claim by comparing it to the complexity of annotation guidelines developed by linguists. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the claim of using \"annotation guidelines\" by pointing out that the paper only considers label names, descriptions, and few-shot examples, which are not as comprehensive as the guidelines developed by linguists. The reviewer provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines, which adds credibility to the claim. However, the comment could be strengthened by providing more detailed examples or references to other annotation guidelines to fully substantiate the claim. Overall, the comment is mostly verifiable, as it provides a logical reasoning and a specific example to support the critique, but it could be more comprehensive with additional references or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critical evaluation of the paper\\'s claim regarding the use of \"annotation guidelines.\" It points out that the paper\\'s approach, which considers label names, descriptions, and few-shot examples, may not fully capture the depth of true guideline understanding. The reviewer supports this critique by referencing a specific example from the TACRED slot filling guidelines, which demonstrates the complexity of annotation guidelines developed by linguists. This feedback is valuable as it highlights a potential gap in the paper\\'s approach and suggests a direction for improvement by considering more comprehensive annotation guidelines. However, the comment could be more helpful if it offered specific suggestions on how the authors might incorporate these guidelines or expand their analysis. Overall, the comment is mostly helpful as it provides clear insights and a specific example, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERT-baseline. This provides a clear and direct action for the authors to take, ensuring that their experimental comparison is strengthened. The comment is specific and concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experiment comparison, specifically mentioning the need to compare the method to token pruning and token combination baselines, in addition to the BERT-baseline. This provides clear guidance on what needs to be addressed in the experimental section. However, the comment does not explicitly mention which part of the paper discusses the experiment comparison, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Despite this, the comment is specific in detailing what needs to be addressed, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment comparison is weak because the authors only compare their method to the BERT-baseline. It suggests that the authors should compare their method to token pruning and token combination baselines. This claim is somewhat verifiable as it provides a logical reasoning for the need to include additional baselines for a more comprehensive comparison. However, the comment lacks specific examples or references to support why these additional baselines are necessary or how they would enhance the comparison. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental comparison, noting that the authors only compare their method to the BERT-baseline. It suggests that the authors should also compare their method to token pruning and token combination baselines, which would provide a more comprehensive evaluation. This feedback is clear and actionable, offering a concrete suggestion for improving the experimental section of the paper. By addressing this point, the authors can enhance the robustness and validity of their results. However, the comment could be more helpful if it provided additional context or rationale for why these additional baselines are important. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental section should include a comparison to coordinate-aware methods, such as TFN or SchNet, as the current comparison only includes methods that are unaware of point coordinates. This feedback is explicit and provides a clear action for the authors to take, which is to include a comparison to coordinate-aware methods. The suggestion is concrete, as it specifies the types of methods to compare against, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting a comparison to coordinate-aware methods like TFN or SchNet, which are not currently included in the experimental section. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental section should include a comparison to coordinate-aware methods, such as TFN or SchNet, as the current comparison only includes methods that are unaware of point coordinates. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, noting the absence of coordinate-aware methods in the current comparison. However, the comment lacks specific examples or references to these coordinate-aware methods, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental section, noting that the current comparison only includes methods that are unaware of point coordinates. It suggests that a comparison to coordinate-aware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup by including additional methods that could enhance the comprehensiveness and relevance of their study. However, the comment could be more helpful if it explained why these coordinate-aware methods are important or how they might impact the results. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the potential weaknesses of the proposed model. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what specific weaknesses should be considered or how to discuss them. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the potential weaknesses of the proposed model. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis where the weaknesses should be discussed. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what specific weaknesses should be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what weaknesses should have been discussed, the comment lacks verifiability. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of a discussion on the potential weaknesses of the proposed model. This is a critical area that authors should address to provide a comprehensive evaluation of their work. However, the comment lacks specificity and does not offer suggestions or guidance on how the authors might identify and discuss these weaknesses. Without actionable advice or examples, the feedback is somewhat helpful, as it points out an important area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extract-then-generate methodologies and questioning the lack of a Related Work section. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to include a Related Work section and compare their methodology with existing ones, but the comment lacks detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extract-then-generate methodologies and questioning the lack of a Related Work section. However, it does not specify which part of the paper these concerns relate to, such as a particular section or experiment. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the lack of related work and comparisons, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extract-then-generate methodologies and questioning the lack of a Related Work section. The comment suggests that the paper lacks context and comparison with existing work, which is a valid concern. However, the comment does not provide specific examples or references to existing work that could be used for comparison, making it somewhat verifiable. The authors would need to conduct their own research to address these concerns, which adds some effort but does not significantly hinder the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extract-then-generate methodologies and questioning the lack of a Related Work section. It also points out the absence of experiments with other extract-then-generate methods using the proposed model, which is a critical gap in the paper. While the comment identifies significant weaknesses and areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it highlights important gaps in the paper, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. While it implies that the authors should consider these alternatives, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the specific changes needed without detailed guidance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting alternative approaches but lacks grounding, as it does not reference any particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a subjective opinion about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The suggestion to explore unlabelled data or apply constraints is more of a direction for future work rather than a critique of the current approach. Without additional context or justification, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" It suggests exploring unlabelled data or applying constraints as alternative directions for dealing with churn. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks specific guidance or detailed advice on how to implement these suggestions. The feedback is somewhat helpful as it provides a direction for the authors to consider, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to highlight the advantages or differences of the proposed method, such as the difference from B-GLN. While the comment implies that the authors should expand the related work section, it does not specify which specific aspects of GLN or B-GLN should be discussed or how to present them. The action is implicit and somewhat vague, as the authors are left to infer what additional information should be included and how to structure it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of related work, specifically mentioning the need for more work on GLN to highlight the advantages or differences of the proposed method, such as the difference from B-GLN. However, it does not specify which part of the introduction is insufficient or where the additional work on GLN should be included. The authors can infer that it relates to the related work section, but the comment lacks full grounding as it does not explicitly mention the section. It is specific in suggesting what needs to be addressed, such as highlighting the differences from B-GLN. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment lacks specific examples or references to support this claim, such as which aspects of GLN or B-GLN should be discussed or how they differ. Without detailed justification or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks the necessary details for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. This feedback is somewhat helpful as it points out a weakness in the paper and provides a direction for improvement by recommending a focus on GLN and its differences from B-GLN. However, the comment lacks detailed guidance on how to incorporate this additional work or what specific aspects of GLN should be emphasized. To be more helpful, the comment could include suggestions on how to structure the related work section or provide examples of relevant work to consider. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of hyperparameters in Moon\\'s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This comment implies that the authors should provide a justification or explanation for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of hyperparameters in Moon\\'s approach, specifically questioning why only one dropout rate is used while Variational dropout gets multiple parameters. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the hyperparameters, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the use of hyperparameters in Moon\\'s approach, specifically regarding the choice of a single dropout rate compared to multiple parameters in Variational dropout. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of hyperparameters in Moon\\'s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This is a relevant observation that could lead to a deeper understanding of the methodology and its implications. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include larger-scale experiments with non-trivial dynamics, such as grid-worlds with walls and other non-trivial tiles. It also implies that the current experiments may not be sufficient to judge the method\\'s scalability. The comment provides a specific suggestion by mentioning video-game domains as a potential area for experimentation, noting that simulators for such experiments are publicly available. This feedback is explicit and provides concrete guidance on how to expand the experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including larger-scale experiments with non-trivial dynamics, such as grid-worlds with walls and other non-trivial tiles. It also mentions the need for experiments on video-game domains, which are publicly available. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the types of experiments to include, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include larger-scale experiments with non-trivial dynamics, such as grid-worlds with walls and other non-trivial tiles. The reviewer questions whether the lack of such experiments is due to time constraints or a potential scalability issue with the method. The comment provides a specific suggestion for experiments on video-game domains, noting that simulators for such experiments are publicly available. This reasoning is somewhat verifiable as it offers a logical argument and a specific suggestion for improvement, but it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the experimental setup by suggesting the inclusion of larger-scale experiments with non-trivial dynamics, such as grid-worlds with walls and other non-trivial tiles. It questions whether the current experiments are sufficient to judge the method\\'s scalability and suggests that experiments on video-game domains would be more convincing. The comment provides specific examples and references to publicly available simulators, offering actionable guidance for the authors to enhance their experimental section. This feedback is clear and detailed, making it highly helpful for the authors to improve their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measurement for occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific measurements could be used. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of quantitative measurement for occupation bias relative to real distributions in society. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references or context, the authors may find it challenging to pinpoint the exact area needing revision. The comment is specific in identifying the absence of quantitative measurement but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This claim is somewhat verifiable as it highlights a gap in the paper\\'s analysis, but it lacks specific examples or references to support the assertion. The authors would need to consider how to address this gap in their work, but the comment itself does not provide detailed guidance or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks quantitative measurement for occupation bias relative to real distributions in society. This is a relevant observation that could help the authors enhance the rigor and comprehensiveness of their analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this gap or what specific measurements could be used. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or whether they should consider using an adaptive gradient method. The action is implicit and somewhat vague, as the authors are left to infer that they might need to explore this possibility but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or experiment where the adaptive gradient method is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, while the comment provides a specific concern about the impact of adaptive gradient methods, it does not specify what needs to be addressed or improved in the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address this issue or whether they should consider using an adaptive gradient method. The feedback is somewhat helpful as it prompts the authors to consider a potential impact on their findings, but it does not provide actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the experiments for being insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to expand the experiments, what additional architectures or methods should be included, or how to improve the comparison. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the experiments for being insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experiments, such as the limited teacher architectures and the outdated methods being compared. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiments, noting that they are insufficient due to limited types of teacher architectures and the fact that most compared methods are proposed before 2019. This feedback is somewhat helpful as it points out a potential weakness in the experimental setup, prompting the authors to consider expanding their experiments to include more diverse teacher architectures and up-to-date methods. However, the comment lacks actionable suggestions or guidance on how to address these issues, such as recommending specific architectures or methods to include. While it provides some insight, the feedback could be more helpful with additional details or concrete actions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that no information from 2-hop neighbors is included, suggesting that this method is simple but unclear in its effectiveness. While the comment implies that the authors should provide more information on the effectiveness of the method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the effectiveness of the method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions that \"no information from 2-hop neighbors is included,\" which implies that it is referring to a specific method or section of the paper. However, it does not explicitly mention which part of the paper this information is missing from, making it weakly grounded. The comment is specific in pointing out the lack of information from 2-hop neighbors and questioning the effectiveness of the method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"no information from 2-hop neighbors is included,\" suggesting that this method is simple but unclear in its effectiveness. However, the comment lacks specific examples or detailed reasoning to support why the inclusion of 2-hop neighbor information would improve the method\\'s effectiveness. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a specific omission in the paper, noting that no information from 2-hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is unclear why the method is effective. While the comment identifies a gap in the paper and raises a valid concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of the method\\'s effectiveness. The feedback is somewhat helpful as it directs the authors\\' attention to a critical area needing further explanation, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends using a real DICOM image instead of a PNG image for the experiment data and suggests using the FastMRI challenge dataset. It also advises comparing inference speed between different methods. These suggestions are clear and provide concrete actions for the authors to take, making the comment highly actionable. The authors know exactly what changes to make to improve their draft, ensuring a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a real DICOM image instead of a PNG image, which allows the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions, such as recommending the FastMRI challenge dataset and comparing inference speed between different methods. This level of detail and explicit guidance makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using a real DICOM image instead of a PNG image for the experiment data and recommends using the FastMRI challenge dataset. It also advises comparing inference speed between different methods. However, the comment lacks specific reasoning or evidence to support why using a real DICOM image is preferable or how the FastMRI challenge dataset would be beneficial. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a suggestion but lacks the necessary depth to fully substantiate the recommendation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending the use of a real DICOM image instead of a PNG image for the experiment data. It also suggests using the FastMRI challenge dataset and comparing inference speed between different methods. This feedback is clear and offers concrete steps for the authors to improve their experimental setup and analysis, making it highly helpful. The comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter. However, it does not specify what aspects of the design need optimization or how to validate it. The comment lacks concrete guidance on how the authors should proceed with these actions, leaving them with a vague understanding of what needs to be done. As a result, the comment is barely actionable, as the authors are not provided with clear steps to improve their draft.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the binder design provided by ProtPainter, suggesting that further optimization and validation are required. However, it does not specify which part of the paper discusses this design, making it weakly grounded. The comment is specific in its request for further optimization and validation, but without clear references to the paper, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"ProtPainter just provides an empirical conformation estimation\" and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current estimation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the binder design provided by ProtPainter, noting that it is limited to an empirical conformation estimation. It suggests that further optimization and validation are necessary, which is a clear and actionable piece of feedback. However, the comment does not provide specific guidance on how to optimize or validate the design, nor does it offer examples or references to support the claim. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests clarification on how the model in Figure 7 was trained. It asks whether the model was trained on full field flicker stimulus changing contrast with a fixed cycle and whether the time scale of adaptation would shorten if the cycle duration changes. This feedback provides clear and specific actions for the authors to take, such as explaining the training process and addressing the potential impact of changing cycle durations. The comment is explicit and provides concrete guidance on what needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on how the model in Figure 7 was trained and asks about the impact of changing cycle durations on adaptation time scales, referencing a specific study (Smirnakis et al., Nature 1997). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests clarification on how the model in Figure 7 was trained and asks about the impact of changing cycle durations on adaptation time scales. It references a specific study (Smirnakis et al., Nature 1997) to support the claim that the time scale of adaptation might shorten. This provides a logical basis for the claim, as it suggests a potential issue with the model\\'s ability to handle longer time scales. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it requires additional context to be fully supported.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback by requesting clarification on how the model in Figure 7 was trained. It asks whether the model was trained on full field flicker stimulus changing contrast with a fixed cycle and whether the time scale of adaptation would shorten if the cycle duration changes. This feedback is clear and directs the authors to address a critical aspect of their methodology, which could significantly impact the interpretation of their results. By clarifying these details, the authors can enhance the transparency and robustness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about what would happen if the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address this issue. As a result, the comment lacks actionability, as it does not offer any direction for improvement or change in the draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. However, it does not specify which part of the paper this scenario is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on why this scenario is relevant or how it relates to the paper\\'s content. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific scenario involving the original CAD model and SV BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. While it highlights a potential area of interest, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this scenario or its implications for their work. Without specific advice or direction, the comment does not offer much value in helping the authors improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that additional evaluation, particularly on CIFAR-10 in the full label and lower label scenarios, would be beneficial. However, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional evaluations but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evaluation would be welcome, particularly on CIFAR-10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be added to, making it weakly grounded. The comment is specific in suggesting a particular scenario for evaluation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evaluation would be welcome, particularly on CIFAR-10 in the full label and lower label scenarios. However, it does not provide any specific reasoning or evidence to support why this additional evaluation is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more evaluation would be beneficial, particularly on CIFAR-10 in the full label and lower label scenarios. This feedback is somewhat helpful as it identifies a specific area where the authors could enhance their work by providing additional evaluation. However, the comment lacks depth and does not offer specific guidance on what aspects of the evaluation should be focused on or how to conduct the additional analysis. While it points out a potential improvement, it does not provide detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data in the comparisons. The reviewer suggests that comparisons should be made using the same amount of data, pointing out specific examples where this is not the case. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The authors can infer that they need to ensure consistency in the data used for comparisons, but the comment lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data in the comparisons. The comment provides examples of where this issue arises, such as comparing H->N and H->B with H->N+B, and H->N->H with H->N+B->H. This level of detail helps the authors understand what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. The reviewer provides specific examples, such as comparing H->N and H->B with H->N+B, and H->N->H with H->N+B->H, to illustrate the issue. This level of detail and specific examples provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by further explaining why this issue is important or how it affects the interpretation of the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a valid concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. It provides specific examples where the data used for comparisons is not consistent, such as comparing H->N and H->B with H->N+B, and H->N->H with H->N+B->H. This feedback is clear and actionable, as it prompts the authors to ensure that their comparisons are made using the same amount of data, which is crucial for accurate analysis and interpretation of results. However, the comment could be more helpful if it suggested ways to address this issue, such as adjusting the experimental setup or providing additional explanations in the text. Overall, the comment is mostly helpful as it identifies a significant issue and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues, including the counterintuitive placement of a section at the end of the paper and questions about the application of Algorithm 1 with different iterations. It also points out a lack of reference to Laplacian eigenmaps and a missing citation in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues or what changes should be made. The authors can infer that they need to clarify the placement of the section, explain the application of Algorithm 1 with different iterations, and ensure proper references and citations. However, the lack of concrete guidance makes the actions somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and figures in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the placement of a section, the application of Algorithm 1, the lack of reference to Laplacian eigenmaps, and the missing citation in the introduction. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims, each of which requires verification. The first claim about the placement of a section is not supported by any reasoning or evidence, making it difficult for the authors to understand the basis of the suggestion. The second claim about the application of Algorithm 1 with different iterations lacks specific examples or references to support the assertion that larger T is not considered. The third claim regarding the lack of reference to Laplacian eigenmaps and its citation in the introduction is somewhat verifiable, as it points out a specific omission that could be addressed. However, the comment does not provide detailed reasoning or references to fully substantiate the claim. Overall, the review point contains a mix of verifiable and unverifiable claims, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several issues that could be addressed to improve the paper. It points out a counterintuitive placement of a section at the end of the paper, which could be more logically positioned earlier. It also questions the application of Algorithm 1 with different iterations and suggests that larger T is not considered, which could be a significant oversight. Additionally, the comment notes the lack of reference to Laplacian eigenmaps and a missing citation in the introduction, which could impact the paper\\'s coherence and completeness. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues or offer suggestions for restructuring the paper. Therefore, the feedback is somewhat helpful, as it highlights important areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the structure of their paper, it does not explicitly instruct them to remove or reorganize Section 2.1. The action is implicit and somewhat vague, as the authors are left to infer that the section might be unnecessary or could be better utilized. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, questioning the inclusion of Batch Normalization as a general technique and suggesting that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. The comment provides a logical reasoning by pointing out that Batch Normalization is a general technique, which implies that the section might not be necessary. However, it lacks specific examples or references to support the claim that the time spent on describing the ResNet architecture could be better utilized. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the structure of the paper, specifically questioning the inclusion of Section 2.1, which describes Batch Normalization as a general technique. The reviewer suggests that the time spent on describing the ResNet architecture could be better utilized to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is somewhat helpful as it points out a possible redundancy in the paper and offers a suggestion for improvement. However, it lacks specific guidance on how to restructure the paper or what additional content could be included to enhance the motivation and intuition for the proposed CBN approach. Therefore, the comment is rated as somewhat helpful, as it provides some direction but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. The reviewer suggests that multiplying by a dense matrix would not lead to sparsity, implying that the authors need to clarify their reasoning. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue or clarify their explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional explanation or justification for the sparsity assumption. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L122\" and \"equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the logic behind assuming a dense projection matrix would result in a sparse matrix, providing a clear direction for the authors to clarify their explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the logic behind assuming a dense projection matrix would result in a sparse matrix, suggesting that multiplying by a dense matrix would not lead to sparsity. The comment provides a logical reasoning by pointing out the contradiction between the assumption and the expected outcome. However, it does not include specific references or examples to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. It points out a potential contradiction in the authors\\' reasoning, which is a valuable observation that could help the authors clarify their assumptions and improve the clarity of their explanation. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered alternative explanations. Despite this, the feedback is somewhat helpful as it directs the authors\\' attention to a critical area that needs clarification.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to address the feedback. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a figure to support the claim about the decline in accuracy of a predictor over time in different settings. This allows the authors to accurately identify the part of the paper being addressed, specifically the motivation section. The comment is also specific because it clearly specifies what is missing, namely a plot to demonstrate the accuracy decline over time. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evidence for the motivation is not direct and suggests plotting a figure to support the claim. This is a logical request based on the stated problem, which is the accuracy decline due to long-term and continuous usage. The suggestion to plot a figure is a clear and specific action that would help substantiate the claim. However, the comment could be strengthened by providing examples or references to similar plots or studies that support this approach. Therefore, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evidence provided for the motivation of the paper, noting that the decline in accuracy due to long-term and continuous usage is not directly supported. It suggests that the authors plot a figure showing the decline in accuracy over time in different settings to substantiate their claim. This feedback is clear and actionable, providing the authors with a concrete step to take to strengthen their argument. By addressing this suggestion, the authors can enhance the credibility and clarity of their work. Therefore, the comment is rated as mostly helpful, as it offers valuable guidance for improvement but could be more comprehensive with additional details or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and the interpretation of the results. It explicitly asks for an explanation of how to calculate excessive risk in practice, particularly in terms of expectation, and questions the validity of the results shown in Figures 3 and 7. Additionally, it inquires about the comparability of excessive risk values across different groups and whether it is a suitable representation of fairness. While the comment does not provide explicit instructions, it clearly identifies areas that need clarification and further explanation, leaving the authors with a clear understanding of what needs to be addressed. The action is implicit but concrete, as the authors know exactly what aspects of their work require additional explanation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the definition of excessive risk, its calculation, and the interpretation of the results, particularly regarding the positivity of values in Figures 3 and 7. The comment also asks for clarification on the comparability of excessive risk values across different groups and whether it is a suitable representation of fairness. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and requests for clarification regarding the definition of excessive risk and its calculation. It questions the validity of the results shown in Figures 3 and 7, as all excessive risk values are positive, and asks about the comparability of excessive risk values across different groups. While the comment identifies areas that need further explanation, it lacks specific evidence or references to support the claims or questions. The authors are left to infer the basis of the questions, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important questions and requests for clarification regarding the definition and calculation of excessive risk, as well as the interpretation of the results shown in Figures 3 and 7. It questions the validity of the results, particularly the positivity of all excessive risk values, and asks whether these values are comparable across different groups. Additionally, it inquires about the suitability of excessive risk as a representation of fairness. These questions are clear and actionable, providing the authors with specific areas to address and clarify in their draft. By answering these questions, the authors can enhance the clarity and robustness of their work. Therefore, the comment is mostly helpful, as it offers detailed guidance for improvement but could be more comprehensive by suggesting specific ways to address the issues raised.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the statement about initialization should be more carefully stated, as initialization plays a role in the context of NGD, which is a discretization of NGF. The reviewer references a specific paper by Kunstner et al. (2019) to support this claim. While the comment implies that the authors should revise their statement on initialization, it does not provide explicit guidance on how to make the statement more accurate or detailed. The reference to the external work is a helpful starting point, but the authors still need to determine how to apply this information to their draft. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as an initial value problem (IVP). The comment provides a reference to a specific paper by Kunstner et al. (2019) to support the claim, which further enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Initialization does play a role NGD is a discretization of NGF. Solving NGF is an initial value problem (IVP) in this setting. Thus, initialization should play a role such as pre-training.\" The reviewer supports this claim by referencing a specific paper by Kunstner et al. (2019), which provides a detailed explanation of the role of initialization in the context of NGD and NGF. This reference offers a clear and logical basis for the claim, making it fully verifiable. The inclusion of a specific reference enhances the robustness of the argument, ensuring that the authors can fully understand and address the feedback. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the statement about initialization. It provides a logical reasoning by connecting the role of initialization in the context of NGD, which is a discretization of NGF, and the fact that solving NGF is an initial value problem (IVP). The comment suggests that the statement about initialization should be more carefully stated, offering a reference to a relevant paper by Kunstner et al. (2019) for further exploration. This feedback is clear and actionable, as it directs the authors to reconsider their statement on initialization and provides a specific reference to support their understanding. However, the comment could be more helpful if it included additional guidance on how to revise the statement or what specific aspects of the paper should be addressed. Overall, the comment is mostly helpful, as it provides valuable insights and resources for improvement but could be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the extraction of named entities from the datasets is unclear and recommends an English-proofreading to improve the readability of the paper. While the comment implies that the authors should clarify the extraction process, it does not provide specific guidance on how to do so or what aspects of the extraction method need clarification. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the clarity. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the clarity of named entity extraction from datasets and suggests an English-proofreading to improve readability. However, it does not specify which part of the paper discusses the extraction process, making it weakly grounded. The comment is specific in suggesting an English-proofreading, but it lacks detailed guidance on what aspects of the extraction process need clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the extraction of named entities from datasets is unclear and suggests an English-proofreading to improve readability. However, the comment does not provide any specific examples, reasoning, or references to support the claim about the clarity of the extraction process. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of named entity extraction from datasets. It suggests that an English-proofreading could improve the readability of the paper. While the comment highlights a potential issue, it lacks depth and does not provide detailed guidance or suggestions on how to improve the clarity of the extraction process. The feedback is somewhat helpful as it points out an area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment consists of two parts. The first part, \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,\" is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part, \"Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" suggests an alternative approach to the condition but does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides a suggestion for an alternative approach to the condition, \"Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give.\" This level of detail guides the authors on what needs to be addressed and how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a claim about the implication of \"for every arm a\" and a suggestion for an alternative approach to the condition. The first part is a factual observation, as it describes the implication of the phrase \"for every arm a\" without suggesting changes or providing an opinion. The second part is a suggestion for an improvement, but it lacks specific reasoning or references to support why this alternative approach is better. The comment does not provide sufficient evidence or justification to fully substantiate the claim or suggestion, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for an improvement in the paper. It points out a potential issue with the implication of \"for every arm a\" and suggests an alternative approach to the condition, which is based on choosing T_0 = m Sqrt(T). This feedback is clear and actionable, offering the authors a concrete way to enhance their analysis. However, the comment could be more helpful if it explained why the suggested approach is better or how it aligns with the paper\\'s objectives. Overall, the comment is mostly helpful as it provides a valuable direction for improvement, but it could be more comprehensive with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the definition of L and E, noting that they should be defined in the immediate vicinity and that their formatting is inconsistent. While the comment identifies a clear action for the authors to take\u2014define L and E in the immediate vicinity and ensure consistent formatting\u2014it does not provide detailed guidance on how to implement these changes. The authors know what needs to be done but may need to infer the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the definition and formatting of L and E, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue with the formatting and definition of L and E in the paper. It points out inconsistencies in the formatting, noting that L and E are sometimes italicized and sometimes not. This observation is factual and does not contain subjective opinions or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting and definition of L and E in the paper, noting that they should be defined in the immediate vicinity and that their formatting is inconsistent. This feedback is clear and actionable, as it directs the authors to address a specific formatting issue that could lead to confusion for readers. By pointing out this inconsistency, the comment provides a concrete step for the authors to take to improve the clarity and readability of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to consistently format these terms throughout the paper. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not provide any specific guidance on what additional experiments should be conducted or how they should be designed. The action is implicit and vague, as the authors are left to infer what specific experiments are necessary without concrete details or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not specify which part of the experimental section is weak or what specific experiments are required. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is not grounded as it does not identify a specific section or element of the paper, and it is not specific because it lacks detailed guidance on what additional experiments should be conducted. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a weakness in the experimental section, noting that it is \"a little weak\" and suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they might improve the section. Without detailed suggestions or examples, the authors are left with a general idea of what needs improvement but without actionable steps to take. This makes the comment barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to effectively address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. While the comment implies that the authors should include additional comparisons, it does not specify which models or techniques should be considered or how to implement these comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific models and techniques to include and how to conduct the comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which specific models or techniques should be considered. This lack of specificity and grounding makes it difficult for the authors to identify where and how to address the suggestion. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these additional comparisons are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. This feedback is somewhat helpful as it identifies a potential area for improvement by encouraging the authors to broaden their comparisons. However, the comment lacks specificity and does not provide guidance on which specific models or techniques should be considered or how to conduct these comparisons. While it points out a direction for enhancement, it does not offer detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment consists of a series of grammatical corrections and clarifications. Each correction is explicit and provides clear guidance on how to modify the text to improve its accuracy and clarity. The authors can directly apply these changes to their draft, making the feedback highly actionable. The comment is specific and provides concrete details on what needs to be corrected, ensuring that the authors know exactly how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment consists of a series of grammatical corrections and clarifications, each of which is specific and actionable. However, it does not provide any context or grounding for where these corrections are needed in the paper. The authors might be able to infer that these corrections are related to specific lines or sections, but without explicit references, the comment is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of grammatical corrections and clarifications, which are factual and do not contain subjective claims or opinions. It does not make any assertions or suggestions that require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a series of grammatical corrections and clarifications, which are specific and actionable. By pointing out these errors, the reviewer helps the authors improve the clarity and accuracy of their manuscript. However, the comment does not offer any broader insights or suggestions for improving the content or structure of the paper. While it is helpful in terms of correcting errors, it lacks depth and does not provide comprehensive feedback that would significantly enhance the draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to. It also mentions a mistake in equations, but it does not specify which equations or what the mistake is. The comment lacks explicit guidance or concrete suggestions on how to address the issue, leaving the authors uncertain about the exact action needed. The action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"W4 \u2013 Mistakes in Eqs,\" which provides some grounding as it implies that the issue is related to equations in the paper. However, it does not specify which equations are incorrect or what the specific mistake is, making it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in identifying a potential issue with equations but lacks full grounding because it does not explicitly mention the section or page where the equations are located. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a factual question that does not contain an opinion, claim, or suggestion requiring verification. It is purely descriptive and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a clear and specific observation that could help the authors clarify a potential misunderstanding in their work. However, the comment does not provide any additional context or suggestions for improvement, such as how to address the issue or what impact it might have on the overall analysis. While it identifies a potential area of confusion, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived incremental nature of the work or suggestions for improving the model. Without any actionable advice or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the model could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is somewhat incremental, as it is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might improve their work or address the perceived incremental nature of the paper. Without actionable advice or constructive criticism, the comment offers limited value to the authors in terms of guiding their revisions. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without state-related registers. It also suggests a comparison between sequential and combinational designs. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to conduct the comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without state-related registers. It also suggests a comparison between sequential and combinational designs. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting a comparison and questioning the method\\'s performance in a specific context. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without state-related registers. It also suggests a comparison between sequential and combinational designs. However, the comment lacks specific evidence, examples, or references to support the claim that the method performs better in combinational logic. Without detailed justification or examples, the claim remains somewhat speculative, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without state-related registers. It also suggests a comparison between sequential and combinational designs, which could provide valuable insights into the method\\'s applicability. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for exploration, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it points out a relevant area for further investigation but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to conduct a specific analysis or provide detailed guidance on how to address this curiosity, it does imply that the authors should consider evaluating the performance of this baseline. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment section\" and the \"baseline\" that combines LDA and LSTM, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of the baseline in terms of the topic switch percent metric, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not provide specific suggestions for improvement or critique the methodology, it does prompt the authors to consider an important aspect of their experiment. This feedback encourages the authors to explore and report on a specific metric, which could enhance the comprehensiveness and depth of their analysis. However, the comment lacks depth and does not offer actionable guidance for improvement. Therefore, it is somewhat helpful, as it provides a direction for the authors to consider but does not fully address their needs for enhancing the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights important areas for improvement but does not offer detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the task, specifically questioning the clarity of the motivation and the potential downstream applications or benefits of amodal tracking. It also raises concerns about the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not explicitly mention which part of the paper discusses the motivation or the potential applications, making it weakly grounded. The authors can infer that it relates to the introduction or motivation sections, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as the potential applications and handling of uncertainty. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important questions about the motivation and potential applications of the task, specifically addressing the challenges of predicting the state of objects when they are totally occluded. It highlights the difficulty in ensuring the quality of annotations due to the lack of knowledge about the real states of these objects. The comment also prompts the authors to consider how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies critical areas for clarification and improvement, it does not provide specific suggestions or examples on how the authors might address these issues. The feedback is somewhat helpful as it points out key areas for improvement but lacks detailed guidance, making it somewhat actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as specific experimental setups or parameters to use. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in suggesting the inclusion of GPT-3.5 experiments, but without clear grounding, it is weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including experiments with GPT-3.5 to provide a more comprehensive evaluation, given the expense of GPT-4. The comment is based on a logical reasoning that GPT-3.5 is a more affordable option and could offer valuable insights. However, it lacks specific examples or references to support the claim that GPT-3.5 is a suitable alternative or that it would provide a more comprehensive evaluation. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it offers a specific suggestion for improving the experimental setup. By including GPT-3.5, the authors can better assess the performance and applicability of their method across different budget constraints. However, the comment could be more helpful if it provided additional context or rationale for why GPT-3.5 is a relevant choice or how it might impact the evaluation. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It also specifies that the best result in terms of BLEU for WMT17-WIKT is in the baselines, providing clear guidance on what needs to be done. This feedback is direct and concrete, giving the authors a specific action to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely bold numbers for the baselines of previous work and the fact that the best result in terms of BLEU for WMT17-WIKT is in the baselines. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically noting that the best result in terms of BLEU for WMT17-WIKT is in the baselines. This is a clear and specific request for improvement, providing a direct action for the authors to take. The comment is fully verifiable as it provides a clear and actionable suggestion, making it easy for the authors to understand and implement the change. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of results in Table 4. It instructs the authors to include bold numbers for the baselines of previous work, specifically highlighting that the best result in terms of BLEU for WMT17-WIKT is in the baselines. This feedback is clear and provides a concrete step for the authors to enhance the clarity and readability of their results, making it highly helpful. By addressing a specific issue with the presentation of results, the comment empowers the authors to improve the overall quality of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the use of the term \"unreliable neighbors\" and asks for examples of such neighbors. This provides a clear and direct action for the authors to take, which is to provide examples or clarify the concept of \"unreliable neighbors\" in their draft. The comment is explicit and concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of the term \"unreliable neighbors\" and asks for examples of such neighbors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for examples of \"unreliable neighbors,\" which is not a claim but rather a request for clarification. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific line in the paper (lines 170-171) where the term \"unreliable neighbors\" is used. It questions the use of this term and asks for examples of such neighbors. This feedback prompts the authors to clarify or provide examples of what constitutes \"unreliable neighbors,\" which could help improve the clarity and specificity of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of sufficient evidence to support the claim about the synergies between DQD and PPO. It specifically points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using on-policy RL better fitting the DQD framework. While the comment identifies a specific issue and suggests a comparison that should be included, it does not provide explicit instructions on how to address the issue or conduct the comparison. The action is implicit and somewhat vague, as the authors know they need to provide more evidence and include a comparison to TD3GA, but they are not given detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim about the synergies between DQD and PPO, specifically questioning the lack of evidence and mentioning the TD3GA algorithm. However, it does not explicitly mention which part of the paper discusses these synergies or where the TD3GA algorithm is mentioned, if at all. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in pointing out the lack of evidence and the importance of the TD3GA algorithm, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up, specifically noting the absence of mention of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA is crucial to understand these synergies. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion and suggests a specific comparison that could strengthen the argument. However, the comment lacks detailed reasoning or references to support the claim fully, making it somewhat verifiable. The authors would need to address the gap themselves to fully understand and improve the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using on-policy RL better fitting the DQD framework. This feedback is clear and actionable, as it highlights a gap in the paper\\'s discussion and provides a specific direction for improvement. By addressing this issue, the authors can strengthen their argument and enhance the comprehensiveness of their work. Therefore, the comment is mostly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the unexpected performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance, as observed in Sections 6.1 and 6.2. It explicitly asks for an explanation of this phenomenon, providing a clear and direct action for the authors to take. The comment is specific in its request for an explanation, which makes it highly actionable. The authors know exactly what they need to do to address the reviewer\\'s concern: provide an explanation for the observed performance difference. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the unexpected performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance, and it requests an explanation for this observation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the unexpected performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance, as observed in Sections 6.1 and 6.2. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a surprising observation in the paper, specifically noting that the tree-sliced Wasserstein distance outperforms the original optimal transport distance in Sections 6.1 and 6.2. It raises a question about the reason for this unexpected performance, which is a relevant and important point for the authors to address. By asking for an explanation, the comment encourages the authors to delve deeper into their findings and potentially uncover insights that could enhance the understanding of their results. However, the comment could be more helpful if it provided suggestions on how to approach this explanation or what aspects to consider. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a slight confusion regarding the use of the word \"confident\" in the context of ceterus paribus convexity. It suggests that the author might be referring to human interpretability rather than model confidence, and recommends a slight rephrasing to clarify this point. While the comment identifies a potential issue and suggests a specific action (rephrasing), it does not provide detailed guidance on how to rephrase the sentence. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely sure of the exact wording. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"We have found it easier to be confident about applying ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a confusion regarding the use of the word \"confident\" and suggests that it might refer to human interpretability rather than model confidence. The comment provides a clear suggestion for rephrasing to clarify this point. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a logical reasoning by questioning the intended meaning of the word \"confident,\" which helps clarify the issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the suggestion to rephrase the sentence to clarify the intended meaning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a clear suggestion to rephrase the sentence to clarify this point, which is a valuable contribution to the authors' understanding and clarity of their work. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in making the necessary changes. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features. It highlights that prior knowledge might not always be available or accurate for specific subpopulations, which is why most researchers focus on mining causal relationships from data automatically. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they should consider the limitations of prior knowledge and explore alternative methods for mining causal relationships. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the practicality of using known causal relationships between features, which is a relevant concern for the paper. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in its critique of the assumption of known causal relationships and the limitations of prior knowledge, particularly for specific subpopulations. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features. It highlights that prior knowledge might not always be available or accurate for specific subpopulations, which is why most researchers focus on mining causal relationships from data automatically. The comment provides a logical reasoning based on common knowledge in the field, suggesting that the assumption of known causal relationships may be limiting in practice. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to consider this critique and provide additional context or evidence to fully address the concern.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the practicality of the work, specifically regarding the assumption of known causal relationships between features. It highlights a common limitation in many research areas, where prior knowledge might not always be available or accurate for specific subpopulations. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their approach and potentially explore alternative methods for mining causal relationships from data. However, the comment could be more helpful if it provided suggestions on how to address this limitation or offered examples of alternative approaches. Overall, the feedback is clear and actionable, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the presentation of empirical findings, including missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two small-scale datasets and a single architecture type for core findings. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add axis labels, clarify the masking of curves, conduct multiple seed experiments, and expand the dataset and architecture types for core findings. However, the lack of concrete guidance on how to implement these changes makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific issues with the presentation of empirical findings, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two small-scale datasets and a single architecture type for core findings. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what is lacking in the presentation of empirical results, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity and confidence in its empirical findings due to issues with the presentation of figures and results. It mentions specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two small-scale datasets and a single architecture type for core findings. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the issues and how they impact the confidence in the results. Therefore, the comment is somewhat verifiable, as it provides a general direction but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues with the presentation of empirical findings, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two small-scale datasets and a single architecture type for core findings. These points are clear and actionable, providing the authors with concrete areas to address in order to improve the clarity and confidence in their empirical results. However, the comment could be more helpful by suggesting specific ways to address these issues, such as recommending the inclusion of multiple seeds or additional datasets. Overall, the feedback is mostly helpful as it directs the authors to specific areas that need improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with fine-tuning are expected due to the nature of task-specific fine-tuning, which increases confidence for a specific task but potentially reduces generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take in response to this feedback. It lacks guidance on how the authors might address the perceived lack of novelty or improve their work based on the observation. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with fine-tuning are expected due to the nature of task-specific fine-tuning. However, the comment does not specify which part of the paper discusses these findings or observations, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides a logical explanation for the limited novelty, it lacks specificity in terms of what aspects of the paper could be improved to enhance the novelty. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the work is limited, citing observations like tighter CIs with fine-tuning as expected due to the nature of task-specific fine-tuning. The comment provides a logical explanation for why these observations are expected, which is based on common knowledge about the effects of fine-tuning on confidence and generalizability. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct additional research to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with fine-tuning are expected due to the nature of task-specific fine-tuning, which increases confidence for a specific task but potentially reduces generalizability. However, the comment does not offer any specific suggestions or guidance on how the authors might enhance the novelty or address the limitations identified. While it provides some insight into the expected outcomes of fine-tuning, it lacks actionable feedback that could help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential limitation but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should report the numbers observed when the label noise experiment is performed on image-net with 1000 classes, specifically focusing on the non-tail classes. This is an explicit suggestion for additional data to be included in the paper, which would strengthen the case and further test the conjecture. The comment provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should report the numbers observed when the label noise experiment is performed on image-net with 1000 classes, specifically focusing on the non-tail classes. This provides a clear and specific suggestion for additional data to be included in the paper. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the label noise experiment, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that reporting the numbers observed when the label noise experiment is performed on image-net with 1000 classes would strengthen the case and further test the conjecture. The comment provides a logical reasoning for why this additional data would be valuable, as it would stress test the conjecture even if the phenomenon weakens in this setting. However, the comment does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the claim is somewhat verifiable, as it lacks detailed evidence but provides a logical basis for the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from reporting the numbers observed when the label noise experiment is performed on image-net with 1000 classes, specifically focusing on the non-tail classes. This suggestion is clear and actionable, as it provides a specific direction for the authors to enhance their study by testing the conjecture in a more challenging setting. The comment also acknowledges that even if the phenomenon weakens in this setting, the numbers are still worth reporting. While the comment is focused on a particular aspect of the paper, it offers a concrete way to strengthen the case and improve the draft. Therefore, it is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. It suggests that the authors provide additional feedback to improve the paper. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional feedback but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional feedback to improve the paper, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of the number of weight updates as a metric, suggesting that the number of network updates might be a more appropriate metric given the parallel nature of brain operations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of network updates would be a better metric. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of the number of weight updates as a metric, suggesting that the number of network updates might be a more appropriate metric given the parallel nature of brain operations. This is a valid point that prompts the authors to reconsider their choice of metric and provides a direction for improvement. However, the comment lacks specific suggestions or examples on how to address this issue, such as proposing alternative metrics or explaining why network updates might be more relevant. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. While it highlights an area of potential interest, it does not provide explicit guidance or suggestions for the authors to address this question or improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore or discuss real scenarios where the proposed objective differs from classical prediction accuracy. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the applicability of the proposed objective, but it lacks grounding as it does not reference a particular section or context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. It does not present an opinion, claim, or suggestion that requires verification. The comment is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. This is a relevant inquiry that could help the authors clarify the practical implications and applications of their work. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their draft. It lacks actionable feedback, leaving the authors with only a vague idea of what needs to be explored. Therefore, the comment is barely helpful, as it identifies a potential area of interest but does not offer specific guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the evaluation in the paper, including the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of in-content examples used, and the reliance on a single dataset. The comment suggests that these issues limit the comprehensiveness and generalizability of the results. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is somewhat actionable as it points out the problems but lacks concrete steps for resolution. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of in-content examples used, and the reliance on a single dataset. This provides clear guidance on what needs to be addressed to improve the comprehensiveness and generalizability of the evaluation. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It highlights specific issues, such as the absence of information on the number of different sets of in-content examples used and the reliance on a single dataset, which may limit the generalizability of the results. The comment provides logical reasoning by pointing out specific areas where the evaluation could be improved, making it mostly verifiable. However, it could be strengthened by providing examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several critical issues with the evaluation section of the paper, specifically the lack of transparency regarding the experiment setup and the reliance on a single dataset. It points out specific areas that need improvement, such as the number of different sets of in-content examples used and the exploration of varying the number of In-Context Examples. This feedback is clear and actionable, as it provides the authors with specific areas to address to enhance the comprehensiveness and generalizability of their evaluation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of best practices in similar studies. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their evaluation methodology, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, whether it is a concern or a suggestion for improvement. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done in response to this comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this claim pertains to, such as a specific section, figure, or table. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the framework are identical or how this similarity affects the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how it affects their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any context, explanation, or justification for this claim, nor does it offer any suggestions for improvement or guidance on how the authors might address this issue. Without additional information or actionable feedback, the comment lacks value and does not assist the authors in enhancing their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include comparative experiments with other non-linear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of their proposed method. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to implement them or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other non-linear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks comparative experiments with other non-linear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This claim is somewhat verifiable as it provides a logical reasoning for the need to include such comparisons to better understand the method\\'s performance in a broader context. However, the comment lacks specific examples or references to existing works that have conducted these comparisons, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests that including such comparisons could help showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By highlighting this gap, the comment provides the authors with a concrete direction for enhancing their draft. However, it could be more helpful if it offered specific suggestions on which blocks to compare or how to conduct these experiments. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their work but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not provide any guidance on how the authors should incorporate these references or what specific aspects of the related work should be addressed. The action is implicit and lacks concrete details on how to implement the suggestion, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on what aspects of the related work should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or justification for why these specific references are relevant or how they could enhance the paper. Without further explanation or context, the authors may find it challenging to understand the importance of these references or how to incorporate them into their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors should incorporate these references or what aspects of the related work should be addressed. The feedback is somewhat helpful as it points out a gap in the paper but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a comparison against existing text GANs, specifically mentioning the lack of testing with the pretrained version of SeqGAN. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or which existing text GANs to consider. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of comparison against existing text GANs, particularly mentioning the absence of testing with the pretrained version of SeqGAN. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental setup or results section, but this inference is not explicit. The comment is specific in detailing the missing comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no comparison against existing text GANs, specifically mentioning the lack of testing with the pretrained version of SeqGAN. This claim is somewhat verifiable as it highlights a gap in the experimental setup, suggesting that the authors should include comparisons with other text GANs and test SeqGAN with a pretrained version. However, the comment lacks specific references to existing text GANs or detailed reasoning on why these comparisons are important, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against existing text GANs, particularly mentioning the lack of testing with the pretrained version of SeqGAN. This feedback is valuable as it highlights an important area for improvement, suggesting that the authors should include such comparisons to enhance the robustness and relevance of their work. However, the comment could be more helpful if it provided specific suggestions on which existing text GANs to consider or how to conduct the comparisons effectively. Despite this, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs attention. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the algorithm should be explored. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the algorithmic aspects but without concrete suggestions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not specify which part of the paper should have included this focus or where the algorithmic aspects are currently lacking. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is vague and lacks specificity, making it not grounded and not specific. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue. It does not offer suggestions on which algorithmic aspects should be explored or how to enhance the novelty of the paper. As a result, the feedback is somewhat helpful, as it points out a weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that Table 4 and 5 would be more readable if they were split into two tables each, with one table per measure. It provides a concrete example of how to implement this suggestion by recommending that the 8 SFII columns should be placed first, followed by the 8 SPDI columns. This level of detail provides clear guidance on how to improve the readability of the tables, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to split the tables into two, with one table per measure, and offers a concrete example of how to rearrange the columns. This level of detail guides the authors on what changes to make to improve the readability of the tables. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. The reviewer provides a specific suggestion for rearranging the columns, which is a logical and straightforward recommendation to improve readability. However, the comment does not include any references or detailed reasoning to support why this arrangement would be more effective. While the suggestion is clear, the lack of additional justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the benefits of the proposed change. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. It recommends splitting each table into two, with one table per measure, and offers a concrete example of how to rearrange the columns. This feedback is clear and provides a straightforward way for the authors to enhance the clarity and organization of their data presentation. By addressing a specific issue with the layout of the tables, the comment offers valuable guidance that can help the authors improve the overall readability and usability of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should specify what \"valid\" and \"orig\" differ in, providing a clear and direct action for the authors to take. The comment is specific and concrete, as it identifies a particular aspect of the figure that needs clarification. This makes the comment highly actionable, as the authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between \"valid\" and \"orig\" in the figure. This provides clear guidance on what the authors need to clarify in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the difference between \"valid\" and \"orig\" in Fig. 5. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, suggesting that the authors clarify what \"valid\" and \"orig\" differ in within Fig. 5. This feedback is clear and provides a direct way for the authors to improve their draft by specifying the differences in the figure. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or rationale for why this clarification is important. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with further explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors could improve their paper by making the comparisons between the present work and the related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method to provide a more comprehensive evaluation. While the comment implies an action, it does not provide explicit instructions on how to implement this suggestion, such as which specific aspects of the comparison should be focused on or how to conduct the systematic evaluation. The action is concrete in terms of the goal but lacks detailed guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the related work of Zemel et al. (2013) and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons more systematic with respect to the tuning of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method. It references the work of Zemel et al. (2013) as a related work and suggests that the present paper should compare the best performance of each method. However, the comment lacks specific examples or detailed reasoning on how the current comparisons could be improved or what aspects of the tuning need to be considered. This makes the claim somewhat verifiable, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need to make comparisons between the present work and the related work of Zemel et al. (2013) more systematic. It suggests that the authors should focus on comparing the best performance of each method, which would provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that could be strengthened. However, the comment could be more helpful if it provided additional guidance on how to conduct these systematic comparisons or what specific aspects of the tuning should be considered. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not explicitly instruct them to do so or provide specific guidance on how to adapt these methods to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and how to adapt the methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, rather than comparing to loss-based sampling. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a particular comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised set-up, but suggests that some of them could be adapted to language tasks relatively easily. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that these methods could be adapted. This makes the claim somewhat verifiable, as the authors would need to explore the feasibility of such adaptations themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to loss-based sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is somewhat helpful as it provides a specific suggestion for improvement, offering a potential direction for the authors to enhance their work. However, the comment could be more helpful if it included examples of specific methods or detailed guidance on how to adapt them to language tasks. Overall, the comment is somewhat helpful, as it offers a clear direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the estimation of the time complexity to prove scalability properties. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a logical claim that is based on a common understanding of scalability analysis in algorithms. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the claim is mostly verifiable, as it requires additional evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by explicitly estimating the time complexity of the learning algorithm. This is important for proving the scalability properties of the algorithm, which is a critical aspect of its evaluation. By addressing this feedback, the authors can enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific guidance on how to estimate the time complexity or examples of similar approaches. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider connecting the third point of definition one to the properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not provide explicit instructions on how to make this connection or what specific aspects of the universal kernels should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition one\" and \"chapter 4 of Steinwart and Christmann,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a connection to the properties of universal kernels and provides a reference to a specific chapter in the literature. This level of detail guides the authors on what aspect of their work needs further exploration and provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a connection between the third point of definition one and the properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides a specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how this connection might be made, which would align with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests a potential connection between the third point of definition one and the properties of universal kernels, as discussed in chapter 4 of Steinwart and Christmann. This feedback is somewhat helpful as it points out a possible area for further exploration or enhancement in the paper. However, the comment lacks specific guidance on how to make this connection or what aspects of the universal kernels should be considered. While it provides a direction for the authors to consider, it does not offer detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions on how to improve the explanation or what specific aspects need clarification. Without guidance on how to enhance the clarity or what additional information should be included, the authors are left without a clear understanding of what changes are needed. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the terseness and lack of clarity in the discussion around equation (10). Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is somewhat helpful as it points out a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how to enhance the clarity of the discussion. Without actionable advice, the authors may struggle to determine exactly what changes are needed to improve the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
