{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the quality of the dataset, specifically mentioning that the \"pristine\" set of tweets might contain misinformation and outofcontext images. The reviewer suggests that more analysis should be conducted on the dataset\"s quality and potential noise. While the comment implies that the authors should conduct additional analysis, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the dataset\"s quality but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the quality of the dataset, specifically mentioning that the \"pristine\" set of tweets might contain misinformation and outofcontext images. However, it does not specify which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing the concern about the dataset\"s quality and suggesting additional analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. The reviewer suggests that more analysis is needed to assess the dataset\"s quality and potential noise. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the dataset\"s quality. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. This is an important point that the authors should address to ensure the reliability and validity of their analysis. The comment provides a clear suggestion for additional analysis on the dataset\"s quality and potential noise, which is actionable and constructive. However, it could be more helpful if it offered specific methods or approaches for conducting this analysis. Overall, the comment is 4 as it identifies a critical area for improvement and provides a direction for further exploration, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what aspects of the theory should be investigated or how to demonstrate convergence properties. Without specific instructions or examples, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. However, it does not specify which part of the paper this critique pertains to, such as a particular section or chapter where the theory should be discussed. Without explicit references to specific sections, the authors may find it challenging to pinpoint the exact areas needing improvement. The comment is specific in its critique of the lack of theoretical exploration but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. This is a critical area that could enhance the understanding and applicability of the algorithm. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular theoretical analyses or experiments to conduct. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically questioning why the \"and\" operator or elementwise max were not considered. While the comment implies that the authors should provide a rationale for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain their reasoning. However, the comment does provide a clear direction for improvement by suggesting that the authors should address the rationale for their operator choices. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or elementwise max, which correspond to the ideas of union and intersection from the \"or\" operator and elementwise min. The comment clearly specifies what needs to be addressed, namely, the rationale for choosing specific operators over others. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. The reviewer provides a logical reasoning by suggesting that these operators correspond to the ideas of union and intersection, respectively, which are related to the \"or\" operator and elementwise min. However, the comment lacks specific examples or references to support the claim that these operators are better options. While the reasoning is sound, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically questioning why the \"and\" operator or elementwise max were not considered. It suggests that these operators might correspond to the ideas of union and intersection, respectively, and that the current choices are not clear. This feedback is 3 as it prompts the authors to reconsider their operator choices and provide a rationale for their selection. However, the comment could be more helpful if it offered specific suggestions or examples of how the \"and\" operator or elementwise max might be beneficial. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it implies that the authors should provide an explanation or justification for this selection, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and its potential impact on performance estimation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation of what it includes. This implies that the authors should provide a supporting explanation for the average duration reported in the table. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the average duration. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and asks for an explanation of what it includes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation of what it includes. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment questions the purpose of the average duration reported in Table 1 and asks for an explanation of what it includes. This is a clear and specific request for clarification, which can help the authors improve the clarity and comprehensiveness of their paper. By addressing this point, the authors can provide a more detailed explanation of the data presented, enhancing the reader\"s understanding of the results. However, the comment could be more helpful if it suggested how the authors might present this information or why it is important. Overall, the feedback is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" The reviewer suggests that this wording should be corrected, implying that the authors should be more specific in their claims. However, the comment does not provide explicit guidance on how to correct this wording or what specific changes should be made. While the action is implicit, it is somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias among NLP researchers and suggests that the wording \"on par or better\" should be corrected. The comment provides a clear direction for improvement by specifying what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" The reviewer suggests that this wording should be corrected. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains somewhat vague and 1. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" This observation is relevant and could be a source of confusion for readers. The reviewer suggests that the wording should be corrected to avoid this bias, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the results to avoid this bias. Overall, the comment is 4 as it directs the authors to a potential issue and offers a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals (CIs) between Baseline and NVSB for Chinese and English MOSV. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these questions or improve their interpretation of the results. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the interpretation of the results, particularly regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOSV. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions about the interpretation of results in Table 3, without expressing any subjective opinions, judgments, or suggestions. It does not contain claims that require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the interpretation of results presented in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOSV. While it identifies areas of potential confusion or ambiguity, it does not provide any suggestions or guidance on how the authors might clarify or address these issues. The comment is 3 as it points out areas that need further explanation, but it lacks actionable feedback or detailed advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point points out a specific issue with the formatting of Table 2 and Table 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is explicit and provides a clear action for the authors to take, which is to ensure consistency in the formatting of these tables. However, the comment does not specify how the authors should address this issue or provide guidance on how to achieve consistency. While the action is explicit, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent spacing between accuracy and standard deviation, which affects the beauty of the tables. This provides clear guidance on what needs to be addressed to improve the presentation of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the formatting of tables, specifically noting inconsistencies in the spacing between accuracy and standard deviation. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is relevant and could affect the visual appeal of the tables. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or why it is important to do so. Without actionable advice or context, the feedback is 3, as it highlights a potential area for improvement but lacks depth and specificity. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and that the related work section nicely summarizes this. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of novelty or improve their work. Without actionable suggestions or a clear direction for improvement, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the lack of novelty in the paper, specifically regarding adversarial attacks by perturbing text. It references the related work section, suggesting that the only new effort is to apply similar ideas to videotext models. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the lack of novelty, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically regarding adversarial attacks by perturbing text. It supports this claim by referencing related work that has already explored this concept on NLP models and imagetext models. The reviewer further notes that the only new effort is to apply similar ideas to videotext models. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the related work mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the paper for lacking novelty, specifically in the context of adversarial attacks by perturbing text. It acknowledges that this concept has been explored in related work, but suggests that the only new effort is to apply it to videotext models. While the comment identifies a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without specific feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 3, as it highlights a concern but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it had separate paragraphs dedicated to each of the lexical features and sentencelevel features. While the comment provides a clear action for the authors to take\u2014organizing the section into separate paragraphs\u2014it does not offer detailed guidance on how to implement this change or what specific content should be included in each paragraph. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations for features being intertwined and confusing, and it provides a suggestion for improvement by recommending separate paragraphs for lexical features and sentencelevel features. This level of detail helps the authors understand what needs to be addressed and how to improve the organization of the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs dedicated to lexical features and sentencelevel features. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors may need to invest additional effort to understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it were organized with separate paragraphs dedicated to each of the lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and structure of their paper. By following this advice, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it included specific examples or further guidance on how to separate the paragraphs effectively. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a lack of usefulness regarding the dedicated section and experimental results, suggesting that the space allocated is excessive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of space allocation or whether the information is necessary. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the allocation of space dedicated to a section and experimental results, suggesting that it is excessive. However, it does not specify which section or results are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. The comment lacks specificity regarding what aspects of the section or results are considered not useful or excessive. Without explicit references or detailed feedback, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the allocation of space in the paper, stating that dedicating a whole section and experimental results is excessive. However, it does not provide any specific reasoning or evidence to support this claim, such as comparing it to similar works or explaining why the space allocation is unnecessary. Without detailed justification or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses a subjective opinion about the allocation of space in the paper, suggesting that dedicating a whole section and experimental results is excessive. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the issue or whether the information is indeed unnecessary. Without actionable advice or constructive criticism, the comment does not help the authors improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to implement these suggestions, such as which models to include or how to structure the comparison. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"MST baseline,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in comparing the proposed models to those that only consider different senses but not sememes. The comment suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. Additionally, it recommends including more baselines based on related work to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between the proposed models and models that only consider different senses but not sememes is unclear. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment provides some reasoning by mentioning the MST baseline, it lacks specific examples or detailed comparisons to support the claim fully. The suggestion for more baselines is logical but not explicitly justified. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison of the proposed models with models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment provides a clear and actionable suggestion by recommending the inclusion of more baselines based on related work to strengthen the paper. This feedback is valuable as it directs the authors to a specific area for improvement and offers a concrete way to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided specific examples of models to include or detailed guidance on how to structure the comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding how the frame similarity factors and attributes similarity factors are selected. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit, as the authors can infer that they need to provide more detailed information on the selection process, but it lacks concrete steps or examples to guide them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue regarding the selection of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it might be related to the methodology or results sections, but without explicit references, the comment is weakly grounded. It is specific in detailing the issue of clarity regarding the selection process, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. This feedback is 3 as it points out a potential issue that the authors need to clarify in their paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as by explaining the selection process or providing examples. To be more helpful, the comment could include actionable steps or examples to assist the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. The comment also questions why objects are not mentioned in relation to \"latent in verbs.\" These actions are clear and concrete, giving the authors specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (681 and 778) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear instructions on what needs to be discussed or included, such as results for the task of inferring knowledge on objects and the use of consistent terminology for the model in Tables 1 and 2. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs.\" This level of detail and specificity helps the authors understand exactly what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and suggestions for improvement. It does not contain subjective opinions, judgments, or claims that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests discussing the results for the task of inferring knowledge on objects, which is a clear and direct request for additional content. Second, it points out the need to include results for model (B) and to use consistent terminology for the model in Tables 1 and 2. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs,\" prompting the authors to clarify this aspect. These suggestions are clear and provide the authors with concrete steps to enhance their draft. Therefore, the comment is 5, as it offers detailed guidance that can significantly improve the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the wording in line 212, suggesting that the sentence is not strictly correct and provides a correction. It also references Figure 2 to support the suggested change. This feedback is explicit and provides concrete guidance on how to improve the draft by correcting the wording and aligning it with the visual representation in Figure 2. The authors know exactly what needs to be changed and where to make the correction, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence in line 212 and provides a correction, suggesting that the correct way to describe the process would be to use a bidirectional encoder. This level of detail helps the authors understand what needs to be revised, making the comment 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a correction. The reviewer provides a specific alternative phrasing (\"bidirectional encoder that encodes the source sentence into a set of vectors\") and references Figure 2 to support the claim. This level of detail and reference to a specific figure provides a clear and logical basis for the claim, making it 5. The authors can easily understand the reasoning behind the suggestion and how it aligns with the visual representation in Figure 2. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the paper, pointing out that the sentence in line 212 is not strictly correct. It provides a clear and actionable suggestion for improvement by recommending that the authors use a bidirectional encoder to encode the source sentence into a set of vectors, rather than a single vector. This feedback is valuable as it directly addresses a potential misunderstanding in the paper and offers a concrete correction that can enhance the clarity and accuracy of the draft. However, the comment could be more helpful if it explained why the current wording is incorrect or how the suggested change would improve the paper. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the adopted baseline models. First, it notes that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks. Second, it points out that the authors do not compare their work with other domain adaptation methods, as mentioned in Section 8. The comment also corrects a grammatical error. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how the authors should address these issues or conduct the comparisons. The actions are implicit and somewhat vague, as the authors need to infer that they should include comparisons with Campos et al. (2020) and other domain adaptation methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the baseline models and references specific sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the baseline models, such as the lack of comparison with Campos et al. (2020) and other domain adaptation methods. Additionally, it points out a grammatical error. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak, providing two reasons for this assertion. First, it notes that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks. Second, it points out that the authors do not compare their work with other domain adaptation methods, as mentioned in Section 8. These claims are supported by specific references to external works, which provides a clear basis for the reviewer\"s assertion. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would improve the paper. Overall, the claim is 4, as it provides a solid foundation but lacks some depth in the explanation.", "helpfulness_rationale": "The review comment identifies two specific issues with the adopted baseline models. First, it points out that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks, suggesting that this comparison is necessary. Second, it notes that the authors do not compare their work with other domain adaptation methods, as mentioned in Section 8. This feedback is clear and actionable, as it highlights areas where the authors can strengthen their work by including additional comparisons. Additionally, the comment corrects a grammatical error, which is a minor but important detail. Overall, the comment provides valuable insights and suggestions for improvement, making it 4 for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment mentions \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig,\" which appears to be a separate comment unrelated to the main issue. As a result, the authors are left without clear direction on how to improve their draft regarding the societal bias issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not specify which part of the paper this concern pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment does not provide specific guidance on how to address this issue or what aspects of the paper should be revised. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. This is an important consideration, especially in the context of AI and natural language processing, where biases can significantly impact the accuracy and fairness of the models. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what steps they could take to ensure their knowledge bases are biasfree. Additionally, the mention of \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig\" appears to be a separate comment unrelated to the main concern. As a result, the comment is 3 as it identifies an important area for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to justify why MCNC does not include many strong baselines that are not compared, such as those mentioned in [1]. This request is clear and direct, providing a specific action for the authors to take. The comment also specifies the baseline in [1] that should be considered, offering concrete guidance on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of strong baselines in MCNC and requests a justification for this omission, specifically mentioning the baselines in [1]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of strong baselines in Table 3, specifically mentioning the baselines in [1]. This is a request for clarification or justification, not a claim. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting the absence of strong baselines that are not compared, such as those mentioned in [1]. It raises a valid question about the justification for this omission, which is a critical point for the authors to address. By pointing out this gap, the comment provides a clear and actionable suggestion for improvement, encouraging the authors to justify their choices or consider including additional baselines. This feedback is 4 as it directs the authors to a specific area that could enhance the comprehensiveness and rigor of their analysis. However, it could be more helpful if it offered specific suggestions on which baselines to consider or how to integrate them into the analysis. Overall, the comment is valuable for guiding the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the independence of the paper. The action is implicit, as the authors can infer that they need to make the paper more selfcontained, but the comment lacks concrete details on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"S3.1\" and \"Sup. Fig. 6,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the paper relies on supplemental space and is not truly independent, particularly in the context of references to supplemental figures and model comparisons. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain its content, making it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not truly independent. While it highlights certain sections that rely on supplemental material, it does not provide a comprehensive analysis or evidence to substantiate the claim. This makes the comment 3, as it points out potential issues but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. This feedback is valuable as it highlights a potential weakness in the paper\"s independence and selfcontainedness. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to integrate the supplemental material more effectively into the main text. Despite this, the comment is 4 as it directs the authors\" attention to a critical area that needs improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task. It provides a rationale for both sides of the argument, suggesting that generic summarization systems build similar knowledge graphs and that the concept map becomes harder to distinguish with increasing node numbers. However, the comment does not explicitly instruct the authors to make a decision or take any specific action. The authors are left to infer that they might need to reconsider their approach to concept map extraction, but without concrete guidance on how to address this issue, the comment remains 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it might be related to the methodology or results sections, but without explicit references, it remains unclear. The comment is specific in its reasoning but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand the basis of the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. While the comment identifies a potential issue and provides some reasoning, it lacks specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it prompts the authors to reconsider their approach, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more information about the traits of the experts and to justify why annotation must be carried out by the experts, rather than focusing solely on commercial values. It also asks specific questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges. These questions provide clear guidance on what additional information should be included in the paper. The action is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is a more detailed description of the traits of the experts and a justification for why annotation must be carried out by them, rather than focusing solely on commercial values. The comment also asks specific questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the need for more information regarding the traits of the experts and the justification for using their expertise for annotation. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples that would help the authors understand the basis of the suggestion. As a result, the claim is 1, as it does not offer sufficient evidence or reasoning to support the need for additional information. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more information about the traits of the experts involved in the annotation process. It also questions the necessity of using experts for annotation, asking whether they were linguistic experts or domain experts, and whether the annotation differed from what nonexperts would do. These questions prompt the authors to clarify the expertise and rationale behind the annotation process, which could enhance the transparency and credibility of their work. While the comment is clear in its suggestions, it could be more helpful if it provided additional context or examples to guide the authors further. Overall, the feedback is 4 as it directs the authors to address a critical aspect of their methodology, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the text in lines 102106, stating that it is misleading. It points out that while the terms \"intersection\" and \"probs\" are true, the phrase \"such distribution\" cannot refer to the discussion in the above. However, the comment does not provide any guidance on how to address this issue or suggest alternative wording. The action is implicit and vague, as the authors are left to infer that they need to clarify or rephrase the text but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, namely that the phrase \"such distribution\" is misleading and cannot refer to the discussion in the above. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion in the above. However, the comment does not provide any further explanation or reasoning to support this claim, such as what specific aspect of the discussion is being referred to or why the phrase is misleading. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text in lines 102106, pointing out that the phrase \"such distribution\" is misleading because it cannot refer to the discussion in the above. This feedback is clear and actionable, as it directs the authors to clarify or rephrase the text to ensure it accurately reflects the intended meaning. However, the comment could be more helpful if it provided suggestions on how to rephrase the text or offered additional context to better understand the issue. Overall, the comment is 4 as it highlights a potential misunderstanding in the text and guides the authors toward improving clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include examples of their system applied to actual texts rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the type of examples or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, rather than focusing on other components or models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of examples, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be valuable or necessary. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion or how it could enhance their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should include examples of their system applied to actual texts, rather than focusing solely on other components or models. This feedback is 3 as it provides a specific direction for enhancing the paper by demonstrating the system\"s practical application. However, the comment lacks depth and does not offer detailed guidance on how to present these examples or what specific aspects of the system should be highlighted. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It explicitly asks whether the CS is used to augment the training material and requests information about the data split. While the comment does not provide explicit instructions, it does imply that the authors should clarify these aspects. The action is implicit but concrete, as it directs the authors to provide specific information about the use of the CS. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) in the evaluation and training process, specifically asking if it is used to augment the training material and requesting information about the data split. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questions about the use of the CS and the data split, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or important. Without additional context or explanation, the authors may find it challenging to understand the significance of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. This feedback is valuable as it prompts the authors to provide more detailed information about their methodology, which can help readers better understand the study. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided guidance on how to present this information in the paper. Overall, the comment is 3 as it identifies a gap in the paper and encourages the authors to clarify their approach, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures in the discussion of section 5.2, which is a direct and concrete action. The authors know exactly what they need to do to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, stating that it is too abstract and lacks examples of spurious structures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is too abstract and lacks examples of spurious structures. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed examples or references to what is considered abstract or lacking, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks examples of spurious structures. This feedback is clear and actionable, as it directs the authors to provide concrete examples to support their claims about the superiority of the new model over MH. By addressing this feedback, the authors can enhance the clarity and persuasiveness of their discussion, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit action that provides a clear direction for improvement. The comment is concrete because it specifies exactly what information should be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is the maximum number of tasks done by any annotator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include the maximum number of tasks done by any annotator. While this is a specific and actionable piece of feedback, it does not provide any context or rationale for why this information is important or how it would enhance the paper. The comment lacks depth and does not offer any additional insights or suggestions for improvement. Therefore, it is 3, as it provides a clear direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments tell us about the underlying research question and the specific hypothesis tested. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the connections between the different pieces of the puzzle, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments tell us about the underlying research question and the specific hypothesis tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or which sections need clarification. Without explicit references to specific sections, tables, or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity in detailing what aspects of the results or analyses are unclear or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the difficulty in understanding the empirical results and analyses presented in the paper. It questions what the experiments tell us about the underlying research question and the specific hypothesis tested. However, the comment does not provide specific examples or detailed reasoning to support why the author finds it challenging to understand the results. Without additional context or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite the numerous empirical results and analyses presented, it is difficult to understand the overall picture of what the experiments tell us about the underlying research question and specific hypothesis tested. This feedback highlights a critical weakness in the paper\"s presentation and suggests that the authors need to clarify the connections between the different pieces of the puzzle. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending a particular structure or format for presenting the results. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a key area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of numerical results and expresses curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to consider or how to conduct the comparisons. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include these comparisons. The comment is 1 as it does not identify a specific section or part of the paper, and it is also not specific because it lacks detailed guidance on what numerical results or comparisons are needed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses curiosity about the lack of numerical results and suggests that the authors should provide comparisons with existing DP algorithms. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and expressing curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\"s contribution and relevance. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as which algorithms to consider or how to conduct the comparisons. While it points out a critical area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection is not drawn well and recommends either cementing the connection more formally or adjusting the language to clarify. While the comment implies that the authors should take action to improve the clarity of the probabilistic connection, it does not provide specific guidance on how to achieve this. The action is explicit but somewhat vague, as it lacks concrete details on how to formalize or adjust the language. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the probabilistic connection in the paper, suggesting that it is not drawn well and is not formally established. However, it does not specify which part of the paper discusses this probabilistic connection, making it weakly grounded. The comment is specific in suggesting that the authors either formalize the connection or adjust the language to clarify it. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not drawn well and suggests that it is not formally established. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or evidence to substantiate the assertion that the connection is not welldefined or motivational. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the probabilistic connection, suggesting that it is not drawn well and lacks formalization. It provides a clear and actionable suggestion for the authors to either cement the connection more formally or adjust the language to clarify it. This feedback is specific and offers a constructive path for the authors to improve their draft, making it 4. However, it could be more helpful if it included examples or further guidance on how to formalize the connection or adjust the language. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This is an explicit request for additional data or analysis to substantiate the claim made in the paper. However, the comment does not specify how the authors should conduct this empirical evaluation or what specific metrics or tests should be used. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific evidence or analysis is needed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of evidence or analysis would be most beneficial. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the algorithm is better suited for this problem. Without such evidence or justification, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This is a clear and actionable suggestion that could help the authors strengthen their paper by demonstrating the effectiveness of their algorithm in a specific context. However, the comment could be more helpful if it provided guidance on how to conduct this empirical evaluation or what specific metrics or tests to use. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the robustness of their scheme. The action is implicit and vague, as the authors are left to infer that they need to explore ways to enhance the robustness of their scheme, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. However, it does not specify which part of the paper discusses this scheme or where the issue of scaling is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the scaling issue, but it lacks grounding as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those in highdimensional domains. The reviewer suggests that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. While the comment identifies a potential limitation of the approach, it lacks specific suggestions or guidance on how the authors might address this issue or improve the robustness of their scheme. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions what kind of style shifts might occur within this timeframe and suggests that without these answers, it is difficult to appreciate what the model is capturing. While the comment implies that the authors should provide more information on the datasets and the time period, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. However, it does not specify which part of the paper discusses these datasets or the time period, making it weakly grounded. The comment is specific in questioning the adequacy of the time period and the nature of style shifts that might occur, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of the time period (4 years) to study style shifts and asks for clarification on the kind of style shifts that might occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support the claim that 4 years is insufficient. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions whether this timeframe is adequate to capture the desired style shifts and suggests that without addressing this issue, it is challenging to appreciate what the model is capturing. This feedback is 3 as it identifies a potential weakness in the study and prompts the authors to provide more context and justification regarding the datasets and time period. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of alternative datasets or timeframes that might be more appropriate. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights concerns about the experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments and provides a suggestion for improvement, it does not explicitly instruct the authors to make these comparisons or explain how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide an explanation for their choice of selfcomparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the lack of comparisons with other methods like SketchRNN, and the need for an explanation for the choice of selfcomparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper has a \"biggest concern\" with its experiments, specifically noting that it only reports selfcomparisons and lacks an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue with the experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include comparisons with SketchRNN is a logical one, but the comment does not provide a clear rationale or evidence for why this is necessary. Therefore, the claim is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper, specifically the lack of comparisons with other methods, such as SketchRNN, in the experiments. It highlights the issue of only reporting selfcomparisons and the need for an explanation for this choice. This feedback is clear and actionable, as it points out a specific area for improvement and suggests a potential direction for enhancing the paper by including comparisons with relevant methods. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of the results being nonobvious or how to make them more accessible to a broader audience. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, noting that they are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not specify which results or techniques are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment lacks specificity regarding what aspects of the results are unclear or how they could be improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples of these \"standard\" techniques or explain why they are not obvious to a broader audience. This lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The comment points out that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. This observation highlights a potential limitation in the accessibility of the results, suggesting that they may not be immediately understandable to a broader audience. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as by explaining the techniques in more detail or providing additional context. While it identifies a potential area for improvement, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide explicit guidance on how to implement this distinction or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to differentiate between these types of updates, but they are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This is a specific and actionable piece of feedback that could help the authors clarify their work and improve the clarity of their paper. By differentiating between these types of updates, the authors can provide a more nuanced understanding of their methodology and its implications. However, the comment could be more helpful if it provided examples or further explanation of how this distinction might impact the paper. Overall, the feedback is 4 as it directs the authors to a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the data usage or analysis. The action is implicit and vague, as the authors are left to infer that they should reconsider their data usage or analysis, but without concrete steps or suggestions, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not specify which part of the paper discusses these models or their performance, making it weakly grounded. The comment is specific in detailing the issue with the data usage and the implications for the conclusion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. The comment highlights a discrepancy in the amount of data used for training, suggesting that this may impact the conclusion. However, the comment lacks specific examples or references to support the claim that the difference in performance is insignificant. Without detailed evidence or comparisons, the claim remains 3, as it provides a logical reasoning but lacks concrete data or references to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. It highlights a discrepancy in the amount of data used for training, which could impact the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two main issues: the lack of motivation for GaRare compared to GaLore and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment provides explicit actions for the authors to take, such as providing evidence or justification for GaRare\"s advantages and clarifying the algorithmic presentation. However, it does not specify how to provide this evidence or clarification, leaving some room for interpretation. Overall, the comment is 4 as it clearly identifies the areas needing improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and does not provide evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of motivation for GaRare, suggesting that the paper does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is clear and actionable, as it directs the authors to enhance their explanation of GaRare\"s benefits. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it provides a specific area for improvement that would enhance the paper\"s clarity. Overall, the comment is 4 as it offers clear and actionable feedback that can guide the authors in improving their draft. However, it could be more comprehensive by suggesting how to address these issues or providing examples of what a detailed algorithmic presentation might entail. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This provides a clear and direct action for the authors to take, which is to include these references in their work. The comment is explicit and provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the link to these similar works that have a similar structure to the CRF and can perform exact inference. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This claim is 3 as it references specific works that could be relevant to the paper. However, the comment does not provide detailed reasoning or examples of how these works are similar or how they could enhance the paper, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks context by pointing out the absence of a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF). These works have a similar structure to the CRF and can perform exact inference, which could be relevant to the paper. By highlighting this gap, the comment provides a clear and actionable suggestion for the authors to enhance the paper by including these references. However, the comment could be more helpful if it explained why these references are important or how they could contribute to the paper\"s context. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide an explanation for why WPA works, specifically asking what the model is predicting with np.ones input and whether any input would serve as a white paper. It also questions why Gaussian noise input does not work as well as WPA and why the authors spend time showing WPA improves test performance without providing insights into how it works. The comment implies that the authors should address these questions to enhance the paper\"s contribution and potential for future research. While the actions are implicit, they are concrete in nature, as the authors know exactly what needs to be addressed to improve the draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and suggestions for improvement, such as explaining why WPA works, what the model is predicting with np.ones input, and why Gaussian noise input does not work as well as WPA. The comment also highlights the importance of providing insights into how WPA works, which can spark future research directions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions, such as asking for an explanation of why WPA works and why Gaussian noise input does not work as well as WPA. It also notes that the authors spend time showing WPA improves test performance without providing insights into how it works. While the comment identifies areas for improvement, it lacks specific evidence, reasoning, or references to support the claims or suggestions. The authors are left to infer the basis of the critique, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a series of questions and suggestions that could significantly enhance the paper. It challenges the authors to explain why WPA works, particularly with np.ones input and whether any input could serve as a white paper. It also questions the effectiveness of Gaussian noise input compared to WPA, which is an important point given the authors\" focus on improving test performance. The comment highlights the need for more insight into how WPA works, which could spark future research directions. While the feedback is clear and actionable, it could be more helpful if it offered specific suggestions on how to address these questions or provided examples of similar approaches in the literature. Overall, the comment is 4 as it guides the authors toward improving the depth and clarity of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It explicitly asks the author to provide more clarification on this issue. This request is clear and direct, giving the authors a specific action to take to address the reviewer\"s concern. The feedback is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is observed in, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the similarity or how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a concern that the authors should clarify this similarity to avoid confusion or potential overlap with existing work. While the comment highlights an important area for clarification, it does not provide specific guidance on how the authors might address this issue or what aspects of the method need further explanation. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with a general direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the experimental section (Section 3) does not mention or discuss how important parameters, such as the minimum cluster size and conductance threshold, are set and how sensitive the performance is to these parameters. This feedback implies that the authors should include a discussion on these parameters in the experimental section, providing explicit guidance on what needs to be addressed. However, the comment does not specify how the authors should present this information or what specific details should be included. While the action is explicit, it lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the absence of discussion on important parameters, such as the minimum cluster size and conductance threshold, in the experimental section. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section (Section 3) does not mention or discuss how important parameters, such as the minimum cluster size and conductance threshold, are set and how sensitive the performance is to these parameters. This is a valid claim as it highlights a gap in the paper that could impact the interpretation of results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these parameters based on the context provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that important parameters, such as the minimum cluster size and conductance threshold, are not discussed in the experimental section. This feedback is valuable as it highlights a critical area that needs clarification and further exploration. By suggesting that the authors should discuss how these parameters are set and how sensitive the performance is to them, the comment provides actionable guidance for improving the draft. However, it could be more helpful if it offered specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their approach. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not specify which part of the paper this concern relates to, such as a specific section or experiment, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, while it identifies a potential issue, it lacks specificity in terms of what specific aspects of the reinforcement learning approach or data efficiency need to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. While the comment identifies a potential issue, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear understanding of how to improve their approach or mitigate the potential weakness. Therefore, the comment is 2, as it highlights a potential issue but does not offer sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly advises the authors to take a cautious approach regarding their contribution until the promised dataset is made publicly available. This is a clear and direct action for the authors to take, as it specifies the need to wait for the dataset to be accessible before making any claims or contributions based on it. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the promised dataset not being publicly available, which is a specific concern regarding the contribution of the paper. However, it does not specify which part of the paper discusses the dataset or where the promise was made, making it weakly grounded. The comment is specific in its request for caution until the dataset is openly accessible, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not been made publicly available, which is a factual statement. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a critical issue regarding the promised dataset not being publicly available, which is a significant concern for the contribution of the paper. By pointing out this gap, the comment provides the authors with a clear and actionable area for improvement. It advises the authors to take a cautious approach until the dataset is openly accessible, which is a logical and necessary step to ensure the validity and reproducibility of the research. However, the comment could be more helpful if it suggested ways to address this issue, such as providing a timeline for dataset release or offering alternative approaches to validate the findings. Overall, the comment is 4 as it identifies a critical problem and guides the authors toward a solution, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The comment implies that the authors should conduct comparisons with existing detection methods, but this is not directly stated. The action is implicit and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, questioning the validity of this claim. It suggests that the performance is primarily due to the first step and implies that comparisons with existing detection methods are necessary. However, the comment does not specify which part of the paper discusses these claims or where the authors should conduct comparisons. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections needing revision. While the comment is specific in its critique, it is 1, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. The reviewer provides a logical reasoning by questioning the validity of the claim and suggesting that comparisons with existing detection methods are necessary. However, the comment lacks specific examples or references to support the claim that the performance is primarily due to the first step. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to validate the claim. While the comment identifies a potential weakness in the paper\"s claims, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. It explicitly asks the authors to provide an explanation for this observation. While the comment does not explicitly instruct the authors to conduct further analysis or make changes, it does imply that the authors should investigate and provide an explanation. The action is clear but not directly stated, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the application of Conditional Batch Norm (CBN) to layer 2, compared to when CBN is applied to layers 4 and 3 only. The comment asks for an explanation of why this might be happening, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. The reviewer asks for an explanation of why this might be happening. While the comment does not provide specific evidence or references to support the claim, it does present a logical question that prompts the authors to investigate and provide an explanation. This makes the comment 3, as it requires the authors to address the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) in Table 2, noting that applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. This observation is relevant and could help the authors understand the impact of their experimental setup. The comment is 3 as it points out a potential issue but does not provide specific suggestions or guidance on how to address it. To be more helpful, the comment could include recommendations for further analysis or experimentation to understand the cause of this performance deterioration. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a specific issue with the \"implicit call to the Witness oracle,\" describing it as confusing. However, it does not provide any guidance or suggestions on how to clarify this aspect or what changes should be made to improve the clarity. The comment lacks explicit instructions or concrete details on how to address the confusion, leaving the authors without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location of the problem. Additionally, the comment lacks specificity regarding what aspect of the call is confusing or how it could be clarified. Without explicit references or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this call is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any further explanation, reasoning, or suggestions on how to clarify this aspect or what changes could be made to improve the clarity. Without additional guidance or context, the authors are left without actionable feedback to address the issue effectively. Therefore, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, questioning why it cannot condition headpose parameters similar to a previous work. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The suggestion to condition headpose parameters is implicit, and the authors would need to infer that they should explore this possibility. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s inability to handle headpose, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method cannot condition headpose parameters similar to a previous work, providing a specific example (Gafni et al. ICCV 2021). This level of detail and reference to a specific work helps the authors understand what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the proposed method\"s inability to handle headpose, questioning why it cannot condition headpose parameters similar to a previous work. The reviewer provides a specific reference to a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the previous work achieves this control. Overall, the claim is 4, as it provides a solid basis for the critique but lacks comprehensive evidence or detailed explanation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose. It questions why the method cannot condition headpose parameters similar to a previous work, providing a specific reference to Gafni et al. ICCV 2021. This feedback is clear and actionable, as it prompts the authors to consider how their method could be extended to address this limitation. By pointing out a gap in the current work and suggesting a potential solution, the comment provides valuable guidance for improving the draft. However, it could be more helpful if it offered additional suggestions or examples on how to implement this extension. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) [1] to illustrate this point. The comment also mentions the wellknown impact of rare spurious examples on trained models. While the comment provides a clear comparison and references external work, it does not explicitly instruct the authors to make any changes or improvements to their draft. The action is implicit and somewhat vague, as the authors can infer that they should consider the implications of these similarities but are not given specific guidance on how to address them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features discussed in the paper and backdoor triggers, providing examples from external works (Chen et al., 2017, and Gu et al., 2019) to illustrate the point. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers, citing examples from Chen et al. (2017) and Gu et al. (2019) [1]. It also mentions the wellknown impact of rare spurious examples on trained models. The comment provides specific references to external works, which helps substantiate the claim. However, it could be more 5 if it included detailed explanations or examples from the paper being reviewed, rather than relying solely on external references. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks some depth in its explanation. This aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) [1] to illustrate this point. The comment also highlights the wellknown impact of rare spurious examples on trained models. While the comment provides valuable insights and references, it does not offer specific suggestions or guidance on how the authors might address this issue in their paper. The feedback is 3 as it points out a potential area of concern, but it lacks actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a key component of the paper and has been emphasized multiple times. However, it notes that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. While the comment highlights a potential issue with the originality of the work, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the source of the optimization algorithm and its contribution to the paper. Additionally, the comment lacks concrete suggestions on how to improve the clarity or originality of the work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"structural optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the structural optimization is a key component of the paper but that the optimization algorithm is directly taken from previous works. The reviewer finds this confusing and suggests it reduces the contribution of the paper. However, the comment lacks specific examples or references to the previous works, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed justification or evidence makes the claim 3, as it provides a general observation but requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the paper, specifically regarding the structural optimization algorithm. It points out that the algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. This feedback is 3 as it highlights a specific area where the authors might need to clarify the novelty and originality of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a more detailed explanation of the algorithm\"s adaptation or highlighting its unique contributions. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This provides a clear and direct action for the authors to take, ensuring that their discussion of related work is comprehensive. The comment also specifies the type of work to include, making it 5. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: mentioning related work on modular networks for VQA. This provides clear guidance on how to improve the introduction, ensuring that it accurately reflects the current state of the field. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not accurately represent the current state of the field regarding modular architectures for VQA, as it does not mention related work on modular networks. The reviewer suggests that this omission creates a misleading impression. However, the comment does not provide specific examples of relevant work or detailed reasoning to support the claim. Without such evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of related work on modular networks for VQA. This feedback is valuable as it highlights a potential gap in the introduction, which could lead to a more comprehensive and accurate representation of the current state of the field. By mentioning specific work, the comment offers a concrete step for the authors to take, ensuring that their draft is more thorough and uptodate. However, the comment could be more helpful if it provided additional context or examples of how this related work might be integrated into the discussion. Overall, the comment is 4, as it directs the authors toward a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment highlights an area for improvement, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include in the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should include a more comprehensive comparison with these methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific area of focus in the paper, namely the authors\" emphasis on SSC and their lack of comparison with other subsequent methods like TSC and greedy subspace clustering by Park. However, it does not specify which part of the paper this observation is based on, such as a particular section or analysis. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in pointing out the need for a more comprehensive comparison, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The comment provides a logical reasoning by pointing out the lack of comparison with other methods, which is a common practice in scientific literature. However, it does not provide specific examples or references to these subsequent methods, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. This feedback is valuable as it highlights a gap in the paper\"s comparison and suggests that the authors should include a more comprehensive evaluation of their method against these other approaches. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is 3 as it directs the authors\" attention to an important area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how to address this problem or what specific changes should be made to improve the clarity or completeness of the tables. The action is implicit and somewhat vague, as the authors can infer that they need to ensure the tables are comprehensive, but they are not given concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the performance without reinforcement learning and without dependency tree, and it notes that the tables do not include cases where both dependency tree and reinforcement learning are not used. This provides clear guidance on what needs to be addressed in the tables. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. This is a factual observation about the content of the tables, which requires no verification or justification. The comment does not contain subjective opinions, suggestions, or claims that need to be supported, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. This feedback is clear and actionable, as it highlights a potential oversight in the experimental setup and suggests that the authors should ensure the tables are comprehensive. By addressing these points, the authors can improve the clarity and completeness of their results, which is valuable for readers and reviewers. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered additional context on why this oversight is important. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific weakness in the paper, namely the limited scope of the experiments, which are only conducted on the CIFAR10 dataset. It suggests that the authors should consider other datasets from the Federated learning benchmarks, such as LEAF, and refer to relevant works like FedProx and FedMAX for details on different datasets and model types. The comment provides explicit guidance on what the authors should do to improve their experimental evaluation, making it 5. The suggestion to consider additional datasets and refer to relevant works gives the authors clear steps to take, ensuring that they know exactly how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section\" and the specific issue of the limited scope of the experiments, which are only conducted on the CIFAR10 dataset. It also specifies the need to consider other datasets from Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments section is a weakness due to the limited scope of the experiments, which are only conducted on the CIFAR10 dataset. The reviewer suggests that the authors should consider other datasets from Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for details on different datasets and model types. This provides a clear rationale and specific references to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional datasets or works would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the limited scope of the experiments, which are only conducted on the CIFAR10 dataset. It suggests that the authors should consider other datasets from Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is clear and actionable, providing the authors with a specific direction to expand their experimental evaluation. By addressing this issue, the authors can significantly enhance the comprehensiveness and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, as stated in the table. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to use an alternative dataset is specific, as it provides a concrete example of what could be done to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a logical suggestion to verify the claim, as it proposes a method to test the robustness of the results. However, the comment lacks specific reasoning or evidence to support why the current dataset may not be sufficient or why the alternative datasets are more appropriate. While the suggestion is reasonable, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This feedback is 3 as it points out a potential weakness in the current dataset choice and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why the current dataset might not be suitable or how using an alternative dataset would enhance the study. Overall, the comment provides a direction for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple CVEs or CWEs simultaneously and questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment also notes that the results are difficult to interpret or are marginal improvements at best. While the comment implies that the authors should clarify their methodology and its implications, it does not provide explicit guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their methodology and its relevance to previous work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It references previous work that considers multiple CVEs or CWEs simultaneously and questions the authors\" approach. However, the comment does not explicitly mention which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in detailing the issue with the methodology and suggesting that the results are difficult to interpret. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. The reviewer references previous work that considers multiple CVEs or CWEs simultaneously and suggests that the results are difficult to interpret or are marginal improvements at best. This claim is 3 as it provides a logical reasoning based on the comparison with previous work, but it lacks specific references or detailed examples to fully substantiate the critique. The authors would need to explore the referenced literature to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the vulnerability discovery methodology used in the paper. It questions the ecological validity of considering a single vulnerability at a time, noting that previous work has considered multiple CVEs or CWEs simultaneously. The comment also points out that the results are difficult to interpret or are marginal improvements at best. This feedback is valuable as it highlights a potential weakness in the study\"s methodology and suggests that the authors should clarify their approach and its relevance to previous work. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or improve their methodology. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. While the comment implies that the authors should provide more details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides some specific feedback, suggesting that more details could be provided, such as the definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The authors might infer that it relates to the sections discussing graph notions or the algorithm, but this inference is not direct. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1. However, the comment lacks specific examples or references to support the claim that more details are needed, making it 3. The authors would need to infer the exact areas where more detail is required, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It provides specific suggestions for improvement, such as providing more details on the definition of the resistance distance and offering more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. These suggestions are clear and actionable, offering the authors concrete steps to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance or examples on how to effectively incorporate these details. Overall, the feedback is 4 as it provides valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically questioning whether the study on transformations of training images is sufficient to prove the point. It suggests that quantitative results on testing images might be needed to fully validate the claim. While the comment implies that the authors should provide such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the evaluation or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the sufficiency of the evaluation on transformations of training images and suggests that quantitative results on testing images might be needed. This provides clear guidance on what aspect of the study needs further evaluation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance. It suggests that quantitative results on testing images might be necessary. However, the comment does not provide specific examples, references, or detailed reasoning to support why testing images are crucial or how they would improve the evaluation. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of testing images based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the evaluation of shape model invariance. It questions the sufficiency of the evaluation on transformations of training images and suggests that quantitative results on testing images might be necessary to fully prove the point. This feedback is clear and actionable, as it directs the authors to consider an additional aspect of their evaluation that could strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct the evaluation on testing images or what metrics to use. Overall, the comment is 4 as it guides the authors toward a potential improvement in their study, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss and compare their work with the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. This feedback is explicit and provides a clear action for the authors to take, which is to include a discussion and comparison with this related work. The comment also specifies the reason for this action, highlighting the relevance of the AAAI15 paper to the authors\" work. Therefore, the comment is 5, as it gives the authors a concrete step to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a discussion and comparison with this related work. This provides clear guidance on how to improve the paper by ensuring it covers relevant stateoftheart work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared to provide a better understanding of the stateoftheart. The comment provides a specific reference to the AAAI15 paper, which is a clear and explicit source of evidence supporting the claim. This makes the claim 5, as it is based on a concrete reference that the authors can easily verify or address in their work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential gap in the authors\" work by pointing out a related paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this paper should be discussed and compared to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a discussion and comparison with this related work, which can enhance the context and relevance of their own work. However, the comment could be more helpful if it provided specific suggestions on how to integrate this comparison or discussed potential insights that could be gained from it. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It explicitly asks for an evaluation of the method\"s scalability on machines with fewer cores and inquires about the conversion from the Sinkhorn method to optimal transport. These questions provide clear and specific actions for the authors to take, such as testing the method\"s scalability and clarifying the conversion process. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions the approach used to compute optimal transport, specifically asking about the conversion from the Sinkhorn method to optimal transport. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. The reviewer points out that the Sinkhorn method provides a doubly stochastic matrix, but it is not clear how to convert it to optimal transport. This claim is 3 as it highlights a potential issue with the method\"s scalability and the conversion process, but it lacks specific examples or references to support the claim fully. The authors would need to provide additional information or clarification to fully understand and address the concerns raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It specifically asks for an evaluation of the method\"s scalability on machines with fewer cores and inquires about the conversion from the Sinkhorn method to optimal transport. These questions are clear and actionable, providing the authors with specific areas to address and improve their draft. By seeking clarification on the scalability and conversion process, the comment offers valuable guidance that can help the authors enhance the comprehensiveness and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should introduce specific aspects of the model that are relevant to the example model being discussed. It provides a concrete example of what should be clarified, such as the fact that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is explicit and provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 132, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be introduced, namely the specific aspects of the model that are relevant to the example model being discussed. The comment specifies that certain parameters are bounded on one side and that the model operates in a setting with finite subdivisions. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the finite subdivisions for certain parameters and the boundedness of parameters like acceleration and scaling. This feedback is based on logical reasoning, as it highlights potential areas of confusion or misunderstanding in the paper. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce the aspects of the specific model that are specific to the example model being discussed. It highlights the need to clarify that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is clear and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the readability and understanding of their work for both experts and nonexperts. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should consider applying their principles to other research areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate generalizability. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters, model, and experiments to areas beyond image data and ViT, suggesting that the authors should explore other research areas such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate generalizability. The comment provides a logical reasoning by questioning the focus on stateoftheart performance and suggesting that the method should be tested on different architectures and tasks. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate the generalizability of their method. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their work and improve its relevance. However, the comment could be more helpful if it offered additional guidance on how to approach these other areas or what specific aspects to consider. Overall, the comment is 4, as it effectively guides the authors toward enhancing the scope and applicability of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the usefulness of the results in the context of machine learning algorithms and the analysis of the algorithm. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the paper. The comment lacks actionable details, such as recommending specific ways to demonstrate the significance of the paper or suggesting how to better integrate the results into machine learning applications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the usefulness of the results in the context of machine learning algorithms and the analysis of the algorithm, suggesting that the significance of the paper is poor. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology, making it difficult for the authors to identify the exact area needing revision. The comment is specific in its critique of the paper\"s significance but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the significance of the paper is poor because the results are not clear in terms of their usefulness to machine learning algorithms or the analysis of the algorithm. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the usefulness of the results in the context of machine learning algorithms or the analysis of the algorithm is unclear. This feedback highlights a critical area that needs clarification or further elaboration to establish the paper\"s significance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional examples, applications, or analyses that could enhance the paper\"s relevance. While it points out a key area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the observations presented do not evaluate their generalizability to fewshot learners beyond Prototypical Networks. This suggests that the scope of the submission\"s contributions may be limited in terms of understanding the properties of episodic training. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or evaluate the generalizability of their observations. The action is implicit and vague, as the authors are left to infer that they need to expand their evaluation to include other fewshot learners, but without concrete steps or examples, it remains unclear how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of generalizability of the observations presented in the paper, specifically questioning whether they extend beyond Prototypical Networks to other fewshot learners. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the scope of contributions, but it lacks grounding as it does not identify the specific part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the observations presented in the paper do not evaluate their generalizability to fewshot learners beyond Prototypical Networks, which limits the scope of the submission\"s contributions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the observations presented do not evaluate their generalizability to fewshot learners beyond Prototypical Networks. This critique highlights a potential gap in the scope of the submission\"s contributions, suggesting that the paper may not fully explore the properties of episodic training. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or expand their evaluation to include other fewshot learners. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. While it identifies an area of potential improvement, it lacks concrete steps or actions for the authors to take. The feedback is 3 as it highlights an issue but does not offer specific guidance on how to resolve it.", "grounding_specificity_rationale": "The comment raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not specify which part of the paper discusses Equation 3 or where this issue is addressed, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact location. The comment is specific in detailing the issue with Equation 3 and the potential problem with modal subsets, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this issue is problematic or needs further exploration. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically questioning how Equation 3 addresses the problem of different modalities contributing differently across instances. It highlights a specific concern about instances with good performance in modality A versus modality B, suggesting that Equation 3 may not adequately handle this variation. While the comment raises an important point, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides feedback on the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the abstract. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details on evaluation and outcomes, but they are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description of how the proposed idea was evaluated and what the outcome was, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This is a subjective opinion based on the reviewer\"s interpretation of the abstract. However, the comment does not provide specific examples or detailed reasoning to support why the evaluation and outcome are missing, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific weakness in the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to enhance their abstract by including details on the evaluation and outcomes of their proposed idea. However, the comment could be more helpful if it provided suggestions on how to effectively present this information in the abstract. Overall, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment also points out a discrepancy between the problem setting description and the original MFDA paper. While the comment highlights an issue, it does not provide explicit instructions or concrete suggestions on how the authors should address this confusion or align their description with the original paper. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description and align it with the original paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section\" and references specific elements of the description, such as \"single target domain with sparse labels\" and \"target distribution p_T(x, y) with label observation.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the confusion regarding the use of unlabeled data in source domains and the discrepancy with the original MFDA paper. It raises questions about the problem setting and suggests that the authors clarify these aspects. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It references the original MFDA paper (Yue et al., 2021a) to highlight a discrepancy in the problem setting description. The comment questions whether the unlabeled data in source domains are used during training, as in the original paper. This provides a logical basis for the claim, as it points out a potential inconsistency in the paper\"s description. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the paper where the confusion arises. Overall, the claim is 4, as it provides a logical reasoning and references an external work, but it lacks detailed evidence or examples within the paper itself. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It points out a discrepancy between the paper\"s description and the original MFDA paper, which could lead to misunderstandings among readers. The comment raises important questions about the problem setting and suggests that the authors clarify these aspects. While it highlights a critical issue, it could be more helpful by providing specific suggestions on how to address the confusion or align the description with the original paper. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It implies that the authors should consider including such an analysis to further investigate the effects of batch size or different sampling strategies on the progress of the algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear direction for potential improvements, it does not explicitly instruct the authors to include this analysis or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an analysis of epochwise behavior, particularly for finite sum settings, to gain insights into optimization algorithms. It provides a specific example of investigating the effects of batch size or different sampling strategies on the progress of the algorithms after every full pass of data. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what could be analyzed, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes that such an analysis could help investigate the effects of batch size or different sampling strategies on the progress of the algorithms after every full pass of data. The comment also mentions that this analysis could aid in comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear direction for potential improvements, it lacks specific examples or references to support the claim. This makes the comment 3, as it provides a reasonable basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests a potential enhancement to the paper by proposing an epochwise analysis, particularly for finite sum settings, to gain insights into the behaviors of optimization algorithms. It provides a specific example of investigating the effects of batch size or different sampling strategies on the progress of the algorithms after every full pass of data. This suggestion could be valuable for the authors as it offers a concrete direction for further analysis and comparison of deterministic and stochastic methods. However, the comment could be more helpful if it included specific guidance on how to implement this analysis or examples of similar studies that have used this approach. Overall, the feedback is 3 as it identifies a potential area for improvement but lacks detailed guidance for execution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they should include these citations and algorithms, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide direct steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, stating that it is essentially a combination of GraphRAG and GraphCare. It also points out the lack of citation for key baselines and suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. While the comment provides some reasoning by referencing specific algorithms, it lacks detailed justification or examples to fully substantiate the claim about the incremental nature of the contribution. The mention of specific algorithms and baselines adds some support, but the overall justification is not robust. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It highlights the incremental nature of the contribution, noting that it is essentially a combination of existing methods like GraphRAG and GraphCare. The comment also points out the lack of citation for key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is valuable as it helps the authors understand the limitations of their work and provides specific suggestions for enhancing the paper. However, the comment could be more helpful if it offered guidance on how to integrate these algorithms or provided examples of how to improve the contribution. Overall, the comment is 4 as it identifies clear areas for improvement and offers actionable feedback, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the paper\"s classification of extreme speech, noting that the distinction between derogatory and exclusionary extreme speech is unclear. It provides a concrete example from the sample data file, asking why a particular instance is classified as exclusionary extreme speech but derogatory extreme speech. The comment also raises questions about the role of local regulations in annotations and their impact on zeroshot crosscountry classification. While the comment identifies a clear issue and provides specific examples, it does not explicitly instruct the authors on how to address these concerns. The action is implicit but concrete, as the authors can infer that they need to clarify the classification criteria and potentially address the impact of local regulations. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clear distinction between the three classes of extreme speech and provides a specific example from the sample data file to illustrate the confusion. The comment raises questions about the role of local regulations in annotations and their impact on zeroshot crosscountry classification, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between derogatory and exclusionary extreme speech, specifically questioning the classification of an instance in the sample data file. The reviewer provides a detailed example and asks for clarification on the role of local regulations in annotations. This level of detail and specific questioning supports the claim, making it 4. However, the comment could be strengthened by referencing relevant literature or studies that address similar issues, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper regarding the distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file to illustrate the issue, which allows the authors to understand the problem more clearly. The comment also raises questions about the role of local regulations in annotations and their impact on zeroshot crosscountry classification, prompting the authors to consider these factors in their analysis. By offering detailed feedback and specific examples, the comment provides actionable guidance for improving the clarity and comprehensiveness of the paper. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to change the notation to make it mathematically correct, unless doing so would make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment implies that the authors should make these changes, it does not provide explicit instructions on how to implement them or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer that they need to make changes but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear feedback on the need for mathematical correctness and the introduction of notation, specifying what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the notation used in the paper, specifically \"L_l\" instead of \"L,\" needs to be changed to be mathematically correct. The reviewer provides a logical reasoning by stating that this change might affect other equations, implying that the current notation is incorrect. However, the comment lacks specific examples or references to support the claim that the current notation is problematic. Without detailed justification or examples, the authors may find it challenging to understand and address the issue fully. Therefore, the comment is 3, as it provides a logical basis but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the need for mathematical correctness and the introduction of notation. It suggests that the notation \"L_l\" should be changed to \"L\" and that this change should be introduced beforehand to avoid making other equations messy. While the comment highlights important areas for improvement, it lacks depth and does not provide detailed guidance on how to address these issues or why they are important. The feedback is 3 as it points out specific areas for improvement, but it could be more actionable with additional explanation or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as shown in Figure 5. It suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the draft. The action is implicit and somewhat vague, as it leaves the authors to infer that they should explore scenarios with different timesteps but does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, it does not provide specific guidance on how to address this issue or what changes should be made. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed methods is questionable when the training and evaluation timesteps are the same, as shown in Figure 5. The reviewer suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim. It provides a logical suggestion but does not fully substantiate the claim with evidence or references, making it 3. The authors would need to explore this further to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as shown in Figure 5. It questions the significance of the proposed methods in achieving good performance when the timesteps are identical. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. While the comment identifies a potential weakness and provides a direction for further exploration, it lacks specific suggestions or detailed guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider different scenarios and their implications, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback provides a clear and explicit action for the authors to take, which is to further elaborate on the disentanglement process and its guarantees. The comment is specific and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed and suggesting that the authors highlight how disentanglement is realized and guaranteed without certain bias types. However, it does not specify which part of the paper discusses disentanglement, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding disentanglement, such as highlighting how it is realized and guaranteed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions disentanglement as a limitation, but suggests that further explanation is needed. The comment provides a logical reasoning by pointing out the importance of highlighting how disentanglement is realized and guaranteed without certain bias types. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional details to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the disentanglement process and its guarantees. By addressing this point, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of what to include. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation phi and the shared model theta_S. The comment also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback provides a clear and explicit action for the authors to take: they should discuss the effect of the proposed objective equation on the number of parameters compared to prior work. The comment is specific and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This claim is 3 as it highlights a gap in the discussion regarding the impact of the proposed objective equation on the number of parameters. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the issue. Providing more detailed analysis or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation phi and the shared model theta_S. The comment points out that the effect of this objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is clear and actionable, as it directs the authors to address the gap in their discussion by comparing the number of parameters with prior work. By providing this specific guidance, the comment is 5, as it empowers the authors to make a meaningful improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential issue with the effectiveness of the proposed solution, but it lacks specific guidance on how to address this concern. Overall, the comment is 3, as it raises questions and points out a potential issue but does not provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the implications of Eq. 4 and critiques the improvement of the designed solutions in Table 5, providing a clear example of the marginal improvement on the OfficeHome dataset. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that requires no verification, as it is a request for clarification. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This is a factual statement without a claim or opinion, as it describes the observed results. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two points. First, it questions the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that prompts the authors to clarify the relationship between these equations. Second, it critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential issue with the effectiveness of the proposed solution, but it lacks specific suggestions or guidance on how to address this concern. The authors are left with a general understanding of the issue but without actionable steps to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing stateoftheart reference in the experiment of face recognition, specifically mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. It also provides a link to the work and notes that the triplet loss is used, reporting results on a dataset similar to Webface. The comment further compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This feedback is explicit and provides concrete details on what reference should be included and how it compares to the current results. The authors know exactly what action to take to improve their draft by adding this reference and potentially revising their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the \"stateoftheart references,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the missing reference, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu, and provides a link to the work. Additionally, the comment details the comparison with the VRF results on LFW, noting that it is better than the results in Table 3. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that stateoftheart references are missing in the experiment of face recognition, specifically mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. The reviewer provides a link to the work and notes that it uses the triplet loss and reports results on a dataset similar to Webface. The comment further compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This level of detail, including references and comparisons, provides a robust basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting the absence of stateoftheart references in the experiment of face recognition. It mentions a particular work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and provides a link to the work. The comment also highlights that the work uses the triplet loss and reports results on a dataset similar to Webface, which is relevant to the paper. Additionally, it compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This feedback is actionable and provides clear guidance on how to enhance the paper by including relevant references and potentially revising the results. However, it could be more helpful if it offered suggestions on how to integrate these references or discuss the implications of the comparison. Overall, the comment is 4, as it directs the authors to a specific area for improvement and provides valuable information for enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, as the authors are left to infer that they need to explore alternative methods or improve the template mapping process, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the question answering process, namely the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper discusses this process, making it weakly grounded. The comment is specific in identifying the potential issue of poor generalization for questions that are not \"Whtypes\" or transformable, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process might lead to poor generalization due to the use of template mapping to transform questions into masked statements. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases or studies that demonstrate the potential issue with generalization. Without additional evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their model. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses should be provided. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The explicit nature of the action and the detailed suggestions make this comment 5.", "grounding_specificity_rationale": "The comment suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses should be provided. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as specific sections or figures where these comparisons are made. While the authors might infer that it relates to the experimental results or methodology sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the proposed three projection errors is more appropriate. The reviewer provides a logical reasoning by suggesting that the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses should be provided. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison of the model\"s performance, noting that it is unfair to only compare the model pretrained on synthetic data. It suggests that demonstrating the importance of the proposed three projection errors is more appropriate, and provides a clear and actionable recommendation to include the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is detailed and offers a concrete direction for improvement, making it 5 for the authors to enhance their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. It suggests that it is also common to average over subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). While the comment provides a reference for the suggestion, it does not explicitly instruct the authors to implement this alternative method or explain why it might be beneficial. The action is implicit and somewhat vague, as the authors can infer that they might consider averaging over subword representations but are not given specific guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion to average over subword representations, referencing a specific example from Hewitt and Manning (2019, footnote 4). This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that averaging over subword representations is a common practice, referencing a specific example from Hewitt and Manning (2019, footnote 4). This provides a clear and specific reference to support the claim, making it 5. The inclusion of a direct citation and the mention of a specific footnote in the referenced work offer robust evidence for the claim, ensuring that the authors can understand and address the suggestion effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by pointing out a common practice in natural language processing, namely averaging over subword representations. It references a specific example from Hewitt and Manning (2019, footnote 4), which offers a concrete reference for the authors to consider. This feedback is clear and actionable, as it directs the authors to a potential enhancement of their methodology. However, the comment could be more helpful if it explained why averaging over subword representations might be beneficial or how it could impact the results. Overall, the comment is 4, as it provides a valuable suggestion for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is a crucial aspect for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their own approach. While the comment implies specific actions, it does not provide detailed guidance on how to conduct these analyses or what specific aspects to focus on. The authors can infer the actions but may need more direction on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as conducting calibration curves to demonstrate consistency between predicted scores and actual risks, and discussing the differences between the traditional method and the authors\" method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The reviewer encourages the use of calibration curves to show this agreement. The comment provides a logical reasoning for the claim, suggesting that the model\"s discriminant ability alone may not be sufficient for clinical applications. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the suggestion to enhance their work, but the comment could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of calibration curves to demonstrate the consistency between predicted scores and actual risks. This is particularly relevant for clinical scoring systems, where such consistency is crucial. The comment also encourages the authors to discuss the differences between their method and traditional approaches, which can further enhance the paper\"s contribution. While the comment is specific and offers valuable guidance, it could be more helpful if it included examples or detailed steps on how to conduct the calibration curves or discuss the differences. Overall, the feedback is 4 as it directs the authors toward important areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2, which requires approximately identical mean as the assumption. The reviewer suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. While the comment identifies areas that need further discussion, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not seem to change much with sparsification, and it questions the importance of Lemma 2, which requires approximately identical mean as the assumption. The comment further suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2, which requires approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that these conditions are not well discussed. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2, which requires approximately identical mean as the assumption. The reviewer points out that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This feedback is clear and actionable, as it highlights a critical area that needs further discussion and explanation. By addressing these points, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to discuss these conditions or what additional information should be included. Overall, the comment is 4, as it directs the authors to a specific area that requires attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the experiments, questioning the strength and fairness of the baselines used. It suggests that the authors should use the default settings of these baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as which baselines to include or how to discuss limitations. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as using the default settings of baselines and including specific baselines related to BO with discrete and categorical variables. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the lack of strength and fairness in the experiments, the absence of certain baselines, and the need to discuss limitations and societal impacts. However, the comment lacks specific examples or detailed reasoning to support these claims. It provides general observations but does not offer concrete evidence or references to substantiate the claims. This makes the comment 3, as it highlights areas for improvement but lacks the necessary detail to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It questions the strength and fairness of the experiments, suggesting that the authors should use the default settings of baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the lack of discussion on limitations and societal impacts of the proposed approach. While the comment highlights important areas for enhancement, it does not provide specific guidance or suggestions on how to address these issues, such as which baselines to include or how to discuss limitations. This limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. It also points out a typo in the text, suggesting a correction. While the comment identifies a potential area for further exploration and provides a specific correction, it does not offer explicit guidance on how the authors should address the lack of insight or conduct further analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the reasons behind the similar performance and potentially explore the generalizability of the findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3\" and \"presentation bits,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a typo in the text (\"presentation bits\" should be \"representation bits\") and raises a concern about the lack of insight into why all sparsity patterns perform similarly. The comment suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform similarly without providing insight into why this is the case. It raises a question about whether this is a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This feedback is 3 as it prompts the authors to consider the broader implications of their findings and potentially explore the generalizability of their results. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar observations have been handled in other works. Overall, the comment provides some direction for further exploration but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part addresses a claim in the paper regarding the methodology requiring significant additional assumptions. The reviewer challenges this claim by pointing out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback provides a clear and explicit action for the authors to reconsider their claim and potentially revise it. The second part of the comment points out an inequality with the wrong sign, providing a specific line number for correction. This feedback is explicit and concrete, giving the authors clear guidance on how to address both issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the claim regarding additional assumptions and the inequality with the wrong sign. The comment clearly specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the methodology requiring significant additional assumptions and a correction regarding an inequality. The first part challenges the claim by providing a logical reasoning that the additional assumption is natural in many machine learning settings, which supports the claim that the assumption is not as extreme as stated. The second part provides a specific correction to an inequality, which is a factual statement requiring no verification. Overall, the comment is 4 for the first part due to the logical reasoning provided, while the second part is verifiable as it corrects a factual error. Therefore, the overall score is 4.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it challenges the claim in the paper that the methodology requires significant additional assumptions, pointing out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback is helpful as it prompts the authors to reconsider their claim and potentially revise it. Second, the comment corrects an inequality on line 310, specifying that the base alpha should be less than one. This is a clear and actionable suggestion that directly improves the accuracy of the paper. Both pieces of feedback are specific and provide valuable guidance for the authors to enhance the clarity and accuracy of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts in the related work. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts in the related work. However, it does not specify which part of Section 6 is being addressed, making it weakly grounded. The comment is specific in suggesting a comparison with prior efforts, but it lacks detailed guidance on how to implement this comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it explain why such a comparison is necessary or how it would enhance the manuscript. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to guide the authors in making improvements.", "helpfulness_rationale": "The comment identifies a potential area for improvement by suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts in the related work. This feedback is 3 as it points out a specific aspect of the paper that could be strengthened by providing a comparative analysis. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects should be highlighted, which limits its usefulness. To be more helpful, the comment could include suggestions on what aspects to focus on or how to structure the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not provide explicit instructions on how to conduct this analysis or what specific steps the authors should take to address this suggestion. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of varying the number of scenarios, but they are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting an area for further exploration, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. This feedback is 3 as it identifies a potential area for further exploration and analysis, which could lead to a deeper understanding of the results. However, the comment lacks specific guidance on how to conduct this analysis or what specific questions to address, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should consider the impact of disturbances on the model\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s performance. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its questioning of the model\"s ability to predict quality labels under disturbances, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s performance, which is a valid point for consideration. However, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to address this concern. It does not offer insights into how the authors might test or validate this hypothesis or how they could improve their model\"s robustness to disturbances. As a result, the comment is 3, as it prompts the authors to consider a potential issue but does not fully support them in addressing it effectively."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a specific issue with the clarity of the state space representation in Appendix A.2. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve the clarity of the representation. There is no suggestion on what specific aspects need to be clarified or how the authors might enhance the illustration. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the state space representation of the environment, providing clear guidance on what needs to be improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve the illustration or clarify the representation. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, the comment is 2, as it points out a problem but does not offer a path to resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors on how to address this issue in their own work. While it identifies a potential area for improvement, it lacks actionable advice on how the authors might incorporate these extensions or address the bounded noise assumption. As a result, the comment is 3, as it points out a limitation but does not offer concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment addresses the bounded noise assumption, which is a specific aspect of the paper related to stochastic optimization. However, it does not specify which part of the paper discusses this assumption, making it weakly grounded. The comment is specific in mentioning several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. This provides a clear direction for the authors to consider in their work. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and references several efforts to extend these noise conditions. The references provided are specific and provide a basis for the claim, making it 4. However, the comment could be strengthened by including more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a potential limitation in the paper, specifically the bounded noise assumption, which is somewhat restrictive in the context of stochastic optimization literature. It references several efforts to extend these noise conditions, providing specific references to works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. This feedback is valuable as it informs the authors about existing work in the field and suggests that they might consider incorporating these extensions into their own work. However, the comment could be more helpful if it offered specific guidance on how to integrate these extensions or addressed the implications of these extensions for the authors\" work. Overall, the comment is 3 as it provides relevant information but lacks detailed suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation behind using characteristic function regularization is unclear. However, it does not provide any explicit or implicit suggestions on how the authors might clarify this motivation or improve the clarity of their explanation. Without guidance on what specific aspects of the motivation are unclear or how to address this issue, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall motivation for using characteristic function regularization, but it does not specify which part of the paper this issue pertains to, such as a specific section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a critical issue with the paper, noting that the overall motivation for using characteristic function regularization is unclear. This is an important observation that could impact the paper\"s clarity and impact. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or examples, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a significant weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the originality or novelty of the work, nor are there suggestions for potential areas of improvement or additional contributions. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper these techniques are discussed in, making it weakly grounded. The comment is specific in detailing the existing techniques used and the perceived lack of originality, but it does not provide guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, citing specific references (Lykouris et al., 2018; Zhou et al., 2021) for context. This provides a clear basis for the claim, as it references specific works that the paper builds upon. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the contribution is incremental. While the references provide some support, the comment could be strengthened by elaborating on how the combination of these techniques is not novel or innovative. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. It references specific works (Lykouris et al., 2018; Zhou et al., 2021) to support this claim, which provides some context for the authors to understand the basis of the critique. However, the comment lacks actionable suggestions or guidance on how the authors might enhance the originality or novelty of their work. While it identifies a potential weakness, it does not offer specific advice on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It asks whether this refers to 100 sampled strategies. This comment is explicit in its request for clarification, as it directly asks for an explanation of the term \"100 steps.\" However, it does not provide any guidance on how the authors should address this issue or what specific information should be included in the explanation. The action is explicit but lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically asking if it refers to 100 sampled strategies. This is a clear and specific question that prompts the authors to clarify an aspect of their work that may be unclear to readers. By addressing this question, the authors can ensure that their paper is more transparent and easier to understand. However, the comment does not provide any additional suggestions or feedback beyond the clarification request. While it is a useful question, it lacks depth and does not offer comprehensive guidance for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, and encourages the authors to explore this further. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, as discussed in the related work review. While the comment highlights a potential overlap with existing work, it does not provide explicit guidance on how the authors should address this issue or how to differentiate their work. The action is implicit and somewhat vague, as it suggests further exploration but lacks concrete steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"use of energy models for image generation\" and the \"motivation and goals of the model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the similarity of the model\"s motivation and goals to those of a prior VAE paper, as discussed in the related work review. This provides clear guidance on what needs to be addressed, such as differentiating the model\"s approach from existing work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to those of a prior VAE paper. The comment provides a logical reasoning by comparing the model to existing work, which is a common practice in the field. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to explore the related work section to fully understand the basis of the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, which is a positive observation. It also highlights the similarity of the model\"s motivation and goals to those of a prior VAE paper, as discussed in the related work review. This feedback is valuable as it prompts the authors to consider how their work differs from existing literature, potentially leading to a more nuanced discussion of their contributions. However, the comment could be more helpful if it provided specific suggestions on how the authors might differentiate their work or address the overlap with existing VAE work. Overall, the comment is 3 as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends running experiments on a different benchmark, such as Atari, to evaluate the method\"s generalizability and applicability to other domains. It provides a clear and direct action for the authors to take, specifying a specific benchmark to use for further evaluation. The comment is concrete in its suggestion, giving the authors a clear path forward to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation being conducted only on the tasks from Meta World, a robotic manipulation domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests running experiments on a different benchmark, such as Atari, to evaluate the method\"s generalizability and applicability to other domains. It provides a clear and actionable recommendation for improving the evaluation process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited to a single domain, Meta World, and suggests running experiments on a different benchmark like Atari to assess generalizability. The comment provides a logical reasoning for the need to evaluate on multiple domains, as it would help determine the method\"s applicability to other domains. However, it lacks specific references or examples of how Atari or other benchmarks could be used to verify the method\"s performance. This makes the claim 3, as it provides a logical basis but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is only tested on tasks from the Meta World domain, a robotic manipulation domain. It suggests running experiments on a different benchmark, such as Atari, to assess the method\"s generalizability and applicability to other domains. This feedback is clear and actionable, providing a specific recommendation for improving the evaluation process. By suggesting a commonly used benchmark like Atari, the comment offers a concrete step for the authors to take to enhance the robustness and validity of their results. However, it could be more helpful if it included additional guidance on how to adapt the method to Atari or other domains. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects of the model should be explored. The comment implies that the authors should consider the feedback or suggestions provided, but it does not specify what those suggestions are. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges that the method is presented nicely and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not specify which part of the paper lacks this analysis or provide examples of what kind of analysis would be beneficial. The comment is 1 as it does not identify a specific section or part of the paper, and it is also not specific about what kind of analysis is missing. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is necessary or how it could enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the method is presented well and the experiments are good and complete, but it points out a missing aspect: analysis on what the model does, which could be interesting. This feedback identifies a specific area for improvement, suggesting that the authors should include an analysis of the model\"s behavior or functionality. However, the comment does not provide detailed guidance on how to conduct this analysis or what specific aspects should be explored. While it highlights a potential enhancement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning whether there might be scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the scalability of their modulator. The comment lacks actionable details, such as recommending specific methods or approaches to address the scalability issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on what aspects of the modulator design or scalability need to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specificity and actionable guidance on how the authors might address this concern or improve the scalability of their modulator. Without detailed suggestions or examples, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 2, as it provides some insight but does not offer sufficient direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments performed in the paper incorporated a significant amount of domain knowledge into the structure of f_R and f_P, implying that a less informed version of these functions might require an impractical amount of data to learn. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experiments. It lacks concrete details on what changes could be made to reduce the reliance on domain knowledge or how to ensure that the experiments are more dataefficient. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the adaptability of f_R and f_P over time and the incorporation of domain knowledge in the experiments. However, it does not specify which part of the paper discusses these functions or experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the reliance on domain knowledge and the potential data requirements for a less informed version of f_R and f_P, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments performed in the paper incorporated a significant amount of domain knowledge into the structure of f_R and f_P, suggesting that a less informed version of these functions might require an impractical amount of data to learn. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, suggesting that the functions f_R and f_P may require an impractical amount of data to learn due to the incorporation of significant domain knowledge. This feedback highlights a limitation in the experimental setup and provides a basis for the authors to consider alternative approaches or adjustments to their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or data sources to reduce the reliance on domain knowledge. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the application of imitation learning and the difficulties in obtaining labeled data. It suggests that the authors should conduct experiments to assess whether there are challenges in obtaining the corresponding data and how performance changes with varying labeled data sizes. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to design or execute them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the application of imitation learning and the challenges in obtaining labeled data, suggesting that the authors should conduct experiments to assess these issues. However, it does not specify which part of the paper this concern relates to, such as a specific section or experiment. The authors can infer that it might pertain to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the difficulties in obtaining labeled data and the impact on performance. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no experiments on the difficulties in obtaining labeled data for imitation learning and how performance changes with varying labeled data sizes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to assess whether there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for further experimentation. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area that could enhance the robustness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the implications of overparameterization leading to powerful memorization and good generalization performance. It suggests that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve their draft. The suggestion to acknowledge this in the conclusion is implicit, but it lacks concrete details on how to implement this acknowledgment. As a result, the comment is 3, as it identifies an area for improvement but does not provide clear steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises a concern about the implications of overparameterization leading to powerful memorization and good generalization performance, suggesting that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the connection between robust memorization and robust generalization, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the implications of overparameterization leading to powerful memorization and good generalization performance. It suggests that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. The reviewer acknowledges that the authors have addressed this in the conclusion but considers it a serious question. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the connection between robust memorization and robust generalization is not clear. This makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the implications of overparameterization leading to powerful memorization and good generalization performance. It suggests that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. The reviewer acknowledges that the authors have addressed this in the conclusion but considers it a serious question. This feedback is 3 as it identifies a potential gap in the paper and encourages the authors to further explore the connection between robust memorization and robust generalization. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the clarity of the connection. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the novelty of the OOD experiments, noting that the trained network demonstrates strong OOD generalization. It suggests that the authors should mention the recent work by Ulyanov et al. (CVPR 2018) and place their method in context, ideally comparing it with those methods. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate this information into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to mention recent work by Ulyanov et al. (CVPR 2018) and place the current method in context, ideally comparing it with those methods. This level of detail guides the authors on what specific information to include and how to improve their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the OOD experiments are interesting because the trained network demonstrates strong OOD generalization. It then suggests that the authors should mention recent work by Ulyanov et al. (CVPR 2018) and place their method in context, ideally comparing it with those methods. The claim is 3 as it provides a logical reasoning for the novelty of the OOD experiments and suggests a relevant reference. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the OOD experiments, noting that the trained network demonstrates strong OOD generalization. It then suggests that the authors should mention recent work by Ulyanov et al. (CVPR 2018) and place their method in context, ideally comparing it with those methods. This feedback is 4 as it provides a clear direction for the authors to enhance their paper by contextualizing their work within the existing literature. However, the comment could be more helpful if it included specific suggestions on how to integrate this information or what aspects to focus on in the comparison. Overall, the comment offers valuable guidance for improving the paper, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. It provides specific examples of references that could guide the authors in their experiments. This feedback is clear and actionable, as it directly instructs the authors on what additional experiments to perform and provides concrete examples of relevant literature. The authors know exactly what actions to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. This provides clear guidance on what specific areas need further exploration. The comment is also specific because it suggests conducting additional experiments and references relevant literature, providing a clear direction for the authors to follow. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. This suggestion is supported by references to specific works in the field, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing. These references provide a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional experiments would contribute to the paper\"s strength. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. This feedback is specific and offers concrete examples of what the authors could explore to strengthen their work. By referencing relevant literature, the comment also provides a basis for the authors to further their research. However, the comment could be more helpful if it included a rationale for why these experiments are necessary or how they would contribute to the paper\"s strength. Overall, the comment is 4 as it guides the authors toward a specific direction for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their explanation. Without guidance on what specific aspects of the mechanism need further elaboration or how the authors might demonstrate its effectiveness, the comment lacks actionability. The authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not specify which part of the paper discusses this mechanism, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of clarity but lacks grounding as it does not mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of why the proposed sample selection mechanism helps preserve the label distribution. This is a relevant observation that could help the authors improve their explanation or justification of the mechanism. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the feedback is 3, as it points out a potential weakness but does not fully support the authors in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on whether the authors should evaluate additional models, what types of models should be considered, or how to address the issue of evaluating only a limited number of models. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this critique pertains to, such as the results section or the discussion of model evaluation. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a specific issue with the models evaluated, it does not provide detailed guidance on how to address this issue or what alternative models should be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. This claim is 3 as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim about the models being old and small, which would strengthen the justification. The authors might need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. While this observation highlights a potential weakness in the study, the comment lacks specific suggestions or guidance on how the authors might address this issue. It does not provide actionable advice on which models should be considered, how to expand the evaluation, or what additional analyses could be conducted to enhance the comprehensiveness of the results. Without such guidance, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it identifies a weakness but does not offer detailed feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly requests the authors to provide an explanation for the observed performance degradation when using additional information about missing, wrong, or redundant data in the FBN results. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be addressed in the draft. The request is concrete, as it provides a specific aspect of the results that requires clarification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors are asked to provide an explanation for the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to explain why the performance degrades when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the performance degradation in the FBN results when using additional information about missing, wrong, or redundant data. It prompts the authors to provide an explanation for this observation, which could help clarify the results and potentially lead to improvements in the draft. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could include questions or suggestions on potential causes or ways to mitigate the performance degradation. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit feedback by pointing out specific sections of the paper that are difficult to read and suggesting that the author failed to explain each method clearly. It includes concrete examples of what is unclear, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers. This feedback is actionable because it directs the authors to clarify these specific points in their draft. The authors know exactly what needs to be addressed and can use the examples provided to improve the clarity of their explanations. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of what is unclear, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers. This level of detail helps the authors understand exactly what needs to be clarified or explained further. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are difficult to read due to the lack of clear explanations of previous approaches. It provides specific examples, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers, to illustrate the confusion. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to specific sections of the paper where these issues occur. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific sections of the paper that are difficult to read due to the lack of clear explanations of previous approaches. It provides concrete examples of what is unclear, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers. This feedback is actionable as it directs the authors to clarify these specific points, which can significantly improve the readability and comprehensibility of their draft. By addressing these issues, the authors can enhance the clarity and accessibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not provide specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. The action is implicit and somewhat vague, as the authors are left to infer what needs to be changed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not specify which parts of the introduction are unclear or what aspects of the motivation need clarification. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need revision. Additionally, the comment does not mention any specific sections or elements of the paper, making it weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation of the paper is unclear, suggesting that the introduction should be revised to make it easier to follow. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It suggests that the introduction should be carefully revised to make the paper easier to follow. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the motivation are unclear or how the introduction should be revised. Without concrete suggestions or examples, the authors are left with a general direction but no clear steps to take. This limits the comment\"s usefulness, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to ensure consistency across categories or proposing alternative methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of including multiple local prompts and notes that the features and their positions may not be the same for different categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its observation about the inconsistency of features and positions across categories, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that including multiple local prompts can be intuitive but points out a potential issue: the features and their positions may not be the same for different categories. This observation highlights a potential weakness in the paper, suggesting that the authors should consider how to ensure consistency across categories. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing methods to standardize the features or positions. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps should be taken to improve the validation process. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation but lacks grounding, as the authors cannot confidently determine which part of the paper this critique relates to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. This is a relevant observation that could impact the reliability and validity of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the validation process. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and vague, as the authors are left to infer that they should expand their experiments to a broader range of molecules or improve the generalizability of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability and the need for broader testing, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value is limited due to its focus on a limited number of molecules and indistribution testing. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why the method\"s value would be limited or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly questions the understanding of the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This provides a clear and direct action for the authors to take: they need to clarify the source of the test data and whether there is a ground truth associated with it. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the understanding of the red line and asking about the source of the test data and the presence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper, namely the red line in Figure 3. By asking where the test data comes from and whether there is a ground truth, the reviewer provides clear and actionable feedback that prompts the authors to clarify an important aspect of their work. This feedback is valuable as it directs the authors to address a potential misunderstanding or lack of clarity in their presentation, which can significantly improve the comprehensibility of their results. However, the comment could be more helpful if it suggested ways to address this issue or provided additional context. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper is not wellwritten and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions that there is a lack of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks actionable details, such as suggesting ways to enhance clarity or providing examples of how to improve the figures or tables. As a result, the authors are left without a clear understanding of what changes to make to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper being poorly written and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. However, the comment does not specify which parts of the paper are particularly problematic or provide detailed feedback on how to improve the writing or formatting. Without specific guidance or references to particular sections, the authors cannot effectively address the issues raised. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and suggests it was possibly written in a hurry, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion about the writing quality or the impact of a hurried writing process. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is not wellwritten and possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how to improve the writing, presentation, or formatting. Without detailed guidance or examples, the authors are left without a clear understanding of what changes to make to enhance the readability and presentation of their work. Therefore, the comment is 2, as it identifies areas for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s main contribution, suggesting that it may not be novel given prior work on samplewise multiple descent in linear regression. The reviewer recommends that the paper should better highlight its novelty in relation to prior results. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific ways to highlight the novelty. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their results but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s main contribution in relation to prior work on samplewise multiple descent in linear regression. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its suggestion to better highlight the novelty of the result in relation to prior results, but it lacks explicit references to sections or parts of the paper where this issue is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work has already shown samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper, but suggests that the claims seem correct. However, the comment lacks specific references or detailed reasoning to support the claim about the novelty of the paper\"s contribution. This makes the claim 3, as it provides some justification but lacks comprehensive evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s main contribution, suggesting that it may not be novel given prior work on samplewise multiple descent in linear regression. It recommends that the paper should better highlight its novelty in relation to prior results. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or enhance their discussion of novelty. The feedback is 3 as it prompts the authors to consider the novelty of their results, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. While the questions imply that the authors should address these discrepancies or provide explanations, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify these issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. However, it does not specify which part of the paper these tables or studies are located in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questions but lacks grounding, as it does not provide clear references to the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the alignment of results in Table 6 with those in Table 1 (MCTpair) and the ablation studies of MCT without adaptive metrics. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. While it identifies potential inconsistencies or gaps in the presentation of results, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment highlights areas that need clarification but lacks actionable feedback or detailed advice, leaving the authors with a general sense of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not specify what kind of discussions are needed or how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer what specific discussions are required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what kind of discussions are required or how the authors should address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks used in the bAbi dataset, suggesting that the authors could solve all the subtasks with their final model. This feedback highlights a possible weakness in the experimental setup and encourages the authors to provide more discussions on this aspect. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional discussions could be included. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve the removal of a component of the method. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, are needed in their draft. There is no actionable advice or suggestions for improvement, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve the removal of a component of the method. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on why the study should not be considered an ablation study or what alternative classification might be more appropriate. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve the removal of a component of the method. The comment provides a logical reasoning by explaining that an ablation study typically involves removing a component to assess its impact, which is not the case in this study. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially consult relevant literature to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve the removal of a component of the method. While the comment identifies a potential misclassification, it lacks depth and does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or what alternative classification might be more appropriate. Therefore, the comment is 2, as it points out a potential problem but does not offer any constructive advice or direction for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate AccNet into a larger predictor or what specific aspects should be considered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This provides clear guidance on what the authors should consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the potential inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This is a thoughtful suggestion that could lead to a broader application of the model and potentially enhance its utility. However, the comment lacks depth and does not provide specific guidance on how to implement this idea or what aspects of the model would benefit from such an integration. While it prompts the authors to consider an interesting extension, it does not offer detailed actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should test the metric on additional datasets, how they might do so, or what specific datasets would be appropriate. Without any actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the metric or dataset testing are problematic. Without clear guidance on where to address the issue or what specific concerns need to be addressed, the comment is 1 and not specific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which is a limitation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation, such as recommending additional datasets for testing or discussing potential implications of this limitation. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. While the comment implies that the authors should consider adding this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. This provides clear guidance on what the authors could do to improve their evaluation. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. The comment provides a logical reasoning for the suggestion, as it highlights the importance of comparing the proposed TransferNorm architecture with direct competitors. However, it does not provide specific examples or references to these competitors, which would strengthen the justification. Therefore, the claim is 4, as it requires additional information to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the evaluation section of the paper. It acknowledges the current evaluation as a good start, which involves comparing several base DA methods with and without the proposed TransferNorm architecture. The comment suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors such as AutoDial and AdaBN, which are direct competitors to TN. This feedback is clear and actionable, as it offers a specific direction for enhancing the evaluation to make it more comprehensive and robust. However, it could be more helpful if it provided additional guidance on how to implement this comparison or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving their evaluation methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues: the lack of definition for the abbreviation \"NE\" on line 73 and the delayed definition of superscript notation in equation 6, which is not defined until line 166. The comment provides references to relevant literature, which could help the authors understand the context and improve their draft. However, while the comment highlights the issues, it does not explicitly instruct the authors to define these terms or provide guidance on how to address the problem. The action is implicit and somewhat vague, as the authors need to infer that they should define these terms and ensure their clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L73 and L166) and equations (Eq 6), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of definition for abbreviations and superscript notation, which hinders understanding during the initial read. Additionally, the comment provides references to relevant literature, which further grounds the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined, such as \"NE\" on line 73, and that superscript notation in equation 6 is not defined until much later (line 166), which hinders understanding during the initial read. The comment supports this claim by referencing three external works that discuss similar issues in communication and multiagent reinforcement learning. This provides a logical basis for the claim, as the references offer context and evidence that such issues are common in the field. However, the comment could be strengthened by providing more detailed examples or explanations from the referenced works to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation but could benefit from additional details.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in equation 6. This feedback is valuable as it helps the authors pinpoint areas where clarity and understanding could be improved. By referencing relevant literature, the comment provides context and suggests that these issues are not unique to the paper, which can guide the authors in addressing them. However, the comment could be more helpful if it offered specific suggestions on how to define these terms or provided examples of how to improve clarity. Overall, the comment is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the evaluation as weak and notes that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the evaluation or which baselines to use that are more appropriate for fair classification. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation as weak and mentions that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this evaluation is discussed in, nor does it provide details on how the baselines are inadequate or how they should be improved. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the baselines are inappropriate or how they impact the evaluation. Without specific details or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically noting that the evaluation is weak and that the baselines used are not designed for fair classification. This feedback is important as it highlights a critical issue that could impact the validity and relevance of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed advice on which baselines to use or how to improve the evaluation, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is 3, as it points out a significant issue but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first three paragraphs of section 2 need to be clarified to spell out the setting more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to spell out the setting more clearly. The comment suggests that the authors may be claiming credit for a more general approach than what is presented, which muddles the exposition. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It suggests that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or references makes the claim 3, as it provides a general direction but requires more elaboration to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific issue with the first three paragraphs of Section 2, suggesting that the setting needs to be clarified more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. This feedback is clear and actionable, as it directs the authors to clarify the setting to avoid confusion and ensure that their claims are accurately represented. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or what aspects need further elaboration. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the experiments, specifically questioning the choice of the old baseline and suggesting that the proposed method should be tested on newer 3D CNNs like X3D and SlowFast. The reviewer also asks for a comparison with these approaches to highlight the advantages of the proposed method. While the comment implies that the authors should test their method on these newer approaches and provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and comparisons. However, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically questioning the choice of the old baseline and suggesting that the authors should test their method on newer 3D CNNs like X3D and SlowFast. It also asks for a comparison with these approaches to highlight the advantages of the proposed method. However, the comment does not explicitly mention which part of the paper discusses the experiments, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in detailing what needs to be addressed, such as testing on newer 3D CNNs and comparing with existing approaches. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point questions the validity of the experiments by suggesting that the choice of the old baseline, such as R3D and C3D, may not be sufficient. It proposes that newer 3D CNNs like X3D and SlowFast should be considered to reduce computation complexity. The reviewer also asks for a comparison with these newer approaches to highlight the advantages of the proposed method. While the comment raises valid concerns about the experimental setup, it lacks specific examples or references to support the claim that newer approaches are more effective. This makes the claim 3, as it provides a logical basis for improvement but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a valid concern about the experiments, specifically questioning the choice of the old baseline and suggesting that newer 3D CNNs like X3D and SlowFast should be considered to reduce computation complexity. It also asks for a comparison with these newer approaches to highlight the advantages of the proposed method. This feedback is clear and actionable, as it prompts the authors to consider expanding their experiments to include more recent and relevant approaches. By addressing these points, the authors can enhance the credibility and comprehensiveness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4, as it directs the authors to improve their experimental setup and analysis."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the improvements over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is insufficient. However, it does not provide explicit guidance on what specific aspects of the analysis should be improved or how the authors should address the marginal improvements. The comment lacks actionable details, such as suggesting additional experiments, analyses, or comparisons that could be conducted to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the improvements over previous works and selfimplemented baselines, suggesting that they are marginal and that further analysis beyond the main experiments is insufficient. However, it does not specify which parts of the paper discuss these improvements or where the analysis is lacking. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper need revision. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is insufficient. However, the comment does not provide specific examples, detailed comparisons, or references to support this claim. Without concrete evidence or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is necessary. However, it does not provide specific guidance on what additional analysis could be conducted or how the authors might enhance their results. The feedback identifies a potential area for improvement but lacks depth and actionable suggestions, leaving the authors with a general direction but no clear path to follow. Therefore, the comment is 3, as it highlights a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the strong requirement of Gaussian features and noise for the theoretical result, and the lack of comparison with existing rates in the literature. The comment suggests that the authors should address these issues by relaxing the Gaussian assumption and comparing their rates with existing rates. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The actions are concrete, as they specify what needs to be done, but they are implicit in nature. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and the \"proposed algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the theoretical result, namely the strong requirement of Gaussian features and noise, and suggests comparing the rates achieved by the procedure with existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates with existing rates in the literature. The claim is 3 as it highlights a specific limitation of the theoretical result and provides a logical reasoning for why it is a concern. However, the comment lacks specific references or detailed comparisons with existing rates, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the strong requirement of Gaussian features and noise for the theoretical result. It points out that this assumption is a strong constraint on the data, especially given that previous algorithms do not require it. Additionally, the comment suggests that the authors should compare the rates achieved by their procedure with existing rates in the literature. This feedback is clear and actionable, as it highlights a critical area for improvement and provides a specific direction for enhancing the theoretical contribution of the paper. However, the comment could be more helpful if it offered suggestions on how to relax the Gaussian assumption or provided examples of existing rates for comparison. Overall, the comment is 4, as it effectively guides the authors toward improving their theoretical results and their paper\"s contribution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This comment implies that the authors should include a comparison with the original approach, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. However, the authors can infer that they need to include a comparison with the original approach, which provides some level of actionability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or analysis. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a comparison with the original approach, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This claim is 3 as it provides a logical reasoning for the comparison, suggesting that it would enhance the paper\"s evaluation. However, the comment lacks specific references or detailed reasoning about why this comparison is necessary or how it would contribute to the paper\"s findings. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the evaluation of the proposed extension. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its usefulness. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It explicitly states that the authors should include additional baselines, specifically mentioning three works that focus on similar questions. This provides a clear and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the addition of more experiments to demonstrate the effectiveness of the proposed method. The comment provides examples of other works that focus on similar questions, which further guides the authors on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It provides a specific reason for this suggestion by mentioning that there are several works that focus on similar questions, and it references specific examples ([1,2,3]). This provides a clear and logical basis for the claim, making it 5. The inclusion of specific references and examples supports the need for additional experiments, ensuring that the authors can understand and address the feedback effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section, noting that the authors have only compared their work with two baselines. It suggests that more experiments should be conducted to demonstrate the effectiveness of the proposed method, particularly by including additional baselines that focus on similar questions. The comment provides a clear and actionable suggestion by referencing specific works that could be included in the comparison. This feedback is valuable as it directs the authors to enhance the robustness and comprehensiveness of their experimental evaluation. However, the comment could be more helpful if it offered guidance on which specific baselines to include or how to structure the additional experiments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this perceived distraction or how to better align the paper with the reviewer\"s preference. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of these elements are distracting or how they could be better integrated into the main focus. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these aspects are distracting or how they could be better integrated. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not offer guidance on how the authors might better align their work with the reviewer\"s preference. Without actionable advice or constructive criticism, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed on the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This provides a clear action for the authors to take, which is to provide additional details on these aspects. The comment is explicit and concrete, as it specifies exactly what information is missing and how the authors can address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, specifically regarding the translation and filtering methodology. This claim is 3 as it highlights a potential gap in the paper, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology, which is crucial for assessing the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could significantly enhance the comprehensiveness and credibility of their dataset. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is an explicit request for additional data or analysis, but it does not specify how the authors should go about obtaining this information or what specific metrics or methods to use. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line number 170, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: information on how much performance difference using different image sizes and different variations of ResNets can lead to. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more information on how much performance difference using different image sizes and different variations of ResNets can lead to. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is a clear and actionable suggestion that could help the authors enhance the clarity and depth of their analysis. By addressing this point, the authors can provide a more comprehensive understanding of the impact of these variations on performance, which is valuable for readers and reviewers. However, the comment could be more helpful if it included specific guidance on how to present this information or what metrics to focus on. Overall, the feedback is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the algorithm should be presented and described in detail, which is a clear and explicit action for the authors to take. However, it does not provide specific guidance on how to present or describe the algorithm in detail, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. While the action is explicit, the lack of detailed instructions makes it somewhat vague, as the authors may not be entirely sure of the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail, which is a general request for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithm need more detail or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail, which is a claim that requires justification. However, the comment does not provide any specific reasoning, examples, or references to support why this level of detail is necessary or how it would benefit the understanding of the proposed method. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which is a valid point as it can help readers better understand the proposed method. However, the comment lacks specificity and does not provide guidance on how to achieve this level of detail or what aspects of the algorithm should be emphasized. Without actionable suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not provide enough detail to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. While the comment implies that the authors should include a runtime comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. However, it does not specify which part of the paper discusses this possibility, making it weakly grounded. The comment is specific in suggesting a particular type of comparison that could be included, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not present subjective judgments, suggestions, or deductions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This feedback is 3 as it points out a potential area for improvement by suggesting a specific analysis that could be included in the paper. However, the comment lacks depth and does not provide detailed guidance on how to conduct the runtime comparison or what aspects to focus on. While it offers a direction for enhancement, it does not fully support the authors in making the necessary improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work offering a way around this issue, the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is explicit in its suggestion to address the omission and provides a clear direction for the authors to improve their draft by adding a statement about the open problem. The action is concrete, as it specifies what needs to be done, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of FFNs or linear decompositions. The suggestion is specific in terms of what needs to be addressed, namely, acknowledging the lack of a solution and the open nature of the problem. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work offering a way around this issue, the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. The comment provides a logical reasoning for the suggestion, noting that the omission of FFNs could impact the paper\"s readability and overall understanding. However, it lacks specific references or examples of existing work that could provide an approximation or solution, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or references to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is 3 as it points out a specific area where the paper could be improved by providing additional context or acknowledging the limitations. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of similar work that has tackled this problem. Overall, the feedback is actionable but incomplete, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. While it implies that the authors should address these issues, the comment does not provide explicit instructions on how to do so. The questions are clear, but the lack of guidance on how to address them makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image number and the explanation of BYOL, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. These are relevant points that could help the authors improve their draft by addressing potential gaps in their explanation or methodology. However, the comment lacks specific guidance or suggestions on how to address these questions, such as recommending additional experiments or providing examples of how to explain BYOL. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the effectiveness of the method, specifically the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what kind of arguments or intuitions are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the effectiveness of the method, particularly regarding the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. However, the comment does not specify which part of the paper discusses the L_pixel component, making it weakly grounded. The comment is specific in its request for stronger arguments or intuitions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the observed effects are strong but questions the clarity of why the method works, particularly regarding the L_pixel component. The reviewer suggests that providing stronger arguments or intuitions about why these particular losses are beneficial would be welcome. However, the comment lacks specific examples or references to support the claim that the method is unclear or that the L_pixel component is not wellexplained. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s effectiveness, particularly the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation of the method\"s workings. However, the comment could be more helpful if it offered specific suggestions or examples of what kind of arguments or intuitions would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its suitability for assessing models\" understanding of finegrained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending alternative metrics or methods to assess the models\" understanding. As a result, the authors are left without a clear path forward to address the issue raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric, suggesting that it may not adequately assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses the binary classification or where the authors introduce the baseline metrics. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, while the comment provides some insight into the issue, it lacks specificity regarding what changes or improvements are needed to address the concern. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not adequately assess models\" understanding of finegrained errors like technique errors. The reviewer provides a logical reasoning by questioning the suitability of a coarsegrained binary classification for assessing a finegrained task. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its suitability for assessing models\" understanding of finegrained errors like technique errors. This is a relevant point that could impact the validity and effectiveness of the evaluation methodology. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left with a general critique but no clear path to improvement. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. The comment provides a logical reasoning by referencing existing work on LLM evaluation and the proposed desiderata, suggesting that the comparison would be beneficial. However, it lacks specific examples or references to the other metrics, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment provides a constructive suggestion for the authors to compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench. This comparison would help the authors understand the conditions under which their metric should be used, which is a valuable insight for improving the paper. The comment is specific and actionable, offering a clear direction for the authors to enhance their work. However, it could be more helpful if it included examples or references to specific metrics for comparison, which would provide even more detailed guidance. Overall, the comment is 4, as it offers a clear path for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of their draft. The comment lacks actionable details, such as identifying particular sections or aspects that need improvement or suggesting specific changes that could be made. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected or provide details on what aspects of the writing or annotations are problematic. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 as it does not refer to any specific sections, figures, or tables, and it is not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing or annotations are unclear, the authors may find it challenging to understand and address the issue. The comment lacks sufficient justification or evidence to be considered verifiable, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their draft. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 1, as it does not offer any actionable insights or direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While it highlights a potential issue with the method\"s performance, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they should investigate the performance metrics and their implications, but without concrete steps or actions, the comment remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance of the proposed method in terms of achieving SOTA performances and the F1 score in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. It highlights a discrepancy between the overall F1 score and the individual F1 scores for each type. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discrepancy exists or how it impacts the overall evaluation. Without additional context or explanation, the claim remains 1, as the authors are left without clear guidance on how to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the performance of the proposed method in Table 2, noting that only 8 of the 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy between the overall F1 score and the individual F1 scores for each type in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This feedback is clear and actionable, as it prompts the authors to investigate and explain these performance discrepancies, which could be critical for the validity and interpretation of their results. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered guidance on potential explanations for the observed performance. Overall, the comment is 4, as it directs the authors to a specific area needing clarification and improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. While the comment implies that the authors should reconsider their approach, it does not explicitly instruct them to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the approach, questioning the rationale behind the chosen methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. The comment provides a logical reasoning by implying that considering all reports would lead to a more comprehensive analysis. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the implications of including all reports to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. This feedback highlights a potential limitation in the methodology and prompts the authors to reconsider their approach. However, the comment does not provide specific suggestions or examples on how to address this issue or improve the methodology. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it 3. The authors gain insight into a possible weakness in their work but are not fully supported in making improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This implies that the authors should consider increasing the complexity of their instances to better test the LLMs\" ability to model problems with larger instance sizes. However, the comment does not provide specific guidance on how to achieve this, such as suggesting additional constraints or variables to include. While the action is implicit, it lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This raises a concern about the LLMs\" ability to model problems with large instance sizes. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact area needing revision. The comment is specific in suggesting more constraints and variables but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This raises a concern about the LLMs\" ability to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that the current instance sizes are insufficient. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the number of variables in the instances used for testing the LLMs\" ability to model problems. It suggests that generating instances with more constraints and variables could help address this concern. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to achieve this, such as recommending additional constraints or variables to include. Additionally, it does not provide a clear rationale or evidence for why this is important or how it might impact the results. Therefore, the comment is 3 as it points out a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative perspectives and baselines to consider, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific examples or references to support the claim that these alternative perspectives are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it identifies a potential area for improvement by suggesting alternative perspectives that could enhance the paper\"s contribution. However, the comment lacks specific guidance on which baselines to consider or how to implement these suggestions, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a brief conclusion and a summary of their contributions. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the paper\"s contributions, providing clear guidance on what needs to be addressed. However, it does not specify which part of the paper this feedback pertains to, such as the conclusion section or the introduction. While the authors can infer that it relates to the conclusion or summary sections, the lack of explicit reference makes it weakly grounded. The comment is specific in detailing what needs to be included, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions are needed. This is a request for clarification or improvement, not a claim that requires verification. It does not express an opinion, judgment, or suggestion that needs to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks a brief conclusion and a summary of its contributions. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s structure and clarity. By addressing this feedback, the authors can better guide readers on the paper\"s main findings and contributions. However, the comment could be more helpful if it offered additional guidance on how to effectively present the conclusion or summary. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, suggesting that the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or explain the problem further. The comment implies that the authors should provide an explanation, but it lacks concrete details on what kind of explanation is needed or how to present it. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the synthetic experiment in a nonseparable case, which is mentioned in the context of Figure 1. This provides full grounding as the authors can accurately identify the part of the paper being discussed. However, the comment lacks specificity because it does not detail what aspect of the experiment is problematic or how the authors should address the issue of separability. The suggestion to explain the inseparability of the data distribution from the network model is vague, leaving the authors without clear guidance on how to improve their draft. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, suggesting that the data distribution illustrated in Figure 1 is inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the synthetic experiment in a nonseparable case, suggesting that the data distribution illustrated in Figure 1 may not be separable from the network model. This is a relevant observation that could impact the validity of the experiment. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve their explanation. Without detailed suggestions or examples, the authors are left with a general concern but no clear path to resolution. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific critique of a statement on line 134, pointing out that it is only true for a specific function and suggesting that Theorem 4.1 should be elaborated on in the main text. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to elaborate on Theorem 4.1. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanation but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the statement on line 134 is only true for a specific function and suggesting that Theorem 4.1 should be elaborated on in the main text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques a statement on line 134, suggesting that it is only true for a specific function and that Theorem 4.1 should be elaborated on. The comment provides a logical reasoning by explaining that the statement depends on the maximum slope and that the RNN will converge to the nearest FP, which is a clear and logical explanation. However, it does not provide specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of a statement on line 134, pointing out that it is only true for a specific function and suggesting that Theorem 4.1 should be elaborated on in the main text. This feedback is clear and actionable, as it identifies a potential misunderstanding in the text and offers a suggestion for improvement by elaborating on the theorem. However, the comment could be more helpful if it included additional guidance on how to elaborate on the theorem or what specific aspects should be clarified. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment implies that this is necessary, it does not explicitly instruct the authors to do so. Additionally, it provides a rationale for why this is important, mentioning the standard practice in most papers on GPs and the potential time constraints due to dataset size. However, the comment lacks concrete guidance on how to implement this suggestion, such as the number of splits or folds to use. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"nearly all experiments\" and \"the results are reported for a single heldout test set,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. The comment provides a clear and specific suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. The reviewer provides a logical reasoning by stating that this is a standard practice in most papers on GPs and that it would give a more accurate representation of the method\"s performance. However, the comment lacks specific examples or references to support the claim that using a single heldout test set is insufficient. While the reasoning is clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single heldout test set, which is not standard practice in most papers on GPs. The reviewer suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. While the comment highlights an important issue, it does not provide specific guidance on how to implement this suggestion, such as the number of splits or folds to use. Additionally, it does not explain why this is important or how it might impact the interpretation of the results. Despite these limitations, the comment provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple comments, each addressing different aspects of the paper. The first comment suggests toning down the statement about the neural network memorizing critical points, providing a specific reference to TopoNet [24] to support the suggestion. This is an explicit action with concrete guidance on how to improve the draft. The second comment suggests compressing the method section and correcting grammatical errors, which are also explicit actions with some level of detail. However, the comment does not specify which grammatical errors need correction, making it somewhat vague. Overall, the comment provides clear and actionable feedback, but the lack of detailed guidance on grammatical errors limits its full actionability. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"34\" and \"the method section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as toning down a statement about neural networks memorizing critical points, compressing the method section, and correcting grammatical errors. The comment even provides a specific example of a grammatical error (\"l\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about the neural network not memorizing critical points is supported by a reference to TopoNet [24], which provides a logical basis for the claim. The suggestion to tone down the statement is reasonable and aligns with the evidence provided. The second comment about the method section being wordy and suggesting compression is a logical suggestion based on common knowledge of writing style. The third comment about grammatical errors is factual and does not require verification. Overall, the comment is 4, as it provides logical reasoning and references for the first claim, while the second and third points are factual. Therefore, the score is 4.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improvement. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and logical suggestion that could enhance the clarity and accuracy of the paper. Additionally, it points out that the method section could be compressed to focus on essential definitions, which is a clear and constructive feedback. The comment also highlights grammatical errors, which is important for clarity and professionalism. However, the comment could be more helpful if it provided specific examples of grammatical errors or suggestions for improvement. Overall, the feedback is 4 as it offers clear and actionable guidance for enhancing the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or address this point in the draft, nor are there suggestions for improvement or alternative phrasing. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the phrase \"initial rationale selector is perfect\" and provides a logical critique by suggesting that if it were perfect, no additional work would be needed. This specificity helps the authors understand what needs to be clarified or addressed in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this assumption is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This critique highlights a potential inconsistency or misunderstanding in the paper, which could be clarified or addressed by the authors. However, the comment does not provide specific suggestions or guidance on how to resolve this issue or improve the clarity of the text. While it identifies a potential area of confusion, it lacks actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for specific details regarding the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of domain ontologies and asks for details regarding the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It does not contain a claim or opinion but rather seeks clarification on a specific aspect of the methodology. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also requests information on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment identifies a potential area for improvement and provides a clear direction for additional information, it does not offer detailed guidance or suggestions on how to address the issue. The feedback is 3 as it prompts the authors to consider a relevant aspect of their methodology and provides a specific request for additional data. However, it could be more helpful if it included suggestions on how to incorporate domain ontologies or how to present the requested information effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include additional citations to set their work in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay with respect to exploration and coordination. The comment provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This guidance is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for additional citations to set the work in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically referencing recent papers on selfplay and populationplay with respect to exploration and coordination. The authors can accurately identify the part of the paper that needs improvement, which is the literature review or context section. The comment is also specific because it provides examples of relevant papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks citations to place it in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail and reference to specific works supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these references would enhance the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks citations to place it in the context of other MultiAgent Reinforcement Learning (MARL) work, particularly recent papers on selfplay and populationplay with respect to exploration and coordination. The comment provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which helps the authors understand the exact references they should consider. This feedback is clear and actionable, guiding the authors on how to enhance the context and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is an explicit action that provides a clear direction for the authors to follow. However, it does not specify which specific methods should be compared or how to conduct the comparison, leaving some room for ambiguity. While the action is explicit, it lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to incorporate this comparison. Additionally, the comment lacks specificity regarding which specific methods should be compared or how the comparison should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the work with other selfsupervised learning methods that are not based on contrastive learning. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This feedback is 3 as it points out a potential gap in the paper\"s comparison and suggests a direction for further exploration. However, the comment lacks specificity regarding which specific methods should be considered or how the comparison should be conducted. Without detailed guidance, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is rated as 3, as it provides a general direction but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar size. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion might also apply to these other approaches. The comment also raises a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. While the comment implies that the authors should reconsider their claims about parameter efficiency and provide more context on the experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issues raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Megatron\" and \"COCOLM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the overrated comparison with Megatron and suggesting that the performance of COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. Additionally, it raises a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the comparison with Megatron is overrated, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This claim is 3 as it provides a logical comparison with other models of similar size, but it lacks specific data or detailed analysis to fully substantiate the claim. The inclusion of a question about the experimental setup adds some context but does not significantly enhance the verifiability of the main claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the overrated comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar size. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion might also apply to these other approaches. Additionally, the comment includes a question about the experimental setup, asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. This feedback is 3 as it points out a potential issue with the comparison and provides a specific question for the authors to address. However, it could be more helpful if it offered suggestions on how to address the issue or provided additional context on why the comparison with Megatron might be overrated. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare with a chainofthought prompting approach, providing a concrete example of a more meaningful baseline. This feedback is clear and actionable, as it directly instructs the authors to include a specific comparison that would enhance the robustness of their analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically mentioning that the authors limit their comparisons to simple naive baselines. The reviewer suggests comparing with a chainofthought prompting approach as a more meaningful baseline. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how the current baselines are insufficient. The suggestion for a chainofthought prompting approach is a logical next step, but the comment could be strengthened by explaining why the current baselines are inadequate or how the chainofthought approach would provide a more meaningful comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that the authors limit their comparisons to simple naive baselines, suggesting that this limits the robustness of the analysis. The comment provides a specific suggestion for improvement by recommending a comparison with a chainofthought prompting approach, which would offer a more meaningful baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance the depth and rigor of their study. However, it could be more helpful if it included additional suggestions or examples of other potential baselines to consider. Overall, the comment is 4, as it effectively guides the authors toward improving the quality of their comparisons."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should clarify this aspect in their paper. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process for the cardiac signal representation learning model, specifically asking whether it is trained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in its inquiry about the pretraining process and generalization, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the pretraining process for the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. This question is relevant and could help the authors clarify their methodology, potentially leading to improvements in the robustness and generalizability of their model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular approach or methodology. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific changes should be made to improve the draft. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper this applies to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding which observations or design decisions are hardware or software dependent, leaving the authors without clear guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. This is a relevant observation that could impact the generalizability and applicability of the findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or mitigate its impact. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it highlights a potential concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section should include an indepth exploration of the reasons for the experimental results. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the indepth exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics in the experimental analysis section. It suggests that there should be an indepth exploration of the reasons for the experimental results. However, it does not specify which part of the experimental analysis section needs this exploration, making it weakly grounded. The comment is specific in its request for an indepth exploration, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It further suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that no new evaluation metrics are proposed and that existing metrics are merely linearly combined. It also suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by introducing novel evaluation metrics and providing a more comprehensive analysis of the experimental results. However, the comment could be more helpful if it offered specific suggestions on how to introduce new metrics or what aspects of the experimental analysis should be explored. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the notation should be changed, clarified, or if there is a better way to differentiate between these two uses. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (L166 and L176) where the notation \"K\" is used for different purposes. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, namely its misuse for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the notation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused, as it is used for both a known kernel function and the number of layers. This claim is 3 as it highlights a potential issue with notation consistency. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more detailed examples or context would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion in the paper. By pointing out this inconsistency, the comment provides the authors with a specific area to address and clarify, which can significantly improve the clarity and readability of their draft. However, the comment could be more helpful if it suggested alternative notations or provided guidance on how to differentiate between these two uses of \"K.\" Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential limitation of the weak recovery problem studied in the paper, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue or improve the practical impact of the AMP algorithm. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practical impact of the weak recovery problem studied in the paper, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not provide detailed guidance on how to address the issue or improve the practical impact. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the weak recovery problem studied in the paper is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the weak recovery problem studied in the paper, suggesting that it may not have significant practical impact due to the AMP algorithm\"s limited usefulness for nonGaussian problems. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the practical relevance of their work. Without detailed feedback or constructive advice, the authors are left without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their statement. The action is implicit and vague, as the authors are left to infer that they need to provide more context or references to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper regarding the relevance of bringing connections to human cognition into the study. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for more context and references to support the claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer challenges the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. The comment provides a logical reasoning by contrasting the authors\" claim with the reductionist nature of the problem, but it lacks specific references or examples to fully substantiate the claim. This makes the comment 3, as it provides a logical basis but requires more detailed evidence or references to be fully convincing.", "helpfulness_rationale": "The review comment raises a valid concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. The comment also points out the need for more citation and comparison against \"previously appreciated\" work. While the comment identifies a potential issue and provides some direction for improvement, it lacks specific suggestions or detailed guidance on how the authors might address this concern. Therefore, it is 3, as it prompts the authors to reconsider their approach and provides a basis for further exploration, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback implies that the authors should include such comparisons to demonstrate the effectiveness of their proposed approach. However, the comment does not provide specific guidance on which baselines to consider or how to conduct the comparison. While the action is clear\u2014adding comparisons to demonstrate effectiveness\u2014the lack of concrete details on how to implement this makes the comment 3. The authors know they need to compare to baselines but may struggle to determine the exact steps to take.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing the need for such comparisons to prove the effectiveness of the proposed approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s biggest weakness is the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, the comment does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or how it would improve the paper. Without specific reasoning or examples, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback is important as it highlights a gap in the paper\"s evaluation, which could impact the credibility of the proposed approach. However, the comment does not provide specific suggestions on which baselines to consider or how to conduct the comparison, leaving the authors with a general direction but without detailed guidance. While the feedback is 3 in pointing out a critical area for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a gap in the explanation and suggests the need for clarification, it does not provide explicit instructions on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"historical observations\" and \"inputs known over all time,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how these observations are combined and fed into the CSCM, particularly in the context of differences in sequence lengths. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embedding and addition with positional encoding but lacks clarification on how these elements are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations in the paper. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of similar approaches. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more discussion on the power of different architectures, but without clear grounding, the authors may struggle to determine where this discussion should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. The comment does not offer detailed feedback or examples of what additional discussion could include, leaving the authors with a general idea of what might be lacking but without a clear path to improvement. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an alternative approach for obtaining robust results, but without grounding, it is challenging for the authors to know where to implement this change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. The comment provides a logical reasoning for why this approach would be beneficial, as it addresses potential issues with initialisation bias. However, it does not provide specific examples or references to support this claim, which would strengthen the argument. Therefore, the comment is 3, as it offers a logical rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. This feedback is 3 as it points out a potential limitation in the current experimental setup and offers a suggestion for improvement. However, the comment lacks specific guidance on how to implement this suggestion or what specific aspects of the trainvaltest splits should be considered. While it provides a direction for enhancing the robustness of the results, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the first two bullets about contributions in the introduction can be combined. This is an explicit action, as it directly instructs the authors to make a specific change to their draft. However, it does not provide detailed guidance on how to combine these bullets or what specific changes should be made to improve the clarity or flow of the text. While the action is explicit, it lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions (at the end of the intro),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the suggestion to combine the first two bullets about contributions. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the first two bullets about contributions in the introduction can be combined. However, it does not provide any reasoning or justification for why this combination would be beneficial or how it would improve the clarity or flow of the text. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the introduction, suggesting that the first two bullets about contributions can be combined. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and organization of the introduction. By combining these bullets, the authors can streamline the presentation of their contributions, making it more concise and easier for readers to understand. However, the comment could be more helpful if it explained why these bullets should be combined or how it would benefit the overall structure of the introduction. Despite this, the feedback is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. While the comment implies that the authors should refer to recent trends in the vision community, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these references or demonstrate the improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting what needs to be addressed, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. The comment provides a logical reasoning by highlighting the importance of these aspects for the paper\"s contribution. However, it lacks specific references or examples to support the claim, making it 3. The authors would need to provide additional evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. This feedback is 3 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific examples or references to recent trends in the vision community that the authors could consider. Overall, the feedback is actionable but incomplete, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies areas where the paper could be improved, it does not provide explicit guidance on how to address these issues or specific suggestions for enhancing the novelty or insights. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete steps or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, specifically mentioning the application of existing literature, such as DeCorr, in a specific domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the introduction and discussion sections, where the novelty and contributions are typically discussed. The comment is specific in detailing what aspects of the paper are lacking in terms of novelty and insights. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, stating that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer provides a detailed explanation of how the paper merely transposes DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. Additionally, the comment mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or examples where the lack of novelty is evident, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment points out a potential weakness, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the uniqueness of their contribution, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the data in Table 4, which indicates the importance of unsupervised pretraining, and the lack of detailed discussion on this topic in the main paper. The reviewer suggests focusing more on the pretraining method in the main paper, implying that the authors should provide a more indepth analysis of this aspect. While the comment explicitly states the need for more focus on pretraining, it does not provide specific guidance on how to achieve this or what aspects of the pretraining method should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the pretraining method but may not be entirely clear on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the main paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining, which is a key factor in the performance gain, as indicated by the data in Table 4. The comment further suggests focusing more on the pretraining method in the main paper, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. However, it notes that there is no detailed discussion on this in the main paper, which might be a problem. The reviewer further suggests focusing more on the pretraining method in the main paper, based on the comparison with the ablation study in Table 5. While the comment provides some reasoning and references to specific tables, it lacks detailed evidence or examples to fully substantiate the claim. The suggestion to focus on pretraining is logical but could be strengthened with more detailed analysis or references. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of detailed discussion on the unsupervised pretraining method, despite its apparent importance in achieving performance gains. By referencing Table 4 and the ablation study in Table 5, the reviewer provides a clear basis for the suggestion to focus more on the pretraining method in the main paper. This feedback is actionable and provides a specific area for the authors to enhance their draft, making it 4. However, the comment could be more helpful if it offered suggestions on how to structure or present the additional discussion on pretraining. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender at inference time. It also suggests that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the choice of ELM and its implications for accuracy. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the choice of ELM and its implications for accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a drawback or how it affects the accuracy. The lack of detailed justification makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to be 5.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of ELM (male/female) and its implications for accuracy. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which could be a drawback if the speaker\"s gender is not known at inference time. This feedback is clear and actionable, as it prompts the authors to consider the implications of their choice of ELM and how it might affect the accuracy of their model. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how other researchers have handled similar challenges. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide an intuition for the proof of Theorem 1 and asks questions about the invertible function $f^*$ and its dependence on the fixed $P^*$. It also inquires about the practical implications of determining which $P^*$ to fix. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide an intuition for the proof and address the questions about $f^*$ and $P^*$. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for an intuition of the proof and inquiring about the dependence of the invertible function $f^*$ on the fixed $P^*$. Additionally, it raises questions about the practical implications of determining which $P^*$ to fix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, such as asking for an intuition of the proof of Theorem 1 and inquiring about the dependence of the invertible function $f^*$ on the fixed $P^*$. These questions are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of questions and suggestions that could help the authors improve their draft. It asks for an intuition of the proof of Theorem 1, which could enhance the reader\"s understanding of the theoretical foundation. Additionally, it inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. This prompts the authors to consider the practical implications of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or provided examples of similar approaches in the literature. Overall, the feedback is 3 as it identifies areas for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the use of variables in equations (7) and (10), specifically questioning why one uses \"X\" and the other \"H^(1).\" While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this inconsistency. The authors are left to infer that they need to clarify or justify the choice of variables, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it questions the inconsistency in the use of variables, specifically \"X\" and \"H^(1),\" and asks for an explanation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the inconsistency in the use of variables in equations (7) and (10). It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry that does not contain a claim, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inconsistency in the use of variables in equations (7) and (10), specifically noting the use of \"X\" in one equation and \"H^(1)\" in the other. This feedback is 3 as it points out a potential issue that the authors need to address, such as clarifying the rationale behind the variable choices or ensuring consistency across equations. However, the comment does not provide specific guidance on how to resolve this inconsistency or suggest alternative approaches. While it prompts the authors to consider this issue, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the applicability of the model to realworld diffusion processes and suggests that the authors provide empirical evidence to support this claim. While the comment implies that the authors should conduct empirical studies to validate the model\"s applicability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the empirical studies or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to support this claim. However, it does not specify which part of the paper this concern pertains to, such as the methodology, results, or discussion sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its request for empirical evidence, it is 1 because it does not identify the specific section or aspect being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to support this claim. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate why the model might not be applicable in realworld scenarios. This lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the basis of the concern and develop their own evidence to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the novelty and elegance of the proposed solutions but highlights the need for empirical evidence to validate the model\"s applicability in realworld scenarios. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address by conducting empirical studies or providing additional evidence. However, the comment could be more helpful if it offered suggestions on how to conduct these empirical studies or what specific aspects of the model should be tested. Overall, the comment is 4 as it directs the authors to a crucial area for enhancing the validity and applicability of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this critique. It lacks guidance on how the authors might address the perceived lack of novelty or improve their contribution. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper these aspects are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not detail what aspects of the ENCODE part or the decomposition part are problematic or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment does not provide any references or detailed reasoning to support this claim, such as comparing the proposed method to the existing work in [10] or explaining how the decomposition part differs from previous approaches. Without specific evidence or detailed analysis, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While the comment implies that the authors should clarify this information, it does not provide explicit guidance on how to address the issue or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the domain of the inputs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the domain of the inputs, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While this question identifies a potential gap in the paper, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment does not offer suggestions for clarifying the domain of the inputs or how this information could be integrated into the paper. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by [A]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should conduct a performance comparison, how to do it, or what specific aspects should be considered. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by [A]. However, it does not specify which part of the paper discusses this algorithm or where the performance comparison should be included. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in asking for a performance comparison but does not provide detailed guidance on how to conduct it or what aspects to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for a performance comparison with the CLN (region proposal generation algorithm) proposed by [A]. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by [A]. While it identifies a potential area for improvement by suggesting a performance comparison, it lacks specificity and does not provide guidance on how to conduct such a comparison or what aspects to focus on. The comment is 3 as it points out a gap in the paper but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in Chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in Section 3 would be helpful. While the comment implies that the authors should consider adding such a figure, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a figure and determine what specific concepts should be illustrated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the presentation, noting that it is too equationdriven and that the notation is convoluted, making it hard to follow. The suggestion to include an illustrative figure of key concepts in section 3 is clear and provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in Chapter 3 is convoluted, making it hard to follow. The suggestion to include an illustrative figure of key concepts in Section 3 is a logical recommendation to improve clarity. However, the comment lacks specific examples or detailed reasoning to support the claim that the notation is particularly challenging. This makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure of key concepts in Section 3 would be helpful. This feedback is clear and actionable, providing the authors with a specific direction for improving the clarity and accessibility of their work. By suggesting a visual aid, the comment offers a concrete way to enhance the readability and understanding of the content. However, it could be more helpful if it provided additional guidance on which specific concepts should be illustrated or how the figure should be structured. Overall, the comment is 4 as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It suggests that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is explicit and provides a clear action for the authors to take: investigate and resolve the apparent contradiction between the second rule and the definition of minimal conditional dependence. The comment is 5 as it specifies the exact issue and guides the authors on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule and the definition of minimal conditional dependence. The comment provides a specific example by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. The reviewer provides a logical reasoning by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing relevant literature or providing more detailed explanations of the conflict. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It provides a specific example by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is clear and actionable, as it directs the authors to investigate and resolve the apparent contradiction. By pointing out this specific issue, the comment offers a concrete way for the authors to improve their draft, making it 5. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, it does not provide explicit guidance on how to enhance the visual presentation or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the visual presentation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular aspect of the visual presentation, namely the subscripts, and suggests that they could be improved for better readability and aesthetic appeal. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be improved for better readability and aesthetic appeal. This feedback is 3 as it points out a potential area for enhancement, which could improve the overall clarity and impact of the figure. However, the comment lacks detailed guidance or suggestions on how to enhance the visual presentation, such as proposing specific changes to the subscripts or offering examples of better practices. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It further suggests that this is grounds for rejection because it effectively violates the 9page paper limit. The comment provides a clear and direct action for the authors to address, which is to increase the whitespace in their paper to comply with the page limit. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace, crammed equations, and captions too close to figures, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the problem of violating the 9page paper limit due to these formatting issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9page paper limit. However, the comment lacks specific examples or references to support the claim, such as screenshots or detailed explanations of how the whitespace reduction affects the readability or compliance with the page limit. Without such evidence, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9page paper limit. While the comment highlights a critical issue, it lacks actionable suggestions or guidance on how the authors might address this problem. It does not provide insights into how to improve the formatting or suggest alternative approaches to ensure compliance with the page limit. As a result, the feedback is 3, as it points out a significant issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the clarity of the concept of \"local interactions,\" asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this concept. The action is implicit, as the authors need to infer that they should provide additional explanation or clarification to address the confusion. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the issue of clarity but lacks grounding as it does not mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. This is a request for clarification rather than a claim or opinion, as it does not express a subjective judgment or suggestion for improvement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential area of confusion regarding the concept of \"local interactions\" in the paper. It raises a specific question about whether this term refers to interactions within a time window or within the same modality. This feedback is 3 as it prompts the authors to clarify this concept, which could enhance the clarity and understanding of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as recommending additional explanations or examples. Therefore, it is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors should address this issue, such as suggesting ways to improve the validity or diversity of the results or explaining the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning the validity and diversity of the proposed constrained method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents better results in the Molecule generation experiment (Table 3), but it questions the validity and diversity of the proposed constrained method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. This is a relevant observation that could prompt the authors to reconsider their claims or provide additional analysis to support their results. However, the comment lacks specificity and does not offer actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or suggestions for improvement, the authors may find it challenging to effectively respond to this critique. Therefore, the comment is 3, as it identifies a potential issue but does not provide enough detail to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the process of updating archetype positions after initialisation in Algorithm 2. It explicitly requests the authors to provide a comment on this aspect, which is a direct and clear action. The comment provides a specific area of interest, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is 5, as it gives the authors a clear direction on how to improve their draft by providing additional information.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the unclear process of updating archetype positions after initialisation. The comment requests clarification on this aspect, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the process of updating archetype positions after initialisation in Algorithm 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which is consistent with the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty in the paper regarding the process of updating archetype positions after initialisation in Algorithm 2. It requests clarification on this aspect, which is a clear and actionable suggestion for the authors to address. By providing this feedback, the reviewer helps the authors improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional guidance or examples on how to clarify this process. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further suggestions or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies several areas where additional information is missing from the empirical study, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These explicit requests provide clear actions for the authors to take, and the comment is specific about what information is needed. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what information is missing, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, a brief explanation of the harmonization technique, and the number of regions in the parcellation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions about the empirical study, such as the recording parameters for MRI, preprocessing steps, restingstate recording conditions, and the harmonization technique. These questions are factual and do not contain subjective claims or opinions that require verification. The comment is primarily seeking clarification and additional information, which is consistent with a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These specific requests provide clear and actionable feedback that can help the authors improve the comprehensiveness and clarity of their study. By addressing these points, the authors can enhance the transparency and reproducibility of their work. Therefore, the comment is 4, as it offers detailed guidance on areas that need improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment implies that crossdataset experiments are necessary to test the generalization of such work, which the paper lacks. While the comment identifies a specific issue and suggests a potential solution, it does not provide explicit instructions on how to implement crossdataset experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for crossdataset experiments and determine how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential risk of methods exploiting relationships between action units, particularly the variability in these relationships across datasets. The comment provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. Additionally, it recommends performing crossdataset experiments to test the generalization of the work, which the paper lacks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point highlights a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment also recommends performing crossdataset experiments to test the generalization of the work, which the paper lacks. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides a specific example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment also recommends performing crossdataset experiments to test the generalization of the work, which the paper lacks. This feedback is clear and actionable, as it highlights a specific issue and provides a concrete suggestion for improvement. By addressing the generalization of the work, the authors can enhance the robustness and applicability of their methods. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more description of the Starcraft environment, possibly in an appendix. While the comment implies an action, it does not explicitly instruct the authors to add this description or specify where it should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more description and determine where it should be placed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The suggestion to include more information is specific, as it identifies a particular aspect that could be improved. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning or examples to support why this additional description is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the need for this change. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the paper could benefit from more description of the Starcraft environment, potentially in an appendix. While it identifies a specific area for improvement, it lacks detailed guidance or suggestions on what aspects of the environment should be described or how this additional information would enhance the paper. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable with specific suggestions or examples. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the timeconsuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues or what aspects of processing efficiency should be described or compared. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model\" and \"parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the timeconsuming nature of the training process due to the pixellevel training of the shape model and the independent training on all font images and characters. Additionally, it suggests that the processing efficiency of training and testing should be described and compared with existing work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the shape model training is timeconsuming due to its pixellevel training and independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors. However, the comment lacks specific evidence or references to support these claims, such as comparisons with existing work or detailed explanations of the timeconsuming aspects. Without such evidence, the claim remains 3, as the authors would need to investigate and substantiate the claims themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas that could be improved in the paper. It points out the timeconsuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors, suggesting that the processing efficiency of training and testing should be described and compared with existing work. This feedback is clear and actionable, as it highlights specific aspects of the methodology that could be improved and provides a direction for further analysis and comparison. However, the comment could be more helpful if it offered specific suggestions on how to improve the efficiency or provided examples of existing work for comparison. Overall, the comment is 4, as it guides the authors toward enhancing the clarity and efficiency of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of innovation in the authors\" framework, noting that it combines existing techniques without proposing new methods. It specifically critiques the use of an old and simple domain adaptation method and suggests exploring other, more recent and effective methods to improve performance. While the comment implies that the authors should consider using alternative domain adaptation methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on which methods to explore or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of existing techniques and the use of an old and simple domain adaptation method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the lack of innovation and suggests exploring other, more recent and effective domain adaptation methods to improve performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" framework combines existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that are both proposed by prior work. The comment further critiques the use of an old and simple domain adaptation method, suggesting that more recent and effective methods could be explored to improve performance. While the comment provides some reasoning by referencing the age of the domain adaptation method, it lacks specific examples or references to recent, effective methods that could be used instead. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" framework, noting that it combines existing techniques without innovation. It points out that the domain adaptation method used is old and simple, suggesting that more recent and effective methods could be explored to improve performance. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a direction for enhancing the framework. However, the comment could be more helpful if it offered examples of alternative domain adaptation methods or provided a more detailed explanation of why the current method is insufficient. Overall, the comment is 4, as it guides the authors toward a potential enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of the motivation or address the perception of the paper being incremental. The comment lacks actionable details, such as what aspects of the motivation are unclear or how the authors might reframe their work to better align with the reviewer\"s expectations. As a result, the authors are left without a clear understanding of what changes are needed to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not specify which part of the paper is unclear or what aspects of the motivation are challenging to follow. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental engineering. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is difficult to follow the motivation of the paper and labels it as an \"incremental engineering paper.\" However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on what aspects of the motivation are unclear or how the paper could be reframed to better align with the reviewer\"s expectations, the authors are left without a clear path for enhancing their draft. Therefore, the comment is 1, as it does not offer any constructive feedback or direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial. It provides a specific example of a scenario where the weighting method might have helped, such as in the Atlantis game where repetitive background sounds could be addressed. While the comment implies that the authors should conduct this ablation study, it does not explicitly instruct them to do so. The action is concrete but implicit, as the authors can infer the need for an ablation study based on the suggestion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, specifically mentioning the Atlantis game as an example where the weighting method might have helped. This provides a clear and specific suggestion for improvement, but it does not explicitly mention which part of the paper this suggestion pertains to. The authors can infer that it relates to the experimental setup or results section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial, particularly in the context of the Atlantis game where repetitive background sounds could be addressed. The reviewer provides a specific example of a scenario where the weighting method might have helped, which adds some level of justification to the claim. However, the comment lacks detailed reasoning or references to support the claim that the weighting method would be beneficial in other scenarios. While the suggestion is logical, it could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the weighting method of the crossentropy loss, which is a specific and actionable recommendation. It provides a concrete example from the Atlantis game, where repetitive background sounds could be addressed using the weighting method. This feedback is clear and offers a clear direction for the authors to improve their work by exploring the impact of different weighting methods on their model\"s performance. However, the comment could be more helpful if it included additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it designs a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might enhance the novelty or incremental nature of their work, or how they could improve their dataset design or benchmark comparison. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It provides specific details about the paper\"s focus on column operations in designing semantic parsers for TexttoSQL and the creation of a new dataset based on a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issues with novelty and incremental nature, providing a clear understanding of what needs to be addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically mentioning the use of a different train/test split of an existing dataset, SQUALL. However, the comment does not provide any specific examples or references to support this claim, such as comparing the paper to other works in the field or discussing how the proposed dataset differs from existing ones. This lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it designs a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this lack of novelty or incremental nature. Without actionable feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it provides insight into a significant weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback provides a clear and direct action for the authors to take, specifying both what needs to be done (explaining the importance of removing these assumptions) and how to do it (using solid examples). The explicit nature of the instruction and the concrete guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of removing these assumptions and the need for solid examples to support this claim. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are significant or how their removal impacts the contribution of the paper. Without such support, the claim remains vague and 1, as the authors are left without a clear understanding of what specific aspects need to be addressed or why they are important. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more explanation and justification. It points out the importance of removing certain assumptions, such as bounded variance and bounded gradients, and suggests that this should be supported by solid examples. This feedback is clear and actionable, as it directs the authors to enhance their paper by providing a rationale for the significance of these assumptions and how their removal contributes to the paper\"s contribution. However, the comment could be more helpful if it offered suggestions on how to present these examples or provided additional context. Overall, the comment is 4, as it guides the authors toward improving their draft by addressing a critical aspect of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to address the issues of speed or accuracy, nor are there suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the implementation or accuracy are problematic. Without clear grounding and specificity, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific times and accuracy rates. This claim is 3 as it provides quantitative data to support the assertion. However, the comment lacks detailed reasoning or references to specific methods or benchmarks used for comparison, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address these issues or enhance their implementation. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The comment implies an action by questioning the current approach and suggesting a potential improvement, but it lacks concrete details on how to execute this suggestion. Therefore, the comment is 3, as the authors can infer the need for further exploration but are not given explicit instructions on how to proceed.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not specify which part of the paper this suggestion pertains to. The authors can infer that it relates to the methodology or experimental setup sections, but without explicit references, the comment is weakly grounded. However, it is specific in suggesting a potential improvement by utilizing labeled data for consistency training. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but this claim is not fully supported by the provided references. The references are relevant to graph contrastive learning, but they do not directly address the specific question of using labeled data for consistency training. The comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, which might enhance the model\"s ability to deal with the task of graph anomaly detection. However, the comment does not provide specific guidance or suggestions on how to implement this idea or what specific aspects of the labeled data could be leveraged for consistency training. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a direction for exploration but lacks actionable steps for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental part needs to be reorganized and further improved. It provides a clear action for the authors to take by suggesting that the experimental content in the main text should highlight the superiority of the method. The comment also offers specific guidance by listing the characteristics that should be included in the experimental suggestions. This provides concrete details on how to implement the suggested changes, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, namely, the reorganization and enhancement of the experimental content to better highlight the superiority of the method. The comment suggests including specific characteristics in the experimental suggestions, which provides detailed feedback on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. However, it does not provide specific examples or detailed reasoning to support why the current organization is inadequate or how it could be improved. The comment lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section, noting that it lacks clarity in highlighting the superiority of the method. It suggests that the experimental content should be reorganized to better showcase the advantages of the method. Additionally, the comment provides specific guidance by listing characteristics that should be included in the experimental suggestions, such as the novelty and effectiveness of the method. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft. However, it could be more helpful if it included examples or detailed suggestions on how to reorganize the experimental content. Overall, the comment is 4, as it provides valuable insights and actionable steps for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the ERM and plugin methods have similar performance to Kearns et al. in Experiment 2, it would be beneficial to have the code published. While the comment implies that the authors should address the discrepancy in training times and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the code should be published. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the German and Law school dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the reasonableness of the training time discrepancy between the German and Law school dataset and Independent in the context of Gerrymandering. Additionally, it suggests that since the ERM and plugin methods have similar performance to Kearns et al. in Experiment 2, it would be beneficial to have the code published. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the ERM and plugin methods have similar performance to Kearns et al. in Experiment 2, it would be beneficial to have the code published. However, the comment lacks specific evidence or reasoning to support the claim about the training time discrepancy or the need for code publication. The suggestion is based on a logical inference but does not provide detailed justification or references to substantiate the claim. Therefore, the comment is considered 2, as it requires more detailed evidence or explanation to be 5.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the ERM and plugin methods have similar performance to Kearns et al. in Experiment 2, it would be beneficial to have the code published. This feedback is 3 as it points out a potential inconsistency in the experimental results and suggests a way to address it by publishing the code. However, the comment could be more helpful if it provided specific guidance on how to analyze or interpret the training time discrepancy or if it offered suggestions on how to improve the presentation of the results. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment implies that the authors should provide additional explanations or examples to clarify these points. While the action is implicit, it is concrete in suggesting what needs to be addressed, such as describing alternate formulations or clarifying the role of entropy. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, specifically asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment references specific lines in the paper (lines 113 and 115), providing full grounding as the authors can accurately identify the parts being addressed. However, the comment lacks specificity as it does not provide detailed guidance on what aspects of CD should be clarified or how alternate formulations could be described. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current form of CD and suggesting that it lacks clarity. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning and potentially conduct additional research to address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It questions the current form of CD and asks why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This feedback is clear and actionable, as it prompts the authors to provide additional explanations or examples to clarify the concept of CD and its relationship to entropy. However, the comment could be more helpful if it offered specific suggestions on how to present these alternate formulations or provided examples of how entropy might be a better measure. Overall, the comment is 4 as it directs the authors to enhance the clarity and depth of their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. The comment also points out that the abstract mentions beating the human baseline, which is misleading given the limited data the human baseline was exposed to. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as it identifies a problem but does not offer specific steps for resolution. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"the abstract,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. Additionally, it critiques the abstract for being misleading given this limitation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours, which is a significant factor in the comparison. The comment also critiques the abstract for being misleading, given this limitation. However, the claim lacks specific examples or references to support the assertion about the human baseline being weaker. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it is weaker than the model baseline due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. This observation is important as it highlights a potential flaw in the comparison between the human and model baselines. The comment also points out that the abstract is misleading by suggesting that the model has already beaten the human baseline, which is not accurate given the limited data the human baseline was exposed to. However, the comment does not provide specific suggestions on how to address this issue or improve the draft. While it highlights a critical problem, the lack of actionable guidance limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the assumption for termination states of instructions, noting that it is expensive to label a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods or strategies for labeling data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, which implies that it relates to the methodology or experimental setup. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in pointing out the issue with labeling a large number of data manually, but it lacks detailed guidance on how to address this problem. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is strong and that labeling a large number of data manually is expensive. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, noting that it may be expensive to label a large number of data manually. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of them is used as a baseline. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including these methods as baselines, but it lacks concrete details on which methods to include or how to integrate them into the study. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of them is used as a baseline. This provides clear guidance on what needs to be addressed, such as including these methods as baselines. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This claim is 3 as it highlights a gap in the related work section, but it lacks specific examples or references to the methods discussed. Providing more detailed information or examples would strengthen the justification for the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of them is used as a baseline. This feedback is 3 as it points out an area where the authors could enhance their work by including these methods as baselines for comparison. However, the comment lacks detailed guidance on which specific methods to consider or how to integrate them into the study. To be more helpful, the comment could suggest potential methods or provide examples of how to incorporate them into the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the paper regarding the use of the term \"Efficient Proxy.\" The reviewer suggests that the authors clarify whether they are referring to a specific proxy or a family of proxies. While the comment identifies a specific issue with the terminology, it does not provide explicit guidance on how to address this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and possibly provide examples or definitions to avoid confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It suggests that the authors need to clarify whether they are referring to a particular proxy or a family of proxies. However, the comment does not specify which part of the paper this ambiguity occurs in, making it weakly grounded. The comment is specific in identifying the issue with the terminology but lacks grounding, as the authors cannot confidently determine the exact section or context where this ambiguity arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the term \"Efficient Proxy\" in the paper. The reviewer suggests that the use of \"is\" implies a specific proxy, but the absence of a proxy named \"Efficient Proxy\" suggests it refers to a family of proxies. This comment highlights a potential ambiguity in the paper, but it does not provide specific examples or references to support the claim. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the term \"Efficient Proxy.\" It points out that the use of \"is\" suggests a specific proxy, but the absence of a proxy named \"Efficient Proxy\" implies a family of proxies. This feedback highlights a specific area where the authors need to clarify their terminology to avoid confusion. While the comment effectively identifies a problem, it does not provide detailed guidance on how to resolve the ambiguity or suggest alternative phrasing. Therefore, the comment is 3, as it directs the authors to a specific area for improvement but lacks comprehensive guidance. This aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the model more complex or what specific aspects need improvement. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, such as a particular model description or section. Without explicit references to specific sections or models, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model are considered overly simple or how this simplicity could be a bug. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model is overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the model is considered overly simple. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on how to address the simplicity or what aspects of the model need to be enhanced, the authors are left without a clear understanding of how to improve their draft. This makes the comment 2, as it identifies a potential issue but does not offer any actionable steps for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the work, noting that its focus on a narrow task and a specific language may restrict its broader impact. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might broaden the scope of their work or address the issue of limited impact. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment points out a limitation, it does not provide specific guidance on how to address this issue or improve the broader impact of the work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s focus on a narrow task (climate change QA) and a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. While this observation is relevant, the comment lacks specificity and actionable guidance on how the authors might address this limitation or expand the scope of their work. Without detailed suggestions or examples, the feedback does not provide the authors with a clear path for improvement. Therefore, the comment is 3, as it identifies a potential issue but does not offer comprehensive guidance for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. While the comment explicitly states the need to include this information, it does not provide specific guidance on how to present the computational cost or runtimes. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the main paper, where the method is discussed. The suggestion is specific in terms of what needs to be addressed, namely, the computational cost and runtimes. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that mentioning the negligible computational cost of CHR in the main paper would help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers. However, the comment does not provide any specific reasoning or evidence to support why this information is crucial or how it would benefit the paper. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for enhancing the paper. By addressing these points, the authors can better motivate their method and make it more accessible to readers. However, the comment could be more helpful if it included specific guidance on how to present the computational cost or runtimes. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should provide more detailed explanation of the EEG topography plots in Figure 3, specifically addressing whether the spatial arrangement of the EEG sensors played a role in the EEG token quantization process. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to provide more detail but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the ambiguity in interpretation due to the presentation of EEG topography plots for both the input and output during the EEG token quantization process. Additionally, it provides a clear suggestion for improvement by recommending that the authors elucidate the procedure in greater detail, specifically addressing whether the spatial arrangement of the EEG sensors played a role in this process. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents EEG topography plots for both the input and output during the EEG token quantization process, leading to ambiguity in interpretation. The reviewer recommends that the authors provide more detailed explanation of this procedure, specifically addressing whether the spatial arrangement of the EEG sensors played a role. This claim is 3 as it highlights a potential issue with the figure and suggests a specific area for improvement. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the ambiguity and how to address it, which could be challenging without further guidance. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, which presents EEG topography plots for both the input and output during the EEG token quantization process. It points out that this presentation leads to ambiguity in interpretation and suggests that the authors should provide a more detailed explanation of the procedure. Additionally, the comment offers a specific suggestion for improvement by asking whether the spatial arrangement of the EEG sensors played a role in this process. This feedback is clear and actionable, as it directs the authors to address a particular aspect of their work that could benefit from further clarification. By providing this detailed guidance, the comment is 5, as it empowers the authors to make significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on the selection process and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses this evaluation, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in its request for clarification on the selection criteria and potential implications, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. The comment suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that other tasks or datasets might yield different insights. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation by questioning the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and justification for their evaluation methodology. By addressing this point, the authors can enhance the transparency and robustness of their results. However, the comment could be more helpful if it offered specific suggestions on how to expand the evaluation or provided examples of alternative datasets or tasks to consider. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity in the introduction, specifically regarding the modelling of curves, which are presumably related to tumour growth. However, it does not provide explicit guidance on how to address this issue or suggest specific changes that could improve the clarity. The action is implicit, as the authors can infer that they need to clarify the context of the modelling, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to implement the change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"second paragraph\" of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding what is being modelled, particularly in relation to tumour growth. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction discusses modelling curves but does not make it immediately clear what is being modelled. The reviewer infers that it is related to tumour growth, but this inference is not explicitly stated in the paper. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the second paragraph discusses modelling curves but does not clarify what is being modelled. This feedback is 3 as it points out a lack of clarity in the paper, prompting the authors to clarify their intentions. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or what additional information should be included. While it highlights an area for improvement, it lacks depth and actionable advice, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. It also asks for an example of what would happen by minimizing both terms in Eq 3 or only the first term. While the comment explicitly states the need for more explanation and discussion, it does not provide specific guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute the actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more explanation to clarify the expected results and discussing different optimization strategies and their corresponding results. The comment also includes a specific example of what should be discussed, such as minimizing both terms in Eq 3 or only the first term. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. The reviewer provides a specific example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and the inclusion of a concrete example contribute to the claim\"s verifiability. However, the comment could be strengthened by referencing similar works or providing additional context to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanation to clarify the expected results. It also highlights the importance of discussing different optimization strategies and their corresponding results, particularly in relation to the main contribution of the paper, the CBR. The comment includes a concrete example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and specificity provides the authors with clear guidance on how to enhance their draft, making the comment 4. However, it could be more comprehensive by suggesting specific ways to present or discuss the optimization strategies. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that the authors should provide this definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the definition should be presented or what level of detail is required. However, the authors can infer that they need to add a definition, making the comment 3.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or proof. This makes it weakly grounded, as the authors cannot confidently determine where to make the addition. The comment is specific in suggesting the inclusion of a definition, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This is a request for clarification or additional information, not a claim or opinion. It does not require verification as it is a factual statement or a suggestion for improvement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional context or clarification for the readers. By addressing this suggestion, the authors can enhance the comprehensibility and accessibility of their work. However, the comment could be more helpful if it provided guidance on how to present the definition or where it should be included in the paper. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. While the comment implies that the authors should expand their analysis to include this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific assumptions should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the analysis of the quality of local minima found by Algorithm 1, particularly the approximation ratio under certain assumptions. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. This is a claim that requires further analysis and justification. While the reviewer provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such an analysis would be beneficial. The comment is 3 as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should analyze the quality of local minima found by Algorithm 1, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and potentially expand their findings. However, the comment could be more helpful if it offered specific suggestions on how to approach this analysis or what assumptions might be relevant. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly states the need for the supplementary material and the release of source code, it does not provide specific guidance on how to improve the selfcontainment of the main paper or how to make the source code available. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper and that the source code should be released for reproducibility. However, it does not specify which parts of the paper are lacking in selfcontainment or which sections of the supplementary material are crucial for understanding. The comment is fully grounded as it mentions the supplementary material, but it is underspecific because it does not provide detailed guidance on what needs to be addressed. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not selfcontained. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for the request but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility, which is a crucial step in ensuring the paper\"s validity. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to enhance the selfcontainment of the main paper or by offering guidance on how to make the source code available. Despite this, the feedback is 4 as it directs the authors to address critical aspects of their work that are essential for reproducibility and understanding. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms need clarification or improvement, leaving the authors without a clear understanding of how to address the issue. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode\" algorithms and the sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and provides a reference to the sentence where this claim is made. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific details or examples that would help the authors understand the issue or provide a basis for addressing it. As a result, the claim is 1, as it does not offer sufficient information for the authors to make improvements or address the concern effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. It references a specific sentence in the paper where the authors claim that the robustness of Cans largely comes from the information redundancy implemented in the weight pool design. However, the comment does not provide any further explanation, analysis, or suggestions on how the authors might address this issue or improve their explanation. Without additional context or guidance, the authors are left without a clear understanding of what specific aspects of the implementation need clarification or improvement. Therefore, the comment is 2, as it identifies a potential area of concern but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. While the comment explicitly states that the authors should provide clarification, it does not specify how to do so or what specific aspects of the choice should be explained. The action is explicit but somewhat vague, as the authors know they need to provide clarification but may not be entirely sure of the exact details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but it does not specify which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a specific section. However, it is specific in suggesting that the authors should clarify their choice of algorithms. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but acknowledges that this is only a presumption. The comment does not provide specific evidence or references to support the claim that REINFORCE is a better choice, nor does it offer a detailed explanation of why the authors should clarify their choice. This lack of supporting evidence or detailed reasoning makes the claim 3, as the authors would need to infer the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of the REINFORCE algorithm for training instead of PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. The comment is clear and actionable, as it prompts the authors to explain their reasoning behind specific choices, which can enhance the transparency and comprehensiveness of their work. However, it could be more helpful if it provided specific guidance on what aspects of the choice should be explained or referenced. Overall, the comment is 4, as it directs the authors to improve their draft by providing additional context and justification for their methodology choices."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include experimental results that exclude the mixup technique from the proposed method. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to demonstrate the pure contribution of the proposed method. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should include experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. This claim is based on the observation that the mixup technique is also used in the experiments on SplitCIFAR100 and SplitTinyImageNet. The comment provides a logical reasoning for the suggestion, as it highlights the need to isolate the contribution of the proposed method from other techniques. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it requires additional evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental setup by suggesting that the authors should include experimental results that exclude the mixup technique from the proposed method. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to demonstrate the pure contribution of their method. By following this advice, the authors can better isolate and highlight the effectiveness of their approach, which is crucial for evaluating its impact. However, the comment could be more helpful if it provided additional context or rationale for why this exclusion is important. Overall, the comment is 4 as it offers a clear direction for enhancing the experimental section of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether the authors overlooked this aspect or if it is not analyzed in the paper. While the comment implies that the authors should address this theoretical support for the merits of Fourier features, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include this analysis or explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if it was overlooked. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the theoretical support for the merits of Fourier features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if it was overlooked. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if it was overlooked, which is an important point for theoretical support of the merits of Fourier features. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the analysis should be included. While it identifies a potential gap in the paper, it lacks actionable feedback or detailed advice, making it 3. The authors are left to infer that they should address this theoretical support, but without specific guidance, the comment does not fully support their efforts to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details on this aspect, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of fitting the network to the residual rather than directly learning the inputoutput mapping. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on what aspects of the network fitting process need clarification or improvement. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. This is a relevant observation that could help the authors improve their draft by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional experiments or theoretical explanations. While it points out a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for details about the experiment setup in Section 3.3, specifically mentioning data augmentation methods, learning rate, etc. This request is clear and direct, providing the authors with a specific action to take. The inclusion of a reference to a relevant paper further supports the action by providing a source for the authors to consider. Therefore, this comment is 5, as it clearly instructs the authors on what information to include and where to find additional guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the details about the experiment setup, such as data augmentation methods and learning rate. The inclusion of a reference to a relevant paper further supports the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking for more details about the experiment setup in Section 3.3. It requests information on data augmentation methods and learning rate, which are important aspects of the experimental design. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. By prompting the authors to clarify these details, the comment does offer some guidance, but it lacks depth and specificity to be fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this possibility, correct the calibration steps, or address the speed disparities in their analysis. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific details or examples that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable steps or detailed feedback on how to improve the draft, leaving the authors with only a vague direction to explore. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment does not explicitly instruct the authors to address this question or provide specific guidance on how to do so, it implies that the authors should consider this aspect of their work and potentially include an analysis or discussion on the topic. The action is implicit and somewhat vague, as it does not provide detailed instructions on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the impact of emission distributions on inference tasks, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This is a request for clarification or additional information, rather than a claim or opinion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question prompts the authors to consider and address a critical aspect of their work that may not be fully explored in the current draft. By highlighting this gap, the comment provides a clear direction for the authors to enhance their paper by including an analysis or discussion on the impact of emission distributions on inference tasks. However, the comment could be more helpful if it offered suggestions on how to approach this analysis or provided examples of similar studies that have addressed this issue. Overall, the comment is 4 as it identifies a specific area for improvement and encourages the authors to expand their discussion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should include an analysis of the reasons behind this outcome, which is an implicit action. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on. While the action is clear, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of explanation for the poor performance of the scope prompting method on GPT3.5turbo. The comment provides a clear direction for improvement by suggesting that the authors should analyze the underlying reasons for this outcome. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or analysis to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by conducting a more thorough analysis of the experimental results. By suggesting that the authors should explore the reasons behind the observed performance, the comment provides a concrete direction for improvement. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to enhance the depth and clarity of their analysis, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why the authors did not compare batch and greedy methods in the remaining 110 datasets, given that only 10 out of 120 datasets were considered in [7,12]. While the comment implies that the authors should consider comparing these methods in the other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include more datasets. However, the comment provides a clear rationale for why this comparison might be beneficial, which could help guide the authors in making this decision. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the authors\" choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. However, it does not specify which part of the paper this discussion is based on, such as a specific section or table where the datasets are mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to compare batch and greedy methods in the remaining datasets, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the authors\" choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. While the comment identifies a potential area for expansion or improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or detailed feedback on why this comparison is important or how it could enhance the paper. As a result, the comment is 3, as it points out a possible area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the sensitivity of performance and sample efficiency to the \u03bb parameters, as well as the process of calculating \u03bb. It also mentions a lack of understanding regarding the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, which could help the authors better understand the context. However, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the clarity or explanation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the calculation process and the explanation of ELLA\"s impact on sample efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines where the issues are discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the calculation of the \u03bb parameter and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the sensitivity of performance and sample efficiency to the \u03bb parameters, as well as the process of calculating \u03bb. It also mentions a lack of understanding regarding the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, which can help the authors better understand the context. However, the claim is 3 as it lacks detailed explanation or examples within the text to fully substantiate the points. The references provide some context but do not fully address the specific issues raised in the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions and observations about the sensitivity of performance and sample efficiency to the \u03bb parameters, as well as the process of calculating \u03bb. It also points out a lack of understanding regarding the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, which can help the authors better understand the context. However, while it identifies areas of confusion and potential improvements, it does not offer specific guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need clarification, but it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the method used to solve the minmin problem, specifically asking which method is being referred to. However, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable details, such as suggesting that the authors clarify or provide more information about the method used. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the method used to solve the minmin problem, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine the exact section or context where this method is mentioned, making the comment weakly grounded. However, it is specific in its inquiry about the method used, which provides some guidance on what needs to be clarified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the method used to solve the minmin problem, specifically asking which method is being referred to. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the method used. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not offer any value to the authors in terms of enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in certain environments. It also raises concerns about overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their draft. The authors are left to infer that they should investigate and address the concerns raised, but without concrete steps or actions, the comment remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in certain environments. However, it does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about the algorithm\"s performance and convergence, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, citing specific examples from Figure 2 and certain environments. However, the comment lacks detailed reasoning or evidence to support why the performance decrease or convergence into similar solutions is problematic. It also mentions overestimating the true maximum value, but without further explanation or references, the claim remains vague. This makes the comment barely verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in certain environments. It also points out a potential issue with overestimating the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how the authors might address these issues or improve their methodology. The feedback is 3 as it highlights potential weaknesses, but it could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the work is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue. It lacks specific guidance on how the authors might enhance the novelty or provide additional context to differentiate their work. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes, if any, are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment provides some specificity by pointing out the lack of novelty, it does not offer detailed guidance on how to address this issue or improve the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any specific suggestions or guidance on how the authors might enhance the novelty or originality of their work. Without actionable feedback or constructive advice, the comment lacks helpfulness, leaving the authors without a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the performance trend. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. The reviewer provides a logical expectation that the performance should approach the vanilla methods from below, which adds clarity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. The comment references figures 34, which could provide some context, but it lacks detailed reasoning or examples to fully support the claim. The authors would need to investigate the figures and the underlying logic to understand the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. This feedback identifies a specific area of confusion or potential issue in the paper, prompting the authors to investigate and clarify the performance trend. However, the comment lacks detailed guidance or suggestions on how to address this concern, such as proposing specific analyses or experiments to conduct. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to elaborate on a specific aspect of their paper, namely the Hoeffding\"s bound and its applicability to stochastic algorithms. It provides a clear action for the authors to take, which is to expand on the explanation in the paper. However, the comment does not specify how the authors should elaborate on this topic, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 124125, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the applicability of Hoeffding\"s bound to stochastic algorithms. The comment provides a clear direction for the authors to improve their explanation, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, making it a normal statement. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors could provide more elaboration, specifically regarding the applicability of Hoeffding\"s bound to stochastic algorithms. It points out that the authors should explain how the conditioning on the previous iterate further guarantees the validity of the Hoeffding inequality. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation in the paper. However, the comment could be more helpful if it included suggestions on how to present this information or examples to illustrate the point. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This is an explicit suggestion that provides a clear action for the authors to take, namely, to incorporate these methods into their table. The comment is concrete because it specifies the type of approach to consider, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, it does not specify which part of Table1 this suggestion pertains to, nor does it provide details on how this addition would improve the paper. The authors can infer that it relates to the experimental results or methodology section, but the lack of specific guidance makes it difficult to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, the comment does not provide any reasoning or evidence to support why this addition would be beneficial or how it would improve the paper. Without further explanation or context, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. While it provides a specific suggestion for improvement, it lacks detailed guidance on how to implement this approach or why it would be beneficial. The comment does not explain the potential advantages or drawbacks of incorporating such an approach, nor does it offer any context or rationale for why this addition would enhance the paper. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using fewshot examples for CoT. This implies that the authors should include an ablation study to demonstrate the effectiveness of their choice. While the comment provides a clear direction for improvement, it does not specify which aspects of the ablation study should be included or how to conduct it. The action is explicit but somewhat vague, as the authors know they need to conduct an ablation study but may not be entirely sure of the specific details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using fewshot examples for CoT. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the prompt choice is discussed. The comment is specific in suggesting the need for an ablation study to explain the choice of prompt. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using fewshot examples for CoT. This claim is 3 as it highlights a potential gap in the paper\"s methodology, suggesting that an ablation study could provide valuable insights. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim, leaving the authors with a general direction for improvement but without concrete guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain the choice of prompt. It highlights the importance of understanding why the authors chose the prompt in a specific way, such as using fewshot examples for CoT, and how this choice might impact performance. This feedback is clear and actionable, providing the authors with a concrete suggestion for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from the term \"temporal relationship.\" This feedback provides a clear and direct action for the authors to take, ensuring they use the terms correctly throughout the paper. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and the specific term \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" pointing out that it should be differentiated from \"temporal relationship.\" Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of the term \"causal mechanisms\" on page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of terminology on page 1, where the term \"causal mechanisms\" is used interchangeably with \"temporal relationship.\" It provides a clear and actionable suggestion to use the terms carefully, ensuring clarity and accuracy in the paper. This feedback is valuable as it helps the authors correct a potential misunderstanding in their work, improving the precision and clarity of their writing. However, the comment could be more helpful if it provided examples or further explanation of how to differentiate between these terms. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to integrate this information or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results should be discussed in relation to the reference. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. However, the comment does not provide specific details or examples from the referenced work to support the claim. Without additional context or explanation, the authors may find it challenging to understand the relevance of the reference or how to incorporate it into their discussion. Therefore, the claim is 3, as it lacks detailed support but provides a general direction for improvement.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. This feedback is 3 as it points out a potential area for improvement by suggesting a connection to existing literature. However, the comment lacks specificity and does not provide detailed guidance on how to integrate this discussion into the paper or what aspects of the results should be highlighted. While it identifies a relevant area for expansion, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment implies that the authors should provide more information on the assumptions and their relevance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their impact on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and significance of using PCA to reduce interaction count, questioning its incremental nature and the clarity of the paper\"s results. It provides a logical reasoning for why using PCA to reduce interaction count might be intuitive, based on the assumption that PCA aims to retain the maximum information in the data with reduced dimensionality. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it is challenging for the authors to pinpoint where to address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive. The reviewer provides a logical reasoning by explaining that PCA aims to retain the maximum information in the data with reduced dimensionality, assuming certain assumptions are met. However, the comment lacks specific examples or references to support the claim that the assumptions are not met or that the results are unclear. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty and significance of using PCA to reduce interaction count, suggesting that it might be intuitive and lacks clarity. It provides a logical explanation for why using PCA to reduce interaction count could be expected, given its aim to retain the maximum information in the data with reduced dimensionality. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve the clarity of their results. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors are left with a general understanding of the critique but without clear steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It questions how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should compare their models to stateoftheart models, it does not explicitly instruct them to do so. Additionally, it lacks specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to compare their models to stateoftheart ones but are not provided with detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot RC models\" considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that these models are not stateoftheart and questions how their performance compares to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, providing specific examples of such models. This claim is supported by references to external works, which helps verify the assertion. However, the comment could be strengthened by providing more detailed comparisons or analysis of the performance differences between the models. Overall, the claim is 4, as it provides a solid foundation for the authors to address the issue but lacks comprehensive evidence or detailed comparisons. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It questions how the performance of these models compares to relation extraction/generation models in fewshot settings, which is a relevant and important point for the authors to address. By highlighting this gap, the comment provides a clear direction for the authors to improve their work by comparing their models to more advanced alternatives. However, the comment could be more helpful if it included specific suggestions on how to conduct this comparison or what metrics to use. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the results in Section 4 only apply to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this limitation, whether it should be clarified, or if it affects the generalizability of the results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, stating that they only apply to shallow fullyconnected ReLU networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Section 4 only apply to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the validity of their results. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific limitation in the results presented in Section 4, stating that they only apply to shallow fullyconnected ReLU networks. While this is a relevant observation, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand the applicability of their results. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide results regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. This is a clear and direct action for the authors to take, as it specifies what additional information should be included in the paper. The comment provides a concrete suggestion on how to improve the draft by asking for specific results to be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to speak about what was observed regarding this discussion, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses an interest in the discussion of using sequential MCB vs a single MCT layers for the decision head and requests additional information on what was observed. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the discussion of using sequential MCB vs a single MCT layers for the decision head is interesting but lacks results. It provides a clear and actionable suggestion for the authors to address by asking them to speak about what was observed in this context. This feedback is valuable as it directs the authors to enhance their paper with additional results or analysis, which could significantly improve the comprehensiveness and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to present or analyze the results. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information about the choice of distribution sets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper discusses this choice, making it weakly grounded. The comment is specific in its questions about the choice of distribution sets and the potential impact of selecting fewer sets. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address these questions or improve their methodology. The feedback is 3 as it prompts the authors to consider these aspects, but it does not provide actionable advice or detailed insights into how to resolve the issues. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should showcase their approach using transformerbased (masked) language models instead of obsolete language models like ngram HMM and RNN, which are no longer commonly used. This comment explicitly states an action for the authors to take, which is to update their experiments to align with current NLP trends. The suggestion is clear and provides a concrete direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the use of \"obsolete language models\" (ngram HMM and RNN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the language models used and suggests an alternative approach using transformerbased (masked) language models to better align with current NLP trends. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are conducted on obsolete language models (ngram HMM and RNN) that are rarely used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. While the claim is based on the observation that these models are outdated, it lacks specific references or detailed reasoning to support why transformerbased models are more relevant or superior. The comment provides a suggestion for improvement but does not fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on obsolete language models (ngram HMM and RNN) that are no longer commonly used. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the relevance and impact of their work. By addressing this feedback, the authors can enhance the credibility and applicability of their research. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to resolve the problem. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the estimation of mu, which is discussed in the paper. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of mu, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the misestimation of mu is unclear, specifically questioning how mu, which represents the proportion of missing observations, can be estimated. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the estimation of mu, which represents the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific way to present the performance of the algorithm by considering the sensitivity to initialization. It provides a clear and concrete action for the authors to take, which is to present the performance as a function of the distance of initialization to the groundtruth. The comment also specifies how to implement this suggestion by providing a range of distances (0.01:0.01:0.1) and a method for sampling matrices. This level of detail ensures that the authors know exactly what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests presenting the performance as a function of the distance of initialization to the groundtruth, which provides a clear and specific direction for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization to the groundtruth, which is a logical and reasonable suggestion. The reviewer provides a clear explanation of how this could be done, including a specific method for sampling matrices and reporting performance. This level of detail and reasoning makes the claim 5, as it provides a concrete and actionable suggestion for improving the paper. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of the paper. It recommends presenting the performance as a function of the distance of initialization to the groundtruth, which could provide valuable insights into the algorithm\"s sensitivity to initialization. The comment offers a clear and detailed method for implementing this suggestion, including a range of distances and a sampling approach. This level of guidance empowers the authors to make a significant improvement to their draft by enhancing the understanding of their algorithm\"s performance. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, providing a clear direction for the authors to address the concern. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that the absolute value is not needed for real numbers, which is a common knowledge in mathematics. However, the comment could be strengthened by providing a reference or further explanation to support the claim. Therefore, the comment is 4, as it provides a logical basis but lacks specific references or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their draft. By addressing this minor detail, the authors can ensure the accuracy and clarity of their mathematical definitions. However, the comment could be more helpful if it provided additional context or explained why this correction is important. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment implies that the authors should provide highprobability bounds and consider adding measures of robustness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in detailing what needs to be addressed, such as providing highprobability bounds and adding measures of robustness. However, the lack of explicit section references makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. The comment provides a logical reasoning for the suggestion, as ensemble methods are known to provide highprobability bounds, and the addition of measures like error bars or standard deviation would enhance the robustness analysis. However, the comment could be strengthened by providing specific examples or references to support the claim about ensemble methods and highprobability bounds. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It provides a concrete suggestion by recommending the use of ensemble methods as performed in the experiments, which could help achieve these highprobability bounds. Additionally, the comment suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, offering the authors specific ways to enhance their work. However, it could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the reviewer is not an expert in the area of pruning but expresses a positive opinion about the motivation. However, the comment suggests that the results are less impressive and recommends evaluating them from more aspects, such as actual latency, memory consumption, and network size. While the comment implies that the authors should consider these additional aspects, it does not provide explicit guidance on how to implement these suggestions or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the reviewer is not an expert in the area of pruning but expresses a positive opinion about the motivation. It also suggests that the results should be evaluated from more aspects, such as actual latency, memory consumption, and network size. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors might infer that it relates to the results section, but this inference is not explicit. The comment is specific in suggesting additional aspects for evaluation, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point acknowledges the reviewer\"s lack of expertise in the area of pruning but expresses a positive opinion about the motivation. It suggests that the results should be evaluated from more aspects, such as actual latency, memory consumption, and network size. However, the comment does not provide specific examples, references, or detailed reasoning to support why these additional aspects are important or how they would impact the evaluation. This lack of detailed justification makes the claim 3, as the authors would need to infer the significance of these aspects themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the reviewer\"s lack of expertise in the area of pruning but expresses a positive opinion about the motivation. It suggests that the results should be evaluated from more aspects, such as actual latency, memory consumption, and network size. While the comment identifies a potential area for improvement by suggesting additional aspects to consider, it lacks specific guidance or examples on how to implement these suggestions. The feedback is 3 as it points out a gap in the evaluation but does not provide detailed actionable steps for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper, questioning whether it is merely an incremental improvement over a previous work. It asks for clarification on how the current paper differs from the referenced work and suggests that it might be applying a similar methodology to a new task. While the comment implies that the authors should provide a clear explanation of their novelty, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of novelty and provide a detailed comparison with the referenced work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper, specifically questioning whether it is merely an incremental improvement over a previous work. It references a specific paper, \"https://aclanthology.org/2021.findingsacl.57.pdf,\" which provides some grounding by indicating a specific work to compare against. However, the comment does not specify which part of the paper should be revised to address this concern, making it weakly grounded. The comment is specific in its request for clarification on the differences between the current paper and the referenced work, but it lacks detailed guidance on how to address the issue of novelty. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty of the paper, suggesting that it is merely an incremental improvement over a previous work. The reviewer questions whether the paper differs significantly from the referenced work and implies that it might be applying a similar methodology to a new task. However, the comment lacks specific examples or detailed reasoning to support the claim of incremental novelty. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered 2, as it provides some basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it is merely an incremental improvement over a previous work. It specifically asks for clarification on how the current paper differs from the referenced work and suggests that it might be applying a similar methodology to a new task. This feedback is 3 as it prompts the authors to clarify the originality and distinctiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how the authors might demonstrate the novelty or if it offered guidance on how to differentiate their work from the referenced paper. Overall, the comment provides a starting point for the authors to address a critical aspect of their paper, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the performance of the complete loss function compared to those with some terms missing. The reviewer questions the logic behind this observation, asking for an explanation. While the comment identifies an area of concern, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide an explanation for the observed results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reported ablation studies, questioning the logic behind the results and asking for an explanation. The comment clearly specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the observation that the complete loss function performed worse than those with some terms missing. The reviewer raises a logical concern about the unexpected outcome and asks for an explanation. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim or guide the authors in understanding the issue. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the reported ablation studies in Table 2, noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. This observation raises a question about the logic behind the results, prompting the authors to provide an explanation. While the comment highlights a potential area of concern, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential problem, but it lacks depth and actionable advice, making it more suitable for a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that a statement in the abstract is unclear and suggests that the abstract should be more highlevel, avoiding technicalities. However, it does not provide specific guidance on how to rephrase the statement or what aspects of it are unclear. The action is implicit and somewhat vague, as the authors are left to infer that they need to simplify the language in the abstract without detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear in the abstract, namely the statement about ensuring a lowrank feature subspace with a small number of attacked samples and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and avoid technicalities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a statement in the abstract is unclear and suggests that the abstract should be more highlevel, avoiding technicalities. However, the comment does not provide any specific reasoning or examples to support why the statement is unclear or how it could be improved. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and should be simplified. It provides a clear suggestion to make the abstract more highlevel and avoid technicalities, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of it are unclear. Despite this, the feedback is 4 as it directs the authors to improve the clarity and accessibility of their abstract, which is crucial for effective communication of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. While the comment provides a general direction for expanding the results, it lacks specific guidance on which modalities to include or how to present the results. The authors can infer that they need to expand their results to other modalities, but the comment does not provide concrete steps or details on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting the inclusion of results in other modalities, particularly languagerelated tasks, and provides a rationale for why expected test loss might not be as relevant. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. However, the comment lacks specific reasoning or references to support why these suggestions are necessary or beneficial. The mention of \"people care about OOD performance\" is a general statement without detailed justification or examples. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests expanding the results to include other modalities, particularly languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics or evaluations might be more relevant. While the comment provides a direction for improvement, it lacks specific guidance on which languagerelated tasks to consider or how to present the results. Additionally, the comment does not explain why expected test loss might not be meaningful, which could help the authors understand the rationale behind the suggestion. Despite these limitations, the comment offers a clear direction for expanding the scope of the results, making it 3 for the authors to consider. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, specifically addressing the use of \"fewshot\" in graph link prediction. It highlights the need to explain how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks with 0/few training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically the use of \"fewshot\" in graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the issues with generalizability are presented, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the motivation and generalizability of the work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically regarding the use of \"fewshot\" in graph link prediction. The reviewer provides a logical reasoning by explaining that in fewshot learning, the goal is to leverage a few instances to learn a generalizable model, but the proposed method does not address how to effectively use \"fewshot\" or guarantee generalizability. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the motivation and justification of the work. It highlights the need to explain how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to address a specific gap in their work. However, the comment could be more helpful if it provided examples or suggestions on how to effectively use \"fewshot\" or enhance generalizability. Overall, the comment is 4 as it guides the authors toward a significant enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their approach. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. Without explicit references to the paper, the authors cannot confidently determine which part of the manuscript is being addressed. Additionally, the comment lacks specificity regarding what aspects of the GP approach are considered naive or how the authors might improve their use of GP. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of GP is \"kind of straightforward and naive\" and suggests that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the use of GP is naive. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their approach or address the critique, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not provide meaningful insights or direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer suggests that this claim is not supported by their experience and references a study by Zaremba et al. (2014) that trains 1500dimensional LSTMs on PTB. The comment also questions whether dropout is applied to the hidden states, implying that this information should be clarified. While the comment raises valid questions and points out potential issues, it does not provide explicit instructions on how to address these concerns or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the statement and potentially provide additional details on regularization methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs), referencing a study by Zaremba et al. (2014) as a counterexample. Additionally, it raises a question about whether dropout is applied to the hidden states, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from their experience (e.g., Zaremba et al. 2014) and suggests that the baseline models may not be properly regularized. This provides a logical reasoning and a specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the baseline models are not properly regularized. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from their experience, suggesting that the claim is not supported by their observations. Additionally, the comment questions whether dropout is applied to the hidden states, which could be relevant to the regularization of the baseline models. This feedback is 3 as it identifies a potential issue with the claim and prompts the authors to clarify or provide additional evidence to support their statement. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or provided additional context or references to support the critique. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some ablations mentioned in previous sections are hard to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly difficult to locate. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some ablations\" that are hard to locate, but it does not specify which ablations or sections are being referred to. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need improvement. Additionally, the comment does not provide any guidance on how to improve the writing or what specific issues need to be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are hard to locate in the following contents. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the specific ablations or sections, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback highlights a potential problem with the organization or presentation of the ablation results, which could impact the clarity and accessibility of the paper. However, the comment lacks specificity and does not provide actionable guidance on how to improve the writing or where to locate the ablations. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. While the comment implies that the authors should improve their work on differential privacy, it does not provide specific guidance on how to do so or what aspects need more attention. The suggestion to move the experimental results is explicit but lacks concrete details on how to implement this change. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given2)5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the differential privacy application is \"halfbaked\" and encourages the authors to think it through more clearly. Additionally, it provides a suggestion to move the experimental results from the appendix to the main paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the differential privacy application is \"halfbaked\" and suggests that the authors should think it through more clearly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to similar works or explain why the application is considered incomplete. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"halfbaked\" and encourages the authors to think it through more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which are separate from the differential privacy application. Additionally, the comment suggests moving the experimental results from the appendix to the main paper, which could improve the paper\"s flow and accessibility. While the comment provides some direction for improvement, it lacks specific suggestions or detailed guidance on how to enhance the differential privacy application or reorganize the experimental results. Therefore, it is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be applied more broadly to robotic manipulation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the scope of their methodology, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology description. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. The comment is specific in its critique but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation and could be more broadly applicable to robotic manipulation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. This is a relevant point that could help the authors clarify the scope of their work and potentially expand its applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or modifications to the methodology. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, suggesting that studying each objective in isolation may affect the comparability of results. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the comparability of their results. The comment implies that the authors should consider comparing the Geffects across different objectives and approaches, but it lacks concrete details on how to implement this comparison. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4\" and \"separate figures and parts of the paper,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, suggesting that studying each objective in isolation may affect the comparability of results. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2, as it provides a general concern but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology used in the paper, specifically the examination of Geffects of each unlearning objective in isolation. It raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, which could impact the interpretation of results. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the comparability of their results. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the advantage of the UNIFORM procedure compared to other methods, particularly in the 1shot setting. It questions the authors\" theory for why the method is not as effective in this setting. While the comment implies that the authors should provide a theory or explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the advantage of the UNIFORM procedure over other methods, specifically in the context of the 1shot setting. It mentions the tables showing inconsistent results and questions the authors\" theory for why the method is not as effective in this setting. However, the comment does not specify which tables or sections of the paper are being referred to, making it weakly grounded. The comment is specific in its request for a theory or explanation regarding the method\"s effectiveness in the 1shot setting. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim. While it provides some evidence, the lack of detailed reasoning or references makes the claim 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It questions the authors\" theory for why the method is not as effective in this setting, which is a relevant and important point for the authors to address. The comment also acknowledges the clarity and welldesigned experiments, which provides a balanced perspective. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might explore or address this inconsistency. Overall, the feedback is 3 as it highlights an area for further investigation and improvement, but it lacks detailed guidance on how to proceed. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reason why information value is a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. While the comment implies that the authors should explore this further, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate an existing theory. The action is implicit and somewhat vague, as the authors need to infer that they should investigate existing theories and integrate them into their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages (7 and 8) where the issue is discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the reason for information value being a stronger predictor for dialogue and suggests that including an explanation from an existing linguistic theory would strengthen the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reason for information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. However, the comment does not provide any specific references or detailed reasoning to support the claim that an existing linguistic theory could explain this phenomenon. The suggestion is 3, as it points to a potential area for improvement, but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the reason for information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting a theoretical basis for the findings. However, the comment lacks specific guidance on which linguistic theory to consider or how to integrate it into the paper. While it provides a direction for the authors to explore, it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a missed opportunity in the paper to discuss the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the potential benefits and takeaways of AutoML approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, it does not specify which part of the paper this critique pertains to, such as a particular section or discussion where this aspect should be addressed. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. It is specific in detailing what the authors should discuss, namely the \"biggest takeaways\" from the found architecture, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point claims that the authors should discuss the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as it provides a general direction but requires more elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the discussion of the benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. This feedback is clear and actionable, as it points out an area where the paper could be strengthened by providing insights into the potential applications and implications of the findings. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or provided examples of what kind of insights could be discussed. Overall, the comment is 4 as it directs the authors to an important aspect of their work that could benefit from further exploration and discussion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the definition of T_a(t), noting that it is used in Section 3.1 but is only defined in Section 4. This feedback is explicit and provides a clear action for the authors to take: they should define T_a(t) in Section 3.1 to ensure consistency and clarity. The comment is concrete because it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the definition of T_a(t), which is used in one section but defined in another. This provides clear guidance on what needs to be addressed to ensure consistency and clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the usage and definition of T_a(t) in different sections of the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that T_a(t) is used in Section 3.1 but is only defined in Section 4. This feedback is clear and actionable, as it points out a potential inconsistency in the paper that could lead to confusion for readers. By highlighting this issue, the comment provides the authors with a direct suggestion to address the problem by defining T_a(t) in the appropriate section. This feedback is valuable as it helps the authors improve the clarity and consistency of their work. However, it could be more helpful if it provided additional context or suggested how the definition might impact the overall understanding of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not provide specific guidance on which complex problems to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors are left to infer the need for additional experiments without detailed instructions on how to implement them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the need for more complex experiments, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that more complex problems are necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. This feedback is 3 as it identifies a potential area for improvement in the experimental scope. However, the comment lacks specificity and does not provide detailed guidance on which complex problems to consider or how to conduct these experiments. While it points out a direction for expansion, it does not offer actionable steps or detailed suggestions, leaving the authors with a general idea but limited guidance on how to implement it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. It suggests that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on how the authors might achieve this or what additional evidence or arguments could be included. The action is implicit and vague, as the authors are left to infer that they need to provide more substantial evidence but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, specifically mentioning the incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for more substantial evidence or arguments to establish the contribution as significant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the gaps in the argument themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s primary contribution, suggesting that it is an incremental advancement over the TACTiS approach. It highlights the need for more substantial evidence or arguments to establish this contribution as significant. While the comment points out an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or provide the necessary evidence. The feedback is 3 as it prompts the authors to consider strengthening their contribution, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While it identifies an area that needs further exploration, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a discussion on the theoretical guarantee but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing discussion on the theoretical guarantee, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address by including a discussion on the theoretical guarantee. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what aspects to consider. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measures to evaluate the generated VCEs, noting that evaluation is primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to introduce quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is primarily based on visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of generated VCEs lacks quantitative measures and is primarily based on visual inspection. This claim is 3 as it highlights a potential gap in the evaluation process, but it lacks specific examples or references to support the assertion. The comment does not provide detailed reasoning or evidence to substantiate why quantitative measures are necessary or how they could be implemented. Therefore, the claim is 3, as it points out a potential issue but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it is primarily based on visual inspection rather than quantitative measures. This feedback is valuable as it highlights a gap in the evaluation methodology, prompting the authors to consider incorporating quantitative metrics to enhance the rigor and objectivity of their evaluation. However, the comment lacks specific suggestions or examples of quantitative measures that could be used, which would make it more actionable and helpful. By providing guidance on potential metrics or methods, the comment could offer more comprehensive feedback. Therefore, the comment is 3, as it points out an important area for improvement but could be more beneficial with additional details or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of marginal improvements or how to improve the method\"s performance. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, specifically mentioning the error range and the claim of better performance. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing the issue with the marginal improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, the comment does not provide specific examples or detailed analysis to support this claim, such as comparing the error ranges or providing data to substantiate the assertion. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. This feedback highlights a potential issue with the paper\"s claims of better performance, suggesting that the authors should reconsider their conclusions or provide more detailed analysis to substantiate their claims. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment identifies a specific area needing clarification, it does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the clarity of the evaluation set and selection process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is unclear, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment highlights an important issue, it lacks actionable suggestions or guidance on how the authors might address these concerns. Without specific advice or examples, the authors may find it challenging to make the necessary improvements. Therefore, the comment is 3, as it points out a weakness but does not provide enough detail to be fully actionable."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address this question, clarify the relevance, or make any changes to their draft. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" in the context of the work of DoshiVelez and Kim. This provides clear guidance on what aspect of the paper needs clarification or further discussion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. It does not contain a claim or opinion that requires verification. It is a factual inquiry, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. While it identifies a potential area for clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on potential additional datasets to include or alternative approaches to consider, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experiments are limited or how this limitation affects the paper\"s conclusions. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this observation is relevant, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand their experimental scope. Without actionable feedback or specific recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. The reviewer implies that the authors should clarify why [10] cannot use these side information, but this is not explicitly stated as an action. The comment lacks concrete guidance on how the authors should address this issue, such as suggesting specific steps to differentiate their method from [10] or explaining the rationale behind the proposed method. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is based on, making it weakly grounded. The comment is specific in its questioning of why [10] cannot use these side information, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. The comment implies that the authors should clarify why [10] cannot use these side information, but it does not provide specific evidence or reasoning to support this claim. The lack of detailed justification or references makes the claim 3, as the authors would need to further explore the issue to address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should clarify why [10] cannot use these side information, which is a relevant point for consideration. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue or differentiate their work from [10]. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation with more tasks. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or implement a sparsity constraint. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding a sparsity constraint but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s lack of sparsity constraint and its potential impact on computation with more tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in computation with more tasks. The comment provides a logical reasoning by explaining that without a sparsity constraint, the model will not be incentivized to use fewer factors, potentially resulting in increased computation. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the potential impact of this issue based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. This observation is relevant and could impact the model\"s efficiency and scalability. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or implement a sparsity constraint. While it highlights a potential area for improvement, the feedback lacks depth and specificity, making it 3. The authors are left to infer the implications and potential solutions on their own, which limits the comment\"s usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides clear guidance on what the authors need to do to improve their draft. The action is direct and concrete, as it specifies the exact experiments that should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this feedback pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in suggesting the need for additional experiments, it is 1 because it does not indicate where these suggestions should be implemented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section of the paper. It suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the robustness and applicability of their evaluation. However, the comment could be more helpful if it explained why these experiments are necessary or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which is implied by the smoothness of neural models. While the comment explicitly states that more explanations are needed, it does not specify what aspects of the explanation should be expanded upon or how to present them. The action is explicit but somewhat vague, as the authors know they need to provide more explanations but may not be entirely sure of the specific details or format of those explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the paper addresses the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that more explanations are needed on this topic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, stating that it can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the suggestion for more explanations. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference, which is attributed to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work. However, the comment could be more helpful if it provided specific suggestions on what additional explanations might be necessary or how to present them. Overall, the comment is 4 as it guides the authors toward enhancing their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the authors\" claim of superior performance with fewer parameters compared to a baseline model. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what parameters to test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the model\"s superior performance with fewer parameters compared to a baseline, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\" claim and suggesting that they test their model with larger word embedding and LSTM parameters to backup their claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters compared to a baseline model. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This is a logical request for verification, as it challenges the authors to provide evidence for their claim. However, the comment does not provide specific examples or references to support the claim that the baseline model was tested with standard parameters. This makes the claim 3, as it requires additional evidence or explanation from the authors to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters compared to a baseline model. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to design these experiments or what parameters to test. Overall, the comment is 4 as it guides the authors toward a potential improvement in their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a discrepancy between the regularization applied to the LN model and the GLM model, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. While the comment implies that the authors should consider adjusting their regularization approach, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what needs to be done, but it is not directly stated as an action. Therefore, the comment is 4, as the authors can infer the need for adjustment but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy in the regularization approach between the LN model and the GLM model, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. This claim is 3 as it references specific regularization techniques used in the GLM model, providing some context for the comparison. However, the comment lacks detailed references or examples from pillow et al. to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the LN model and the GLM model, noting that the authors apply regularization (in the form of a cropped stimulus) to both models, while the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for how to address it. By pointing out the need for consistency in the comparison, the comment offers valuable guidance that can help the authors enhance the rigor and clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include some failure cases and related discussion in their paper. While the comment implies that the authors should add this information, it does not provide specific guidance on which failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer what specific failure cases to address and how to discuss them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including failure cases and related discussion, but it does not specify which part of the paper this should be added to. The authors might infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of failure cases, but it lacks grounding as it does not identify a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including failure cases and related discussion would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of addressing failure cases. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should include failure cases and related discussion in their paper. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on which failure cases to include or how to structure the discussion. The suggestion is 3 as it points out a gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the ablation study or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in suggesting an ablation study to address the issue, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, the comment does not provide any specific reasoning, examples, or references to support why this encoding is unclear or unnecessary. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to determine its importance. This feedback is 3 as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it points the authors in the right direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add an explicit discussion on the upper bounds of counting and potentially elaborate on empirical runtimes related to the computational complexity of counting homomorphisms. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is explicit and provides specific guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145\" and the specific topic of \"computational complexity of counting homomorphisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for an explicit discussion on upper bounds of counting and potential elaboration on empirical runtimes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms and suggests that they should add an explicit discussion on upper bounds and potentially elaborate on empirical runtimes. The comment provides a specific example from the paper (\"L 145\") to support the claim, which helps justify the need for additional discussion. However, it lacks detailed reasoning or references to specific methods or studies that could further substantiate the claim. While the comment provides a clear direction for improvement, it could be strengthened with more detailed evidence or examples. Therefore, the comment is 4, as it provides a solid basis for the claim but could benefit from additional support.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the discussion on the computational complexity of counting homomorphisms. It points out that the authors make only brief statements about this topic and suggests that the paper would benefit from explicitly adding upper bounds and potentially elaborating on empirical runtimes. This feedback is clear and actionable, providing the authors with a specific direction for improvement that could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it included examples or references to guide the authors in addressing this issue. Overall, the comment is 4 as it effectively directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of three parts: a correction of a typographical error, a correction of a punctuation error, and a question about the convergence of the baseline MCL with deep learning. The first two parts are explicit and provide clear actions for the authors to take, making them 5. The third part is a question that seeks clarification, which is also explicit and actionable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the corrections required, such as changing \"f\" to \"g\" and removing an extra period. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three parts: a correction of a typographical error, a correction of a punctuation error, and a question about the convergence of the baseline MCL with deep learning. The first two parts are factual corrections that do not require verification. The third part is a question seeking clarification, which is not a claim and does not require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying typographical errors and punctuation mistakes in the manuscript. It also raises a question about the convergence of the baseline MCL with deep learning, which is a relevant concern for the authors to address. This feedback is clear and direct, offering the authors concrete steps to improve the accuracy and clarity of their draft. However, the comment could be more helpful if it included suggestions on how to ensure convergence or provided examples of how to address this issue. Overall, the comment is 4 as it effectively guides the authors in improving their draft, but it could be more comprehensive with additional guidance or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. While the comment implies that this is an important aspect to consider, it does not explicitly instruct the authors to conduct this study or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include a study of inference time but are not given detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in suggesting a comparison with other methods, it is 1 because it does not indicate where this comparison should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. The claim is based on the premise that the current method is direct and does not require detection or keypoint grouping, which could potentially lead to faster inference. However, the comment lacks specific examples or references to previous works that have studied inference time, making it difficult for the authors to fully understand the basis of the suggestion. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. This feedback is 3 as it identifies a potential area for improvement by highlighting the importance of evaluating inference speed. However, the comment lacks specific guidance on how to conduct this study or what metrics to use, which would make it more actionable. Additionally, it does not provide any context or explanation for why this comparison is relevant or how it might impact the paper\"s contribution. Therefore, while the comment points out a relevant area for improvement, it does not fully support the authors in making those improvements, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. It further notes that batch normalization standardizes the variance and centers the activation, and recommends discussing these limitations explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address the limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about evolutionary dropout addressing internal covariate shift, suggesting that it is limited in its ability to increase the variance of some lowvariance units. It also mentions batch normalization as a comparison, suggesting that it standardizes the variance and centers the activation. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. The comment is specific in detailing the limitations of the claim and suggesting that these should be discussed explicitly. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with batch normalization, which standardizes the variance and centers the activation. While the comment provides a logical comparison, it lacks specific examples or references to support the claim fully. The reasoning is 3, as it highlights a potential limitation of the claim, but the lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, suggesting that it can only increase the variance of some lowvariance units. It contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion to discuss these limitations explicitly, which could help the authors refine their understanding and presentation of the topic. However, the comment could be more helpful if it offered additional guidance on how to address these limitations or provided specific examples of how to discuss them. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution should be elaborated on or how this description should be incorporated into the paper. The action is explicit in terms of adding more description, but it lacks concrete guidance on what specific aspects to focus on or how to present the contribution. As a result, the comment is 3, as the authors know they need to add more description but may struggle to determine the exact content or format of the additional information.", "grounding_specificity_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description or what specific aspects of the contribution need elaboration. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need improvement. This makes the comment weakly grounded, as the authors cannot pinpoint the exact areas needing attention. Additionally, the comment lacks specificity because it does not provide detailed guidance on what aspects of the contribution should be described. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such details, the claim lacks verifiability, as the authors are left without a clear understanding of what aspects of the contribution need further elaboration. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated upon or how to present them. Without detailed suggestions or examples, the authors may struggle to determine how to effectively address this feedback. Therefore, the comment is 2, as it points out a general area for improvement but does not provide actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions into a dedicated section, which would help readers understand the significance of the two types of attention introduced for deep VAEs. Additionally, it suggests referencing normalization and feature scaling techniques in a separate section, which could provide more context and clarity. However, the comment does not specify how these suggestions should be implemented or provide concrete steps for the authors to follow. While the actions are explicit, they lack detailed guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions into a dedicated section and suggests referencing normalization and feature scaling techniques in a separate section. However, it does not explicitly mention which sections these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to sections 2.3 and 2.4, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as the scattering of the layerwise attention mechanism description and the need for a separate section on normalization and feature scaling. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of minor suggestions and comments, such as recommending a separate section for describing the main contributions and referencing normalization or feature scaling techniques. These suggestions are not claims or opinions that require verification. They are factual statements or requests for clarification, making them \"No.\"", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions into a dedicated section, which would help readers understand the significance of the two types of attention introduced for deep VAEs. Additionally, it suggests referencing normalization and feature scaling techniques in a separate section, which could provide more context and clarity. These suggestions are clear and specific, offering the authors concrete steps to enhance the readability and structure of their work. However, the comment could be more helpful if it included additional details or examples on how to implement these suggestions effectively. Overall, the feedback is 4 as it guides the authors toward improving the organization and clarity of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include supervised baselines in their experiments, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be informative to compare selfsupervised methods to fully supervised pretrained networks. The comment is clear and provides concrete guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be informative to compare selfsupervised methods to fully supervised pretrained networks. However, the comment does not specify which part of the paper should include these baselines, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or experiments, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. The reviewer provides a logical reasoning by stating that full annotation is likely available for such datasets and that it would be informative to compare selfsupervised methods to fully supervised pretrained networks. This reasoning is clear and provides a solid basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support the need for supervised baselines, which would align it with a score of 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why these baselines are important, noting that full annotation is likely available for such datasets and that it would be informative to compare selfsupervised methods to fully supervised pretrained networks. This feedback is clear and actionable, as it directly suggests a specific improvement that the authors can make to enhance the comprehensiveness and validity of their experiments. By addressing this feedback, the authors can significantly strengthen their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. While the comment raises important points for consideration, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions and concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. However, the comment does not specify which part of the paper these questions or observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these issues could be addressed, the lack of explicit references or detailed guidance makes the comment weakly grounded. The comment is specific in its questions and observations, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions and observations, each of which requires verification or clarification. The first question about the method\"s applicability on Hopper, which has deterministic dynamics, is not supported by evidence or reasoning. The second question about evaluating the method on domains with nondeterministic dynamics is a request for further empirical evaluation, but it lacks specific suggestions or references. The third question about the absence of BEAR from the baselines is a request for clarification, not a claim. Overall, the comment consists of factual statements and questions, making it \"No\" for the claim extraction step. Therefore, it is classified as \"X.\"", "helpfulness_rationale": "The review comment raises several important questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This is a valuable suggestion that could help the authors better understand and demonstrate the method\"s effectiveness. Additionally, the comment points out the absence of BEAR from the baselines, which is a relevant observation that could impact the paper\"s evaluation. However, the comment lacks specific guidance or suggestions on how to address these questions or observations, such as recommending specific domains or experiments to evaluate the method. While it identifies important areas for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact details of the theoretical justification that should be provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where these methods are discussed. Without explicit references to the paper, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in its request for a theoretical justification but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. This is a valuable suggestion as it encourages the authors to deepen their understanding of the methods and their impact on performance. However, the comment could be more helpful if it provided specific guidance on what aspects of the theoretical justification should be included or how to approach it. While it identifies a potential area for improvement, the feedback lacks depth and actionable details, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present these details or what format to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details should be provided about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in detailing what additional information is needed, but without clear grounding, the authors may struggle to identify the exact sections that require revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details should be provided about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, reasoning, or references to support why these details are necessary or how they would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these details or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more details about their proposed method. It highlights the need to explain how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it directs the authors to enhance their explanation of a critical aspect of their methodology. However, the comment could be more helpful if it provided specific suggestions on how to present these details or examples of similar approaches. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a key area of uncertainty."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides an example scenario where the prompt \"introduce a sports celebrity to me\" could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to enhance the method\"s ability to detect hallucinations in openended responses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides an example scenario involving a prompt about introducing a sports celebrity, which could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not specify which part of the paper discusses the proposed method or where this limitation is addressed. While the authors might infer that it relates to the methodology or evaluation sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the issue but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically in the context of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a specific example scenario to illustrate the challenge, which is a clear and logical reasoning to support the claim. However, the comment could be strengthened by providing additional examples or references to similar cases where this issue has been observed. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides a specific example scenario involving a prompt about introducing a sports celebrity, which could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. This feedback is valuable as it highlights a specific area where the method might struggle, prompting the authors to consider ways to address this issue. However, the comment could be more helpful if it offered suggestions or potential solutions for improving the method\"s ability to detect hallucinations in such scenarios. Overall, the comment is 3 as it provides insight into a potential weakness but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding the relationship between theoretical findings and realworld deep learning models. It suggests that the authors should verify their conclusion about label noise and model size on MNIST and CNN. While the comment implies that the authors should conduct additional experiments to validate their findings, it does not provide specific guidance on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity regarding the relationship between theoretical findings and realworld deep learning models. It suggests verifying the conclusion about label noise and model size on MNIST and CNN. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The suggestion to verify the conclusion is specific, as it provides a clear direction for the authors to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relationship between theoretical findings and realworld deep learning models is unclear. It suggests verifying the conclusion about label noise and model size on MNIST and CNN. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The suggestion to verify the conclusion is logical, but the lack of detailed reasoning or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the applicability of theoretical findings to realworld deep learning models. It suggests that the authors should verify their conclusion about label noise and model size on MNIST and CNN, which is a clear and actionable suggestion. This feedback provides the authors with a concrete step to take to improve the validity and relevance of their findings. However, the comment could be more helpful if it included additional guidance on how to conduct these verifications or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. It lacks concrete details on what actions the authors should take to resolve the problem or how they might interpret the results differently. As a result, the comment is vague and does not offer actionable steps for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the plots end at a weight decay strength where cosine similarities are still close to optimal, suggesting that this could be a limitation in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that weight decay applied to all layers would lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of \"conveniently\" suggests that the reviewer is aware of the absence of data or analysis supporting this claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that it could lead to suboptimal training loss and cosine similarities for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that this could be a limitation in the analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights a potential area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant omission in the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is considered a \"fairly serious omission\" that could lead to incorrect conclusions among casual readers. The reviewer emphasizes the importance of fixing this issue for publication, suggesting that it would be straightforward to do so. However, the comment does not provide specific guidance on how to address this omission, such as suggesting changes to the text or providing examples of how to clarify the results. While the action is explicit, it lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions among casual readers. The comment provides a clear direction for improvement by suggesting that this omission needs to be fixed for publication. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a \"fairly serious omission.\" The reviewer suggests that this omission could lead to incorrect conclusions among casual readers. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the omission and how to address it. The reference to \"DETAILED COMMENTS\" implies that more detailed information is available, but without access to this information, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a critical issue that could lead to incorrect conclusions among casual readers. The reviewer emphasizes the importance of fixing this omission for publication, acknowledging that it would be straightforward to address. However, the comment does not provide specific suggestions or examples on how to clarify the results or improve the clarity of the paper. While it highlights a crucial area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods. It explicitly asks the authors to compare the computational complexity, which is a direct and concrete action. The comment provides clear guidance on what the authors need to do to address this concern, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the proposed method compared to other methods. However, it does not specify which part of the paper discusses the online version of the algorithm or where the authors mention the impracticality of training multiple iterations/epochs with large models and datasets. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in its request for a comparison of computational complexity with other methods, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods. It does not make a claim or express an opinion but rather seeks clarification and comparison. The comment is factual and does not require verification, as it is a request for additional information. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the computational complexity of the proposed method compared to other methods. It challenges the authors to provide a comparison, which is a valuable request for clarification and could help the authors improve their draft by addressing a potential limitation or advantage of their method. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its helpfulness. While it identifies an area for improvement, it does not provide detailed suggestions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis or provide detailed guidance on how to implement it. The action is somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific analysis that could be conducted to study the impact of the cost of incentivization on performance. It provides examples of what could be analyzed, such as the reward incentives for various values of alpha and the collective return. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a hypothetical scenario where the cost to reward the other agent becomes high for cooperators, leading to the emergence of roles between \"winners\" and \"cooperators.\" The comment further suggests that lowering this cost might affect the collective return. While the comment offers a logical reasoning and a hypothetical scenario, it lacks specific examples or references to support the claim. This makes the claim 3, as it provides a basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a valuable analysis that could be conducted to study the impact of the cost of incentivization on performance. It provides a specific example of how this analysis could be structured, such as examining the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. This feedback is clear and actionable, as it directs the authors to a specific area for further exploration and analysis. However, it could be more helpful if it included additional guidance on how to conduct this analysis or potential outcomes to expect. Overall, the comment is 4, as it provides a constructive suggestion for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly highlights the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT4 significantly improve translation quality and discourse awareness. The reviewer points out that the differences between the scores are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is explicit and provides concrete guidance on what needs to be done to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of significance testing and provides a concrete example from line 486, where the authors claim significant differences in translation quality and discourse awareness. The comment suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between methods without providing significance testing. The reviewer provides a specific example from line 486, where the authors claim that ChatGPT and GPT4 significantly improve translation quality and discourse awareness. The reviewer points out that the differences in scores are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific statistical methods or standards for significance testing, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a significant issue with the paper: the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors make a claim about the significant improvement in translation quality and discourse awareness, but the reviewer points out that the differences in scores are minimal and not statistically significant. The comment suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is clear and actionable, guiding the authors on how to strengthen their claims and improve the rigor of their analysis. By addressing this issue, the authors can enhance the credibility and impact of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what specific evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or analysis. Without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that need improvement. The comment is specific in its request for additional evidence and analysis but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. This feedback is clear and actionable, as it directs the authors to enhance their paper by providing additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what types of evidence or analysis would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in comprehending Figure 5 and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is not aligned with the widespread use of text generation APIs for translation across multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the baselines and consider extending CATER to other languages. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the need for more details about the two baselines presented in Figure 5 and the suggestion to extend CATER to other languages. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is not aligned with the widespread use of text generation APIs for translation across multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future. While the comment provides some reasoning by highlighting the need for more details and the mismatch between the study and the widespread use of APIs, it lacks specific examples or references to support the claim about the difficulty in comprehending Figure 5. The suggestion to extend CATER to other languages is a logical inference but could be strengthened with more detailed reasoning or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, stating that it is hard to comprehend. It suggests that more details about the two baselines presented in the figure are needed, which is a clear and actionable piece of feedback. Additionally, the comment points out a limitation in the study, noting that the authors only focus on Englishcentric datasets while text generation APIs are used for translation across multiple languages. The reviewer implies that the authors could extend their work to include other languages in the future. This feedback is valuable as it highlights a potential gap in the study and provides a direction for future work. However, the comment could be more helpful if it offered specific suggestions on how to improve the presentation of Figure 5 or how to extend the study to other languages. Overall, the comment is 4, as it provides clear guidance on areas for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution and distinction from existing work, particularly in relation to GFlowNet for sequence generation. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by clearly articulating the main contribution and distinguishing it from existing work. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details what needs to be improved, namely the clarity of the main contribution and the distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear direction for the authors to enhance their literature review by offering a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific areas of improvement based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the literature review. It points out that the current literature review lacks clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. This feedback is clear and actionable, as it provides a direct suggestion for the authors to enhance their literature review by offering a more explicit and comparative analysis of related work. By addressing this feedback, the authors can better position their work within the existing literature and enhance the clarity and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and provide concrete actions for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two distinct suggestions for improvement: (i) adding performance on word similarity and sentence translation tasks, as in the MUSE paper, to enhance credibility, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are supported by logical reasoning, as they provide specific examples of tasks and languages that could enhance the robustness and effectiveness of the framework. However, the comment could be strengthened by referencing the MUSE paper or providing more detailed reasoning for why these additions would be beneficial. Overall, the claim is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the experiments in the paper. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. This is a clear and actionable suggestion that could significantly strengthen the paper\"s claims. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This addition would broaden the applicability and relevance of the framework, making it more robust and useful. The feedback is detailed and provides concrete steps for the authors to take, making it 5 for improving the draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. While the comment highlights areas of concern, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the experimental setup and the inclusion of related works, but it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. The comment provides a logical reasoning by questioning the relevance of node importance in the 1shot scenario and pointing out a discrepancy in the experimental setup. However, it lacks specific examples or detailed references to support the claim fully. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two important questions about the paper. First, it questions the relevance of node importance in the 1shot scenario, which is a critical aspect of the paper\"s methodology. Second, it points out that the paper does not include a 1shot paper setting in the experiments, despite related works like RALE having this setting. These questions highlight potential gaps or inconsistencies in the paper\"s methodology and experimental setup, which could be addressed to improve the draft. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, such as proposing alternative approaches or suggesting additional experiments. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to do so or what aspects should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more discussion and determine the specific content themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper should include these discussions, making it weakly grounded. The comment is specific in its request for additional discussion on a particular topic, but without clear grounding, the authors may find it challenging to determine where to make these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. This feedback is clear and actionable, as it provides a direction for the authors to expand their discussion and potentially enhance the depth and relevance of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach this topic. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. While the comment implies that the authors should make these observations and conclusions more prominent, it does not provide specific guidance on how to achieve this, such as suggesting where to place them or what format to use. The action is implicit and somewhat vague, as the authors can infer that they need to make changes but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, it does not specify which part of the experimental section contains these observations or conclusions, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in suggesting how to improve the paper by highlighting these observations and conclusions, but it lacks full grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the tradeoffs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why these observations and conclusions are currently hidden or how they could be better highlighted. Without additional context or evidence, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of observations and conclusions in the experimental section, suggesting that they are hidden and could be better highlighted to improve understanding of the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and impact of their work. However, the comment could be more helpful if it offered suggestions on how to effectively highlight these observations and conclusions, such as through specific formatting or placement within the paper. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments. However, it does not specify which modifications should be tested or how to implement the ablation experiments, leaving some room for ambiguity. Therefore, the comment is 4, as it clearly identifies the need for additional experiments but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. However, it does not specify which specific modifications are being referred to, nor does it provide details on what kind of ablation experiments are needed. This lack of specificity makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment is 1 as it does not explicitly mention a section or part of the paper, leaving the authors to infer the relevant context. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance, specifically mentioning modifications from Section 3.4. However, the comment does not provide any reasoning or evidence to support why these modifications are significant or how they might impact the model performance. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the necessity of the suggested experiments. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is clear and actionable, as it identifies a specific area for improvement by recommending additional experiments to substantiate the effectiveness of the modifications. However, the comment could be more helpful if it provided more detailed guidance on which modifications to focus on or how to design the ablation experiments. Despite this, the suggestion is valuable and provides the authors with a concrete step to enhance the robustness of their findings. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the KDE\"s requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It also references an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests showing a comparison of performance on datasets with decision spaces beyond binary. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it is possible to show a comparison of performance on datasets with decision spaces beyond binary. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the KDE\"s requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It contrasts this with an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests comparing the performance on datasets with decision spaces beyond binary. However, the claim is 3 as it lacks specific examples or detailed reasoning to fully substantiate the comparison. The reference to Zhang et al. provides some context but does not fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the KDE\"s requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It contrasts this with an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests that the authors should consider showing a comparison of performance on datasets with decision spaces beyond binary. This feedback is 3 as it identifies a potential limitation in the paper and provides a direction for further exploration. However, it lacks specific guidance on how to conduct the comparison or what aspects to focus on, which could be more beneficial for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or investigate the potential issues. The authors are left to infer that they need to explore these aspects further, but without concrete guidance on how to do so, the comment lacks actionability. Therefore, it is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on what aspects of the SR model capacity or the pipelining method are causing the unexpected artifacts. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: \"How the capacity of the SR model affects the FID\" and \"whether there are unexpected artifacts due to the proposed method being pipelined.\" These are requests for clarification or additional information, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions are relevant and could lead to further exploration and clarification in the paper, the comment lacks specificity and actionable guidance. It does not provide suggestions on how to address these questions or improve the paper, leaving the authors with a general direction but no detailed steps to take. Therefore, the comment is 2, as it identifies areas for improvement but does not offer actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might be meant to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The comment also notes that the authors\" socalled \"proof\" is missing. While the comment identifies specific issues and provides some context, it does not explicitly instruct the authors on how to address these issues or what specific actions to take. The feedback is 3 as it highlights areas that need clarification or improvement, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with these sections, such as the blank appendix and the unclear purpose of the proposition. The comment provides a suggestion that the proposition might be meant to illustrate a wellknown concept in machine learning, which adds further clarity. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear, suggesting it might be meant to illustrate a wellknown concept in machine learning. The reviewer also notes that the authors\" socalled \"proof\" is missing. While the comment raises valid concerns about the clarity and completeness of the appendices, it lacks specific examples or references to support the claim that the concept is wellknown or that the proof is missing. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or explanation to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the appendices, specifically noting that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might be meant to illustrate a wellknown concept in machine learning, such as the classic partitioning principle of Kmeans. Additionally, the comment points out that the authors\" socalled \"proof\" is missing. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues, such as what content should be included in Appendix A or how to clarify the purpose of Proposition B.1. The feedback is 3 as it directs the authors\" attention to specific areas needing attention, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the approximations introduced in the paper, specifically mentioning the vulnerability due to the assumption of attacks being in the feasible set. It suggests that this vulnerability needs to be expanded upon to reassure readers that it is not a real concern. While the comment identifies a potential issue and suggests addressing it, it does not provide specific guidance on how to expand the discussion or what additional information should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability in the approximations introduced and suggests expanding the discussion to reassure readers that this vulnerability is not a real concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approximations introduced in the paper leave loose ends and suggests expanding the discussion to reassure readers that the vulnerability is not a real concern. However, the comment does not provide specific examples or detailed reasoning to support the claim about the vulnerability or the need for expansion. The lack of detailed justification or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the approximations introduced in the paper, specifically mentioning a vulnerability due to the assumption of attacks being in the feasible set. It acknowledges the necessity of approximations for deriving clean results but suggests that the authors should expand on this vulnerability to reassure readers that it is not a real concern. This feedback is 3 as it points out a specific area that needs further clarification or discussion. However, it could be more helpful if it provided suggestions on how to address this vulnerability or expand the discussion. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. However, it implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the analysis or what details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. It implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures. However, it does not specify which benchmarks are considered \"old\" or how the data might have been indirectly seen, making it weakly grounded. The comment is specific in suggesting the need for more detailed analysis and evaluation procedures, but without explicit references to specific sections or parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. It suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures. While the claim about the model\"s performance is factual, the suggestion for a more careful analysis and the mention of \"old\" benchmarks are subjective and require further justification. The comment lacks specific examples or references to support the claim about the \"data curation\" process or the need for more detailed evaluation procedures. Therefore, the claim is 3, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on various benchmarks, setting new stateoftheart (SOTA) scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures, which could help clarify the methodology and results. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks specific guidance on how to conduct the more thorough analysis or what details to include in the evaluation procedures. This limits the comment\"s helpfulness, as it provides a general direction but not detailed actionable steps. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. While the comment implies that the authors should add collaborative games to their experiments, it does not provide specific guidance on which games to choose or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding collaborative games to the experiments to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or experiments, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its request for collaborative games but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this would be interesting or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This feedback is 3 as it identifies a potential area for improvement by suggesting a broader evaluation of the methods. However, the comment lacks specificity and does not provide guidance on how to implement collaborative games or what specific benefits might be gained from this addition. While it points out a direction for enhancement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not provide explicit guidance on what specific information should be included or how the authors should present it. The action is implicit, as the authors can infer that they need to provide experimental settings, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not specify which part of the paper discusses these figures, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of missing experimental settings, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes the results less convincing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the paper, noting the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. This is a critical observation that highlights a gap in the presentation of the experimental results, which is essential for the paper\"s credibility. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of specific details or methods. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. While it identifies a gap in the explanation, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically questioning how the proposed method avoids impeding the learning of new task knowledge. It mentions the observation that current parameter isolation methods often hinder the acquisition of new task knowledge, and it highlights the suggestion of pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment also points out that some parameter isolation methods are specifically tailored to leverage this sparsity, which adds a layer of complexity to the explanation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or methodology sections where the rationale and method are discussed. The comment is specific in detailing the issue of ambiguity in the explanation but lacks full grounding as it does not explicitly mention a section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the rationale behind the work, suggesting that the authors\" observation that current parameter isolation methods hinder the acquisition of new task knowledge is not fully supported. The comment questions how the proposed method avoids this issue, noting that some parameter isolation methods are specifically tailored to leverage sparsity. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. It highlights a gap in the explanation by pointing out that some parameter isolation methods are specifically tailored to leverage sparsity, which could be relevant to the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it raises an important point, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should integrate benchmark comparisons against stateoftheart fairness algorithms in the experimental section. This is a clear and direct action that the authors can take to enhance their paper. The comment provides a concrete suggestion by specifying the need for benchmark comparisons, which would offer tangible evidence of the proposed method\"s performance and position it within the existing FairML research landscape. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of benchmark comparisons with existing fairness algorithms. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include comparisons with existing fairness algorithms in the experimental section. The claim is supported by logical reasoning, as it highlights the importance of benchmarking to position the proposed method within the existing FairML research landscape. However, the comment could be strengthened by providing specific examples of relevant fairness algorithms or studies that could be used for comparison. This would make the claim more verifiable. Therefore, the comment is categorized as 4, as it provides a solid basis for the suggestion but lacks detailed references or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper\"s credibility and position the ManyFairHPO framework within the existing FairML research landscape. This feedback is valuable as it guides the authors on how to strengthen their experimental section and improve the overall impact of their work. However, the comment could be more helpful if it offered specific examples of algorithms to consider or detailed guidance on how to conduct these comparisons. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment challenges the claim of \"generalpurpose neural network model\" made in the paper. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their claims or provide additional evidence to support them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and the \"downstream experiments\" on QM9, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a concrete example of the poor performance of TransformerM on most tasks other than homo, lumo, and gap, which challenges the claim of the paper being a \"generalpurpose neural network model.\" This level of detail helps the authors understand the issue and potential areas for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, citing the example of TransformerM performing poorly on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This claim is 3 as it provides a specific example of poor performance, which supports the assertion of negative transfer. However, the comment lacks detailed reasoning or references to substantiate the claim fully. The authors would need to further explore the implications of this example to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically citing the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This feedback challenges the claim of the paper being a \"generalpurpose neural network model,\" as it highlights a specific issue with the model\"s performance. While the comment identifies a potential weakness, it does not provide detailed guidance on how the authors might address this issue or improve their model\"s performance. The feedback is 3 as it points out a critical area for improvement, but it lacks actionable suggestions or detailed advice, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 8082. While the comment highlights a potential inconsistency or lack of clarity, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their reasoning or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (4 A&B) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the authors\" use of the center correlation metric, which was previously deemed uninformative, and asking for clarification on why it was found useful in this context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 8082. This comment raises a valid point about the inconsistency in the authors\" reasoning, but it does not provide any specific evidence, references, or detailed reasoning to support the claim. The lack of additional context or explanation makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it highlights a potential inconsistency but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" use of the center correlation metric. It points out that the metric was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer questions the authors\" reasoning and asks for clarification on why this metric was found useful in this context. This feedback is 3 as it highlights a specific area of confusion or inconsistency in the paper, prompting the authors to clarify their rationale. However, the comment could be more helpful if it provided suggestions on how to address this inconsistency or offered alternative metrics that might be more appropriate. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a rationale for this suggestion by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment does not explicitly instruct the authors to change the terminology or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider the terminology but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the terminology used to describe the phenomenon, suggesting that it might be too strong and that the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero might not be the case. The comment offers a specific suggestion for improvement by proposing a more accurate description of the phenomenon. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. The reviewer provides a logical reasoning by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used to describe the empirical phenomenon presented in the paper, specifically the term \"distributional generalization.\" It provides a rationale for this critique by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. This feedback is clear and actionable, as it suggests a more accurate description of the phenomenon, which could help the authors improve the clarity and precision of their work. However, the comment could be more helpful if it offered specific suggestions on how to rephrase or redefine the term. Overall, the comment is 4, as it provides valuable insight into a potential terminology issue that could be addressed to enhance the paper\"s clarity and accuracy."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this issue or whether the authors should make changes to their wording. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"above/below diagonal\" and \"above/below 45 degree,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree\" to avoid confusion. This specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. The reviewer provides a logical reasoning by explaining that the diagonal reference is more general and not specific to a local property, such as when the red line saturates. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear direction for the authors to enhance the interpretability of their work. By addressing this suggestion, the authors can improve the readability and understanding of their results, which is a valuable contribution to the paper. However, the comment could be more helpful if it explained why the suggested change would be beneficial or provided additional context. Overall, the comment is 4 as it offers a concrete improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the wording in lines 240 and 428, suggesting that the phrase \"is sufficient\" needs clarification. It provides a potential correction, indicating that the authors might want to write that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is explicit and provides a clear direction for the authors to improve their draft by clarifying the intended meaning. The action is concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the phrase \"is sufficient\" should be clarified by writing that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" in lines 240 and 428, suggesting that it should be clarified. The reviewer provides a potential correction, stating that the sum of the \"optimistic\" hopedfor rewards should be close to the expected actual rewards. This feedback is logical and provides a clear suggestion for improvement, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in lines 240 and 428, where the phrase \"is sufficient\" is used without clear context. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their writing. However, the comment could be more helpful if it included additional context or examples to further guide the authors in making this clarification. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models and whether it offers an explanation for the emergence of solutions through optimization. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer explanation of the scientific contribution and potential advantages of their model. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically mentions Section 2.3, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific in detailing what is unclear, namely the lack of a prototype approximation to nonlinear RNN models and the absence of an explanation for emergent behavior through optimization. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models and whether it offers an explanation for emergent behavior through optimization. The comment provides a logical reasoning by pointing out the lack of a clear explanation for the model\"s contribution. However, it does not include specific references or examples to support the claim, making it 3. The authors would need to provide additional evidence or clarification to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically points out the lack of a prototype approximation to nonlinear RNN models and questions whether the work offers an explanation for emergent behavior through optimization. This feedback is clear and actionable, as it prompts the authors to clarify the unique contribution of their model and its potential advantages over existing approaches. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or offered examples of how to demonstrate the model\"s advantages. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computation time reduction and the loss of information due to the reduced search space. It questions the extent to which the ancestral graphs encode the information of DAGs. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to improve their draft. The comment implies that the authors should consider the tradeoff and its implications, but it lacks concrete steps or recommendations. As a result, the comment is 3, as it highlights an important consideration but does not offer direct guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its comparison with [10], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the tradeoff between computation time reduction and the loss of information due to the reduced search space. The comment raises a question about the extent to which ancestral graphs encode the information of DAGs, which provides a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the tradeoff between computation time reduction and the loss of information due to the reduced search space. It compares the proposed method with a previous work ([10]) and suggests that the output of the proposed method has less information compared to the output of [10] due to the reduced search space. The comment questions the extent to which ancestral graphs encode the information of DAGs. While the claim is based on a logical comparison and raises a valid point, it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate the claim themselves. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a tradeoff in the proposed method, specifically the reduction in computation time achieved by limiting the search space to ancestral graphs, which results in a loss of information compared to the output of a method with a richer search space (DAGs). This observation is relevant and highlights a potential limitation of the proposed approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this tradeoff or mitigate the loss of information. While it raises an important point, the feedback lacks actionable advice, making it 3. The authors are left with a general understanding of the issue but without clear steps to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what the authors should discuss, making it 5.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion section, where such a discussion could be included. The suggestion is specific in detailing what should be discussed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This suggestion is supported by logical reasoning and a clear example, making the claim 5. The authors can understand the rationale behind the suggestion and how it could enhance their discussion, providing a clear path for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the discussion section of the paper. It recommends including a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. The comment offers a concrete example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is clear and provides the authors with a direct path to enhance their discussion, making it 5. By addressing this suggestion, the authors can significantly improve the comprehensiveness and depth of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchorbased regression and the regression in RepPoints. It also mentions that RetinaNet and ATSS use a oneshot regression, which is similar to the method in RepPoints. The reviewer suggests that the authors clarify this issue, as the motivations for the method may not be solid without a clear distinction. While the comment implies that the authors should clarify the definitions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the doubts about the definitions in Table 1, particularly the distinction between anchorbased regression and the regression in RepPoints. The comment further explains the similarities between RetinaNet, ATSS, and RepPoints, and suggests that the motivations for the method may not be solid without a clear distinction. This provides clear guidance on what needs to be clarified or improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1, specifically questioning the difference between anchorbased regression and the regression in RepPoints. It provides a detailed comparison with other methods like RetinaNet and ATSS, which use a oneshot regression, and suggests that the method that directly regresses [w, h] to the center point is sufficient. The reviewer also expresses doubt about the motivations for the method, suggesting that the authors clarify this issue. While the comment provides a logical comparison and reasoning, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a solid basis for the claim but requires more detailed justification or references to be 5.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, particularly the distinction between anchorbased regression and the regression in RepPoints. It provides a detailed comparison with other methods like RetinaNet and ATSS, which use a oneshot regression, and suggests that the method that directly regresses [w, h] to the center point is sufficient. The reviewer also questions the motivations for the method, suggesting that the authors clarify this issue. This feedback is clear and actionable, as it identifies a potential confusion in the paper and offers a specific suggestion for improvement. By addressing these points, the authors can enhance the clarity and robustness of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together, which results in experiments that are difficult to understand. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of the paper. The comment lacks actionable details, such as recommending specific changes to the presentation or experiments to make them more intuitive. As a result, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper\"s lack of clarity and difficulty in understanding the pieces that fit together. However, it does not specify which parts of the paper are particularly challenging or what specific aspects need improvement. The authors might infer that the experiments are difficult to follow, but the comment lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded as it does not identify a specific part of the paper, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the pieces fit together. This observation is important as it highlights a fundamental weakness in the paper\"s presentation and structure. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback, the authors are left without a clear path to address the issues raised. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses this training method or where the KID/FID metrics should be included. While the authors might infer that it relates to the methodology or results sections, the lack of explicit references makes it weakly grounded. The comment is specific in its request for metrics, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment lacks specific reasoning or evidence to support the claim that training the networks simultaneously may improve performance. It does not provide examples, references, or detailed explanations to substantiate the suggestion. As a result, the claim is not verifiable, as it lacks sufficient justification or evidence to support the assertion. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network, which could provide additional insights into the performance of the model. While the comment identifies a potential issue and provides a specific request for additional metrics, it lacks depth and does not offer detailed guidance on how to address the fairness concern or interpret the KID/FID metrics. The feedback is 3 as it points out an area for improvement, but it could be more comprehensive with additional suggestions or explanations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. While the comment implies that the authors should consider this scaling factor, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they should consider the scaling factor but are not given concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning the scaling factor and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. The reviewer provides a logical reasoning by explaining the relationship between the attention weight and the scaling factor. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the implications of this scaling to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. This feedback is 3 as it identifies a potential issue with the scaling of the vector and prompts the authors to consider an alternative approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular scaling method or explaining the potential benefits of introducing a scaling variable. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the LLM\"s performance or what specific changes should be made to enhance the recovery of formal goal predicates. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the LLM\"s performance on the ALFRED benchmark, particularly regarding goal misspecification. However, it does not specify which part of the paper discusses the LLM\"s performance or where the issue of goal misspecification is detailed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\"s performance, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate. The comment provides a logical explanation by mentioning the challenges posed by ambiguities in human language. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further investigate the issue to fully understand and address the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is 3 as it highlights a potential weakness in the LLM\"s performance and provides some insight into the cause of the issue. However, the comment lacks actionable suggestions or guidance on how the authors might address this problem, such as recommending specific techniques or modifications to improve the LLM\"s performance. Without actionable advice, the authors may find it challenging to implement the necessary changes to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to implement it or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the sections discussing the models and their performance. The suggestion is specific in detailing what additional analysis could be conducted, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This claim is 3 as it provides a specific suggestion for enhancing the paper\"s analysis, but it lacks detailed reasoning or examples to fully substantiate the need for this additional investigation. The authors would need to infer the potential benefits of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It provides a concrete example of how this could be achieved by presenting differences in false positive rates (FPR) between models with and without ReGuide. This feedback is actionable and offers a clear direction for the authors to enhance their analysis, providing valuable guidance for improving the depth and nuance of their conclusions. However, the comment could be more helpful if it included specific suggestions on how to conduct this analysis or what other metrics might be relevant. Overall, the comment is 4 as it effectively directs the authors to a meaningful area for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This is a clear and direct action for the authors to take, providing them with a specific task to enhance their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be supplemented, namely, the result comparison between the two methods. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests supplementing the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by adding additional analysis or results. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall impact. Despite this, the feedback is 4 as it guides the authors toward a specific enhancement that could strengthen their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to clarify the axes or what information should be included to make them more understandable. Without any actionable advice or concrete steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing a difficulty in understanding the axes of Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a clear area for improvement in the clarity of the figure. However, it lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending additional labels, explanations, or alternative visualizations. Without specific advice, the authors may struggle to determine the exact steps needed to enhance the figure\"s clarity. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that direct runtime comparisons with existing methods are missing, emphasizing the need for such comparisons to demonstrate the efficiency of the proposed approach. The comment provides a clear and concrete action for the authors to take, which is to include direct runtime comparisons with existing methods. This feedback is 5 as it specifies exactly what the authors need to do to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, which allows the authors to identify the specific part of the paper that needs attention. It also specifies the issue by pointing out the absence of such comparisons and the importance of demonstrating the efficiency of the proposed approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The comment provides a logical reasoning by stating that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific existing methods or providing examples of how such comparisons would be beneficial. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of direct runtime comparisons with existing methods. It highlights the importance of such comparisons to demonstrate the efficiency of the proposed approach, particularly given the computational costs associated with implicit differentiation. This feedback is clear and actionable, providing the authors with a concrete step to enhance their draft by including direct runtime comparisons. However, the comment could be more helpful if it suggested specific methods to compare against or provided guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of focusing on which clusters are \"best\" rather than exploring the differences in representation between them, given the paper\"s motivation. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their focus, but it lacks concrete details on how to make this change or what specific aspects of the representation differences should be explored. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\"s motivation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the focus on \"best\" clusters, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\"s motivation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is odd or how it deviates from the paper\"s motivation. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\"s motivation. This feedback highlights a potential mismatch between the paper\"s objectives and its approach, which could be a significant issue. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or what alternative approaches could be considered. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of how the paper could be improved by discussing the Elementlevel Graph Pretraining, which abandons the strategy of capturing complex structure and focuses on core elements. The reviewer also references a specific example of a case study from another paper, \"Graph pretraining for AMR parsing and generation,\" which could serve as a model for the authors. This feedback is explicit and provides concrete guidance on how to enhance the paper by including case studies and error studies. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of how the paper could be improved by discussing the Elementlevel Graph Pretraining, which abandons the strategy of capturing complex structure and focuses on core elements. The comment also references a specific example of a case study from another paper, \"Graph pretraining for AMR parsing and generation,\" which could serve as a model for the authors. This provides clear guidance on what needs to be addressed and offers a specific example, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of how the paper could be improved by mentioning the Elementlevel Graph Pretraining and its focus on core elements. The reviewer also references a specific example of a case study from another paper, \"Graph pretraining for AMR parsing and generation,\" which could serve as a model for the authors. This provides a clear and logical reasoning for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. It specifically mentions the Elementlevel Graph Pretraining and how it focuses on core elements, suggesting that this could be better illustrated through case studies. The comment also references a specific example from another paper, \"Graph pretraining for AMR parsing and generation,\" which could serve as a model for the authors. This feedback is detailed and offers a concrete way for the authors to enhance their draft, making it 5. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The reviewer also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to improve the evaluation. The feedback is 3 as it highlights an area for clarification, but it lacks concrete steps for the authors to follow. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework, specifically mentioning explicitness (E) and size (S) as potential considerations. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The comment also raises a concern about the entanglement between DCI and ES, suggesting that changes in probing capacity or latent size could affect the DCI evaluation. However, the comment does not explicitly mention which part of the paper this discussion is based on, making it weakly grounded. The authors can infer that it relates to the methodology or evaluation sections, but this inference is not as direct as it could be. The comment is specific in detailing the concerns about the evaluation process, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The reviewer also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific references or detailed examples to support the claim that DCI and ES are entangled. While the reasoning is logical, the lack of concrete evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The comment also points out that DCI and ES may be entangled, as changes in probing capacity or latent size could affect the DCI evaluation. While the comment identifies potential issues and provides some insight into the evaluation process, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it highlights areas for clarification and improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. While the comment identifies specific problems, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the organization and layout of their paper, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. The authors can accurately identify the parts of the paper being addressed, such as Figure 1, Figure 2, and Table 2. Additionally, the comment is specific because it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and provides specific examples of issues with the layout, such as font size, figure placement, and table insertion. However, it lacks detailed reasoning or references to support these claims, such as comparisons to other wellorganized papers or guidelines for proper layout. The comment provides some evidence through specific examples, but it does not fully substantiate the claim with comprehensive reasoning or references. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several specific issues with the organization and layout of the paper, such as font size, figure placement, and table insertion. It provides clear and actionable feedback by pointing out these specific problems, which can help the authors improve the readability and presentation of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided guidance on improving the overall organization of the paper. Despite this, the feedback is 4 as it directs the authors to specific areas that need attention, allowing them to make targeted improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not provide explicit guidance on how to address this concern or what specific steps the authors should take to evaluate the practicality and safety of their interventions. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess the practicality and safety of their interventions but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not identify a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, the comment does not provide specific examples, reasoning, or references to support why these interventions might be impractical or unsafe. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important consideration regarding the practicality and safety of the interventions discussed in the paper. It suggests that the authors should think about whether these interventions are feasible and safe for querying in the real world. This feedback is relevant and provides a valuable perspective for the authors to consider when refining their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to assess the practicality and safety of the interventions. Despite this, the comment is 3 as it prompts the authors to address an important aspect of their work that could impact its applicability and safety."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what changes, if any, should be made to the draft. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the treatment or interchangeability are unclear or problematic. Without explicit references to sections or detailed explanations, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of how to address this concern or what changes might be beneficial. As a result, the comment is 1, as it does not provide any actionable insights or direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should evaluate the proposed method\"s performance gain by comparing it to baseline detection or parsing techniques separately. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional evaluations to support their claims. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and its two major components, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the contribution of each component to the performance gain and suggests evaluating the proposed approach separately against baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the contribution of each component in the proposed method and suggests evaluating it separately against baseline detection or parsing techniques. This claim is 3 as it highlights a potential gap in the paper\"s evaluation, but it lacks specific examples or references to support the suggestion. The authors would need to consider the reviewer\"s point and potentially conduct additional experiments to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the evaluation of the proposed method. It points out that the contribution of each component to the performance gain is unclear and suggests evaluating the proposed approach separately against baseline detection or parsing techniques. This feedback is clear and actionable, providing the authors with a concrete step to take to better support their claims. By addressing this feedback, the authors can enhance the clarity and robustness of their evaluation, which is crucial for the credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. While the comment implies that the authors should consider alternative approaches to disentangling, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods for disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The reviewer suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment lacks specific reasoning or evidence to support why this manual disentangling is problematic or how it could be improved. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the manual disentangling of the semantic segmentation network as the first module in the pipeline. It questions the rationale behind this choice and suggests that it would be more interesting if the paper did not have this type of manual disentangling and everything was learned. This feedback is 3 as it points out a potential weakness in the methodology and encourages the authors to consider alternative approaches. However, the comment lacks detailed guidance on how to address this issue or what specific changes could be made to improve the paper. While it provides some direction, it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what additional information or analysis should be included to clarify this point. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis where this assumption is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to justify why this assumption is important or how its absence affects the method\"s behavior. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the method behaves without the Lipschitz Hessian assumption. This is a relevant observation that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or clarify the method\"s behavior. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide explicit guidance on how the authors should address this issue or improve the clarity of the presentation. The comment implies that the authors should clarify the methods used, but it lacks concrete suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions specific elements, such as \"equation (12)\" and the \"presentation of these methods,\" which allows the authors to identify the parts of the paper being addressed. However, it does not specify what aspects of the presentation are vague or how they could be improved. The comment lacks detailed guidance on what needs to be clarified or how to enhance the clarity. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some of the pieces are using existing methods and that the presentation of these methods is vague. This feedback is 3 as it points out a potential area for improvement, specifically the clarity of the presentation. However, the comment lacks detailed guidance or suggestions on how the authors might clarify or enhance the presentation of these methods. Without specific advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples or suggestions for improvement. It lacks explicit guidance or concrete actions for the authors to take to address the issue. The comment is vague and does not offer any actionable steps for the authors to enhance the clarity of their draft. As a result, the authors are left without a clear understanding of what needs to be done to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the writing or presentation is \"jumbled\" at times, but it does not specify which parts of the paper are affected or what aspects are unclear. This makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Without detailed guidance, the authors cannot effectively address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the writing or presentation is \"jumbled\" at times, suggesting that the structure or organization of the paper may be unclear or difficult to follow. However, it does not provide specific examples or details about where the jumbled sections are located or what aspects need improvement. Without actionable feedback or suggestions for clarification, the comment lacks depth and does not offer the authors a clear path for enhancing their draft. As a result, it is 2, as it identifies a potential issue but does not guide the authors in addressing it effectively."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand on a mobile device. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of computational complexity or power demand should be considered. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides a specific context (mobile device power demand), it lacks detailed guidance on how to address the issue or what specific aspects of computational complexity should be considered. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand on a mobile device. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim about the computational complexity or power demand. The comment lacks specific examples or data to justify the concern, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand on a mobile device. While it identifies a potential area of concern, it lacks specificity and actionable guidance. The comment does not provide detailed suggestions on how to address the issue or what specific aspects of computational complexity or power demand should be considered. Without clear direction, the authors may struggle to understand how to improve their draft in this regard. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. However, it does not provide explicit guidance on how to address this issue or suggest specific steps for developing a distributed version. The action is implicit and lacks concrete details, leaving the authors to infer that they need to explore scalability and potentially develop a distributed version. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. However, it does not specify which part of the paper discusses the method or its scalability, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of scalability but lacks grounding, as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version might be necessary to handle large datasets. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential scalability issue with the method, suggesting that a distributed version might be necessary to handle large datasets. This is a relevant concern that could impact the practical application of the method. However, the comment lacks specific guidance or suggestions on how the authors might address this scalability issue or develop a distributed version. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights an important area for consideration but does not provide sufficient detail for the authors to effectively address the issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in lines 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard to support this claim. This feedback is explicit and provides concrete examples, making it 5. Second, the comment critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated later in the paper. While the comment identifies an issue, it does not provide specific guidance on how to address it, leaving the authors to infer that they should revise or remove the analogy. Overall, the comment is 4, as it provides clear guidance on one point but requires more detail on the other.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15, L1618) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks and referencing specific literature and a leaderboard. Additionally, it critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two distinct claims. The first claim, regarding the vagueness of the statement in line 15, is supported by a reference to specific literature and a leaderboard, providing a clear basis for the critique. This makes the claim 4. The second claim, about the reinforcement learning / agent analogy being outofplace, is supported by a logical reasoning that suggests generalization capabilities are better illustrated later in the paper. However, the comment could be strengthened by providing specific examples or references to illustrate this point more effectively. Overall, the comment is 4, as it provides a solid foundation for the first claim but could be improved with more detailed support for the second claim.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard to support this claim, which is a helpful addition. Second, the comment critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated later in the paper. While the comment identifies a potential issue, it does not offer specific suggestions on how to address the analogy or improve its placement. Overall, the feedback is 4 as it highlights areas for improvement and provides some guidance, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: first, it notes that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and second, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to provide more detailed analysis or justification for the proposed method, but without specific instructions on what this analysis should entail. Therefore, the comment is 3, as it highlights areas for improvement but lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and that the authors do not further discuss this observation. Additionally, it notes the lack of mathematical or theoretical justification for the proposed Algorithm.1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and that the authors do not further discuss this observation. Additionally, it notes the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these issues, it does not provide specific examples, detailed reasoning, or references to support the claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and the authors do not further discuss this observation. This feedback highlights a potential gap in the paper that could be addressed by providing additional analysis or discussion. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm.1, which is a critical aspect of the paper\"s methodology. By pointing out these areas, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what a more detailed analysis might entail. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuplelike structure rather than as sets. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be changed in the draft. The comment provides concrete guidance on how to improve the presentation of the data, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of triples, suggesting that they should be shown in a tuplelike structure rather than as sets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of triples as $(e_1, r, e_2)$ should be changed to a tuplelike structure instead of sets. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or understanding of the data. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of data in the paper. By recommending that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuplelike structure rather than as sets, the reviewer offers a clear and concrete way for the authors to enhance the clarity and readability of their work. This feedback is valuable as it directly addresses a potential confusion in the data representation, which could help the authors improve the overall quality of their draft. However, the comment could be more helpful if it explained why this change is important or how it might impact the understanding of the data. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional context."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the scalability of optimal quantization, noting that it is mentioned in the paper and is a bottleneck for achieving fast convergence in big data/big model settings. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their method. The feedback lacks actionable details, such as recommending specific techniques or approaches to enhance scalability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It also mentions the paper\"s aim to speed up VI by fast convergence, which is a bottleneck for big data/big model settings. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the scalability problem and its impact on the paper\"s objectives, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper, and that it is a bottleneck for achieving fast convergence in big data/big model settings. The comment provides a logical reasoning by stating that even with clustering before, the quantization process is costly in terms of both the number of data points and the dimensionality. However, the comment lacks specific examples, references, or detailed explanations to fully substantiate the claim. While the reasoning is clear, the lack of supporting evidence or references makes the claim 3, as the authors might need additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the scalability of optimal quantization, which is mentioned in the paper as a bottleneck for achieving fast convergence in big data/big model settings. It highlights the potential loss of the method\"s point due to this scalability issue. However, the comment lacks specific suggestions or guidance on how the authors might address this scalability problem or improve the method\"s efficiency. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it points out a critical area for improvement but does not provide sufficient guidance to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare the effectiveness of their method, Contrastive Response Tuning, against existing methods like contrastive decoding. It also mentions that issues mentioned earlier should be addressed and suggests that the work should be considered for a more applicationoriented venue. The comment provides clear and specific actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison with existing methods, such as contrastive decoding, and addressing the \"notations issues.\" This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. It mentions that this comparison is necessary to address issues mentioned earlier and suggests that the work should be considered for a more applicationoriented venue. However, the comment does not provide specific examples of existing methods or detailed reasoning for why this comparison is crucial. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the importance of the comparison and its relevance to the paper\"s contribution. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. This comparison is crucial to validate the effectiveness of the proposed method and address issues mentioned earlier. Additionally, the comment advises that the work should be considered for a more applicationoriented venue, which is a constructive suggestion for improving the paper\"s relevance and impact. The mention of \"notations issues\" further highlights areas that need attention. Overall, the comment is clear, actionable, and provides valuable guidance for the authors to enhance their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically regarding the requirement for access to the entire training dataset. It also questions the comprehensiveness of the related validation experiments and the analysis of the algorithm\"s time complexity and efficiency. Additionally, the reviewer suggests that the authors should further clarify the technical contribution rather than focusing on the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to address these concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses multiple aspects of the paper, including the effectiveness and problem of the algorithm, the comprehensiveness of related validation experiments, the time complexity of computation, and the efficiency of the algorithm. However, it does not specify which sections or parts of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact areas needing revision. The comment is specific in its critique of the algorithm\"s requirements, the comprehensiveness of validation experiments, and the analysis of time complexity and efficiency. However, without explicit references to sections or parts of the paper, the authors cannot confidently determine where to make these improvements. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises several claims, including the need for the algorithm to access the entire training dataset, the lack of comprehensive validation experiments, and the absence of a clear analysis of time complexity and efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out the algorithm\"s requirement for access to the entire training dataset, questioning how it would operate effectively when the dataset is not fully perceptible. Additionally, it highlights the need for more comprehensive validation experiments and a clearer analysis of the algorithm\"s time complexity and efficiency. The comment also suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. While the feedback is clear about the areas needing improvement, it could be more helpful by providing specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it directs the authors\" attention to critical aspects of their work that require further development."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network.\" It points out that this is not true for RBF kernels, as the RKHS is infinitedimensional, requiring an NN with infinite width to represent it. The comment suggests that this limitation should be made more clear. While the comment identifies a specific issue and provides a clear direction for improvement, it does not explicitly instruct the authors to make the necessary changes or offer detailed guidance on how to address the limitation. The action is implicit and somewhat vague, as the authors know what needs to be clarified but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels and neural networks, providing a clear explanation of why the claim is incorrect and suggesting that the limitation should be made more clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, specifically for RBF kernels. The reviewer provides a logical reasoning by explaining that the RKHS for RBF kernels is infinitedimensional, requiring an NN with infinite width to represent it. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing additional literature or studies that further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network.\" It provides a clear and logical explanation of why this claim is incorrect, specifically for RBF kernels, by pointing out that the RKHS is infinitedimensional, requiring an NN with infinite width to represent it. The comment suggests that this limitation should be made more clear, which is a valuable insight for the authors to address. However, the comment could be more helpful if it offered specific suggestions on how to clarify this point or provided examples of how to address the limitation. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention handles autoregressive decoding during inference, specifically questioning whether the benefits of inference are maintained when only limited tokens are used to generate the next token. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to provide additional explanation or evidence regarding the inference process, but the comment lacks concrete steps or actions to take. Therefore, this comment is 3, as it identifies an area for clarification but does not offer specific guidance on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the linear attention mechanism\"s handling of autoregressive decoding during inference. It specifically asks how the network handles long token dimensions during training and whether it still benefits from inference when only limited tokens are used to generate the next token. However, the comment does not explicitly mention a specific section of the paper where this issue is discussed, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not straightforward. The comment is specific in its question about the inference process, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the linear attention mechanism\"s handling of autoregressive decoding during inference. It questions whether the benefits of inference are maintained when only limited tokens are used to generate the next token. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the concern. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the linear attention mechanism\"s handling of autoregressive decoding during inference. It points out a potential issue regarding the use of limited tokens for generating the next token, which could impact the benefits of inference. This feedback is 3 as it prompts the authors to consider and address a critical aspect of their methodology. However, the comment lacks specific suggestions or guidance on how to resolve this issue, such as recommending additional experiments or modifications to the model. To be more helpful, the comment could provide more detailed feedback or examples of how to address the concern. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model. It also suggests considering other measures, such as behavioral trajectories or time to goal, to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. While the comment implies that the authors should consider these questions and discussions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the possibility of GPI with noise added reproducing the data similarly well and suggests considering other measures, such as behavioral trajectories or time to goal, to demonstrate the limitations of GPI. Additionally, it suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of Generalized Pattern Inference (GPI) with noise added, suggesting that it might not reproduce the data as well as the original GPI model. It also proposes considering other measures, such as behavioral trajectories or time to goal, to demonstrate the limitations of GPI. The comment provides a logical reasoning by questioning the robustness of the model and suggesting alternative measures to evaluate its performance. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises several important questions and suggestions that could enhance the paper. It questions the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model, suggesting that other measures, such as behavioral trajectories or time to goal, could be considered to demonstrate the limitations of GPI. Additionally, it highlights the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and suggests discussing this aspect further. These questions and suggestions provide the authors with clear directions for improving their draft by addressing potential limitations and expanding the discussion. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to incorporate these suggestions. Overall, the feedback is 4 as it identifies areas for improvement and offers actionable insights, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach, if they have the resources to do so. While the comment implies an action\u2014conducting a comparison\u2014it does not explicitly instruct the authors to perform this analysis. Additionally, it lacks concrete guidance on how to conduct the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting a comparison, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is important or how it might impact the paper. The suggestion is based on the reviewer\"s personal interest, but it lacks the necessary justification or context to be considered verifiable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach, if the authors have the resources to do so. While this suggestion is specific and could provide valuable insights into the performance of the proposed method, it lacks depth and does not offer detailed guidance on how to conduct the comparison or what specific aspects to focus on. The comment provides a direction for further exploration but does not fully support the authors in making improvements to their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and suggesting that the distribution might have changed. The comment further highlights specific points of confusion, such as the need for experiments to disentangle changes in distribution from the removal of information. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. It also highlights specific points of confusion, such as the need for experiments to clarify these issues. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas for clarification, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the methods they are comparing using the same setting as the original paper, specifically using AdamW with cosine lr instead of Adam with fixed lr. This is a clear and direct action for the authors to take, as it provides a specific method for improving the fairness of the comparison. The comment also explains why this change is necessary, which adds to the clarity of the action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s use of AdamW with cosine lr for training, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness of comparing methods using Adam with fixed lr, suggesting that the authors should reproduce the results using the same setting as the original paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method\"s use of AdamW with cosine lr for training is unfair when compared to methods using Adam with fixed lr. The reviewer suggests that the authors should reproduce the results using the same setting as the original paper, as most recent methods have their code released. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action for improvement. However, the comment lacks detailed examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods in the paper. It points out that the proposed method uses AdamW with cosine lr for training, while the comparison methods use Adam with fixed lr. The reviewer suggests that this discrepancy makes the comparison unfair and recommends that the authors reproduce the results using the same setting as the original paper, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific direction to improve the fairness and validity of their comparisons. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the plots are terrible and provides specific reasons for this assessment, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are the main presentation of the experimental results and should be much clearer. This feedback is direct and provides concrete details on what needs to be improved, making it 5. The authors know exactly what aspects of the plots need attention and can take specific actions to enhance their clarity and readability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors, and the confusion between \"sdropout(tr)\" and \"edropout(tr)\" labels. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing suggestions on how to improve the plots, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axes, and visually similar labels. By pointing out these specific problems, the comment offers clear guidance on how to improve the presentation of the experimental results, which is crucial for the paper\"s clarity and impact. The reviewer\"s suggestion to make the plots clearer is direct and actionable, making this feedback 5 for the authors. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. While the questions imply that the authors should consider these aspects, they do not explicitly instruct the authors to conduct specific analyses or make changes to their draft. The action is implicit and somewhat vague, as the authors can infer that they need to explore these aspects but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It also asks for performance metrics with and without these types of information, as well as with just natural language feedback. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its questions about the performance metrics, but without grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the feedback network. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. This feedback is 3 as it prompts the authors to consider the impact of different types of information on the performance of their feedback network. However, it lacks specific suggestions or guidance on how to address these questions or improve the draft. While it identifies an area for exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, it does not provide specific guidance on how to achieve these improvements or what additional experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to enhance the experiments. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely the standard deviations, and suggests that more extensive experiments would strengthen the submission. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, it does not provide any specific reasoning or evidence to support why the inclusion of standard deviations or more extensive experiments would significantly improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it lacks standard deviations. It also suggests that the experiments could be more extensive to strengthen the submission. While the comment points out a clear area for improvement, it does not provide detailed guidance on how to address the issue or what specific experiments should be conducted. The feedback is 3 as it highlights a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with a general direction but not a comprehensive plan for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance boost due to more parameters, specifically comparing the results in Tables 1, 2, and 3 with those reported in [14]. It suggests that using a better Unary baseline could impact the performance boost. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions on how to address the issue or what specific actions to take. The authors can infer that they need to investigate the impact of different baselines on performance, but the comment lacks concrete guidance on how to conduct this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance boost due to more parameters, specifically comparing the results in Tables 1, 2, and 3 with those reported in [14]. The comment suggests that using a better Unary baseline could impact the performance boost, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to more parameters, specifically comparing the results in Tables 1, 2, and 3 with those reported in [14]. It suggests that using a better Unary baseline could impact the performance boost. The comment provides a logical reasoning by pointing out the difference in performance between LinearTop and NLTop, which adds additional parameters, and the performance of Unary, which is worse compared to the numbers reported in [14]. This comparison raises a valid question about the impact of different baselines on performance. However, the comment could be strengthened by providing specific references or examples from [14] to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid basis for the claim but lacks detailed references.", "helpfulness_rationale": "The review comment raises a pertinent question about the performance boost due to more parameters, specifically comparing the results in Tables 1, 2, and 3 with those reported in [14]. It points out that the addition of parameters in LinearTop and NLTop does not seem to improve performance compared to the Unary baseline, which is reported to perform better in [14]. This feedback is valuable as it prompts the authors to reconsider their assumptions about the impact of parameter addition on performance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative approaches to validate the performance boost. Overall, the comment is 4 as it identifies a potential weakness and encourages further investigation, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests several actions to improve the paper, including restructuring the sections (introduction>method>experiments) and focusing more on the IEM in Figure 3, which is considered the main figure. It also recommends improving the visualization of Figures 7 and . While the comment provides explicit actions, it lacks specific guidance on how to implement these changes, such as what specific elements to focus on or how to improve the visualization. The authors know what needs to be done but may struggle with the execution details, making the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the paper, such as restructuring the sections (introduction>method>experiments) and focusing more on the IEM in Figure 3, which is considered the main figure. It also recommends improving the visualization of Figures 7 and . However, the comment does not explicitly mention which sections are difficult to follow or where the figures are located, making it weakly grounded. The authors can infer that the issues are related to the structure and figures, but they cannot pinpoint the exact parts of the paper being addressed. Despite this, the comment is specific in detailing what needs to be addressed, such as the structure and visualization of figures. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the paper is difficult to follow and suggests improvements to the structure and focus on specific figures. However, it does not provide any specific examples or detailed reasoning to support why the paper is hard to follow or how the suggested changes would improve it. The comment lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including its structure and the focus on specific figures. It suggests restructuring the sections to improve readability and emphasizes the importance of the IEM in Figure 3, which is considered the main figure. Additionally, it recommends improving the visualization of Figures 7 and . While the comment provides actionable feedback, it could be more helpful by offering specific suggestions on how to restructure the sections or improve the visualizations. Overall, the comment is 4 as it directs the authors to areas that need attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly requests information about the final learning rates used for the deep models, particularly for CIFAR10 and CIFAR100. It also raises a concern about the potential impact of the learning rate search interval on the results, suggesting that the optimal learning rate for the baseline might be outside the tested interval. While the comment clearly identifies the need for additional information, it does not provide specific guidance on how to obtain or present this information. The action is explicit but somewhat vague, as the authors know what information is needed but may not be entirely sure of the best way to provide it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the final learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is missing and why it is important, namely the potential impact of the learning rate search interval on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the learning rates used in the experiments, specifically questioning whether the optimal learning rate for the baseline was within the tested interval. This is a logical claim based on the methodology described in the paper, as the authors only searched four different learning rates. However, the comment lacks specific examples or references to support the claim that the optimal learning rate could spoil the results. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by requesting information about the final learning rates used for the deep models, particularly for CIFAR10 and CIFAR100. This request is clear and actionable, as it prompts the authors to provide additional details that could impact the interpretation of their results. However, the comment could be more helpful if it provided context or reasoning for why this information is crucial or how it might affect the results. Overall, the feedback is 3, as it directs the authors to a specific area that requires clarification, but it could be more comprehensive with additional guidance or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses skepticism about the claim that a transformer free of localitybias is the best option. It suggests that the authors should explain why the absence of locality would not be a concern, given the limited speed of information propagation. While the comment implies that the authors should provide additional justification or evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment expresses skepticism about the claim that a transformer free of localitybias is the best option, suggesting that the authors should explain why this would not be a concern. However, it does not specify which part of the paper discusses this claim, making it weakly grounded. The comment is specific in its request for further explanation, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses skepticism about the claim that a transformer free of localitybias is the best option. It suggests that the authors should explain why this would not be a concern, given the limited speed of information propagation. The comment provides a logical reasoning based on the concept of localitybias and the potential impact of neighborhood agents on each other. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or explanation to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment expresses skepticism about the claim that a transformer free of localitybias is the best option, suggesting that the authors should explain why this would not be a concern. It provides a logical reasoning based on the limited speed of information propagation, implying that neighborhood agents should have more impact on each other compared to distant nodes. While the comment identifies a potential weakness in the argument and prompts the authors to provide further explanation, it lacks specific suggestions or examples on how to address this concern. The feedback is 3 as it points out an area for improvement but does not fully guide the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It suggests that additional experiments or more indepth analysis are necessary to better justify the claims in the paper. The comment provides a clear and direct action for the authors to take, which is to conduct further experiments or analysis to strengthen their claims. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The comment further suggests that additional experiments or more indepth analysis are needed to better justify the claims. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It supports this claim by pointing out that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This provides a logical reasoning for the claim, as it highlights the lack of robustness and consistency in the results. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is valuable as it highlights a potential weakness in the paper\"s claims about the effectiveness of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims, providing clear and actionable guidance for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on what additional experiments or analyses might be beneficial. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a direction for further work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the action is explicit, it lacks concrete guidance on how the authors should clarify the impact of these components. The suggestion is 3 as it directs the authors to provide more information, but it does not specify the exact steps or details needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure\" and the \"sophisticated filtering template,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of incorporating heuristic components and suggests that the authors clarify the impact of these components. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. The comment suggests that the authors clarify the impact of these heuristic components. However, the claim lacks specific examples or detailed reasoning to support the assertion about the effectiveness of the method or the impact of the heuristic components. Without such evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. It suggests that the authors clarify the impact of these heuristic components, which is a valuable suggestion for improving the transparency and comprehensiveness of the paper. However, the comment could be more helpful if it provided specific guidance on how to clarify the impact or offered examples of how other works have addressed similar issues. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the feasibility of training the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. The reviewer challenges the logic of the method by asking how the ray\"s origin can be determined without camera information. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation or justification for the method\"s functionality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without camera information, particularly regarding the use of \"CAD model correspondences\" and the determination of the ray\"s origin without knowing the viewpoint. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim by questioning the feasibility of training the proposed method without using camera information, specifically regarding the determination of the ray\"s origin. The reviewer challenges the logic of the method by asking how it can perform ray marching without knowing the viewpoint. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. The authors would need to infer the basis of the doubt and potentially conduct additional research to address the concern. Therefore, the claim is 3, as it provides a logical question but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a significant concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. The reviewer challenges the logic of the method by asking how the ray\"s origin can be determined without camera information, which is a critical aspect of the proposed approach. This feedback is clear and actionable, as it prompts the authors to address a fundamental issue with their method. However, the comment could be more helpful if it provided suggestions on how the authors might resolve this issue or offered alternative approaches to consider. Overall, the comment is 4 as it identifies a critical flaw in the method and encourages the authors to reconsider their approach, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that the authors should include a more detailed comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the discussion of related work, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a detailed comparison, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, the comment does not provide specific examples or references to support this claim, nor does it explain why a more detailed comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper would benefit from a more detailed comparison with related work, particularly focusing on the time complexity and competitiveness of prior art. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a more comprehensive analysis of the time complexity and competitiveness of their work compared to existing literature. However, the comment could be more helpful if it offered examples of how to conduct this comparison or suggested specific aspects to consider. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset rather than just the lowresource regime. This feedback is clear and provides a direct action for the authors to take, making it 5. The authors know exactly what needs to be done to improve their draft, which is to conduct additional experiments on more datasets and on the full dataset. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset rather than just the lowresource regime. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in suggesting additional experiments, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset rather than just the lowresource regime. This is a request for additional experiments, which is not a claim but rather a suggestion for improvement. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a limitation in the experimental evaluation by pointing out the lack of results on more datasets. It provides a clear and actionable suggestion to conduct experiments on more datasets, which would enhance the comprehensiveness of the evaluation. Additionally, it encourages experiments on the full dataset rather than just the lowresource regime, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it offered specific suggestions on which additional datasets to consider or how to approach the experiments on the full dataset. Overall, the feedback is 4 as it directs the authors toward a meaningful improvement in their experimental evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their work. The feedback lacks actionable details, such as what aspects of the dataset transformation or experimental setup need to be clarified or simplified. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. However, the comment does not specify which sections of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact parts that need revision. Additionally, while it highlights specific areas of concern, it lacks detailed guidance on how to address these issues. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references makes the claim 3, as the authors would need to infer the specific areas of concern and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in how the generic argument task and the random argument task support the authors\" claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors may struggle to understand exactly what changes are needed to improve the clarity and effectiveness of their work. Therefore, the comment is 3, as it points out areas for improvement but does not provide sufficient detail or direction for the authors to effectively address the issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for the authors to discuss the impact of adding additional parameters and additional computational effort due to the multistage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. While the comment implies that the authors should include this analysis, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"idea of jointly discovering, hallucinating, and adapting,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. Additionally, it suggests that the authors should provide this analysis for a fair comparison with the baseline [31, 33]. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is crucial or how it would impact the comparison. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and validity of their work. However, the comment could be more helpful if it offered guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that requires attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It highlights the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues. It lacks concrete details on what specific analyses or theoretical evidence should be included to improve the draft. As a result, the authors are left with a vague understanding of what needs to be done to enhance their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, which provides some grounding as it implies a specific part of the paper where this analysis is discussed. However, it does not explicitly mention the section or figure where this analysis is presented, making it weakly grounded. The comment is specific in detailing what is lacking, such as the need for clarity on whether the trend holds across different model architectures and the absence of theoretical evidence for the correlation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It questions the generalizability of this trend across different model architectures and the lack of theoretical evidence for the correlation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that is underwhelming, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. While the comment highlights a critical area for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance their analysis. The feedback is 3 as it directs the authors\" attention to a specific weakness, but it lacks actionable advice, making it incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the references list, noting that it contains duplicates and lacks publication venues and/or years for many papers. This feedback provides clear and explicit guidance on what needs to be corrected in the references section. The authors know exactly what needs to be done to address the issue, which is to check for duplicates and ensure that all references include the correct publication venues and years. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of duplicates and the missing publication venues and/or years for many papers. This provides clear guidance on what needs to be addressed in the references section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and lacks publication venues and/or years for many papers. This is a factual observation that can be verified by checking the references list. The comment does not include subjective opinions, suggestions, or judgments that require additional justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the references list, noting that it contains duplicates and lacks publication venues and/or years for many of the papers. This feedback is clear and actionable, as it provides the authors with a direct and concrete step to improve their draft by ensuring the accuracy and completeness of the references. By addressing these issues, the authors can enhance the credibility and professionalism of their work. However, the comment could be more helpful if it suggested ways to check for duplicates or provided examples of how to format the references correctly. Overall, the comment is 4, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it suggests that the authors need to analyze and compare the theoretical results to other comparable methods. This feedback provides a clear action for the authors to take, which is to clarify the meaning of the error bound in Theorem 1 and to compare their results with other methods. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and suggesting that the authors should analyze and compare their results with other comparable methods. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by clarifying the theoretical analysis and enhancing its relevance. However, the comment could be more helpful if it offered specific suggestions on how to clarify the error bound or which comparable methods to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of lowresource language pairs in finetuning the multilingual model, suggesting that the improvement in translation quality from 1.2 to 2.0 is insignificant in a practical sense. It references a specific paper, \"Better FineTuning by Reducing Representational Collapse,\" which could provide additional context or guidance for the authors. However, the comment does not explicitly instruct the authors to address this issue or provide specific suggestions on how to improve the practical significance of the results. The action is implicit and somewhat vague, as the authors can infer that they need to address the practical significance of their results but are not given concrete steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of lowresource language pairs and the method \"R3F\" to maintain the generalization ability of the model. It also references specific language translations from 1.2 to 2.0, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific in detailing the issue of insignificant improvement in practical terms and references a relevant paper for further context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement in translation quality from 1.2 to 2.0 is insignificant in a practical sense. It references a specific paper, \"Better FineTuning by Reducing Representational Collapse,\" which provides some support for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a basis for the claim but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of lowresource language pairs in finetuning the multilingual model, suggesting that the improvement in translation quality from 1.2 to 2.0 is insignificant in a practical sense. It references a relevant paper, \"Better FineTuning by Reducing Representational Collapse,\" which could provide additional context or guidance for the authors. While the comment highlights a potential weakness, it lacks detailed suggestions or actionable steps for the authors to address this issue. It provides some insight but could be more helpful with specific guidance on how to improve the practical significance of the results. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This comment implies that the authors should provide a justification or explanation for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the reason for the limited results shown, but it lacks grounding as it does not explicitly mention a specific section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This is a factual observation that does not contain a subjective claim or opinion. It is a request for clarification, which is not a claim requiring verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment questions the authors about the reason for showing results only on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This is a valid point that prompts the authors to provide a justification or explanation for their choice of experimental setup. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential weakness in the paper, it lacks actionable feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This is an explicit request for a specific action, namely, to create a visualization to support the claim. The comment provides a clear direction for the authors to follow, making it 5. The authors know exactly what they need to do to address the feedback, which is to create a visualization to illustrate the effect described in the paper.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. It references the claim made in the paper regarding the gradual decline in performance, which provides some grounding as it implies the section discussing this claim. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to visualize the effect is specific, as it provides a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This claim is based on the authors\" assertion in the paper, which provides some initial support. However, the comment lacks specific examples, detailed reasoning, or references to substantiate the claim further. The suggestion to visualize the effect is logical, but the lack of additional evidence or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that the authors should visualize this effect, which is crucial for the research motivation of the paper. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance their draft by illustrating the claim with a visualization. However, the comment could be more helpful if it offered guidance on how to create the visualization or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the explanation of Corollary 10 in lines 180182, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or improve the explanation, leaving the authors without a clear understanding of what steps to take to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (180182) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with Corollary 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out the limitations of the corollary, which is a clear and specific critique. However, it does not provide additional references or examples to further substantiate the claim, making it 3. The authors would need to consider the reasoning and potentially seek additional evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of Corollary 10 in lines 180182, pointing out that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is 3 as it highlights a potential misunderstanding or misinterpretation in the paper, prompting the authors to clarify or expand their explanation. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or additional evidence. Therefore, while it points out a relevant area for improvement, it lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the proposed model: first, that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\"s dynamics; and second, that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their model. The feedback lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the model\"s complexity. As a result, the authors are left without a clear understanding of how to proceed with improving their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, such as the reassignment probability and the evolution model, allowing the authors to identify the parts of the paper being discussed. However, it does not specify what needs to be addressed or improved in these aspects, such as suggesting alternative approaches or providing guidance on how to enhance the model\"s complexity. While the authors can infer that the comment is related to the methodology or results sections, the lack of specificity in detailing what needs to be improved or clarified makes it 2. Therefore, this comment is categorized as 2.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\"s dynamics. It also states that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model: first, that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\"s dynamics; and second, that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment highlights these limitations, it does not provide actionable suggestions or guidance on how the authors might address these issues or improve their model. The feedback lacks depth and specificity, leaving the authors with a general understanding of the problems but without clear steps to take for improvement. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add details about the division of the dataset into training and test sets, including the numbers and the method used for division (e.g., random or with other considerations). This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what information to include in their draft. The comment is explicit and provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what details are missing and what needs to be added, such as the method used for division (e.g., random or with other considerations). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. This is a factual statement that requires no verification or justification. It does not express an opinion, judgment, or suggestion that would necessitate verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks details, namely the division of the dataset into training and test sets. It highlights the importance of including information about the numbers and the method used for division, such as whether it was random or involved other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. By adding these details, the authors can enhance the transparency and rigor of their experimental setup, which is crucial for reproducibility and credibility. However, the comment could be more helpful if it suggested specific methods or considerations for division, which would provide even more actionable guidance. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks specific guidance on how to address these concerns or improve the draft. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some insight into potential issues, it lacks specificity in terms of what specific changes or improvements are needed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these concerns or improve their work. Without detailed guidance or constructive advice, the authors are left without a clear path for improvement. Therefore, the comment is rated as 2, as it identifies areas of concern but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the performance improvement of the proposed methods, as shown in Figure 3, does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. While the comment implies that the authors should consider presenting their results in a more detailed and intuitive manner, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on presenting their results in a more detailed and intuitive way. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. The comment further suggests using tables to directly show key improvements, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, particularly in the bank dataset where the improvement is only ~0.02. The comment suggests using tables to directly show key improvements, which could be more intuitive and detailed. However, the comment lacks specific examples or references to support the claim about the lack of significance or the need for more detailed presentation. Without additional context or evidence, the claim remains 3, as it provides a general observation but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the performance improvement of the proposed methods, as shown in Figure 3, does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. This feedback is clear and actionable, as it provides a specific area for improvement and a concrete suggestion for enhancing the presentation of results. By addressing this feedback, the authors can better highlight the significance of their contributions and improve the clarity of their findings. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the use of a particular loss in a specific setting might be novel, but it does not provide any evidence or reasoning to support this claim. It also states that the work lacks new theoretical results, but again, it does not offer any guidance on how the authors might address this issue or what specific theoretical results are missing. The comment lacks explicit or implicit actions for the authors to take, leaving them without any direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of a particular loss in a specific setting might be novel but lacks theoretical results. However, it does not specify which part of the paper this claim pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is also not specific about what theoretical results are missing or how they could be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of a particular loss in a specific setting might be novel but lacks theoretical results. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. Without supporting evidence or detailed explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the use of a particular loss in a specific setting might be novel but lacks theoretical results. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what theoretical results could be explored. The comment identifies a potential area for improvement but lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. While the comment implies an action, it does not explicitly instruct the authors to include these baselines or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should add these baselines and determine how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the addition of fullysupervised baselines, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. The comment provides a logical reasoning for why this addition would be beneficial, as it would help clarify the performance gap between different supervision methods. However, it does not provide specific examples or references to support the claim, which could strengthen the argument. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific addition that could enhance the understanding of the results. However, the comment lacks depth and does not provide detailed guidance on how to implement these baselines or what specific aspects of the gap should be explored. While it points out a relevant area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. While the comment implies that the authors should address the time complexity issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the time complexity of the proposed algorithm, particularly in relation to the calculation of hypervolume for problems with many objectives. The comment provides a clear question about the practicality of the algorithm for such problems, which gives the authors a clear direction for addressing the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\"s scalability, which is a valid concern. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It points out a potential issue with the algorithm\"s scalability, particularly for problems with many objectives, which could make LaMOO impractical for such problems. This feedback is valuable as it highlights a potential limitation of the algorithm and prompts the authors to consider and address this issue. However, the comment could be more helpful if it provided suggestions on how to mitigate the time complexity or offered examples of similar algorithms that address this challenge. Overall, the comment is 4 as it identifies a significant area for improvement and encourages the authors to consider the scalability of their algorithm."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges a minor issue with the dataset used in the experiments, noting that they are all small. It suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is implicit and lacks concrete details on how to implement the suggestion, making it 3. The authors can infer that they should consider using larger datasets, but without specific guidance, the action remains somewhat vague.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the dataset used in the experiments, noting that they are all small and suggesting that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or where the results are presented, making it weakly grounded. The comment is specific in identifying the issue with the dataset and suggesting a potential improvement, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning or evidence to support why a larger dataset would be more convincing or how it would impact the results. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a minor issue with the dataset used in the experiments, noting that they are all small. It suggests that results on medium or large datasets, such as ImageNet, would be more convincing. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what specific datasets they could consider. Additionally, the comment does not provide any context or explanation as to why larger datasets would be more convincing or how they might impact the results. As a result, the feedback is 3, as it points out a potential weakness but does not offer actionable advice or depth to guide the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, suggesting that the title is too generic and vague. The comment implies that the authors should clarify what \"brittle convergence properties\" mean and mentions that DeepRL methods are widely adopted. While the comment provides some direction, it lacks specific guidance on how to address these points, such as suggesting particular aspects to explore or examples to include. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods and the need for deeper discussion on leveraging state, reactiveness, and learning during an episode. It also addresses the title, suggesting it is too generic and vague, and questions the meaning of \"brittle convergence properties.\" The comment provides specific feedback on what needs to be addressed, such as being more precise in the critique and clarifying the meaning of certain terms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. The comment also critiques the title as being too generic and vague, suggesting that the authors should be more precise in their critique. However, the claim lacks specific examples or references to support the assertion that there are deeper issues to address or that the title is too generic. The mention of \"brittle convergence properties\" is not elaborated upon, and the claim about DeepRL methods being widely adopted is not substantiated with evidence or references. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to delve deeper into the limitations of evolutionary methods, particularly regarding state, reactiveness, and learning during an episode. It also suggests being more precise in the critique and clarifying the meaning of terms like \"brittle convergence properties.\" Additionally, the comment points out that the title is too generic and vague, advising the authors to be more specific. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or suggestions on how to address these issues. Overall, the comment is 4 as it guides the authors toward improving their draft by identifying key areas for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide empirical justification for their claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. While the comment implies that the authors should include empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the empirical evaluation or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, specifically questioning the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for empirical justification, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s first claimed contribution, which is that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. It suggests that the authors provide empirical justification for this claim, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct the empirical evaluation or what aspects to focus on. Despite this, the feedback provides a valuable direction for the authors to improve their draft, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al., 2015), limiting its novelty. It explicitly instructs the authors to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of similarity to RMED (Komiyama et al., 2015) and the need for a sufficient discussion on the comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al., 2015), limiting its novelty. The reviewer provides a specific reference to RMED, which supports the claim by offering a point of comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of the similarities between the two algorithms. Despite this, the reference to RMED is a solid starting point for the authors to address the issue. Therefore, the claim is 4, as it provides a basis for further exploration but lacks comprehensive evidence or detailed analysis.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, suggesting that it is too similar to RMED (Komiyama et al., 2015). It provides a specific reference to RMED, which is helpful for the authors to understand the context of the comparison. The comment also suggests that the paper needs to give a sufficient discussion on the comparison with RMED, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered guidance on how to differentiate the proposed algorithm from RMED or provided specific suggestions for enhancing the discussion. Overall, the comment is 4 as it directs the authors to address a critical issue in their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comprehensive discussion of previous work on the topic, but it does not provide any explicit or implicit actions for the authors to take. It does not suggest what specific aspects of previous work should be discussed or how the authors might improve their discussion. Without guidance on how to address this issue, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue pertains to, nor does it provide details on what aspects of previous work are missing or how they could be incorporated. Without specific guidance or references to particular sections or discussions, the authors cannot effectively address the feedback. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant weakness in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is an important area for improvement, as it can help establish the novelty and context of the current work. However, the comment lacks specificity and does not provide guidance on what aspects of previous work should be discussed or how the authors might address this gap. Without actionable suggestions or examples, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It explicitly requests a more detailed explanation from the authors to understand the difference. This request is clear and direct, providing a specific action for the authors to take. The comment is 5 as it specifies exactly what the authors need to do to address the reviewer\"s concern.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the difference between similarity and exit times in nature. The comment requests a more detailed explanation, which provides clear guidance on what the authors need to address. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer expresses a lack of understanding and requests a more detailed explanation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the difference is unclear. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It highlights a potential gap in the explanation provided by the authors, which could be addressed by offering a more detailed explanation. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work. However, the comment could be more helpful if it provided suggestions on how to present the explanation or examples to illustrate the difference. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. While the comment implies that the authors should address this limitation, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the framework\"s applicability to different types of POMDPs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the framework\"s applicability to different types of POMDPs, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the limitations of the unified framework. It does not express an opinion, judgment, or suggestion that requires verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. This is a relevant inquiry that could help the authors clarify the scope and applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their framework to accommodate these types of POMDPs. While it prompts the authors to consider an important aspect of their work, it lacks actionable feedback or detailed suggestions for improvement. Therefore, the comment is 3, as it identifies a potential area for exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the comment implies that the authors should consider using the Kialo dataset instead of creating their own, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate the Kialo dataset or what changes to make to the existing dataset. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset, noting that the Kialo dataset, which is wellstudied in the community, provides what the authors need\u2014pairs of short claims and their counters. The comment further specifies that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. Additionally, it suggests that the dataset created in the paper could serve as additional data for learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional, as the Kialo dataset provides what the authors need. It supports this claim by comparing the Kialo dataset to the one created in the paper, noting that the former is cleaner since it does not rely on automatic processes. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that the creation of the dataset is optional, as the Kialo dataset, which is wellstudied in the community, already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the feedback highlights a potential alternative dataset and its advantages, it does not provide specific guidance on how to integrate the Kialo dataset or what changes to make to the existing dataset. The comment is 3 as it identifies a potential improvement area but lacks detailed suggestions for implementation. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the proposed modification to the transformer, specifically the crosslayer approach, and questions its significance in terms of machine learning insights. It also suggests that the improvements over other methods are primarily due to using a na\u00efve transformer rather than the proposed modification. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. It lacks actionable details on how the authors might improve their draft or what specific changes could be made to enhance the novelty or significance of their work. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the proposed modification to the transformer, questioning its novelty and significance in machine learning. The comment further critiques the limited improvement (<1%) brought by the selfcross attention in the ablation study. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed modification to the transformer, specifically the crosslayer approach, does not bring much insight in the field of machine learning and that the improvements over other methods are primarily due to using a na\u00efve transformer rather than the proposed modification. The reviewer supports this claim by referencing the ablation study (table 4 and 5), where the selfcross attention brings limited improvement (<1%). However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the reference to the ablation study provides some evidence, the lack of additional context or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical evaluation of the novelty and significance of the proposed modification to the transformer, specifically the crosslayer approach. It questions the extent to which this modification brings new insights to the field of machine learning, noting that the improvements over other methods are primarily due to using a na\u00efve transformer rather than the proposed modification. The comment also critiques the limited improvement (<1%) brought by the selfcross attention in the ablation study. While the feedback highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The comment provides a basis for reflection but does not offer actionable steps for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and direct action for the authors to take, specifying the types of tasks they should consider. The comment is explicit and concrete, giving the authors a specific direction for expanding their experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically noting the limitation of conducting evaluations only on sentence similarity tasks and open domain QA tasks. It also provides a clear suggestion to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This specificity guides the authors on what additional tasks to consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only cover sentence similarity tasks and open domain QA tasks, suggesting that there are many other tasks involving sentence pairs. The reviewer provides an example of sentence inference tasks like MNLI and RTE, which are common in the NLP field. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or works that support the need for broader experimentation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental scope. By suggesting additional tasks, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their experiments. However, it could be more helpful if it included specific suggestions on how to implement these additional tasks or why they are important. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. While it implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their rationale. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment is specific in questioning the rationale for the choice of the last layer and suggesting that numerosity should appear in earlier layers. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the claim. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the concern effectively.", "helpfulness_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity should appear in earlier layers. This feedback highlights a potential gap in the paper\"s explanation and prompts the authors to clarify their rationale. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing alternative analyses or suggesting ways to improve the explanation. While it identifies a weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a human evaluation but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections where caption generation is discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the human evaluation would be more convincing or how it should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate why human evaluation would be more effective or how it could address the limitations of automatic metrics. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. This feedback highlights a potential weakness in the current evaluation approach and provides a clear suggestion for improvement. By recommending a human evaluation, the comment offers a specific and actionable direction for the authors to enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided additional guidance on how to conduct the human evaluation or what specific aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and offers a constructive suggestion, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the theoretical proof for convergence, claiming it is trivial due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. It suggests that previous theorems can be adapted with straightforward modifications, implying that the authors should provide a more substantial proof or explain the novelty of their approach. While the comment identifies an issue with the proof, it does not provide explicit instructions on how to address it or what specific modifications are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical proof for convergence\" and \"Assumption 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, explaining that the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$ lead to a clear covariance matrix for $Z$, which makes the proof trivial. The comment further suggests that previous theorems can be adapted with straightforward modifications, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. The reviewer supports this claim by referencing Modification 1 in Appendix C, suggesting that previous theorems can be adapted with straightforward modifications. This provides a logical reasoning and specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical proof for convergence, suggesting that it appears trivial due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. The reviewer further explains that previous theorems can be adapted with straightforward modifications, indicating a lack of novelty and rigor in the proof. This feedback is clear and actionable, as it points out a potential weakness in the paper and suggests that the authors should provide a more substantial proof or explain the novelty of their approach. However, the comment could be more helpful if it offered specific suggestions on how to enhance the proof or what aspects to focus on. Overall, the comment is 4, as it provides valuable insights for improving the draft but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential contradiction in the paper, noting that it states both that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The comment explicitly requests clarification on this apparent contradiction. This feedback is clear and direct, providing a specific action for the authors to take\u2014clarify the conflicting statements. The action is explicit and concrete, as it specifies what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a potential contradiction in the paper regarding the performance of the multienv model. It explicitly mentions that the model is stated to have an inevitable performance loss and also to outperform the singleenv model due to knowledge sharing. This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed, specifically the sections discussing the performance of the multienv model. The comment is also specific because it clearly identifies the issue of conflicting statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential contradiction in the paper, noting that it states both that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The comment highlights this apparent contradiction and requests clarification. However, it does not provide any additional reasoning, examples, or references to support the claim of contradiction. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss and also to outperform the singleenv model due to knowledge sharing. This feedback is clear and actionable, as it prompts the authors to clarify the apparent contradiction in their claims. By addressing this issue, the authors can ensure that their paper is more coherent and accurate. However, the comment could be more helpful if it provided suggestions on how to resolve the contradiction or offered additional context to better understand the issue. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. While the comment implies that the authors should either explain the metrics or cite them, it does not specify which metrics need clarification or how to present this information. The action is implicit and somewhat vague, as the authors are left to infer which metrics require attention and how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of metrics used in the paper, suggesting that it is limited and recommends providing an explanation or citing the metrics. However, it does not specify which part of the paper discusses the metrics, making it weakly grounded. The comment is specific in suggesting that an explanation or citation would be beneficial, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the description of the metrics used in the paper is limited and suggests that an explanation or citation of the metrics would be beneficial. However, the comment does not provide specific examples of which metrics are unclear or how they could be better explained. Without detailed reasoning or references, the claim lacks sufficient support, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the description of the metrics used in the paper is limited. It suggests that an explanation of the metrics or a citation to them would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance the clarity and context of their metrics, which is crucial for understanding the results and their significance. However, the comment could be more helpful if it provided specific examples of metrics that need clarification or suggested ways to present them. Overall, the comment is 4 as it guides the authors toward improving the comprehensiveness of their metrics section."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of motivation for the problem considered in the paper, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should spend more time motivating the applications where such algorithms are needed. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects should be included to motivate the problem. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context and motivation for the problem. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective of designing fast label aggregation algorithms for a streaming setting and questions the lack of motivation for such algorithms. It also points out that the datasets used in the empirical analysis are static, which contradicts the paper\"s objective. However, the comment does not specify which part of the paper lacks motivation or where the datasets are discussed, making it weakly grounded. The comment is specific in its critique of the lack of motivation and the use of static datasets, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem considered, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the paper\"s objective. However, the comment does not provide specific examples or references to support the claim that the problem is not wellmotivated or that the datasets are inappropriate. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while it aims to design fast label aggregation algorithms for a streaming setting, it lacks motivation for the problem and does not provide examples of applications where such algorithms are needed. This is a critical issue that the authors need to address to make their work more relevant and impactful. The comment is clear and actionable, as it highlights a specific area for improvement and suggests that the paper should include examples or applications to motivate the problem. However, it could be more helpful if it provided specific suggestions on how to incorporate these examples or applications. Overall, the comment is 4, as it directs the authors to a crucial aspect of their work that needs further development."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of specificity in the study\"s scope, suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models. It implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Table 2 and 3. While the comment identifies a potential issue, it does not explicitly instruct the authors to include these baselines or specify how to address the lack of specificity in the study\"s scope. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines and clarify the scope of their study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It further implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Table 2 and 3. However, the comment lacks specific examples or references to support the claim about the missing baselines, making it 3. The authors would need to infer the missing information and potentially conduct additional research to address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and that the work seems to focus on injecting a CoTbased approach into smallscale Language Models. It points out the absence of relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, in Table 2 and 3. This feedback is clear and actionable, as it directs the authors to clarify the scope of their study and potentially include additional baselines to enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or what additional baselines might be relevant. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and depth of their study."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the readability of the figure, such as suggesting ways to enhance the visual clarity or providing specific examples of what needs to be addressed. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in reading the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement describing the difficulty in reading Figure 3. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment points out a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any actionable feedback or suggestions on how the authors might improve the figure\"s readability. Without guidance on what aspects of the figure are causing the difficulty or how to address it, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a problem but does not offer actionable advice for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the mentioned fact in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should take to clarify the connection. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the mentioned fact and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim. The lack of specific examples or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the connection. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as 2, as it points out a potential area for improvement but does not offer detailed guidance for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first concern is explicit, as it directly instructs the authors to clarify the reasoning behind the replacement. The second concern is also explicit, as it questions the justification for the learning rate choice. Both points provide clear actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the replacement of a mathematical expression with an arbitrary parameter and the lack of justification for the learning rate choice. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first claim is supported by referencing specific lines in the paper (lines 119121), which provides a clear basis for the critique. The second claim questions the justification for the learning rate choice, but it does not provide specific reasoning or references to support why the Adam default value is more appropriate. This makes the claim 3, as it highlights a potential issue but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter, which could potentially affect the accuracy or interpretation of the results. Second, it questions the choice of a specific learning rate for SGD, noting that it differs from the default value and lacks justification. These critiques are clear and actionable, as they prompt the authors to provide a rationale for these choices or consider alternative approaches. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to justify the choices. Overall, the feedback is 4, as it directs the authors to improve the clarity and justification of their methods, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. While the comment implies that the authors should address these points, it does not provide explicit instructions on how to conduct the analysis or discussion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should address these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper. The comment is specific in suggesting what needs to be discussed, such as the domain gap and the value of the approach. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the domain gap or the potential value of the approach. This makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap between datasets and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to conduct the analysis or discussion. The feedback is 3 as it points out important considerations, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include at least one NCEbased method for comparison. It provides a specific action by referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, giving the authors a direct and detailed instruction on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a study that shows the feasibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of an NCEbased method and referencing a study, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This claim is 3 as it provides a reference to a specific study that supports the feasibility of the suggestion. However, the comment lacks detailed explanation or examples of how this comparison would benefit the paper, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by including a relevant comparison method. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\"s contribution. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs and points out that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The authors are left to infer that they need to provide a justification for the need for a new method and discuss the limitations of existing approaches. However, the lack of concrete suggestions or detailed guidance makes the action vague and difficult for the authors to implement effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is valuable as it highlights a critical area that needs further elaboration or justification in the paper. However, the comment could be more helpful if it provided specific suggestions on how to address this gap or what aspects of existing methods should be discussed. Despite this, the comment is 4 as it directs the authors to a crucial area that requires attention and improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using ngram features. This comment provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to improve their draft. The suggestion is concrete, as it outlines a specific approach to enhance the paper\"s methodology. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than using ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks full grounding as it does not explicitly mention a particular section. It is specific in suggesting a change in the methodology, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that powerful pretrained language models like BERT and XLNet can overcome the domainshift problem to some extent. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the suggestion or to assess its validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a significant change in the methodology by recommending the use of powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than relying on ngram features. This feedback is clear and actionable, providing the authors with a specific direction to enhance their approach and potentially improve the efficacy of their work. However, the comment could be more helpful if it explained why this change is beneficial or how it would address the domainshift problem. Despite this, the suggestion is valuable and offers a concrete way to improve the draft, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion to improve the draft by requesting more explanation for the difference between two quantities and why it captures the difference in learning settings. This feedback is explicit and provides a clear action for the authors to take, which is to provide additional explanation in the manuscript. The comment also includes a subjective opinion about the acceptance of the paper, but this does not affect the actionability of the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 196197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more explanation regarding the difference between two quantities and why it captures the difference in learning settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the explanation of the difference between two quantities and why it captures the difference in learning settings. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by requesting more explanation regarding the difference between two quantities and why it captures the difference in learning settings. This feedback is clear and actionable, as it directs the authors to provide additional context and reasoning in their manuscript. However, the comment could be more helpful if it included suggestions on how to present this explanation or what specific aspects to focus on. Despite this, the feedback is 4 as it guides the authors toward enhancing the clarity and comprehensiveness of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and provides a direct action for the authors to take, which is to include a discussion on the sensitivity of these parameters. The feedback is specific and concrete, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks for a discussion on the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is specific and provides clear guidance on what the authors should address. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for additional discussion, specifically asking the authors to address the sensitivity of fixed tuning parameters in the model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or expansion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of fixed tuning parameters in their model. This feedback prompts the authors to consider an important aspect of their methodology that could impact the robustness and performance of their model. However, the comment lacks depth and does not provide specific guidance on how to approach this discussion or what aspects to focus on. While it highlights a relevant area for exploration, the authors may need to infer the exact steps to take to address this feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). While the suggestion to explore different policy gradient approaches is explicit, it lacks concrete guidance on how to implement this exploration. The question about random seeds is explicit and provides a clear action for the authors to take. However, the overall comment is 3 as it provides a direction for further exploration but lacks detailed instructions on how to conduct the experiments.", "grounding_specificity_rationale": "The comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not specify which part of the paper this suggestion or question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting an extension and asking for clarification on random seeds, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. This feedback provides a clear direction for the authors to consider, offering a potential avenue for enhancing the applicability and robustness of their work. Additionally, the comment includes a specific question about the number of random seeds used for learning the policies (DDPO and IPPG), which is a relevant detail that could impact the reproducibility and robustness of the results. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific policy gradient approaches to consider. Overall, the comment is 4 as it offers actionable suggestions and prompts for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing could be improved in some places, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. While the comment identifies a potential issue, it does not provide explicit guidance on how to improve the writing or clarify the definition. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the definition but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the interpretation of the \"relevant\" auxiliary model weights, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. However, the comment does not provide any further explanation or reasoning to support why the definition is difficult to interpret or how it could be improved. Without additional context or examples, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the writing could be improved, pointing out a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. This feedback is 3 as it directs the authors to a particular section of the paper that needs clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the definition or clarify the concept. While it highlights an area for improvement, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It recommends using ULiRA [1] instead. While the comment implies that the authors should consider an alternative method for evaluating unlearning effectiveness, it does not provide specific guidance on how to implement this change or why ULiRA is preferable. The action is implicit and somewhat vague, as the authors need to infer the need for a change and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MIA (Membership Inference Attack) Testing via Ulira,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the robustness of MIA testing for privacy guarantees and recommending the use of ULiRA [1]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s reliance on MIA testing as a metric for unlearning effectiveness is not robust for privacy guarantees. It supports this claim by suggesting that the use of ULiRA [1] is recommended. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the robustness of MIA testing. While it provides a suggestion for improvement, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA testing as a metric for unlearning effectiveness, questioning its robustness for privacy guarantees. It provides a specific recommendation to use ULiRA [1] as an alternative, which could be a valuable suggestion for the authors to consider. However, the comment could be more helpful if it explained why ULiRA is a better choice or provided more detailed guidance on how to implement this change. Overall, the comment is 4 as it points out a critical area for improvement and offers a potential solution, but it could be more comprehensive with additional context and explanation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the paper could also be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate the suggestion or address the question about applicability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question or suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider kernel regression and present the paper in a different context, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this should be the case. It lacks specific examples or detailed explanations that would help the authors understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for expansion or clarification, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to address this issue. The feedback is somewhat vague and does not offer detailed insights or steps for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This feedback provides a clear and explicit action for the authors to take, which is to include these settings in their paper. The comment also explains why this is important, as it would help the community by providing a comprehensive review of the advances in this area. The suggestion is concrete and direct, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these settings could be included. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in suggesting what needs to be addressed, it is 1 because it does not indicate where in the paper these settings should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. The comment provides a clear suggestion for improvement, but it lacks specific examples or references to these prior works, making it 3. The authors would need to consult these works themselves to fully understand the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including these settings. By following this suggestion, the paper would offer a comprehensive review of the advances in this area, benefiting the community. However, the comment could be more helpful if it provided examples or detailed guidance on how to present these settings. Overall, the feedback is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the generalizability of these examples, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases of target statistics and prediction shift of gradient values, but it does not specify how these examples are unclear or how they impact the generalizability of the results. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the paper, particularly in relation to the generalizability of examples presented in Section 3.2 and Theorem 1. It points out that while the paper demonstrates specific biases and prediction shifts, it does not clarify how general these situations are. This feedback is 3 as it highlights a potential gap in the paper that the authors need to address. However, it lacks detailed suggestions or guidance on how to improve the clarity or provide additional context. To be more helpful, the comment could include specific recommendations or examples of how to enhance the generalizability discussion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, it does not specify which datasets should be included or how they would contribute to the evaluation of crosstask transferability. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in suggesting the inclusion of additional datasets for crosstask transferability evaluation, but without clear grounding, the authors may struggle to identify the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, the comment does not provide any specific reasoning or examples to support why additional datasets are necessary or how they would enhance the evaluation of crosstask transferability. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including \"a few more datasets\" would be beneficial, particularly for evaluating crosstask transferability. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets should be included or how they would contribute to the evaluation. The feedback is 3 as it points out a direction for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks used in the paper are somewhat standard and proposes that the authors could create unique tasks from the dataset to showcase the diversity of images and plots. It specifically mentions that tasks like Question Answering from images could be considered. While the comment implies that the authors should consider creating new tasks, it does not provide explicit instructions on how to do so or what specific tasks to explore. The action is implicit and somewhat vague, as the authors need to infer the need for new tasks and determine how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. It mentions specific examples, such as Question Answering from images, which could be considered. However, the comment does not explicitly mention which part of the paper discusses the tasks, making it weakly grounded. The authors can infer that it relates to the task description or methodology sections, but this inference is not as direct as it could be. The comment is specific in suggesting unique tasks and providing examples, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. The reviewer provides a specific example of a task that could be considered, such as Question Answering from images. This suggestion is supported by logical reasoning and a clear example, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar tasks in the literature. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the tasks used are somewhat standard, such as figure captioning and matching figures to captions. It suggests that the authors could create unique tasks from the dataset to showcase the diversity of images and plots, providing a specific example of a task like Question Answering from images. This feedback is clear and actionable, as it offers a concrete suggestion for enhancing the paper by introducing more diverse and innovative tasks. However, the comment could be more helpful if it provided additional guidance on how to develop these unique tasks or referenced similar works that have successfully implemented such tasks. Overall, the comment is 4 as it provides a valuable direction for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to clarify whether there is any additional novel effort in Section 3.1 for 3D Gaussian generation, given that it appears to follow the previous work, Luciddreamer. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies exactly what the authors need to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on whether there is any additional novel effort in this section, given that it appears to follow the previous work, Luciddreamer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussian generation in Section 3.1 is original or merely follows the previous work, Luciddreamer. However, it does not provide any specific reasoning, examples, or references to support the claim that the section is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussian generation in Section 3.1, suggesting that it may not be original and merely follows the previous work, Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether there is any additional novel effort in this section. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the originality of their work. To be more helpful, the comment could include suggestions for potential novel contributions or ways to differentiate the work from existing literature. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the MMD DRO method, specifically noting that it lacks a tractable exact equivalent reformulation and that the upper bound provided in Theorem 3.1 is crude. It also points out that the nonnegative constraint on the distribution is dropped, requiring further approximation even for a simple kernel ridge regression problem. Additionally, the comment suggests that assuming the loss function belongs to the RKHS is restrictive. While the comment identifies several areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MMD DRO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the method, such as the lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. Additionally, it points out the assumption that the loss function belongs to the RKHS, which is restrictive. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that MMD DRO lacks a tractable exact equivalent reformulation, which is a severe drawback. It supports this claim by pointing out the crudeness of the upper bound provided in Theorem 3.1, which drops the nonnegative constraint on the distribution and requires further approximation even for a simple kernel ridge regression problem. Additionally, the comment mentions the assumption that the loss function belongs to the RKHS, which is restrictive. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or references to be fully convincing.", "helpfulness_rationale": "The review comment identifies several critical issues with the MMD DRO method, specifically noting its lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. It also points out the restrictive assumption that the loss function belongs to the RKHS, which has already been noted by the authors. While the comment highlights important weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it identifies areas for improvement but lacks actionable advice, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion or what specific features to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment by asking what would happen if the baselines on the left hand side were sparsified to reduce the number of selected features and compared to the proposed model. This provides a clear direction for the authors to consider in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the baselines in Figure 3. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. This is a constructive suggestion that could potentially lead to a more comprehensive analysis of the results. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what aspects of the sparsification process should be considered. While it offers a direction for improvement, it does not fully support the authors in making these changes. Therefore, the comment is 3, as it provides a starting point for further exploration but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is not written to be reproduced, even with the pseudocode provided in the supplementary material. It suggests that more details are needed, such as those related to the RNN implementation (like the number of units) and other technical details. While the comment identifies the issue and provides a general direction for improvement, it does not specify which specific details are missing or how the authors should address these gaps. The action is explicit but somewhat vague, as it lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not being written to be reproduced, even with the pseudocode provided in the supplementary material. It suggests that more details are needed, such as those related to the RNN implementation and other technical details. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what is missing, such as details about the RNN implementation, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, even with the pseudocode provided in the supplementary material. The reviewer suggests that more details are needed, such as those related to the RNN implementation and other technical details. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more specific guidance to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not written to be reproduced, even with the pseudocode provided in the supplementary material. It points out that the paper is written to provide an intuitive understanding of the work but lacks the necessary details for actual reproduction. The comment specifies areas that need more detail, such as the RNN implementation and other technical details. This feedback is clear and actionable, as it provides the authors with a specific direction for improvement by highlighting what is missing in the paper. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of what additional details might be needed. Overall, the comment is 4, as it effectively guides the authors toward improving the reproducibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED for determining chunk significance, suggesting that it might introduce biases. The reviewer provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or mitigate the biases. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative approaches or additional criteria for eviction decisions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIITED,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the utilitybased approach to determining chunk significance and the potential biases it might introduce, such as premature evictions of valuable chunks due to temporary high utility scores. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for premature evictions of valuable chunks due to temporary high utility scores. This claim is 3 as it provides a logical reasoning for the potential bias, but it lacks specific examples or references to support the claim fully. The authors would need to consider this potential issue and address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED for determining chunk significance, suggesting that it might introduce biases. It provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This feedback is clear and actionable, as it highlights a specific area where the authors might need to reconsider their approach to avoid potential biases. However, the comment could be more helpful if it offered suggestions on how to address this issue or alternative methods to mitigate the biases. Overall, the comment is 4, as it provides valuable insight into a potential weakness in the methodology, prompting the authors to consider improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms, as well as more detailed explanations of the presented algorithms. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The feedback is 3 as it provides a clear direction for improvement, but it lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It mentions the experimental aspect and the result section, providing some grounding by referencing specific parts of the paper. However, it does not specify which parts of the framework are unclear or which algorithms need more detailed explanations, making it weakly grounded. The comment is specific in suggesting the need for quantitative experiments and comparisons between algorithms, as well as more detailed explanations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of different parts of the framework and their contribution to the final result are unclear. It suggests that the lack of quantitative experiments and comparisons between algorithms, as well as detailed explanations, makes it difficult to assess the framework\"s performance. The comment provides a logical reasoning by pointing out the absence of specific details that would help evaluate the framework\"s effectiveness. However, it does not include specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of the framework\"s performance and contribution. It points out that while the results section shows promising visual stimuli, there is a lack of quantitative experiments and comparisons between different algorithms, as well as detailed explanations of the presented algorithms. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the comprehensiveness and clarity of their work. By suggesting the inclusion of quantitative experiments and detailed explanations, the comment offers valuable guidance for the authors to strengthen their draft. However, it could be more helpful if it provided examples or specific suggestions on how to conduct these experiments or explanations. Overall, the comment is 4, as it effectively directs the authors toward enhancing the clarity and rigor of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps should be taken to clarify the model\"s capabilities. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the model or methodology are unclear or need further elaboration. Without clear grounding and specificity, the authors cannot effectively address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. While it identifies a potential area of concern, it lacks specificity and does not provide any actionable suggestions or guidance for the authors to address this issue. Without clear feedback on how to improve the model\"s capabilities or what specific aspects need clarification, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors present a simplified version of Theorem 2 for the general audience, similar to how Theorem 1 is presented. This is an explicit request for the authors to simplify the presentation of Theorem 2, which is a concrete action. The comment provides clear guidance on what needs to be done to improve the accessibility of the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests simplifying the presentation of Theorem 2 for the general audience, similar to how Theorem 1 is presented. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the presentation of Theorem 2, but this inference is not as direct as it could be. The comment is specific in suggesting a simplification for the general audience, but it lacks grounding because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult to understand without a simplified version, similar to Theorem 1. However, the comment does not provide specific examples or detailed reasoning to support why Theorem 2 is challenging or how a simplified version would improve accessibility. Without additional context or explanation, the claim lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the accessibility of Theorem 2, suggesting that it may be difficult for the general audience to understand without a simplified version. This feedback is 3 as it points out a specific area where the paper could be improved, but it lacks detailed guidance or suggestions on how to simplify the presentation. The authors are given a direction to consider, but the comment does not provide concrete steps or examples to help them achieve this simplification. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting experiments with a larger image resolution to evaluate performance. While it implies that the authors should consider this change, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion or what specific resolutions to test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments with a larger image resolution, implying that the current experiments are limited to a resolution of 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by testing with a larger resolution, but without explicit grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments with a larger image resolution to evaluate performance. However, it does not provide any reasoning, evidence, or references to support why this would be interesting or beneficial. The comment lacks specific details or justification for why a larger resolution would impact performance, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments with a larger image resolution to evaluate performance. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or what specific resolutions to test. The feedback is 3 as it points out a possible enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the keypoint mask averaged feature vector and whether it is obtained by multiplying each feature map elementwise by H_psi. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the clarity of the section. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to obtain the keypoint mask averaged feature vector, asking whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or explained in the section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the method used to obtain the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the method used to obtain the keypoint mask averaged feature vector, specifically asking whether it is obtained by multiplying each feature map elementwise by H_psi. While this question identifies a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might clarify or improve this aspect of their work. As a result, the comment is 2, as it points out a potential issue but does not assist the authors in addressing it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the central contribution of the paper, specifically the use of ODEs to model weight evolution. It suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy when recomputing activations. While the comment implies that the authors should provide such evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the issue of inaccuracy in neural ODEs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, which is modeling weight evolution using ODEs. It mentions a specific issue with neural ODEs, namely their inaccuracy when recomputing activations, and suggests that this problem was first reported in a previous paper. However, the comment does not specify which part of the paper discusses this issue or where the authors should address it. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the issue with neural ODEs but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not provide a convincing analytical argument or empirical evidence to support the central contribution of modeling weight evolution using ODEs. The reviewer suggests that a previous paper first reported the issue of neural ODEs exhibiting inaccuracy when recomputing activations. However, the comment does not provide a reference to this previous paper, making it difficult for the authors to verify the claim. The lack of specific evidence or references leaves the claim 3, as the authors would need to investigate further to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s central contribution, which is the use of ODEs to model weight evolution. It points out that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy when recomputing activations. This feedback is valuable as it highlights a significant gap in the paper\"s justification of its main contribution. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what evidence could be included to strengthen their argument. Despite this, the comment is 4 as it directs the authors\" attention to a critical area that needs further development. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is an explicit suggestion that provides a clear action for the authors to take. The comment is specific and provides a concrete direction on what needs to be added to the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular addition to the text, namely mentioning that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a suggestion for improvement, not a claim or opinion that requires verification. It is a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While this is a specific and actionable suggestion, it is limited in scope and does not provide broader feedback or context for improvement. The comment lacks depth and does not offer insights into why this information might be important or how it could enhance the paper. Therefore, it is 3, as it provides a clear direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer actionable advice on how to handle it. The feedback is somewhat vague, as it suggests an additional experiment but lacks concrete details on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting additional experiments and acknowledging the potential issue of compute, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. The reviewer provides a logical reasoning for the suggestion, noting that larger datasets could provide more robust results. However, the comment does not specify which datasets would be suitable or how they would impact the results, leaving some gaps in the justification. This makes the claim 3, as it provides a logical basis but lacks specific details or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. While it provides a clear suggestion for improvement, it lacks specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment also acknowledges that the author\"s response addressed the reviewer\"s concerns well, but it does not offer further insights or suggestions for improvement. Therefore, the feedback is 3, as it identifies a potential area for enhancement but lacks depth and actionable advice. The authors gain some insight into a possible direction for improvement but need more detailed guidance to fully benefit from the comment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the performance of Table 4, noting that it is behind more recent models. It provides examples of models, GLaMM and UNINEXT, that have achieved better results on specific metrics. However, the comment does not explicitly instruct the authors to improve their results or suggest ways to address this issue. The action is implicit, as the authors can infer that they need to improve their performance, but it lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of the model, noting that it is behind more recent models and provides examples of models that have achieved better results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of Table 4 is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by providing specific metrics and results from these models, which helps verify the assertion. However, the comment could be strengthened by including more detailed comparisons or references to other relevant works. Overall, the claim is 4, as it provides sufficient evidence but lacks comprehensive references or additional context.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of Table 4, noting that it is behind more recent models. It provides examples of models, GLaMM and UNINEXT, that have achieved better results on specific metrics. This feedback is clear and actionable, as it highlights an area where the authors\" model performance could be improved. However, the comment could be more helpful if it suggested ways to address this issue, such as comparing the models\" architectures or suggesting potential improvements. Overall, the comment is 4 as it directs the authors\" attention to a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for comparison but are not given detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Additionally, it lacks specificity regarding what aspects of the method should be compared or how the comparison should be conducted. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It proposes a comparison with previous methods on a dataset with such images, which could provide valuable insights. However, the comment lacks specific examples or references to previous works that have addressed this issue, making it 3. The suggestion is logical and provides a direction for further exploration, but the lack of detailed evidence or references limits its full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method\"s applicability, suggesting that it may struggle with images containing multiple objects or cluttered scenes. It offers a constructive suggestion to compare the approach with previous methods on a dataset with such images, which could provide valuable insights into the method\"s limitations and strengths. This feedback is clear and actionable, as it directs the authors to a specific area for further exploration and improvement. However, it could be more helpful if it provided examples of datasets or previous works that could be used for comparison. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it implies that the authors should provide additional explanation, it does not explicitly instruct them to do so or specify how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more explanation but are not given specific guidance on what to include or how to structure it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper currently lacks this explanation, making it weakly grounded. The comment is specific in suggesting that additional explanation could be beneficial, but it does not provide detailed guidance on what aspects of the bounds need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning or examples to support why this additional explanation is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment acknowledges the space limitations but suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to enhance the explanation or what aspects of the bounds need further clarification. The feedback is 3 as it points out a gap in the paper but does not provide actionable steps for the authors to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary because of wellknown engineering improvements. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific aspects of the explanation are unnecessary. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"kernels\" and \"OpenAI\"s Triton,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that a fullpage explanation of the implementation is unnecessary due to wellknown engineering improvements. This provides clear guidance on what aspect of the paper should be revised or omitted. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper uses OpenAI\"s Triton for kernel implementation instead of CUDA, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. While the comment identifies a potential area for improvement by suggesting that the explanation could be condensed, it lacks depth and does not provide specific guidance on how to address this issue or what aspects of the explanation could be simplified. The feedback is 3 as it highlights a potential area for streamlining the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides specific examples to support the claim, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario. The comment explicitly states that the authors need to clarify these points in the paper to avoid misleading readers. The feedback is clear and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support its claims. However, it does not explicitly mention which part of the paper these examples are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the difficulty of policy transfer and the need to make these points clear in the paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support their claim. This level of detail and reasoning makes the claim 4, as it provides a logical basis for the critique. However, the comment could be strengthened by referencing specific literature or studies that support the idea of limited transferability in similar scenarios. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical question about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support its claim. The comment also highlights the need for the authors to clarify these points in the paper to avoid misleading readers. This feedback is clear and actionable, as it identifies a potential weakness in the study and offers specific suggestions for improvement. By addressing these issues, the authors can enhance the clarity and validity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these critiques or improve their analysis. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 3.2 and 3.3, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the critique that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. The comment further specifies that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also suggests that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it points out a limitation, but it does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific suggestion to include a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work. However, the comment also points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which is not actionable advice. The suggestion to include a reference is explicit and concrete, while the critique of the abstract and introduction is vague and lacks guidance on how to address it. Therefore, the comment is 4, as it provides a clear action but also includes a less actionable point.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the multifidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive.\" Additionally, it provides a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion to include a reference to a relevant paper and a critique of the abstract and introduction regarding the term \"relatively inexpensive.\" The suggestion to include a reference is supported by the specific citation provided, making it 5. The critique of the abstract and introduction is based on a logical inconsistency, which is a factual observation rather than a claim. Therefore, the comment is a combination of a 5 suggestion and a factual observation, aligning with the label \"5.\"", "helpfulness_rationale": "The review comment provides a specific suggestion to include a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work within the field. This is a valuable suggestion that can enhance the paper\"s relevance and impact. Additionally, the comment points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which could be confusing for readers. While the comment identifies these issues, it does not offer detailed guidance on how to address them or improve the clarity of the text. Overall, the comment is 4 as it provides actionable feedback on references and identifies a potential inconsistency, but it could be more comprehensive with additional suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The comment lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questioning of the method\"s effectiveness but lacks grounding, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide any specific evidence, examples, or references to support the claim that the method does not address sparse reward problems effectively. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems, specifically questioning whether it offers a better solution compared to other methods like Qmix. It also points out a potential issue with the proposed method requiring subtaskspecific rewards, which could be seen as providing a dense reward signal. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns or improve their method. While it identifies an area for improvement, the feedback is somewhat vague and incomplete, making it 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN had access to this data during training for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training for a fair comparison. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its inquiry about the use of the dataset and the fairness of comparisons, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and whether other methods had access to this data during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the fairness of the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training. This is a relevant concern for ensuring a fair comparison among different methods. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or what steps they should take to clarify the use of the dataset. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more helpful with additional direction. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their results on the official COOC leader board on the blind test set, referencing a specific URL and mentioning previous winners and other approaches that have improved since the paper was published. This provides clear and concrete guidance on what the authors need to do to improve their draft. The comment is explicit and detailed, leaving no ambiguity about the action required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board on the blind test set,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results on the official test set and the inclusion of recent approaches that have improved since the paper was published. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leader board on the blind test set, referencing specific examples of previous winners and other approaches that have improved since the paper was published. The reviewer provides a link to the official leaderboard, which supports the claim by offering a clear reference for the authors to follow. This level of detail and specific references make the claim 5, as it provides a clear path for the authors to address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out that the paper should compare its results on the official COOC leader board on the blind test set, rather than on a not official test set or dev set. It references previous winners and other approaches that have improved since the paper was published, suggesting that the authors should at least compare to the ones where a corresponding publication is available. This feedback is clear and detailed, offering a concrete direction for the authors to improve their draft by aligning their results with the official benchmark. Therefore, the comment is 5, as it provides specific guidance that can significantly enhance the paper\"s credibility and relevance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides a clear and direct action for the authors to take, which is to clarify the terminology used in the paper. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 248, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"wrong\" and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific point in the paper where the term \"wrong\" is used without clarification, suggesting that the authors should clarify the meaning of good, bad, and wrong explanations before using these concepts. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity in their work. By providing this guidance, the comment helps the authors improve the clarity and precision of their draft. However, it could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of what constitutes a good or bad explanation. Overall, the comment is 4, as it effectively points out a need for clarification and offers a direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. The comment implies that the authors should include this comparison to prove the superiority of their method over MVF. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to address the issue: include a comparison with the image classification result of MVF. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely the comparison with MVF. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points. It specifically notes the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF, which is necessary to prove the superiority of the schema searched by the authors\" method over MVF. This claim is 3 as it highlights a specific gap in the experimental section that could be addressed to strengthen the paper\"s claims. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a specific gap in the experimental demonstration of the contribution points, noting the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. This feedback is clear and actionable, as it highlights a critical area where the authors can strengthen their experimental results to substantiate their claims. By suggesting the inclusion of this comparison, the comment provides a concrete step for the authors to take to improve the paper. However, it could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided sufficient information on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to include more information on these aspects, but it lacks concrete details on what specific information should be added or how to present it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of coverage on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a specific section or chapter. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in identifying the missing information but lacks grounding, as it does not clearly indicate where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not covered more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it points out an area where the authors could provide more detailed information or analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data or analysis to include. While it highlights a potential area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of clarity regarding the concept of \"state\" and suggests that the authors should elaborate on it. It questions whether \"elements\" are equivalent to \"states\" or \"actions\" and requests further elaboration. While the comment explicitly points out the need for clarification, it does not provide specific guidance on how to elaborate or what additional information should be included. The action is explicit but somewhat vague, as the authors know they need to clarify the concept of \"state\" but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (186187) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the equivalence of \"elements\" to \"states\" or \"actions,\" which provides clear guidance on what needs to be clarified. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. The reviewer also asks whether \"elements\" are equivalent to \"states\" or \"actions.\" This comment is 3 as it raises a valid point about the clarity of the paper, but it lacks specific examples or references to support the claim. The authors would need to further investigate and clarify the concept themselves, making the comment 4.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the concept of \"state\" in the paper. It questions whether \"elements\" are equivalent to \"states\" or \"actions,\" suggesting that the authors should provide more elaboration on this concept. This feedback is 3 as it points out a specific area where the paper could be improved, but it lacks detailed guidance on how to clarify the concept or what additional information should be included. While it provides a starting point for the authors to address the issue, it could be more helpful with more specific suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular comparison method, but without clear grounding, the authors may struggle to identify the exact section where this comparison should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. This feedback is 3 as it provides a specific suggestion for enhancing the paper by adding a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct this comparison or what specific metrics to use. While it points out a potential area for improvement, it does not fully support the authors in implementing the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific aspects need clarification. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Without concrete steps or examples, the authors are unable to make meaningful changes to their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue pertains to. The authors can infer that it might be related to the theoretical sections or discussions, but without explicit references, it is weakly grounded. The comment is specific in pointing out the lack of clarity in the theoretical comparisons, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve this aspect of their paper. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 2, as it points out a problem but does not offer any direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or improve the measurement methodology. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through only yes/no responses, suggesting that a yes response does not necessarily indicate comprehension. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate comprehension, as the model may still produce incorrect objects in other tasks. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. This feedback is 3 as it prompts the authors to reconsider their measurement methodology and potentially explore more comprehensive approaches to assessing object hallucination. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or metrics. To be more helpful, the comment could include actionable advice or examples of how to improve the measurement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not provide specific guidance on what aspects of the FRM should be elaborated upon or how the authors should present this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on what to include. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not specify which part of the paper this description should be added to, making it weakly grounded. The comment is specific in its request for more detailed explanation of the innovative aspects of the FRM. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. However, the comment does not provide any specific reasoning or evidence to support why this description is lacking or what aspects should be elaborated upon. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. This feedback is 3 as it points out a potential weakness in the paper and encourages the authors to provide a more comprehensive explanation of their innovative approach. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the FRM should be elaborated upon or how to present this information. To be more helpful, the comment could include suggestions on what specific details should be included or how to better explain the innovative aspects of the FRM. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide explicit guidance or suggestions on how the authors might clarify this connection or improve the clarity of their work. The comment highlights an issue but lacks actionable advice, leaving the authors uncertain about how to address the identified problem. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by pointing out the lack of clarity, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that there is a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide specific suggestions or guidance on how the authors might clarify this connection or improve the clarity of their work. While it highlights an area for improvement, the comment lacks actionable feedback, making it 3. The authors are given a general direction but are left without detailed guidance on how to address the issue, limiting the comment\"s usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide explicit instructions or concrete steps on how to conduct these analyses or experiments. While the authors can infer that they need to perform additional research, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It mentions specific aspects that could be explored, such as the performance of simple greedy selection versus more principled acquisition functions and the superiority of deterministic MLP predictors over probabilistic predictors. However, the comment does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical results of the proposed method are strong and that a more novel contribution would be to explore theoretical analyses or extensive experiments to understand the reasons behind the performance of simple greedy selection and deterministic MLP predictors. The comment highlights the absence of such rigorous analyses in the paper. However, it does not provide specific examples, references, or detailed reasoning to support the claim that these analyses are necessary or would be beneficial. The lack of evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these analyses based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It specifically mentions the superiority of simple greedy selection over more principled acquisition functions and the performance of deterministic MLP predictors over probabilistic predictors. While the comment highlights an interesting direction for further exploration, it lacks specific guidance or detailed suggestions on how to conduct these analyses or experiments. The authors are left with a general idea of what could be explored but without concrete steps to follow. Therefore, the comment is 3, as it provides some direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a citation for the \"kmax problem\" and to discuss it elsewhere in the paper. This is a clear and direct action, leaving no ambiguity about what the authors need to do. The comment provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the kmax problem,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the action needed, which is to provide a citation for this problem and discuss it elsewhere in the paper. This provides full grounding and specificity, as the authors know exactly what needs to be addressed and where to make the additions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking for a citation for the \"kmax problem\" and where else it was discussed. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific in its request for additional information. It asks for a citation for the \"kmax problem\" and where else it was discussed, providing a direct and actionable suggestion for the authors to enhance their draft. By addressing this request, the authors can provide a more comprehensive context for their work, which is beneficial for readers and reviewers. However, the comment could be more helpful if it included a rationale for why this information is important or how it relates to the paper\"s contributions. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include this information, but it lacks concrete details on how to estimate the function or what specific aspects of reliability should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not specify which part of the paper discusses this estimation or where the model reliability is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its request for information on the estimation and reliability, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. However, it does not provide any specific reasoning, examples, or references to support the claim. The comment is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This is a critical area that the authors need to address to ensure the validity and robustness of their work. However, the comment does not provide specific suggestions or guidance on how to estimate the function or improve the model\"s reliability. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two issues: forward referencing and the need for clearer explanations of contributions in the introduction. It also mentions that material supporting the main contributions is in the appendix rather than the main sections. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the contributions in the introduction and ensure that the main contributions are discussed in the main sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for clearer explanations of contributions and the placement of material supporting the main contributions in the appendix rather than the main sections. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, with material being introduced without proper explanation and then explained later. It also mentions that the main contributions are not clearly written in the introduction and that supporting material is in the appendix rather than the main sections. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the exact issues and address them effectively. The lack of detailed evidence or examples makes the claim 3, as it provides a general direction but requires more detailed justification for the authors to fully understand and address the issues.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: forward referencing, where material is introduced without proper explanation, and the need for clearer explanations of contributions in the introduction. It also points out that material supporting the main contributions is in the appendix rather than the main sections, which could impact the reader\"s understanding. While the comment highlights important areas for improvement, it does not provide detailed guidance on how to address these issues or specific suggestions for reorganizing the content. The feedback is 3 as it directs the authors\" attention to critical areas needing clarification, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. While the comment implies that the authors should provide results for the generative setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in Table 1, noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The comment further questions the results for the generative setting, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer requests clarification on the results for the generative setting. This is a logical question that requires the authors to provide additional information or results to address the concern. However, the comment does not provide specific reasoning or evidence to support why the discriminative setting is not applicable to real applications, making it 3. The authors would need to provide additional context or references to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 1, noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. This feedback is clear and actionable, as it highlights a gap in the paper\"s presentation of results and prompts the authors to address this issue by providing results for the generative setting. By doing so, the authors can enhance the comprehensiveness and applicability of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present the results for the generative setting. Overall, the comment is 4, as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional evidence or examples should be included or how to present them. The comment is explicit in stating that more should be done, but it lacks concrete guidance on how to implement this suggestion. As a result, the action is somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that more should be done to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what additional evidence or examples should be provided to support the feasibility of the query. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should provide more evidence to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the authors should provide more evidence to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. This feedback is 3 as it points out an area where the paper could be strengthened, but it lacks specific guidance or suggestions on how to address this issue. The comment is somewhat vague in terms of actionable steps, making it difficult for the authors to fully understand what changes are needed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to evaluate the approach for other language families or what specific steps should be taken to determine its effectiveness. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how to evaluate the approach for other language families. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the evaluation of the proposed approach, noting that its effectiveness for other language families remains unknown. This is a critical observation that highlights an important area for further exploration and validation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this gap. Without detailed feedback or recommendations, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific guidance on how to achieve this improvement or which works need more detailed descriptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the differences between the related works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not specify which part of the related work section is lacking in clarity or which specific works need more detailed descriptions. This makes it difficult for the authors to pinpoint the exact areas that need improvement. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to illustrate which works are insufficiently described or how their differences could be better explained. Without this level of detail, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement in the related work section, noting that some works are mentioned but their differences are not described in detail. This feedback is 3 as it points out a potential weakness in the paper and suggests a direction for enhancement. However, it lacks specificity and actionable guidance on how to address this issue, such as which works need more detailed descriptions or what aspects of their differences should be highlighted. To be more helpful, the comment could provide examples or suggestions on how to improve the related work section. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. This request is explicit and provides a clear action for the authors to take, which is to provide an explanation of the PPP maps and their significance. The feedback is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It points out that this explanation or understanding is not explicitly given in the article. The comment raises a question about the type of understanding one reaches by looking at PPP maps, implying that the authors should provide an explanation. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for an explicit explanation, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point questions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks, noting that this explanation is not explicitly given in the article. The reviewer asks for clarification by inquiring about the type of understanding one reaches by looking at PPP maps. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It points out that while the authors mention this point, they do not provide an explicit understanding or explanation. The comment raises a specific question about the type of understanding one reaches by looking at PPP maps, which prompts the authors to clarify this aspect of their work. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation, making it 4. However, it could be more helpful if it offered suggestions on how to present this explanation or provided examples of what the authors might consider. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with other stateoftheart methods, such as SpanBERT, which could impact the credibility of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include in the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional comparisons but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with other stateoftheart methods, specifically mentioning SpanBERT. However, it does not specify which part of the paper this comparison should be included in, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for comparison with SpanBERT, but it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods, specifically mentioning SpanBERT. However, the comment does not provide any specific examples or detailed reasoning to support why this comparison is necessary or how it would impact the credibility of the paper. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of comparisons with other stateoftheart methods, specifically mentioning SpanBERT. This feedback is valuable as it highlights an area where the paper could be strengthened by including such comparisons, which would enhance its credibility and relevance. However, the comment does not provide specific suggestions on which methods to compare or how to conduct these comparisons, leaving the authors with a general direction but without detailed guidance. While the feedback is 3 in pointing out a critical area for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic representation of the forward prediction model. It also notes that it was difficult to connect the text with the figure and equations. This feedback provides a clear and direct action for the authors to take, which is to redraw Figure 2(b) to improve its clarity and connection with the text. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that it does not show the schematic representation of the forward prediction model and that it is difficult to connect the text with the figure and equations. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, specifically mentioning that Figure 2(b) does not show the schematic representation of the model. The reviewer suggests that the figure should be redrawn to improve clarity. This claim is 3 as it provides a specific critique of the figure and suggests a potential improvement. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, noting that Figure 2(b) does not effectively represent the schematic representation of the model. It suggests that the figure should be redrawn to improve its connection with the text and equations. This feedback is clear and actionable, providing the authors with a concrete step to enhance the clarity and comprehensibility of their work. By addressing this feedback, the authors can significantly improve the readability and understanding of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for a stronger baseline but are not given concrete steps on how to achieve it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not specify which part of the paper discusses RBI or FP, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment provides a specific concern about the training process, it lacks detailed guidance on how to address this issue or improve the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment lacks specific examples or references to support the claim that rewardless actions are ignored, making it 3. The authors would need to further explore and substantiate the claim to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. While the comment highlights a relevant issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their draft. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that the statement is misleading because the RNNs operate on a logical time scale rather than a physical one. The reviewer provides a rationale for this critique, explaining that the only benefit seems to be the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the terminology, it does not provide explicit guidance on how the authors should address this issue or suggest alternative wording. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the terminology or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that it is misleading because the RNNs operate on a logical time scale rather than a physical one. However, the comment does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this discussion could be, the lack of explicit grounding makes it challenging to identify the specific part of the paper being addressed. The comment is specific in its critique of the terminology but lacks grounding, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of the term \"multiscale\" is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical reasoning by explaining that the only benefit seems to be the reduction of gradient path by the slow RNN. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"multiscale,\" which the reviewer argues is misleading. The reviewer provides a clear explanation of why this term is misleading, stating that the slow and fast RNNs operate on a logical time scale rather than a physical one. This feedback is valuable as it helps the authors understand the source of confusion and suggests a more accurate way to describe the RNNs\" operation. However, the comment could be more helpful if it offered suggestions for alternative terminology or provided additional context on how to clarify this aspect of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the baseline methods are weak and not stateoftheart, and it suggests that the authors should discuss limitations. It also raises questions about the difference between the work and reinforcement learning and suggests discussing similarities and differences in the conclusion. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss limitations and similarities to reinforcement learning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, noting that they are weak and not stateoftheart, and suggests discussing limitations. It also raises questions about the difference between the work and reinforcement learning and suggests discussing similarities and differences in the conclusion. However, the comment does not specify which part of the paper discusses the baseline methods or where the discussion of limitations should be included. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a direction for the conclusion, but it lacks detailed guidance on how to address the issues with the baseline methods or limitations. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and it suggests discussing limitations. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to discuss similarities and differences with reinforcement learning is also vague and lacks detailed reasoning or examples. Without explicit evidence or detailed justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the baseline methods are weak and not stateoftheart. It also points out the absence of a discussion on limitations, which is crucial for evaluating the work. Additionally, the comment raises questions about the difference between the work and reinforcement learning, suggesting that the authors should discuss similarities and differences in the conclusion. This feedback is clear and actionable, as it provides specific areas for improvement and offers a direction for the authors to enhance their draft. However, it could be more helpful if it included suggestions on how to address the limitations or discuss the differences with reinforcement learning in more detail. Overall, the comment is 4, as it guides the authors toward improving their paper by highlighting important areas for discussion and comparison."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the notation used in Equation (3) and points out the exponential dependence of corollaries and theorems on the domain data\"s diameter, $M$. It also notes that the performance is worse than expected, suggesting a potential weakness in the proposed approaches. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their work. The authors are left to infer that they need to clarify the notation and potentially investigate the performance issues, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. (3)) and results (Corollaries 1, 2, and 3, Theorem 4), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the domain data\"s diameter, $M$, and the impact on the required feature size. Additionally, it discusses the performance in Figure 1, which provides further context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the notation in Equation (3) and the exponential dependence of corollaries and theorems on the domain data\"s diameter, $M$. It also discusses the impact of this dependence on the required feature size and the performance shown in Figure 1. While the comment provides some logical reasoning and references specific equations and figures, it lacks detailed explanations or references to external works that could further substantiate the claim. The authors would need to infer the full implications of these observations themselves. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment raises several points that could be helpful for the authors to address. It questions the notation used in Equation (3), which could help clarify the terminology in the paper. Additionally, it points out the exponential dependence of corollaries and theorems on the domain data\"s diameter, $M$, and its impact on the required feature size. This observation could prompt the authors to reconsider the implications of this dependence and its potential impact on the performance of their methods. The comment also references Figure 1, which shows that the performance is worse than expected, suggesting a potential weakness in the proposed approaches. However, the comment does not provide specific suggestions on how to address these issues or improve the paper. While it identifies areas for improvement, it lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The mention of a specific paper provides some context but does not offer actionable steps for the authors. As a result, the comment is vague and lacks concrete details on how to implement any changes, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of \"poor longrange modelling ability\" of DGNs, which allows the authors to accurately identify the part of the paper being addressed. It also provides a specific reference to a paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning,\" which supports the claim about oversmoothing. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The reviewer supports this claim by referencing a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning,\" which is cited in AAAI\"18. This reference provides a clear and specific source for the claim, making it 5. The inclusion of an external reference enhances the credibility and justification of the claim, ensuring that the authors can understand and address the issue effectively.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance, referencing a specific paper for context. This feedback is 3 as it points out a specific area of concern and provides a reference for further exploration. However, the comment could be more helpful if it offered suggestions on how to address or mitigate these issues, such as recommending specific techniques or experiments to explore. Overall, the comment provides some direction but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any explicit or implicit guidance on how to clarify the problem formulation or what specific aspects are unclear. Without additional details or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, nor does it provide details on what aspects need clarification. This lack of specificity and lack of explicit references to sections or examples make it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples of what needs to be clarified, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 2, as it points out a problem but does not offer a path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This feedback is clear and provides a concrete action for the authors to take, which is to conduct additional experiments. The suggestion is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. The comment is based on a logical reasoning that additional experiments could enhance the understanding of the method\"s applicability across various LLM families. However, it lacks specific examples or references to support the claim that these experiments are necessary or beneficial. The suggestion is 3 as it provides a logical rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting the absence of experiments with different LLM families, such as OPT, BLOOM, or other alternatives. It suggests that conducting such experiments could provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it offers a specific direction for the authors to enhance their study by expanding their experimental scope. However, the comment could be more helpful if it provided additional context or rationale for why these experiments are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. The reviewer suggests that the connection between these two parts is weak and that the initial expectation of the first part was not met. However, the comment does not provide explicit guidance or suggestions on how the authors might strengthen the connection or address the perceived disconnect. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it difficult for the authors to pinpoint the exact areas needing revision. The comment provides some specific feedback about the expectations and outcomes of the first part, but it lacks detailed guidance on how to address the perceived disconnect. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the connection between the curve finding (the first part) and FGE (the second part) is weak. The reviewer provides a specific expectation of what the first part should entail, which is learning curves between weights and finding nice weights to be mixed into the final ensemble. However, the comment does not explain why this expectation was not met or how the current approach differs from the expected one. Additionally, the comment mentions that the approach could work but is computationally demanding, without elaborating on the implications or providing evidence to support this claim. The lack of detailed reasoning or examples makes the claim 3, as it requires more information to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. It suggests that the initial expectation of the first part was not met, as it did not involve learning curves between weights and finding nice weights to be mixed into the final ensemble. However, the comment acknowledges that this approach could work but is computationally demanding. While the comment highlights a potential issue, it lacks specific guidance or suggestions on how the authors might address this disconnect or improve the clarity of their work. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the results for linear scalarization with Concorde, a heuristicbased solver, for a better comparison. This is an explicit action with concrete details on what needs to be added to the experimental results. The authors know exactly what to do to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Concorde,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the need to include the results for linear scalarization with Concorde for a better comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, except for the single objective TSP where the SOTA heuristicsolver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison. However, the comment lacks specific examples or references to support the claim that Concorde is the best heuristic solver for the single objective TSP. Without detailed evidence or comparisons, the claim remains 3, as the authors would need to investigate the claim further to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers except for the single objective TSP, where the SOTA heuristicsolver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison, given that the Pareto front is not highly nonconvex. This feedback is clear and actionable, providing the authors with a specific direction to enhance their experimental analysis. By addressing this suggestion, the authors can improve the comprehensiveness and validity of their results. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should discuss the proposed method in relation to existing methods that capture similar general ideas, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. While the comment implies that the authors should make these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to make these comparisons or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and the \"general ideas\" that are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, discussing the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. The reviewer provides a detailed explanation of how these existing methods capture similar ideas, such as reasoning topologically and longterm storage through pose graphs. This reasoning is supported by references to specific methods and concepts, making the claim 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from these existing approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas proposed are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could provide a more comprehensive understanding of its novelty and contribution. This feedback is clear and actionable, as it directs the authors to consider how their work fits within the existing literature and to highlight its unique aspects. However, the comment could be more helpful if it provided specific examples or references to guide the authors in making these comparisons. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why the authors did not consider finer grouping for quantization, such as pertensor or perchannel. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or what specific changes they should make. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization grouping, specifically asking why pertensor and perchannel quantization were not considered. However, it does not specify which part of the paper discusses quantization or where this choice is made, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the choice of quantization grouping but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking why a specific approach was not considered, rather than a claim or opinion. It does not express a subjective judgment, suggestion, or deduction that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization grouping, specifically asking why pertensor and perchannel quantization were not considered. While it identifies a potential area for improvement, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights into why this choice might be beneficial or how it could be implemented. As a result, the comment is 3, as it prompts the authors to consider an alternative approach but does not fully support them in making improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. This feedback is explicit and provides a concrete suggestion for the authors to explore, making it 5. The authors know exactly what aspect of their work needs further investigation and how to approach it, which is a clear indication of the actionability of the comment.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting a particular aspect to explore, but it lacks grounding because it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes, providing an example of how performance varies with different ratios of unseen classes. This suggestion is based on logical reasoning, as it proposes an additional aspect of the study that could provide valuable insights. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the potential benefits of this analysis and how it could enhance their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an additional aspect of the study that could be explored, specifically the impact of the ratio of unseen classes on performance. It provides a concrete example of how the performance varies with different ratios of unseen classes, which is a clear and actionable suggestion for the authors to consider. By addressing this point, the authors could potentially enhance the depth and comprehensiveness of their analysis, making the comment 4. However, the comment could be more helpful if it provided further guidance on how to conduct this analysis or what specific metrics to focus on. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential area of interest, it does not provide explicit guidance or suggestions for the authors to address this question or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they might need to provide a rationale or justification for their architectural choices. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. However, it does not specify which part of the paper discusses these architectural choices, making it weakly grounded. The comment is specific in its inquiry about the rationale behind the architectural choices, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of using GRU for the Pyramid and LSTM for the sequential part. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential area of interest, it does not provide specific guidance or suggestions on how the authors might address this question or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of mention of the inapplicability of the theory to the used model in the limitations section and the vague nature of the structural assumptions given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the limitations and provide more detailed information on the structural assumptions, as well as consider the societal impact of graph neural networks. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the inapplicability of the theory to the used model, the vagueness of the structural assumptions given in the appendix, and the need for more elaboration on potential negative societal impacts of graph neural networks. This provides clear guidance on what needs to be addressed in the limitations section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the inapplicability of its theory to the used model in the limitations section, which is a subjective opinion. The reviewer also suggests that the structural assumptions are vague and not clearly stated, which could be a valid observation. However, the comment lacks specific examples or references to support these claims, making it 3. The suggestion to provide more elaboration on potential negative societal impacts of graph neural networks is a logical request but again lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It points out that the theory\"s applicability to the used model is not mentioned in the limitations section, which is a significant oversight. The comment also highlights the vagueness of the structural assumptions given in the appendix, making it difficult for readers to understand the limitations. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. This feedback is clear and actionable, offering specific areas for the authors to address and improve their draft. However, it could be more helpful if it included suggestions on how to clarify the structural assumptions or address the societal impact concerns. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"For training we used an epsilongreedy ...\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This comment explicitly identifies a point of confusion in the paper and requests clarification. However, it does not provide specific guidance on how the authors should address this issue or clarify the meaning of the statement. While the action is explicit, it lacks concrete details on how to resolve the confusion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilongreedy ...\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific statement in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a specific phrase in the paper, \"For training we used an epsilongreedy ...,\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This feedback is 3 as it identifies a potential area of confusion in the paper and prompts the authors to clarify their wording. However, the comment does not provide specific guidance on how to address the issue or improve the clarity of the text. While it points out a potential problem, it lacks depth and actionable suggestions, making it 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the framework need further discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the importance of different parts of the framework and how they contribute to the paper\"s distinction from related work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for a discussion on the importance of different parts of the framework, but without explicit references to sections or elements, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide any specific reasoning, examples, or references to support the claim that a discussion is needed or how it would distinguish the paper from related work. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the importance of specific parts of the framework in using CLIP for weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or detailed feedback on what aspects of the framework should be discussed or how to distinguish the paper from related work. As a result, the comment is 3, as it points out a gap in the paper but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, while most existing ML accelerators use bitparallel fixedpoint numbers. This implies that the proposed methodology might be limited in its applicability. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or explore alternative applications. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning its applicability to bitserial accelerators. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the potential restriction due to the use of bitparallel fixedpoint numbers in most existing ML accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, while most existing ML accelerators use bitparallel fixedpoint numbers. This claim is based on a logical inference about the applicability of the proposed methodology, but it lacks specific examples or references to support the assertion. The comment provides a reasonable basis for the claim, but the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, specifically noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. It also points out that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative applications. The feedback is 3 as it prompts the authors to consider the broader applicability of their work, but it could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It also points out the large loss of precision introduced by the quantization of MHSA, which has been observed in transformer quantization in NLP. The comment highlights specific examples and references to support its claims, providing concrete evidence for the authors to consider. However, while it identifies issues, it does not explicitly instruct the authors on how to address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors can infer that they need to provide a more detailed explanation or address the issues raised, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed critiques and examples, such as the comparison of quantization methods in Line 45 and the figures (1(b) and 5(b)), as well as references to similar work in NLP. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two main claims: (1) the analysis of vit quantification could be explained in more depth, and (2) the quantization of MHSA introduces a large loss of precision, which has been observed in transformer quantization in NLP. The first claim is supported by specific examples and references to figures, providing a clear basis for the critique. The second claim is also supported by references to similar work in NLP, which adds credibility to the assertion. However, the comment could be strengthened by providing more detailed reasoning or examples for the first claim. Overall, the claims are 4, as they are wellsupported but could benefit from additional explanation or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It supports this claim with specific examples from the paper, such as the comparison of quantization results in Figures 1(b) and 5(b). Additionally, the comment highlights the large loss of precision introduced by the quantization of MHSA, which has been observed in transformer quantization in NLP. This feedback is valuable as it identifies specific areas where the analysis could be improved and provides concrete examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to address these issues or improve the analysis. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a main weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. Additionally, it points out the lack of empirical or conceptual comparisons to STN, which is considered important. While the comment identifies the issue and provides some context, it does not explicitly instruct the authors on how to address these concerns or improve the draft. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the novelty and include comparisons to STN, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a main weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It mentions the proposed Xtransformation, which is similar to STN but applied locally, and references existing works that apply STN in a local pixel neighborhood. The comment also notes that PointNet uses a variant of STN in their network architecture. This provides specific details about the issue, allowing the authors to understand what needs to be addressed. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to existing work, specifically spatial transformer networks (STN) and PointNet. The reviewer provides a detailed explanation, noting that the proposed Xtransformation is similar to STN but applied locally, and that existing works have already applied STN in a local pixel neighborhood. This reasoning is supported by references to specific works, such as PointNet, which uses a variant of STN in their network architecture. The comment also highlights the lack of empirical or conceptual comparisons to STN, which is considered important. Overall, the claim is wellsupported by logical reasoning and references to external works, making it 5.", "helpfulness_rationale": "The review comment identifies a significant weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. The comment also notes the absence of empirical or conceptual comparisons to STN, which is considered important. This feedback is clear and actionable, as it directs the authors to enhance the novelty of their work by comparing it to existing methods, particularly STN. However, it could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving the technical novelty and comparison aspects of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is explicit and actionable, as it clearly instructs the authors to correct the figure reference. The second part is also explicit and actionable, as it provides a specific action for the authors to take to improve the paper\"s readability. However, the comment does not provide detailed guidance on how to link the theorems and corollaries to their proofs, which could be more concrete. Overall, the comment is 4, as it provides clear actions but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a typographical error (\"Fig.7\" should be \"Fig.12\") and suggests linking theorems and corollaries to their corresponding proofs to improve readability. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is factual and does not contain a claim, while the second part is a suggestion for improvement. The suggestion is logical and straightforward, aiming to enhance the paper\"s readability. However, it lacks specific examples or references to support the claim that this improvement is necessary or beneficial. Therefore, the comment is 4, as it provides a clear suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides two specific pieces of feedback. First, it corrects a typographical error by pointing out that \"Fig.7\" should be \"Fig.12\" in a specific row of the supplementary material. This is a clear and actionable suggestion that helps the authors improve the accuracy of their paper. Second, it suggests linking theorems and corollaries to their corresponding proofs, which would enhance the paper\"s readability and make it easier for readers to follow the logical flow. This is a constructive and actionable piece of feedback that could significantly improve the paper\"s clarity. However, the comment does not address broader issues or provide suggestions for improving the paper\"s overall structure or content. Therefore, while it is 4 for specific improvements, it could be more comprehensive to be fully helpful. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically regarding the focus on mask selection and rawlevel features. It points out that the framework discussed in Section 4.2 is not limited to rawlevel selection and suggests that representation learning could be considered for further improvement. However, the comment does not provide explicit guidance on how to incorporate representation learning or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the proposed invariant learning module, focusing on mask selection and rawlevel features, and suggests that representation learning could be considered for further improvement. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed invariant learning module focuses on mask selection and rawlevel features, and suggests that the framework discussed in Section 4.2 is not limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. However, the comment lacks specific examples or detailed reasoning to support the claim that representation learning could be further improved. While it identifies potential areas for improvement, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed invariant learning module, noting that it focuses on mask selection and rawlevel features. It points out that the framework discussed in Section 4.2 is not limited to rawlevel selection and suggests that representation learning could be considered for further improvement. This feedback is clear and actionable, as it highlights a potential area for enhancement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered specific suggestions or examples on how to incorporate representation learning into the feature selection process. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards. However, it does not provide explicit guidance on what details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors uncertain about how to improve their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions that \"some details are missing,\" specifically regarding the design of rewards. However, it does not specify which part of the paper this pertains to, such as a section or subsection, making it weakly grounded. The comment is specific in identifying the missing detail about the design of rewards, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically regarding the design of rewards. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand which details are missing or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks detail, namely the design of rewards. This is a clear and actionable piece of feedback that can guide the authors in improving their draft by providing more information on this critical aspect. However, the comment could be more helpful if it offered suggestions on what specific details should be included or how the authors might approach the design of rewards. Despite this, the feedback is still 3 as it directs the authors to a specific area needing attention. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the incremental nature of the improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also highlights the importance of experimental design. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived weakness or improve the paper, such as suggesting ways to enhance novelty or provide additional context. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the incremental nature of the improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the importance of experimental design. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides some insight into the perceived weaknesses, it lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work is an incremental improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the importance of experimental design. However, the comment lacks specific examples or references to support the claim of incremental improvement or the lack of novelty. Without detailed evidence or comparisons to other works, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 3, as it provides some justification but lacks comprehensive support.", "helpfulness_rationale": "The review comment acknowledges the incremental nature of the improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also highlights the importance of experimental design. However, the comment lacks specificity and actionable feedback, as it does not provide guidance on how the authors might address the perceived weakness or enhance the novelty of their work. Without detailed suggestions or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to discuss the runtime or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its suggestion to address the runtime as a limitation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selling point of MLbased emulators is their computational cheapness, and it suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count. The comment provides a logical reasoning for why the runtime is important, as it could be a limitation for applications requiring computational cheapness. However, it lacks specific examples or references to support the claim about the large parameter count or the potential impact on runtime. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a potential limitation of the Prithvi WxC model, specifically its large parameter count, which could impact its computational cheapness. It suggests that the authors should discuss the runtime of Prithvi WxC as a limitation for applications that require computational cheapness. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the inclusion of runtime discussions. However, the comment could be more helpful if it offered guidance on how to measure or present the runtime data or suggested ways to mitigate the limitation. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs further attention."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to implement the feedback. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not specify which part of the paper is being referred to, such as a particular section, figure, or table, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the method are being oversold or how the contribution could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper may be overselling its method, which could make the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references to particular aspects of the paper that are being oversold, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific examples or details on what aspects of the method are being oversold or how the contribution could be clarified. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of what changes are needed to address the issue. This lack of specificity and guidance makes the comment 2, as it identifies a potential issue but does not offer meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement them or what specific steps should be taken. The authors can infer that they need to restructure the model description and consider adding a notation table, but the comment lacks concrete guidance on how to achieve these improvements. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need for a better presentation of the generative process in separate steps and the inclusion of a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where the model description is presented. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in suggesting improvements, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would enhance understanding or what specific issues are currently present in the model description. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be better understood if presented in separate steps. It also mentions the need for a notation table to enhance clarity. While the comment highlights important aspects for improvement, it lacks detailed guidance or examples on how to implement these changes. The feedback is 3 as it points out areas for enhancement, but it could be more actionable with additional suggestions or specific instructions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework beyond LLMbased models, such as HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or evaluations, it does not provide specific guidance on how to implement this verification or what specific tests to perform. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of the framework\"s applicability, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the need for further verification, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo. The comment provides a logical reasoning by suggesting that the framework\"s applicability should be tested with nonLLMbased models. However, it lacks specific examples or references to support the claim that these models should be included in the evaluation. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo. This feedback is 3 as it identifies a potential limitation in the paper\"s scope and suggests a direction for further validation. However, the comment lacks specific guidance on how to conduct these additional verifications or what specific aspects of the framework should be tested. While it provides a valuable insight, the lack of detailed suggestions limits its usefulness for the authors in terms of actionable steps to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The action is implicit and vague, as the authors are left without clear direction on how to enhance the clarity of their writing. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not specify which parts of the paper are particularly challenging or what aspects of the writing need improvement. Without explicit references to sections, figures, or specific issues, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what needs to be addressed to improve clarity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear or confusing, the authors may find it challenging to address the feedback effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it lacks specificity and does not provide actionable feedback or guidance on how to improve the writing. Without detailed suggestions or examples of what aspects need clarification or enhancement, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the theoretical novelty of their method. The action is implicit and vague, as the authors are left to infer what specific changes or additions might be necessary to enhance the theoretical contribution. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its reliance on existing methods, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the lack of theoretical novelty and suggests that the authors address this concern to improve the score. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This claim is supported by the explicit mention of specific existing methods, such as ClopperPearson intervals and Gaussian elimination, which are referenced with citations. This provides a clear basis for the reviewer\"s assertion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method relies on these existing methods, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This feedback is 3 as it points out an area where the authors might need to enhance their contribution. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve the theoretical novelty of their work. Without actionable advice, the authors may struggle to know exactly what steps to take to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the sentence in lines 1217 of the abstract, noting that it is cumbersome and can be made clearer. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes that could be made. The action is implicit, as the authors can infer that they need to simplify the sentence, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence in lines 1217 of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 of the abstract is cumbersome and can be made clearer. However, it does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in lines 1217 of the abstract, noting that it is cumbersome and could be made clearer. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should consider revising the sentence for clarity. However, the comment lacks detailed guidance or suggestions on how to achieve this clarity, such as proposing alternative phrasing or restructuring the sentence. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a tradeoff between head and tail categories, but this tradeoff has not been fully investigated for the baselines. The reviewer suggests that by changing hyperparameters in Decouple [Kang et al.], it could also significantly improve tail accuracy while slightly decreasing head accuracy. This feedback provides a clear direction for the authors to explore further, suggesting that they should investigate the tradeoff for the baselines and potentially improve their approach. The comment is explicit in its suggestion to continue this line of work for future submission, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. Additionally, it points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a tradeoff between head and tail categories, but this tradeoff has not been fully investigated for the baselines. The reviewer suggests that by changing hyperparameters in Decouple [Kang et al.], it could also significantly improve tail accuracy while slightly decreasing head accuracy. This claim is 3 as it provides a logical reasoning for the potential improvement in the baselines, but it lacks specific examples or references to support the claim fully. The authors would need to explore this suggestion themselves to verify the claim, making the comment 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This feedback is actionable as it identifies specific areas for improvement and provides a clear direction for the authors to explore. The suggestion to continue this line of work for future submission is also constructive. Overall, the comment is 5 as it offers detailed and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not provide specific guidance on which datasets to consider or how to incorporate them into the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the need for additional datasets and how to integrate them effectively. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the evaluation, which is primarily based on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides clear guidance on what needs to be addressed to improve the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included. The comment references Figure 4(5), which the authors admit may be unreliable, providing some justification for the claim. However, the comment lacks specific examples or detailed reasoning about why the LLaVA benchmark would be beneficial or how it could improve the evaluation. This makes the claim 3, as it provides a basis for the suggestion but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, noting that it primarily relies on four OCR QA datasets. It acknowledges the authors\" admission that this evaluation may be unreliable, as seen in Figure 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, providing the authors with a specific direction for improving the robustness and comprehensiveness of their evaluation. However, it could be more helpful if it offered additional guidance on how to incorporate the suggested benchmarks or provided examples of how to conduct a more comprehensive evaluation. Overall, the comment is 4 as it effectively guides the authors toward enhancing their evaluation methodology."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment does not provide explicit guidance or suggestions for how the authors might address these concerns or simplify the tasks. The action is implicit and vague, as the authors are left to infer that they should simplify the tasks but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"abstract visual reasoning tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with these tasks, such as their unintuitiveness, difficulty, and potential for confusion due to multiple rows and changing factors. The comment further questions the necessity of these tasks and suggests simpler alternatives. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. The reviewer expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment lacks specific examples or references to support the claim that simpler tasks would be more effective. The suggestion to provide proof that the current formulation is the best approach is also not substantiated with evidence or references. Without detailed reasoning or examples, the claim remains 3, as it provides a basis for questioning but lacks comprehensive support.", "helpfulness_rationale": "The review comment raises significant concerns about the abstract visual reasoning tasks used in the paper, describing them as unintuitive and overly difficult. It highlights the complexity of the tasks, with multiple rows and changing factors, and questions the interpretation of the models\" learning. The reviewer suggests that simpler visual reasoning tasks might be more effective and asks for proof that the current formulation is the best approach. While the comment identifies a critical issue with the tasks, it lacks specific suggestions or guidance on how to address these concerns or simplify the tasks. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"[author] embeddings\" is not realistic. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the realism of the evaluation and generation, but they are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the prompt, as well as critiquing the generation of authors. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that weak supervision could be better evaluated, specifically questioning the realism of the evaluated tweets and the prompt. It provides a detailed critique of the prompt, noting that it requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, stating that the use of \"[author] embeddings\" is not realistic. While the comment provides specific examples and reasoning, it could be strengthened by referencing similar studies or practices that support the claim. Overall, the claim is 4, as it provides a logical and detailed critique, but lacks comprehensive references or examples to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the realism of the evaluated tweets and the prompt used for weak supervision. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"[author] embeddings\" is not realistic. This feedback is clear and actionable, as it directs the authors to reconsider the realism of their evaluation and prompts them to make improvements in this area. However, the comment could be more helpful if it offered suggestions on how to enhance the realism or provided examples of more realistic approaches. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by identifying specific areas for enhancement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of essential visualizations of intermediate processes and comparisons, suggesting that these are necessary for the paper. However, it does not provide specific guidance on what these visualizations should include or how they should be presented. The action is implicit, as the authors can infer that they need to add visualizations, but it is vague because it lacks concrete details on what exactly should be visualized or compared. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualizations of intermediate processes and comparisons, but it does not specify which part of the paper lacks these visualizations or what specific comparisons are missing. This makes it difficult for the authors to identify the exact sections that need improvement. The comment is 1 as it does not mention any specific sections, figures, or tables, and it is not specific because it lacks detailed guidance on what should be visualized or compared. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out the lack of essential visualizations of intermediate processes and comparisons. This feedback is valuable as it highlights a potential gap in the paper that could enhance its clarity and comprehensibility. However, the comment does not provide specific suggestions or examples of what these visualizations should include or how they could be implemented. While it directs the authors\" attention to an important aspect of their work, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is a concern that needs to be addressed. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. The comment provides a clear and specific issue to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This feedback is 3 as it prompts the authors to consider the potential impact of colloquial language on their analysis and to ensure that their categorization is accurate. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a review of the classification criteria or suggesting alternative approaches. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the output quality is reasonable but notes that it is still far from realistic. It references recent GAN works that have achieved amazing quality in synthesized results, suggesting that the bar has become much higher than a few years ago. The reviewer implies that there is still room for improvement in result quality, but does not provide specific guidance on how to achieve this improvement. The comment also mentions the limited novelty, low resolution output, and high hardware requirement, which could be considered as reasons for rejection. However, the feedback lacks actionable advice or suggestions for the authors to address these issues. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, specifically mentioning that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive results, suggesting that the bar has been raised. However, the comment does not specify which part of the paper discusses the output quality, making it weakly grounded. The comment is specific in its critique of the output quality and the need for improvement, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive results. The reviewer suggests that the bar has been raised significantly in recent years, implying that the current output quality is insufficient. However, the comment lacks specific examples or references to these recent GAN works, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides a general context but lacks detailed evidence or examples to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the output quality is reasonable but notes that it is still far from realistic, particularly in comparison to recent GAN works that have achieved impressive results. The reviewer suggests that the bar has been raised significantly in recent years, implying that there is still room for improvement in result quality. However, the comment does not provide specific guidance or suggestions on how the authors might enhance the output quality or address the identified issues. Additionally, the comment mentions the limited novelty, low resolution output, and high hardware requirement, which could be considered as reasons for rejection. While it highlights areas for improvement, the feedback lacks actionable advice or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors might infer that it relates to the experimental results or methodology sections, but this is not explicitly stated. The comment is specific in detailing the concerns about the use of soft labels and hyperparameters, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots, suggesting that they might be subpar. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these concerns or improve their draft. Without detailed feedback or examples, the authors are left without a clear understanding of what changes are needed to enhance their work. Therefore, the comment is 2, as it identifies potential issues but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the small number of images in the VioT dataset, questioning its ability to validate the approach. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. There is no guidance on whether additional images should be included, how the dataset could be expanded, or what specific steps the authors should take to improve the dataset\"s validity. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images in each category, which raises concerns about the dataset\"s validity. However, the comment lacks specificity as it does not provide suggestions or guidance on how to address this issue or what steps the authors could take to improve the dataset\"s validity. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the small number of images in the VioT dataset, questioning its ability to validate the approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why 20 images per category are insufficient. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the VioT dataset, specifically noting that the number of images provided (20 per category) may be insufficient to validate the approach. This is a relevant observation that could impact the robustness and generalizability of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without additional context or recommendations, the authors are left with a general concern but no clear path to improvement. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting an ablation study to explore the relationship between the number of layers and performance. While the suggestion is explicit, it lacks concrete details on how to implement this study or what specific aspects should be considered. The authors are given a clear direction but may not be entirely sure of the exact steps to take. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to explore the relationship between the number of layers and performance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting an ablation study, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point suggests conducting an ablation study to explore the relationship between the number of layers and performance. However, it does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or necessary. The suggestion is made without any context or explanation, making it difficult for the authors to understand the rationale behind the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to explore the relationship between the number of layers and performance. While this is a specific and actionable suggestion, it lacks depth and does not provide additional context or rationale for why this study would be beneficial or how it could impact the paper. The comment does not offer guidance on how to conduct the ablation study or what specific aspects to focus on, leaving the authors with a clear direction but limited insight into how to implement it effectively. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance for execution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including its lack of intuitive explanations for mathematical derivations, insufficient figure captions, and the need for additional explanations and legends. The reviewer also mentions that Figures 1 and 2 did not contribute much to their understanding and required multiple readings. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The actions are implicit and somewhat vague, as the authors are left to infer what kind of explanations or legends are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Fig. 1 and Fig. 2) and the need for more intuitive explanations in the mathematical derivations. It also points out the lack of figure captions and the need for additional explanations and legends. This allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it details what is missing or unclear, such as the need for more intuitive explanations and the lack of figure captions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also criticizes the figure captions and legends, stating that they require additional explanations and that Figures 1 and 2 did not contribute much to the reviewer\"s understanding. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or examples makes the claim 3, as it provides a general direction but not enough detail for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the lack of intuitive explanations for mathematical derivations and insufficient figure captions. It provides specific feedback by suggesting that the authors include additional explanations and legends, particularly for Figure 2, which the reviewer found confusing. This feedback is actionable as it directs the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the explanations or provided examples of what additional information should be included in the figure captions. Overall, the comment is 4 as it highlights clear areas for improvement and provides some guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could negate any improvement gained from the method. The reviewer explicitly states that they are willing to reconsider their rating if this issue is addressed. While the comment highlights an important area for improvement, it does not provide specific guidance on how the authors should evaluate or address the sensitivity of the results to hyperparameter choices. The action is explicit but lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing the importance of this issue. However, it does not specify which part of the paper discusses the empirical results or hyperparameter choices, making it weakly grounded. The comment is specific in its request for addressing the sensitivity of the results to hyperparameter choices, which could impact the overall evaluation of the method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing the potential impact on the method\"s effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 2, as it lacks sufficient support to be fully actionable.", "helpfulness_rationale": "The review comment raises an important concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could negate any improvement gained from the method. This is a critical point that the authors need to address to ensure the robustness and validity of their findings. However, the comment does not provide specific guidance on how to evaluate or address this sensitivity, such as suggesting methods for parameter tuning or sensitivity analysis. While it identifies a significant area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it highlights a crucial issue but lacks actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, given that it utilizes existing attack methods on a surrogate model. While the comment implies that the authors should provide a justification for the novelty of their approach, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty and contribution of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and contribution of the proposed method, specifically mentioning that it utilizes existing attack methods on a surrogate model. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its request for further clarification on the novelty and contribution, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model, which is similar to using the transferability of adversarial examples directly. The reviewer suggests that the authors need to further claim the novelty and contribution of their proposed method. However, the comment lacks specific examples or references to support the claim that the work is not novel or lacks contribution. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model. It suggests that the authors should further clarify the novelty and contribution of their approach. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a critical aspect of the paper that needs clarification, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of multiple observations and suggestions. It explicitly states that the text in Table 1 is too small and hard to read, providing a clear action for the authors to improve the readability of their tables. Additionally, it points out that Algorithm 1 is missing a gradient symbol in line 4, which is a specific and actionable issue to address. The comment also includes references to relevant literature, which can guide the authors in improving their work. Overall, the comment is 5 as it provides explicit and concrete actions for the authors to take, ensuring they know exactly what needs to be done to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in Table 1 and the missing gradient symbol in Algorithm 1, providing clear guidance on what needs to be addressed. Additionally, it includes references to relevant literature, which further specifies the areas needing improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple observations and suggestions, each of which is verifiable. The first point about the text in Table 1 being too small and hard to read is a factual observation that can be verified by examining the table. The second point about Algorithm 1 missing a gradient symbol in line 4 is also factual and can be verified by checking the algorithm. The references provided for the third point, regarding differentially private stochastic convex optimization, are specific and can be used to support the claim. Therefore, the comment is 4, as it provides clear and specific evidence for each point, except for minor gaps in the explanation of the references. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out two issues: the small and hardtoread text in Table 1, and the missing gradient symbol in Algorithm 1. It also references relevant literature, which can guide the authors in improving their work. This level of detail and specificity empowers the authors to make targeted improvements to their draft, making the comment 5. The authors are given clear directions on what needs to be addressed, which is crucial for enhancing the clarity and readability of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not discuss computational aspects in detail, particularly in high dimensions, and questions the practical usefulness of their proposed methods. It highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on smallscale datasets. While the comment identifies a concern about the computational aspects and the scalability of the methods, it does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed discussions and potentially conduct experiments on larger datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions the requirement to solve several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on smallscale datasets. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the discussion of computational aspects and the appendix, where the LPs are mentioned. The comment is specific in detailing the issue with the computational aspects and the scalability of the methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail, particularly in high dimensions, and questions the practical usefulness of their proposed methods. It highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on smallscale datasets. While the claim is based on logical reasoning and observations from the paper, it lacks specific examples or references to support the assertion about the difficulty of solving LPs in high dimensions. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the authors do not provide sufficient detail on the practical usefulness of their proposed methods, especially in terms of scalability. The comment highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. This observation is relevant and important, as it raises concerns about the applicability of the method in realworld scenarios. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues, such as providing more detailed explanations or conducting experiments on larger datasets. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests that a potentially interesting baseline would be to compare to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether the ResNet in the experiments shares parameters between residual blocks and suggests a potentially interesting baseline for comparison. The comment provides a clear suggestion for improvement by recommending a deeper ResNet with parameter sharing as a baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests a potentially interesting baseline for comparison, which is a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support the claim that this comparison would be interesting or beneficial. The suggestion is based on logical reasoning but lacks specific examples or references to substantiate the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests that a potentially interesting baseline would be to compare to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it provides a specific suggestion for a potential improvement or comparison that could enhance the experimental setup. However, the comment lacks detailed guidance on how to implement this suggestion or why it would be beneficial, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically addressing the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the motivation, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the motivation but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer provides a logical reasoning by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support this reasoning, making it 3. The authors would need to further explore the architecture to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment lacks actionable suggestions or guidance on how the authors might improve the motivation or clarify the architecture\"s functionality. Without specific feedback or recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is 3, as it identifies a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, especially since the question model is a bag of words, which is not expensive to encode longer sequences. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their design. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10, providing a clear rationale for why this might be an odd choice, especially since the question model is a bag of words. This level of detail helps the authors understand what aspect of their work needs attention and improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. The comment provides a logical reasoning based on the nature of the question model, which is a straightforward explanation. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence or context to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. This feedback highlights a potential inconsistency or inefficiency in the design, prompting the authors to reconsider their approach. However, the comment does not provide specific suggestions or alternatives for improving the design, nor does it offer detailed guidance on how to address this issue. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement or action. It lacks specific guidance on what the authors should do to address these issues, such as recommending the use of more modern models or methods or suggesting alternative approaches. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights the issue of antiquated models, it does not provide specific suggestions or examples of more modern alternatives. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of an \"antiquated\" GNN model and method negatively impacts the performance of the framework. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks evidence or justification for why the model and method are considered antiquated and how this impacts performance. Without such support, the claim remains 1, as the authors would need to make significant efforts to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable advice or examples of more modern alternatives, the feedback is limited in its usefulness to the authors. Therefore, it is rated as 2, as it highlights a critical area for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity in Figure 1 regarding how the proposed method produces the type of explanation mentioned. It suggests that additional adhoc postanalysis is needed to extract shared motifs to explain a set of instances. While the comment implies that the authors should provide more detailed explanations or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the explanation but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation in Figure 1, noting the lack of clarity regarding how the proposed method produces the type of explanation mentioned. The comment further suggests that additional adhoc postanalysis might be necessary to extract shared motifs, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis is needed to extract shared motifs. However, the comment does not provide specific examples or detailed reasoning to support this claim. The reference to \"Line 48\" is not sufficient to fully substantiate the claim, as it does not provide context or explanation. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanation in Figure 1, noting that it is unclear how the proposed method produces the type of explanation mentioned. It suggests that additional adhoc postanalysis might be necessary to extract shared motifs, which could help explain a set of instances. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a weakness but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a concern about the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large perturbation value to ensure the correctness of the pseudo feature importance. The comment suggests that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two ways to strengthen the experiment: by using true feature importance or by providing a more detailed analysis of the perturbation value. These suggestions are explicit and provide concrete guidance on how to improve the experiment. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, namely the use of pseudo feature importance due to the lack of true feature importance, and the reliance on Proposition 3.2 and a large perturbation value. The comment further suggests ways to strengthen the experiment, such as using true feature importance or providing a more detailed analysis of the perturbation value. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiment using pseudo feature importance is difficult to trust because it relies on Proposition 3.2 and a large perturbation value. The reviewer suggests that the experiment could be strengthened by using true feature importance or providing a more detailed analysis of the perturbation value. While the comment provides a logical reasoning for the claim, it lacks specific references or detailed examples to fully substantiate the critique. The suggestion for improvement is clear, but the initial claim could be more robust with additional evidence or references. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large perturbation value to ensure the correctness of the pseudo feature importance. The comment points out that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two actionable suggestions for improvement: using true feature importance or providing a more detailed analysis of the perturbation value. This feedback is clear and constructive, offering the authors specific ways to enhance the robustness and credibility of their experiment. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for changes, specifying that two lines in red should be in green in the Supplementary Material. It also provides specific line numbers and references to equations, tables, and algorithms that need to be updated. This feedback is clear and actionable, as it directly tells the authors what changes need to be made and where. The authors know exactly what to do to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the Supplementary Material that need to be updated, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the color of the lines and the references to equations, tables, and algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of factual statements regarding specific lines in the Supplementary Material that need to be updated. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying specific lines in the Supplementary Material that need to be updated. It specifies the changes required, such as changing the color of certain lines and updating references to equations, tables, and algorithms. This level of detail empowers the authors to make precise corrections, ensuring the accuracy and clarity of their draft. The comment is 5 as it directly addresses a specific issue and provides concrete steps for improvement, making it easy for the authors to implement the suggested changes."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper, but acknowledges that it is a short paper and therefore not a strong negative against what the authors have done. While the comment implies that the authors should consider expanding their analysis, it does not provide specific guidance on how to achieve this or what aspects of the analysis should be expanded. The action is implicit and somewhat vague, as the authors are left to infer that they should enhance their analysis but without concrete steps or details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should focus on or what specific aspects need improvement. The mention of \"this paper\" implies that the comment is addressing the entire paper, but without explicit references to sections or specific elements, the authors cannot confidently determine the exact parts that need attention. The comment is vague and lacks specificity, making it 1 and not specific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it acknowledges that the paper is short and does not consider this a strong negative against the authors\" work. The comment does not provide specific examples, references, or detailed reasoning to support the claim that a more comprehensive analysis would be beneficial. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is short and suggests that a more comprehensive and dataintensive analysis would significantly improve it. However, it does not provide specific guidance or suggestions on how the authors might achieve this improvement or what aspects of the analysis could be expanded. The comment lacks actionable feedback and does not offer a clear path for the authors to enhance their work. As a result, it is 2, as it identifies a potential area for improvement but does not provide sufficient detail or direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches to metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment provides a clear direction for the authors to expand their citations and make connections between different areas of research, it does not specify which specific works should be cited or how the authors should distinguish between different approaches. The action is explicit but somewhat vague, as the authors know they need to expand their citations and make connections but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches to metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment does not explicitly mention specific sections or parts of the paper, it does provide a clear direction for the authors to expand their citations and make connections between different areas of research. The authors can infer that this pertains to the sections discussing related work or literature review, as these are typically where citations are included. However, the comment lacks specific details on which works should be cited or how to distinguish between different approaches. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work, as it seems to directly follow as an application to continual learning. However, the comment lacks specific references or examples of these works, making it difficult for the authors to fully understand and address the suggestion. The claim is 3, as it provides a logical reasoning for the suggestion but lacks detailed evidence or references to support it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper\"s citation and connection to related works, specifically suggesting that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches to metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning, which are already cited. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their citations and make connections between different areas of research. However, the comment could be more helpful if it included specific suggestions on which works to cite or how to distinguish between different approaches. Overall, the comment is 4, as it guides the authors toward improving the comprehensiveness and context of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. It asks whether the authors intend to use human turkers to provide feedback or generate different types of feedback to make it more realistic. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the lack of lexical and syntactic diversity in the teacher feedback, implying that it might be autogenerated. However, it does not explicitly mention which part of the paper this feedback is discussed in, making it weakly grounded. The comment is specific in detailing the issue of diversity and suggesting ways to address it, such as using human turkers or generating different types of feedback. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. The reviewer asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the feedback is autogenerated or that diversity is lacking. This makes the claim 3, as the authors would need to provide evidence or further explanation to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the teacher feedback, noting a lack of lexical and syntactic diversity. It raises a question about whether the feedback is autogenerated and suggests that using human turkers or generating different types of feedback could make it more realistic. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement by suggesting ways to enhance the diversity and realism of the feedback. However, the comment could be more helpful if it offered specific examples or guidance on how to implement these suggestions. Overall, the comment is 3, as it provides a clear direction for improvement but lacks detailed guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and that these results should be summarized. While the comment implies that the authors should include a summary of the supplementary experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary and where it should be placed. However, the comment provides a clear direction on what needs to be addressed, making it 4.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. However, it does not specify which part of the main text this issue pertains to, making it weakly grounded. The comment is specific in its request for summarizing the results of the supplementary experiments, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. However, the comment does not provide any specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper. By addressing this point, the authors can ensure that readers are fully informed about the scope and results of their work. However, the comment could be more helpful if it included specific guidance on how to present the supplementary results or examples of effective summaries. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the discrepancy between the claim and the results, nor are there suggestions for further analysis or experimentation to support the claim. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment does not provide specific details on what aspects of the claim are questionable or how the slight improvement affects the overall conclusion. Without explicit references or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the slight improvement is insufficient to support the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment identifies a potential weakness in the paper but lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. As a result, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel, is insufficient. It suggests that there could be many different designs of this process and recommends conducting experiments or analysis with different sampling intervals and sample sizes. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment suggests conducting experiments or analysis with different sampling intervals and sample sizes, which provides some specificity regarding what could be improved. However, the lack of explicit grounding in the paper makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the Cycle FC is insufficient and suggests conducting experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or detailed reasoning to support why these additional experiments or analyses are necessary. Without concrete evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. It suggests that the analysis could be improved by conducting experiments or analysis with different sampling intervals and sample sizes. This feedback is 3 as it points out an area for improvement and provides a specific suggestion for enhancing the analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific insights might be gained from them. Overall, the comment provides some direction but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of standard deviations in the paper, which makes it difficult to determine if the best method is truly the best or if other RF configurations have similar performance. While the comment implies that the authors should include standard deviations to provide more robust analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but are not given specific guidance on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which affects the evaluation of the best method\"s performance. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures where standard deviations should be included. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in identifying the issue, it is 1 because it does not specify where in the paper this issue occurs. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations makes it difficult to determine the robustness of the best method\"s performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it challenging for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the absence of standard deviations, which is crucial for evaluating the robustness of the best method\"s performance. By pointing out this gap, the comment provides the authors with a clear direction for improvement, as including standard deviations would enhance the transparency and reliability of their results. However, the comment could be more helpful if it suggested specific ways to incorporate standard deviations or provided examples of how this information could be presented. Despite this, the feedback is 4 as it highlights a critical area for improvement that the authors can address to strengthen their draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the feature extractor used for the dimensionality of each region, which is mentioned in line 201. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern or a suggestion for improvement, and it does not offer any direction on how the authors should address this question. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the feature extractor used for the dimensionality of each region, providing a clear area for clarification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the feature extractor used for the dimensionality of each region, as mentioned in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the feature extractor used for the dimensionality of each region, as mentioned in line 201. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the information. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it points out a potential issue but does not offer any actionable steps for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors are left to infer that they need to add these details but are not guided on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in suggesting what kind of details should be added, but without clear grounding, the authors may struggle to determine where these details should be incorporated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning or evidence to support why these details are necessary or how they would enhance the paper. The comment lacks depth and does not provide a clear justification for the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on which details should be included or how they should be presented. The feedback is 3 as it points out a general area for enhancement, but it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification regarding the choice of p < 0.4 in Algorithm 1. This is a direct and concrete question that the authors can address by providing an explanation or justification for their selection. The action is clear and specific, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4, which is a clear and direct question. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification on the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it directly questions the choice of p < 0.4 in Algorithm 1. This prompts the authors to provide an explanation or justification for their selection, which can help clarify the rationale behind their methodology. By addressing this point, the authors can enhance the transparency and credibility of their work. However, the comment could be more helpful if it provided additional context or suggested alternative approaches for selecting p. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. It suggests that references to specific works, such as [1] and [2], could help clarify the unique advantages of the method. While the comment implies that the authors should conduct additional analysis and comparisons, it does not provide explicit instructions on how to implement these actions. The authors can infer the need for more analysis and comparisons, but the comment lacks concrete guidance on how to execute these steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the effectiveness of each data augmentation method, allowing the authors to identify the specific part of the paper being addressed. It also specifies the need for a comparison with other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of the method. The comment provides specific suggestions for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of the method. The comment supports this claim by referencing specific works, including [1] and [2], which provide examples of relevant studies. This provides a solid basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis on the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. The comment provides specific references to relevant works, which can guide the authors in enhancing their analysis and understanding of their approach. This feedback is clear and actionable, offering a concrete direction for improvement that can significantly enhance the paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider this scenario, it does not provide explicit guidance on how to address it or what specific aspects of the model\"s performance should be evaluated. The action is implicit and somewhat vague, as the authors need to infer that they should investigate this scenario and determine its impact on the model\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, experiment, or analysis. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance should be evaluated or how this scenario relates to the overall study. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the performance of a specific model scenario. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting scenario that the authors might not have considered, it lacks depth and does not provide any guidance or suggestions on how to address this issue or its implications. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is 2, as it prompts the authors to consider a specific scenario but does not provide meaningful direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a trend in the performance of RLCD compared to RLAIF, noting that the advantage shrinks as the model size increases. It also raises a question about the scalability of RLCD to larger language models. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation about the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about the scalability of RLCD to larger language models. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, referencing Table 2. It also raises a question about the scalability of RLCD to larger language models. However, the comment lacks specific examples or detailed reasoning to support the claim about the shrinking advantage or the scalability issue. Without additional evidence or references, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a trend in the performance of RLCD compared to RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It also raises a question about the scalability of RLCD to larger language models, suggesting that it remains to be seen whether RLCD can scale to models that are better at differentiating responses near the decision boundary. While the comment identifies an important observation and raises a relevant question, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is 3 as it points out a potential area of concern, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies the lack of quantitative analysis on computational gains and suggests that specific measurements or comparisons should be included to substantiate the claims. It provides clear guidance by specifying what kind of quantitative analysis would be beneficial, such as GPU hours, memory usage, or training time. This feedback is direct and concrete, giving the authors a clear understanding of what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely specific measurements or comparisons to substantiate the claimed computational benefits. The comment provides a clear direction for improvement by suggesting the inclusion of quantitative analysis, such as GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains from replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 4 as it provides a clear suggestion for what kind of evidence would strengthen the paper\"s claims. However, it lacks specific examples or references to existing literature or studies that could further substantiate the need for such quantitative analysis. Therefore, the comment is categorized as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights the importance of specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNNbased data augmentation strategy. The suggestion to include quantitative analysis, such as GPU hours, memory usage, or training time, provides clear and actionable guidance for the authors to strengthen their claims and improve the credibility of their findings. This feedback is valuable as it directs the authors to a specific area for improvement, making it 4. However, it could be more helpful if it offered examples or references to similar studies that have successfully implemented such analyses. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, as it renders the method less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should account for this time or how it affects the efficiency comparison. The action is implicit and lacks concrete details on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, which implies that the efficiency of the method is being discussed. However, the comment does not specify which part of the paper this comparison is made in, nor does it provide details on what specific aspects of efficiency are being addressed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of efficiency. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, implying that this factor affects the efficiency of the method. However, the comment does not provide any specific data, examples, or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed evidence or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method being evaluated, specifically mentioning the time taken by COLMAP and scenebyscene finetuning. This is a relevant observation that could impact the overall efficiency comparison of the method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the efficiency comparison. Without detailed feedback or suggestions, the authors may struggle to understand how to incorporate this information into their draft. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage,\" potentially hindering the performance of the planning component. The reviewer wonders if the CNN could perform reasonably well with less data. While the comment implies that the authors should consider reporting results at different stages of training and potentially explore the performance of the CNN with less data, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timing of the results reporting, specifically noting that the results are only presented after a significant amount of training has occurred. It raises a concern about the agent\"s behavior during the learning process and speculates that the model parameters might be \"garbage\" early in training, potentially hindering the planning component. The comment also wonders if the CNN could perform reasonably well with less data. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the results or methodology sections. The comment is specific in its critique and suggestion, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. The reviewer speculates that early in training, the model parameters might be \"garbage,\" potentially hindering the performance of the planning component. This claim is based on logical reasoning and common knowledge about the nature of reinforcement learning (RL) agents, where early training stages can be challenging. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct additional analysis to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the timing of the results reporting, noting that the results are only presented after a significant amount of training has occurred. It suggests that in reinforcement learning (RL), it is often important to understand how the agent behaves during the learning process, as early stages might involve \"garbage\" model parameters that could hinder the planning component. The reviewer speculates that the CNN might perform reasonably well with less data, which could be an interesting exploration for the authors. While the comment identifies a potential issue and provides some direction for further investigation, it lacks specific suggestions or actionable steps for the authors to take. Therefore, it is 3, as it prompts the authors to consider a different perspective on their results but does not fully guide them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their contribution. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to sections, figures, or specific contributions, the authors cannot confidently determine which parts of the paper are being addressed. This lack of grounding and specificity makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal because the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why the contribution is considered marginal, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their contribution or address the concerns raised. Without actionable advice or constructive criticism, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It suggests that the performance gain is mostly attributed to PBSD, which is a component related to supervised contrastive learning (DSCL). The reviewer asks for additional motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. While the comment implies that the authors should clarify the contribution and motivation of PBSD, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanations or motivations for PBSD. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically questioning the motivation behind the PBSD component. It references the ablation study to highlight the performance gain from PBSD and suggests that the paper is mostly motivated by supervised contrastive learning (DSCL). However, the comment does not specify which part of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in its request for additional motivations for PBSD beyond improving discriminative power on tail classes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the main contribution of the paper being unclear, specifically questioning the motivation behind the PBSD component. The reviewer provides a logical reasoning by pointing out that the performance gain is mostly attributed to PBSD, which is a component related to supervised contrastive learning (DSCL). However, the comment lacks specific examples or references to support the claim that the paper is mostly motivated by DSCL. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of clarity regarding the main contribution. It points out that the performance gain is mostly attributed to the PBSD component, which is related to supervised contrastive learning (DSCL). The reviewer questions the motivation for PBSD beyond improving the discriminative power of the learned representation on tail classes. This feedback is 3 as it prompts the authors to clarify the main contribution and motivation of their work. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to better articulate the contribution. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)identity tester as well. It specifically mentions a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the tester\"s capabilities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)identity tester and provides a specific example of how it might not handle (\u03c0,\u03d5) pairs where \u03d5=\u03d50 but dK(\u03c00,\u03c0) is large. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the tester for the spread parameter, specifically asking if it immediately yields an (\u03f5,\u03b4)identity tester. It provides a specific example of a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment raises a valid point, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to infer the potential issue and address it themselves. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment raises a question about the tester for the spread parameter, specifically asking whether it immediately yields an (\u03f5,\u03b4)identity tester. It provides a specific example of a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. This feedback is 3 as it identifies a potential gap in the paper\"s explanation or testing methodology. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their testing framework. To be more helpful, the comment could include specific recommendations or examples of how to handle such scenarios. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific information should be included or how the authors should present the distribution. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the distribution is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or what additional information is needed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the detailed distribution of the proposed dataset, which is an important aspect of the paper. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect of their work. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, the comment is 2, as it points out a problem but does not offer a path to resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment highlights a potential limitation, it does not provide explicit guidance on how the authors might address this issue or explore a selfsupervised approach. The action is implicit and somewhat vague, as the authors are left to infer that they should consider a selfsupervised approach but are not given specific steps or examples on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or where the limitation is mentioned, making it weakly grounded. The comment is specific in its suggestion to consider a selfsupervised approach, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that a selfsupervised approach would be more appealing. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, noting that it requires annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might implement a selfsupervised approach or address the limitation. The feedback is 3 as it points out a critical issue, but it lacks depth and actionable advice, leaving the authors with a general direction but no detailed steps to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit suggestion that provides a clear direction for the authors to improve their work. However, the comment does not specify how the authors should go about implementing this suggestion, such as which specific tasks to consider or how to present the results. While the action is explicit, the lack of concrete guidance makes it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the types of tasks that could be used to demonstrate scalability, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to make these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that continuous control experiments are typically performed on simple and lowdimensional tasks, such as cartpole or mountain car, and recommends demonstrating the scalability of LFF by showing its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for the suggestion, noting the common practice of using simple tasks for experimentation. However, the comment lacks specific examples or references to support the claim about the scalability of LFF on these more complex tasks, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the applicability and robustness of their work. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their study. However, the comment could be more helpful if it included additional guidance on how to implement these more complex tasks or what specific aspects of LFF should be highlighted in the context of these tasks. Overall, the comment is 4, as it provides a clear path for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest whether the authors should update their baseline selection, include additional baselines, or address the issue of outdated baselines in their discussion. Without actionable guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the papers \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" However, the comment does not provide any supporting evidence, references, or reasoning to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s selection of baselines, specifically noting that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" This feedback is 3 as it points out a potential weakness in the paper\"s methodology, prompting the authors to reconsider their choice of baselines and potentially update their analysis to include more recent and relevant works. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative baselines or discussing the implications of using outdated baselines. Therefore, while it provides some insight, it could be more helpful with additional detail and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. It provides a clear action for the authors to take, which is to compare the tensor completion results for all the models with the same number of model parameters. The reviewer suggests a method for computing the number of model parameters, which is a concrete step for the authors to follow. This feedback is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"tensor completion results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, namely the omission of the value of the used ranks, which makes it difficult to make a fair comparison. The comment further provides a suggestion on how to address this issue by comparing the tensor completion results for all models with the same number of model parameters. This level of detail provides clear guidance on what needs to be improved, making the comment 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. The reviewer suggests that to show the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models with the same number of model parameters. This claim is 3 as it provides a logical reasoning for the need to include the value of the used ranks and suggests a specific way to improve the comparison. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand the issue and address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the omission of the value of the used ranks for all the models, which makes it difficult to make a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all models with the same number of model parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and rigor of their experimental results, allowing for a more robust evaluation of their model. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully implemented this approach. Overall, the comment is 4, as it provides clear guidance for improving the draft but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the inconsistency in the normalization module between the two versions and the need for standardization in the pictograms used in the figures. It also mentions a specific issue with Figure 4, where the chosen symbols overlap in the 0/50 latency range and 2.5/4.0 MAE. Additionally, it points out minor textual issues on page 4. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific changes to the normalization module or how to standardize the pictograms. The authors can infer that they need to make these changes, but the lack of concrete guidance makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4\" and \"pag. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the normalization module, the need for standardization in the pictograms, and the confusion in Figure 4 regarding the symbols. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the inconsistency in the normalization module between the two versions and the need for standardization in the pictograms. It also points out a specific issue with Figure 4, where the chosen symbols overlap. However, the comment lacks detailed reasoning or examples to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of \"minor problems about the text\" is also vague without specific examples. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail and evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including inconsistencies in the normalization module between the two versions and the need for standardization in the pictograms used in the figures. It also points out a specific issue with Figure 4, where the chosen symbols overlap, which could lead to confusion. Additionally, the comment mentions minor textual issues on page 4. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues, such as proposing specific changes to the normalization module or suggesting alternative symbols for Figure 4. The feedback is 3 as it directs the authors\" attention to specific areas that need attention, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the author\"s claim regarding the removal of subdivision splines and the potential extra computation cost involved. It questions whether the proposed algorithm is detailed enough to remove these splines and addresses a specific issue related to the theoretical part of the paper. While the comment highlights a potential gap in the explanation of the algorithm, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as it points out a problem but does not guide the authors on how to resolve it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the author\"s claim about removing subdivision splines and the potential extra computation cost involved. It also refers to the theoretical part of the paper, allowing the authors to accurately identify the sections being addressed. The comment is specific because it questions the detailed explanation of the proposed algorithm and its potential impact on computation cost. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the author\"s claim about removing subdivision splines and the potential extra computation cost involved. It highlights a gap in the theoretical explanation of the proposed algorithm, suggesting that the authors should provide more details on how the algorithm removes subdivision splines. The comment is 3 as it identifies a specific area where the paper lacks clarity, but it does not provide detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for additional explanation, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the author\"s claim about removing subdivision splines and the potential extra computation cost involved. It points out a gap in the theoretical explanation of the proposed algorithm, which is a critical area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it highlights an important area for clarification, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it does not explicitly instruct the authors to clarify or address this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental methodology and address the potential unfair advantage. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the 300WLP dataset in the experimental methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the experimental methodology and raises concerns about the potential unfair advantage provided by the use of the 300WLP dataset. The comment clearly specifies what needs to be clarified or addressed regarding the experimental methodology, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. The comment provides a logical reasoning by pointing out the inconsistency in the experimental setup and its potential impact on the results. However, it lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This feedback is clear and actionable, as it prompts the authors to clarify their experimental setup and address any potential biases in their methodology. By doing so, the authors can ensure the fairness and transparency of their experiments, which is crucial for the credibility of their results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to clarify the experimental methodology. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their techniques. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide details on why these techniques might not be novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or improve the novelty of their techniques. Without actionable feedback or guidance, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It explicitly states that providing such an analysis would strengthen the paper. However, it does not specify what aspects of the analysis should be included or how the authors should approach it. The action is explicit but vague, as it lacks concrete guidance on how to conduct the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, which would enhance the paper\"s solidity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It suggests that providing such an analysis would strengthen the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of indepth analysis in the paper, specifically regarding the inverse scaling phenomenon over compute. It suggests that providing an analysis of this training dynamic would strengthen the paper. While the comment highlights an area for improvement, it does not offer specific guidance or suggestions on how the authors might conduct this analysis or what aspects to focus on. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the proposed algorithm, suggesting that it requires an additional assumption that each individual\"s data is iid drawn from the same distribution. The reviewer questions the validity of this assumption, noting that in practice, users\" preferred sets of emojis are likely to be different. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or revise the assumption, but without concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6\" and \"Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed algorithm, namely the assumption that each individual\"s data is iid drawn from the same distribution, and questions the validity of this assumption. The comment provides a detailed critique of the theoretical foundation of the algorithm, which is a clear and actionable point for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of an assumption made in the paper regarding the iid nature of individual data. The reviewer provides a logical reasoning by questioning how Theorem 6 can be applied to prove Theorem 7 without this assumption. Additionally, the comment highlights a potential issue with the assumption by noting that in practice, users\" preferred sets of emojis are likely to be different. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed algorithm, specifically questioning the assumption that each individual\"s data is iid drawn from the same distribution. It points out that this assumption may not be justifiable in practice, as users\" preferred sets of emojis are likely to be different. This feedback is clear and actionable, as it prompts the authors to reconsider and justify their assumption or explore alternative approaches. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to make the assumption more realistic. Overall, the comment is 4 as it directs the authors\" attention to a critical area that requires further consideration and justification."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments focus primarily on presenting results, with insufficient analysis of the method itself and the experimental outcomes. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more comprehensive analyses and clarify the attribution of performance improvements. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the focus of the experiments, which is primarily on presenting results, and questions the comprehensiveness of the analysis of the method itself and the experimental outcomes. It also raises concerns about the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the experimental sections, but the lack of explicit references makes it challenging to pinpoint the exact areas needing attention. The comment is specific in its critique of the analysis and attribution of performance improvements, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments focus primarily on presenting results, with insufficient analysis of the method itself and the experimental outcomes. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed justification makes the claim 3, as the authors would need to infer the issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the experiments primarily focus on presenting results rather than comprehensively analyzing the method and its outcomes. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. This feedback is valuable as it highlights a potential weakness in the paper\"s analysis and suggests that the authors should provide more detailed and comprehensive analyses to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions on how to improve the analysis or what additional information should be included. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how to broaden the applicability or what specific changes should be made to improve the paper. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not specify which part of the paper this focus is discussed in, nor does it provide details on how the applicability could be broadened. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of applicability are limited or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper primarily focuses on explaining multitask models, which limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of applicability are limited or how the focus on multitask models affects it, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any specific suggestions or guidance on how the authors might broaden the applicability or address this limitation. Without actionable feedback or detailed advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the literature review in the next section ignores several papers that are seemingly relevant, specifically mentioning VRMARINA for online problems from [1] and DASHAMVR from [2]. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment implies that the authors should include these papers in their literature review to provide a more comprehensive overview. However, it does not explicitly instruct the authors to do so or provide detailed guidance on how to integrate these references into the literature review. The action is implicit and somewhat vague, as the authors can infer what needs to be done but lack specific instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"next section\" and the \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by mentioning several papers that are seemingly relevant but have been ignored, specifically VRMARINA for online problems from [1] and DASHAMVR from [2]. The comment further specifies that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear guidance on what needs to be addressed in the literature review. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review in the next section ignores several papers that are seemingly relevant, specifically mentioning VRMARINA for online problems from [1] and DASHAMVR from [2]. It further suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment provides specific references to external works, which helps verify the claim. However, it lacks detailed reasoning or examples on why these papers are relevant or how they relate to the current literature review. This makes the claim 4, as it provides a starting point for the authors to explore but requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are seemingly relevant, particularly VRMARINA for online problems from [1] and DASHAMVR from [2]. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it provides specific references and a rationale for why these papers should be included in the literature review. By addressing this oversight, the authors can enhance the comprehensiveness and accuracy of their literature review, which is crucial for the credibility of their work. However, the comment could be more helpful if it offered suggestions on how to integrate these references or provided additional context on why these papers are relevant. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions: the first asks for additional insights into modest performance gains on Clothing1M, and the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are explicit and seek specific information from the authors. However, they do not provide any guidance or suggestions on how the authors should address these questions or improve their draft. The lack of actionable advice makes it difficult for the authors to know what steps to take in response to the questions. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment consists of two questions, each of which seeks additional information or clarification. The first question asks for insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, the questions lack specificity regarding what kind of insights or performance details are being sought. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions seeking additional insights or information. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of two questions seeking additional insights or information. The first question asks for additional insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are relevant and could provide valuable context for the authors to enhance their understanding of the performance and applicability of their algorithm. However, the comment lacks actionable feedback or suggestions on how the authors might address these questions or improve their draft. While it prompts the authors to consider these aspects, it does not offer guidance on how to incorporate the insights or information into the paper. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper should describe the hyperparameters used by each defense and how they are derived. It also suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing how much clean data is required to remove the attack. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding hyperparameters used by each defense and how they are derived. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what is missing, namely the description of hyperparameters and their derivation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing how much clean data is required to remove the attack. This claim is 3 as it provides a logical reasoning for why this information is important and how it could impact the evaluation of defenses. However, the comment could be strengthened by providing specific examples or references to support the claim, such as similar studies that include such details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing how much clean data is required to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on what information is missing and how to improve their evaluation of defenses. By addressing these points, the authors can enhance the comprehensiveness and rigor of their study. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical results\" lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate these takeaway points or whether this observation is indeed novel. The action is implicit and somewhat vague, as the authors are left to infer that they should include more practical implications and clarify the novelty of their findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, acknowledging the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not specify which part of the paper discusses these theoretical results or where the authors should include more practical implications. While the authors might infer that it relates to the theoretical sections, the comment lacks full grounding as it does not explicitly mention specific sections or figures. The suggestion is specific in terms of what the authors should consider, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the theoretical nature of the results and their lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific examples or references to support the claim that this observation is novel or lacks practical implications. The reasoning is somewhat logical but lacks detailed evidence or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the theoretical nature of the results and their lack of immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific guidance on how to incorporate these takeaway points or how to present them in a more practical context. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why separators are needed. However, the comment does provide a clear direction for the authors to follow by asking for an explanation of the additional information conveyed by the separators. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for introducing separators and asks for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the introduction of separators is questionable. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This feedback is 3 as it prompts the authors to provide a justification for the inclusion of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. To be more helpful, the comment could include more detailed feedback or suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of mean pooling for tokens and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to explore or evaluate other pooling strategies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling for tokens and suggests considering other pooling strategies. The comment provides a clear direction for the authors to explore alternative approaches, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of mean pooling for tokens and suggests considering other pooling strategies. However, it does not provide any specific reasoning, examples, or references to support why mean pooling might not be the best choice or how other pooling strategies could be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling for tokens, suggesting that other pooling strategies could be considered. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples of alternative pooling strategies that could be explored. The comment is 3 as it prompts the authors to consider other options, but it does not offer detailed suggestions or actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information. However, the comment does provide a clear direction on what specific details are missing, which makes it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections. The comment is specific in its request for clarification on the training details, providing clear guidance on what information is missing. However, since the exact part of the paper is not explicitly mentioned, the comment is weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a clear and actionable suggestion that prompts the authors to provide additional information about their training process. By addressing this question, the authors can enhance the transparency and comprehensiveness of their methodology section. However, the comment could be more helpful if it provided context or explained why this information is important. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. While the comment implies that the authors should reconsider their experimental approach, it does not explicitly instruct them to make changes or provide detailed guidance on how to implement the suggested alternative. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their experimental setup and potentially make changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the experimental methodology, namely the need to run a descent procedure for 40 different networks from the training phase. However, it does not explicitly mention which section of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the alternative method suggested by the reviewer, which involves running vanilla Adam on the final network with 40 random initial points. This provides clear guidance on what could be improved in the experimental setup. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the proposed approach by suggesting an alternative method that could potentially reach the global minimum. The reviewer provides a logical reasoning by comparing the proposed algorithm to a simpler method involving vanilla Adam and random initial points. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is clear and actionable, as it provides a specific suggestion for improving the experimental design. However, the comment could be more helpful if it included additional context or explanation on why the suggested alternative might be more effective. Overall, the comment is 4 as it offers a constructive critique and a potential path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment raises several questions and suggestions regarding specific aspects of the paper. It explicitly asks why the authors did not specify what Omega is at line 178 and suggests being more explicit about the OMD algorithm and the link function. Additionally, it inquires about the specific theorem in reference [32] that is being referred to for the regret guarantee. These questions and suggestions provide clear and explicit actions for the authors to take, such as specifying Omega, being more explicit about OMD, and clarifying the link function and theorem reference. The feedback is concrete and direct, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 178, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the need to specify what Omega is, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to for the regret guarantee. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, such as \"Why not say what Omega is here\" and \"What link function?\" It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the lack of clarity in the paper regarding the definition of Omega, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being used for the regret guarantee. This feedback is clear and directs the authors to address these areas of ambiguity, which can significantly improve the comprehensibility and rigor of their work. By prompting the authors to clarify these points, the comment is 5 as it empowers the authors to enhance the clarity and precision of their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"UCF101\" and \"synthesized results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. It also highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. However, the comment does not provide detailed reasoning or examples to support these claims, making it 3. The authors would need to further investigate these issues themselves to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. It highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. However, the comment lacks depth and does not provide specific guidance or suggestions on how to improve the results or address the identified issues. While it points out areas for improvement, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether studying the number of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32bit logit should improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to conduct it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this aspect. However, the comment does provide a concrete suggestion about the potential impact of the experiment on strengthening the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does provide some specificity by suggesting that having a 32bit logit might improve robustness, but it lacks detailed guidance on how to address this question or where to incorporate it into the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. The comment suggests that having a 32bit logit might improve robustness, but it does not provide any evidence or references to support this claim. The reasoning is based on intuition, which is not sufficient to fully substantiate the claim. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises an interesting question about the potential impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, which is a logical inference based on the authors\" work. However, the comment does not provide specific guidance or suggestions on how the authors might explore this question or incorporate it into their study. While it identifies a potential area for further investigation, it lacks actionable advice or detailed feedback, making it 3. The authors are left with a general idea but no clear direction on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the difference between the meta solvers and the centralized RL where agents share the weights. It provides a specific example from Foester et al., which gives the authors a clear direction on how to address the issue. The comment is explicit and provides concrete guidance on what needs to be clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking for clarification on the difference between meta solvers and centralized RL, where agents share weights. Additionally, it provides a specific reference to Foester et al., which further grounds the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers and suggests that the authors clarify the difference between them and centralized RL where agents share weights. The comment provides a specific reference to Foester et al., which supports the claim by offering a relevant example. This external reference enhances the verifiability of the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples within the context of the paper, which would align with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the nature of the meta solvers, suggesting they might be centralized controllers. It provides a specific reference to Foester et al. to clarify the difference between meta solvers and centralized RL where agents share weights. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work. By referencing a relevant study, the comment offers a concrete example of how to address the issue, making it 5 for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the paper\"s methodology, specifically the way it categorizes papers based on their publication years on the ACL anthology. The reviewer points out that many papers are available on arXiv much earlier than their publication on the ACL anthology, using the example of the BERT paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their methodology. The action is implicit, as the authors can infer that they need to reconsider their categorization method, but it lacks concrete details on how to implement this change. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with categorizing papers based on their publication years on the ACL anthology, providing a specific example of the BERT paper being available on arXiv earlier. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out a potential issue with the methodology and provides a concrete example of a paper that contradicts the categorization. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s categorization of papers based on their publication years on the ACL anthology is problematic because many papers are available on arXiv much earlier. The reviewer provides a specific example of the BERT paper being available on arXiv from October, which supports the claim. This level of detail and reference to a specific example makes the claim 4, as it provides a clear basis for the critique. However, the comment could be strengthened by including more examples or additional reasoning to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically the categorization of papers based on their publication years on the ACL anthology. It points out that many papers are available on arXiv much earlier than their publication on the ACL anthology, using the example of the BERT paper. This feedback is valuable as it highlights a potential flaw in the paper\"s categorization approach and suggests that the authors may need to reconsider their methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered alternative categorization methods. Despite this, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that requires further consideration. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of M_T on page 3 is not clear and recommends providing examples to explain it. This feedback is explicit and provides a clear action for the authors to take, which is to include examples to clarify the concept. The suggestion is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, suggesting that M_T is defined over probabilities of atomic events and recommending the inclusion of examples to clarify the concept. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the definition of M_T on page 3 is not clear and suggests providing examples to explain it. However, the comment does not provide any specific reasoning or examples to support why the current definition is unclear or how examples would improve understanding. Without additional context or explanation, the claim lacks sufficient justification, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of M_T on page 3, suggesting that it is not clear because it is defined over probabilities of atomic events. The reviewer recommends providing examples to clarify this concept, which is a clear and actionable suggestion that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples to illustrate the issue further. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with more detailed guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this observation. There is no guidance on how to refine the work or what specific aspects could be improved upon. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects could be refined or improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how to improve the performance enhancements. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting that there is room for further refinement. However, the comment lacks specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the modest performance enhancements observed in the paper, suggesting that there is room for further refinement in the future. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might improve their work. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their draft need refinement or how to achieve it. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that the performance is similar to IRM and questioning whether this is due to the issues mentioned earlier. However, it does not provide explicit guidance on how the authors should address these concerns or improve their experimental results. The comment lacks actionable details, such as suggesting specific analyses or modifications to enhance the experimental validation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the last two datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that they are not convincing enough to validate the effectiveness of the proposed method due to similarities with IRM. The comment raises a question about whether this similarity is caused by the issues mentioned earlier. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. The reviewer questions whether this similarity is due to the issues mentioned earlier. However, the comment lacks specific examples or detailed reasoning to support the claim that the performance is similar to IRM or to explain why the results are not convincing. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the performance on the last two datasets is not convincing enough to validate the effectiveness of the proposed method. It suggests that the performance is similar to IRM, which raises questions about whether this similarity is due to the issues mentioned earlier. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or improve their experimental validation. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it highlights a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this question, modify the figure, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to respond. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the figure and asks for clarification on the difference between detecting both entities and just knowing the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a question seeking clarification about the necessity of detecting both entities in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. This is a valid point that prompts the authors to reconsider the relevance and importance of detecting both entities in their analysis. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it does not offer actionable feedback or insights that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks empirical validation and suggests that experiments should be conducted to validate the bounds. This provides a clear and direct action for the authors to take, which is to include empirical validation through experiments. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks empirical validation and requests experiments to validate the bounds. However, it does not specify which part of the paper this lack of validation pertains to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for empirical validation but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation and suggests that experiments should be conducted to validate the bounds. However, the comment does not provide any specific examples, references, or detailed reasoning to support why empirical validation is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of empirical validation. It suggests that the authors should include experiments to validate the bounds, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on what types of experiments or validation methods might be appropriate. Despite this, the feedback is still valuable as it directs the authors to a critical area for improvement in their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This comment is explicit in its request for clarification, as it directly asks for an explanation of the phrase. However, it does not provide any guidance on how the authors should address this confusion or clarify the terminology. The action is explicit but lacks concrete details on how to implement the clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"nonsequential information such as chunks\" and asks for clarification on whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks,\" specifically asking whether \"chunk\" is still considered sequential information. This is a clear and specific question that prompts the authors to clarify a potential ambiguity in their work. By addressing this question, the authors can ensure that their terminology is consistent and understandable to readers. However, the comment does not provide any additional context or suggestions for improvement beyond the clarification request. While it is a useful prompt for the authors to clarify their terminology, it lacks depth and does not offer broader guidance for enhancing the draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or clarify the exception. The action is implicit, as the authors need to infer that they should provide an explanation for this exception, but it is vague because it lacks concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound when there is a separate node with 0 neighbors, and it seeks an explanation for this exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the upper bound is not true. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. This feedback is 3 as it identifies a potential issue with the theorem and prompts the authors to consider and explain this exception. However, the comment lacks depth and does not provide specific guidance on how to address the issue or improve the theorem. To be more helpful, the comment could include suggestions on how to resolve the exception or clarify the theorem. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty of their work but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited technical novelty by comparing the current paper with two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not specify which sections of the paper these comparisons should be made in, making it difficult for the authors to pinpoint the exact parts that need revision. The comment is specific in identifying the issue of limited novelty but lacks grounding as it does not explicitly mention the sections of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. This claim is 3 as it provides a basis for comparison with specific references, allowing the authors to understand the context of the critique. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current paper lacks novelty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical novelty, noting that it is similar to two previous works (Xing and Tsang, 2022a, b) despite focusing on graphbased approaches. This feedback is 3 as it points out a specific area where the paper may lack originality, prompting the authors to consider how they might differentiate their work from existing literature. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it highlights a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the analysis regarding the detection of rumors generated by GPT, suggesting that further analysis or solutions should be proposed. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this analysis or propose solutions. The action is implicit and somewhat vague, as the authors are left to infer what kind of analysis or solutions are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by questioning the analysis of why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. The comment suggests that further analysis or solutions should be proposed to address this gap. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or solutions regarding the detection of rumors generated by GPT, specifically questioning why GPTgenerated rumors are as difficult to detect as natural rumors. The reviewer provides a logical reasoning by pointing out that both GPTgenerated and natural rumors are written by humans, and therefore, the difficulty in detection should be similar. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning and evidence themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis or solutions regarding the detection of rumors generated by GPT. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is clear and actionable, as it prompts the authors to further explore and analyze this aspect of their work. By addressing this gap, the authors can enhance the comprehensiveness and depth of their analysis, which is crucial for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this analysis. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the font size in Figure 6 is a bit small, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the font size should be increased, how much it should be increased, or if there are any specific considerations for the figure. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6 being small. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment points out a specific issue with the font size in Figure 6, noting that it is a bit small. While this is a factual observation, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or why it is important to do so. As a result, the comment is 2, as it identifies a minor issue but does not assist the authors in making meaningful improvements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in the comparison or what steps to take to improve the draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what aspect of the comparison is unfair or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any supporting evidence, reasoning, or references to justify why the comparison might be unfair. The comment lacks specific examples or detailed analysis to substantiate the claim, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. While it identifies a potential issue with the comparison, it does not provide any actionable guidance or suggestions for the authors to address this concern. The comment lacks depth and does not offer any specific advice on how the authors might improve their draft to resolve the issue of fairness in the comparison. As a result, the feedback is 2, as it points out a potential problem but does not assist the authors in making meaningful improvements to their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors need to infer that they should investigate other relationships and explain their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the context of \"training\" and the \"mono tonic relationship\" between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about whether the mono tonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. The reference to [1] provides additional context and support for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and asks for an explanation. The comment references a specific paper, \"Learning the Pareto Front with Hypernetworks,\" which provides some context and direction for the authors to explore alternative relationships. However, the comment lacks detailed reasoning or examples of how other relationships might be explored or why the mono tonic relationship is problematic. This makes the claim 3, as it provides a starting point but requires further elaboration from the authors to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and encourages the authors to explain this point further. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might explore alternative relationships or what specific aspects of the explanation could be improved. The reference to a related work provides some context but does not fully support the claim or offer actionable advice. Therefore, the comment is 3, as it prompts the authors to consider an aspect of their work but does not provide comprehensive guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the goal of their paper in the introduction and provide examples that better demonstrate the need for interprocess communication. It also implies that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to make these changes, leaving some room for interpretation. The action is mostly concrete, as it specifies the types of examples to consider, but it is not fully explicit. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the examples provided do not convincingly demonstrate the need for interprocess communication, particularly regarding samplingbased Bayesian methods. The reviewer provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This level of detail and guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples in the paper do not convincingly demonstrate the need for interprocess communication, particularly regarding samplingbased Bayesian methods. The reviewer suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion. This makes the claim 3, as the authors would need to further develop the reasoning to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the introduction regarding the paper\"s goal and the need for interprocess communication. It suggests that the examples provided, particularly those related to samplingbased Bayesian methods, do not convincingly demonstrate the relevance of the paper\"s results. The reviewer offers a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and relevance of their work. However, it could be more helpful if it included additional guidance on how to incorporate these suggestions into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is an explicit statement that clearly directs the authors to check and fix the hyperlinks. The action is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue of broken hyperlinks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the functionality of hyperlinks in the paper, specifically noting that footnotes 3 and 4 do not seem to work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is straightforward and identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address by checking and fixing the hyperlinks. However, the comment does not provide any additional context or suggestions on how to troubleshoot or prevent similar issues in the future. While it is a useful observation, it lacks depth and does not offer comprehensive guidance for improvement. Therefore, the comment is 3, as it provides a clear direction for the authors to take action but lacks broader insights or suggestions for enhancement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. The action is concrete but stated implicitly, making the comment 4.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. This provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the modeling section is unclear, making it weakly grounded. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding regarding the figure, suggesting that the Label Embeddings are external parameters rather than the output of the encoder. This feedback is specific and provides clear guidance on how to improve the paper. However, it does not include references or detailed reasoning to fully substantiate the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting revisions to the discussion, particularly in the modeling section. It highlights that the current form of the discussion is not clear enough and offers a concrete example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. This guidance is clear and actionable, giving the authors a direct path to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the discussion further. Overall, the feedback is 4 as it provides valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network in Section 528 is hard to understand and recommends starting the section with the final paragraph, which is clearer. This feedback provides a clear and explicit action for the authors to take, which is to restructure the section to improve clarity. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the readability of the section. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, noting that it is hard to understand but becomes clearer in the final paragraph. The comment provides a clear suggestion to start the section with the final paragraph, which offers a concrete way to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network in Section 528 is hard to understand but becomes clearer in the final paragraph. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network in Section 528, noting that it becomes clearer in the final paragraph. It provides a clear and actionable suggestion to improve the draft by recommending that the authors start the section with the final paragraph, which is clearer. This feedback is valuable as it directs the authors to a specific area for improvement and offers a concrete solution to enhance the readability of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to further clarify the initial description. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance or suggestions on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its suggestion to explore attentionbased training, but without clear grounding, it is challenging for the authors to determine where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or how it might impact the model\"s performance. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. This is a relevant point that could lead to potential improvements in the model\"s performance or applicability. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might explore this possibility or what specific steps they could take to implement it. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning whether the column header should suffice as one type. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should clarify the division, revise the table structure, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the division of tables into three types and suggests that the column header should suffice as one type. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the division of tables into three types, specifically questioning whether the column header should suffice as one type. However, it does not provide any supporting evidence, reasoning, or examples to justify why the division is unclear or unnecessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning whether the column header should suffice as one type. While it identifies a potential area of confusion, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect of their paper. The comment is 3 as it points out a potential issue, but it does not offer actionable advice or detailed feedback to assist the authors in addressing the concern. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are considered naive and suggests that other classical attack methods in NLP should be considered. However, it does not provide specific guidance on which classical attack methods should be used or how to incorporate them into the paper. The comment implies that the authors should explore additional attack methods, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the attack methods used in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the attack methods are considered naive and suggests that other classical attack methods in NLP should be considered. The comment provides specific examples of papers that could be referenced for alternative attack methods, which adds further clarity and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of papers that could be referenced for alternative attack methods, which helps to substantiate the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current attack methods are inadequate or how the suggested methods would be more effective. Overall, the claim is 4, as it provides some support but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by pointing out that the attack methods used are considered naive. It suggests that other classical attack methods in NLP should be considered, providing specific examples of papers that could be referenced for alternative approaches. This feedback is clear and actionable, as it directs the authors to explore additional attack methods and references that could enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it included specific suggestions on how to integrate these alternative methods or provided more detailed guidance on which aspects of the current methods are considered naive. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue, such as suggesting ways to mitigate the impact or improve the image quality. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and their impact on \"image generation capabilities of diffusion models,\" but it does not specify which part of the paper discusses these methods or their effects. This makes it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of image quality are affected or how the authors might address these issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.\" However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they may affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue or improve the image quality. Without detailed guidance or examples, the authors are left without a clear understanding of what steps to take to resolve the problem. Therefore, the comment is 2, as it highlights a potential concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to mitigate the potential issues. The feedback is implicit and lacks concrete details on how to implement changes, making it 3.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper discusses this issue or where the prior knowledge is incorporated, making it weakly grounded. The comment is specific in detailing the potential issue of unfairness due to the leakage of additional information from the pretrained visual model and target dataset. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides a general concern but lacks sufficient detail for verification.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue of unfairness resulting from the leakage of additional information from the pretrained visual model and target dataset. This feedback is 3 as it identifies a critical area that could impact the validity of the results and suggests a potential source of bias. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or mitigate the potential bias. To be more helpful, the comment could include recommendations for controlling or accounting for this bias in the experimental setup or analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further analysis, clarification, or improvement. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps, if any, they should take in response to this observation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise at the dominance of function words over content words in a Japanese sentence. However, the comment does not provide further details or suggestions on how to address this observation, making it specific but not fully grounded. Therefore, this comment aligns with category 4.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this observation. The comment lacks specific examples or explanations that would help the authors understand the basis of the surprise or how this observation relates to the paper\"s content. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue or improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any further context, analysis, or suggestions for improvement. It lacks depth and does not offer actionable feedback or guidance for the authors to address this observation or its implications. As a result, the comment is 1, as it does not provide any value to the authors in terms of improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use the minimal kmeans objective over multiple seeds as a baseline instead of the average of kmeans objectives with multiple seeds. The comment provides specific references to support this suggestion, which is a concrete action for the authors to take. The references offer a clear direction on how to implement the suggested change, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the average of kmeans objectives with multiple seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using the minimal kmeans objective over multiple seeds as a more reasonable baseline, providing a clear and actionable suggestion. The comment further supports this suggestion with references to relevant literature, which enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds is not a suitable baseline and proposes using the minimal kmeans objective instead. This claim is supported by references to two external works that provide evidence and reasoning for the suggestion. The references offer specific examples and arguments, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It points out that the average of kmeans objectives with multiple seeds is used as a baseline, and it proposes using the minimal kmeans objective over multiple seeds as a more reasonable baseline. This suggestion is supported by references to relevant literature, which adds credibility to the feedback. By offering a concrete alternative and providing references, the comment empowers the authors to make a meaningful improvement to their draft. However, it could be more helpful if it explained why the minimal kmeans objective is a better choice or how it might impact the results. Overall, the comment is 4, as it provides clear guidance for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It suggests that the authors clarify this point by explaining the role of H in uncertainty calibration and how it relates to temperature calibration. Additionally, it points out a potential contradiction in the paper regarding the effect of reducing entropy, which is against the paper\"s motivation to calibrate networks. While the comment identifies specific areas for clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the relationship between uncertainty and temperature calibration and reconcile the contradiction regarding entropy reduction. However, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relationship between uncertainty and temperature calibration, particularly regarding the regularization term H. The comment further clarifies the confusion by pointing out a potential contradiction in the paper regarding the effect of reducing entropy. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. The reviewer provides a detailed explanation of the apparent contradiction, referencing specific lines in the paper (155160) to support their claim. This level of detail and logical reasoning makes the claim 4, as it provides a clear basis for the authors to address the issue. However, the comment could be strengthened by including references to relevant literature or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It points out a contradiction in the paper, noting that the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. The comment also highlights a contradiction in the paper\"s motivation, where reducing entropy is against the goal of calibrating networks. This feedback is clear and actionable, as it prompts the authors to clarify the relationship between these concepts and reconcile any contradictions in their work. By addressing these points, the authors can improve the clarity and coherence of their paper. Therefore, the comment is rated as 4, as it provides specific guidance for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the importance of including a reference to the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, and place itself in an appropriate context. While the comment implies that the authors should include this reference and discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate the reference or discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of unrolling, which is closely related to the paper\"s topic. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the importance of referencing the work of Yann LeCun, \"Lista,\" and suggests that the paper should discuss the similarities and differences between the proposed work and Lista. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically mentioning the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. The reviewer suggests that the paper should discuss the similarities and differences between the proposed work and Lista, and place itself in an appropriate context. This claim is 4 as it provides a specific reference to the work of Yann LeCun, which supports the assertion that the paper is related to the idea of unrolling. However, the comment could be strengthened by providing more detailed reasoning or examples of how the paper should discuss the similarities and differences with Lista. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper by pointing out the importance of referencing the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It highlights the need for the paper to discuss the similarities and differences between the proposed work and Lista, and to place itself in an appropriate context. This feedback is clear and actionable, as it provides a specific reference and a clear direction for the authors to enhance the context and relevance of their work. By addressing this point, the authors can improve the comprehensiveness and credibility of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined, providing a clear and direct action for the authors to take. The comment specifies exactly what needs to be addressed, which is the definition of the FLOT cost matrix in Algorithm 1. This makes the action 5, as the authors know precisely what step to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of definition for the FLOT cost matrix. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that the FLOT cost matrix in Algorithm 1 is not defined. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with the paper: the FLOT cost matrix in Algorithm 1 is not defined. This feedback is actionable as it identifies a clear gap in the paper that needs to be addressed. By specifying the exact element that is missing, the comment provides the authors with a concrete step to take to improve their draft. However, it could be more helpful if it suggested how the authors might define the FLOT cost matrix or provided examples of similar definitions in related work. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or suggest alternative terminology. The action is explicit but lacks concrete details on how to implement the change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"connectivity,\" explaining that it does not refer to structural connections between the brain and body. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity\" used in the paper, pointing out that it does not accurately reflect the structural connections between the brain and body. This feedback is 3 as it highlights a potential misinterpretation or confusion in the paper. However, the comment lacks depth and does not provide suggestions for alternative terminology or how to address this issue in the context of the paper. To be more helpful, the comment could include recommendations or guidance on how to clarify the term or its usage. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers to another section for more details, but this does not provide actionable advice within the current context. As a result, the authors are left without clear direction on how to improve their draft. Since the comment lacks explicit or implicit actions and is vague, it is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are lacking in detail or provide examples of what is missing. Additionally, it does not mention specific sections or elements of the paper, making it difficult for the authors to pinpoint the exact areas needing improvement. The reference to \"Clarity, Quality, Novelty And Reproducibility\" does not provide sufficient guidance for the authors to address the issues effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The reference to \"Clarity, Quality, Novelty And Reproducibility\" does not offer additional context or evidence to substantiate the claim. Without specific examples or detailed justification, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed feedback on what aspects are missing or how they could be improved. The reference to \"Clarity, Quality, Novelty And Reproducibility\" suggests that more detailed information can be found in those sections, but this does not offer actionable guidance within the current context. As a result, the comment is 3 as it identifies areas for improvement but lacks depth and specificity, leaving the authors with limited direction for enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also suggests that the authors should explain their decision to pad the shorter sequence by replicating its last state and the lack of a normalization factor of 1/T, which can affect the distance calculation. The comment provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the equation, namely the handling of comparisons between episodes with different lengths and the lack of a normalization factor, which can affect the distance calculation. The comment also provides a suggestion for how the authors could address this issue by explaining their decision to pad the shorter sequence and the impact of the normalization factor. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the equation between lines 282 and 283, specifically regarding the handling of comparisons between episodes with different lengths. The reviewer provides a detailed explanation of how the authors pad the shorter sequence by replicating its last state and the impact of this decision on the distance calculation. The comment also highlights the lack of a normalization factor, which can affect the distance calculation and favor longer trajectories. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific literature or studies that support the claim about the impact of normalization on distance calculations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the equation between lines 282 and 283, where the authors should clarify how they handle comparisons between episodes with different lengths. It provides a detailed explanation of the issue, noting that the authors pad the shorter sequence by replicating its last state and that this decision can affect the distance calculation. The comment also points out the lack of a normalization factor, which can impact the distance calculation and favor longer trajectories. This feedback is clear and actionable, as it guides the authors on what aspects of their methodology need further explanation and justification. By addressing these points, the authors can enhance the clarity and transparency of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention a specific detail regarding the preprocessing and evaluation in SI 6.5. It provides clear guidance on what needs to be added to the draft, making the action concrete and direct. The authors know exactly what to do to address the comment, ensuring a high level of actionability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the preprocessing and evaluation, which is different from Mnih et al. [7]. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should mention a specific difference in preprocessing and evaluation compared to Mnih et al. [7]. However, it does not provide any further explanation or evidence to support why this difference is significant or how it impacts the evaluation. The comment lacks detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to include a mention of a difference in preprocessing and evaluation compared to Mnih et al. [7]. By pointing out this detail, the comment helps the authors clarify and improve the transparency of their work. However, the comment could be more helpful if it explained why this difference is important or how it affects the evaluation. Despite this, the feedback is clear and actionable, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what metrics should be included or how to measure efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should include metrics to demonstrate efficiency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. However, it does not specify which part of the paper discusses the advantages over previous work, making it weakly grounded. The comment is specific in pointing out the absence of efficiency metrics, which is a clear indication of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method compared to previous work. However, it does not provide specific examples of what metrics should be included or how the current metrics are insufficient. This lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific metrics needed to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. This is a critical observation that highlights a potential weakness in the paper\"s claims about its advantages. However, the comment does not provide specific suggestions or guidance on which metrics should be included or how to measure efficiency. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests more details on the statespace, actions, and the space in which theta lies. It suggests that the authors should be precise in their descriptions rather than leaving the reader to guess. This feedback provides a clear and direct action for the authors to take, which is to provide more detailed information in the draft. The comment is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more details about the statespace, actions, and the space in which theta lies. The comment provides a clear direction for improvement by suggesting that the authors should be precise in their descriptions rather than leaving the reader to guess. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the nature of the statespace, actions, and the space in which theta lies. The reviewer suggests that these details should be provided for clarity. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the details about the statespace, actions, and the space in which theta lies. It suggests that the authors should provide more precise information to avoid leaving the reader to guess. This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their descriptions. By addressing these points, the authors can improve the comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to present these details or why they are important. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. While the comment implies a change in the choice of downstream task, it does not provide explicit guidance on how to implement this change or why LiDARbased segmentation is the preferred choice. The authors can infer that they should consider this suggestion, but the lack of concrete details or rationale makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. However, it does not specify which part of the paper discusses the choice of downstream task, making it weakly grounded. The comment is specific in its suggestion to use LiDARbased segmentation and provides a rationale for why it is a better choice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task compared to object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. The claim is 3 as it provides a logical reasoning for the preference of LiDARbased segmentation, particularly in the context of benchmark metrics. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. This feedback is 3 as it provides a specific suggestion for improvement, offering a potential alternative approach that could enhance the paper\"s results. However, the comment lacks detailed reasoning or examples to fully support the claim that LiDARbased segmentation is the best choice, which would make it more actionable. Additionally, it does not address other aspects of the paper, such as the methodology or results, limiting its overall helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm 1, specifically regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. While the comment identifies a specific issue, it does not provide explicit guidance on how to address this confusion or suggest alternative terminology or explanations. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation or terminology, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of potential confusion regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be addressed to improve the clarity of the algorithm description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about potential confusion in the notation used in Algorithm 1. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically regarding the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their notation or terminology to improve the clarity and understanding of their algorithm. However, the comment could be more helpful if it provided suggestions on how to resolve this confusion, such as recommending alternative notation or explaining the distinction between the two uses of $p$. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not specify which specific tasks should be included or how they would contribute to the paper. The action is implicit and lacks concrete details, making it somewhat vague. The authors can infer that they should consider adding more benchmarking tasks, but without specific guidance, it may be challenging to determine which tasks to include and how to integrate them into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine whether this suggestion relates to the methodology, results, or discussion sections. Additionally, the comment lacks specificity regarding which additional benchmarking tasks should be included or why they are necessary. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, the comment does not provide any reasoning, examples, or references to support why these additional tasks are necessary or how they would enhance the paper. Without such evidence or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific tasks should be included or how they might enhance the paper. The feedback is 3 as it points out a direction for expansion, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a confusion in the reference to \"PointNet\" in Figure 1, noting that this name does not appear anywhere in the paper and that there exists another paper with the same name. The reviewer provides a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is clear and actionable, as it directs the authors to correct the reference to avoid confusion and ensure accurate attribution. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a suggestion to correct it by referencing the original paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear anywhere in the paper and there exists another paper with the same name. The reviewer supports this claim by providing a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This detailed reference and explanation provide a clear basis for the claim, making it 5. The authors can easily understand and address the issue by correcting the reference to avoid confusion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that the name does not appear anywhere in the paper and that there exists another paper with the same name. It provides a clear and actionable suggestion by referencing the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is valuable as it helps the authors correct the reference, ensuring accurate attribution and avoiding confusion for readers. The comment is detailed and provides a specific solution, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the policy gradient in Equation 6 and its relationship to the optimal solution in Equation 5. It suggests that the authors clarify these points to ensure clarity. Additionally, it points out a minor grammatical error in Line 78 and a potential typo in Line 132. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address the questions or correct the errors. The actions are explicit but somewhat vague, as the authors know what needs to be clarified but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. 6 and Eq. 5) and lines (78 and 132), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the policy gradient and its relationship to the optimal solution, suggesting that clarification is needed. Additionally, it points out a minor grammatical error and a potential typo, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, such as clarifying the relationship between equations and correcting grammatical errors. These are factual statements or requests for clarification, not claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several specific questions and points out potential areas for clarification. It questions the relationship between the policy gradient in Equation 6 and the optimal solution in Equation 5, suggesting that the authors clarify this connection. Additionally, it identifies a minor grammatical error and a potential typo, which could be easily corrected. While the comment provides valuable feedback on areas that need clarification, it does not offer detailed suggestions or guidance on how to address these issues. The feedback is 3 as it directs the authors\" attention to specific areas that require clarification, but it could be more comprehensive with additional guidance on how to improve the clarity of the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two distributions. While the comment implies that the authors should consider this assumption, it does not explicitly instruct them to do so or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors can infer that they should consider the assumption but are not given specific instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the difference between the two distributions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It seeks clarification on the difference between the two distributions, which could be relevant for the authors to consider in their work. While the comment identifies a potential area for improvement or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider an alternative assumption, but it could be more beneficial with additional detail or actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, which is a risky choice that makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to address the limitations of this approach. The comment is explicit and concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment further suggests that the authors should discuss the limitations of this approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is risky or what specific assumptions are being made. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the choice to freeze the partitioning in the first iteration. It points out that this approach makes strong assumptions about the coverage of the initial data, which could be a risky choice. The comment suggests that the authors should discuss the limitations of this approach, providing a clear and actionable piece of feedback. By addressing this concern, the authors can enhance the robustness and transparency of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to discuss these limitations or alternative approaches to consider. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the decision to use early stopping based only on link prediction accuracy should be explained. It questions why not averaging with type accuracy, providing a specific example for consideration. This feedback is clear and actionable, as it directs the authors to explain their reasoning behind this choice. The comment offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use early stopping only by link prediction accuracy and suggests an alternative approach by questioning why not averaging with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping based only on link prediction accuracy and suggests considering an average with type accuracy. However, it does not provide any reasoning or evidence to support why this alternative approach would be beneficial or how it might improve the results. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the decision to use early stopping based only on link prediction accuracy. It suggests that this choice should be explained, potentially by considering an average with type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their methodological choice, which could enhance the clarity and justification of their approach. However, the comment could be more helpful if it offered additional context or examples on why averaging with type accuracy might be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. While the comment highlights a gap in the explanation, it does not provide explicit guidance on what additional information should be included or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the pruning process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detailed explanation on how the ground truth of sensitivity is achieved, particularly regarding the process of pruning. The comment provides a clear direction for the authors to improve their draft by detailing the pruning process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detailed explanation, namely the process of achieving the ground truth of sensitivity. It points out that the authors mention \"pruning\" but do not provide details on how this is done. This feedback is clear and actionable, as it directs the authors to include more detailed information on the methodology used to estimate sensitivity. However, the comment could be more helpful if it suggested specific aspects of the pruning process that need to be explained or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which is similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. However, the comment does not provide explicit guidance or suggestions for the authors to improve their approach or address the critique. It lacks actionable details, such as recommending alternative methods or suggesting ways to enhance the universality of the approach. As a result, the authors are left without a clear understanding of how to address the feedback, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which is similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, while it provides some specific details about the critique, it lacks detailed guidance on how to address the issues raised. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which is similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. While the comment provides a logical reasoning for the critique, it lacks specific examples or references to support the claim about the limitations of the proposed approach. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which is similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. While the comment identifies a potential limitation of the approach, it lacks actionable suggestions or guidance on how the authors might address this critique or improve their work. The feedback is 3 as it points out a weakness, but it does not provide specific advice or direction for improvement, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit feedback on specific sections of the paper, indicating that the reviewer has difficulty understanding the content and suggests that the authors clarify their explanations. The comment explicitly states that the paragraph from lines 156 to 166 is unclear and that the figure is hard to understand. It also provides a concrete suggestion to clarify the explanation of the dashed lines in the figure. This feedback is clear and actionable, as it directs the authors to specific parts of the paper that need improvement and offers a concrete way to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (L156166) that are unclear, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the paragraph, noting that the reviewer has difficulty understanding it and suggesting that the authors clarify their explanation. Additionally, the comment provides specific feedback on the figure, stating that the dashed lines are too vague to be understood concretely. This level of detail and specificity helps the authors understand what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph from lines 156 to 166 is unclear and that the figure is hard to understand. The reviewer provides specific examples, such as the difficulty in understanding the dashed lines in the figure, which helps to substantiate the claim. However, the comment lacks detailed reasoning or references to support why the paragraph is unclear or how the figure could be improved. While the examples provide some basis for the claim, the lack of comprehensive explanation or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct issues: the clarity of a particular paragraph (lines 156166) and the understanding of a figure. It identifies the difficulty in understanding the paragraph, suggesting that the authors clarify their explanation. Additionally, it points out that the figure is hard to understand due to vague explanations, such as the dashed lines indicating planning ahead. This feedback is clear and actionable, as it directs the authors to specific parts of the paper that need improvement and offers concrete suggestions on how to enhance clarity. By addressing these issues, the authors can significantly improve the readability and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific guidance on how the authors should address this issue or what actions they should take to improve the applicability of their approach. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds or where the authors should focus their attention to address this issue. The comment lacks grounding as it does not mention specific sections, figures, or tables, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while it raises a concern about the applicability of the approach, it does not provide specific guidance on how to address this limitation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific examples or references to support this claim, nor does it explain how these improvements would limit the applications of the approach. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific guidance or suggestions on how the authors might address this issue or its implications for the applicability of their approach. The comment lacks actionable feedback or detailed insights that could help the authors improve their draft. As a result, it is 1, as it does not offer any direction for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question, whether it should be explored further in the paper, or how it might impact the results or conclusions. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on videos of different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP\"s performance on differentlength videos are of interest or how this might impact the paper. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the performance of DVP on videos of different lengths. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on videos of different lengths. However, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks specificity and does not offer any guidance on how the authors might explore or incorporate this aspect into their work. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the target or improve the clarity of the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not specify which part of the paper lacks this clarification, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of clarity regarding the target of the paper, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the target of the paper, whether it focuses on singletoken or multitoken cloze queries. It notes that a clear clarification is not provided until the conclusion, which is a relevant observation. However, the comment does not provide any suggestions or guidance on how the authors might clarify this aspect of their work. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights an issue but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, it does not provide explicit guidance on how the authors should address these issues or improve the connection between the sections. The comment implies that the authors should enhance the theoretical analysis and its connection to the methodology, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited connection with the methodology section and the simplistic nature of the theoretical analysis, which is closely related to a specific reference, [1]. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, the comment does not provide any further explanation or examples to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or specific examples makes the claim 1, as the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of connection between Section 2 and the methodology section, and the simplistic nature of the theoretical analysis, which is closely related to a specific reference. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out weaknesses, but it lacks actionable advice or examples to help the authors make meaningful improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. While the comment implies that the authors should provide additional discussion or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the situations where the losses are beneficial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion would be beneficial or how it could enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. This feedback provides a clear direction for the authors to enhance their paper by offering a specific area for additional discussion or analysis. However, the comment could be more helpful if it included suggestions on how to approach this discussion or what aspects to focus on. Despite this, the feedback is actionable and encourages the authors to expand their work, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that Algorithm 2 does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. It also mentions that the answer is not found in reference [30]. This feedback provides clear and direct actions for the authors to take: they need to clarify how n_t is determined and explain the meaning of \"appropriate number\" in line 225. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of determining n_t and the meaning of \"appropriate number\" in line 225, and it references a specific reference [30] where the answer is not found. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of Algorithm 2 by pointing out that it does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. The reviewer also mentions that the answer is not found in reference [30]. This provides a clear and specific critique, but it lacks additional context or references to fully substantiate the claim. The authors would need to address these points to clarify the algorithm, but the comment itself does not provide detailed reasoning or evidence to fully support the claim. Therefore, the comment is 3, as it highlights areas for improvement but requires further elaboration from the authors.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. It also mentions that the answer is not found in reference [30]. This feedback is clear and actionable, as it directs the authors to clarify these aspects of their algorithm, which is crucial for the paper\"s comprehensibility and reproducibility. By addressing these points, the authors can significantly improve the clarity and transparency of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. While the comment implies that the authors should make their code publicly available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make their code accessible. However, the comment does provide a clear direction on what needs to be done to address the issue of reproducibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where reproducibility is an issue. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its request for code availability but lacks grounding, as it does not clearly indicate where this issue arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. This is a factual statement without any subjective claims or opinions, as it does not express an opinion, judgment, or suggestion. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results, which is an important issue for the authors to address. It also asks whether the code will be made publicly available, which is a relevant question for transparency and reproducibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address the issue of reproducibility or make their code available. While it identifies a critical area for improvement, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claims about the mixing time being \"even better\" in practice, stating that the evidence provided is insufficient and limits the usefulness for practitioners. However, it does not provide explicit guidance or suggestions on how the authors could improve the evidence or support for these claims. The comment lacks actionable details, such as recommending specific experiments or analyses that could strengthen the evidence. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claims about the mixing time being \"even better\" in practice, suggesting that the evidence provided is insufficient. However, it does not specify which part of the paper these claims are made in, nor does it provide details on what specific aspects of the evidence are lacking. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need revision. This lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evidence supporting the claim that \"in practice the mixing time is even better\" is insufficient. However, it does not provide specific examples or detailed reasoning to support this claim. The lack of concrete evidence or references makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of sufficient evidence to support the claim that \"in practice the mixing time is even better.\" This critique highlights a critical weakness in the paper, as the evidence provided is limited, which could impact the usefulness of the findings for practitioners. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the evidence. While it points out a crucial area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides insight into a key weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not provide explicit guidance on how to implement this suggestion or what specific attributes should be included in the vector form. The action is implicit and somewhat vague, as the authors are left to infer the details of the proposed change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the protected feature is discussed. Without explicit references or context, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the protected feature should be included in the vector form or how this extension would benefit the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or how it might improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. This feedback provides a potential direction for improvement by suggesting a more comprehensive representation of the protected feature. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what specific attributes should be included in the vector form. While it identifies a potential area for enhancement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and actionable steps."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. It lacks explicit instructions or concrete details on what the authors should do to enhance the novelty of their approach. As a result, the comment is vague and does not offer actionable advice, making it 1.", "grounding_specificity_rationale": "The comment suggests that the proposed transductive method is not very novel, as it is related to a common way to incorporate unlabeled data in semisupervised methods. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology discussion. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while the comment provides some insight into the potential lack of novelty, it does not specify what aspects of the method are not novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. It does not offer actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of how to address the perceived lack of novelty. As a result, the comment is 1, as it does not provide meaningful guidance for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not provide explicit guidance on how to address this issue or suggest which specific features should be compared or how to incorporate the missing papers. The action is implicit, as the authors can infer that they need to expand the feature comparison to include these papers, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is presented in, nor does it provide details on which specific features are missing or how the comparison could be improved. This lack of specificity and grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the feature comparison in the paper is shallow and missing two relevant papers. However, it does not provide any specific examples or references to these missing papers, nor does it explain why the current comparison is insufficient. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. This feedback is 3 as it points out a gap in the analysis that the authors need to address. However, the comment lacks detailed guidance on how to incorporate these missing papers or what specific features should be compared. Without more detailed suggestions, the authors may struggle to fully understand and implement the necessary improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use the word \"equivalent\" more cautiously, particularly if the equivalence is not verified. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the draft. The comment provides a concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8, 56, 70, and 93) where the word \"equivalent\" is used. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" particularly if the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the usage of the word \"equivalent\" should be more cautious, especially if the equivalence is not verified. However, the comment does not provide any specific examples or reasoning to support why this caution is necessary. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the recommendation.", "helpfulness_rationale": "The review comment identifies specific instances where the word \"equivalent\" is used and suggests that its usage should be more cautious, particularly if the equivalence is not verified. This feedback is clear and actionable, as it directs the authors to be more precise in their language and to provide evidence or verification for any claims of equivalence. However, the comment could be more helpful if it provided examples of how the authors might address this issue or suggested alternative language to use. Overall, the comment is 4 as it points out a potential area for improvement and offers a specific direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer suggests that a more detailed analysis of the differences and similarities between these views is needed to draw solid conclusions. While the comment implies that the authors should conduct a more thorough analysis, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of the other views and suggesting that a more detailed analysis is needed to understand the differences and similarities between these views. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach, specifically the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but notes that there is no further analysis of how these views differ. This suggests that the claim is based on a lack of detailed analysis, which is a valid observation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to conduct additional analysis to address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the effectiveness of the multiview clustering approach, particularly questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. It highlights the need for a more detailed analysis of the differences and similarities between these views to draw solid conclusions about their usefulness. The comment provides a clear direction for the authors to improve their draft by suggesting a more comprehensive analysis of the different views. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and guides the authors toward a more thorough evaluation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that consistency should be maintained. This provides a clear and direct action for the authors to take, which is to ensure that these terms are consistently typeset across the paper. The comment is specific and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore and BLEURT,\" allowing the authors to accurately identify the parts of the paper where these terms are inconsistently typeset. It also specifies the issue by suggesting that consistency should be maintained, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistent typesetting of \"BertScore\" and \"BLEURT\" throughout the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the terms \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper. This feedback is clear and actionable, as it provides a straightforward suggestion to maintain consistency in the typesetting of these terms. By addressing this issue, the authors can improve the professionalism and clarity of their paper. However, the comment could be more helpful if it provided additional context or explained why consistency is important. Overall, the feedback is 4, as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what aspect of Greek is problematic or how it relates to the paper\"s content. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a request for information, asking if other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a question seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. While it raises an intriguing question, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this issue. The comment does not offer guidance on how the authors might investigate or resolve the potential problem with Greek, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not provide any actionable insights or direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes the above point unclear and difficult for readers to understand. It suggests that the results are acceptable, but it does not provide specific guidance on how to clarify the text or improve its clarity. The action is implicit, as the authors need to infer that they should revise the text to make it clearer. Additionally, the comment lacks concrete details on how to achieve this clarity, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (293295) where the issue is identified, allowing the authors to accurately pinpoint the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, namely that it makes the point unclear and difficult for readers to understand. The comment provides a clear direction for improvement by suggesting that the results should be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point unclear and difficult for readers to understand. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or explanation, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, suggesting that it makes the point unclear and difficult for readers to understand. This feedback is 3 as it points out a potential area for improvement, allowing the authors to revise their draft to enhance clarity. However, the comment lacks detailed guidance or suggestions on how to improve the clarity, such as proposing alternative phrasing or additional explanations. While it provides some direction, it could be more helpful with more specific feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It specifically mentions Lemma 3 and questions whether the result holds for any polynomial function. This feedback provides a clear and explicit action for the authors to improve the organization and clarity of their proofs, as well as to address the specific concern about Lemma 3. The comment is 5 as it identifies a specific area for improvement and provides a concrete question to consider, giving the authors clear guidance on how to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of poor organization and clarity in the proofs, providing a concrete example with the question about Lemma 3. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the proof is not well organized and difficult to follow, providing a specific example with Lemma 3. The reviewer questions whether the result holds for any polynomial function, which is a logical and relevant concern. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the overall organization and clarity of the proofs. While it provides a specific question, it does not offer a comprehensive analysis or evidence to support the broader claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It provides a specific example by questioning whether the result in Lemma 3 holds for any polynomial function. This feedback is clear and actionable, as it highlights a specific area for improvement and prompts the authors to reconsider the organization and logic of their proofs. By addressing these issues, the authors can enhance the rigor and clarity of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This is an explicit suggestion that provides a clear action for the authors to take. However, the comment does not specify which realworld datasets should be used or how to conduct the experiments, leaving some room for ambiguity. While the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of realworld datasets, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This claim is based on the premise that the paper claims to address realistic scenarios, which is a logical reasoning. However, the comment lacks specific examples or references to support why realworld datasets are more appropriate or how they would better address the claim of disentangled representation learning. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by addressing a potential limitation in the experimental setup. However, the comment could be more helpful if it offered examples of realworld datasets that would be suitable for the study or provided additional context on why this change would enhance the paper\"s claims. Despite this, the comment is 4 as it guides the authors toward a meaningful improvement in their experimental design."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide explicit guidance on how to clarify these explanations or what specific aspects need to be addressed. The comment consists of questions and comments, but without actionable suggestions, the authors are left to infer what needs to be done. The lack of concrete details and explicit instructions makes the comment vague and 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations in this section are vague, providing a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the vagueness. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where explanations are deemed vague, pointing out the last paragraph of Section 3 (lines 207210) on the single image case. This feedback is 3 as it directs the authors\" attention to a particular section that may need clarification. However, the comment lacks detailed guidance or suggestions on how to improve the clarity of the explanations, leaving the authors with a general direction but no concrete steps to take. To be more helpful, the comment could include specific questions or examples to help the authors understand what aspects of the explanation are unclear. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limited scope of the study, which only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. While the comment implies that the authors should consider expanding their study to a more complex setting, it does not provide explicit guidance on how to do so or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors can infer that they should consider a more complex scenario but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the limited scope of the study, which only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in pointing out the need for a more complex setting, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the scope of the study, noting that it only considers one truck and one drone. The reviewer suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment lacks specific reasoning or evidence to support why this extension would be beneficial or necessary. It does not provide examples or references to justify the claim that multiple trucks and drones would be more interesting or practical. As a result, the claim is 3, as it raises a valid point but lacks sufficient justification or evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment points out a limitation in the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might go about expanding the study to multiple scenarios. The feedback is 3 as it highlights a direction for further exploration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential confusion regarding the number of biases and kernels in the model. It suggests that the resulting volume should be WxHx1 and the bias should be a scalar, but the authors have only found a hyperparameter for feedforward models in section 3.4. The comment implies that the authors should clarify this aspect of their model, but it does not provide explicit instructions on how to do so. While the action is implicit, it is 3 as it points out a specific area for clarification. However, the lack of concrete guidance on how to address the issue limits the actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the number of biases and kernels in the model, suggesting that the resulting volume should be WxHx1 and the bias should be a scalar. The comment clarifies that the authors have only found a hyperparameter for feedforward models in section 3.4, which is confusing. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the resulting volume should be WxHx1 and the bias should be a scalar, suggesting that the authors have only found a hyperparameter for feedforward models in section 3.4. The comment provides a logical reasoning for the claim, explaining that the authors most likely want multiple kernels and biases, which is not consistent with the current description. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concern.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the number of biases and kernels in the model. It suggests that the resulting volume should be WxHx1 and the bias should be a scalar, but the authors have only found a hyperparameter for feedforward models in section 3.4. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their model architecture. By addressing this issue, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to resolve the confusion or suggested specific ways to clarify the model description. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it implies that the authors should investigate these aspects, it does not provide explicit instructions or concrete suggestions on how to address these questions. The authors can infer that they need to conduct additional analyses or experiments to explore these relationships, but the comment lacks specific guidance on how to proceed. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. However, it does not specify which part of the paper these questions pertain to, such as specific sections, figures, or tables. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in its inquiry about the effects of MC samples and network structure, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples and the network structure on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek information that would help the authors improve their draft. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. By asking for empirical evidence on how these factors affect performance, the comment prompts the authors to consider these aspects in their analysis. This feedback is 3 as it directs the authors to explore additional aspects of their work that could enhance its comprehensiveness and robustness. However, the comment lacks specific suggestions or guidance on how to address these questions, which would make it more actionable. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as whether the smoothed GT shapes should be added as an overlay or as a separate figure. The comment also mentions a \"minor concern,\" but this is not elaborated upon, leaving the authors uncertain about its significance. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in suggesting a particular change to improve the clarity of the figures, but without explicit references to the figures, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a request for clarification or enhancement, not a claim or opinion that requires verification. It is a factual statement that does not need justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests a specific improvement to the figures by recommending the inclusion of smoothed GT shapes in Figures 3 and 5. This suggestion is clear and actionable, as it provides a concrete way for the authors to enhance the clarity and understanding of their results. By showing the smoothed GT shapes, the authors can better demonstrate the quality of the reconstruction, which is a valuable addition to the figures. However, the comment does not elaborate on why this suggestion is important or how it would impact the overall understanding of the paper. While it offers a specific improvement, it could be more helpful with additional context or explanation. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, specifically in terms of test accuracy. It suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline. The comment implies that the authors should include direct comparisons to demonstrate the effectiveness of their approach. However, it does not provide specific guidance on how to conduct these comparisons or what metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to add comparisons but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, which is a clear and specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach lacks direct comparisons with the prior approach PRANC, specifically in terms of test accuracy. The reviewer points out that while there are comparisons of training loss and the rank of possible solutions, a direct comparison of test accuracy is missing. This claim is 3 as it highlights a gap in the evaluation process, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to consider the implications of this gap and address it in their revisions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons with the prior approach PRANC in terms of test accuracy. It highlights that while there are comparisons of training loss and the rank of possible solutions, the absence of a direct comparison of test accuracy makes it unclear whether the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it points out a critical area for improvement and suggests that the authors should include direct comparisons to demonstrate the effectiveness of their approach. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to focus on. Overall, the comment is 4, as it directs the authors to a key area for enhancing their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The comment implies that the authors should investigate the hyperparameter tuning process and the distance to the next best model, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some specificity by suggesting that the authors should investigate the hyperparameter tuning process and the distance to the next best model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for concern but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. This feedback is 3 as it points out a potential issue with the hyperparameter tuning process, which could impact the reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their methodology. To be more helpful, the comment could include recommendations on how to validate the hyperparameter choices or suggest alternative approaches to ensure the results are not biased. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or improved. The authors can infer that they need to provide more detailed information about the corpora and datasets used in the experiments, but the comment lacks concrete suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment mentions \"some aspects of the experimental setup\" as being unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in identifying the issue with corpora and datasets, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. This feedback is 3 as it points out a potential area for improvement, prompting the authors to clarify and motivate their experimental choices. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as specific questions to consider or examples of how to improve the clarity. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This feedback implies that the authors should provide more detailed information about the model\"s size, which is an implicit action. However, the comment does not specify how the authors should present this information, such as through a table or a detailed description. While the action is clear, the lack of concrete guidance on how to present the information makes the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This provides a clear indication of what needs to be addressed, namely the size of the model and its components. However, the comment does not explicitly mention which part of the paper this information should be included in, such as the methodology or results sections. While the authors can infer that it relates to the methodology or model description, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what is missing, so it is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This is a request for clarification or additional information, which does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This feedback is valuable as it highlights a gap in the paper that could be addressed to provide a more comprehensive understanding of the model\"s architecture and its relationship to other approaches. However, the comment could be more helpful if it suggested ways to present this information, such as through a table or a detailed description. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their work. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also mentions that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. While the authors might infer that it relates to the theoretical sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in its critique of the metric learning theory, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It also suggests that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specific references or detailed reasoning to support these claims. Without explicit evidence or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also claims that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address these issues or enhance their work. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. While the comment implies that the authors should move visual results and condense figures, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit and lacks direct guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. The comment is fully grounded as it explicitly mentions the lack of visual results in the main paper and suggests specific changes, such as condensing figures. It is also specific because it provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. The comment provides a logical reasoning for this suggestion, noting that the current paper lacks visual results despite having figures for the proposed network architecture. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the need for these visual results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of visual results from the supplementary material into the main paper. It specifically points out the lack of visual results on crowd density estimation, which is the main experiment, and suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. This feedback is valuable as it directly addresses a gap in the paper and offers a concrete way to enhance its content. However, the comment could be more helpful if it provided specific examples of which visual results to include or how to condense the figures effectively. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in the presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of dataset, specifically the WebQuestionsSP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for why the authors should consider using the more popular WebQuestions benchmark set instead, explaining that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, facilitating direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. The reviewer provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This reasoning is logical and provides a clear basis for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific studies or examples that support the claim about the advantages of using WebQuestions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This feedback is clear and actionable, as it offers a specific alternative dataset that could enhance the paper\"s relevance and comparability. However, the comment could be more helpful if it included additional guidance on how to integrate the suggested dataset or addressed potential challenges in doing so. Overall, the comment is 4, as it provides a valuable suggestion for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. While the comment implies that the authors should provide evidence for their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to demonstrate the benefits or what evidence is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the need for certain claims regarding sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in its critique of the claims and suggests that the authors should provide evidence for their assertions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. However, the comment lacks specific examples or references to support the claim that sparsity is not desirable or that the benefits are not significant. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the necessity of certain claims made in the paper regarding the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or provide the necessary evidence. The feedback is 3 as it prompts the authors to consider the validity of their claims and potentially explore alternative metrics or demonstrations, but it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the paper should include analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives. It provides a clear and concrete action for the authors to take, which is to present results on these datasets in the main paper. The comment specifies what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives. It provides a clear direction for improvement by suggesting that results on ImageNet1k or ImageNet100 should be included in the main paper. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or results section. While the authors can infer that it relates to the results or discussion sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically suggesting the inclusion of results on ImageNet derivatives. The comment provides a logical reasoning by stating that verifying the effectiveness of the framework on larger datasets is important for a comprehensive evaluation. However, it does not provide specific examples or references to support the claim that ImageNet1k or ImageNet100 are particularly relevant or necessary for evaluation. This lack of detailed justification or references makes the claim 3, as it provides a general direction but lacks specific evidence or examples to fully substantiate the need for these datasets. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that while it shows improvements on CIFAR derivatives, it lacks analysis or results on other datasets, particularly ImageNet derivatives. The comment provides a clear and actionable suggestion by recommending that the authors present results on ImageNet1k or ImageNet100 in the main paper. This feedback is valuable as it directs the authors to expand their evaluation to a more comprehensive dataset, which can enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided additional context or rationale for why these datasets are important or how they might impact the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consistently refer to BigFive and MBTI as datasets throughout the paper, rather than treating them as models to be extended. The comment provides a clear and explicit action for the authors to take, specifying that they should either consistently refer to them as datasets or provide an extended explanation for why they are addressing them differently. This feedback is concrete and direct, giving the authors a clear understanding of what needs to be changed in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in referring to BigFive and MBTI as models in the abstract and introduction, while they are used as datasets in the experiments. The comment provides a clear suggestion to either consistently refer to them as datasets or provide an extended explanation for the different treatment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that BigFive and MBTI are inconsistently referred to as models in the abstract and introduction, while they are used as datasets in the experiments. The reviewer provides a clear and logical reasoning for this inconsistency, suggesting that the authors should either consistently refer to them as datasets or provide an extended explanation for their different treatment. This reasoning is based on a logical expectation for consistency in terminology and provides a clear direction for the authors to address the issue. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper, noting that BigFive and MBTI are referred to as models to be extended in the abstract and introduction, while they are used as mere datasets in the experiments. The reviewer suggests that the authors should either consistently refer to them as datasets or provide an extended explanation for their different treatment. This feedback is clear and actionable, as it points out a potential confusion in the paper and offers a straightforward solution. By addressing this inconsistency, the authors can improve the clarity and consistency of their work. Therefore, the comment is rated as 4, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential limitation in the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of different methods or features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the dataset analysis or methodology sections, but this inference is not direct. The comment is specific in detailing the potential dependency on the method or features used, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this depends on the method or features used for answer detection, such as POS/dependency parse features. The comment provides a logical reasoning by pointing out a potential dependency on the method used, which is a valid critique. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore this aspect to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it points out a specific area where the authors might need to consider the impact of their methodology on their findings. However, the comment does not provide detailed guidance on how to address this issue or suggest alternative methods or features to explore. While it highlights a potential weakness, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or what specific changes should be made to address the issues with the related work section. The action is implicit and somewhat vague, as the authors are left to infer what specific improvements are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the writing quality, suggesting that the authors should improve it. It mentions specific issues, such as the authors spending the same space on explaining basic memory networks and then the forward model, and the missing pieces in the related work section regarding more reinforcement learning tasks in the literature. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as improving the writing quality and expanding the related work section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references makes the claim 3, as it requires more information to be fully actionable.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and then the forward model, suggesting that this could be improved by focusing on more relevant content. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature, which is an important area for the paper to address. However, the comment does not provide detailed suggestions or examples on how to improve the writing quality or what specific tasks should be included in the related work section. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the replacement of the first column of Qo with vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or which assumption should be revised. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise the assumptions, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo with vo, which results in the first state becoming unreachable but from a terminating state. The comment further assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a state) is violated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the replacement of the first column of Qo with vo, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a state) is violated. However, the comment lacks specific reasoning or examples to support this assumption, making it difficult for the authors to understand the basis of the claim. The lack of detailed explanation or references to relevant literature or previous work makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the replacement of the first column of Qo with vo, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a state) is violated. While the comment highlights a specific concern, it lacks detailed guidance or suggestions on how the authors might address this issue or clarify the assumptions. The feedback is 3 as it points out a potential problem, but it does not provide actionable steps for improvement, leaving the authors with a general direction but no clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of how this could be done, such as examining whether the sequential relationship is easier to model with a recurrent model. This feedback is explicit and provides concrete guidance on what the authors should explore, making it 5.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should explore, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. The comment provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This reasoning is logical and provides a clear direction for the authors to explore, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to support the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This feedback is actionable and offers a clear direction for the authors to explore, which can help them refine their work. However, the comment could be more helpful if it provided additional guidance on how to measure or evaluate these specific properties or accuracy improvements. Overall, the comment is 4 as it provides a constructive suggestion for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should test this assumption, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to test this assumption or what specific tests should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about the testing of this assumption, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or what implications it might have. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. This is an important point that the authors should address, as it could impact the validity and robustness of their findings. However, the comment lacks specificity and does not provide guidance on how to test this assumption or what specific tests should be conducted. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is unclear how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify these aspects in their draft. However, the comment lacks concrete details on how to achieve this clarity, making it 3. The authors know they need to provide more information but may struggle to determine the exact steps to take.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the \"scoring function\" and the different threshold values/ranges. This provides full grounding as the authors can accurately identify the part of the paper being discussed. However, the comment lacks specificity because it does not detail what is unclear about the components of the scoring function or how the authors arrived at the threshold values/ranges. Without specific guidance, the authors may struggle to understand what needs to be clarified or improved. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that it is unclear how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that is unclear, namely the components of the \"scoring function\" and the different threshold values/ranges. This feedback is valuable as it points out a potential weakness in the paper that needs clarification. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or examples. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability and does not provide any direction for improvement. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this information might be discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity as it does not provide guidance on what aspects of the simulation are being questioned or how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be present in a simulation. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. While it is a valid question that could help clarify the scope and complexity of the simulation, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or enhance their work. As a result, it is 2, as it provides limited value to the authors in terms of improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights specific issues with the model comparison, noting that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The comment provides a clear and explicit action for the authors to take, which is to expand the dataset selection to include more diverse features and consider using onehot encoding for categorical features. The feedback is concrete and directly guides the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key contribution of the paper, which is the thorough comparison of models on a wide range of datasets. It also specifies the issue with the dataset selection, noting that only one dataset has categorical features, while all others have exclusively numerical features. This is a clear indication of what needs to be addressed. The comment provides specific reasoning about the impact of this omission on the conclusions and suggests a potential issue with onehot encoding for categorical features. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chosen dataset selection is inadequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The reviewer provides a logical reasoning by explaining that categorical features are generally more challenging for deep learning models, which could affect the conclusions. However, the comment lacks specific examples or references to support the claim that the chosen datasets are insufficient. While the reasoning is clear, the lack of detailed evidence or references makes the claim 3, as the authors may need to further substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, specifically addressing the selection of datasets. It highlights that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features, which are generally considered more challenging for deep learning models. The comment also points out that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it identifies specific issues with the dataset selection and suggests ways to improve the model comparison. By addressing these concerns, the authors can enhance the robustness and validity of their conclusions. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the choice of IoT datasets, FlatCam Face [26] and Headpose detection [11], is unusual and suggests that better options should have been chosen. It provides specific examples of more popular datasets, such as wearable health or mobile activity recognition data, or even sets from UCI. This feedback is clear and actionable, as it directs the authors to consider alternative datasets that might be more relevant and widely used in the field. The authors know exactly what needs to be done to improve their draft by selecting more appropriate datasets for benchmarking. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the two IoT datasets, FlatCam Face [26] and Headpose detection [11], as unpopular and strange choices. The reviewer provides specific examples of more popular datasets that could have been used, such as wearable health or mobile activity recognition data, or even sets from UCI. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, FlatCam Face [26] and Headpose detection [11], is unusual and suggests that better options should have been chosen. The reviewer provides a logical reasoning by stating that the first dataset is relatively recent but not widely followed, while the second is outdated and no longer used. This reasoning is based on common knowledge about the popularity and relevance of datasets in the field. However, the comment could be strengthened by providing specific examples of more popular or relevant datasets that could have been used instead. Overall, the claim is 4, as it provides a logical basis but lacks detailed references or examples to fully substantiate the suggestion. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the choice of two IoT datasets, FlatCam Face [26] and Headpose detection [11], as unusual and potentially less relevant for benchmarking. The reviewer suggests that more popular or widely used datasets, such as wearable health or mobile activity recognition data, or even sets from UCI, would be better options. This feedback is clear and constructive, offering the authors a specific direction for improving their dataset selection and benchmarking results. By suggesting alternative datasets, the comment empowers the authors to enhance the relevance and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the possibility of subfigures in Figs 1 and 2 being swapped by mistake. While it implies that the authors should check for this potential error, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to verify or correct the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it raises a question about the possibility of subfigures being swapped by mistake, providing clear guidance on what needs to be checked. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking whether some subfigures in Figs 1 and 2 have been swapped by mistake. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the possibility of subfigures in Figs 1 and 2 being swapped by mistake. While it identifies a potential issue, it lacks actionable guidance or suggestions for the authors to address this concern. The comment does not provide specific instructions on how to verify or correct the issue, leaving the authors without clear steps to improve their draft. As a result, the comment is 2, as it points out a potential problem but does not offer actionable feedback for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the positive impact of the dropout probe, noting that it improves sensitivity and finds a causal role for syntactic representations. However, it also raises a concern about the potential increase in false positives. The reviewer suggests that this should be a substantial part of the discussion, implying that the authors should address this issue in their paper. While the comment highlights a potential concern, it does not provide explicit guidance on how to address it or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the tradeoff between sensitivity and false positives. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the positive impact of the dropout probe in finding a causal role for syntactic representations and raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the positive impact of the dropout probe in improving sensitivity and finding a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. The comment provides a logical reasoning by pointing out the tradeoff between sensitivity and false positives, which is a common concern in machine learning. However, it does not provide specific examples or references to support the claim about the risk of false positives, making it 3. The authors would need to further explore and substantiate this point themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the positive impact of the dropout probe in improving sensitivity and finding a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is 3 as it identifies a potential tradeoff that the authors should consider and address in their paper. However, the comment lacks specific suggestions or guidance on how to balance sensitivity and false positives, or how to discuss this tradeoff effectively. While it points out an important area for consideration, it does not provide detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim and the actual content of the paper. It points out that the regret bound for the proposed minibatch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the authors to address the issue. However, the comment does not explicitly instruct the authors to include the regret bound or provide specific guidance on how to address the discrepancy. The action is implicit and somewhat vague, as the authors need to infer that they should either clarify the location of the regret bound or provide it in the supplementary material. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regret bound for the proposed minibatch method\" and the \"supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the authors\" claim and the actual content of the paper, noting that the regret bound for the minibatch estimator is not found in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which provides a basis for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have stated that the regret bound for the proposed minibatch method is in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the claim. However, the comment does not provide detailed reasoning or specific examples from the referenced work to substantiate the claim, making it 3. The authors would need to investigate the referenced work to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim and the actual content of the paper. It points out that the regret bound for the proposed minibatch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. This feedback is valuable as it highlights a potential error or omission in the paper, prompting the authors to verify and correct their claims. However, the comment could be more helpful if it provided specific guidance on how to address the issue, such as suggesting where the regret bound should be included or offering examples of similar approaches. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for comparison. The action is implicit, as the authors can infer that they need to include a discussion and comparison of these methods, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion and comparison, but it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of these methods and their relevance to the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an important area for improvement that could enhance the comprehensiveness and depth of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending particular methods to include or ways to structure the comparison. While it provides a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it offers a clear area for enhancement but could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and potentially conduct additional analyses, but the feedback lacks specificity and actionable steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique, but it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies specific areas that need clarification or improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While it identifies specific areas that need clarification or improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The comment highlights potential weaknesses but lacks actionable advice, making it 3. The authors are given some direction but are left to figure out the specifics of how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed method, namely that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this weakness. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this method or where the comparison with PQ is made. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is presented as a main weakness of the method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data to support the assertion, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is presented as a main weakness of the method, which is relevant information for the authors to consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several subjective statements that need to be supported with proofs and references. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it points out the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment implies that the authors should provide additional evidence and explanations, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some subjective statements\" and \"proofs and references,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing detailed explanations and references to support subjective statements. Additionally, it provides specific examples of issues related to the choice of neural architecture and multiscale feature fusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some subjective statements are inappropriate and requires proofs and references to support them. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment further mentions the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment identifies areas that need clarification, it lacks specific examples or references to substantiate the claims, making it 3. The authors would need to provide additional evidence or explanation to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding subjective statements that lack proof or references, the challenges of seeking an effective architecture, and the sensitivity of image recovery performance to neural architecture choices. It also highlights the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment points out important areas for improvement, it could be more helpful by providing specific suggestions or examples of how to address these issues. The feedback is 4 as it directs the authors to enhance the clarity and evidence in their paper, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data that includes various languages and nationalities. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. While the comment implies that the authors should expand their analysis to include more detailed comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more detailed analyses and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the different languages and nationalities included. It expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. However, the comment does not specify which part of the paper this analysis is currently presented in, making it weakly grounded. The suggestion for more detailed analysis is specific, as it highlights a particular aspect of the data that could be explored further. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the different languages and nationalities included. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses could be more detailed or to justify the curiosity about potential biases. This makes the claim 3, as it provides a general direction for improvement but lacks the necessary details to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the analyses could be more detailed. It highlights the \"language/nationality\" data, which includes various languages and nationalities, and expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. This feedback is clear and actionable, as it prompts the authors to consider expanding their analysis to include more detailed comparisons and potentially uncover interesting insights. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm. It implies that the authors should consider exploring additional properties to enhance their approach design. However, the comment does not provide explicit guidance on how to identify or evaluate these properties or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore other properties and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for alternative properties to be considered, but without clear grounding, the authors may struggle to determine where this feedback fits into their manuscript. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the approach. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. This is a relevant point that could prompt the authors to consider expanding their analysis to include other properties, potentially leading to a more comprehensive understanding of their approach. However, the comment lacks specificity and does not provide detailed guidance on how to explore or evaluate these additional properties. While it identifies a potential area for improvement, the feedback could be more actionable and helpful with additional suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should include tasks beyond link prediction where PE (Positional Encoding) is important. However, it does not provide any explicit or implicit guidance on how to identify or implement these additional tasks. The comment lacks concrete details or suggestions on what specific tasks should be included or how to incorporate them into the paper. As a result, the authors are left without a clear understanding of what actions to take to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what specific tasks should be included or how they should be integrated. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where PE (Positional Encoding) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this expectation. Without additional context or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the paper should include tasks beyond link prediction where Positional Encoding (PE) is important. While it identifies a potential area for expansion, the comment lacks specificity and does not provide any guidance on how to incorporate these additional tasks or why they are relevant. Without actionable suggestions or examples, the authors are left with a general idea of what could be improved but without a clear path to implementation. Therefore, the comment is 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference [1]. While it implies that the authors should elaborate on these differences, the comment does not provide explicit guidance on how to address this point. The action is implicit and somewhat vague, as it lacks specific instructions on what aspects to focus on or how to present the comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference [1]. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results section where comparisons with other works are typically made. The comment is specific in its request for elaboration on the differences, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference [1]. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion. It is purely factual and does not require verification. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference [1]. This prompts the authors to clarify and differentiate their work from existing literature, which is a valuable contribution to the paper. However, the comment could be more helpful if it provided specific suggestions on how to present these differences or what aspects to emphasize. While it identifies an area for improvement, it lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. It provides a specific example of where this could be done, suggesting that details around parameter settings could be moved to the appendix. This feedback is clear and provides concrete guidance on how to improve the draft by reducing the use of footnotes and reorganizing content. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the excessive use of footnotes and suggests moving content from the footnotes to the main body of the paper. Additionally, it provides a concrete example of where this could be done, such as moving details about parameter settings to the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting that details around parameter settings could be moved to the appendix. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more examples or specific instances of excessive footnotes, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the excessive use of footnotes in the paper, which is distracting and should be moved into the main body of the paper. It provides a clear and actionable suggestion by recommending that details around parameter settings, for example, could be moved to the appendix. This feedback is valuable as it helps the authors reorganize their content effectively, making it more readerfriendly and focused. However, the comment could be more helpful if it provided additional guidance on how to determine which content should be moved or if it offered suggestions for alternative ways to present this information. Overall, the comment is 4 as it provides actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. It also questions the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. However, the comment does not provide explicit guidance on how to implement the suggestion for fewshot demonstrations or how to address the concern about zeroshot generation results. The actions are implicit and somewhat vague, as the authors are left to infer what specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the inclusion of zeroshot generation results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The comment further suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The reviewer provides a logical reasoning by questioning the relevance of the zeroshot results in the context of the paper. However, the comment lacks specific examples or references to support why the inclusion of zeroshot results is unnecessary or how it could be improved. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance in the context of the paper. It also suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for enhancing the paper. However, the comment could be more helpful if it offered more detailed guidance on how to incorporate the fewshot demonstrations or why the zeroshot results are not relevant. Overall, the comment provides some direction but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference, which is provided in the comment. This feedback is explicit and provides a clear action for the authors to take, which is to compute and report the effective receptive field after applying the GS module. The comment is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effectiveness of the GS module in improving the effective receptive field, and it suggests that the authors should compute this from a reference provided in the comment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that the authors should compute this from a reference provided in the comment. However, the comment does not provide any specific reasoning or evidence to support why this computation is necessary or how it would impact the paper. The reference to [2] is not elaborated upon, making it difficult for the authors to understand the significance of this suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification or explanation.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference provided in the comment, which could be a valuable addition to the paper. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a concrete step to take. However, the comment could be more helpful if it included additional context or explanation about why this computation is important or how it might impact the paper. Overall, the comment is 4, as it provides a clear direction for enhancing the draft, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights concerns about the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the time complexity. The comment implies that the authors should consider optimizing these aspects, but it lacks concrete steps or recommendations. As a result, the authors are left with a vague understanding of what actions to take, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concerns about time complexity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity seems high, providing three reasons: the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, the comment lacks specific examples or detailed reasoning to support these claims, such as comparisons with other methods or benchmarks. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed evidence to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. This feedback is 3 as it points out areas that could be optimized to improve the efficiency of the method. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, such as recommending alternative approaches or techniques to reduce complexity. While it highlights a relevant concern, the lack of actionable advice limits its usefulness to the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a clear and explicit action for the authors to take, which is to modify the figures to include this information. The suggestion is concrete, as it specifies exactly what needs to be changed, making it 5. Therefore, the comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that the figures should specify \"pretrained solution encoders & solution decoders\" to clarify the types of autoencoders used. This level of detail guides the authors on what changes to make to enhance the clarity of their figures. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion that the current figures are unclear. The authors would need to infer the exact nature of the confusion based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures by recommending that they specify \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and comprehensibility of their figures. By addressing this suggestion, the authors can improve the readability and understanding of their work for both reviewers and readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment implies that the authors should make these comparisons, it does not provide explicit instructions on how to implement them or why these comparisons are important. The action is implicit and somewhat vague, as the authors need to infer the specific comparisons needed and how to integrate them into their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion to include comparisons with specific methods is specific, but the comment lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides some context by mentioning specific methods, it lacks detailed reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. The claim is 3, as it highlights potential areas for improvement but lacks specific justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe,\" which could provide a more comprehensive evaluation of the method. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment highlights important areas for improvement, it lacks specific guidance on how to implement these comparisons or why the occlusion experiment is not relevant. The feedback is 3 as it points out potential enhancements, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request provides a clear and direct action for the authors to take, as it specifies exactly what information is needed. The authors know exactly what to include in their draft to address this feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request is specific and provides clear guidance on what the authors need to address. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for additional information about the computation required to implement the experiments and the duration and hardware used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests additional information about the computation required to implement the experiments, including the duration and hardware used. This feedback is 3 as it prompts the authors to provide more detailed information about the experimental setup, which can be beneficial for readers interested in replicating or understanding the experiments. However, the comment does not offer specific suggestions on how to present this information or why it is important, leaving the authors with a general direction but without detailed guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. While it does not explicitly instruct the authors to address this issue, it implies that the authors should consider and discuss this aspect in their paper. The question is somewhat vague, as it does not provide specific guidance on how to address the issue or what kind of analysis or discussion would be most beneficial. However, the authors can infer that they need to explore and report on the effects of missing data on the model. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the effects of missing data and how the model handles it, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. The comment does not present a claim or opinion but rather poses a question seeking clarification. It is purely factual and does not require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. It prompts the authors to consider the potential compounding effects of missing data and how the model might handle such situations. This feedback is 3 as it encourages the authors to explore a critical aspect of their work that could impact the model\"s performance and robustness. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of similar approaches in the literature. Overall, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability of their method on these benchmarks, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the stability of the OGEAug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. However, it does not specify which part of the paper discusses these benchmarks or methods, making it weakly grounded. The comment is specific in detailing the issue of stability verification on these datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug method on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific concern about the stability of the OGEAug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. This feedback is 3 as it points out a potential gap in the evaluation of the method\"s performance on outofdistribution data. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation methodology. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and provides a direct action for the authors to take, which is to conduct additional experiments with multiple seeds. The suggestion is concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of singleseed experiments, which limits the assessment of performance differences and the impact of the proposed cycle consistency loss. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is 3 as it provides a logical reasoning for the need for multiple seed experiments to ensure the robustness of the results. However, the comment lacks specific examples or references to support the claim that singleseed experiments are insufficient. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experimental setup, specifically the use of a single seed for training. It highlights the difficulty in assessing the significance of performance differences and the impact of the proposed cycle consistency loss on convergence due to this limitation. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and actionable, offering a specific improvement that the authors can implement to enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided guidance on how to conduct these multiple seed experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While the comment implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify their rationale but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice of distributions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. The comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The comment highlights a gap in the paper but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting alternative approaches or optimizations that could make the method more accessible. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed method, specifically mentioning that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. The authors can infer that it relates to the methodology or experimental setup sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it identifies a potential limitation, it does not provide specific guidance on how to address it or suggest alternative approaches. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, which limits its accessibility to potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the need for a multiGPU setup, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a concern but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that the authors should consider Ref[2] as a strong baseline for comparison. While the comment provides a clear action to compare the current system with another system that captures semantics, it does not specify which aspects of the current system should be compared or how to implement the comparison. The suggestion to use Ref[2] as a baseline is also vague, as it does not provide specific guidance on how to incorporate this reference into the comparison. Therefore, the comment is 4, as it identifies a clear action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that Ref[2] could be a strong baseline for comparison. However, the comment does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to implement the comparison or what specific aspects should be focused on. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that Ref[2] could be a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why Ref[2] is a suitable baseline or how it would provide a meaningful comparison. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the relevance of Ref[2] themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that this comparison could provide valuable insights into the performance of the current system. Additionally, the comment suggests using Ref[2] as a strong baseline for comparison, which could help the authors benchmark their work effectively. While the comment identifies a potential area for improvement and provides a specific suggestion, it lacks detailed guidance on how to implement the comparison or what specific aspects should be focused on. This limits the comment\"s helpfulness, as it provides a general direction but not a comprehensive plan for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the quantitative results, specifically asking how the data is used for training, validation, and testing. While the comment implies that the authors should provide more detailed information on the data used, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the data usage but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where these results are presented. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification on the data usage, but without grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the clarity of the quantitative results, specifically asking how the data is used for training, validation, and testing. This is an important point that can help the authors improve the transparency and reproducibility of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of detailed methodology or data descriptions. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a crucial aspect that needs attention but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It questions whether one of the assumptions is not satisfied or if there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the model\"s performance. The comment implies that the authors should investigate these possibilities, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s performance in identifying true sources in the triangle dataset, but it does not specify which part of the paper discusses this issue. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment lacks specificity as it does not provide details on what assumptions might not be satisfied or what learning difficulties might exist. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the model\"s performance in identifying true sources in the triangle dataset, but it does not provide any specific reasoning, examples, or references to support this claim. The comment suggests that there might be issues with assumptions or learning difficulties, but it lacks detailed justification or evidence to substantiate these claims. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s performance in identifying true sources in the triangle dataset, questioning whether one of the assumptions is not satisfied or if there are learning difficulties. This feedback is 3 as it points out a potential area of concern that the authors need to address. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might investigate or resolve these issues. To be more helpful, the comment could include suggestions for further analysis, alternative approaches, or specific areas to focus on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or improve the generalizability of the system. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper discusses the limitation or how the authors could address this issue. The comment is 1 as it does not refer to a specific section, figure, or table, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, it lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation exists or how it could be addressed. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. While it identifies a potential area for improvement, it lacks specificity and actionable guidance. The comment does not provide suggestions on how to address this limitation or expand the system\"s generalizability. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to address the issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the use of information, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. This is a relevant question that could help the authors clarify their methodology and potentially improve the clarity of their paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks depth and actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to take, which is to include this discussion in their paper. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on the arbitrary hyperparameter \u03b3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice for a given graph and the analysis of its sensitivity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This claim is 3 as it highlights a gap in the discussion, but it lacks specific examples or references to support the assertion. The comment suggests that this omission could make it difficult for researchers to follow, but it does not provide detailed reasoning or evidence to substantiate this claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion of the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a critical area that needs further exploration and explanation in the paper. By addressing these points, the authors can enhance the comprehensiveness and utility of their work for researchers. However, the comment could be more helpful if it provided specific suggestions or examples on how to incorporate this discussion. Overall, the feedback is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. It implies that a controlled baseline should be included, which ablates heads at different locations in the model. While the comment identifies a potential confounding factor and suggests a way to address it, it does not provide specific guidance on how to implement this controlled baseline or what specific locations should be tested. The action is explicit but somewhat vague, as the authors know they need to include a controlled baseline but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"induction heads\" and \"FV heads,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the \"location\" of these heads within the model could be a confounding factor affecting the ICL performance. The comment further suggests a controlled baseline that ablates heads at different locations in the model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. The reviewer provides a logical reasoning by pointing out that induction heads and FV heads are located at different layers, which could be a confounding factor. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this reasoning and potentially conduct additional experiments to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the analysis of induction heads and FV heads, suggesting that the \"location\" of these heads within the model could influence the ICL performance. It provides a clear and actionable suggestion by recommending a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it directs the authors to consider a more comprehensive approach to their analysis, which could lead to a more robust understanding of the results. However, the comment could be further improved by providing specific guidance on how to implement this controlled baseline or what locations to test. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under similarity measurement, suggesting that the authors should include this section to describe how the multiplechoice task is approached. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to their draft. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions a missing section on synonym identification under similarity measurement, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies what is missing, namely a description of how the multiplechoice task is approached, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this section or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks a section on synonym identification under similarity measurement, which would describe how the multiplechoice task is approached. This feedback is clear and actionable, as it provides a direct suggestion for improvement by specifying what the authors should include in their draft. However, the comment could be more helpful if it offered additional guidance on how to approach this section or what specific aspects should be covered. Despite this, the comment is 4 as it directs the authors to a clear area for enhancement, making it a 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide explicit guidance on how to create this overview or what specific elements should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide an overview but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not specify which part of the paper lacks this overview or where it should be included. The authors can infer that it might be in the introduction or the methodology section, but this inference is not explicit. The comment is specific in suggesting what is needed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more comprehensive introduction. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this overview or what elements should be included. While it points out a general area for enhancement, it does not offer actionable steps or suggestions for improvement, leaving the authors with a vague idea of what needs to be addressed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to redefine the figure in Figure 3, as the expected quantities are scalars but are shown as a vector. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: redefining the figure to show scalar quantities instead of vectors. This provides clear guidance on how to improve the figure, making the comment 5.", "verifiability_rationale": "The review point is a request for clarification regarding the presentation of data in Figure 3. It suggests that the expected quantities are scalars but are shown as vectors, and it asks for a redefinition of the figure. This is a factual statement that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of data in Figure 3, noting that the expected quantities are scalars but are shown as vectors. It provides a clear and actionable suggestion for improvement by asking the authors to redefine the figure to accurately represent the data. This feedback is valuable as it directs the authors to a specific area of their draft that needs revision, offering a concrete step to enhance the clarity and accuracy of their presentation. However, the comment could be more helpful if it explained why this change is necessary or how it might impact the reader\"s understanding of the results. Overall, the comment is 4 as it provides clear guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance on how to improve the setup or what questions need to be addressed. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations or what specific questions arise regarding the setup. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper is being addressed. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific examples or detailed reasoning to support why the current setup is inadequate. The comment lacks concrete evidence or references to justify the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects of the experiments need attention. Without actionable feedback or detailed advice, the authors are left with a general observation that does not offer a clear path for improvement. This lack of specificity and actionable guidance makes the comment 2, as it does not effectively support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. While the comment implies that the authors should conduct additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the analysis or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of the paper being addressed, namely the proposed models\" usefulness for learning representations for lowfrequency words. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and the need for deeper exploration. However, it does not provide specific guidance on how to address these issues or what additional evidence or analysis would be beneficial. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks empirical evidence to support its claim about the usefulness of the proposed models for learning representations of lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct this empirical analysis or what metrics to use. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in understanding Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could improve the figure by reporting flops or model size, which would make the metrics more concrete. While the comment implies that the authors should make changes to the figure, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely the difficulty in understanding due to the overlapping lines, and suggests that reporting flops or model size would make the metrics more concrete. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could improve the figure by reporting flops or model size, which would make the metrics more concrete. However, the comment lacks specific examples or detailed reasoning to support why these additional metrics would enhance understanding or provide more context. The suggestion is 3, as it provides a logical direction for improvement but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the presence of many lines on top of each other. It suggests that the authors could improve the figure by reporting flops or model size, which would make the metrics more concrete. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the clarity and comprehensibility of their figures. However, the comment could be more helpful if it included additional guidance on how to present these metrics or examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors toward a concrete improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or how the authors should address this issue. The comment lacks explicit guidance or concrete suggestions on what needs to be added or clarified, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which part of the paper these questions are from, nor does it provide details on what specific details are missing. This lack of explicit reference to a specific section or element of the paper makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment lacks specificity regarding the missing details, leaving the authors uncertain about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references to what details are missing, the authors may find it challenging to understand and address the issue. The comment lacks verifiability as it does not offer sufficient evidence or justification for the claim, making it difficult for the authors to improve their work based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or provide any guidance on how the authors might address this issue. Without specific feedback or suggestions, the authors are left without actionable insights to improve their draft. The comment lacks depth and clarity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 is confusing and that the columns are not explained in the text or caption. This provides a clear action for the authors to take, which is to clarify the meaning of the columns in the figure by either adding an explanation in the text or updating the caption. The feedback is direct and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure. The comment highlights the lack of explanation in the text or caption, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because the columns are not explained in the text or caption. However, it does not provide any further explanation or reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that the columns are confusing and not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure by either adding an explanation in the text or updating the caption. By addressing this feedback, the authors can enhance the clarity and accessibility of their work, making the comment 4. However, the comment could be more helpful if it provided suggestions on how to clarify the figure or offered examples of how to improve the explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations, it does not explicitly instruct them to do so or offer specific guidance on what aspects of the results or explanations should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper this observation is based on, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests that more explanations are needed, it does not specify what aspects of the results or explanations should be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. However, the comment lacks specific reasoning or evidence to support why the results are unexpected or how they compare to the early methods mentioned. Without detailed justification or references, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or provide the requested explanations. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of an ablation analysis in the main paper, which makes it challenging to identify the source of a small performance gain. While the comment implies that an ablation analysis should be included, it does not explicitly instruct the authors to conduct one. The action is implicit and somewhat vague, as the authors can infer that they need to add an ablation analysis but are not provided with specific guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of ablation analysis in the main paper, which makes it difficult to identify the source of a small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or methodology sections, but this inference is not explicit. The comment is specific in pointing out the need for an ablation analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to identify the source of a small performance gain. This is a subjective opinion based on the reviewer\"s expectation of what should be included in the paper. However, the comment does not provide specific examples or detailed reasoning to support why an ablation analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, specifically the lack of an ablation analysis, which makes it difficult to pinpoint the source of a small performance gain. This feedback is valuable as it highlights a critical area for improvement that could enhance the paper\"s clarity and understanding of the results. However, the comment does not provide specific suggestions or guidance on how to conduct the ablation analysis or what components to focus on. While it points out a clear weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined for enhancing the experiments. Without any guidance or direction, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in, nor does it provide details on what aspects of the experiments are not convincing. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. Without additional context or suggestions for improvement, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be strengthened. This lack of specificity and actionable feedback makes the comment 2, as it does not guide the authors in addressing the issue effectively. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This is an explicit action that provides a clear direction for the authors to follow. The suggestion is concrete, as it specifies a particular model to compare with, making it easy for the authors to understand and implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be made in, such as the results section or a specific experiment. This lack of explicit reference to a particular section makes it weakly grounded. The comment is specific in suggesting a comparison with HateXplain models, which provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This is a request for additional analysis or comparison, but it does not contain a claim or opinion that requires verification. It is a suggestion for improvement, which is factual and does not necessitate verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it provides a clear direction for the authors to enhance their work by benchmarking against established models. However, the comment lacks depth and does not offer specific guidance on how to conduct the comparison or what aspects to focus on. While it identifies a potential area for improvement, it does not fully support the authors in making these enhancements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it implies that the authors should provide a clearer explanation for their choice of freezing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should address the issue or provide a detailed explanation of the adaptive method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, it does not specify which part of the paper discusses the freezing method or where the MLS selection process is described. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the freezing method and suggests an alternative approach, but it lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be better or why freezing is not appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. The comment points out a potential weakness but does not offer actionable advice or examples to help the authors improve their draft. Therefore, the feedback is 3, as it prompts the authors to reconsider their approach but does not fully support them in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue addressed in the existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting a particular analysis that could be conducted, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. The comment references an external work (https://arxiv.org/abs/2104.06378) that has done closelyrelated analyses, providing some support for the suggestion. However, the comment lacks specific examples or detailed reasoning from the authors\" work, making it 3. The authors would need to further develop the claim with their own analysis to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. This feedback is 3 as it provides a specific suggestion for further analysis that could enhance the paper. However, the comment could be more helpful if it offered more detailed guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 3 as it prompts the authors to consider an additional analysis that could strengthen their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach and suggests that the paper should provide a more comprehensive discussion on the computational complexity. It also questions whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so or provide specific guidance on how to conduct the additional discussion or analysis. The action is implicit and somewhat vague, as the authors can infer that they need to address the computational cost but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational cost of the proposed approach, specifically questioning why the additional cost did not lead to significant delays in computation. It suggests that the paper should provide a more comprehensive discussion on the computational complexity of the proposal and raises a concern about whether the approach becomes prohibitive in certain settings. However, the comment does not explicitly mention which part of the paper discusses the computational cost, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in its request for a more comprehensive discussion on computational complexity and the potential prohibitive nature of the approach in certain settings. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach, questioning why the additional cost did not lead to significant delays in computation. The reviewer suggests that the paper should provide a more comprehensive discussion on the computational complexity of the proposal and wonders if the approach becomes prohibitive in some settings. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the concern and how to address it. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It points out that while the paper mentions the additional cost did not lead to significant delays in computation, it lacks a comprehensive discussion on the computational complexity of the proposal. The reviewer also raises a question about whether the approach becomes prohibitive in certain settings. This feedback is 3 as it highlights an area that could benefit from further exploration and discussion, providing the authors with a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address the computational complexity or provided examples of settings where the approach might be prohibitive. Overall, the comment is 3, as it directs the authors to a relevant area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is an explicit request for additional clarification, which is clear and actionable. The authors know exactly what needs to be done to improve their draft by adding more explanation on this topic. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 97, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more explanation about how novel values in the test set are handled. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors clarify an aspect of their methodology that may be unclear to readers. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or examples of what specific information should be included. Overall, the feedback is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should address this issue, discuss the existing methods, or incorporate them into their work. Without any actionable steps or suggestions, the comment lacks direction for the authors, making it 1.", "grounding_specificity_rationale": "The comment mentions that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not specify which part of the paper should include this discussion or where the authors should incorporate these methods. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding which specific methods or aspects of multitask learning should be discussed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not provide any references or examples of these existing methods, making it difficult for the authors to verify the claim. Without specific evidence or references, the authors may find it challenging to address the issue or understand the context of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or incorporate these existing methods into their work. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a more detailed analysis of their experimental results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a missing indepth analysis and provides a concrete example of what is lacking: the analysis of why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. This provides clear guidance on what the authors need to address in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the analysis of experimental results. It points out a gap in understanding why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is clear and actionable, as it prompts the authors to conduct a more indepth analysis of their experimental results to better understand and explain the observed trends. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method to ensure a fair comparison. This is an explicit action, as it directly instructs the authors to address a specific issue related to the hyperparameter tuning of the baseline. However, the comment does not provide detailed guidance on how to implement this action, such as which hyperparameters to focus on or how to conduct the tuning. While the action is clear, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment addresses the introduction of multiple hyperparameters and the extensive hyperparameter search, specifically mentioning \"temperature, penalty, and threshold.\" However, it does not specify which part of the paper discusses these hyperparameters or the hyperparameter search, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, which could impact the fairness of the comparison with the proposed method. The reviewer recommends ensuring that the baseline is fully tuned with similar resources as the proposed method. However, the comment lacks specific examples or references to support the claim about the impact of hyperparameters on the comparison. Without detailed evidence or examples, the claim is 3, as it provides a logical suggestion but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and the baseline due to the extensive hyperparameter search. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method could improve the fairness of the comparison. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it offered guidance on how to conduct the tuning or which hyperparameters to focus on. Overall, the comment is 4, as it provides valuable insight into improving the draft but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This comment provides a clear and explicit action for the authors to take: they should include standard deviations in their experimental results to allow for a more accurate evaluation of the results\" significance. The feedback is direct and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, namely the absence of standard deviations, which makes it difficult to judge the significance of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual statement that does not require verification or justification. It is a request for clarification or improvement, not an opinion or suggestion that needs to be substantiated. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the lack of standard deviations makes it challenging to assess the significance of the results. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations. By addressing this point, the authors can enhance the clarity and robustness of their experimental findings, which is crucial for the credibility of their work. However, the comment could be more helpful if it provided additional context or examples on how standard deviations can be incorporated or why they are important. Overall, the comment is 4 as it guides the authors toward a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived weakness in the analysis, specifically noting the lack of discussion on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. While the comment identifies areas that need further exploration, it does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to improve the analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional analysis and guarantees. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"SDE (2a)(2d),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the lack of discussion on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. While the comment identifies areas that could be strengthened, it lacks specific examples or references to support the claim. The reasoning is somewhat logical but could be more robust with additional evidence or detailed explanations. Therefore, the comment is 3, as it provides a basis for improvement but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific area where the analysis could be strengthened, namely the lack of discussion on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. This feedback is clear and actionable, as it points out a gap in the theoretical foundation of the paper that the authors can address to enhance the robustness and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or referenced relevant literature for guidance. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific suggestions or guidance on how to improve the quality of the generated images or what aspects of the realism need to be enhanced. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the realism of the generated results, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the lack of realism in the results shown in the paper and supplemental material. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it points out a potential weakness in the paper, prompting the authors to consider ways to improve the realism of their generated images. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending techniques or methods to enhance realism. Without actionable advice, the authors may find it challenging to know where to focus their efforts for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the statement in lines 559560 is not entirely true and provides a correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is clear and provides a direct action for the authors to correct their statement. The comment is specific and actionable, as it guides the authors on how to revise their draft to ensure accuracy. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 559560, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it corrects a statement by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This provides clear guidance on what needs to be revised in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely true. It provides a specific correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the paper, pointing out that the statement in lines 559560 is not entirely true. It provides a clear and actionable correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is valuable as it corrects a factual error and guides the authors on how to improve the accuracy of their draft. However, the comment could be more helpful if it also suggested how this correction might impact the overall understanding or results of the paper. Overall, the comment is 4, as it provides clear and actionable feedback, but it could be more comprehensive with additional context or suggestions for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the term \"hyperspectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyperspectral\" and instead use \"hyperspectral imaging,\" which is the correct terminology. The comment provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"hyperspectral\" and provides a correct definition of \"hyperspectral imaging.\" This level of detail guides the authors on what needs to be corrected, making the comment 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. This claim is 5 as it is supported by a clear explanation of what hyperspectral imaging is and why the term \"hyperspectral\" might be confusing. The comment provides a logical reasoning and a precise definition, making it easy for the authors to understand and address the issue. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific terminology issue, clarifying that the term \"hyperspectral\" is confusing and provides a correct definition of \"hyperspectral imaging.\" This feedback is actionable and helpful as it guides the authors to use the correct terminology, which can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it also suggested alternative ways to describe the imaging technique or provided context on why the terminology is important. Overall, the comment is 4, as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the role of visual information in the paper and questions the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it suggests that the improvements are not significant given the sample size of 1000 users. While the comment identifies areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The authors are left with a general understanding of what needs to be clarified or improved but without concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ablation study, questioning the effectiveness of the visual information and the implementation detail of the model without perception. The comment further critiques the experiment results, suggesting that the improvements are not significant given the sample size. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific examples from Table 10, where the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, the comment suggests that the improvements are not significant given the sample size of 1000 users. This reasoning is logical and provides specific examples to support the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, the comment raises concerns about the significance of the improvements given the sample size of 1000 users. This feedback is clear and actionable, as it highlights specific areas that need clarification or further investigation. By addressing these points, the authors can enhance the robustness and clarity of their experimental results. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how to improve the ablation study. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the end of Section 4.2 claims that Transfer Lasso shows the best accuracy in feature screening, but it does not cite or compare previous works on Lasso screening, such as the work by Ren et al. The comment explicitly instructs the authors to include these previous works in their comparison, providing a clear and concrete action to take. By specifying the exact works to be included, the authors know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular claim about Transfer Lasso\"s accuracy in feature screening and notes the absence of citations or comparisons to previous works on Lasso screening, such as the work by Ren et al. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso shows the best accuracy in feature screening, but it does not cite or compare previous works on Lasso screening, such as the work by Ren et al. This claim is verifiable as it is supported by a specific reference to a previous work that should be included in the comparison. The mention of Ren et al. provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the omission affects the paper\"s claims or conclusions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims that Transfer Lasso shows the best accuracy in feature screening but does not cite or compare previous works on Lasso screening, such as the work by Ren et al. This feedback is clear and actionable, as it directs the authors to include relevant references and comparisons to strengthen their claims. By addressing this omission, the authors can enhance the credibility and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references into the discussion. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address it or suggest alternative ways to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the notation used in the results, specifically the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This is a factual observation that requires no verification or justification, as it is a straightforward request for clarification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the notation used in the results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This feedback is clear and actionable, as it directs the authors to clarify the notation used in their results section. By addressing this issue, the authors can improve the transparency and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or offered examples of how to present the results more clearly. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text rather than human reading comprehension. This is an explicit action that the authors can take to improve the clarity of their work. The comment provides a clear direction on what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and should clarify that it refers to machine comprehension of text rather than human reading comprehension. This provides clear guidance on what needs to be addressed to improve the clarity of the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text rather than human reading comprehension. The comment provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" are often associated with human understanding, which is different from the context of machine comprehension. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the distinction between machine and human comprehension. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and accuracy of the title. By addressing this issue, the authors can enhance the clarity and precision of their work, which is beneficial for both readers and reviewers. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between machine and human comprehension. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. While the comment highlights a potential issue, it does not provide explicit guidance on what the authors should do to address this concern. The action is implicit, as the authors need to infer that they should reconsider their choice of metric for human evaluation. Additionally, the comment lacks concrete details on how to implement this change or what specific human metric should be used. Therefore, the comment is 3, as it points out an issue but does not provide clear steps for resolution.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. However, it does not specify which part of the paper discusses the human evaluation or where the use of TSS is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the choice of metric but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. The reviewer claims that this choice weakens the convincingness of the human evaluation. However, the comment lacks specific reasoning or examples to support why a human metric would be more appropriate or how the use of TSS affects the evaluation. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment questions the choice of using an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It highlights a potential weakness in the methodology, suggesting that the use of an automatic metric may weaken the convincingness of the human evaluation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what alternative human metrics could be considered. While it identifies a potential problem, it lacks actionable advice, making it 3. The authors are given a direction to consider but are not fully supported in making improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of confidence intervals for the results, making it unclear whether the performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The reviewer provides specific references to external works that could be relevant to the authors, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for confidence intervals to determine the statistical significance of performance gains. Additionally, the comment highlights the limited evaluation on only two datasets, which are standard in the RNP community. The inclusion of specific references to external works further grounds the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of confidence intervals makes it unclear whether performance gains are statistically significant. It also notes the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be relevant to the authors, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022. These references provide a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples within the text to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be relevant to the authors, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022. This feedback is clear and actionable, as it highlights specific areas for improvement and provides relevant references to guide the authors in enhancing their work. However, it could be more helpful if it included suggestions on how to address these issues or specific examples of how to incorporate confidence intervals or additional datasets. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment implies that the authors should include training losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to present the training losses or what specific metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method and suggests including training losses. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this method is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment is specific in its request for training losses but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. However, the comment does not provide any supporting evidence, reasoning, or references to justify why training losses are necessary or how they would demonstrate stability. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment identifies a potential area for improvement, it lacks specificity and actionable guidance on how to address the issue. The authors are left with a general suggestion to include training losses but without detailed instructions on what specific losses to include or how to present them. This limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, that are claimed to be the same thing. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to clarify or revise their claims. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their claims but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It specifically mentions the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, suggesting that these are all the same thing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which section or part of the paper these aspects are discussed in, making it weakly grounded. The authors can infer that it relates to the theoretical analysis section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, specifically mentioning the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability. The reviewer argues that these aspects are essentially the same thing, which is applying stronger constraints for samples with higher popularity. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It points out that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are all essentially the same thing, which is applying stronger constraints for samples with higher popularity. This feedback is clear and actionable, as it highlights a potential overreach in the paper\"s claims and suggests that the authors need to clarify or revise their theoretical analysis. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to better differentiate these aspects. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the training process. The action is implicit and somewhat vague, as the authors are left to infer that they need to ensure a fair comparison by adjusting the training process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of RegMixup seeing 2x samples per iteration, which could lead to unfair comparisons with other methods. The comment provides a clear explanation of the problem and suggests a potential solution, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as specific examples or references, to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This is a relevant observation that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure a fair comparison. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are left to infer that they need to adjust their training process or methodology to ensure a fair comparison. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer implies that the authors may have chosen focal loss for a unified form without considering the differences between classification and regression tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative methods might be more suitable. The action is implicit and vague, as the authors are left to infer that they should reconsider their choice of loss function and provide a justification for it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It suggests that the authors may have chosen focal loss for a unified form without considering the differences between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but the exact location is not explicitly mentioned. The comment is specific in its critique of the choice of focal loss and its potential impact on regression tasks, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning by explaining that focal loss has lower gradients on easy samples, which could be problematic for regressing the IoU. However, the comment lacks specific examples or references to support the claim that using focal loss in regression tasks could lead to inaccurate results. While the reasoning is clear, the lack of detailed evidence or references makes the claim 3, as the authors may need to further explore and substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It points out that focal loss is typically used for class imbalance problems in classification tasks, where lower gradients on easy samples can be beneficial. However, the comment suggests that this approach may not be appropriate for regression tasks like IoU, as it could lead to inaccurate results due to the lower weight given to easy samples. The comment also implies that the authors may have chosen focal loss for a unified form without fully considering the differences between classification and regression tasks. While the comment identifies a potential issue and provides some insight, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. Therefore, the comment is 3, as it prompts the authors to reconsider their choice of loss function but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and report on the scalability of their method. However, the comment does not specify what aspects of scalability should be considered or how to conduct the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to determine where to address the issue. The comment is specific in its inquiry about scalability, but without clear grounding, it is challenging for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the scalability of the method as the corpus size or hidden dimension size increases. This is a relevant concern that the authors should address to ensure the practicality and applicability of their method in realworld scenarios. However, the comment lacks specificity and does not provide guidance on how the authors might investigate or address this scalability issue. While it identifies a critical area for improvement, the feedback could be more helpful if it included suggestions or examples of how to approach scalability testing. Therefore, the comment is 3, as it points out a significant area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. While the comment implies that the authors should expand their dataset selection, it does not provide specific guidance on which datasets to include or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting the inclusion of additional datasets, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any reasoning or evidence to support why these specific datasets are necessary or how they would contribute to the study. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. This feedback is 3 as it identifies a potential area for improvement by suggesting additional datasets that could strengthen the paper\"s claims about generalizability. However, the comment lacks specific guidance on which datasets to include or how to integrate them into the study, which would make it more actionable. The authors are given a direction to expand their dataset selection, but the comment could be more helpful with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the biggest concern during reading is the lack of implementation details of the proposed methods, which should have been described in Section 4.1. This provides a clear and direct action for the authors to take, which is to include the implementation details in the specified section. The comment is explicit and concrete, as it specifies exactly what needs to be done to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the biggest concern during reading is the lack of implementation details of the proposed methods. It suggests that these details should have been described in Section 4.1. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without detailed justification or examples, the claim remains somewhat vague, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, providing clear and actionable feedback for the authors to address. By pointing out this omission, the comment helps the authors improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered suggestions on what specific implementation details should be included or how to present them effectively. Overall, the feedback is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of empirical evaluation and comparison with other methods, which is a significant concern for a submission to NeurIPS. It also notes the absence of a theoretical argument for the practical value of the contribution. While the comment identifies the need for empirical evaluation and comparison, it does not provide specific guidance on how to address these issues or what aspects should be evaluated. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment is 3, as it highlights important areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation and comparison with other methods, as well as the absence of a theoretical argument for the practical value of the contribution. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is missing, such as empirical evaluation and comparison with other methods, and the need for a theoretical argument for practical value. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation, comparison with other methods, and a theoretical argument for the practical value of the contribution. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment suggests that the theoretical contributions may be significant but does not elaborate on how this could be demonstrated. Without detailed justification or examples, the claim remains 3, as it lacks the necessary evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several critical weaknesses in the paper, specifically the lack of empirical evaluation, comparison with other methods, and a theoretical argument for the practical value of the contribution. It highlights that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. While the comment effectively points out the deficiencies, it does not provide specific suggestions or guidance on how to address these issues or improve the paper. The feedback is 3 as it directs the authors to areas that need attention, but it lacks actionable advice, making it more beneficial for the authors to understand the scope of the revisions needed. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (3) and (4) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed to avoid confusion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the symbol \"P\" is used inconsistently in the manuscript, representing both a probability and a cumulative distribution function. This claim is 3 as it highlights a potential source of confusion in the paper. However, the comment does not provide specific examples or detailed explanations of where this inconsistency occurs, which would help the authors understand and address the issue more effectively. The lack of detailed examples or references makes it challenging for the authors to fully grasp and rectify the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the symbol \"P\" in the manuscript, noting that it is used to represent both a probability and a cumulative distribution function. This observation highlights a potential source of confusion for readers, which is important for the authors to address. However, the comment does not provide specific suggestions or guidance on how to resolve this issue, such as recommending a consistent notation or clarifying the context in which each usage is appropriate. While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in understanding how neural nets learn natural rare spurious correlations, suggesting that most analysis and ablation studies use artificial patterns instead of natural spurious correlations. It implies that the authors should consider using natural spurious correlations in their analysis. However, the comment does not provide explicit guidance on how to incorporate natural spurious correlations or what specific steps to take to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should focus on natural spurious correlations but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a gap in understanding how neural nets learn natural rare spurious correlations, suggesting that most analysis and ablation studies use artificial patterns instead of natural spurious correlations. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures that discuss these patterns. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the issue of using artificial patterns versus natural spurious correlations, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the community lacks understanding of how neural nets learn natural rare spurious correlations and suggests that most analysis and ablation studies use artificial patterns instead of natural spurious correlations. The reviewer provides a logical reasoning by contrasting artificial patterns with natural spurious correlations, noting that the latter are complex and different in every example. However, the comment lacks specific examples or references to support the claim about the prevalence of artificial patterns in analysis and ablation studies. This makes the claim 3, as it provides a logical argument but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a gap in understanding how neural nets learn natural rare spurious correlations, suggesting that most analysis and ablation studies use artificial patterns instead of natural spurious correlations. It points out that duplicating artificial patterns is different from the complexity and variability of natural spurious features. While the comment identifies an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or incorporate natural spurious correlations into their analysis. The feedback is 3 as it provides insight into a potential weakness, but it could be more actionable with additional direction or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method discussed in the paper can be applied to general MDPs but is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRMRL~[1] and suggests exploring the application of such algorithms in more general tasks. However, the comment does not provide explicit guidance on how the authors should address these limitations or suggestions. While it implies that the authors should consider expanding the applicability of their method, it lacks concrete steps or detailed instructions on how to do so. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it is limited to navigation problems. It also references PRMRL~[1] as an example of combining RL and planning, suggesting that such algorithms could be applied to more general tasks. However, the comment does not specify which part of the paper discusses the method or where the limitations are mentioned, making it weakly grounded. The comment is specific in suggesting a potential direction for expansion, but without explicit references to the paper, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper is limited to navigation problems and suggests exploring its application in more general tasks. The comment references PRMRL~[1] as an example of combining RL and planning, which provides some context for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the method is limited to navigation problems. While it provides a reference, it does not fully explain why this limitation exists or how it could be addressed. Therefore, the claim is 3, as it requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method discussed is primarily applicable to navigation problems. It suggests that combining RL and planning, as discussed in PRMRL~[1], could be applied to more general tasks. This feedback is 3 as it points out a potential area for expansion and improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might explore this direction or address the limitation. While it provides a starting point for further exploration, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the suitability of feature spaces for 1NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. While the comment identifies a potential problem and provides a suggestion for addressing it, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider standardizing feature dimensions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces and suggests a potential solution by mentioning the need for individual standardization of feature dimensions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. The comment provides a logical reasoning by explaining that feature spaces that are not close to a spherical Gaussian may perform poorly. This reasoning is based on a common understanding of the properties of 1NN classification and the potential impact of feature space characteristics. However, the comment does not provide specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the suitability of feature spaces for 1NN classification, specifically mentioning that feature spaces that are not close to a spherical Gaussian may perform poorly. It provides a suggestion to address this issue by standardizing feature dimensions individually. This feedback is clear and actionable, offering the authors a specific direction to improve their draft by considering the impact of feature space characteristics on classification performance. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4 as it provides valuable guidance for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the paper. It acknowledges that an intuitive example was provided but notes that the setting of this example is less convincing. The comment suggests that a formal definition for the contrastive gap is still needed. While the action is explicit, the comment does not provide specific guidance on how to define the contrastive gap or what aspects should be included in the definition. The authors are given a clear direction to address the issue but lack detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a central concept in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a clear definition for the contrastive gap, even after providing an intuitive example. The comment further details the problem by noting that the setting of the example is less convincing and that a formal definition is still lacking. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the \"contrastive gap\" is a central concept in the paper but has not been defined clearly. It acknowledges that an intuitive example was provided but notes that the setting of this example is less convincing. The comment suggests that a formal definition is still lacking. While the reviewer provides a logical reasoning for the claim by pointing out the lack of a clear definition, it could be strengthened by offering specific examples or references to what a clear definition might entail. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of a clear definition for the \"contrastive gap,\" which is a central concept. It acknowledges that an intuitive example was provided but points out that the setting of this example is less convincing. The comment highlights the need for a formal definition of the contrastive gap, which is crucial for understanding and replicating the work. This feedback is clear and actionable, as it directs the authors to address a critical gap in their paper. However, it could be more helpful if it provided specific suggestions on how to define the contrastive gap or examples of what a clear definition might entail. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that other baselines, such as those discussed in related work [29, 5, 6], should also be included. It implies that the authors should consider adding these baselines to their study. However, the comment does not provide explicit guidance on which specific baselines to include or how to integrate them into the paper. While the action is implicit, it is somewhat vague as it lacks concrete details on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those discussed in related work [29, 5, 6], and implies that this would enhance the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, referencing specific works from the related work section. The reviewer acknowledges that the authors have addressed their concerns in the response, which is a positive step. However, the comment lacks specific reasoning or examples to support why these additional baselines are necessary or how they would enhance the paper. This makes the claim 3, as it provides a general suggestion but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including other baselines, such as those discussed in related work, would enhance the paper. It acknowledges that the authors have addressed the reviewer\"s concerns in their response, which is a positive step. However, the comment could be more helpful if it provided specific examples of additional baselines or detailed guidance on how to integrate them into the paper. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a discrepancy between the task loss being referred to as \"L_task\" in the text and \"L_class\" in Figure 1. This is a clear and explicit observation that the authors need to address. The comment provides a specific action for the authors to take, which is to ensure consistency in the naming of the task loss across the text and figures. The feedback is direct and provides clear guidance on what needs to be corrected, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the naming of the task loss, which is clearly identified as \"L_task\" in the text but \"L_class\" in Figure 1. This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistency in the naming of the task loss between the text and Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the naming of the task loss between the text and Figure 1. This is a clear and actionable observation that the authors can address to ensure consistency and clarity in their paper. By pointing out this discrepancy, the comment provides a direct and concrete suggestion for improvement, which is highly valuable for the authors. However, the comment could be more helpful if it explained why this inconsistency is important or how it might impact the reader\"s understanding of the paper. Overall, the comment is 5 as it directly addresses a specific issue that can be easily corrected, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about other limitations of the method and specifically asks if the network is shallow in the graph case. While it implies that the authors should address these limitations, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss additional limitations and potentially address the depth of the network. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about other limitations of the method and specifically asks if the network is shallow in the graph case. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional information on limitations and the depth of the network, but without clear grounding, the authors may struggle to determine where to address these points. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on other limitations of the method and whether the network is shallow in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. While it prompts the authors to consider additional limitations, it does not provide specific suggestions or guidance on how to address these limitations or improve the depth of the network. The comment lacks depth and actionable feedback, leaving the authors with only a general direction for improvement. Therefore, it is 3, as it identifies an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. While the comment implies that the authors should consider adding machine translation evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"answer generation and summarization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. This provides clear guidance on what the authors need to address to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. The reviewer provides a logical reasoning by contrasting the tasks used in the paper (answer generation and summarization) with machine translation, suggesting that the latter would provide a more rigorous evaluation. However, the comment lacks specific references or examples to support the claim about the lower uncertainties in machine translation. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are closer to \"open domain\" generation rather than \"close domain\" tasks like machine translation. The reviewer suggests that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" task with lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation of the proposed method. However, it could be more helpful if it offered additional guidance on how to conduct the machine translation evaluation or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address these questions by including the requested details in their draft. The action is implicit but concrete, as the authors know exactly what information is needed to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the dropout\" and \"the reading of the response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the dropping rate and the number of masks generated. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout process, specifically asking for the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the dropout process, seeking clarification on the dropping rate and the number of masks generated. While it identifies a gap in the explanation of the dropout method, it does not provide suggestions or guidance on how the authors might address these questions or improve their explanation. The comment is 3 as it points out a lack of clarity, but it lacks actionable feedback or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks information about the type of GPUs used and the inference time during testing. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of information about the type of GPUs used and the inference time during testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: the type of GPUs and inference time during testing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information about the type of GPUs used and the inference time during testing. This is a factual statement that does not require verification or justification. It is a request for additional information to be included in the paper, which is a normal statement and not a claim. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a clear and actionable piece of feedback that can help the authors improve their draft by providing crucial details that could impact the reproducibility and understanding of their results. However, the comment could be more helpful if it suggested where this information should be included or how it might affect the interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, suggesting that it may only attend to neighboring nodes based on the description of N_l^(s) in equation 2. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or clarify the issue, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its question about the attention mechanism, but without explicit references to sections or equations, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. This is a claim that requires verification, as it suggests a limitation or misunderstanding in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lowerlevel representation. It references equation 2 and the description of N_l^(s) to support the question. While the comment identifies a potential area of confusion or misunderstanding, it does not provide specific guidance or suggestions on how the authors might clarify or address this issue. The feedback is 3 as it prompts the authors to reconsider their explanation of the attention mechanism, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests including the bottomup method [9] in the tables, as it has reported results on the crowdpose dataset outperforming all methods, including the paper\"s method, with a ResNet50. Additionally, the reviewer suggests evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide concrete guidance on what the authors should do to improve their draft. The reviewers clearly specify which methods to include and what additional evaluations to conduct, making the feedback 5.", "grounding_specificity_rationale": "The comment suggests including the bottomup method [9] in the tables and evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. However, it does not specify which part of the paper these suggestions pertain to, such as which tables or sections should include the additional information. This lack of explicit grounding makes it difficult for the authors to identify the exact parts of the paper that need revision. The comment is specific in suggesting the inclusion of the bottomup method and the evaluation on the MS coco dataset, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the bottomup method [9] in the tables and evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. The claim is 3 as it provides a specific reference to the bottomup method [9] and suggests a comparison with the paper\"s method on the crowdpose dataset. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the drop in performance on the MS coco dataset. The authors would need to conduct additional analysis to verify the claim, making it 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method [9] in the tables, as it has reported results on the crowdpose dataset outperforming all methods, including the paper\"s method, with a ResNet50. This recommendation is clear and could help the authors improve the comprehensiveness of their results. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. This additional evaluation could provide valuable insights into the robustness of the method. The feedback is detailed and offers concrete steps for improvement, making it 5 for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of demonstration of potential weaknesses in the proposed model. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what specific weaknesses should be considered or how they might be demonstrated. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the authors did not demonstrate the possible weaknesses of the proposed model. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis where weaknesses should have been discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what specific weaknesses should have been addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not demonstrate the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that the authors did not demonstrate the possible weaknesses of the proposed model. This is a critical area for improvement, as understanding and addressing potential weaknesses is essential for the robustness and credibility of a model. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights an important area for improvement but does not offer sufficient guidance to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to highlight the advantages or differences of the proposed method, such as the difference from BGLN. While the comment implies that the authors should expand the related work section, it does not provide specific guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, specifically mentioning the need for more work on GLN to highlight the advantages or differences of the proposed method. However, it does not specify which part of the introduction is insufficient or where the additional work on GLN should be included. The authors can infer that it relates to the related work section, but the comment lacks full grounding as it does not explicitly mention the section. It is specific in suggesting what needs to be addressed, such as highlighting the differences from BGLN. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment lacks specific examples or references to support this claim, such as which aspects of GLN are missing or how the proposed method differs from BGLN. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. This feedback is 3 as it points out a weakness in the paper and provides a direction for improvement by recommending a focus on GLN. However, the comment lacks detailed guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. While it offers a starting point for improvement, it could be more helpful with additional specificity and actionable suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This comment implies that the authors should provide a justification or explanation for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout gets multiple parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the hyperparameters, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout gets multiple parameters. This is a factual observation that does not contain an opinion, claim, or suggestion requiring verification. It is a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout gets multiple parameters. This is a relevant observation that could prompt the authors to clarify their methodology or provide a justification for their choice. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks depth and actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter. However, it does not specify what aspects of the design need optimization or how to validate it. The comment lacks concrete guidance on how the authors should proceed with these actions, leaving them with a vague understanding of what needs to be done. As a result, the comment is barely actionable, as the authors are not provided with clear steps to improve their draft.", "grounding_specificity_rationale": "The comment addresses the binder design provided by ProtPainter, suggesting that further optimization and validation are required. However, it does not specify which part of the paper discusses this design, making it weakly grounded. The comment is specific in its request for further optimization and validation, but without clear references to the paper, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"ProtPainter just provides an empirical conformation estimation\" and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current estimation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the binder design provided by ProtPainter, noting that it is limited to an empirical conformation estimation. It suggests that further optimization and validation are necessary, which is a clear and actionable piece of feedback. However, the comment does not provide specific guidance on how to optimize or validate the design, nor does it offer examples or references to support the claim. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for enhancement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that additional evaluation, particularly on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional evaluations but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be welcome, particularly on CIFAR10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be added to, making it weakly grounded. The comment is specific in suggesting a particular scenario for evaluation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation would be welcome, particularly on CIFAR10 in the full label and lower label scenarios. However, it does not provide any specific reasoning or evidence to support why this additional evaluation is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in the full label and lower label scenarios. This feedback is 3 as it identifies a specific area where the authors could enhance their work by providing additional evaluation. However, the comment lacks depth and does not offer specific guidance on what aspects of the evaluation should be focused on or how to conduct the additional analysis. While it points out a potential improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues, starting with a comment about the placement of the algorithm at the end of the paper, suggesting it might be counterintuitive. It also questions the application of the algorithm with one or two iterations and asks about larger T values. Additionally, it points out a lack of reference to Laplacian eigenmaps in Line 224 and the absence of a citation in the introduction. The comment provides explicit actions for the authors to take, such as clarifying the application of the algorithm and referencing Laplacian eigenmaps. However, it lacks concrete guidance on how to address these issues, such as specific suggestions for clarifying the algorithm\"s application or examples of relevant references. Therefore, the comment is 4, as it identifies areas for improvement but does not provide detailed instructions on how to implement the changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and figures in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the placement of the algorithm, the application of the algorithm with different iterations, the lack of reference to Laplacian eigenmaps, and the absence of a citation in the introduction. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises several claims, each of which requires verification. The first claim about the placement of the algorithm at the end of the paper is not supported by any reasoning or evidence, making it difficult for the authors to understand the basis of the critique. The second claim about the application of the algorithm with one or two iterations and the question about larger T values lacks specific examples or references to support the assertion. The third claim regarding the lack of reference to Laplacian eigenmaps and its absence in the introduction is 3, as it points out a potential oversight but does not provide detailed reasoning or references to substantiate the claim. The fourth claim about Figure 4 is not a claim but a request for clarification. Therefore, the overall comment is a mix of claims and requests, with some parts being verifiable and others not. Overall, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several actionable points for improvement. It questions the placement of the algorithm at the end of the paper, suggesting it might be counterintuitive, and asks for clarification on the application of the algorithm with one or two iterations and what happens for larger T values. This feedback prompts the authors to reconsider the presentation of their algorithm and its application, which could enhance the clarity and understanding of their work. Additionally, the comment points out the lack of reference to Laplacian eigenmaps in Line 224 and the absence of a citation in the introduction, which is a critical oversight that the authors need to address. The comment is 4 as it identifies specific areas for improvement and provides clear guidance on how to enhance the draft, but it could be more comprehensive by offering suggestions on how to address these issues. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and focus more on the motivation and intuition for CBN, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should restructure the content to better align with the paper\"s focus. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, questioning the inclusion of Batch Normalization as a general technique and suggesting that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. The comment provides a logical reasoning by pointing out that Batch Normalization is a general technique, which implies that the section might not be necessary. However, it lacks specific examples or references to support the claim that the time spent on describing the ResNet architecture could be better utilized. This makes the claim 3, as it provides a logical basis but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. It highlights a potential redundancy in the content and offers a constructive suggestion for improving the paper by focusing more on the motivation and intuition for the proposed method. While the comment identifies a specific area for improvement, it could be more helpful if it provided additional guidance on how to restructure the content or what specific aspects of the proposed methodology should be emphasized. Overall, the feedback is 3 as it points out a potential issue and offers a direction for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. The reviewer suggests that multiplying by a dense matrix would not lead to sparsity, implying that the authors need to clarify their reasoning. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue or clarify their explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional explanation or justification for the sparsity assumption. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122\" and \"equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the logic behind assuming a dense projection matrix would result in a sparse matrix, providing a clear direction for the authors to clarify their explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logic behind assuming a dense projection matrix would result in a sparse matrix, suggesting that multiplying by a dense matrix would not lead to sparsity. The comment provides a logical reasoning by pointing out the contradiction between the assumption and the expected outcome. However, it does not include specific references or examples to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. It points out a potential contradiction in the authors\" reasoning, which is a valuable observation that could help the authors clarify their assumptions and explanations. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization should be more carefully stated, as initialization plays a role in the context of NGD, which is a discretization of NGF. The reviewer references a specific paper by Kunstner et al. (2019) to support this claim. While the comment implies that the authors should revise their statement on initialization, it does not provide explicit guidance on how to make the statement more accurate or detailed. The reference to the external work is a helpful starting point, but the authors still need to determine how to apply this information to their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Initialization\" and \"NGD,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, particularly in relation to NGD being a discretization of NGF and the role of initialization as a pretraining step. The comment provides a reference to a specific paper by Kunstner et al. (2019) to support the claim, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Initialization does play a role NGD is a discretization of NGF. Solving NGF is an initial value problem (IVP) in this setting. Thus, initialization should play a role such as pretraining.\" The reviewer supports this claim by referencing a specific paper by Kunstner et al. (2019), which provides a detailed explanation of the role of initialization in the context of NGD and NGF. This reference is a clear and explicit source of evidence, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the statement about initialization. It provides a logical reasoning by connecting the role of initialization in the context of NGD, which is a discretization of NGF, and the fact that solving NGF is an initial value problem (IVP). The comment suggests that the statement about initialization should be more carefully stated, potentially by considering pretraining as a role for initialization. This feedback is clear and actionable, as it directs the authors to reconsider their statement and potentially expand on the role of initialization. However, the comment could be more helpful if it included specific suggestions or examples of how to improve the statement. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the extraction of named entities from the datasets is unclear and recommends an Englishproofreading to improve the readability of the paper. While the comment implies that the authors should clarify the extraction process, it does not provide specific guidance on how to do so or what aspects of the extraction method need clarification. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of named entity extraction from datasets and suggests an Englishproofreading to improve readability. However, it does not specify which part of the paper discusses the extraction process, making it weakly grounded. The comment is specific in suggesting an Englishproofreading, but it lacks detailed guidance on what aspects of the extraction process need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the extraction of named entities from datasets is unclear and suggests an Englishproofreading to improve readability. However, it does not provide any specific examples, reasoning, or references to support the claim about the clarity of the extraction process. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of named entity extraction from datasets. It suggests that an Englishproofreading could improve the readability of the paper. While the comment highlights a potential issue, it lacks depth and does not provide detailed guidance or suggestions on how to improve the clarity of the extraction process. The feedback is 3 as it points out a specific area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the definition of L and E, noting that they should be defined in the immediate vicinity and that their formatting is inconsistent. While the comment identifies a clear action for the authors to take\u2014define L and E in the immediate vicinity and ensure consistent formatting\u2014it does not provide detailed guidance on how to implement these changes. The authors know what needs to be done but may need to infer the exact steps to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the definition and formatting of L and E, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue with the formatting and definition of L and E in the paper. It notes that these terms should be defined in the immediate vicinity and that their formatting is inconsistent. However, the comment does not provide any reasoning or evidence to support why this inconsistency is problematic or how it affects the clarity or understanding of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting and definition of L and E in the paper, noting that they should be defined in the immediate vicinity and that their formatting is inconsistent. This feedback is clear and actionable, as it directs the authors to clarify the definitions and ensure consistent formatting throughout the paper. By addressing these issues, the authors can improve the clarity and readability of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively define and format these terms. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should include additional comparisons, it does not specify which models or techniques should be considered or how to implement these comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific models and techniques to include and how to conduct the comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be considered. This lack of specificity and grounding makes it difficult for the authors to identify where these comparisons should be added or what specific models or techniques should be included. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support the claim that these comparisons would be beneficial or necessary. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to broaden their comparisons. However, the comment lacks specificity and does not provide guidance on which models or techniques should be considered or how to conduct these comparisons. While it points out a direction for enhancement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment consists of a series of grammatical corrections and clarifications. Each correction is explicit and provides clear guidance on how to modify the text, making the actions concrete. The authors know exactly what changes to make to improve the clarity and correctness of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment consists of a series of grammatical corrections and clarifications, each of which is specific and actionable. However, it does not provide any context or grounding for where these corrections are needed in the paper. The authors may have to search through the document to identify the specific lines mentioned, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of grammatical corrections and clarifications, which are factual and do not require verification. It does not contain subjective opinions, claims, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of grammatical corrections and clarifications, which are important for the clarity and correctness of the manuscript. Each correction is specific and actionable, guiding the authors on how to improve the language and grammar of their paper. However, the comment does not offer any broader insights or suggestions for improving the content or methodology of the paper. While it is helpful in terms of language and grammar, it lacks depth and does not provide comprehensive feedback for enhancing the overall quality of the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to. It also mentions a mistake in equations, but it does not specify which equations or what the mistake is. The comment lacks explicit guidance or concrete suggestions on how to address the issue, leaving the authors uncertain about what actions to take. The action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions \"W4 \u2013 Mistakes in Eqs,\" which provides some grounding as it implies that the issue is related to equations in the paper. However, it does not specify which equations are incorrect or what the specific mistake is, making it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in identifying a potential issue with equations but lacks full grounding because it does not explicitly mention the section or page where the equations are located. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a factual question that does not contain an opinion, claim, or suggestion requiring verification. It is purely descriptive and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a clear and specific observation that could help the authors clarify a potential misunderstanding in their work. However, the comment does not provide any guidance on how to address this issue or suggest ways to improve the clarity of the equation. While it identifies a potential area for improvement, it lacks actionable feedback or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to conduct the comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. While the comment is specific in suggesting a comparison, it is 1 because it does not clearly indicate where this comparison should be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. However, the comment lacks specific evidence, examples, or references to support the claim that the method performs better in combinational logic or that it would be easier to model without staterelated registers. The suggestion for a comparison is logical but requires further elaboration or evidence to be 5. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs, which could provide valuable insights into the method\"s applicability and efficiency. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for exploration, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it points out a relevant area for further investigation but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to conduct a specific analysis or provide detailed guidance on how to address this curiosity, it does imply that the authors should consider evaluating the performance of this baseline. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section\" and the \"baseline\" that combines LDA and LSTM, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of the baseline in terms of the topic switch percent metric, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not provide specific suggestions for improvement or critique the methodology, it does prompt the authors to consider an important aspect of their experiment. This feedback encourages the authors to explore and report on a specific metric, which could enhance the comprehensiveness and depth of their analysis. However, the comment lacks depth and does not offer actionable guidance for improvement. Therefore, it is 3, as it provides a direction for the authors to consider but does not fully address their needs for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient evidence to support the claim about the synergies between DQD and PPO. It specifically points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using onpolicy RL better fitting the DQD framework. While the comment identifies a specific issue and suggests a comparison that should be included, it does not provide explicit instructions on how to address the issue or conduct the comparison. The action is implicit and somewhat vague, as the authors know they need to provide more evidence and include a comparison to TD3GA, but they are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, specifically questioning the lack of evidence and mentioning the TD3GA algorithm. However, it does not explicitly mention which part of the paper discusses these synergies or where the TD3GA algorithm is mentioned, if at all. The authors can infer that it relates to the methodology or results sections, but this inference is not straightforward. The comment is specific in pointing out the lack of evidence and the importance of the TD3GA algorithm, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up, specifically noting the absence of mention of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA is crucial to understand these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion and suggests a specific comparison that could strengthen the argument. However, the comment lacks detailed reasoning or references to support the claim fully, making it 3. The authors would need to address the gap themselves to fully understand and improve the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using onpolicy RL better fitting the DQD framework. This feedback is clear and actionable, as it highlights a gap in the paper\"s discussion and provides a specific direction for improvement. By addressing this issue, the authors can strengthen their argument and enhance the comprehensiveness of their work. Therefore, the comment is 4, as it offers valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a slight confusion regarding the use of the word \"confident\" in the context of ceterus paribus convexity. It suggests that the author might be referring to human interpretability rather than model confidence, and recommends a slight rephrasing to clarify this point. While the comment identifies a potential issue and suggests a specific action (rephrasing), it does not provide detailed guidance on how to rephrase the sentence. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely sure of the exact wording. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"We have found it easier to be confident about applying ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential confusion regarding the use of the word \"confident\" and suggests that it might refer to human interpretability rather than model confidence. The comment provides a clear suggestion for rephrasing to clarify this point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a logical reasoning by questioning the intended meaning of the word \"confident,\" which helps clarify the issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the suggestion to rephrase the sentence to clarify the intended meaning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confusion in the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. It provides a clear suggestion for rephrasing the sentence to clarify this point, which is a valuable contribution to the authors\" understanding and clarity of their work. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in making the necessary changes. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with finetuning are expected due to the nature of taskspecific finetuning, which increases confidence for a specific task but potentially reduces generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take in response to this feedback. It lacks guidance on how the authors might address the perceived lack of novelty or improve their work based on the observation. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with finetuning are expected due to the nature of taskspecific finetuning. However, the comment does not specify which part of the paper discusses these findings or observations, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides a logical explanation for the limited novelty, it lacks specificity in terms of what aspects of the paper could be improved to enhance the novelty. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, citing observations like tighter CIs with finetuning as expected due to the nature of taskspecific finetuning. The comment provides a logical explanation for why these observations are expected, which is based on common knowledge about the effects of finetuning on confidence and generalizability. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct additional research to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with finetuning are expected due to the nature of taskspecific finetuning, which increases confidence for a specific task but potentially reduces generalizability. However, the comment does not offer any specific suggestions or guidance on how the authors might enhance the novelty or address the limitations identified. While it provides some insight into the expected outcomes of finetuning, it lacks actionable feedback that could help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential limitation but does not provide detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. While it highlights an area of potential interest, it does not provide explicit guidance or suggestions for the authors to address this question or improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore or discuss real scenarios where the proposed objective differs from classical prediction accuracy. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the applicability of the proposed objective, but it lacks grounding as it does not reference any particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. It does not contain a claim or opinion but rather seeks clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. This is a valid inquiry that could help the authors clarify the practical relevance and applicability of their proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their draft. It lacks actionable feedback, leaving the authors with only a vague idea of what needs to be explored. Therefore, the comment is 2, as it identifies a potential area of interest but does not offer specific guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation in the paper, including the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests that the evaluation is not comprehensive and lacks generalizability. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific steps the authors should take to enhance the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details about the experiment setup and consider using multiple datasets, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. This provides clear guidance on what needs to be addressed to improve the evaluation. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. Additionally, it points out that relying on a single dataset may limit the generalizability of the results. These claims are supported by logical reasoning, as the lack of transparency and exploration of different scenarios could impact the comprehensiveness and validity of the evaluation. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies several weaknesses in the evaluation section of the paper, specifically noting the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. This feedback is clear and actionable, as it highlights specific areas where the authors can improve the comprehensiveness and transparency of their evaluation. By addressing these points, the authors can enhance the robustness and generalizability of their results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending the use of multiple datasets or providing guidance on how to present the experiment setup more transparently. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not provide any guidance on how the authors should incorporate these references or what specific aspects of the related work should be addressed. The action is implicit and lacks concrete details on how to implement the suggestion, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on what aspects of the related work should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or justification for why these specific references are relevant or how they could enhance the paper. Without further explanation or context, the authors may find it challenging to understand the importance of these references or how to incorporate them into their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors should incorporate these references or what aspects of the related work should be addressed. The feedback is 3 as it points out a gap in the paper, but it does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the algorithm should be explored. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the algorithmic aspects but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not specify which part of the paper should have included this focus or where the algorithmic aspects are currently lacking. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is vague and lacks specificity, making it 1 and not specific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue. It does not offer suggestions on which algorithmic aspects should be explored or how to enhance the novelty of the paper. As a result, the feedback is 3, as it points out a weakness but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors could improve their paper by making the comparisons between the present work and the related work of Zemel et al. (2013) more systematic. Specifically, it recommends comparing the best performance of each method to provide a more comprehensive evaluation. While the comment implies an action\u2014making the comparisons more systematic\u2014it does not provide explicit guidance on how to achieve this, such as suggesting specific metrics or analysis methods to use. The action is concrete in terms of the desired outcome but lacks detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the related work of Zemel et al. (2013) and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons more systematic with respect to the tuning of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method. It references the work of Zemel et al. (2013) as a related work and suggests that the present paper should compare the best performance of each method. However, the comment lacks specific examples or detailed reasoning on how the current comparisons could be improved or what specific aspects need to be addressed. This makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the comparisons between the present work and the related work of Zemel et al. (2013) could be made more systematic. It provides a clear and actionable suggestion to compare the best performance of each method, which would enhance the paper\"s originality and clarity. However, the comment could be more helpful if it offered additional guidance on how to conduct these systematic comparisons or what specific metrics or analyses could be used. Despite this, the feedback is 4 as it directs the authors to a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider connecting the third point of definition one to the properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not provide explicit instructions on how to make this connection or what specific aspects of the universal kernels should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a connection between the third point of definition one and the properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides a specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this connection might be made, which would align it with a score of 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and the properties of universal kernels, as discussed in chapter 4 of Steinwart and Christmann. This feedback is 3 as it points out a possible area for further exploration or enhancement of the paper. However, the comment lacks specific guidance on how to make this connection or what aspects of the universal kernels should be considered. While it provides a direction for the authors to consider, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
