{"generated_text": "{'actionability_rationale': 'The review comment questions the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or element-wise max, which seem to correspond to the ideas of union and intersection from the \"or\" operator and element-wise min. While the comment raises a valid point about the rationale behind the operator choices, it does not provide explicit guidance on what the authors should do to address this issue. The authors are left to infer that they should provide a justification for their operator choices, but without specific suggestions or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or element-wise max, which seem to correspond to the ideas of union and intersection from the \"or\" operator and element-wise min. This provides clear guidance on what aspect of the paper needs clarification or justification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or element-wise max, which seem to correspond to the ideas of union and intersection from the \"or\" operator and element-wise min. The comment highlights a lack of clarity in the rationale behind the chosen operators, suggesting that the authors should provide justification for their choices. However, the comment does not provide any specific reasoning or evidence to support why these alternative operators might be better options, making it somewhat verifiable. The authors would need to further explore the rationale themselves to address the comment effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of operators used in the paper, specifically questioning why the authors did not consider the \"and\" operator or element-wise max, which seem to correspond to the ideas of union and intersection from the \"or\" operator and element-wise min. This feedback is valuable as it prompts the authors to provide a rationale for their operator choices, which could enhance the clarity and justification of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how the alternative operators might be applied. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential inconsistency in the description of the data used in the paper, specifically regarding the selection of sentences from raw data versus data with syntactic information. The reviewer suggests that the authors revise the description to clarify and make it precise, possibly by mentioning Li et al. (2019a) earlier. This feedback provides a clear and explicit action for the authors to take, as it specifies exactly what needs to be revised and how to improve the clarity of the description. The comment is highly actionable because it offers concrete guidance on how to address the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (226-238 and 242-244), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the description of the data selection process, suggesting that the authors revise the description to clarify and make it precise. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the description of the data used in the paper, specifically questioning the selection process and the presence of syntactic information. The reviewer provides a logical reasoning by pointing out the apparent contradiction between lines 226-238 and 242-244, suggesting that the description could be revised to clarify the source and nature of the data. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the issue to fully understand and address the concern, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the description of the data used in the paper, specifically regarding the selection of sentences from raw data versus data with syntactic information. It suggests that the authors revise the description to clarify and make it precise, possibly by mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and accuracy of their manuscript. By addressing this point, the authors can enhance the transparency and precision of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the purpose of the average duration reported in Table 1 and notes the lack of supporting explanation. It also asks whether this duration includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide an explanation or clarification about the average duration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and asks whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the purpose and content of the average duration reported in Table 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of supporting explanation. It also inquires whether this duration includes time spent by the user waiting for the model to generate a response. This feedback is somewhat helpful as it identifies a specific area where the paper lacks clarity and suggests a potential aspect that needs further explanation. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their explanation. To be more helpful, the comment could include recommendations on how to clarify the purpose or content of the average duration. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Chinese and English MOS-V between Baseline and NVSB. While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the interpretation of these results, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the interpretation of certain results, such as the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Chinese and English MOS-V between Baseline and NVSB. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the interpretation of results shown in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Chinese and English MOS-V between Baseline and NVSB. While the comment identifies areas of potential confusion, it does not provide any suggestions or guidance on how the authors might address these issues or clarify the results. The feedback is limited to pointing out the need for clarification, which offers some insight but lacks actionable advice. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This affects the overall appearance of the tables. The comment explicitly identifies the problem and suggests that the authors should ensure consistency in formatting across all items in the tables. However, it does not provide specific guidance on how to achieve this consistency, such as whether the spaces should be removed or added. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent spacing between accuracy and standard deviation, which affects the beauty of the tables. This provides clear guidance on what needs to be addressed to improve the presentation of the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the beauty of the tables. However, it does not provide any reasoning or evidence to support why this inconsistency is problematic or how it affects the tables\\' appearance. Without additional context or explanation, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This inconsistency affects the overall appearance of the tables. While the comment points out a minor aesthetic issue, it does not provide any guidance on how to address it or why it might be important. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable suggestions, making it difficult for the authors to fully understand the impact or how to resolve the issue. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take, including checking the antecedent for \"both tasks\" and ensuring proper formatting of references, such as capitalization and bibliographic details. These instructions are clear and concrete, giving the authors specific tasks to address. The comment is highly actionable as it provides direct guidance on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"781\" and the phrase \"both tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, including checking the antecedent for \"both tasks\" and ensuring proper formatting of references, such as capitalization and bibliographic details. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the missing antecedent and a suggestion to check the formatting of references. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying a missing antecedent in the text and suggesting that the references should be checked for format, such as capitalization and bibliographic details. This guidance is clear and directly addresses issues that can improve the clarity and professionalism of the manuscript. By pointing out these specific areas for correction, the comment empowers the authors to make precise improvements to their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations in Section 3.2 are intertwined and confusing, and recommends organizing the section more coherently by dedicating separate paragraphs to each of the lexical features and sentence-level features. This feedback provides a clear and explicit action for the authors to take, specifying exactly how to improve the organization of the section. The comment is specific and provides concrete guidance on how to implement the suggested changes, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations being intertwined and suggests a solution by recommending separate paragraphs for lexical features and sentence-level features. This provides clear guidance on how to improve the organization of the section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations in Section 3.2 are intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs for lexical features and sentence-level features. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is confusing or how the suggested changes would improve clarity. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the specific issues and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It provides a clear and actionable suggestion to improve the clarity by dedicating separate paragraphs to each of the lexical features and sentence-level features. This feedback is constructive and offers a concrete way for the authors to enhance the coherence and readability of their section, making it mostly helpful. However, it could be more helpful if it included additional guidance on how to structure the paragraphs or examples of what information should be included in each. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the abstract is well-written and intriguing but suggests that it could be improved by providing an example of inconsistency between evaluating with gold answers and human evaluation. The reviewer explicitly states that an example of the inconsistency, such as models getting ranked differently, should be included. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to enhance the abstract. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an improvement by providing an example of inconsistency between evaluating with gold answers and human evaluation, which could enhance the abstract. The comment offers a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the abstract is well-written and intriguing but suggests that it could be improved by providing an example of inconsistency between evaluating with gold answers and human evaluation. The reviewer supports this suggestion by mentioning that models might get ranked differently, which is a specific example of the inconsistency. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the claim fully. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the abstract is well-written and intriguing, which is a positive observation. However, it also suggests an area for improvement by pointing out that the abstract could be enhanced by providing an example of inconsistency between evaluating with gold answers and human evaluation. This feedback is actionable as it offers a specific suggestion for improvement, which is to include an example of the inconsistency, such as models getting ranked differently. By providing this guidance, the comment helps the authors understand how to enhance their abstract, making it mostly helpful. However, it could be more comprehensive by explaining why this inconsistency is important or how it impacts the overall understanding of the paper. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. The comment is clear and provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (681 and 778) and refers to specific elements of the paper, such as the task of inferring knowledge on objects and the model (B). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, including discussing results for the task of inferring knowledge on objects and using consistent terminology for the model in Tables 1 and 2. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and using consistent terminology for the model in Tables 1 and 2. It does not contain subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out two areas for improvement. First, it suggests discussing the results for the task of inferring knowledge on objects, which is a clear and direct recommendation for enhancing the paper. Second, it advises using consistent terminology for the model in Tables 1 and 2, which would improve clarity and consistency in the paper. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs,\" prompting the authors to consider this aspect. The comment is detailed and offers concrete suggestions, making it highly helpful for the authors to improve their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific sentence in the paper that is not strictly correct and provides a clear and concrete suggestion for how to correct it. The reviewer explains that the sentence should be revised to reflect that a bidirectional encoder is used to encode the source sentence into a set of vectors, as shown in Figure 2. This feedback is direct and provides precise guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 212\" and \"Figure 2,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected in the sentence, suggesting that a bidirectional encoder should be used instead of a single vector. This provides clear guidance on how to improve the accuracy of the statement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in line 212 is not strictly correct and suggests a correction. The reviewer provides a specific alternative phrasing (\"bidirectional encoder that encodes the source sentence into a set of vectors\") and references Figure 2 to support their claim. This detailed explanation and reference to a specific figure provide a clear and robust justification for the claim, making it fully verifiable. The authors can easily understand and address the issue based on the provided information.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying a grammatical error in the paper and suggesting a correction. It points out that the sentence in line 212 is not strictly correct and offers a clear alternative phrasing to improve the accuracy of the statement. This guidance is valuable as it helps the authors correct a potential misunderstanding in their manuscript, enhancing the clarity and precision of their writing. The comment is highly helpful as it directly addresses a specific issue and offers a concrete solution, empowering the authors to make a meaningful improvement to their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: the lack of comparison with Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It also points out a grammatical error. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to include comparisons with Campos et al. (2020) and other domain adaptation methods, but the comment lacks concrete guidance on how to implement these comparisons. The grammatical correction is straightforward, but the other points are vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the baseline models and a particular line number (277), allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the baseline models, including the lack of comparison with Campos et al. (2020) and other domain adaptation methods, and provides a grammatical correction. This level of detail helps the authors understand what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak, providing two reasons: the lack of comparison with Campos et al. (2020) and the absence of comparison with other domain adaptation methods. The comment supports the claim by referencing specific works, which adds to its verifiability. However, it could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. As it stands, the claim is mostly verifiable, as it provides a basis for the critique but lacks comprehensive evidence or examples. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it points out that the adopted baseline models are weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. Second, it notes the absence of comparison with other domain adaptation methods, such as those cited in Section 8. Additionally, it provides a grammatical correction. While the comment highlights important areas for improvement, it could be more helpful by offering specific suggestions on how to incorporate these comparisons or by providing examples of relevant domain adaptation methods. Overall, the feedback is somewhat helpful as it directs the authors to important aspects of their work that need attention, but it lacks detailed guidance on how to address these issues.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and specific action that the authors can take to improve their draft. The comment provides a concrete suggestion, leaving no ambiguity about what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the suggestion to use \"Exact Match ratio\" directly as the y-axis label. This provides clear guidance on how to improve the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. This is a specific and actionable suggestion, but it does not provide any reasoning or justification for why this change is necessary or how it would improve the figure. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the clarity of Figure 5 by recommending the use of \"Exact Match ratio\" as the y-axis label. This feedback is clear and directly addresses a potential issue with the figure\\'s labeling, which can help the authors enhance the readability and accuracy of their presentation. However, the comment could be more helpful if it explained why this change is necessary or how it would benefit the understanding of the figure. Despite this, the suggestion is actionable and provides a clear path for improvement, making the comment mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of strong baselines in Table 3, specifically mentioning the need for comparison with baselines from reference [1]. While the comment implies that the authors should justify the reason for not including these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what kind of justification is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the absence of strong baselines in Table 3, specifically mentioning the need for comparison with baselines from reference [1]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of strong baselines in Table 3, specifically mentioning the need for comparison with baselines from reference [1]. This is a request for clarification or justification, rather than a subjective claim or opinion. It does not express an opinion or require verification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting the absence of strong baselines that are not compared with the current results. It references a specific source, [1], which suggests that the authors should justify the reason for not including these baselines. This feedback is clear and actionable, as it directs the authors to provide a rationale for their choice of baselines, which could enhance the comprehensiveness and validity of their experimental comparisons. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific baselines to consider. Overall, the comment is mostly helpful, as it highlights a critical area for improvement and provides a starting point for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it suggests that the authors should clarify that the input to the Lample et al. Bi-LSTM-CRF model is word embeddings, similar to the original work. This is an explicit and concrete suggestion, providing clear guidance on how to improve the draft. Second, it questions whether the KNs in Figure 3 are in the source language or in English, given that the mentions have been translated to English. This is also an explicit and concrete suggestion, as it asks for clarification on a specific aspect of the figure. Both suggestions are clear and actionable, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed in these sections. The comment suggests adding a clarification about the input being word embeddings, similar to Lample et al., and questions whether the KNs in Figure 3 are in the source language or in English. This level of detail provides clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify that the input to the Lample et al. Bi-LSTM-CRF model is word embeddings, similar to the original work. This claim is somewhat verifiable as it provides a logical suggestion to improve clarity in the paper. However, it lacks specific references or detailed reasoning to fully substantiate the need for this clarification. The second part of the comment, regarding Figure 3, is a factual observation about the language of the KNs, which does not require verification. Overall, the comment provides some support for its claim but lacks detailed justification, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors clarify the input to the Lample et al. Bi-LSTM-CRF model, specifying that it is word embeddings, similar to the original work. This is a clear and actionable suggestion that can help improve the clarity and accuracy of the paper. Second, it questions whether the KNs in Figure 3 are in the source language or in English, given that the mentions have been translated to English. This feedback is also actionable, as it prompts the authors to verify and correct the figure. Both pieces of feedback are specific and provide clear guidance for improvement, making the comment highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the text in lines 102-106, stating that it is misleading. However, it does not provide any guidance on how to correct this issue or what specific changes should be made to clarify the text. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the identified problem. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is that the statement \"such distribution\" is misleading because it cannot refer to the discussion in the above lines. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading because the phrase \"such distribution\" cannot refer to the discussion in the above lines. However, the comment does not provide any specific reasoning or evidence to support why this reference is misleading or how it affects the understanding of the text. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the text in lines 102-106, stating that the phrase \"such distribution\" is misleading because it cannot refer to the discussion in the above lines. This feedback is clear and actionable, as it points out a potential misunderstanding in the paper that the authors can address to improve clarity. However, the comment could be more helpful if it provided suggestions on how to correct the misleading statement or offered additional context to clarify the intended meaning. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing revision, but it could be more comprehensive with further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims need further analysis or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims require more attention and how to proceed with the analysis. Without explicit instructions or examples, the authors may struggle to determine the necessary steps to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims or sections of the paper are being referred to, making it difficult for the authors to identify the exact parts that need improvement. Additionally, the comment lacks specificity regarding what aspects of the claims require further analysis or how the analysis should be conducted. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a number of claims from this paper would benefit from more in-depth analysis.\" However, it does not specify which claims are being referred to or provide any reasoning or examples to support this assertion. Without specific details or evidence, the authors may find it challenging to understand which claims need further analysis and why. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the paper, noting that several claims would benefit from more in-depth analysis. However, it lacks specificity and does not provide any guidance or suggestions on which claims need further analysis or how the authors might conduct this analysis. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two areas that need improvement in the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It provides specific questions and observations that the authors need to address, such as the type of pooling method used and the definition of E_i in Equation (7). The comment also suggests that the left-hand side (LHS) of Equation (7) should be a conditional probability. These explicit and concrete suggestions provide clear guidance on what the authors need to clarify or revise in their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and equations in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, such as the pooling method used for embedding features and the clarity of Equation (7), including the definition of E_i and the nature of the left-hand side of the equation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific issues regarding the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). The reviewer questions whether E_i represents the type or identity of AC i, and suggests that the left-hand side of the equation should be a conditional probability. While the comment identifies areas of confusion, it lacks detailed reasoning or references to support these claims. The authors are left to infer the potential issues and how to address them, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas in the presentation of the model that require improvement. It raises questions about the pooling method used for embedding features and the clarity of Equation (7), specifically questioning whether E_i represents the type or identity of AC i. The comment also suggests that the left-hand side of Equation (7) should be a conditional probability. This feedback is clear and actionable, as it provides the authors with precise points to address in order to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of how similar issues have been addressed in other works. Overall, the comment is mostly helpful, as it effectively directs the authors toward specific improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the hypotheses raised in the paper and the actual content discussed. It suggests that the hypotheses are not optimally phrased and could be tested as given, but notes that the paper does not study these hypotheses or mention them again. The reviewer expresses a desire for the paper to delve deeper into the topics, but does not provide specific guidance on how to achieve this. The feedback is somewhat actionable as it identifies an area for improvement but lacks concrete steps or suggestions for the authors to follow. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 078-086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the hypotheses being raised, noting that they are not optimally phrased and could be tested as given. The comment further specifies that the paper does not study these hypotheses or mention them again, which is misleading. Additionally, it suggests that the paper should delve deeper into the respective topics. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper raises hypotheses about multilinguality and country/language-specific bias but does not study or discuss them further. The reviewer suggests that the hypotheses are not optimally phrased and could be tested as given. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed further. Without detailed evidence or reasoning, the claim remains somewhat vague, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically that it raises hypotheses about multilinguality and country/language-specific bias but does not study or discuss these hypotheses further. The reviewer points out that this is misleading and suggests that the paper should delve deeper into these topics. While the comment highlights a critical weakness, it lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it provides insight into a potential area for improvement, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific suggestion for improving the paper by recommending the addition of a baseline smaller PCFG with state size being r, where certain parameters are directly parameterized as learned matrices. The comment explains the rationale behind this suggestion, noting that parsing F-1 might not be directly comparable but that perplexity can still be compared. This feedback is explicit and provides concrete guidance on how to implement the suggested change, making it highly actionable. The authors know exactly what modifications to make and why, ensuring they can effectively apply this feedback to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides a specific suggestion for improving the paper by recommending the addition of a baseline smaller PCFG with state size being r, where certain parameters are directly parameterized as learned matrices. It explains the rationale behind this suggestion, noting that parsing F-1 might not be directly comparable but that perplexity can still be compared. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the suggested improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a baseline smaller PCFG with state size being r, where certain parameters are directly parameterized as learned matrices. The claim is that parsing F-1 might not be directly comparable, but perplexity can still be compared. The comment provides a logical reasoning for the suggestion, explaining the potential impact on comparability. However, it lacks specific examples or references to support the claim fully. This makes the comment somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the addition of a baseline smaller PCFG with state size being r, where certain parameters are directly parameterized as learned matrices. This suggestion is clear and offers a concrete way to enhance the experimental setup, allowing the authors to better compare their results with a smaller, more manageable baseline. The comment also explains why parsing F-1 might not be directly comparable but suggests that perplexity can still be compared, providing additional context for the authors to consider. This level of detail and guidance makes the comment highly helpful, as it empowers the authors to make a meaningful improvement to their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit and concrete action, as it clearly instructs the authors on what additional information to provide. The comment specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely stating the maximum number of tasks done by any annotator. This provides clear guidance on what the authors need to add to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any justification or reasoning for why this information is important or how it would enhance the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the necessity of this addition. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include the maximum number of tasks done by any annotator. While this is a specific and actionable piece of feedback, it does not provide a detailed explanation of why this information is important or how it would enhance the paper. The comment could be more helpful if it explained the potential impact of this information on the study\\'s validity or interpretation. Nonetheless, it offers a clear direction for improvement, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. This is an explicit suggestion, as it directly instructs the authors to add a specific element to their table. The action is clear and concrete, providing the authors with a specific step to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the baseline should be included. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a hard prompt baseline in Table 1 to compare performance increases. However, it does not provide any justification or reasoning for why this inclusion is necessary or beneficial. The comment lacks supporting evidence or explanation, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a hard prompt baseline in Table 1 to compare the performance increase of each method. This feedback is clear and actionable, providing a specific recommendation that can help the authors enhance the comprehensiveness and interpretability of their results. By including the hard prompt baseline, the authors can better demonstrate the effectiveness of their methods and provide a more robust comparison. However, the comment could be more helpful if it explained why this inclusion is important or how it might impact the overall analysis. Despite this, the suggestion is mostly helpful as it offers a concrete step for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing DP algorithms. While the comment implies that the authors should include numerical results and comparisons, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on which algorithms to consider or how to conduct the comparisons. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing DP algorithms. However, it does not specify which part of the paper lacks these numerical results or where the authors should include them. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in terms of what is missing\u2014numerical results and comparisons\u2014but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing DP algorithms. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the lack of numerical results is a significant issue. Without additional context or evidence, the authors may find it challenging to understand the importance of this feedback and how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of numerical results in the paper. It expresses curiosity about how the method could be applied to popular algorithms and how its performance compares with existing DP algorithms. While the comment highlights an important aspect that could enhance the paper, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it directs the authors to a critical area needing attention, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional experiments should be conducted to improve the draft. The suggestion is concrete, as it outlines specific methods and backbones to test, ensuring the authors know exactly how to implement the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion is specific, as it provides a clear direction for additional experiments to be conducted. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental comparisons are insufficient and suggests testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This claim is somewhat verifiable as it provides a logical suggestion for expanding the experimental comparisons, which could enhance the comprehensiveness of the results. However, the comment lacks specific examples or references to support why these wider backbones are relevant or how they would impact the results. Providing more detailed reasoning or evidence would strengthen the claim, making it easier for the authors to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental comparisons, noting that they are insufficient and suggesting that the authors test their proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This feedback is clear and actionable, providing a specific suggestion for expanding the experimental scope to enhance the comprehensiveness of the results. By recommending additional comparisons, the comment offers a concrete way for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it included additional context or rationale for why these comparisons are important, which would elevate it to a highly helpful comment. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It instructs them to correct the callout to table 5, directing it to table 3 instead, and to ensure that the callout to figure 6 is directed properly. These instructions are clear and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements such as \"table 5,\" \"table 3,\" \"page 7,\" \"section 5,\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the callouts to tables and figures. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations about the placement of callouts in the paper, specifically noting that the callout to table 5 should go to table 3 and that the callout to figure 6 is not directing properly. These are descriptive statements without subjective opinions, claims, or suggestions for improvement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out errors in the callouts to tables and figures. It clearly identifies the incorrect callout to table 5, which should instead point to table 3, and notes that the callout to figure 6 is not directing properly. This feedback is precise and allows the authors to make immediate corrections, improving the accuracy and clarity of their manuscript. However, the comment could be more helpful if it included additional context or suggestions on how to ensure proper callouts in the future. Despite this, the feedback is mostly helpful as it directly addresses specific issues that can be easily resolved, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern with the experiments, noting that the paper only reports self-comparisons and lacks an explanation for this choice. It suggests that in a generative setting, comparisons with SketchRNN could be performed. While the comment identifies a specific issue with the experiments and provides a suggestion for improvement, it does not explicitly instruct the authors to make these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide a rationale for their experimental choices. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically mentioning the lack of comparisons with other methods like SketchRNN. This provides full grounding as it clearly identifies the part of the paper being discussed. The comment is also specific, as it points out the issue of only reporting self-comparisons and suggests a potential improvement by including comparisons with SketchRNN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s experiments are limited to self-comparisons and lacks explanation for this choice, which contributes to a poor motivation problem. The reviewer suggests that in a generative setting, comparisons with SketchRNN could be performed. While the comment identifies a specific issue with the experimental design, it does not provide detailed reasoning or examples to support why comparisons with SketchRNN would be beneficial or necessary. The lack of explicit justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s experiments, noting that they are limited to self-comparisons and lack explanation. It suggests that in a generative setting, comparisons with SketchRNN could be performed, which would provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to consider including additional comparisons that could strengthen the paper\\'s experimental section. However, the comment could be more helpful if it provided specific guidance on how to incorporate these comparisons or why they are important. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a constructive suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" and provides specific observations to support this disagreement. The comment suggests that the authors should focus on the performance trends of DeiT-B models compared to DeiT-T and DeiT-S on specific datasets, such as APTOS2019, ISIC2019, and CheXpert. This feedback provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. The comment challenges the authors\\' viewpoint and provides specific observations about the performance of DeiT-B models compared to DeiT-T and DeiT-S on different datasets, suggesting that CNNs provide more consistent model improvements as capacity increases. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" by providing specific observations from Figure 3. It notes that DeiT-B models do not outperform DeiT-T on APTOS2019 and DeiT-S on APTOS2019, ISIC2019, and CheXpert, suggesting that CNNs provide more consistent model improvements as capacity increases. This detailed analysis and specific references to datasets and models provide a robust foundation for the claim, making it fully verifiable. The reviewer\\'s reasoning is clear and supported by concrete evidence, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" by providing specific observations from the figure. The comment highlights that DeiT-B models do not outperform DeiT-T on APTOS2019 and DeiT-S on APTOS2019, ISIC2019, and CheXpert, suggesting that CNNs provide more consistent model improvements as capacity increases. This feedback is clear and constructive, guiding the authors on how to enhance their analysis and potentially revise their conclusions. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. While the comment implies an action, it does not explicitly instruct the authors to make this distinction or provide guidance on how to implement it. The action is inferred and somewhat vague, as the authors need to determine how to differentiate between these types of updates. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This feedback is somewhat helpful as it identifies a potential area for clarification or improvement in the paper. However, the comment lacks depth and does not provide specific guidance on how to implement this distinction or why it is important. Without further elaboration or examples, the authors may find it challenging to fully understand and address the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also expresses interest in the performance of ATT(+H) in Figure 4 and asks for results if the model did not consider relevant attention retrieval from the attention memory. The comment provides clear and specific actions for the authors to take, including conducting an ablation study and analyzing the performance of ATT(+H) under different conditions. The explicit nature of the suggestions and the detailed guidance on what to analyze make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests an ablation study on the visDial dataset and expresses interest in the performance of ATT(+H) in Figure 4, asking for results if the proposed model did not consider relevant attention retrieval from the attention memory. This provides clear guidance on what additional experiments or analyses are needed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also expresses interest in the performance of ATT(+H) in Figure 4 and asks for results if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a specific suggestion for further experimentation, it lacks detailed reasoning or evidence to support why this particular ablation study would be beneficial or necessary. The suggestion is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting an additional experiment on the visDial dataset to further validate the proposed visual reference resolution model. It also expresses interest in the performance of ATT(+H) in Figure 4 and asks for results if the model did not consider relevant attention retrieval from the attention memory. This feedback is clear and detailed, offering the authors a concrete way to enhance the robustness and comprehensiveness of their experimental results. By addressing these points, the authors can significantly improve the depth and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide an explanation for why WPA works, specifically asking what the model is predicting with np.ones input and whether any input could serve as a white paper. It also questions why Gaussian noise input does not work as well as WPA and why the authors spend time showing WPA improves test performance without providing insights into how it works. The comment implies that the authors should address these questions to enhance the paper and potentially spark future research directions. While the actions are implicit, they are concrete in terms of what the authors need to explore and explain. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and discusses the performance of WPA with different inputs, such as np.ones and Gaussian noise. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it raises several questions about the model\\'s predictions, the effectiveness of different inputs, and the lack of insights provided by the authors. It suggests that the authors should explain why WPA works and how it can spark future research directions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide an explanation for why WPA works, specifically questioning what the model is predicting with np.ones input and whether any input could serve as a white paper. It also questions why Gaussian noise input does not work as well as WPA and why the authors focus on improving test performance without providing insights into how WPA works. While the comment raises valid questions, it lacks specific evidence or references to support the claims or suggestions. The reasoning is somewhat verifiable, as it highlights areas for further exploration, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a gap in the paper regarding the explanation of why WPA works. It raises specific questions about the model\\'s predictions with np.ones input and whether any input could serve as a white paper, which are important for understanding the model\\'s functionality. The comment also points out the discrepancy between the authors\\' focus on improving test performance and the lack of insights into how WPA works, suggesting that this could spark future research directions. While the comment effectively highlights areas for improvement, it could be more helpful by offering suggestions on how to address these issues or by providing examples of similar approaches in the literature. Overall, the feedback is actionable and encourages the authors to provide a deeper understanding of their model, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the setting of two important parameters, the minimum cluster size and the conductance threshold, and their impact on performance. It points out that these parameters are not mentioned or discussed in the experimental section (Section 3). The comment implies that the authors should include a discussion on how these parameters are set and how sensitive the performance is to them. While the action is implicit, it is concrete because it specifies the exact parameters and the need for a discussion on their impact. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the absence of discussion on how two important parameters, the minimum cluster size and the conductance threshold, are set and how sensitive the performance is to these parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a gap in the paper regarding the setting of two important parameters and their impact on performance. It notes that these parameters are not mentioned or discussed in the experimental section. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are informed of the omission but are not provided with specific guidance on how to address it. Therefore, the comment is somewhat verifiable, as it points out a gap but does not fully support the claim with detailed evidence or suggestions for improvement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the setting of two important parameters, the minimum cluster size and the conductance threshold, and their impact on performance. It points out that these parameters are not mentioned or discussed in the experimental section, which is crucial for understanding the robustness and generalizability of the results. This feedback is clear and actionable, as it directs the authors to include a discussion on how these parameters are set and how sensitive the performance is to them. By addressing this point, the authors can enhance the comprehensiveness and rigor of their experimental analysis. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of similar discussions in other works. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a personal belief that the need for reinforcement learning for a static VQA task may be a potential weakness, suggesting that it could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this potential weakness or improve their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less data efficient and harder to train models using gradient descent. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this could be addressed or improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the need for reinforcement learning for a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a potential concern about the use of reinforcement learning for a static VQA task, suggesting that it may be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It is more of an observation or opinion rather than a constructive critique that would guide the authors in enhancing their work. As a result, the comment is barely helpful, as it identifies a potential issue but does not offer a clear path for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the implementation of the bilinear layer, specifically asking how it differs from other approaches that use bilinear pooling, and whether the dimensionality of embeddings is the main difference. It also inquires about the swapping of the bilinear layer with the Hadamard product and MCB approaches and whether the compression of representations using Equation (3) is still done in this case. While the comment raises important questions, it does not provide explicit instructions or concrete suggestions for the authors to address these questions. The authors can infer that they need to clarify these aspects, but the lack of specific guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the implemented bilinear layer differs from other approaches that use bilinear pooling, and it raises specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with the Hadamard product and MCB approaches, and the compression of representations using Equation (3). This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the implementation of the bilinear layer, specifically asking for clarification on how it differs from other approaches that use bilinear pooling. It also inquires about the swapping of the bilinear layer with the Hadamard product and MCB approaches and whether the compression of representations using Equation (3) is still done in this case. While the comment seeks clarification, it does not make any subjective claims or judgments that require verification. It is primarily a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the implementation of the bilinear layer, specifically asking for clarification on how it differs from other approaches that use bilinear pooling. It inquires about the dimensionality of embeddings, the swapping of the bilinear layer with the Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still done in this case. These questions highlight potential areas of confusion or lack of clarity in the paper, prompting the authors to provide more detailed explanations or comparisons. While the comment identifies specific areas for improvement, it could be more helpful by offering suggestions on how to address these questions or by providing examples of how similar issues have been handled in other works. Overall, the comment is somewhat helpful as it directs the authors to clarify important aspects of their methodology, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the illustration of results related to the latter loss term of Eqn 13, suggesting that the authors should directly show these results instead of relying on the cosine similarity of preactivation values. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on how to present the results. The action is implicit and somewhat vague, as the authors need to infer that they should add a new illustration or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3 e\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the rationale behind not directly illustrating the results of the latter loss term of Eqn 13, providing a clear suggestion for improvement. This level of detail helps the authors understand what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the illustration of results related to the latter loss term of Eqn 13, suggesting that the authors should directly show these results instead of relying on the cosine similarity of preactivation values. However, the comment does not provide any reasoning or evidence to support why this alternative illustration would be more beneficial or necessary. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Figure 3 and Equation 13, suggesting that the authors should directly illustrate the results of the latter loss term instead of relying on the cosine similarity of preactivation values. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and comprehensibility of the results. By addressing this point, the authors can enhance the transparency and effectiveness of their presentation. However, the comment could be more helpful if it included additional context or explanation of why this change is important or how it might impact the interpretation of the results. Overall, the comment is mostly helpful, as it offers a specific direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should compare its approach to test-time adaptation (TTA) methods, such as those mentioned, to demonstrate the superiority of data processing over model parameter adjustment. While the comment explicitly states the need for a comparison, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The authors are left with a clear action to take but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the topic of \"robustness in video action recognition\" and the lack of comparison with test-time adaptation (TTA) methods, such as those mentioned. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: a comparison with TTA methods and an explanation of how data processing is superior to model parameter adjustment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparison with test-time adaptation (TTA) methods, which are relevant for robustness in video action recognition. The reviewer suggests that these TTA methods aim to adapt to out-of-distribution data and questions the superiority of data processing over model parameter adjustment. While the comment provides a logical reasoning for the comparison, it lacks specific references or examples of TTA methods that could be used for comparison. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the lack of comparison with test-time adaptation (TTA) methods, which are relevant for robustness in video action recognition. It suggests that a comparison with these methods could help demonstrate the superiority of data processing over model parameter adjustment. The comment provides a clear direction for improvement by recommending a specific type of comparison and questioning the current approach. However, it could be more helpful if it offered specific examples of TTA methods to consider or suggested metrics for comparison. Overall, the feedback is mostly helpful as it highlights an important area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an error in the first expression for J(\\\\(\\\\theta\\\\)) in Section 3.2.1, stating that it should be Q(\\\\(s_t^0, \\\\pi_{\\\\theta}(s_t^0)\\\\)). This feedback provides a clear and direct action for the authors to take, as they know exactly what needs to be corrected in their draft. The comment is specific and leaves no ambiguity about what needs to be done to improve the accuracy of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J(\\\\(\\\\theta\\\\)), stating that it should be Q(\\\\(s_t^0, \\\\pi_{\\\\theta}(s_t^0)\\\\)). This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first expression for J(\\\\(\\\\theta\\\\)) in Section 3.2.1 is incorrect and should be Q(\\\\(s_t^0, \\\\pi_{\\\\theta}(s_t^0)\\\\)). This claim is verifiable as it provides a specific correction to the expression, which can be easily verified by the authors. The comment is precise and provides a clear suggestion for improvement, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the first expression for J(\\\\(\\\\theta\\\\)) in Section 3.2.1, stating that it should be Q(\\\\(s_t^0, \\\\pi_{\\\\theta}(s_t^0)\\\\)). This feedback is clear and actionable, providing the authors with precise information about where the mistake lies and how to correct it. By addressing this error, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it explained why this correction is necessary or how it impacts the overall understanding of the section. Despite this, the comment is mostly helpful as it directly points out a critical error that needs correction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of specific corrections to be made in the manuscript, including changes to the text and references. These corrections are explicit and concrete, giving the authors clear guidance on what needs to be done to improve the draft. The detailed nature of the feedback ensures that the authors know exactly how to implement the changes, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and references in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed corrections for various words and references, including capitalization issues and publication details. This level of detail helps the authors understand exactly what needs to be revised, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of corrections to the manuscript, including changes to the text and references. These corrections are factual and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a list of specific corrections to be made in the manuscript, including changes to the text and references. It identifies issues such as incorrect capitalization in references and inconsistencies in the text. These detailed corrections are actionable and can help the authors improve the accuracy and professionalism of their draft. However, the comment could be more helpful if it included an explanation of why these corrections are important or how they impact the overall quality of the paper. Despite this, the feedback is mostly helpful as it offers clear and specific guidance for improving the manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the model parameters for task 1 and the choice of lambda for the Boltzmann policy. It also inquires about the method used to choose the parameters, suggesting maximum likelihood estimates. While the comment implies that the authors should provide more information on these aspects, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can deduce that they need to include this information in their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the model parameters for task 1 and the choice of lambda for the Boltzmann policy. It also inquires about the method used to choose the parameters, suggesting maximum likelihood estimates. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these parameters are discussed. The comment is specific in detailing what information is missing or unclear. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification on specific parameter values and the method used to choose them. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the model parameters used in the paper, specifically asking for the model parameters for task 1 and the choice of lambda for the Boltzmann policy. It also inquires about the method used to choose the parameters, suggesting maximum likelihood estimates. This feedback is clear and actionable, as it directs the authors to provide specific information about their model parameters and the methodology used to select them. By addressing these points, the authors can improve the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to present this information or why it is important. Overall, the comment is mostly helpful, as it effectively highlights areas for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation regarding Table 2, where applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4 results in deteriorated performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. The reviewer asks the authors to provide an explanation for this observation, specifically asking why they think this might be happening. While the comment does not explicitly instruct the authors to conduct further analysis or provide a specific explanation, it implies that the authors should investigate and clarify this issue. The action is implicit but concrete, as the authors know they need to address the performance discrepancy and provide an explanation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. The comment further asks for an explanation, which adds specificity to the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an observation from Table 2, noting that applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4 results in deteriorated performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. The reviewer asks the authors to provide an explanation for this observation, which is a request for clarification rather than a subjective claim or suggestion. Therefore, the comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific observation regarding the performance of Conditional Batch Norm (CBN) in Table 2, noting that applying CBN to layer 2 in addition to layers 3 and 4 results in deteriorated performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. The comment asks the authors to provide an explanation for this observation, which is a clear and actionable request for further analysis. By prompting the authors to investigate and clarify this issue, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it suggested potential reasons or hypotheses for the observed performance deterioration, which would provide even more actionable feedback. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and encourages further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. However, the comment does not provide explicit guidance or suggestions on how the authors should address this similarity or improve their work. The authors are left to infer that they might need to differentiate their spurious features from backdoor triggers, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the spurious features, comparing them to backdoor triggers and providing examples from Chen et al. (2017) and Gu et al. (2019) to illustrate the similarity. This provides clear guidance on what the authors need to address regarding the spurious features. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers, providing examples from Chen et al. (2017) and Gu et al. (2019) to support this comparison. The comment also references the impact of rare spurious examples on trained models, which is a well-known concept in the field. This provides a logical and evidence-based reasoning to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the spurious features discussed in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides specific examples from existing literature, such as Chen et al. (2017) and Gu et al. (2019), to illustrate the concept of rare spurious examples having a significant impact on trained models. This feedback is valuable as it highlights a critical aspect of the paper that may need further exploration or clarification. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or differentiate their spurious features from backdoor triggers. Overall, the comment is somewhat helpful, as it provides insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semi-supervised trained. It provides a specific example by suggesting that the authors rename the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect the semi-supervised nature of the proposed framework. Additionally, the reviewer suggests a more comprehensive approach by specifying the data used to train each model and proposing two big columns to differentiate between mixture and single-source data. This feedback is explicit and provides concrete guidance on how to improve the clarity and presentation of the results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semi-supervised training, and suggests a renaming of the column in Table 1. Additionally, it provides a suggestion for a more comprehensive presentation of the data used to train each model. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the distinction between weak supervision and semi-supervised training in their proposed method. It provides a specific example by pointing out that the proposed framework row in Table 1 refers to the semi-supervised version of the method, and suggests renaming the column to \"Fully supervised\" from \"Supervised.\" The comment also proposes a more comprehensive approach to presenting the data used for training. While the suggestion is logical and provides a clear direction for improvement, it lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the suggestion but could benefit from additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific area where the paper could be improved: the distinction between weak supervision and semi-supervised training. It suggests renaming a column in Table 1 to reflect the semi-supervised nature of the proposed framework and proposes a more comprehensive approach to presenting the data used for training. This feedback is detailed and offers concrete suggestions that can help the authors clarify their methodology and improve the clarity of their presentation. By addressing these points, the authors can enhance the transparency and comprehensibility of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how to address it or suggest specific actions to take. The authors can infer that they need to include these cases in the tables, but the comment lacks concrete instructions on how to implement this change. Therefore, the comment is somewhat actionable, as it identifies an issue but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the performance without reinforcement learning (RL) and without dependency tree, and notes that the tables do not include cases where both RL and dependency tree are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. While the comment identifies a specific issue, it lacks detailed reasoning or evidence to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue without additional context or explanation. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. This feedback is clear and actionable, as it highlights a gap in the experimental setup that the authors need to address. By including these cases in the tables, the authors can provide a more comprehensive analysis of the experiment. However, the comment could be more helpful if it suggested how to present or interpret these additional cases. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific weakness in the paper, namely the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. It suggests that the authors should consider other datasets from the Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for guidance on different datasets and model types. The comment provides explicit actions for the authors to take, including expanding the experimental evaluation and referencing relevant literature. The guidance is clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and the use of the CIFAR-10 dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the limited scope of the experiments and suggests considering other datasets from Federated learning benchmarks, such as LEAF, and referencing relevant works like FedProx and FedMAX. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s main weakness lies in the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. The reviewer suggests that the authors should consider other datasets from Federated learning benchmarks and references relevant works like FedProx and FedMAX for guidance. This claim is mostly verifiable as it provides specific examples of datasets and references that could be used to expand the experimental evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional datasets would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. It suggests that the authors should consider other datasets from Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX to provide guidance on different datasets and model types. This feedback is clear and actionable, as it directs the authors to expand their experimental evaluation to include a broader range of datasets, which would significantly enhance the comprehensiveness and impact of the paper. The comment also acknowledges the importance of the problem addressed, providing a positive note that could motivate the authors to address the identified weaknesses. Overall, the comment is highly helpful as it offers specific guidance for improvement and acknowledges the potential impact of the work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment highlights a potential gap in the explanation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect of their methodology, but without concrete instructions, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (182-183) and figures (2.c) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for non-stochastic networks and how the denominator of Figure 2.c is computed for specific networks. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the construction of clean exemplar manifolds for non-stochastic networks and the computation of the denominator in Figure 2.c. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the construction of clean exemplar manifolds for non-stochastic networks, specifically questioning how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This feedback highlights a potential gap in the explanation provided by the authors, prompting them to clarify their methodology. However, the comment does not offer specific suggestions or guidance on how to address this issue, leaving the authors with a clear area for improvement but without detailed direction. Therefore, the comment is somewhat helpful, as it identifies a specific area needing clarification but lacks actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusion regarding the notation and the explicit split between \"static\" and temporal features, specifically mentioning the variables \"S\" and \"Xt.\" However, it does not provide explicit guidance on how to address this confusion or suggest specific actions for the authors to take. The comment implies that more information is needed, but it lacks concrete instructions or examples on how to clarify the notation or provide additional details. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, mentioning the variables \"S\" and \"Xt.\" This allows the authors to accurately identify the part of the paper being addressed, providing full grounding. However, the comment lacks specificity as it does not provide detailed guidance on how to clarify the notation or what additional information is needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point expresses confusion about the notation and the explicit split between \"static\" and temporal features, specifically mentioning the variables \"S\" and \"Xt.\" However, it does not provide any supporting evidence or reasoning to justify why this split is confusing or how it could be improved. The comment lacks detailed explanation or examples, making it difficult for the authors to understand the basis of the confusion and address it effectively. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, noting that it is confusing, at least initially. It points out the lack of clarity regarding the variables \"S\" and \"Xt,\" suggesting that more information is needed. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might clarify the notation or provide additional information. This limits the comment\\'s usefulness, as it provides insight into a problem but does not offer actionable steps for resolution. Therefore, the comment is somewhat helpful, as it points out a specific issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from theorem 3 is not straightforward and lacks clarity. It notes that the paper describes this choice as empirical but provides little justification for the specific form. However, the comment does not offer explicit guidance on how the authors should address this issue or suggest specific steps to improve the clarity of the motivation. The action is implicit and vague, as the authors are left to infer that they need to provide more justification for the choice of $\\\\theta$, but without concrete suggestions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$, noting that the paper describes this choice as empirical but lacks sufficient motivation for the specific form. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from theorem 3, noting that the paper describes this choice as empirical but lacks sufficient justification. The comment highlights a gap in the explanation, suggesting that the authors need to provide more detail on the rationale behind this choice. However, the comment does not offer specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the explanation themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from theorem 3. It points out that the paper describes this choice as empirical but lacks sufficient explanation or justification for the specific form. This feedback is clear and actionable, as it prompts the authors to provide a more detailed rationale for their choice, which could enhance the clarity and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this motivation or examples of what kind of justification would be acceptable. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study, which could lead to confusion and additional experimentation for practitioners. It specifically mentions the role of \\\\(\\\\sigma\\\\) in the RBF kernel and suggests analyzing how \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) affect performance. While the comment identifies areas that need attention, it does not provide explicit instructions on how to conduct these analyses or what specific experiments to perform. The feedback is somewhat actionable as it points out missing elements but lacks detailed guidance on implementation. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements such as the ablation study, the \\\\(\\\\sigma\\\\) in the RBF kernel, Figure 4, and equation (7). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely an analysis of the \\\\(\\\\sigma\\\\) in the RBF kernel and how \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) affect performance. The minor comments section provides additional guidance on specific areas that need attention. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"some ablation study is missing,\" which could lead to confusion and additional experimentation for practitioners. It provides specific examples, such as the role of \\\\(\\\\sigma\\\\) in the RBF kernel and the lack of analysis on how \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) affect performance. These examples provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies where such analyses are standard. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a missing ablation study, which could lead to confusion and additional experimentation for practitioners. It provides specific examples, such as the role of \\\\(\\\\sigma\\\\) in the RBF kernel and the lack of analysis on how \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) affect performance. This feedback is clear and actionable, as it guides the authors to include additional analyses that could enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to conduct these analyses or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable insights into areas needing improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the claim about INRs operating on a per-data-instance basis is true but questions its advantage. However, it does not provide any explicit or implicit suggestions for improvement or action. The comment lacks guidance on how the authors might address this issue or enhance their draft. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2\" and a specific quote within that section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the advantage of a model that can only handle a single time series data, providing a clear critique of the claim made in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that INRs operate on a per-data-instance basis, suggesting that this is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specific examples or references to support the claim that this limitation is a significant drawback. While the reasoning is sound, the absence of detailed evidence or comparisons makes the claim somewhat verifiable. The authors would need to further explore the implications of this limitation themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that INRs operate on a per-data-instance basis, suggesting that this limitation might not be an advantage. However, the comment does not provide any constructive feedback or suggestions on how the authors might address this limitation or improve their work. It lacks actionable guidance or specific advice, leaving the authors without a clear path for improvement. As a result, the comment is not particularly helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the experiments, specifically noting that most experiments are conducted with RoBERTa-base and questioning the generalizability of the results to other models adopting learnable APEs. It suggests investigating the generalizability to differences in model size, objective function, and architecture, and recommends including more analysis and discussion for GPT-2. The reviewer explicitly requests to see the results of Figure 2 for GPT-2. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional analysis and discussion are needed. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of limited experiments, particularly focusing on the lack of generalizability to other models adopting learnable APEs. The comment suggests investigating the generalizability to differences in model size, objective function, and architecture, and specifically recommends including more analysis and discussion for GPT-2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the limited scope of the experiments, specifically noting that most experiments are conducted with RoBERTa-base and questioning the generalizability of the results to other models. The reviewer suggests investigating the generalizability to differences in model size, objective function, and architecture, and provides a specific example by requesting results for GPT-2. This claim is mostly verifiable as it logically points out a potential limitation in the experimental design and provides a clear suggestion for improvement. However, it lacks detailed evidence or references to support the claim about the necessity of broader experimentation, which would strengthen the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental scope, noting that most experiments are conducted with RoBERTa-base and questioning the generalizability of the results to other models. It suggests investigating the generalizability to differences in model size, objective function, and architecture, and provides a specific example by recommending more analysis and discussion for GPT-2. This feedback is clear and actionable, as it guides the authors to expand their experimental analysis to include other models, which could significantly enhance the robustness and applicability of their findings. The comment is highly helpful as it provides detailed suggestions for improvement, offering a clear path for the authors to enhance their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the parameters, model, and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). It suggests that the authors should consider applying their principles to these areas to demonstrate the method\\'s generalizability beyond transformers in vision. While the comment implies an action, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the applicability of the parameters, model, and experiments to other research areas such as NLP or simpler models in the image domain (CNNs). The comment suggests that the authors should demonstrate the method\\'s generalizability beyond transformers in vision, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the applicability of the parameters, model, and experiments to other research areas, such as NLP or simpler models in the image domain. The reviewer suggests that the authors should demonstrate the method\\'s generalizability beyond transformers in vision. While the comment provides a logical reasoning for why this would be beneficial, it lacks specific examples or references to support the claim that the method could generalize to these other areas. This makes the claim somewhat verifiable, as it provides a rationale but requires additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an important question about the applicability of the parameters, model, and experiments to other research areas, such as NLP or simpler models in the image domain. It suggests that the authors should demonstrate the method\\'s generalizability beyond transformers in vision, which would enhance the paper\\'s impact and relevance. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. Providing examples or methodologies for extending the work to other domains would make the feedback more actionable. Therefore, the comment is somewhat helpful, as it prompts the authors to consider broadening their scope but does not fully support them in doing so.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights an interesting observation about the performance of TTA methods on non-standard benchmarks and suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. While the comment implies that the authors should consider evaluating TTA on more conditions, it does not explicitly instruct them to do so. The action is concrete in terms of what could be done to improve the paper, but it is communicated indirectly. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA on more conditions of natural distribution shift, such as WILDS, to strengthen the paper. This provides clear guidance on what additional analysis could be conducted to enhance the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes an observation about the performance of TTA methods on non-standard benchmarks and suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. While the comment provides a logical suggestion for improvement, it lacks specific examples or detailed reasoning to support why evaluating TTA on WILDS would be beneficial. The reference to WILDS is a starting point, but more context or explanation would be needed to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires additional detail to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges an interesting observation about the performance of TTA methods on non-standard benchmarks and suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by expanding their evaluation to include additional benchmarks. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or discussed potential challenges in doing so. Overall, the comment is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use a more convincing setting for their unlabeled data, similar to the approach used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al. (2018). The comment explicitly recommends using unlabeled data directly sampled from millions of reviews, providing a clear and concrete action for the authors to take. However, it does not specify how the authors should implement this change or what specific aspects of the current setting are impractical. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the label distribution of unlabeled data and suggests using a more convincing setting as done in a referenced study. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unlabeled data from the Amazon review dataset is perfectly balanced, which is impractical in real-world applications. The reviewer supports this claim by suggesting that the authors should use a more convincing setting, as done in a referenced study. This provides a logical reasoning and a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of unlabeled data from the Amazon review dataset, noting that it is perfectly balanced, which is impractical in real-world applications. It suggests that the authors should use a more convincing setting, as done in a referenced study, which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing a concrete example of how the authors could improve their approach to better align with real-world scenarios. By recommending a specific method and referencing a relevant study, the comment offers valuable guidance for enhancing the draft. Therefore, it is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential differences in the contributions of different modalities across instances, suggesting that Equation 3 may not adequately address this issue. However, it does not provide explicit guidance or suggestions on how to handle this problem. The comment implies that the authors should consider addressing this issue, but it lacks concrete steps or recommendations for how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential differences in the contributions of different modalities across instances and how Equation 3 may not adequately address this problem. The comment raises a specific concern about how to handle this issue, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential differences in the contributions of different modalities across instances, suggesting that Equation 3 may not adequately address this issue. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of explicit evidence or references leaves the claim somewhat vague, requiring the authors to infer the issue and its implications. Therefore, the comment is classified as 3: Somewhat Verifiable, as it provides some insight but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s methodology, specifically regarding the contribution of different modalities across instances. It highlights a concern that Equation 3 may not adequately address this issue, suggesting that some instances may perform better with one modality while others perform better with another. However, the comment does not provide specific suggestions or guidance on how to address this problem, such as proposing alternative methods or analyses. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section, noting that the notation for the target domain is unlabeled and that the problem setting description differs significantly from the original MFDA paper. The reviewer asks questions about the use of unlabeled data in source domains and whether they are used during training, as in the original paper. While the comment highlights areas of confusion, it does not provide explicit instructions on how to address these issues or clarify the problem setting. The authors are left to infer that they need to clarify the notation and problem setting, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section\" and references specific elements such as \"single target domain with sparse labels,\" \"target distribution p_T(x, y) with label observation,\" and the notation for the target domain \u03c4. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the confusion regarding the description of the MFDA setting, questions the use of unlabeled data in source domains, and compares it to the original MFDA paper. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the description of the MFDA setting in the paper, specifically questioning the use of unlabeled data in source domains and its alignment with the original MFDA paper. The reviewer provides specific references to the original MFDA paper by Yue et al. (2021a) to support their claim, which helps to verify the comment. However, the comment could be strengthened by providing more detailed examples or explanations of the confusion, such as specific sections or paragraphs where the issue arises. Despite this, the reference to the original paper provides a solid basis for the claim, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the paper, specifically pointing out inconsistencies and confusion regarding the use of unlabeled data in source domains. It references the original MFDA paper by Yue et al. (2021a) to highlight the discrepancy in the problem setting description. By questioning the use of unlabeled data in source domains and comparing it to the original paper, the comment provides the authors with a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to clarify the description or align it with the original paper. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an epoch-wise analysis, particularly for finite sum settings, could provide insights into the behavior of optimization algorithms. It implies that investigating the effects of batch size or different sampling strategies could be beneficial. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for an epoch-wise analysis and determine how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an epoch-wise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It provides specific examples of what could be investigated, such as the effects of batch size or different sampling strategies. However, the comment does not explicitly mention which part of the paper it addresses, leaving the authors to infer that it relates to the methodology or results sections. While the suggestion is specific, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an epoch-wise analysis, particularly for finite sum settings, could provide insights into the behavior of optimization algorithms. The comment proposes specific examples, such as investigating the effects of batch size or different sampling strategies, which could enhance the understanding of algorithmic progress. However, the claim lacks specific references or detailed reasoning to fully substantiate the benefits of this approach. While the suggestion is logical, the absence of explicit evidence or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an epoch-wise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It provides specific examples of what could be investigated, such as the effects of batch size or different sampling strategies, which could enhance the understanding of algorithmic progress. Additionally, it mentions that this analysis could aid in comparative analysis of deterministic and stochastic methods. While the comment identifies a potential area for improvement and offers some direction, it lacks detailed guidance or specific suggestions on how to implement the epoch-wise analysis. This limits its helpfulness, as the authors are left with a general idea but no clear steps to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper\\'s classification of extreme speech, noting that the distinction between derogatory and exclusionary extreme speech is unclear. It provides an example from the sample data file to illustrate the confusion and questions the role of local regulations in annotations. The reviewer suggests that the authors should clarify the definitions and consider the impact of local regulations on zero-shot cross-country classification. While the comment identifies a clear area for improvement, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to clarify the definitions and address the impact of local regulations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. Additionally, it raises questions about the role of local regulations in annotations and their impact on zero-shot cross-country classification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the paper\\'s distinction between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. The reviewer questions the role of local regulations in annotations and their impact on zero-shot cross-country classification. While the comment highlights a specific issue and provides some reasoning, it lacks detailed examples or references to fully substantiate the claim. The authors would need to further explore and clarify these points themselves. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional effort to fully validate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s classification of extreme speech, noting that the distinction between derogatory and exclusionary extreme speech is unclear. It provides an example from the sample data file to illustrate the confusion and questions the role of local regulations in annotations. The comment also raises a relevant point about the impact of local regulations on zero-shot cross-country classification. This feedback is clear and actionable, as it directs the authors to clarify their definitions and consider the implications of local regulations on their classification approach. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the clarity of the definitions. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by highlighting a critical area for clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the context of sequential ensembling and homomorphic encryption, specifically noting the issue of noise accumulation. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their work. There is no guidance on potential solutions, alternative approaches, or additional experiments that could be conducted to mitigate the issue of noise accumulation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the topic of sequential ensembling and its limitations in the context of homomorphic encryption, specifically mentioning the issue of noise accumulation. However, it does not specify which part of the paper discusses sequential ensembling or homomorphic encryption, making it weakly grounded. The comment is specific in identifying the issue of noise accumulation and its implications for using deep neural networks on encrypted data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the importance of studying noise accumulation in the context of sequential ensembling and homomorphic encryption. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant limitation or how it affects the use of deep neural networks on encrypted data. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the context of sequential ensembling and homomorphic encryption, noting the issue of noise accumulation. It highlights a potential barrier to using even single deep neural networks on encrypted data. While the comment points out an important consideration, it lacks actionable suggestions or guidance on how the authors might address this limitation or explore the implications further. Without specific advice or examples, the authors may find it challenging to incorporate this feedback into their work. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and direct action for the authors to take, as it specifies exactly what additional information should be added to the figure for comparison purposes. The comment is concrete, as it outlines a specific modification that would help the authors demonstrate the impact of mean teacher and pi regularization on learning. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added to the left graph in fig 3, namely, the learning curve for a model without any mean teacher or pi regularization for comparison. This provides clear guidance on what additional information is needed to enhance the analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a learning curve for a model without mean teacher or pi regularization in Figure 3 for comparison. This claim is somewhat verifiable as it logically suggests that including such a comparison could provide insight into the impact of mean teacher and pi regularization on learning. However, the comment lacks specific examples or references to similar studies that have used this approach, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the inclusion of a learning curve for a model without mean teacher or pi regularization in Figure 3. This would allow the authors to compare the impact of these techniques on learning, potentially shedding light on whether mean teacher accelerates or slows down the learning process. The comment is clear and offers a concrete way to enhance the analysis, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed objective equation requires optimization over both the parameters of the transformation and the shared model, and notes that the impact on the number of parameters compared to prior work, such as AlignFlow, is not clearly discussed. While the comment identifies an area that needs clarification, it does not provide explicit instructions on how to address this issue or suggest specific aspects that should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with prior work regarding the number of parameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the discussion of the effect on the number of parameters compared to prior work like AlignFlow. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed objective equation requires optimization over both the parameters of the transformation and the shared model, and notes that the impact on the number of parameters compared to prior work has not been clearly discussed. While the comment identifies a specific aspect of the paper that needs clarification, it lacks detailed reasoning or examples to support the claim about the impact on the number of parameters. The reference to AlignFlow (Grover et al. 2019) is mentioned but not fully integrated into the critique, making it somewhat verifiable. The authors would need to further explore the claim themselves to fully understand and address it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the proposed objective equation, which requires optimization over both the parameters of the transformation and the shared model. It points out that the impact on the number of parameters compared to prior work, such as AlignFlow, is not clearly discussed. This feedback is clear and actionable, as it directs the authors to provide a comparison with prior work to clarify the implications of their approach. However, the comment could be more helpful if it offered suggestions on how to present this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it highlights an important area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking whether the \\\\(u^l\\\\) in Eq. 3 tends to be 1 if Eq. 4 stands. This is a request for clarification and does not provide any explicit or implicit action for the authors to take. The second part of the comment critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on some datasets. However, it does not offer any specific guidance or suggestions on how the authors might address this issue or improve their results. Both parts of the comment lack actionable details, leaving the authors without clear steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Eq. 3 and Eq. 4) and a table (Table 5), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on some datasets. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking whether the \\\\(u^l\\\\) in Eq. 3 tends to be 1 if Eq. 4 stands. This is a request for clarification and does not contain a claim or opinion that requires verification. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on some datasets. This is a factual observation without subjective claims or opinions. Therefore, the review point does not contain claims that require verification, and the appropriate label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two points. First, it questions the implications of Eq. 4, asking whether the \\\\(u^l\\\\) in Eq. 3 tends to be 1 if Eq. 4 stands. This is a request for clarification and does not provide actionable feedback for improvement. Second, it critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on some datasets. While this observation highlights a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve their results. Overall, the comment provides some insight but lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific gap in the literature review by mentioning the missing state-of-the-art reference \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. It also highlights the use of the triplet loss and the reported results on a dataset similar to Webface, which could be relevant for comparison. The comment provides a clear action for the authors to include this reference and potentially update their results for comparison. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. Nonetheless, the comment is concrete in suggesting a specific reference and comparison point, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the \"state-of-the-art references,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the missing reference, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and provides a link to the work. Additionally, it highlights the use of the triplet loss and the reported results on a dataset similar to Webface, which is relevant for comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that state-of-the-art references are missing in the face recognition experiment, specifically mentioning Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" The reviewer provides a link to the work and notes that it uses the triplet loss and reports results on a dataset similar to Webface, which is relevant for comparison. The comment also highlights that the VRF achieves a better result on LFW compared to the results in Table 3 of the paper. This detailed comparison and reference to specific work provide a robust basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific gap in the literature review by pointing out the omission of a state-of-the-art reference related to face recognition. It provides a clear and actionable suggestion by mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu, which uses the triplet loss and reports results on a dataset similar to Webface. The comment also highlights that the VRF achieves a better result on LFW compared to the results in Table 3 of the paper. This feedback is valuable as it directs the authors to include a relevant reference and potentially update their results for comparison, which could enhance the credibility and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this reference into the paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the range of ID and OOD does not seem to change much with sparsification, as shown in Figure 4, and that Lemma 2 requires approximately identical mean as the assumption. It also notes that these conditions are crucial for DICE but are not well discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to ensure DICE meets these conditions. The feedback is vague and lacks concrete steps for the authors to follow, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not seem to change much with sparsification and that Lemma 2 requires approximately identical mean as the assumption. The comment further highlights the importance of these conditions for DICE and suggests that they are not well discussed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the range of ID and OOD does not seem to change much with sparsification, as shown in Figure 4, and that Lemma 2 requires approximately identical mean as the assumption. The reviewer suggests that these conditions are crucial for DICE but are not well discussed. While the comment provides some reasoning by referencing Figure 4 and Lemma 2, it lacks specific examples or detailed explanations to fully substantiate the claim. The suggestion to discuss how to ensure DICE meets these conditions is a logical step, but the comment could be strengthened with more detailed reasoning or references. Therefore, the claim is somewhat verifiable, as it provides a basis for the argument but requires additional detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the range of ID and OOD does not seem to change much with sparsification, as shown in Figure 4. It also points out that Lemma 2 requires approximately identical mean as the assumption, which is crucial for DICE but is not well discussed. The comment suggests that the authors should address how to ensure DICE meets these conditions. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. Providing more specific advice or examples would make the feedback more actionable and helpful. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of integrating over all possible environments for the update to be meaningful, assuming the true environment is unknown. This implies that the authors should clarify this aspect in their draft. Additionally, it suggests that the bolded sections on page 6 should be broken out into paragraphs to improve readability. While the comment provides a clear action for the second part, the first part is more of a question that implies an action but does not explicitly instruct the authors to address it. Overall, the comment is mostly actionable as it provides concrete guidance on formatting but leaves some room for interpretation regarding the integration over environments.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the integration over all possible environments and the need to break out the bolded sections into paragraphs for improved readability. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of integrating over all possible environments for the update to be meaningful, assuming the true environment is unknown. This is a request for clarification rather than a claim, as it does not express an opinion or judgment that requires verification. Additionally, the second part of the comment suggests formatting changes, which is a request for improvement rather than a claim. Therefore, the review point consists of factual statements and requests for clarification, making it appropriate to label it as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment addresses two distinct issues. First, it questions the necessity of integrating over all possible environments for the update to be meaningful, assuming the true environment is unknown. This raises a critical point that the authors should clarify in their paper. Second, it suggests that the bolded sections on page 6 should be broken out into paragraphs to improve readability. While the comment identifies these areas for improvement, it lacks detailed guidance or suggestions on how the authors might address the first issue or how to effectively break up the text. The feedback is somewhat helpful as it points out areas for improvement but does not provide comprehensive guidance or actionable steps for the authors to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the experimental setup and the lack of comparison with certain baselines. It questions the choice of using position kernels for all baselines and suggests using the default settings of these baselines in the literature. Additionally, it points out the absence of baselines related to BO with discrete and categorical variables and recommends including them for comparison. The comment also highlights the need for the paper to discuss limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses multiple issues related to the experiments and the paper\\'s content. It questions the strength and fairness of the experiments, specifically mentioning the use of position kernels for all baselines and suggesting the use of default settings from the literature. It also points out the absence of certain baselines related to BO with discrete and categorical variables and recommends including them for comparison. Additionally, it highlights the lack of discussion on limitations and societal impacts of the proposed approach. While the comment covers several points, it does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. However, it is specific in detailing what needs to be addressed, such as the choice of baselines and the need for a discussion on limitations and societal impacts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the strength and fairness of the experiments, questioning the choice of using position kernels for all baselines and suggesting the use of default settings from the literature. It also points out the absence of certain baselines related to BO with discrete and categorical variables and recommends including them for comparison. Additionally, the comment highlights the lack of discussion on limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims about the experiments\\' strength and fairness. The absence of specific examples or evidence makes it somewhat verifiable, as the authors would need to further explore and substantiate the claims themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It questions the strength and fairness of the experiments, specifically pointing out the use of position kernels for all baselines and suggesting the use of default settings from the literature. Additionally, it notes the absence of certain baselines related to BO with discrete and categorical variables and recommends including them for comparison. The comment also highlights the lack of discussion on limitations and societal impacts of the proposed approach. While the feedback is somewhat helpful as it identifies specific weaknesses and areas for improvement, it could be more beneficial if it provided more detailed guidance or examples on how to address these issues. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature variable, \u03c4, and suggests that it should be included in a rigorous manner or mentioned in the paper. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added or clarified. The comment is concrete, as it identifies a specific element that is missing and provides a clear path for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqn. 3\" and \"Eqn. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the temperature variable \u03c4 in the derivation or its mention in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature variable, \u03c4, and suggests that it should be included or mentioned rigorously. This claim is somewhat verifiable as it identifies a specific omission in the derivation process. However, the comment lacks detailed reasoning or examples to fully substantiate why the inclusion of \u03c4 is necessary or how it impacts the derivation. Providing more context or explanation would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the derivation presented in the paper, noting that the temperature variable, \u03c4, is missing from the transition from Equation 3 to Equation 4. It suggests that this omission should be addressed either by including \u03c4 in a rigorous manner or by mentioning it in the paper. This feedback is clear and actionable, providing the authors with a precise area to correct or clarify in their work. By addressing this point, the authors can improve the rigor and completeness of their derivation, making the comment mostly helpful. However, it could be more helpful if it offered additional guidance on how to incorporate \u03c4 or why it is important, which would elevate it to a highly helpful comment. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, as it identifies a particular area where the authors can enhance their paper by including a relevant citation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear action for the authors to take. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a request for clarification or improvement, not a claim or opinion. It does not require verification, as it is a suggestion for enhancing the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the paper by recommending the inclusion of a citation on differential privacy. This feedback is clear and directly addresses a potential gap in the literature review or background section, which could enhance the reader\\'s understanding of the topic. By suggesting a standard work like [2], the reviewer offers a concrete reference that the authors can use to improve the comprehensiveness and credibility of their work. This guidance is valuable for the authors, as it helps them enhance the quality and depth of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point addresses two distinct issues. First, it questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the assumption is not as extreme as stated. The reviewer provides a specific example of the assumption and critiques the usefulness of Theorem 4 if this assumption is indeed too hard to satisfy. This part of the comment implies that the authors should reconsider or clarify their claim about the assumptions. Second, it points out a specific error in the inequality on line 310, suggesting a correction. Both parts of the comment provide explicit and concrete actions for the authors to take, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310\" and \"line 227,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it critiques the claim about additional assumptions and provides a detailed explanation of the issue, as well as pointing out an error in the inequality on line 310. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"this methodology requires significant additional assumptions,\" suggesting that the assumption is not as extreme as stated. The reviewer provides a specific example of the assumption, which is that the test set is drawn from the same distribution as the query set, a common practice in machine learning. This reasoning is logical and based on common knowledge in the field, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or examples where this assumption is commonly made. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses two distinct issues. First, it questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the assumption is not as extreme as stated. The reviewer provides a specific example of the assumption and critiques the usefulness of Theorem 4 if this assumption is indeed too hard to satisfy. This feedback is clear and actionable, as it prompts the authors to reconsider or clarify their claim about the assumptions. Second, the comment points out an error in the inequality on line 310, suggesting a correction. This is a specific and actionable piece of feedback that can help the authors improve the accuracy of their draft. Overall, the comment is highly helpful as it provides detailed and constructive feedback on both the theoretical claims and the mathematical content of the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to effectively revise their draft. Without detailed guidance, the authors may struggle to identify and correct the specific writing issues mentioned. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues occur in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these issues could be present, the comment lacks full grounding. It is specific about the types of issues but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed evidence to support these claims. Without concrete instances or references, the authors may find it challenging to identify and address the writing issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it lacks specific examples or detailed guidance on how to address them. The comment provides a general overview of the issues but does not offer actionable feedback or suggestions for improvement. As a result, the authors are informed of the problems but are left without clear steps to enhance the clarity and quality of their writing. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It instructs them to run experiments and add the results to the figures and Table 1 if the figures do not show results for untrained networks. Additionally, it requests clarification on specific aspects of the figures, such as whether the network was trained on random data or evaluated with random data, and whether the non-random data was normalized. The comment also suggests showing examples of the random data in the appendix. These instructions are clear and specific, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Fig 3c and Fig 3) and Table 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as running experiments for untrained networks, clarifying the nature of the random data, and potentially adding examples to the appendix. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and suggestions for additional experiments. It does not contain subjective opinions, judgments, or claims that require verification. The comments are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying areas where the figures and Table 1 could be improved. It suggests running additional experiments to include results for untrained networks, which would enhance the comprehensiveness of the analysis. Additionally, it requests clarifications on the nature of the random data used in the figures, asking whether the network was trained on random data or evaluated with random data. The comment also suggests showing examples of the random data in the appendix, which would provide further insight into the methodology. This detailed guidance empowers the authors to make significant improvements to their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It asks whether this refers to 100 sampled strategies. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides the authors with precise guidance on what needs to be clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically asking if it refers to 100 sampled strategies. While this question highlights a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment is somewhat helpful as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers presented in Table 1 and Fig. 5. It also points out that the results do not report the mean and standard deviation, making it difficult to assess the statistical significance of the improvements. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what steps to take to improve their draft. The suggestion to repeat the experiments and conduct statistical significance analysis is specific and actionable, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the results, noting the lack of mean and standard deviation reporting and the difficulty in determining statistical significance. The comment further suggests repeating the experiments and conducting statistical significance analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement over previous methods is small, about 0.2%-1%, and notes that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis to address these issues. While the comment provides some reasoning by pointing out the lack of statistical information, it lacks specific examples or references to substantiate the claim about the small improvement. The suggestion to repeat the experiments is logical but not fully supported by detailed evidence or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, ranging from 0.2% to 1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess the statistical significance of the differences. The reviewer suggests repeating the experiments and conducting statistical significance analysis to address these issues. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by enhancing the statistical rigor of their results. However, the comment could be more helpful by offering additional guidance on how to conduct the statistical analysis or suggesting specific tests to use. Overall, the comment is mostly helpful as it identifies critical areas for improvement and provides a clear path forward, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing section in the main paper, specifically the \"approach section,\" and suggests that the supplementary material should be used more like additional information rather than an extension of the paper. The reviewer references a specific paper by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee as a potential source for the missing section. This feedback provides a clear and explicit action for the authors to include the approach section in the main paper and to use the supplementary material appropriately. The reference to a specific paper offers concrete guidance on how to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing section and suggesting that the supplementary material should be used more appropriately. The comment provides a clear direction for improvement by referencing a specific paper that could be used to address the missing section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more appropriately. The reviewer provides a reference to a specific paper by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which could be used to address the missing section. This reference provides a clear and specific example of how the supplementary material could be utilized, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the supplementary material is currently misused. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, specifically the absence of an \"approach section\" in the main paper. It highlights that the reviewer had to refer to the supplementary material for this information, which should ideally be included in the main paper. The comment also suggests that the supplementary material should be used more appropriately, as it is meant to provide additional information rather than an extension of the paper. By referencing a specific paper by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, the reviewer provides a clear direction for the authors to improve their draft by including the missing section. This feedback is actionable and constructive, offering a specific resource for the authors to consider. However, it could be more helpful if it provided additional guidance on how to integrate the supplementary material more effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the statement in the introduction regarding the biological plausibility of backpropagation is too weak and suggests that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should revise this statement or what specific changes should be made to strengthen it. The action is implicit, as the authors can infer that they need to revise the statement, but it remains vague because it lacks concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, pointing out that it is too weak and that backpropagation is widely accepted as biologically implausible. This provides clear guidance on what needs to be revised or clarified in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. This claim is supported by logical reasoning, as it references a common understanding in the field that backpropagation is considered biologically implausible. However, the comment could be strengthened by providing specific references or examples to substantiate the claim further. As it stands, the claim is mostly verifiable due to the logical reasoning provided, but it lacks detailed evidence or references. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the statement in the introduction regarding the biological plausibility of backpropagation. It points out that the statement is too weak and suggests that it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it provides the authors with a direct suggestion to revise the statement to reflect the consensus in the field. However, the comment could be more helpful if it offered additional guidance on how to strengthen the statement or provided references to support the claim. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the implications of overparameterization on generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the reviewer acknowledges that the authors address this in the conclusion, they express a need for further clarification. The comment implies that the authors should provide more detailed explanations or evidence to address this concern, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the implications of overparameterization on generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. It acknowledges that the authors address this in the conclusion but suggests that it is a serious question. However, the comment does not specify which part of the paper discusses these constructions or where the authors address the issue in the conclusion, making it weakly grounded. The comment is specific in its critique of the implications of overparameterization on generalization but lacks grounding in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the implications of overparameterization on generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. The reviewer acknowledges that the authors address this in the conclusion but suggests that it is a serious question. While the comment highlights a potential issue, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors are left to infer the significance of this question without additional guidance. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the implications of overparameterization on generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. It acknowledges that the authors address this in the conclusion but suggests that it is a serious question that deserves further exploration. While the comment identifies an important area for clarification, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it highlights a potential weakness and encourages the authors to provide more detailed explanations, but it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the interest in the OOD experiments and notes that the trained network demonstrates strong OOD generalization. It then suggests that the authors should mention recent papers that show untrained NNs can solve inverse problems across a wide class of images. The comment implies that the authors should compare their method with these untrained NNs, providing a clear and explicit action for the authors to take. However, it does not specify which specific papers should be mentioned or how the comparison should be conducted, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention recent papers that demonstrate the effectiveness of untrained NNs in solving inverse problems across a wide class of images. The comment further suggests comparing the current method with these untrained NNs, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the interest in the OOD experiments and notes the strong OOD generalization of the trained network. However, it suggests that the authors should mention recent papers showing that untrained NNs can solve inverse problems across a wide class of images. This claim is supported by referencing a specific paper (Ulyanov et al., CVPR 2018) and suggesting a comparison with these methods. The inclusion of a specific reference and the suggestion for comparison provide a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these untrained NNs compare to the current method. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the interest in the OOD experiments and notes the strong OOD generalization of the trained network. It then suggests that the authors should mention recent papers that demonstrate the effectiveness of untrained NNs in solving inverse problems across a wide class of images. The comment further recommends comparing the current method with these untrained NNs, providing a clear and actionable suggestion for the authors to place their work in context and enhance its relevance. This feedback is mostly helpful as it guides the authors to situate their work within the existing literature and potentially improve the depth and comprehensiveness of their analysis. However, it could be more helpful if it included specific references or examples of the papers to consider, which would provide even more detailed guidance. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This implies that the authors should consider improving the prox-linear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit instructions or concrete steps on how to implement this reformulation or improvement. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to clarify the motivation of Algorithm 1. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This provides clear guidance on what needs to be addressed regarding the motivation of Algorithm 1. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is somewhat verifiable as it provides a logical reasoning for the equivalence, but it lacks specific examples or references to support the assertion fully. The authors would need to further explore the reasoning themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could help the authors clarify the rationale behind their approach and potentially improve the clarity of their work. However, the comment lacks specific guidance or suggestions on how to address this issue or improve the motivation of Algorithm 1. While it points out a potential weakness, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point requests clarification on why the performance degrades when using additional information about missing, wrong, or redundant data in the FBN results. While it explicitly asks for an explanation, it does not provide specific guidance on how the authors should address this issue or what aspects of their analysis might be lacking. The action is explicit in asking for clarification but lacks concrete details on how to provide that clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the performance degradation when using additional information about missing, wrong, or redundant data in the FBN results. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the FBN results, noting a performance degradation when using additional information about missing, wrong, or redundant data. It requests clarification on this point, which is a relevant and actionable piece of feedback. However, the comment does not provide suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches and the use of stacked LSTMs. It provides examples of unclear sections, such as the conversion of stacked LSTM to sequential LSTM and the explanation of \"lower hierarchical layers zooming in time.\" By highlighting these specific areas, the comment provides explicit and concrete guidance on what needs to be clarified or improved in the draft. The authors are given clear instructions on where to focus their revisions, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of where the explanation is unclear, such as the conversion of stacked LSTM to sequential LSTM and the explanation of \"lower hierarchical layers zooming in time.\" This level of detail helps the authors understand what needs to be clarified or improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first two sections of the paper are difficult to read due to the lack of clear explanations of previous approaches. The reviewer provides specific examples, such as the conversion of stacked LSTM to sequential LSTM and the explanation of \"lower hierarchical layers zooming in time,\" to illustrate the issues. These examples offer a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar cases where such explanations were successfully provided. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and explanation of the first two sections of the paper, particularly regarding the stacking of previous approaches and the conversion of stacked LSTM to sequential LSTM. It provides detailed examples of where the explanation is unclear, such as the lack of explanation for the stacked LSTM conversion and the meaning of \"lower hierarchical layers zooming in time.\" This feedback is highly helpful as it offers precise guidance on where the authors need to improve the clarity of their explanations, allowing them to make significant improvements to the readability and comprehensibility of their paper. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the analysis of flatness, specifically questioning whether minimizing the averaged loss across noise-injected models ensures flat minima. The reviewer explicitly states that the authors need to provide an analysis on the losses of the noise-injected models after training to support their claim about finding flat minima. This feedback is explicit and provides a clear action for the authors to take, which is to conduct the necessary analysis. The comment is specific and actionable, as it guides the authors on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (3)\" and the \"loss used for training base model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of flatness and the losses of the noise-injected models after training. This provides clear guidance on what the authors need to revise. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the proposed method finds flat minima, noting that the analysis of flatness is missing. It provides a logical reasoning by explaining that minimizing the averaged loss across noise-injected models does not ensure flatness. The comment suggests that an analysis of the losses of the noise-injected models after training is required to support the claim. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or studies that support the argument about flatness analysis, which would elevate it to a fully verifiable claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper regarding the analysis of flatness, specifically questioning whether minimizing the averaged loss across noise-injected models ensures flat minima. It provides a clear and actionable suggestion by recommending that the authors conduct an analysis on the losses of the noise-injected models after training to support their claim about finding flat minima. This feedback is valuable as it directs the authors to a specific area that needs further exploration and justification, which can significantly enhance the robustness of their findings. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the presentation of the model in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides specific actions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are explicit and concrete, giving the authors clear guidance on how to enhance the clarity and accessibility of their presentation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This level of detail helps the authors understand what changes are needed to enhance the presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model presentation in section 4 is complicated and requires careful reading, possibly with reference to the supplement. The reviewer provides a specific suggestion to improve the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment offers a logical suggestion for improvement, it lacks detailed examples or references to support the claim that the current presentation is overly complex. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the suggestion without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the model in section 4, noting that it is somewhat complicated and requires careful reading. It provides actionable suggestions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. These recommendations are clear and constructive, offering the authors a concrete way to enhance the clarity and accessibility of their presentation. By addressing these suggestions, the authors can significantly improve the readability and comprehensibility of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly questions the understanding of the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This direct inquiry provides a clear action for the authors to take, which is to clarify the source of the test data and whether a ground truth exists. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking about the source of the test data and whether there is a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the red line in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about Figure 3, asking for clarification on the source of the test data and whether there is a ground truth associated with the red line. This feedback is clear and actionable, as it prompts the authors to provide additional information or clarification in their manuscript. By addressing this point, the authors can improve the transparency and comprehensibility of their work. However, the comment could be more helpful if it suggested how the authors might address this issue or provided context for why this information is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the goal of the paper, specifically questioning the lack of comparison or justification of the proposed method against existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that if the claim is to establish the method as a foundation model, the authors should clarify this and demonstrate or justify its future usefulness. While the comment implies that the authors should provide comparisons or justifications, it does not explicitly instruct them to do so. The action is somewhat clear but lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically questioning the lack of comparison or justification of the proposed method against existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that if the claim is to establish the method as a foundation model, the authors should clarify this and demonstrate or justify its future usefulness. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or discussion sections where the paper\\'s goals and contributions are typically outlined. The comment is specific in detailing what needs to be addressed regarding the comparison and justification of the method. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s goal, specifically questioning the lack of comparison or justification of the proposed method against existing DAS earthquake detectors, such as PhaseNet-Das. The reviewer suggests that if the claim is to establish the method as a foundation model, the authors should clarify this and demonstrate or justify its future usefulness. While the comment identifies a gap in the paper\\'s comparison and justification, it lacks specific examples or references to other DAS detectors, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the paper\\'s goal, specifically questioning the lack of comparison or justification of the proposed method against existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that if the claim is to establish the method as a foundation model, the authors should clarify this and demonstrate or justify its future usefulness. This feedback is clear and actionable, as it directs the authors to provide a clearer rationale for their work and to demonstrate its potential benefits. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or examples of how to demonstrate future usefulness. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides a general direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the alignment of results in Table 6 with those in Table 1 (MCT-pair) and asks about the ablation studies of MCT without adaptive metrics. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete steps on how to investigate or resolve these questions. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the alignment and ablation studies further. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCT-pair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the alignment of results in Tables 1 and 6 and the ablation studies of MCT without adaptive metrics. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the alignment of results in Tables 1 and 6 and the ablation studies of MCT without adaptive metrics. These questions highlight potential inconsistencies or areas that need further clarification in the paper. By pointing out these issues, the comment provides the authors with clear directions for improvement, prompting them to investigate and address these discrepancies. However, the comment could be more helpful if it offered suggestions on how to resolve these issues or provided additional context. Overall, the feedback is mostly helpful as it identifies specific areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to implement this suggestion or what specific aspects of AccNet should be considered. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what the authors need to consider or address in their work. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion regarding the inclusion of AccNet in a larger predictor. It does not contain any claims, opinions, or judgments that require verification. The statement is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the potential inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, which uses similar operators. This question prompts the authors to consider an additional application or integration of their work, which could lead to broader impact or relevance. However, the comment lacks specific guidance or suggestions on how to implement this idea or what aspects of AccNet might be relevant in this context. While it encourages the authors to think beyond their current scope, it does not provide actionable steps or detailed feedback. Therefore, the comment is somewhat helpful, as it offers a direction for exploration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper, such as undefined abbreviations and the lack of definition for superscript notation in an equation. It provides examples of these issues, which helps the authors understand what needs to be addressed. The comment also includes references to related works, which could guide the authors in improving their draft. While the comment does not explicitly instruct the authors to make these changes, the actions are clear and concrete, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L73 and L166) and an equation (Eq 6), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with undefined abbreviations and the lack of definition for superscript notation, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights two specific issues: undefined abbreviations and the lack of definition for superscript notation in an equation. The comment provides examples of these issues, which helps verify the claim. Additionally, it references three external works, which could provide context or guidance for addressing these issues. However, the comment could be strengthened by explaining how these issues impact the understanding of the paper or by providing more detailed examples. Overall, the claim is mostly verifiable due to the specific examples and references provided, but it could be further supported with more detailed reasoning or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as undefined abbreviations and the lack of definition for superscript notation in an equation. These are actionable points that the authors can address to improve the clarity and readability of their draft. Additionally, the comment provides references to related works, which could help the authors situate their work within the existing literature. However, the comment could be more helpful if it offered suggestions on how to define these abbreviations or clarify the notation. Overall, the feedback is mostly helpful as it highlights specific areas for improvement and provides some guidance, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It corrects a statement in the Related Work section, clarifying that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This feedback is actionable as it directly addresses the inaccuracy in the text. Additionally, it points out a grammatical issue in Section 3, where the pronoun \"it\" lacks a clear reference, prompting the authors to clarify the intended reference. Both comments are specific and provide clear guidance on how to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the inaccuracies in the text regarding the Walkman algorithm and the use of \"it\" in Section 3, offering clear guidance on what needs to be corrected. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization\" by pointing out that the Walkman algorithm is solved by ADMM with two versions. This provides a specific counterexample to the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that ADMM is not equivalent to SGD. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two distinct issues. First, it corrects an inaccuracy in the Related Work section, pointing out that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This clarification is important for the accuracy of the paper\\'s literature review. Second, it identifies a grammatical issue in Section 3, where the pronoun \"it\" lacks a clear reference, prompting the authors to clarify the intended reference. Both points are clear and directly address specific weaknesses in the manuscript, making the feedback highly helpful for the authors to improve their draft. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the paper. The comment is concrete, as it outlines a specific method for enhancing the paper\\'s credibility and convincingness. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on what the authors need to do to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the reported results in Tables 1 and 2, suggesting that relying solely on the dev set for hyper-parameter search and model selection is insufficient for convincing results. The reviewer recommends presenting average results on the test set with clearly defined error bars under different random seeds. This claim is somewhat verifiable as it logically argues that using the dev set alone may not accurately reflect the model\\'s performance on unseen data. However, the comment lacks specific examples or references to support the assertion that using the test set is necessary for convincing results. Providing more detailed reasoning or evidence would strengthen the claim, making it easier for the authors to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out a potential issue with the reported results, specifically the reliance on the dev set for hyper-parameter search and model selection, which may not be sufficient for convincing results. The reviewer recommends presenting average results on the test set with clearly defined error bars under different random seeds. This feedback is specific and offers a concrete way for the authors to enhance the credibility and robustness of their findings. By addressing this suggestion, the authors can significantly improve the quality and reliability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct a more comprehensive ablation study on the parameter \\\\(\\\\alpha\\\\). It specifies that the current study only considers values of \\\\(\\\\alpha\\\\) set to 1e-4, 1e-1, and 5e-1, with a large gap between 1e-4 and 1e-1. The reviewer recommends providing additional values, such as 1e-2 and 1e-3, to fill in this gap. This feedback is clear and provides concrete guidance on how to expand the ablation study, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a more comprehensive ablation study on the parameter \\\\(\\\\alpha\\\\) with additional values such as 1e-2 and 1e-3. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation study on \\\\(\\\\alpha\\\\) is insufficient because it only considers values of 1e-4, 1e-1, and 5e-1, with a large gap between 1e-4 and 1e-1. The reviewer recommends providing additional values, such as 1e-2 and 1e-3, to fill in this gap. This claim is somewhat verifiable as it highlights a specific issue with the study\\'s design and suggests a potential improvement. However, it lacks detailed reasoning or references to support why these additional values are necessary or how they would impact the study\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the insufficient ablation study on the parameter \\\\(\\\\alpha\\\\). It points out that the study only considers values of \\\\(\\\\alpha\\\\) set to 1e-4, 1e-1, and 5e-1, with a large gap between 1e-4 and 1e-1. The reviewer recommends providing more values of \\\\(\\\\alpha\\\\), at least 1e-2 and 1e-3, to fill in this gap. This feedback is clear and actionable, as it guides the authors on how to improve their study by conducting a more comprehensive ablation analysis. By following this suggestion, the authors can enhance the robustness and comprehensiveness of their experimental results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology and dataset used in the paper. It asks how many topics were used, how the topic-word parameters were obtained for the \"real\" dataset, and how big the AG news dataset is. Additionally, it suggests that the main paper should describe the number of documents in the training and testing sets and the number of vocabulary words. These questions imply that the authors should provide more detailed information about their methodology and dataset. While the comment does not explicitly instruct the authors to make specific changes, the questions are clear and concrete, providing a clear direction for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology and dataset used in the paper, specifically asking about the number of topics used, the topic-word parameters for the \"real\" dataset, the size of the AG news dataset, and the number of documents and vocabulary words in the training and testing sets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or dataset sections. The questions are specific, as they seek detailed information about the dataset and methodology. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology and dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the methodology and dataset used in the paper. It asks how many topics were used, how the topic-word parameters were obtained for the \"real\" dataset, and how big the AG news dataset is. Additionally, it suggests that the main paper should describe the number of documents in the training and testing sets and the number of vocabulary words. These questions highlight specific areas where the paper lacks clarity and suggest that the authors provide more detailed information about their methodology and dataset. While the comment is somewhat helpful in identifying areas for improvement, it could be more beneficial if it offered suggestions on how to address these issues or provided examples of what kind of information should be included. Overall, the feedback is somewhat helpful as it points out important gaps in the paper but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It also notes that this is different from Figure 4, where the discriminator is co-adapting with the generator and might get stuck at a local optimum. While the comment provides a clear action\u2014training a discriminator\u2014it does not offer detailed guidance on how to implement this suggestion or what specific steps to take. The authors are left with a general idea of what needs to be done but without concrete instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that training a discriminator on generations from the learned model is needed to evaluate the claim of reducing exposure bias. The comment provides a clear rationale for this suggestion, noting the difference between Figures 1 and 4 in terms of the discriminator\\'s role during training. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. The comment provides a logical reasoning by contrasting this approach with Figure 4, where the discriminator is co-adapting with the generator and might get stuck at a local optimum. This reasoning is based on a common understanding of the role of discriminators in generative models. However, the comment could be strengthened by providing more detailed examples or references to similar studies that support this approach. As it stands, the claim is mostly verifiable, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for evaluating the claim of reducing exposure bias. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. This feedback is specific and offers a concrete step for the authors to take to strengthen their evaluation process. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it is necessary. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their evaluation methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the prompts in Table 6 and 7 are not well-organized, with all sentences squeezed together. However, it does not provide any explicit or implicit suggestions on how to improve the organization of the prompts. The authors are left without guidance on how to address this issue, such as by suggesting ways to restructure the prompts or provide additional spacing. Without actionable advice, the authors may struggle to know how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is that the prompts are not well-organized and all sentences are squeezed together. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prompts in Table 6 and 7 are not well-organized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is somewhat helpful as it identifies a potential area for improvement in the presentation of the prompts. However, it lacks depth and does not provide specific suggestions or guidance on how to reorganize the prompts or improve their readability. While it highlights a problem, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies issues with the clarity of the figures, specifically mentioning that the relationship between the sub-figures in Figure 2 is confusing and that certain modules, such as CMAF, L_BT, and VoLTA, are not labeled. This feedback provides clear and specific actions for the authors to take, which are to improve the clarity of the figures and ensure all modules are labeled. The comment is explicit and concrete, giving the authors precise guidance on how to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2\" and specific modules like \"CMAF, L_BT, VoLTA\" that are not labeled, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the figures and the labeling of certain modules. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures are not clear, specifically mentioning that the relationship between sub-figures in Figure 2 is confusing and that certain modules are not labeled. This claim is somewhat verifiable as it provides specific examples of what is unclear or missing in the figures. However, it lacks detailed reasoning or suggestions on how to improve the clarity, such as proposing specific labeling or organizational changes. The authors would need to infer the exact improvements needed, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relationship between sub-figures is confusing. It also points out that certain modules, such as CMAF, L_BT, and VoLTA, are not labeled. This feedback is clear and actionable, as it provides the authors with precise areas to address in order to improve the clarity and comprehensibility of their figures. By highlighting these specific issues, the comment offers valuable guidance for enhancing the draft. However, it could be more helpful if it included suggestions on how to improve the labeling or organization of the figures. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about questionable design choices, specifically the use of perplexity as a measure of semantic information retention after fine-tuning. It questions how factors like domain drift and catastrophic forgetting are controlled. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their design choices. The feedback lacks concrete actions or detailed advice, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about questionable design choices, specifically the use of perplexity as a measure of semantic information retention after fine-tuning. It questions how factors like domain drift and catastrophic forgetting are controlled. However, the comment does not specify which part of the paper these design choices are discussed in, making it weakly grounded. The comment is specific in its critique of the design choices and the need for controlling factors like domain drift and catastrophic forgetting. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of perplexity as a measure of semantic information retention after fine-tuning, suggesting that it may not adequately address factors like domain drift and catastrophic forgetting. While the comment raises valid concerns, it lacks specific examples or references to support the claim that perplexity is an inadequate measure. The reasoning is somewhat verifiable, as it highlights potential issues with the chosen metric, but it could be strengthened with more detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about questionable design choices, specifically the use of perplexity as a measure of semantic information retention after fine-tuning. It questions how factors like domain drift and catastrophic forgetting are controlled, which are important considerations in the context of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their design choices. While it identifies a potential issue, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is clear and provides concrete guidance on what needs to be added to the draft, making it highly actionable. The authors know exactly what information to include and how to improve the Related Work section.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section and the paragraph on \"long-context language models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be addressed, including a comprehensive overview of existing methods and their limitations, as well as specific examples of sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for improvement, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section lacks details and suggests that the paragraph on long-context language models should provide a more comprehensive overview of existing methods and their limitations. The reviewer supports this claim by listing specific types of methods that should be discussed, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed list provides a clear direction for the authors to improve their work, making the claim mostly verifiable. However, the comment could be strengthened by providing examples or references to these methods, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the Related Work section, noting that it lacks details and does not provide a comprehensive overview of existing methods and their limitations. It offers a clear and actionable suggestion by specifying the types of methods that should be discussed, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is highly helpful as it guides the authors on how to enhance the Related Work section, ensuring it is more thorough and relevant to the context of the paper. By providing specific examples and categories of methods to cover, the comment empowers the authors to make significant improvements to their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the writing are unclear or how they could be improved. The feedback lacks explicit instructions or concrete examples, leaving the authors uncertain about which aspects of the writing need attention. As a result, the comment is vague and does not provide actionable guidance, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing needs improvement and mentions that some points are unclear. However, it does not specify which parts of the paper are unclear or how the writing could be improved. Without explicit references to sections, figures, or specific content, the authors cannot confidently determine which parts of the paper need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the writing should be improved\" and that \"some points in the paper are unclear.\" However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or examples of what is unclear or how the writing could be improved, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it lacks specificity and does not provide detailed guidance or examples of what needs to be clarified or improved. Without concrete suggestions or actionable feedback, the authors are left without a clear path to enhance their draft. This lack of detail and specificity makes the comment barely helpful, as it identifies an issue but does not assist the authors in addressing it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the writing and annotations are difficult to follow, indicating a need for improvement. However, it does not provide specific guidance on how to improve the writing or what aspects of the annotations are problematic. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to address the issue. Since the comment is vague and does not offer actionable steps, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the writing and annotations are difficult to follow, suggesting a need for improvement. However, it does not specify which parts of the paper are problematic or provide details on what aspects of the writing or annotations are unclear. Without specific references or examples, the authors cannot effectively identify the areas needing attention. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"Poor writing and annotations are a little hard to follow,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the writing and annotations are difficult to follow, indicating a need for improvement in clarity and readability. However, it lacks specific examples or detailed guidance on what aspects of the writing or annotations are problematic. Without actionable feedback or suggestions for improvement, the authors are left with a general critique but no clear direction on how to enhance their draft. Therefore, the comment is barely helpful, as it identifies an issue but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the proposed method in Table 2, specifically noting that only 8 of the 14 evaluation metrics achieve state-of-the-art (SOTA) performances. It also questions why the proposed method achieves the best overall F1 score under a specific setting while not achieving the best F1 score in all single types. While the comment highlights areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they might need to investigate or clarify these performance discrepancies, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of only 8 out of 14 evaluation metrics achieving state-of-the-art (SOTA) performances for the proposed method. Additionally, it raises a question about the performance under a specific setting, which further specifies the issue. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the performance of the proposed method in Table 2, noting that only 8 of the 14 evaluation metrics achieve state-of-the-art (SOTA) performances. It also questions why the proposed method achieves the best overall F1 score under a specific setting while not achieving the best F1 score in all single types. While the comment highlights a discrepancy in performance, it lacks detailed reasoning or evidence to support the claim. The authors may find it challenging to understand the basis of the critique without further explanation or examples. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in Table 2, noting that only 8 of the 14 evaluation metrics achieve state-of-the-art (SOTA) performances. It also raises a question about the discrepancy in performance under a specific setting, where the proposed method achieves the best overall F1 score but not the best F1 score in all single types. This feedback is somewhat helpful as it highlights a potential inconsistency in the results and prompts the authors to investigate and clarify these discrepancies. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into potential causes for the observed performance differences. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the proposed solution is an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any specific suggestions or actions for the authors to take. The comment lacks clarity and does not offer guidance on how the authors might improve their draft or address the incremental nature of their solution. Without explicit or implicit actions or suggestions, the authors are left without direction on how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the proposed solution is an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the solution are considered incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed solution is an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the proposed solution is an incremental step compared to the relaxation proposed by Guzman et al. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the results presentation, specifically mentioning that the y-axis in Figures 2 and 3 is labeled as \"performance,\" which is ambiguous, and that the runtime is not represented. The reviewer suggests using a scatter plot with x/y axes being runtime/performance to help readers better understand and interpret the results. Additionally, the comment advises highlighting the best results in tables. These suggestions are clear and concrete, giving the authors specific actions to take to enhance the clarity and presentation of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as labeling the y-axis as \"performance\" and using a scatter plot with x/y axes being runtime/performance to better understand and interpret the results. Additionally, it suggests highlighting the best results in tables. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results presentation could be improved by clarifying the y-axis labels in Figures 2 and 3, which are currently labeled as \"performance,\" and by including runtime information. The suggestion to use a scatter plot with x/y axes being runtime/performance is a logical recommendation to enhance clarity. However, the comment lacks specific examples or references to support the claim that the current presentation is ambiguous or insufficient. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the presentation of results in the paper. It points out that the y-axis labels in Figures 2 and 3 are ambiguous, suggesting that the y-axis should be labeled as \"performance\" instead of just \"performance.\" Additionally, it recommends using a scatter plot with x/y axes being runtime/performance to enhance the reader\\'s understanding and interpretation of the results. The comment also advises highlighting the best results in tables, which is a practical suggestion for improving the clarity and impact of the results section. This feedback is clear, constructive, and offers concrete steps for the authors to enhance the clarity and effectiveness of their results presentation, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the setting of Unsupervised Online Adaptation, noting that the model requires a training set with documents, queries, and labels, which seems to contradict the term \"unsupervised.\" However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending ways to clarify the setting or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the setting of Unsupervised Online Adaptation, noting that the model requires a training set with documents, queries, and labels, which seems to contradict the term \"unsupervised.\" This provides clear guidance on what aspect of the setting is questionable. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the setting of Unsupervised Online Adaptation, noting that the model requires a training set with documents, queries, and labels, which seems to contradict the term \"unsupervised.\" The comment provides a logical reasoning by pointing out the apparent contradiction between the requirement for annotations and the claim of unsupervised adaptation. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the issue, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology used in the paper, specifically questioning the setting of \"Unsupervised Online Adaptation\" as described in Section 3.1. It points out that the model requires a training set with documents, queries, and labels, which seems to contradict the term \"unsupervised.\" This feedback is valuable as it highlights a possible misalignment between the terminology and the actual process described in the paper. However, the comment does not provide suggestions on how to address this issue or clarify the terminology, which limits its helpfulness. While it prompts the authors to reconsider their terminology, it lacks actionable guidance for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results are presented in a convoluted manner and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. However, it does not provide explicit guidance on how to improve the presentation of the results or suggest alternative ways to present the data. The comment lacks actionable details, such as recommending specific changes to the presentation or providing examples of how to better incorporate safety violations into the results. As a result, the authors are left without clear direction on how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the presentation of results, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is unclear about the presentation of results, providing some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results are presented in a convoluted manner and that the safety violations of the agent in the first 1000 episodes are disregarded. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. It highlights a lack of clarity in the reason for presenting the results in this manner. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might improve the presentation or address the issue. This limits the comment\\'s usefulness, as it offers insight into a problem but lacks actionable advice. Therefore, the comment is somewhat helpful, as it provides some direction for improvement but not comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific writing errors in the paper, such as \"informative informative\" and \"performance\" on particular pages. This feedback is explicit and provides concrete examples of what needs to be corrected, allowing the authors to directly address these issues. The clarity and specificity of the feedback make it highly actionable, as the authors know exactly what needs to be revised to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages (page 5 and page 1) where writing errors are found, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the exact errors, such as \"informative informative\" and \"performance,\" which need to be corrected. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific writing errors in the paper, such as \"informative informative\" and \"performance,\" which are factual observations. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific writing errors in the paper, such as \"informative informative\" and \"performance,\" which are mentioned on particular pages. This feedback is actionable as it provides clear and precise guidance on what needs to be corrected, allowing the authors to improve the clarity and professionalism of their manuscript. However, the comment could be more helpful if it included suggestions on how to avoid such errors in the future or if it provided additional context on why these errors are significant. Overall, the comment is mostly helpful as it directs the authors to specific areas needing correction, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two separate comments. The first comment, regarding a statement on line 134, suggests that the statement is only true for a specific function and depends on the maximum slope. This implies that the authors should clarify or provide additional context for this statement. The second comment, regarding Theorem 4.1, suggests that the authors should elaborate more on why the theorem holds, particularly in terms of the RNN converging to the nearest FP. Both comments imply actions\u2014clarifying the statement on line 134 and elaborating on Theorem 4.1\u2014but they are not explicitly stated. The actions are somewhat vague, as they lack specific guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on what needs to be addressed, such as clarifying the statement on line 134 and elaborating on why Theorem 4.1 holds. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim questions the validity of a statement on line 134, suggesting that it is only true for a specific function and depends on the maximum slope. This claim is somewhat verifiable as it provides a logical reasoning that the statement may not be universally applicable, but it lacks specific examples or references to support the assertion. The second claim suggests that Theorem 4.1 could benefit from further elaboration in the main text, particularly regarding the convergence of the RNN to the nearest FP. This claim is also somewhat verifiable, as it provides a logical basis for the suggestion but lacks detailed reasoning or examples. Overall, the review point provides some justification but requires more detailed evidence or references to be fully verifiable. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it questions a statement on line 134, suggesting that it is only true for a specific function and depends on the maximum slope. This feedback is somewhat helpful as it points out a potential inaccuracy or lack of clarity in the statement, prompting the authors to reconsider or clarify this point. Second, it suggests that Theorem 4.1 could benefit from further elaboration in the main text, particularly regarding the convergence of the RNN to the nearest FP. This feedback is more actionable, as it provides a specific area for improvement and a rationale for why this elaboration would be beneficial. Overall, the comment offers valuable insights and suggestions for enhancing the clarity and accuracy of the paper, making it mostly helpful. However, it could be more comprehensive by providing additional guidance or examples on how to address these issues. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the plan-based method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, as shown in Table 2. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the generalizability of the proposed method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the plan-based method and its limitations, specifically mentioning the need for manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also compares the learned plan methods to those with pre-defined plans, as shown in Table 2, and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment does not explicitly mention which part of the paper discusses these methods or Table 2, making it weakly grounded. The comment is specific in detailing the issue with the plan-based method and its generalizability, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It further suggests that the learned plan methods are not comparable to those with pre-defined plans, as evidenced by Table 2. This claim is somewhat verifiable as it provides a logical reasoning based on the comparison in Table 2. However, the comment lacks specific examples or detailed explanations of how the learned plan methods differ from those with pre-defined plans, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the plan-based method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, as shown in Table 2. This feedback highlights a potential weakness in the generalizability of the proposed method to new datasets without ground truth summaries. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it offers valuable insight into a critical aspect of the work, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct experiments using multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. While the comment explicitly states the need for this exercise, it does not provide specific guidance on how to implement it or what specific aspects should be considered in the additional experiments. The action is explicit but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the issue of reporting results for a single held-out test set in nearly all experiments. It suggests that standard practice involves using multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. The comment also provides a specific suggestion for improvement by encouraging the authors to conduct this exercise, even though it acknowledges the potential time constraints due to dataset size. This level of detail and specificity allows the authors to clearly understand what needs to be addressed and why, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the standard practice in most papers on Gaussian Processes (GPs) involves using multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. The reviewer acknowledges the potential time constraints due to dataset size but strongly encourages the authors to conduct this exercise. The claim is somewhat verifiable as it references a common practice in the field of GPs, providing a logical basis for the suggestion. However, it lacks specific examples or references to studies that have successfully implemented this approach, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single held-out test set, which is not standard practice in most papers on Gaussian Processes (GPs). The reviewer acknowledges the time constraints due to dataset size but strongly encourages the authors to conduct experiments using multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. This feedback is clear and actionable, as it suggests a specific improvement that could enhance the robustness and credibility of the results. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or discussed potential challenges in doing so. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide specific guidance on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer that they should simplify the method but without concrete steps or examples on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the method are considered overly complex. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method is more complex than necessary and suggests that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of how the method could be simplified, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might simplify the method or identify the underlying principle. Without concrete examples or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of \"s_n\" instead of \"s_t\" in algorithm 1, line 8, suggesting a potential error. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment implies that the authors should address these issues, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or correct the potential error. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of \"s_n\" instead of \"s_t\" and expresses curiosity about the asymptotic performance of the proposed method. The comment further requests average return results with more environment steps and provides a reference to a related work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of \"s_n\" instead of \"s_t\" in algorithm 1, line 8, suggesting a potential error. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions or suggestions. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the use of \"s_n\" instead of \"s_t\" in algorithm 1, line 8, suggesting a potential error. This is a clear and actionable piece of feedback that can help the authors correct any mistakes in their algorithm. Additionally, the comment expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. This part of the comment provides a direction for further exploration and analysis, which could enhance the paper\\'s depth and comprehensiveness. However, the comment could be more helpful if it included specific suggestions on how to address the asymptotic performance question or provided examples of how to present the requested results. Overall, the comment is mostly helpful as it identifies a potential error and suggests an area for further exploration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as the reviewer believes this is not accurate in the context of TopoNet. Additionally, it advises compressing the method section to focus on essential definitions and suggests double-checking grammatical errors, particularly with plurals and articles. Each of these points is clear and provides concrete guidance on how to improve the draft. The authors know exactly what changes to make, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"34 \\\"to force the neural network to memorize them\\\"\" and the \"method section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as toning down the statement about memorization, compressing the method section, and correcting grammatical errors. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests toning down the statement about the neural network memorizing critical points, as it contradicts the understanding of TopoNet [24]. This claim is somewhat verifiable as it references an external work (TopoNet) to support the argument, but it lacks detailed reasoning or examples to fully substantiate the claim. The reviewer does not provide specific evidence or examples from TopoNet to illustrate why the statement is inaccurate, leaving the authors to infer the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable pieces of feedback. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and constructive suggestion that could improve the accuracy of the paper. Additionally, it advises compressing the method section to focus on essential definitions, which is a clear and actionable recommendation for improving the clarity and conciseness of the paper. The comment also points out several grammatical errors, which is helpful for ensuring the paper\\'s professionalism. Overall, the comment is mostly helpful as it offers detailed and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a suggestion for improving the clarity of the paper by offering a more detailed explanation of the concept of uncertainty. It explicitly recommends updating the definition to include the distinction between epistemic model uncertainty and posterior distribution, and how these relate to each other. This feedback is clear and provides concrete guidance on how to enhance the clarity of the paper. The authors know exactly what changes to make to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to a specific statement in the paper, \"The uncertainty is defined based on the posterior distribution,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by explaining how the definition of uncertainty could be updated to include the distinction between epistemic model uncertainty and posterior distribution. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an update to the definition of uncertainty by explaining the relationship between epistemic model uncertainty and the prior and posterior distributions. This suggestion is based on logical reasoning, as it clarifies the concept of uncertainty in the context of Bayesian statistics. However, the comment does not provide specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and implement the suggestion, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the paper by offering a more detailed explanation of the concept of uncertainty. It suggests updating the definition to include the distinction between epistemic model uncertainty and the prior and posterior distributions, which would help readers understand the relationship between these concepts. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can significantly improve the comprehensibility of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the overrated comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which have similar sizes. It implies that if the authors claim COCO-LM is parameter-efficient, the conclusion should also apply to these other models. The comment also raises questions about the experimental setup, specifically why the authors switched the types of BPE vocabulary and whether this change affects performance variance. While the comment raises important questions, it does not provide explicit actions or concrete guidance on how to address these issues. The authors are left to infer that they should reconsider their comparison and provide justification for their experimental setup. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with Megatron and questions the overrated nature of this comparison. It provides specific examples of other approaches, such as RoBERTa, ELECTRA, and DeBERTa, which have similar sizes as COCO-LM. This makes the comment specific in terms of the issue it raises. However, it does not explicitly mention which part of the paper discusses the comparison with Megatron, leaving the authors to infer that it relates to the results or discussion sections. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its critique. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the overrated comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which have similar sizes. This claim is somewhat verifiable as it provides a logical reasoning by comparing the performance of different models with similar sizes. However, the comment lacks specific data or references to substantiate the claim fully, making it difficult for the authors to directly verify the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the overrated comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which have similar sizes. This feedback is somewhat helpful as it challenges the authors to reconsider their claims about the parameter efficiency of COCO-LM. However, the comment lacks specific guidance on how the authors might address this issue or improve their analysis. Additionally, it raises questions about the experimental setup, such as the change in BPE vocabulary, but does not provide suggestions on how to address these questions. Overall, the comment identifies a potential weakness but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides specific observations from the histogram in Fig 3, noting that the GS-P-50 model has a smaller class selectivity score, indicating that it shares more features and ResNet-50 learns more class-specific features. The comment also mentions the authors\\' hypothesis that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the analysis. While it raises questions and provides references, it lacks concrete suggestions for improvement, leaving the authors uncertain about how to enhance their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific line range \"from line 128 to 149\" and references Figure 3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the validity of the analysis and providing a hypothesis about the GS-P-50 model\\'s performance. The comment further supports its claim with references to external works, which adds specificity to the critique. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the analysis from line 128 to 149, specifically regarding the class selectivity score and the hypothesis that additional context may allow the network to reduce its dependency. The reviewer provides a logical reasoning by referencing the histogram in Fig 3 and comparing the class selectivity scores of GS-P-50 and ResNet-50. This reasoning is supported by external references, which adds to the verifiability of the claim. However, the comment could be strengthened by providing more detailed explanations or examples from the references to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, from line 128 to 149, questioning its convincing nature. It provides a detailed critique by referencing the histogram in Fig 3 and explaining the implications of the class selectivity scores. The comment also raises a pertinent question about the hypothesis that additional context may allow the network to reduce its dependency, prompting the authors to provide a clearer rationale for their observations. Additionally, the comment references relevant literature, which can guide the authors in further exploring and substantiating their claims. This feedback is clear, actionable, and provides a solid foundation for the authors to improve their analysis and presentation. Therefore, it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the validity of certain conclusions, specifically regarding the accumulation of noise in continuous learning with unlabeled data. It suggests that the results might be due to limited exploration of combination methods and mentions specific works that have shown potential in rehearsal-free continual learning, such as feature-replay methods. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their conclusions. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to respond to the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the validity of certain conclusions, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It provides examples of works that have shown potential in rehearsal-free continual learning, such as feature-replay methods, and references specific studies like [R1], [R2], and [R3]. However, the comment does not explicitly mention which part of the paper these conclusions are found in, making it weakly grounded. The comment is specific in detailing the issue with the conclusions and providing references to related works, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of certain conclusions, specifically regarding the accumulation of noise in continuous learning with unlabeled data. The reviewer provides examples of works that have shown potential in rehearsal-free continual learning, such as feature-replay methods, and references specific studies like [R1], [R2], and [R3]. This provides a logical basis for the claim, as it suggests that the conclusions might be due to limited exploration of combination methods. However, the comment could be strengthened by providing more detailed comparisons or analyses of these referenced works. Overall, the claim is mostly verifiable due to the inclusion of relevant references, but it lacks comprehensive evidence or detailed reasoning to fully substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the validity of certain conclusions in the paper, specifically regarding the accumulation of noise in continuous learning with unlabeled data. It suggests that the results might be due to limited exploration of combination methods and references specific works that have shown potential in rehearsal-free continual learning, such as feature-replay methods. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s conclusions and provides examples of relevant literature that could be considered for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or integrate the referenced works into the paper. Overall, the feedback provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions. It explicitly asks for more explanations about Figure 5a and how the authors dealt with DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as a reference did, which implies that the authors should consider including such an analysis. While the comment provides explicit actions, it lacks concrete details on how to implement these suggestions, such as specific aspects of Figure 5a that need more explanation or how to analyze energy consumption. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions \"Fig. 5 a,\" allowing the authors to identify the part of the paper being addressed. However, it lacks full grounding because it does not specify which part of the paper discusses \"other bit operations\" or the \"aer format\" and \"DVS input.\" The comment is specific in its request for more explanations about Figure 5a and suggests analyzing energy consumption as a reference, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims and suggestions. It questions the use of \"other bit operations\" and asks for more explanations about Figure 5a. Additionally, it inquires about how the authors handled DVS input when the input is in aer format and suggests analyzing energy consumption as a reference did. While the comment raises valid points, it lacks specific examples, detailed reasoning, or references to support these claims. The suggestions are somewhat verifiable, as they provide a direction for improvement but require more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several points that could help the authors improve their draft. It acknowledges the contribution of \"11\" but questions the inclusion of other bit operations, suggesting that this could enhance the paper. It also points out that Figure 5a seems strange and requests more explanations, which is a specific and actionable suggestion. Additionally, the comment inquires about how the authors handled DVS input when the input is in aer format and suggests analyzing energy consumption as a reference did, which could strengthen the paper\\'s solidity. While the comment provides valuable insights and suggestions, it could be more helpful by offering more detailed guidance on how to address these issues. Overall, the feedback is mostly helpful as it identifies areas for improvement and provides some direction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first two bullets about contributions at the end of the introduction can be combined. This is an explicit suggestion, as it directly instructs the authors to make a specific change to their draft. However, it does not provide detailed guidance on how to combine these bullets or what specific aspects should be merged. While the action is clear, the lack of detailed instructions makes it somewhat vague in execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions (at the end of the intro),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that these two bullets can be combined, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the first two bullets about contributions at the end of the introduction can be combined. However, it does not provide any justification or reasoning for why this combination would be beneficial or necessary. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a specific suggestion for improving the clarity and organization of the paper by recommending that the first two bullets about contributions at the end of the introduction can be combined. This feedback is actionable and offers a clear direction for the authors to enhance the coherence and presentation of their work. However, the comment could be more helpful if it explained why this combination would be beneficial or how it might improve the reader\\'s understanding. Despite this, the suggestion is still valuable and provides a concrete step for the authors to take, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the dashed lines in specific figures (fig. 2A-B and 4B). This is a clear and direct action, leaving no ambiguity about what the authors need to do to improve their draft. The comment is specific and provides concrete guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (\"fig. 2A-B and 4B\"), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the dashed lines in specific figures. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback by requesting the authors to define the dashed lines in specific figures (fig. 2A-B and 4B). This feedback is clear and directly addresses a potential area of confusion for readers, allowing the authors to improve the clarity and comprehensibility of their figures. By following this suggestion, the authors can enhance the reader\\'s understanding of their work, making the comment highly beneficial for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the data in Table 4 and the lack of detailed discussion on unsupervised pretraining in the main paper. It suggests that the authors should focus more on the pretraining method in the main paper, given its importance compared to other modules. While the comment implies that the authors should expand their discussion on unsupervised pretraining, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the lack of detailed discussion on unsupervised pretraining in the main paper, despite its importance indicated by the data in Table 4. The suggestion to focus more on the pretraining method in the main paper provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by the data in Table 4. However, it notes the lack of detailed discussion on unsupervised pretraining in the main paper. The reviewer suggests focusing more on the pretraining method, which is supported by the comparison with the ablation study in Table 5. While the comment provides some reasoning and references specific tables, it lacks detailed examples or further explanation of how the pretraining method impacts performance. This makes the claim mostly verifiable, as it provides a basis for the suggestion but could benefit from more detailed evidence or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of unsupervised pretraining, which is crucial for understanding the performance gains observed. It highlights the importance of this aspect by comparing it to other modules in the paper, suggesting that the authors should focus more on the pretraining method in the main paper. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, the comment could be more helpful if it offered suggestions on how to incorporate this discussion or provided examples of what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide specific guidance on which parts of the writing are problematic or how the authors should simplify them. The action is implicit and vague, as the authors are left to infer which sections need improvement and how to achieve simplification. Without concrete examples or detailed suggestions, the authors may struggle to determine exactly what changes are needed to improve the clarity of their writing. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the writing is difficult to follow in many places and suggests simplification. However, it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This lack of detail makes it difficult for the authors to identify and address the issues effectively. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the writing is difficult to follow in many places and can be simplified.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it can be simplified. However, it lacks specificity and does not provide detailed guidance or examples of where the writing is unclear or how it could be improved. Without specific suggestions or examples, the authors may struggle to understand which parts of the writing need simplification or how to achieve this. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide an intuition for the proof of Theorem 1 and questions the dependence of the invertible function $f^*$ on the fixed $P^*$. It also asks whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment raises important questions and suggests areas for clarification, it does not explicitly instruct the authors on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should provide an intuition for the proof and address the questions about $f^*$ and $P^*$. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as the need for intuition in the proof of Theorem 1 and questions about the dependence of the invertible function $f^*$ on the fixed $P^*$. The comment also raises practical questions about determining which $P^*$ to fix. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide an intuition for the proof of Theorem 1 and questions the dependence of the invertible function $f^*$ on the fixed $P^*$. It also asks whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment raises valid questions and suggests areas for clarification, it does not provide specific reasoning or evidence to support these claims. The lack of detailed justification or examples makes the comment somewhat verifiable, as the authors would need to further develop the rationale themselves to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for more intuition in the proof of Theorem 1, which is a valuable suggestion for improving the clarity and accessibility of the paper. It also raises important questions about the dependence of the invertible function $f^*$ on the fixed $P^*$, asking whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. These questions prompt the authors to consider the practical implications of their theoretical findings and provide a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the feedback is somewhat helpful as it highlights areas for improvement and encourages deeper analysis, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inconsistency in the use of variables in equations (7) and (10), specifically noting that one uses \"X\" while the other uses \"H^(1).\" This implies that the authors should clarify the rationale behind this choice or consider making the equations more consistent. However, the comment does not explicitly instruct the authors to make any changes or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the equations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed, which provides full grounding. It also specifies the issue by questioning the inconsistency in the use of variables \"X\" and \"H^(1)\" in these equations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inconsistency in the use of variables in equations (7) and (10), specifically noting that one uses \"X\" while the other uses \"H^(1).\" This is a factual observation about the content of the paper, as it does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the use of variables in equations (7) and (10), noting that one uses \"X\" while the other uses \"H^(1).\" This observation highlights a potential issue in the paper that could confuse readers or affect the clarity of the mathematical presentation. However, the comment does not provide any suggestions or guidance on how the authors might address this inconsistency or clarify the equations. While it points out a specific area for improvement, it lacks actionable feedback that would empower the authors to make the necessary changes. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the description in Section 4.2, particularly regarding the use of the question to learn an attention on the image feature and the meaning of the term \\\\(\\\\sigma\\\\) in the equation. The reviewer suggests clarifying these points, which is an explicit action. Additionally, the comment raises a concern about the potential ill-conditioning and numerical instability due to the multiplication of sigmoid activations, suggesting that this aspect should also be clarified. The feedback provides clear and concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in that section, particularly the absence of a term for \\\\(r^q\\\\) and the unclear meaning of \\\\(\\\\sigma\\\\). The comment provides clear guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the description in Section 4.2, specifically regarding the use of the question to learn an attention on the image feature and the meaning of the term \\\\(\\\\sigma\\\\) in the equation. The reviewer suggests that the equation does not include a term for \\\\(r^q\\\\) and questions the meaning of \\\\(\\\\sigma\\\\), suggesting it might be a sigmoid activation. This critique is somewhat verifiable as it highlights specific issues with the clarity of the description and the potential implications of the equation. However, it lacks detailed reasoning or references to support the claim about the ill-conditioning and numerical instability due to the multiplication of sigmoid activations. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity of the description in Section 4.2, particularly regarding the use of the question to learn an attention on the image feature. It points out that the description does not match the equation in the section, specifically noting the absence of a term for \\\\(r^q\\\\) in the equation. The comment also questions the meaning of \\\\(\\\\sigma\\\\) in the equation and raises a concern about the potential ill-conditioning and numerical instability due to the multiplication of sigmoid activations. This feedback is mostly helpful as it provides clear and actionable suggestions for the authors to clarify their description and address potential issues with their methodology. However, it could be more helpful if it offered specific guidance on how to resolve these issues or suggested alternative approaches. Overall, the comment provides valuable insights that can guide the authors in improving their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It provides a specific example by taking Z\\\\' to be the empty set and explaining the expected outcome. This feedback is explicit and provides a clear action for the authors to address the conflict by either revising the definition or the equation. The comment is highly actionable as it gives precise guidance on how to resolve the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. The comment provides a specific example by taking Z\\\\' to be the empty set and explaining the expected outcome, which helps the authors understand the problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. The reviewer provides a specific example by taking Z\\\\' to be the empty set and explaining the expected outcome, which is that x and y should be independent given W. This reasoning is clear and logical, providing a solid basis for the claim. However, the comment could be strengthened by referencing specific sections or equations in the paper, which would make it fully verifiable. As it stands, the claim is mostly verifiable due to the logical reasoning and specific example provided, but it lacks detailed references to the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a specific example by taking Z\\\\' to be the empty set and explaining the expected outcome, which is that x and y should be independent given W. This feedback is clear and actionable, as it directs the authors to examine and potentially revise the equation or the definition to resolve the conflict. By pinpointing a specific issue and offering a concrete example, the comment provides valuable guidance for improving the draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify how the archetype positions are updated after initialisation in Algorithm 2. This request is direct and provides a clear action for the authors to take, which is to provide additional explanation or details on this aspect of the algorithm. The comment is specific and leaves no ambiguity about what the authors need to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of how the archetype positions are updated after initialisation, providing a clear direction for the authors to address. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of how the archetype positions are updated after initialisation in Algorithm 2. It does not make a subjective claim or suggestion but rather seeks clarification. Therefore, it is a factual inquiry and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the updating of archetype positions after initialisation in Algorithm 2. It asks the authors to clarify this aspect, which is a clear and actionable request for additional information. By addressing this point, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or offered insights into potential issues with the current explanation. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several missing pieces of information related to the empirical study, such as recording parameters for MRI, preprocessing steps, the recording condition (eyes-open or eyes-closed), a brief explanation of the harmonization technique, and the number of regions in the parcellation. The comment explicitly states that this information should be included in the supplement or the main text, providing clear and concrete actions for the authors to take. The feedback is specific and actionable, giving the authors a clear understanding of what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the empirical study and the supplement, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the missing information that should be included, such as recording parameters for MRI, preprocessing steps, the recording condition (eyes-open or eyes-closed), a brief explanation of the harmonization technique, and the number of regions in the parcellation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights several missing pieces of information related to the empirical study, such as recording parameters for MRI, preprocessing steps, the recording condition (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. While the comment identifies specific areas that need clarification, it does not provide detailed reasoning or examples to support why these details are crucial or how they impact the study. The lack of explicit justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, the recording condition (eyes-open or eyes-closed), a brief explanation of the harmonization technique, and the number of regions in the parcellation. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve the completeness and clarity of their study. However, while it highlights specific areas for improvement, it could be more helpful by suggesting how these details might be integrated into the paper or supplement. Overall, the comment is mostly helpful as it directs the authors to important missing information, but it could be more comprehensive with additional guidance on implementation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major risk associated with methods that exploit relationships between action units, specifically highlighting the potential differences in relationships across datasets. It suggests that cross-dataset experiments could be a good way to test the generalization of such work, which the paper currently lacks. While the comment implies that the authors should conduct cross-dataset experiments, it does not provide specific guidance on how to implement these experiments or which datasets to use. The action is implicit and somewhat vague, as the authors know they need to perform cross-dataset experiments but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential risk of methods exploiting relationships between action units, particularly the differences in correlations across datasets. The comment suggests performing cross-dataset experiments as a way to test the generalization of the work, which is a specific and actionable recommendation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential risk in methods that exploit relationships between action units, specifically noting the variability in these relationships across datasets. It provides a specific example of how AU6 can occur in different contexts, such as pain and happiness, and how this co-occurrence might differ across datasets like SEMAINE and UNBC pain. The comment suggests that cross-dataset experiments could test the generalization of such work, which the paper lacks. This reasoning is logical and supported by specific examples, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to similar studies that have successfully implemented cross-dataset experiments. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the potential variability in these relationships across datasets. It provides a specific example of how AU6 can occur in different contexts, such as pain and happiness, and how this co-occurrence might differ across datasets like SEMAINE and UNBC pain. The comment suggests a good way to test the generalization of such work by performing cross-dataset experiments, which the paper currently lacks. This feedback is clear and actionable, offering a concrete suggestion for improving the robustness and applicability of the work. However, it could be more helpful if it provided additional guidance on how to design and implement these cross-dataset experiments. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a contradiction between the statement in the paper and the reviewer\\'s observation regarding over-parameterization. The reviewer acknowledges that over-parameterization is beneficial in practice and references theoretical works supporting this claim. However, the comment does not provide explicit guidance on how the authors should address this contradiction or suggest any specific actions to improve the draft. The feedback lacks actionable details, leaving the authors uncertain about how to resolve the issue. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the statement about over-parametrization and provides a counter-argument by referencing theoretical works that show the benefits of over-parametrization. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim made in the paper regarding over-parametrization, suggesting that it is beneficial in practice and supported by theoretical works. The reviewer provides a counter-argument by referencing specific theoretical works, which helps substantiate the claim. However, the comment could be strengthened by providing more detailed references or examples from these theoretical works. As it stands, the claim is mostly verifiable due to the inclusion of references, but it could be more robust with additional details. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses a specific claim made in the paper regarding over-parametrization and its impact on performance. It challenges the statement by providing a counter-argument that over-parameterization is beneficial in practice and references theoretical works that support this view. This feedback is valuable as it prompts the authors to reconsider their claim and potentially revise their argument. However, the comment could be more helpful if it offered suggestions on how to integrate this counter-argument into the paper or provided additional references for further exploration. Overall, the comment is somewhat helpful as it identifies a potential issue and provides some direction for improvement, but it lacks detailed guidance or actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning and requests clarification on the correspondence between the learning curves and M-PHATE in Figure 3. The reviewer also asks specific questions about the learning curves, structural collapse, and accuracy numbers, providing clear guidance on what information is needed. Each of these points is actionable and concrete, giving the authors a clear understanding of what needs to be addressed in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 3\" and the \"experimental setting for continual learning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as explaining the correspondence between the learning curves and M-PHATE, questioning the relationship between performance and structural collapse, and clarifying the accuracy numbers. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and additional information, such as explaining the experimental setting for continual learning and the correspondence between learning curves and M-PHATE in Figure 3. It does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the addition of a few more sentences to explain the experimental setting for continual learning. It also requests clarification on the correspondence between the learning curves and M-PHATE in Figure 3, asking questions about the relationship between performance and structural collapse, and the accuracy numbers. This feedback is clear and directs the authors to address specific areas of confusion or lack of clarity in their manuscript. By following these suggestions, the authors can improve the comprehensibility and clarity of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It suggests that if the compared methods were not pre-trained, the results in Table 1 might be misleading. However, the comment does not provide explicit guidance on how the authors should address this issue, such as recommending specific actions to ensure fairness in the comparison. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental comparison with other methods, specifically mentioning that the proposed method was pre-trained before the fine-tuning stage. It questions whether the compared methods were also initialized with the same or similar pre-trained models, which is a relevant concern for the fairness of the comparison. The comment also references Table 1, providing some grounding by indicating the specific table being discussed. However, it lacks full grounding as it does not specify the exact part of the paper where the comparison is detailed. The comment is specific in its critique of the fairness of the comparison and the potential impact of pre-training on the results. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair because the proposed method was pre-trained before fine-tuning, while it is unclear if the compared methods were initialized with the same or similar pre-trained models. This claim is somewhat verifiable as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to substantiate the claim fully. The authors would need to investigate the details of the pre-training and initialization processes to address the concern, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. This is an important point that could affect the interpretation of the results, particularly when the proposed method performs poorly without SSL. However, the comment does not provide specific suggestions on how to address this issue, such as recommending a fairer comparison methodology or suggesting ways to account for pre-training differences. While it identifies a potential weakness, the feedback lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings, referencing a particular study by Reed et al. It explicitly suggests that the authors include an evaluation of their proposed method with these better embeddings, which would provide a more comprehensive comparison. The comment is explicit in its action and provides concrete guidance on how to implement it, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and the \"meta-data used here are \u00e2\u0080\u009cattribute\u00e2\u0080\u009d,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using better metadata embeddings and references a specific study by Reed et al. to support this suggestion. The comment provides clear guidance on what needs to be addressed and offers a specific reference for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the meta-data used in the zero-shot learning results on the CUB dataset could be improved for better performance. It references a specific study by Reed et al. to support the claim that better metadata embeddings are available. This provides a clear direction for improvement and a specific reference to substantiate the claim. The suggestion to explore the performance of the proposed method with better metadata embeddings is logical and well-supported by the reference, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the use of better metadata embeddings for the zero-shot learning results on the CUB dataset. It references a particular study by Reed et al. to support the claim that better metadata embeddings are available, which could enhance the performance of the proposed method. This feedback is clear and constructive, offering the authors a concrete direction for improving their work. Additionally, the comment acknowledges the authors\\' response to the reviews, which is a positive gesture. Overall, the comment is highly helpful as it provides a specific suggestion for improvement and references relevant literature, making it easy for the authors to implement the changes. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a plot with sparsity on the x-axis and performance on the y-axis to directly compare the flexibility of SGC with LoRA. This explicit suggestion provides a clear action for the authors to take, which is to create a visualization to demonstrate the practical benefits of SGC\\'s fine-grained control. The comment is specific and provides concrete guidance on how to implement the suggested action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a plot with sparsity on the x-axis and performance on the y-axis to compare the flexibility of SGC with LoRA. This allows the authors to accurately identify the part of the paper being addressed, providing clear guidance on what needs to be revised. The comment is also specific, as it details the type of visualization needed and the purpose of comparing the flexibility of SGC with LoRA. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about SGC offering a more flexible, fine-grained tradeoff is limited in applicability because PEFT methods typically target compute-constrained scenarios. The reviewer suggests including a plot with sparsity on the x-axis and performance on the y-axis to directly compare the flexibility of SGC with LoRA. This suggestion is based on logical reasoning, as it proposes a visual representation to demonstrate the practical benefits of SGC\\'s fine-grained control. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of SGC\\'s applicability. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the applicability of the proposed method, SGC, by pointing out that PEFT methods typically target compute-constrained scenarios where fine-grained control may require extra tuning. It suggests including a plot with sparsity on the x-axis and performance on the y-axis to directly compare the flexibility of SGC with LoRA, which could provide a more intuitive demonstration of the practical benefits of SGC\\'s fine-grained control. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the paper\\'s clarity and impact. However, it could be more helpful if it provided additional context or examples of how such a plot might be constructed. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since ERM and plug-in have similar performance to Kearns et al., it would be beneficial to have the code published. While the comment implies that the authors should address the discrepancy in training time and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the code should be published. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and the \"German and Law school dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the reasonableness of the training time difference between Gerrymandering and Independent and suggests that the code should be published due to the similar performance of ERM and plug-in to Kearns et al. This provides clear guidance on what needs to be addressed or clarified. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since ERM and plug-in have similar performance to Kearns et al., it would be beneficial to have the code published. However, the comment lacks specific evidence or references to support the claim about the training time discrepancy or the need for code publication. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since ERM and plug-in have similar performance to Kearns et al., it would be beneficial to have the code published. This feedback is somewhat helpful as it prompts the authors to consider and address a potential discrepancy in their experimental results. However, the comment lacks depth and does not provide specific guidance on how to investigate or resolve the issue. It also does not explain why the code publication would be beneficial, other than mentioning computation time. To be more helpful, the comment could include suggestions on how to analyze or present the data to clarify the discrepancy. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the human baseline and the model baseline, noting that the human baseline only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It suggests that this makes the human baseline weaker, apart from other factors mentioned in Section 4.1. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the human baseline. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the human baseline and the abstract, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the human baseline only follows a little more than 1 hour of speech recordings compared to the full 15 hours, which makes it weaker than the model baseline. Additionally, it critiques the abstract for being misleading due to this discrepancy. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the human baseline is weaker than the model baseline due to the limited time (1 hour) of speech recordings compared to the full 15 hours. The reviewer supports this claim by pointing out that the authors mention in the abstract that their model \"already beats\" the human baseline, which is misleading given the limited time of the human baseline. This provides a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the assertion about the human baseline\\'s weakness. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the human baseline, noting that it only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This discrepancy is highlighted as a major factor in the human baseline\\'s weakness, apart from other factors mentioned in Section 4.1. The comment also points out that the authors\\' claim in the abstract about beating the human baseline is misleading due to this limitation. While the comment clearly identifies a critical flaw in the experimental setup, it does not provide specific suggestions on how to address this issue or improve the human baseline. The feedback is somewhat helpful as it highlights a significant problem but lacks actionable guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the use of synthetic data in the paper. It asks for an example of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests explicit mention of the model used in the paper, possibly in the appendix. These questions imply that the authors should provide additional information or clarification. While the actions are not explicitly stated, they are concrete and provide clear guidance on what the authors need to do to improve their draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for examples of synthetic data, clarification on \"support data\" and \"predicted training count data,\" and a written model in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the use of synthetic data and the terminology used in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the use of synthetic data in the paper, specifically asking for examples of what kind of data could look like synthetic data and seeking clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1. It also requests explicit mention of the model used in the paper, possibly in the appendix. This feedback is clear and actionable, as it guides the authors to provide additional details and clarification that could enhance the reader\\'s understanding of the methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment is mostly helpful as it directs the authors to improve the clarity and comprehensiveness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors provide a more detailed explanation of the EEG topography plots in Figure 3, specifically addressing whether the spatial arrangement of the EEG sensors played a role in the EEG token quantization process. This feedback is clear and provides a specific action for the authors to take, which is to elaborate on the interpretation of the plots. The suggestion is concrete, as it guides the authors on what additional information to include to clarify the process. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the ambiguity in interpretation and the need for greater detail in elucidating the EEG token quantization process. The comment further specifies that understanding the role of the spatial arrangement of EEG sensors would be insightful. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 3 presents EEG topography plots that lead to ambiguity in interpretation, recommending a more detailed explanation. The comment provides a specific suggestion to understand whether the spatial arrangement of EEG sensors played a role in the process. While the comment identifies a potential issue and offers a constructive suggestion, it lacks detailed reasoning or evidence to fully substantiate the claim of ambiguity. The authors would need to infer the specific aspects of the process that require clarification. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It provides a clear and actionable suggestion by recommending that the authors elucidate this procedure in greater detail, specifically addressing whether the spatial arrangement of the EEG sensors played any role in the process. This feedback is valuable as it directs the authors to provide additional explanation and analysis, which could enhance the clarity and understanding of their work. The comment is mostly helpful as it offers a concrete suggestion for improvement, but it could be more comprehensive by suggesting specific aspects to focus on in the explanation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors use the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, as a solution. However, it suggests that this approach does not directly address the problem. While the comment implies that the authors should consider a more direct approach, it does not provide specific guidance on how to achieve this or what alternative methods might be more effective. The action is implicit and vague, leaving the authors without clear steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment also lacks specificity as it does not provide details on what aspects of the approach are considered indirect or how they could be improved. Without clear references or detailed feedback, the authors cannot effectively identify the areas needing attention. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' approach to leveraging the complexity of checking on the Witness oracle is not direct. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach is considered indirect. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the authors\\' approach to addressing the complexity of checking on the Witness oracle, suggesting that it may not be a direct solution. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not explain why the current approach is considered indirect or how the authors might address this issue more directly. Without detailed guidance or constructive criticism, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the use of moment matching instead of quantile regression in distributional reinforcement learning (DRL), as it is a relevant topic in the literature. It explicitly mentions a specific paper (Nguyen-Tang et al AAAI\u201921) that could be referenced for this discussion. The comment provides a clear and concrete action for the authors to take, which is to include a discussion on moment matching in the context of DRL. This guidance is explicit and provides specific details on how to implement the suggested improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific range of lines (22-30) and the topic of distributional reinforcement learning (DRL), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the paper should discuss the use of moment matching instead of quantile regression in DRL, referencing a specific paper (Nguyen-Tang et al AAAI\u201921) for context. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks discussion on the use of moment matching in distributional reinforcement learning (DRL), as opposed to quantile regression, which is commonly used in DRL methods. The reviewer supports this claim by referencing a specific paper (Nguyen-Tang et al AAAI\u201921) that discusses moment matching in DRL. This reference provides a clear and specific example of relevant literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area where the paper could be improved by discussing the use of moment matching in distributional reinforcement learning (DRL) instead of quantile regression. It provides a clear and actionable suggestion by referencing a relevant paper (Nguyen-Tang et al AAAI\u201921) that could be used to support this discussion. By pointing out this gap in the literature review, the comment empowers the authors to enhance the comprehensiveness and depth of their work. The inclusion of this discussion would not only improve the paper\\'s academic rigor but also provide a valuable contribution to the field. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second paragraph in the introduction discusses modelling curves but does not make it clear what is being modelled, presumably tumour growth. However, it does not provide explicit guidance on how the authors should clarify this in their draft. The action is implicit, as the authors can infer that they need to specify what is being modelled, but it remains vague because it lacks concrete instructions on how to achieve this clarity. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second paragraph in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of unclear modelling, suggesting that the authors need to clarify what is being modelled, presumably tumour growth. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of clarity in the introduction regarding what is being modelled, specifically mentioning that it is not immediately obvious what is being modelled (presumably tumour growth). However, the comment does not provide any specific reasoning or examples to support why this lack of clarity is an issue or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand and rectify the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue in the introduction, where the second paragraph discusses modelling curves but does not clarify what is being modelled, presumably tumour growth. This feedback is somewhat helpful as it points out a lack of clarity in the introduction, which is important for readers to understand the context and focus of the paper. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing ways to clarify the modelling or suggesting additional information to include. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. While the comment implies that the authors should expand their analysis to include this aspect, it does not provide explicit instructions or detailed guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps needed to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of local minima found by Algorithm 1, particularly the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. While the comment provides a logical suggestion for further analysis, it lacks specific examples or references to support the claim that such an analysis would be beneficial. The suggestion is based on a general expectation for more detailed analysis, but without concrete evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically noting that it only analyzes under which cases Algorithm 1 converges to permutations as local minima. It suggests that the quality of these local minima should also be analyzed, such as the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and improve the depth of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct this analysis. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. However, it does not provide any explicit or implicit suggestions for improvement or action. The comment lacks guidance on what the authors should do to address this question or how they might improve their draft. Without actionable advice or specific instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode\" algorithms and the sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning how information redundancy is built into these algorithms, providing clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. It references a specific sentence in the paper to clarify the context of the question. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their explanation in the paper. While it identifies a potential area of confusion, it lacks actionable feedback or specific advice, making it somewhat helpful. The authors are informed of a potential issue but are not given a clear path to resolve it, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include experimental results that exclude the mixup technique from the proposed method. This is a clear and direct action, as it specifies exactly what additional experiments should be conducted to demonstrate the pure contribution of the proposed method. The comment provides concrete guidance on how to improve the draft by adding these experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and the \"mixup technique in LUMP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide experimental results excluding the mixup technique to demonstrate the pure contribution of the proposed method. This claim is based on the observation that the mixup technique is also used in the experiments on SplitCIFAR-100 and SplitTiny-ImageNet. However, the comment does not provide specific reasoning or evidence to support why excluding the mixup technique is necessary or how it would impact the results. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient support or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide experimental results that exclude the mixup technique from the proposed method. This feedback is clear and actionable, as it directly addresses the need to demonstrate the pure contribution of the proposed method without the influence of the mixup technique. By following this suggestion, the authors can better isolate and highlight the unique aspects of their method, which is valuable for understanding its impact and contribution. However, the comment could be more helpful if it provided additional context or rationale for why this exclusion is important. Overall, the comment is mostly helpful, as it offers a clear direction for enhancing the draft, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider citing the original algorithm used in their work, specifically mentioning Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper. Additionally, it raises a question about potential errors in the initial calibration steps (steps 1 & 2) that might explain the observed speed disparities between RSPs and FDs. While the comment implies that the authors should investigate these calibration steps, it does not provide explicit instructions or concrete guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer the need for further investigation and citation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section III of \\\"Recognition and Velocity Computation of Large Moving Objects in Images\\\" paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the observed speed disparities between RSPs and FDs. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there might be an error in the initial calibration steps (steps 1 & 2) that could explain the observed speed disparities between RSPs and FDs. However, the comment does not provide any specific evidence or reasoning to support this claim. It references an original algorithm but does not elaborate on how this might relate to the observed disparities. Without detailed justification or examples, the claim remains unverifiable, as it lacks the necessary evidence to substantiate the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider citing the original algorithm used in their work, specifically referencing Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper. This is a helpful suggestion as it encourages the authors to provide proper attribution and potentially gain insights from the original work. Additionally, the comment raises a question about potential errors in the initial calibration steps (steps 1 & 2) that might explain the observed speed disparities between RSPs and FDs. This is a thoughtful observation that could prompt the authors to investigate and clarify these calibration steps. However, the comment could be more helpful if it provided specific examples or guidance on how to address the potential errors. Overall, the comment is mostly helpful as it offers actionable feedback and a direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning whether they are derived from the dataset itself or from other sources. This request is clear and direct, providing the authors with a specific action to take. The comment also provides concrete guidance on what information is needed, making it highly actionable. The authors know exactly what needs to be clarified and how to address the reviewer\\'s concern.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the labels for each dataset, particularly questioning where they are coming from and whether they are derived from the dataset itself or other sources. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the labels used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the labels used in the paper, particularly in section 4.1. It asks for clarification on where the labels are coming from, whether they are derived from the dataset itself or from other sources. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the clarity and transparency of their work. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how similar questions have been handled in other works. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the sensitivity of performance and sample efficiency to the \u03bb parameter. It explicitly asks for clarification on how the \u03bb parameter is computed and why ELLA does not increase sample efficiency in a COMBO environment. The reviewer also provides references to related works, which could be useful for the authors to consider. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address these issues. While the questions and observations are clear, the lack of specific guidance on how to improve the draft makes the comment somewhat actionable. The authors know they need to clarify these points but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages and lines (Page 9, lines 310-313; Page 8, lines 281-285), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the \u03bb parameter and the lack of understanding regarding the calculation of \u03bb. Additionally, it provides references to related works, which could help the authors understand the context better. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameter and questions the process of calculating \u03bb. It also mentions a lack of understanding regarding why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to related works, which could help the authors understand the context better. However, the comment lacks specific examples or detailed explanations of the issues, making it somewhat verifiable. The references to external works provide some context, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several issues and questions regarding the sensitivity of performance and sample efficiency to the \u03bb parameter, as well as the process of calculating \u03bb. It also questions the explanation provided by the authors regarding why ELLA does not increase sample efficiency in a COMBO environment. The comment is somewhat helpful as it identifies areas where the authors need to provide more clarity and explanation. However, it lacks specific suggestions or guidance on how the authors might address these issues, such as proposing alternative explanations or methods for calculating \u03bb. While the comment points out important areas for improvement, it does not offer detailed, actionable advice, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the effectiveness of lower bound double q-learning, specifically mentioning its performance decrease in MsPacman and its convergence into similar solutions in certain environments. It also raises a concern about overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. The feedback lacks actionable details, such as recommending specific analyses or modifications to address the concerns raised. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MsPacman of Figure2\" and specific environments like \"WizardOfWor, Zaxxon RoadRunner, and BattleZone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the algorithm, such as its performance decrease and convergence into similar solutions, and raises a concern about overestimating the true maximum value. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the effectiveness of lower bound double q-learning by providing specific examples from Figure 2, such as the performance decrease in MsPacman and the convergence into similar solutions in certain environments. It also raises a concern about overestimating the true maximum value. While the comment provides some evidence and examples, it lacks detailed reasoning or references to substantiate the claim fully. The authors would need to further explore these examples and the reasoning behind the concerns to fully understand and address the issue. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the effectiveness of lower bound double q-learning by providing specific examples from Figure 2, such as the performance decrease in MsPacman and the convergence into similar solutions in certain environments. It also raises a concern about the algorithm overestimating the true maximum value. While the comment identifies potential issues with the algorithm, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it points out areas of potential weakness, but it could be more beneficial with additional actionable advice or detailed analysis. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, as shown in figures 3-4. The reviewer expresses a specific expectation that the performance should approach the vanilla methods from below. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might investigate or address this issue, such as suggesting additional experiments or analyses. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig.3-4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and it provides an expectation that the performance should approach the vanilla methods from below. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, as shown in figures 3-4. The reviewer expresses an expectation that the performance should approach the vanilla methods from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this expectation is valid or how it relates to the figures. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, as illustrated in figures 3-4. It expresses an expectation that the performance should approach the vanilla methods from below. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might investigate or address this issue. Without actionable feedback or specific advice, the authors are left with only a vague understanding of the problem. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper does not compare its results with some of the earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer notes that the authors have compared their results to earlier systems with worse performances. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific comparisons that should be made. The action is implicit and vague, as it lacks concrete details on how to improve the draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper should include comparisons with earlier research work from 2020. It mentions that the authors have explained their reasons for not doing so, but it does not provide details on where these explanations are located in the paper. Additionally, the comment lacks specificity as it does not provide clear guidance on what specific comparisons should be made or how the authors could address the issue. Without clear references or detailed suggestions, the authors cannot effectively understand or respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not compare its results with some of the earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer acknowledges the authors\\' explanation but points out that they have compared their results to earlier systems with worse performances. However, the comment lacks specific examples or references to the earlier research work that should be compared, making it difficult for the authors to fully understand and address the issue. The claim is somewhat verifiable as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a specific issue with the paper, noting that it does not compare its results with some of the earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer acknowledges the authors\\' explanation but highlights that they have compared their results to earlier systems with worse performances. This feedback is somewhat helpful as it identifies a gap in the comparison section of the paper and suggests that the authors should consider including comparisons with more relevant and recent work. However, the comment could be more helpful if it provided specific examples of earlier research that should be considered or offered guidance on how to effectively incorporate these comparisons into the paper. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to elaborate on the statement regarding Hoeffding\\'s bound and its applicability to stochastic algorithms. It provides specific lines (124-125) where the authors should focus their elaboration. This direct request and the clear indication of where to add more detail make the comment highly actionable. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 124-125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests elaboration on the statement regarding Hoeffding\\'s bound and its applicability to stochastic algorithms. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the applicability of Hoeffding\\'s bound to stochastic algorithms, suggesting that it holds true as long as samples are drawn independently. The reviewer provides a logical reasoning by explaining that stochastic algorithms impose additional conditions, which further guarantee the validity of the inequality. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is sound, the absence of explicit evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where the authors could provide further elaboration, specifically regarding the applicability of Hoeffding\\'s bound to stochastic algorithms. It highlights the importance of understanding the conditions under which the inequality holds and suggests that the authors elaborate on this aspect. This feedback is clear and actionable, as it directs the authors to a particular section of the paper where they can enhance their explanation. By addressing this point, the authors can improve the clarity and depth of their discussion, making the comment mostly helpful. However, it could be more helpful if it included specific suggestions or examples on how to elaborate on this topic, which would elevate it to a highly helpful comment. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate these comparisons or suggest specific aspects to focus on. The action is implicit, as the authors need to infer that they should include these models in their comparison, and it is somewhat vague because it lacks detailed instructions on how to implement the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of comparisons with specific panoptic segmentation models, such as PanopticFPN and Mask2Former. However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in identifying the models that should be considered, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some other representative panoptic segmentation models are not compared,\" specifically mentioning PanopticFPN and Mask2Former. However, the comment does not provide any reasoning or justification for why these models should be included in the comparison. Without specific examples or explanations, the claim lacks verifiability, making it difficult for the authors to understand the importance of these comparisons. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is clear and actionable, as it provides the authors with a direct suggestion to enhance their work by including these models in their comparisons. However, the comment could be more helpful if it explained why these models are important or how their inclusion would benefit the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests that the authors should address the sensitivity to other hyper-parameters and offers specific examples of language usage issues to correct. The comment is clear and provides concrete guidance on how to implement the changes, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"above of (7),\" \"Theorem 1,\" and \"above of (14),\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear examples of language usage issues that need to be corrected, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" The comment also includes a general request to proofread the paper and fix all language problems, which adds further specificity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of minor comments on language usage, such as \"we typically considers\" and \"two permutation,\" and a request to proofread the paper. These are factual observations and requests for clarification, not subjective claims or opinions. Therefore, the review point does not contain any claims and is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment addresses two distinct issues: sensitivity to other hyper-parameters and minor language usage errors. The suggestion to examine sensitivity to other hyper-parameters is a relevant point that could enhance the robustness of the experimental results. However, the comment does not provide specific guidance on how to investigate this sensitivity or what other hyper-parameters to consider. The second part of the comment is more actionable, as it provides specific examples of language usage errors and requests a proofread to fix all such issues. While the comment identifies areas for improvement, it lacks depth and specificity in addressing the sensitivity to hyper-parameters. Therefore, it is somewhat helpful, as it provides some guidance but not comprehensive feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluative framework is limited in scope, considering only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance or suggestions on how the authors could expand the scope of their framework or address these concerns. The feedback lacks actionable details, such as recommending specific tasks or models to include or suggesting ways to demonstrate broader applicability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework\\'s scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not explicitly mention which part of the paper discusses the evaluative framework, making it weakly grounded. The comment is specific in detailing the limitations of the framework and suggesting areas for further exploration. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, considering only three Question-Answering tasks and two language models. It suggests that the method\\'s applicability to other reasoning or generation tasks and more advanced models is uncertain. While the comment raises a valid concern about the framework\\'s scope, it lacks specific examples or references to support the claim. The reasoning is somewhat verifiable, as it highlights a potential limitation, but it could be strengthened with more detailed evidence or comparisons to other frameworks. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models, such as vicunna or alpaca. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might expand the scope of their framework or address these concerns. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with actionable advice or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments should be conducted to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the results from Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, including specific types of experiments to conduct and a reference to include. The authors know exactly what needs to be done to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the sufficiency of the experiments, specifically mentioning the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also suggests citing the results from Kaplan et al. 2020. However, the comment does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more empirical experiments and the citation of external work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the results from Kaplan et al. 2020. While the suggestion to conduct additional experiments is logical, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the insufficiency of the experiments. It suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. Additionally, the comment mentions the need to cite the results from Kaplan et al. 2020, which provides a direction for the authors to incorporate relevant literature. This feedback is clear and actionable, offering specific guidance on how to enhance the experimental section of the paper. However, it could be more helpful if it provided additional details on what kind of experiments or analyses would be most beneficial. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific method for presenting the performance of the algorithm as a function of the distance of initialization to the ground-truth. It provides a clear and explicit action for the authors to take, including the steps to follow (varying the distance, sampling matrices, and reporting performance). The comment is highly actionable because it offers concrete guidance on how to implement the suggested analysis, ensuring the authors know exactly what changes to make to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests presenting the performance as a function of the distance of initialization to the ground-truth, providing a specific method for analysis. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the suggested analysis, but it lacks full grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests presenting the performance as a function of the distance of initialization to the ground-truth, providing a specific method for analysis. The claim is supported by logical reasoning, as it explains that the mean error and variance should increase as the quality of initialization decreases. However, the comment lacks specific examples or references to similar studies that have used this approach, which would strengthen the justification. Therefore, the claim is mostly verifiable, as it provides a clear rationale but could benefit from additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending a method to present the performance as a function of the distance of initialization to the ground-truth. It offers a clear and detailed approach for analyzing the sensitivity to initialization, which could help the authors better understand and communicate the robustness of their method. By suggesting a specific analysis, the comment empowers the authors to enhance their draft with additional insights and evidence. This level of detail and guidance makes the comment highly helpful, as it provides a concrete direction for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This feedback is explicit and provides a clear action for the authors to take: remove the absolute value operation. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of the Frobenius norm, pointing out that the absolute value operation is unnecessary due to the real nature of tensor entries. This provides clear guidance on what needs to be revised. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that the absolute value is not needed for real numbers. However, the comment does not provide any references or detailed explanations to fully substantiate this claim. While the reasoning is sound, the lack of additional evidence or references makes the claim somewhat verifiable, as the authors might need more context to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a minor but specific observation regarding the definition of the Frobenius norm in the paper. It points out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is actionable as it guides the authors to simplify their mathematical expression, potentially improving the clarity and accuracy of their work. However, the comment could be more helpful if it explained why this simplification is important or how it impacts the overall understanding of the paper. Despite this, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is concrete, as it outlines a specific change that can be implemented to enhance the evaluation of the work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of FIDs and the need to use DinoV2 Frechet Distances for comparisons, referencing specific metrics and sources. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the use of DinoV2 Frechet Distances in addition to the widely used FID metric. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using DinoV2 Frechet Distances instead of FIDs for evaluation, citing \"clear flaws\" associated with FIDs and referencing the use of the Inception network. While the comment provides a rationale for the suggestion by mentioning the flaws associated with FIDs, it lacks specific examples or detailed explanations of these flaws. Additionally, the reference to the Inception network is not elaborated upon, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the claim is somewhat verifiable, as it provides a direction but lacks comprehensive justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the paper. It acknowledges the widespread use of FIDs but points out the flaws associated with them, specifically mentioning the use of the Inception network. The reviewer recommends using DinoV2 Frechet Distances as an alternative metric, which is a specific and constructive suggestion that can help the authors enhance the robustness and validity of their evaluations. This feedback is highly helpful as it offers a concrete step for the authors to take, aligning with the criteria for a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider using a second y-axis or another visualization to make Figure 6C more physically accurate, as it currently implies negative rates when this is not the case. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed to improve the figure. The comment is explicit and provides detailed guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when this is not the case, and suggests using a second y-axis or another visualization to make it more physically accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C implies negative rates, which is not the case, and suggests using a second y-axis or another visualization to make it more physically accurate. While the comment identifies a potential issue with the figure, it lacks specific reasoning or evidence to support why the current visualization is misleading or how a second y-axis would improve accuracy. The suggestion is based on logical reasoning but lacks detailed justification or examples, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when this is not the case. It provides a clear and actionable suggestion to use a second y-axis or another visualization to make the figure more physically accurate. This feedback is valuable as it directly addresses a potential misunderstanding in the visualization and offers a concrete solution to improve the clarity and accuracy of the figure. By following this advice, the authors can enhance the effectiveness of their presentation, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to generative adversarial networks (GAN). The reviewer provides an example from Zaremba et al. (2014) to challenge the claim and suggests that the baseline models may not be properly regularized. Additionally, the reviewer asks whether dropout is applied to the hidden states. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for the authors to investigate and clarify their claims. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement about the necessity of smaller architectures for language models (LM) compared to generative adversarial networks (GAN), and suggests that the baseline models may not be properly regularized. Additionally, it asks whether dropout is applied to the hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to generative adversarial networks (GAN). The reviewer provides a counterexample from Zaremba et al. (2014) to challenge the claim, suggesting that the baseline models may not be properly regularized. Additionally, the reviewer asks whether dropout is applied to the hidden states, which could further clarify the regularization approach. This provides a logical reasoning and a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to generative adversarial networks (GAN). It challenges the claim by providing a counterexample from Zaremba et al. (2014), suggesting that the baseline models may not be properly regularized. Additionally, the comment asks whether dropout is applied to the hidden states, which could provide further insight into the regularization process. This feedback is mostly helpful as it identifies a potential issue with the claim and prompts the authors to clarify or revise their statement. However, it could be more helpful if it offered specific suggestions on how to address the issue or provided additional context or references. Overall, the comment provides valuable direction for the authors to improve their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a statement about the contribution of multilingual chain-of-thought being incremental compared to the villa chain-of-thought. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or improve their draft based on this feedback. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of multilingual chain-of-thought compared to the villa chain-of-thought. However, it does not specify which part of the paper this comparison is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contribution of multilingual chain-of-thought is considered incremental compared to the villa chain-of-thought. However, it does not provide any specific guidance or suggestions on how the authors might address this perceived lack of contribution or enhance their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the comparability of G-effect values across various unlearning objectives and approaches when each learning objective is studied in isolation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the comparability of their results. The comment lacks actionable details, such as recommending specific methods or analyses to enhance comparability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of G-effect values across various unlearning objectives and approaches when each learning objective is studied in isolation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of G-effect values across various unlearning objectives and approaches when each learning objective is studied in isolation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks the necessary detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology used in Section 4, specifically the examination of G-effects of each unlearning objective in isolation. It raises a valid concern about the comparability of G-effect values across various unlearning objectives and approaches. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the comparability of their results. While it highlights an important area for consideration, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1-shot setting. It questions whether the authors have a theory for why the method is less effective in this setting. While the comment highlights an area of concern, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is implicit and somewhat vague, as it lacks concrete steps or suggestions for improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the inconsistency in the advantage of UNIFORM over other procedures, specifically in the 1-shot setting. It references the tables where the results are presented, allowing the authors to identify the specific part of the paper being discussed. However, the comment does not provide detailed guidance on what needs to be addressed or improved, such as suggesting ways to enhance the effectiveness of UNIFORM in the 1-shot setting. While the comment is fully grounded, it lacks specificity regarding the improvements needed. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1-shot setting. The reviewer supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage over the results. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the mention of the 1-shot setting provides some context, the absence of explicit evidence or references makes the claim somewhat verifiable. The authors would need to further explore the data and reasoning to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1-shot setting. It questions whether the authors have a theory for why the method is less effective in this setting. While the comment highlights a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their theoretical understanding. The feedback is somewhat helpful as it points out an area for further exploration, but it could be more beneficial with additional direction or specific advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason why information value is a stronger predictor for dialogue, suggesting that adding an explanation from an existing linguistic theory could strengthen the paper. While the comment implies that the authors should explore and incorporate such a theory, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to identify or integrate the relevant linguistic theory. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the reason why information value is a stronger predictor for dialogue and suggests that adding an explanation from an existing linguistic theory could strengthen the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reason why information value is a stronger predictor for dialogue, suggesting that adding an explanation from an existing linguistic theory could strengthen the paper. However, the comment does not provide any specific references or examples of existing linguistic theories that could be relevant, nor does it offer a detailed explanation of why this addition would strengthen the paper. The lack of supporting evidence or detailed reasoning makes the claim somewhat verifiable, as the authors would need to conduct additional research to address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an interesting question about the reason why information value is a stronger predictor for dialogue, suggesting that adding an explanation from an existing linguistic theory could strengthen the paper. This feedback is somewhat helpful as it prompts the authors to consider a theoretical basis for their findings, which could enhance the depth and credibility of their work. However, the comment lacks specific guidance on how to identify or incorporate such a theory, and it does not provide actionable steps for the authors to follow. To be more helpful, the comment could suggest potential theories or references to explore, or offer a framework for integrating theoretical explanations into the paper. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper, noting that T_a(t) is used in Section 3.1 but is only defined in Section 4. This feedback implies that the authors should either define T_a(t) earlier in the paper or clarify its usage in Section 3.1. However, the comment does not explicitly instruct the authors on which action to take, leaving it to the authors to infer that they need to address this inconsistency. The action is implicit and somewhat vague, as it lacks specific guidance on how to resolve the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the definition of T_a(t), which is used in Section 3.1 but only defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the placement of a definition in the paper. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that T_a(t) is used in Section 3.1 but is only defined in Section 4. This is a clear and actionable piece of feedback, as it highlights a potential inconsistency or lack of clarity in the paper. By pointing out this discrepancy, the reviewer provides the authors with a direct area to address and improve the coherence and clarity of their manuscript. However, the comment could be more helpful if it suggested how to resolve this issue, such as by recommending where to define T_a(t) or how to better integrate its definition into the text. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the empirical analysis in Figure 3, specifically questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score and their impact on model prediction accuracy. The reviewer requests additional clarification and explanation regarding these adjustments and their effectiveness. Additionally, the comment notes large spacing in Equations (9) and (10) and references a paper by Liu et al. (2022). While the comment implies that the authors should provide more information and clarification, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can deduce that they need to address the issues raised. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the confusion regarding the empirical analysis and the need for clarification on how adjustments to amplitudes affect model prediction accuracy. Additionally, it suggests explaining why these adjustments are effective. The comment provides specific guidance on what needs to be clarified or improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the empirical analysis in Figure 3, specifically questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. While the comment highlights areas of confusion, it does not provide specific examples or references to support the claim that the adjustments are confusing or ineffective. The mention of Equations (9) and (10) with large spacing is a factual observation, but it does not contribute to the claim about the empirical analysis. Overall, the comment lacks sufficient justification or evidence to fully substantiate the claim, making it somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the empirical analysis in Figure 3, noting that it is confusing to the reviewer. It requests additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The comment also asks for an explanation of why these adjustments are effective in enhancing the model\\'s performance. Additionally, it points out large spacing in Equations (9) and (10), which could affect readability. The comment provides clear and actionable feedback by specifying areas that need clarification and improvement, making it mostly helpful. However, it could be more comprehensive by suggesting how the authors might address these issues or provide examples of what kind of clarification would be helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare their work with the recent related work CoCoOp in their experiments. It provides a clear and direct action for the authors to take, which is to include a comparison with CoCoOp. The comment also specifies that CoCoOp is the extended version of CoOp, providing additional context for the authors to understand the importance of this comparison. The action is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the recent related work \"CoCoOp\" and its comparison with the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need to compare CoCoOp in the experiments, even though it is a CVPR\\'22 work published after the NeurIPS deadline. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent related work CoCoOp should be compared in the experiments, despite being published after the NeurIPS deadline. The reviewer provides a logical reasoning by stating that CoCoOp is the extended version of CoOp, which is relevant to the paper\\'s topic. This reasoning supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific details or references to CoCoOp\\'s relevance or impact, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the paper\\'s experimental comparison, noting the absence of CoCoOp, a recent related work that is officially published after the NeurIPS deadline. It emphasizes the necessity of comparing with CoCoOp, given its extended version of CoOp, which is relevant to the paper\\'s topic. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the comprehensiveness of their experimental analysis. By addressing this point, the authors can improve the rigor and relevance of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions that the figure should indicate where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes, such as which elements should be emphasized or how the figure should be structured. The action is explicit but somewhat vague, as the authors know they need to improve the figure but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved by suggesting how the figure could be drawn better to show the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. This provides clear guidance on what the authors need to address in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide any specific reasoning or evidence to support why these changes would be beneficial or how they would enhance the figure. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving Figure 1 by recommending that it be redrawn to better illustrate the processing pipeline. It outlines the key components of the pipeline, such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, and suggests including information about where model training is used to optimize the selection modules. This feedback is clear and actionable, offering the authors a concrete way to enhance the visual representation of their work. By following this suggestion, the authors can improve the clarity and comprehensibility of their figure, which is crucial for conveying the methodology and results effectively. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to avoid using abbreviations like \"MoCo\" in section headers, as a reader might not understand them. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with using abbreviations like \"MoCo\" in section headers, explaining that a reader might not understand them. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that abbreviations like \"MoCo\" should not appear in section headers because a reader might not understand them. This is a logical claim based on the principle of clarity in communication. However, the comment does not provide specific examples or references to support why this is a common issue or how it affects reader comprehension. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the use of abbreviations in section headers. It points out that abbreviations like \"MoCo\" might not be understood by readers, which could affect the clarity and accessibility of the paper. By advising against the use of such abbreviations in section headers, the comment offers a clear and straightforward way for the authors to improve the readability of their draft. This feedback is precise and directly addresses a potential issue, making it highly helpful for the authors to enhance their manuscript. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors can clarify their technical contribution or make their analysis more innovative. The comment lacks actionable details, such as recommending ways to enhance the contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the analysis are considered standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might clarify their contribution or make their analysis more innovative. Without actionable feedback or detailed critique, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach and suggests that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments should be included or how the authors should demonstrate the significance of their contribution. The feedback lacks explicit instructions or concrete details on how to address the issue, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper\\'s primary contribution as an incremental advancement over the TACTiS approach and suggests that more substantial evidence or arguments are needed to establish its significance. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, while it identifies a potential issue with the contribution\\'s significance, it lacks specificity in detailing what kind of evidence or arguments are needed to strengthen the claim. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper\\'s primary contribution is an incremental advancement over the TACTiS approach and suggests that more substantial evidence or arguments are needed to establish its significance. However, the comment does not provide specific examples or references to support this claim, nor does it elaborate on what constitutes a significant contribution or how the current evidence falls short. This lack of detailed justification makes the claim borderline verifiable, as it provides a general critique without concrete evidence or reasoning to support it. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s primary contribution, suggesting that it is an incremental advancement over the TACTiS approach. It points out the need for more substantial evidence or arguments to establish this contribution as significant. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might enhance their contribution or provide the necessary evidence. This limits the comment\\'s usefulness, as it provides a general critique without actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. It acknowledges that efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment implies that the authors should provide more information on the parameters, it does not explicitly instruct them to do so or offer specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details on the parameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters not changing, despite an increase in depth, and suggests that more details are needed regarding the parameters. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment provides some logical reasoning about the potential increase in parameters, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It acknowledges that efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment highlights an area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or provide the necessary details. The feedback is somewhat helpful as it points out a potential weakness but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a clearer explanation of why the GPC (benchmark) is performing better than BPC (their method). It implies that the authors should reiterate that the performance difference is due to the bandit feedback and not using information about the form of the cost function. While the action is implicit, it is concrete because it specifies what the authors need to address and how they can improve their explanation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of commentary on why the GPC (benchmark) is performing better than BPC (the authors\\' method). The comment provides a clear suggestion for improvement by recommending that the authors reiterate the reason for the performance difference, which is due to the bandit feedback and not using information about the form of the cost function. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation of the simulation study does not benefit the authors because they do not comment on why the GPC (benchmark) performs better than BPC (their method). The reviewer suggests that the authors should reiterate that the performance difference is due to the bandit feedback and not using information about the form of the cost function. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not provide an explanation for why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that the performance difference is due to the bandit feedback and not using information about the form of the cost function. This feedback is clear and actionable, as it guides the authors to clarify their results and provide a more comprehensive explanation. By addressing this point, the authors can enhance the clarity and understanding of their simulation study, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback implies that the authors should provide more detailed evidence or analysis to support their claim. However, it does not explicitly instruct the authors on how to do this, leaving some room for interpretation. The action is implicit but concrete, as the authors can infer that they need to provide additional evidence or analysis. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific claim regarding the performance of ReLU in deep or convolutional networks, suggesting that it might be helpful to quantify and clarify this claim. It provides a reference to the AlexNet paper, which used ReLU and was considered deep and convolutional at the time. This reference helps the authors understand the context of the claim and potentially address it. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting a way to clarify the claim, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the claim about ReLU not working well in deep or convolutional networks might be overstated, as ReLUs were used in the AlexNet paper, which was considered deep and convolutional at the time. This provides a logical reasoning by referencing a specific example from the literature, the AlexNet paper, to challenge the claim. However, the comment could be strengthened by providing more detailed comparisons or additional references to support the argument. As it stands, the claim is mostly verifiable, but it lacks comprehensive evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should quantify and clarify their claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLU and was considered deep and convolutional at the time. This feedback is actionable as it encourages the authors to provide more evidence or analysis to support their claim, which could enhance the clarity and robustness of their argument. However, the comment could be more helpful if it offered additional guidance on how to quantify or clarify the claim further. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores in the reviewer\\'s experience. It explicitly asks how perplexity was calculated, indicating that the authors should provide an explanation or clarification on this point. The action is explicit and concrete, as it directly instructs the authors to address the discrepancy and explain their perplexity calculation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the high perplexity reported in the figure and questions how it was calculated, providing a clear direction for the authors to address the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores in the reviewer\\'s experience. The comment questions how perplexity was calculated, indicating a need for clarification. However, the claim is somewhat verifiable as it lacks specific examples or references to support the assertion about the high perplexity. The authors would need to provide additional information to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported perplexity in Figure 1, noting that it appears high compared to the better BLEU scores. It questions how perplexity was calculated, which is a relevant and actionable point for the authors to address. By asking for clarification on the perplexity calculation, the reviewer encourages the authors to provide more detailed information that could help validate their results. However, the comment could be more helpful if it offered suggestions on how to address the discrepancy or provided additional context on what might be causing the high perplexity. Overall, the comment is somewhat helpful as it highlights a specific area for improvement and prompts the authors to provide additional information, but it could be more comprehensive with further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide more explanations regarding the ease of satisfying consistency between training and inference due to the smoothness of neural models. While the comment implies that the authors should expand on this aspect, it does not specify what additional explanations are needed or how to present them. The action is implicit and somewhat vague, as the authors know they need to provide more information but may not be entirely sure of the exact details to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (Line 95-97, Line 308-310), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests that the authors provide more explanations on the ease of satisfying consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper repeatedly states that the consistency between training and inference can be easily satisfied due to the smoothness of neural models. However, it does not provide any specific examples or references to support this claim, nor does it explain why more explanations are needed. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the comment unverifiable. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where the authors repeatedly mention that the consistency between training and inference can be easily satisfied due to the smoothness of neural models. It suggests that the authors provide more explanations on this point, which is a clear and actionable piece of feedback. By asking for additional explanations, the comment guides the authors to enhance the clarity and depth of their discussion, which could improve the overall understanding of their work. However, the comment could be more helpful if it offered specific suggestions on what aspects of the explanation should be expanded or clarified. Overall, the comment is mostly helpful as it directs the authors to a specific area needing further elaboration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include failure cases and related discussion in their paper. While the suggestion is explicit, it lacks concrete details on what specific failure cases should be included or how the discussion should be structured. The authors are given a clear action to take but without detailed guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including failure cases and related discussion, but it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what constitutes a failure case or how the discussion should be structured. Without clear guidance, the authors may struggle to implement the suggestion effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that including failure cases and related discussion would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why this would be helpful or necessary. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of this suggestion or how it would improve the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests including failure cases and related discussion, which could provide valuable insights into the robustness and limitations of the proposed method. However, it lacks specificity and does not provide guidance on what constitutes a failure case or how the discussion should be structured. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors introduce the variable \\\\( \\\\epsilon \\\\) when discussing equation (11) in Section 4.1. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the clarity of the paper. The comment is concrete, as it provides a specific point of clarification that can be easily implemented. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and equations \"(10)\" and \"(11),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the inconsistent use of \\\\( \\\\epsilon \\\\) in the equations, and suggests introducing \\\\( \\\\epsilon \\\\) when discussing equation (11). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction of \\\\( \\\\epsilon \\\\) when discussing equation (11) would improve clarity. However, it does not provide any reasoning or evidence to support why this change is necessary or how it would enhance the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, noting that the variable \\\\( \\\\epsilon \\\\) is not introduced when discussing equation (11) in Section 4.1. It suggests that introducing \\\\( \\\\epsilon \\\\) when discussing this equation would improve clarity. This feedback is clear and actionable, providing the authors with a straightforward way to enhance the readability and coherence of their manuscript. By addressing this point, the authors can improve the overall quality of their draft. However, the comment could be more helpful if it provided additional context or explained why this change is important. Overall, the comment is mostly helpful, as it effectively directs the authors toward a specific improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss the computational complexity of counting homomorphisms more thoroughly. It points out that the current discussion is brief and recommends adding explicit upper bounds and potentially elaborating on empirical runtimes. This feedback provides a clear and concrete action for the authors to take, specifying what needs to be added and potentially expanded upon. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number, \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of discussion on the computational complexity of counting homomorphisms and suggests adding explicit upper bounds and elaborating on empirical runtimes. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, despite making brief statements about it. The reviewer suggests that the paper would benefit from explicitly adding upper bounds and potentially elaborating on empirical runtimes. While the comment identifies a gap in the discussion, it lacks specific examples or references to support the claim that the current discussion is insufficient. The suggestion to add upper bounds and empirical runtimes is logical, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the discussion of computational complexity in counting homomorphisms. It points out that the current discussion is brief and suggests that the authors should explicitly add upper bounds and potentially elaborate on empirical runtimes. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their paper by addressing a critical aspect of their methodology. However, the comment could be more helpful if it offered examples or guidance on how to effectively present this information. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take, making it highly actionable. It identifies specific errors in the manuscript, such as a typo in \"f\" that should be \"g\" in line 108 and an extra \".\" in the middle of a sentence in line 115. Additionally, it raises a question about the convergence of networks in the baseline MCL with deep learning, suggesting that cutting learners early could affect ensemble performance. This feedback is clear and provides specific guidance on how to improve the manuscript, ensuring that the authors know exactly what changes to make.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (line 108 and line 115), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the typo in \"f\" that should be \"g\" in line 108 and the extra \".\" in the middle of a sentence in line 115. Additionally, it raises a question about the convergence of networks in the baseline MCL with deep learning, suggesting that cutting learners early could affect ensemble performance. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and a question about the convergence of networks in the baseline MCL with deep learning. It does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying typographical errors in the manuscript, such as the incorrect \"f\" in line 108 and an extra \".\" in line 115. This level of detail is valuable for the authors to correct these errors, ensuring the manuscript's accuracy. Additionally, the comment raises a question about the convergence of networks in the baseline MCL with deep learning, suggesting that cutting learners early could affect ensemble performance. This question prompts the authors to consider and address a potential methodological issue, which is helpful for improving the robustness of their work. Overall, the comment is highly helpful as it combines specific corrections with a thoughtful question that encourages further exploration, providing the authors with clear guidance on how to enhance their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the proof of Theorem A.3, specifically questioning how the input x has two indices when it should be a vector and not a matrix. It also points out a potential error in the equation, suggesting that the summation should be over k, not d. These questions imply that the authors should review and correct the proof and equation. While the comment does not explicitly instruct the authors to make these changes, the actions are clear and concrete, as the authors can directly address the issues raised. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the input x having two indices, which is a clear indication of a potential issue in the proof. Additionally, it points out a potential error in the equation, suggesting that the summation should be over k, not d. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the proof of Theorem A.3, specifically regarding the input x having two indices when it should be a vector, not a matrix. It also points out a potential error in the equation, suggesting that the summation should be over k, not d. These observations are based on logical reasoning and common sense, as the reviewer is questioning the consistency and accuracy of the mathematical notation and equations. However, the comment does not provide specific references or detailed explanations to fully substantiate the claims, making it somewhat verifiable. The authors would need to further investigate the proof and equation to address the concerns, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the proof of Theorem A.3, questioning how the input x has two indices when it should be a vector, not a matrix. It also points out a potential error in the equation, suggesting that the summation should be over k, not d. This feedback is clear and actionable, as it directs the authors to review and correct the mathematical notation and equations in the proof. By addressing these issues, the authors can improve the accuracy and clarity of their theoretical contributions. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve these issues. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in section 4.3 and 4.4. It questions the effectiveness of beam search in ensuring that the plugged-in entities and relationships are correct, especially when no ground truth is available. The reviewer asks for clarification on the percentage of correct entities and relationships being plugged in. While the comment highlights specific issues and questions, it does not provide explicit instructions or concrete suggestions for how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analysis or clarification on these points. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the use of words like \"somewhat\" and \"good generative ability\" in the description, and it raises concerns about the effectiveness of beam search in ensuring correct entities and relationships are plugged in. The comment further questions the percentage of correct entities and relationships being plugged in if no ground truth is available. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in section 4.3 and 4.4. It questions the effectiveness of beam search in ensuring that the plugged-in entities and relationships are correct, especially when no ground truth is available. The comment provides a logical reasoning by highlighting the discrepancy between the description and the actual results, which is a valid concern. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in section 4.3 and 4.4. It questions the effectiveness of beam search in ensuring that the plugged-in entities and relationships are correct, especially when no ground truth is available. The comment prompts the authors to provide more detailed analysis on the percentage of correct entities and relationships being plugged in, which is a valuable suggestion for improving the clarity and robustness of the results. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of how to present the results more effectively. Overall, the comment is somewhat helpful as it identifies a potential issue and encourages further exploration, but it lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the performance of FedPCL is heavily reliant on the selection of different pre-trained models, which limits its applicability to broader areas. It also notes that the model accuracy is sensitive to the choice of pre-trained models, as shown in Table 4. However, the comment does not provide any explicit or implicit suggestions for improvement or actions that the authors could take to address this limitation. There is no guidance on how to mitigate the sensitivity to pre-trained models or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the performance of FedPCL being heavily reliant on the selection of different pre-trained models, which limits its applicability to broader areas. The comment further specifies that the model accuracy is sensitive to the choice of pre-trained models and acknowledges the authors\\' efforts to address these limitations by developing a lightweight federated learning framework. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedPCL is heavily reliant on the selection of different pre-trained models, which limits its applicability to broader areas. The reviewer supports this claim by referencing Table 4, where the model accuracy is shown to be sensitive to the choice of pre-trained models. This provides a logical basis for the claim, as it highlights a specific aspect of the methodology that affects the results. However, the comment could be strengthened by providing more detailed examples or additional references to substantiate the claim further. As it stands, the claim is mostly verifiable due to the specific reference to Table 4, but it could be improved with more comprehensive evidence or reasoning. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the limitations of the FedPCL method, specifically its reliance on the selection of different pre-trained models, which restricts its applicability to broader areas. It also notes that the model accuracy is sensitive to the choice of pre-trained models, as shown in Table 4. However, the comment does not provide any constructive feedback or suggestions on how the authors might address these limitations or improve the robustness of their method. While it acknowledges the authors\\' efforts in developing a lightweight federated learning framework and integrating pre-trained models, it lacks actionable advice or specific guidance for improvement. As a result, the comment is somewhat helpful, as it highlights an issue but does not offer a clear path for enhancement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. Additionally, it suggests referencing normalization and feature scaling tricks in a separate section. These suggestions are clear and provide concrete guidance on how to restructure the paper for better clarity and organization. The authors know exactly what changes to make to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the organization and clarity of the paper. It suggests separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. Additionally, it recommends referencing normalization and feature scaling tricks in a separate section. While the comment does not explicitly mention specific sections, the authors can infer that it relates to sections 2.3 and 2.4, where the layer-wise attention mechanism is described. This makes the comment weakly grounded, as the authors can make an educated guess about the relevant sections, but it is specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests organizing the paper by separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. It also recommends referencing normalization and feature scaling tricks in a separate section. While the comment provides a logical suggestion for improving the paper\\'s organization, it lacks specific examples or references to support why this reorganization would be beneficial. The suggestion is somewhat verifiable, as it provides a reasonable rationale but lacks detailed justification or evidence, making it difficult for the authors to fully understand the necessity of the changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the organization and clarity of the paper. It suggests separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. This would help readers better understand the contributions without being overwhelmed by the details of the generative and inference models. Additionally, the comment recommends referencing normalization and feature scaling tricks in a separate section, which could enhance the comprehensiveness of the paper. While the comment is clear and offers concrete suggestions, it could be more helpful by providing additional guidance on how to implement these changes. Overall, the feedback is mostly helpful as it directs the authors toward meaningful improvements in the paper\\'s structure and clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set, and that the set of multisets of size n should be used instead. This is a clear and explicit action, as it specifies exactly what needs to be changed and why. The authors are given a concrete step to take to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suggestion that \"X\" should be a multiset rather than a set, and that the set of multisets of size n should be used instead. This provides clear guidance on what needs to be revised in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set, as it is necessary to include the multiplicities of labels in the graph to accurately represent it. This claim is based on logical reasoning, as it explains the need for a multiset to capture the repeated vertex or edge labels. However, the comment does not provide specific examples or references to support this reasoning, which would make the claim more robust. Therefore, the comment is categorized as \"3: Somewhat Verifiable,\" as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the terminology used in Section 4. It proposes that the term \"X\" should be a multiset rather than a set, and it explains why this change is necessary to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and constructive, offering the authors a precise way to improve the technical accuracy and clarity of their manuscript. By addressing this point, the authors can enhance the rigor and precision of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a mix of positive and constructive feedback. It acknowledges the paper\\'s organization and writing quality but suggests specific areas for improvement. The reviewer explicitly recommends drawing a table to compare different CoT prompting methods across different dimensions, which is a clear and actionable suggestion. Additionally, the comment raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequent-error cluster and why certain selection criteria are used. These questions imply that the authors should provide more justification or clarification, but they do not explicitly instruct the authors to do so. Overall, the comment provides both explicit and implicit actions, with the explicit suggestion being the most concrete. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment provides a mix of positive and constructive feedback. It acknowledges the paper\\'s organization and writing quality but suggests specific areas for improvement. The comment explicitly mentions drawing a table to compare different CoT prompting methods across different dimensions, which provides a clear and specific action for the authors to take. Additionally, it raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequent-error cluster and why certain selection criteria are used. These questions highlight specific areas that need clarification or justification. The comment is fully grounded as it refers to specific sections (e.g., section 4.2) and provides specific feedback on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the paper\\'s organization and writing quality but provides specific feedback on areas for improvement. It suggests drawing a table to compare different CoT prompting methods and questions the assumptions made in the paper. The comment raises valid points about the selection criteria in section 4.2, asking why certain criteria are chosen. While the feedback is specific and provides a direction for improvement, it lacks detailed reasoning or references to support the claims. This makes the comment somewhat verifiable, as it provides a basis for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of positive and constructive feedback. It acknowledges the paper\\'s organization and writing quality but suggests specific areas for improvement. The comment explicitly recommends drawing a table to compare different CoT prompting methods across different dimensions, which is a clear and actionable suggestion. Additionally, it raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequent-error cluster and why certain selection criteria are used. These questions prompt the authors to provide more justification or clarification, which can enhance the clarity and robustness of their work. Overall, the comment is mostly helpful as it offers specific and actionable feedback, but it could be more comprehensive by addressing additional areas for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant omission in the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a critical issue that needs to be addressed to ensure that readers understand the context of the results. The reviewer suggests that this omission is a serious issue and must be fixed for publication. While the comment does not provide specific guidance on how to address this omission, it clearly identifies the problem and implies that the authors should make the necessary corrections. The action is explicit but somewhat vague, as it does not offer detailed instructions on how to implement the changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment also highlights the importance of addressing this omission for publication and suggests that it would be straightforward to fix. However, it does not provide specific guidance on how to make these corrections, which limits its specificity. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The reviewer suggests that this omission could lead to incorrect conclusions by casual readers. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The suggestion to fix this omission is based on logical reasoning, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a significant issue that could lead to incorrect conclusions by casual readers. The comment emphasizes the importance of addressing this omission for publication and suggests that it would be straightforward to fix. However, the comment does not provide specific guidance on how to make these corrections, which limits its helpfulness. While it highlights a crucial area for improvement, it could be more actionable with detailed suggestions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, noting that the authors make claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT-4 significantly improve translation quality and discourse awareness. The reviewer points out that the differences in scores are minimal and suggests that proper testing, including distribution checks and accounting for multiple comparisons, is necessary to support these claims. The comment is explicit in its request for significance testing and provides concrete guidance on how to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 486\" and provides specific examples of methods and scores discussed in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of significance testing to support the claims made about the differences between methods. The comment provides detailed guidance on what needs to be addressed, such as conducting proper testing and accounting for multiple comparisons. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. The reviewer provides specific examples from the paper, such as the comparison between ChatGPT and GPT-4, and highlights the need for proper testing to determine the significance of these differences. This detailed critique, supported by specific examples and logical reasoning, makes the claim mostly verifiable. However, the comment could be further strengthened by suggesting specific statistical tests or methodologies that could be used for significance testing. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a critical issue with the paper: the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors make a claim about the significant improvement in translation quality and discourse awareness, and highlights the need for proper testing to substantiate these claims. The comment suggests conducting significance testing, including distribution checks and accounting for multiple comparisons, to provide a more robust evaluation of the differences. This feedback is clear, actionable, and offers a concrete path for the authors to enhance the rigor and credibility of their findings. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about Figure 5, stating that it is difficult to comprehend and suggesting that more details about the two baselines should be provided. It also points out that the authors only study CATER for English-centric datasets and suggests that they could extend it to other languages in the future. While the comment implies that the authors should provide more details about the baselines and consider extending CATER to other languages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to improve Figure 5 or what details to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the difficulty in comprehending Figure 5 and the need for more details about the two baselines presented. Additionally, it suggests that the authors could extend CATER to other languages, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the two baselines should be provided. It also points out that the authors only study CATER for English-centric datasets, implying that the widespread text generation APIs support multiple languages. The suggestion to extend CATER to other languages is based on common knowledge about the capabilities of text generation APIs. However, the comment lacks specific examples or references to support the claim that Figure 5 is difficult to comprehend or to justify the need for more details about the baselines. This makes the claim somewhat verifiable, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, stating that it is difficult to comprehend. It suggests that more details about the two baselines presented in the figure are needed. Additionally, the comment points out that the authors only study CATER for English-centric datasets, which is a limitation given that widespread text generation APIs support multiple languages. The reviewer provides a constructive suggestion by recommending that the authors extend CATER to other languages in the future. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by providing more details and considering the applicability of their work to other languages. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the literature review needs improvement and provides specific guidance on what needs to be addressed. It highlights the lack of clarity in the main contribution and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"literature review\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be improved, such as clarifying the main contribution and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides clear guidance on what the authors need to address, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review is unclear and lacks a clear distinction between the proposed method and existing work, particularly regarding the utilization of GFlowNet for sequence generation. However, the comment does not provide specific examples or references to illustrate these issues, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed justification or examples results in the claim being somewhat verifiable, as it provides a general critique but lacks the specificity needed for full verification. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the literature review, noting that it lacks clarity in distinguishing the proposed method from existing work, particularly in the context of utilizing GFlowNet for sequence generation. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and actionable, as it guides the authors to improve the literature review by highlighting the need for a clearer explanation of the contribution and its differentiation from existing work. However, the comment could be more helpful if it provided specific examples or suggestions on how to enhance the literature review. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. However, it does not provide any specific guidance on how to address this suggestion or what alternative content could be included in its place. The action is implicit and vague, as the authors are left without clear instructions on how to implement the suggested change. Without concrete details on how to revise the draft, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 3.2,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by suggesting that the section can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it impacts the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution. While this feedback identifies a potential area for simplification or streamlining, it lacks depth and does not provide specific guidance on how to improve the draft. The comment does not offer actionable suggestions or explain why this section might be unnecessary, leaving the authors with only a vague direction for improvement. Therefore, the comment is barely helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula in the text, specifically mentioning the example of $\\\\ell_{BCE}$. This direct request leaves no ambiguity about what the authors need to do to improve their draft. The comment is clear and concrete, providing specific guidance on how to implement the suggested action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. While it does not explicitly mention a specific section or line, the authors can infer that it relates to the sections where the formula is discussed. The suggestion to provide specific details about the formula is clear, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the formula, specifically mentioning $\\\\ell_{BCE}$. However, it does not provide any justification or reasoning for why this additional detail is necessary or how it would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending that the authors provide more details about the formula, particularly mentioning $\\\\ell_{BCE}$. This feedback is clear and directly addresses a potential area for enhancement, guiding the authors on how to improve the clarity and comprehensiveness of their work. By suggesting a specific example, the comment offers concrete guidance that can help the authors enhance the readability and understanding of their manuscript. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that the link between IP and terms/equations should be explained more explicitly and prominently, which gives the authors a clear direction on how to improve the clarity of their explanation. Additionally, it instructs the authors to include labels for subfigures in Figures 3 and 4, rather than just stating them in the captions. This feedback is specific and actionable, providing the authors with clear steps to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining the link between IP and terms/equations more explicitly and prominently, and including labels for subfigures in Figures 3 and 4. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the link between IP and terms/equations could be explained more explicitly and prominently, and it requests the inclusion of labels for subfigures in Figures 3 and 4. These are requests for clarification or improvement, which do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment consists of factual statements and requests, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two aspects of the paper. First, it suggests that the link between IP and terms/equations could be explained more explicitly and prominently, which is a clear and constructive suggestion for improving the clarity of the paper. Second, it requests the inclusion of labels for subfigures in Figures 3 and 4, rather than just stating them in the captions, which is a straightforward and helpful suggestion for enhancing the presentation of the figures. This feedback is clear, actionable, and directly addresses areas for improvement, making it highly helpful for the authors to enhance their draft. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback provides a clear and explicit action for the authors to take, specifying exactly what kind of experiments should be conducted. The suggestion is concrete, as it outlines a specific type of analysis that could be performed to enhance the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting ablation experiments on the modifications mentioned in that section to validate the model performance further. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting ablation experiments to validate the model performance, given the modifications mentioned in Section 3.4. However, the comment does not provide specific examples or detailed reasoning to support why these modifications require further validation. Without additional context or explanation, the authors may find it challenging to understand the necessity or impact of these modifications. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by demonstrating the impact of the modifications on model performance. However, the comment could be more helpful if it included examples of what specific modifications should be tested or how the ablation experiments should be structured. Despite this, the suggestion is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that Proposition B.1 might be meant to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. The comment also points out that the authors\\' so-called \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to fill in Appendix A and clarify the purpose of Proposition B.1, but the lack of concrete guidance on how to do so makes the comment somewhat actionable. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the blank Appendix A and the unclear purpose of Proposition B.1, suggesting that it might be meant to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. Additionally, it points out the missing \"proof\" associated with the proposition. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the content and clarity of the appendices, specifically mentioning that Appendix A is blank and that the purpose of Proposition B.1 in Appendix B is unclear. The reviewer suggests that Proposition B.1 might be meant to illustrate a well-known concept in machine learning, the partitioning principle of K-means. However, the comment lacks specific examples or references to support the claim that the concept is well-known or that the proof is missing. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that Proposition B.1 might be meant to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. Additionally, it points out the absence of a \"proof\" associated with this proposition. While the comment highlights areas that need clarification or improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to specific parts of the paper that require attention, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the approximations introduced in the paper, noting that they leave loose ends and suggesting that the authors expand on the possible vulnerabilities, such as the assumption of attacks being in the feasible set. While the comment identifies an area that needs further exploration, it does not provide specific guidance on how the authors should address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (107-110) and approximations (i-iii), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the possible vulnerability due to the assumption of attacks being in the feasible set and suggests expanding on this to reassure readers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approximations introduced in the paper leave loose ends and suggests that the authors expand on the possible vulnerabilities, such as the assumption of attacks being in the feasible set. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of lines 107-110 provides some context, but without further elaboration, the authors may find it challenging to understand the full extent of the vulnerability. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approximations introduced in the paper, noting that they leave loose ends and may lead to vulnerabilities. It acknowledges the necessity of approximations for deriving clean results but suggests that the authors expand on the possible vulnerabilities, such as the assumption of attacks being in the feasible set. This feedback is somewhat helpful as it points out a specific area that needs further exploration and clarification. However, it lacks detailed guidance or suggestions on how the authors might address these vulnerabilities or reassure readers about their validity. To be more helpful, the comment could include specific questions or examples that the authors should consider. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve their work. There is no explicit or implicit action for the authors to take, leaving them without direction on how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this opinion is based on, nor does it provide details on what aspects of the contribution or model are considered limited or incremental. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references to what makes the contribution limited or the model incremental, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or suggestions on how the authors could enhance their contribution or make their model more innovative. Without actionable feedback or constructive criticism, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the different metrics used for different OPE methods in the experimental part of the paper. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods shown in Figures 4 and 5. While the comment implies that the authors should address this discrepancy, it does not explicitly instruct them to do so or provide guidance on how to analyze or discuss the differences. The action is implicit and somewhat vague, as the authors need to infer the need for additional commentary and may not be entirely sure of the specific aspects to focus on. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the differences in the methods used for different OPE methods in the two sets of benchmarks. The comment requests additional comments on these differences, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the different methods in the two sets of benchmarks proposed in the paper are quite different in different OPE methods. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests that the authors should provide comments on the differences, but without further elaboration, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experimental section, noting that the different metrics used for different OPE methods are not consistent across the two sets of benchmarks. It suggests that the authors should provide comments on the differences between these evaluation methods. This feedback is clear and actionable, as it directs the authors to address a potential inconsistency in their experimental setup. However, the comment could be more helpful if it included specific suggestions on how to analyze or discuss these differences. Overall, the comment is mostly helpful, as it highlights an important area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests that they include a discussion of the iteration cost for all related methods, including baseline methods. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be addressed in the paper. The suggestion is concrete, as it outlines the specific information that should be included, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its request for a discussion on iteration cost, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim is not verifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing an important aspect of the methodology. By including a discussion on iteration cost, the authors can provide a more comprehensive evaluation of their method and its efficiency compared to others. However, the comment could be more helpful if it offered additional guidance on how to present this information or why it is crucial. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit and concrete actions for the authors to take. It suggests reporting the average over multiple runs to address the issue of results being close together, which would help in favoring one method. It also recommends discussing the decision boundaries in the toy-dataset, which would provide insight into the results. Additionally, it asks for clarification on what information is in Figure 9, specifically the middle and right parts. Each of these points is clear and actionable, giving the authors specific guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections (a, b, and c) of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be addressed in each section. For example, it suggests reporting averages over multiple runs, discussing the decision boundaries in the toy-dataset, and clarifying the information in Figure 9. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for additional information and clarification regarding the experimental section. It does not contain subjective opinions, judgments, or suggestions that require verification. The requests for reporting averages over multiple runs and discussing the decision boundaries in the toy-dataset are factual and descriptive in nature. Similarly, the question about the information in Figure 9 is a request for clarification. Therefore, the review point is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several actionable points for improvement in the experimental section. It suggests reporting the average over multiple runs to address the issue of results being close together, which would help in favoring one method. Additionally, it recommends discussing the decision boundaries in the toy-dataset, which could provide insight into the results. The comment also asks for clarification on what information is in Figure 9, specifically the middle and right parts. These suggestions are clear and actionable, offering the authors specific guidance on how to enhance their draft. However, the comment could be more helpful if it provided additional context or examples for the suggested improvements. Overall, the feedback is mostly helpful as it directs the authors toward meaningful enhancements, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the inconsistency in the authors\\' use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer asks for clarification on why this metric was found useful in this context and not elsewhere. While the comment highlights a potential inconsistency, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their reasoning or provide an explanation for the discrepancy. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (80-82) and figures (4 A&B), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the inconsistency in the use of the center correlation metric and asking for clarification on why it was found useful in this context but not elsewhere. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inconsistency in the authors\\' use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer seeks clarification on why this metric was found useful in this context and not elsewhere. While the comment highlights a potential inconsistency, it does not provide any reasoning or evidence to support the claim that the metric is uninformative. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the authors\\' use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer questions why this metric was found useful in this context and not elsewhere, seeking clarification on the authors\\' statement. This feedback is somewhat helpful as it points out a specific area of confusion that the authors need to address. However, it lacks detailed guidance or suggestions on how the authors might clarify or resolve this inconsistency, which limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, making it highly actionable. It identifies specific issues with the experimental evaluation, such as the lack of ablation for the \"picking\" step and the unconvincing comparison on CIFAR. The reviewer suggests that the authors should include more extensive experiments on CIFAR, comparing their approach to multiple methods in the continual learning literature. Additionally, the comment advises that the authors should ensure the correct use and evaluation of DEN to make the comparison fair. Each of these points provides clear guidance on what needs to be addressed and how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Experimental Evaluation,\" \"Ablations,\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the ablation study, the lack of convincing comparison on CIFAR, and the need for a fair comparison with DEN. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the experimental evaluation, specifically questioning the ablation study and the comparison on CIFAR. It points out that the paper claims a specific distinction but does not ablate it, and it criticizes the comparison on CIFAR as not convincing. The reviewer suggests that the authors should include more extensive comparisons and ensure the correct use and evaluation of DEN to make the comparison fair. While the comment provides some reasoning and suggests improvements, it lacks specific examples or references to support the claims fully. Therefore, the comment is somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides detailed and actionable feedback on the experimental evaluation section of the paper. It identifies specific issues, such as the lack of ablation for the \"picking\" step and the unconvincing comparison on CIFAR, which is not supported by extensive experiments or comparisons to multiple approaches in the continual learning literature. The reviewer suggests that the authors should use the same setup as in the DEN paper to ensure a fair comparison, which is a clear and constructive suggestion. This feedback is highly helpful as it guides the authors on how to improve the robustness and credibility of their experimental results, making it easier for them to enhance the quality of their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which might be perceived as a local property. However, it does not provide explicit guidance on how the authors should revise their draft to implement this suggestion. The action is implicit and lacks concrete details, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"above/below diagonal\" and the plot, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree,\" which is easier to interpret. This provides clear guidance on how to enhance the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which might be perceived as a local property. However, the comment does not provide any supporting evidence or reasoning to justify why the former is preferable. It lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a specific suggestion for improving the clarity of the paper by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a concrete way to enhance the interpretability of the plot, which is valuable for the authors. However, the comment could be more helpful if it explained why the suggested change would be beneficial or how it might impact the reader\\'s understanding. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion, but it could be expanded to offer more comprehensive guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of scientific insight provided by the model and formalism compared to prior task-optimized approaches. It questions whether the model is a prototype approximation to non-linear RNN models and whether it offers an explanation for how these models attain solutions through optimization. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their work. The feedback lacks actionable details, such as recommending specific analyses or experiments to demonstrate the model\\'s insights or suggesting ways to enhance the explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the lack of scientific insight provided by the model and formalism compared to prior task-optimized approaches. The comment questions whether the model is a prototype approximation to non-linear RNN models and whether it offers an explanation for how these models attain solutions through optimization. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the scientific insight provided by the model and formalism compared to prior task-optimized approaches. It specifically critiques the lack of demonstration that the model is a prototype approximation to non-linear RNN models and questions whether it offers an explanation for how these models attain solutions through optimization. While the comment raises valid concerns, it lacks specific examples or references to support the claim that the model does not provide additional insight. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the critique themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the scientific insight provided by the model and formalism compared to prior task-optimized approaches. It specifically questions whether the model is a prototype approximation to non-linear RNN models and whether it offers an explanation for how these models attain solutions through optimization. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the explanation. The feedback is somewhat helpful as it prompts the authors to consider the novelty and contribution of their work, but it could be more beneficial with additional direction or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training of O_{up} in the supplementary material, specifically regarding the output of offsets for keypoints relative to the center of the upper part. It questions the methodology used to build the groundtruths and how the network parts predict all the keypoints of the pose. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions for the authors to address this concern. The authors are left to infer that they need to clarify or revise the explanation of the training process, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the training of O_{up} and questions how the groundtruths are built and how the network parts predict all the keypoints of the pose. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the methodology and training process described in the supplementary material. It does not contain subjective claims, opinions, or suggestions that require verification. The questions seek clarification and understanding, which are factual in nature. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific concern about the methodology described in the supplementary material, particularly regarding the training of O_{up}. It questions the logic behind the training process and how the network parts predict all the keypoints of the pose. This feedback is somewhat helpful as it identifies a potential issue with the explanation or implementation of the methodology. However, it lacks actionable suggestions or guidance on how the authors might address this concern or clarify the methodology. While it prompts the authors to reconsider their approach, it does not provide detailed advice on how to improve the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit and concrete actions for the authors to take. It suggests that the figures are too small and almost unreadable, implying that they should be enlarged or improved in quality. It also points out specific issues with the explanation of equations and parameters, such as the lack of clarity on how equation 5 follows from equation 4 and the unclear role of \\\\( \\\\theta^{t+1/2} \\\\). Additionally, it highlights the need to properly define \\\\( S^{*} \\\\) and \\\\( S^{\\\\sim} \\\\), noting that the current definition is improper. These comments provide clear guidance on what needs to be addressed and how to improve the draft, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements such as \"figures,\" \"equation 5,\" \"equation 4,\" \"\\\\( \\\\theta^{t+1/2} \\\\),\" \"S^{*} and S^{~},\" and \"Assumption 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, the explanation of equations, and the definition of parameters, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims about the figures, equations, and parameters in the paper. It states that the figures are small and almost unreadable, which is a factual observation. The comment also points out that the explanation of how equation 5 follows from equation 4 is unclear, and it questions the clarity of how \\\\( \\\\theta^{t+1/2} \\\\) is used. Additionally, it notes that the definition of \\\\( S^{*} \\\\) and \\\\( S^{\\\\sim} \\\\) is improper and that the definition in Assumption 1 is not correct. These claims are somewhat verifiable as they highlight specific issues with the presentation and clarity of the paper, but they lack detailed explanations or references to support the claims fully. The authors would need to make a significant effort to understand and address these points, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several specific and actionable pieces of feedback that can help the authors improve their draft. It points out that the figures are too small and almost unreadable, suggesting that they should be enlarged or improved in quality. Additionally, it highlights issues with the explanation of equations, specifically how equation 5 follows from equation 4, and the unclear role of \\\\( \\\\theta^{t+1/2} \\\\) in the context. The comment also addresses the definition of important parameters \\\\( S^{*} \\\\) and \\\\( S^{\\\\sim} \\\\), noting that their definition is improper and that the reference to Assumption 1 is incorrect. This detailed feedback provides clear guidance on what needs to be clarified or corrected, making it highly helpful for the authors to enhance the clarity and accuracy of their work. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that the texts in legends and axis labels should be larger, corrects the notation \"Proposition (1)\" to \"Proposition 1,\" and recommends increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These instructions are clear and specific, giving the authors precise guidance on how to improve the presentation of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"page 6\" and \"Fig. 2 and 3,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it provides clear guidance on what needs to be addressed, including the font size of texts in legends and axis labels, the correction of \"Proposition (1)\" to \"Proposition 1,\" and the font size of captions and legends in Figures 2 and 3. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the presentation of the paper, such as increasing the font size of texts in legends and axis labels, correcting the notation \"Proposition (1)\" to \"Proposition 1,\" and adjusting the font size of captions and legends in Figures 2 and 3. These suggestions are based on logical reasoning and common practices in academic writing, ensuring clarity and readability. However, the comment does not include references or detailed explanations to fully substantiate the claims, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback regarding the presentation of the paper. It suggests increasing the font size of texts in legends and axis labels, which would improve readability. Additionally, it corrects a notation error, clarifying the distinction between \"Proposition (1)\" and \"Equation 1.\" The comment also recommends adjusting the font size of captions and legends in Figures 2 and 3 to match the text size, ensuring consistency and clarity. This detailed guidance empowers the authors to make precise improvements to the visual presentation of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison against Journey TRAK [1] at a particular step of the sampling trajectory, specifically mentioning Figure 2 from Journey TRAK, which shows a larger effect of removing high-scoring images compared to CLIP cosine similarity. This comment provides a clear and explicit action for the authors to take, specifying exactly what comparison should be made and referencing a specific figure for guidance. The suggestion is concrete, as it outlines a specific experiment to conduct and a particular aspect to focus on. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"counterfactual experiments\" and suggests a comparison against Journey TRAK [1], specifically referencing Figure 2 from Journey TRAK. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely, a comparison against Journey TRAK at a particular step of the sampling trajectory, and it provides a specific reference to Figure 2 from Journey TRAK. This level of detail provides clear guidance on what the authors need to consider or add to their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the counterfactual experiments could benefit from a comparison against Journey TRAK [1] at a specific step of the sampling trajectory. The reviewer supports this claim by referencing Figure 2 from Journey TRAK, which shows a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This reference provides a specific example and reasoning to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It recommends comparing the results against Journey TRAK [1] at a particular step of the sampling trajectory, referencing Figure 2 from Journey TRAK, which shows a larger effect of removing high-scoring images compared to CLIP cosine similarity. This feedback is clear and constructive, offering a concrete way for the authors to enhance the depth and relevance of their analysis. By following this suggestion, the authors can provide a more comprehensive evaluation of their method, potentially leading to a stronger contribution to the field. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results suggest that replacing normal convolutions with adaptive convolutions is not always beneficial, as demonstrated by the performance of ACNN-v3 compared to ACNN-v2 in Table-3. It highlights the importance of the placement of adaptive convolutions but notes the lack of analysis or comments on this aspect. While the comment identifies an area for further exploration, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors know they need to analyze the placement of adaptive convolutions but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of the placement of adaptive convolutions and notes the lack of analysis or comments on this aspect. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the placement of adaptive convolutions is important based on the experimental results presented in Table-3. It provides specific evidence by comparing the performance of ACNN-v3 (all adaptive convolutions) with ACNN-v2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions affects the outcome. However, the comment lacks further analysis or references to support the claim that the placement is crucial. While the evidence provided is somewhat verifiable, the absence of additional details or comparisons makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the placement of adaptive convolutions appears to be important for performance. It points out that ACNN-v3, which uses all adaptive convolutions, performed worse than ACNN-v2, which uses adaptive convolutions only in the last layer. This observation highlights a potential area for further analysis and discussion in the paper. However, the comment does not provide detailed guidance or suggestions on how the authors might explore or address this issue, such as recommending specific analyses or experiments to conduct. While it offers some insight into a potential weakness, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a trade-off in the proposed method, noting that while it reduces computation time, it does so by limiting the search space to ancestral graphs, which results in less information compared to the output of a richer search space (DAGs). The reviewer poses a question about how much information from a DAG is encoded in its corresponding ancestral graph. While the comment identifies an area of concern and raises a question, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore or address the trade-off between computation time and information richness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the proposed method, namely the reduction in computation time compared to a previous work ([10]) and the trade-off between search space and information richness. It highlights the limitation of the proposed method in terms of information loss due to the reduced search space. However, the comment does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the issue of information loss and the trade-off involved, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method reduces computation time by limiting the search space to ancestral graphs, resulting in less information compared to the output of a richer search space (DAGs). The reviewer questions how much information from a DAG is encoded in its corresponding ancestral graph. While the comment provides a logical reasoning about the trade-off between computation time and information richness, it lacks specific examples or references to support the claim. The question posed is more of a request for clarification rather than a direct critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a trade-off in the proposed method, noting that while it reduces computation time, it does so by limiting the search space to ancestral graphs, resulting in less information compared to the output of a richer search space (DAGs). This observation highlights a potential limitation of the method, which is valuable for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this trade-off or improve the method to retain more information while maintaining computational efficiency. While it raises an important point, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a brief discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. This feedback is explicit and provides concrete guidance on what the authors should address in their discussion. The suggestion is clear and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests including a brief discussion on the empirical motivation for time-varying Q^t and S_t, and provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. This provides clear guidance on what needs to be addressed in the discussion section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. This suggestion is based on logical reasoning and provides a clear direction for the authors to explore in their discussion. However, it lacks specific references or detailed examples from existing literature to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the suggestion but could benefit from additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the discussion section of the paper. It recommends including a brief discussion on the empirical motivation for time-varying Q^t and S_t, as opposed to a fixed one as in Section 4.2. The comment offers a concrete example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. This feedback is clear and constructive, guiding the authors on how to enhance their discussion and potentially improve the understanding of their methodology. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchor-based regression and the regression in RepPoints. It also mentions that RetinaNet and ATSS use a one-shot regression and that the method of directly regressing [w, h] to the center point is sufficient. The reviewer suggests that RepPoints regresses distance to the location of feature maps, implying that there may be no obvious difference between the two methods. The comment concludes by requesting clarification and questioning the motivations if the issue is not addressed. While the comment implies that the authors should clarify the definitions and motivations, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the definitions in Table 1, particularly the differences between anchor-based regression and the regression in RepPoints, and questions the motivations behind these methods. The comment provides a detailed critique and suggests that the authors clarify the issue, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchor-based regression and the regression in RepPoints. It references RetinaNet and ATSS, suggesting that the regression methods do not significantly influence performance. The reviewer argues that the method of directly regressing [w, h] to the center point is sufficient, implying that RepPoints may not offer significant advantages. While the comment provides some context and references, it lacks detailed explanations or specific examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the critique, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the definitions in Table 1, specifically questioning the differences between anchor-based regression and the regression in RepPoints. It references other works like RetinaNet and ATSS to support the claim that the regression methods do not significantly influence performance. The reviewer suggests that the method of directly regressing [w, h] to the center point is sufficient and questions the need for RepPoints, which regresses distance to the location of feature maps. The comment is mostly helpful as it identifies a potential issue with the clarity of the definitions and motivations in the paper. However, it could be more helpful by providing specific suggestions on how to clarify the definitions or improve the explanation. Overall, the feedback is actionable and provides a clear direction for the authors to enhance their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete guidance on how to correct a specific error in the manuscript. It instructs the authors to change \"Fig. 5.1\" to \"Fig. 1\" on line 205 and suggests using the correct LaTeX syntax for labeling figures. This feedback is clear and actionable, as it gives the authors precise steps to take to resolve the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be corrected, namely changing \"Fig. 5.1\" to \"Fig. 1\" and suggesting the correct LaTeX syntax for labeling figures. This level of detail provides the authors with clear instructions on how to address the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding a typographical error in the manuscript. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual statement about the correct labeling of a figure, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable piece of feedback regarding a typographical error in the manuscript. It identifies the incorrect reference to \"Fig. 5.1\" on line 205 and suggests the correct label, \"Fig. 1.\" Additionally, it offers a technical suggestion for correcting the error in LaTeX syntax, which is valuable for ensuring the manuscript's accuracy and professionalism. This level of detail and clarity makes the comment highly helpful, as it empowers the authors to make a precise correction that will improve the overall quality of their draft. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it recommends adding references next to baseline names in tables, specifying that citations should be placed next to specific baseline names if they refer to a particular paper method. This is a clear and concrete suggestion, providing the authors with a direct action to improve the clarity of their tables. Second, it points out that in Corollary 1, $\\\\Omega$ is not explicitly defined, but it is not hard to infer what it means. This implies that the authors should clarify the definition of $\\\\Omega$ in the text. Both actions are explicit and provide concrete guidance on how to implement the changes, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables\" and \"Corollary 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: adding references next to baseline names in tables and explicitly defining $\\\\Omega$ in Corollary 1. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: one regarding the need to add references next to baseline names in tables, and another about the lack of explicit definition of $\\\\Omega$ in Corollary 1. The first claim is somewhat verifiable as it suggests a standard practice in academic writing, but it lacks specific examples or references to support the necessity of this practice. The second claim is also somewhat verifiable, as it points out a potential issue with clarity in the paper, but it does not provide detailed reasoning or examples to fully substantiate the need for clarification. Both claims could be strengthened with more detailed justification or examples, making them somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two specific and actionable pieces of feedback. First, it suggests adding references next to baseline names in tables, which would help readers identify the sources of the methods being compared. This is a clear and practical suggestion that can improve the clarity and transparency of the paper. Second, it points out that $\\\\Omega$ is not explicitly defined in Corollary 1, although it is not difficult to infer its meaning. This feedback highlights a potential area for clarification, which could enhance the reader\\'s understanding of the theoretical contributions. Both pieces of feedback are constructive and offer concrete steps for the authors to improve their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to correct the caption for Figure 7, specifying that it should be changed from \"Node Dynamics\" to \"Edge Dynamics.\" This direct and clear instruction provides the authors with a specific action to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable as it gives concrete guidance on how to implement the change.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected in the caption, namely changing \"Node Dynamics\" to \"Edge Dynamics.\" This provides clear guidance on what needs to be revised. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the incorrect caption for Figure 7, which is easily verifiable by checking the figure. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable piece of feedback by pointing out an error in the caption for Figure 7. It clearly identifies the issue and suggests a correction, which is a straightforward and effective way to improve the accuracy and clarity of the paper. This feedback is highly helpful as it directly addresses a specific mistake, allowing the authors to make a precise correction that will enhance the overall quality of their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide the standard deviation after multiple experiments and to clarify whether the observed improvements are within the range of standard deviation fluctuations or are due to the SoRA method. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section of the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue of missing standard deviation after multiple experiments and suggests that the authors clarify whether the observed improvements are due to random fluctuations or the SoRA method. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the standard deviation after multiple experiments is not provided, which may lead to the perception that the improvement brought by SoRA is limited due to random fluctuations. The reviewer suggests that the authors clarify whether the observed effects are within the range of standard deviation fluctuations or are improvements due to the SoRA method. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim about the limited improvement. The suggestion to clarify the effects is reasonable, but the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the experimental section of the paper, namely the absence of standard deviation after multiple experiments. It highlights the potential issue of random fluctuations affecting the perceived improvement of the SoRA method over the baseline. The comment provides a clear and actionable suggestion for the authors to clarify whether the observed effects are within the range of standard deviation fluctuations or are due to the SoRA method. This feedback is valuable as it guides the authors to provide additional statistical analysis to support their claims, thereby enhancing the robustness and clarity of their findings. However, the comment could be more helpful if it offered specific guidance on how to present this information or suggested additional analyses to differentiate the effects. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several specific issues with the organization and presentation of the paper, such as the font size of annotations in figures, the placement of Table 2, and the formatting of the top two lines on page 6. These issues are clearly stated, providing the authors with explicit and concrete actions to take to improve the layout and presentation of their paper. The comment is highly actionable as it offers precise guidance on how to address the identified problems.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific issues with the organization and presentation of the paper, including the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These specific references allow the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with the layout, such as the font size, figure clarity, and table placement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well organized and provides specific examples of issues with the layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These specific examples provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by offering suggestions for improvement or referencing accepted standards for layout and presentation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the organization and presentation of the paper, such as the font size of annotations in figures, the placement of Table 2, and the formatting of the top two lines on page 6. These detailed observations provide the authors with clear and actionable feedback on how to improve the layout and presentation of their paper. By addressing these specific concerns, the authors can enhance the readability and professionalism of their work. However, the comment could be more helpful if it included suggestions on how to improve the overall organization of the paper. Despite this, the feedback is mostly helpful as it directs the authors to specific areas needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies an issue with the notation \\\\( \\\\mathcal{P} \\\\) with a subscript being used multiple times without being defined. This feedback provides a clear and explicit action for the authors to take: define the notation \\\\( \\\\mathcal{P} \\\\) with a subscript. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"same section\" where the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of the notation not being defined, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the paper, noting that the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used multiple times without being defined. This is a factual observation about the paper\\'s content, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used multiple times without being defined. This is a clear and actionable piece of feedback, as it directs the authors to clarify the notation in their manuscript. By addressing this point, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggested how the authors might define the notation. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a clear action for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It corrects a spelling error (\"known\" instead of \"know\") at line 148, requests a definition for \\\\( \\\\gamma_0^{***} \\\\) at line 156, and asks for the meaning of the colors in Figure 1 to be specified in both the caption and the text. Each of these points is clear and actionable, giving the authors specific tasks to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (l148 and l156) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear and actionable feedback, such as correcting a spelling error, defining a term, and specifying the meaning of colors in the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual corrections and requests for clarification, such as specifying the meaning of colors in a figure. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying spelling errors, requesting a definition for a term, and specifying the need to clarify the meaning of colors in a figure. These points are clear and directly address areas where the manuscript can be improved, making the feedback highly helpful. By correcting these minor issues, the authors can enhance the clarity and professionalism of their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues that need clarification. It questions the meaning of \"upper faces\" of the convex hull and requests a better explanation of the dual subdivision and projection \u03c0. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. The reviewer suggests that it would make sense to move the definition of \"p\" earlier in the paper. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit but concrete, as the authors can infer that they need to clarify these points and possibly reorganize the content. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the \"upper faces\" of the convex hull and the dual subdivision and projection \u03c0, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for better explanation of the dual subdivision and projection \u03c0 and the explicit definition of the variable \"p.\" Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the paper, specifically questioning the meaning of \"upper faces\" of the convex hull and the need for better explanation of the dual subdivision and projection \u03c0. It also points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. While the comment identifies specific areas of confusion, it lacks detailed reasoning or examples to fully substantiate the claims. The authors are left to infer the issues and address them without explicit guidance. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper lacks clarity and precision. It questions the meaning of \"upper faces\" of the convex hull and requests a better explanation of the dual subdivision and projection \u03c0. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. The comment provides actionable feedback by suggesting that the definition of \"p\" should be moved earlier in the paper. This guidance is clear and constructive, offering the authors specific areas to address and improve the clarity and coherence of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that the authors evaluate the method separately on baseline detection or parsing techniques to better support their claim. While the comment implies a specific action\u2014conducting separate evaluations\u2014it does not provide detailed guidance on how to implement this evaluation or which specific baselines to use. The action is explicit but somewhat vague, as the authors know they need to conduct separate evaluations but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and its two major components: the \"generative shape model\" and the \"word parsing model.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of unclear contribution of each component to the performance gain and suggests evaluating the method separately on baseline detection or parsing techniques to support the claim. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the proposed method\\'s components and their contribution to performance gain. It suggests evaluating the method separately on baseline detection or parsing techniques to better support the claim. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the current evaluation is insufficient. The suggestion to conduct separate evaluations is logical, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that the authors evaluate the method separately on baseline detection or parsing techniques to better support their claim. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by conducting additional evaluations. However, the comment could be more helpful if it offered examples of baseline techniques or provided more detailed guidance on how to conduct these evaluations. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses questions about the experimental setup and design choices in Figure 1, specifically regarding the timbre encoder module and the input of SADTW. While these questions highlight areas that may need clarification or justification, they do not provide explicit actions for the authors to take. The authors can infer that they need to provide more information or justification for these aspects, but the comment lacks concrete guidance on how to address these questions. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs of the content encoder (and not the timbre encoder) as input. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the experimental setup and design choices in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the experimental setup and design choices in Figure 1, specifically regarding the timbre encoder module and the input of SADTW. By asking for the main rationales behind these decisions, the comment prompts the authors to provide a clearer explanation or justification for their design choices. This feedback is somewhat helpful as it highlights areas that may need further clarification or justification, but it lacks specific suggestions or guidance on how to address these questions. To be more helpful, the comment could include potential reasons or implications for these choices, which would provide the authors with a clearer path for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Table 4 is incomplete and should include results for all four datasets. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and leaves no ambiguity about the necessary change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue, which is that the table is incomplete and should include results for all four datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Table 4 is incomplete\" and suggests that it should include results for all four datasets. However, the comment does not provide any supporting evidence or reasoning to justify why the table is considered incomplete or why including results for all four datasets is necessary. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, as it provides the authors with a direct suggestion to improve their draft by ensuring that all relevant data is presented. However, the comment could be more helpful if it explained why including all datasets is important or how it would enhance the paper\\'s contribution. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement in their manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing or presentation is \"jumbled at times,\" but it does not provide specific examples or guidance on how to improve the clarity or organization of the text. Without concrete suggestions or detailed feedback, the authors are left without a clear understanding of what needs to be done to address the issue. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing or presentation is \"jumbled at times,\" but it does not specify which parts of the paper are problematic or provide examples of where the jumbled writing occurs. This lack of detail makes it difficult for the authors to identify and address the issues effectively. The comment is not grounded as it does not refer to specific sections, figures, or examples, and it is not specific because it lacks detailed guidance on what needs to be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or examples, the authors may find it challenging to understand and address the issue. The lack of supporting information makes the claim unverifiable, as it does not provide a clear basis for the authors to improve their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the writing or presentation is \"jumbled at times,\" but it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular sections or issues that contribute to the perceived jumbled nature of the writing, the authors are left without a clear understanding of what needs to be addressed. This lack of detail and guidance makes the comment unhelpful, as it does not offer a constructive path for the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the annealing scheme mentioned in the last paragraph of Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that might outweigh the benefits of using IWAE. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. It lacks concrete steps or recommendations for improvement, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"last paragraph in Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the importance of the annealing scheme and its potential to induce bias, particularly when $\\\\alpha$ is not decreased to $0$. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the importance of the annealing scheme mentioned in the last paragraph of Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that might outweigh the benefits of using IWAE. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without such evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides an initial rationale but requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the importance of the annealing scheme mentioned in the last paragraph of Section 4, particularly when $\\\\alpha$ is not decreased to $0$. It suggests that this could induce a bias that might outweigh the benefits of using IWAE. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or explore alternative approaches. The feedback is somewhat helpful as it prompts the authors to consider the implications of their method, but it could be more beneficial with additional detail or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It provides a clear and direct action for the authors to correct this misstatement by referencing Section 3 of Wang et al., 2023. The comment is specific and provides a concrete example of what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific statement in the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" and provides a clear reference to Section 3 of Wang et al., 2023. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is incorrect and provides a correction based on the referenced section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads is incorrect according to Section 3 of Wang et al., 2023. The reviewer provides a specific reference to an external source, which supports the claim by offering a clear and precise correction. This detailed reference and the explicit comparison to an authoritative source make the claim fully verifiable, as it provides a robust basis for the authors to understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It provides a clear and actionable suggestion by referencing Section 3 of Wang et al., 2023, which corrects the authors\\' claim that these heads primarily attend to the S2 token. This feedback is highly helpful as it directly addresses a factual inaccuracy in the paper, allowing the authors to make a precise correction that will improve the accuracy and credibility of their work. The comment is specific and provides a clear path for the authors to enhance the quality of their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, describing it as a \"pack of tricks\" to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors could address this critique or improve their work. There is no explicit or implicit action for the authors to take, leaving them without direction on how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the work, describing it as incremental and unimpressive. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the proposed pipeline are considered unimpressive or lacking in novelty. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, describing it as a \"pack of tricks\" to improve defense evaluation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or comparisons to other works, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the work, describing it as incremental and unimpressive, and suggests that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not identify particular aspects of the work that are considered unimpressive or suggest ways to enhance the novelty or impact of the contribution. Without specific guidance or constructive feedback, the authors are left without a clear path to address the critique. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it critiques the vagueness of a statement about certain RNNs working well for certain natural language reasoning tasks, suggesting that the authors refer to specific literature or a leaderboard for further clarification. This feedback is explicit and provides a clear action for the authors to take, which is to include references or examples to support their claim. Second, it questions the relevance of the reinforcement learning/agent analogy in the current context, suggesting that generalization capabilities are better illustrated later in the paper. While the first part of the comment is explicit and actionable, the second part is more vague and lacks specific guidance on how to address the issue. Overall, the comment is mostly actionable due to the explicit nature of the first part and the implicit nature of the second part.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the vagueness of certain statements about RNNs and the out-of-place reinforcement learning/agent analogy. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: one about the vagueness of a statement regarding RNNs and another about the out-of-place reinforcement learning/agent analogy. The first claim is somewhat verifiable as it suggests that the statement is vague and references specific literature and a leaderboard for further clarification. However, it lacks detailed reasoning or examples to fully substantiate the claim. The second claim is also somewhat verifiable as it questions the relevance of the analogy and suggests that generalization capabilities are better illustrated later in the paper. While it provides a direction for improvement, it lacks specific examples or references to fully substantiate the claim. Therefore, both claims are rated as somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it critiques the vagueness of a statement about certain RNNs working well for certain natural language reasoning tasks, suggesting that the authors refer to specific literature or a leaderboard for further clarification. This feedback is actionable as it directs the authors to provide more specific references or examples to support their claims. Second, the comment questions the relevance of the reinforcement learning/agent analogy in the current context, suggesting that generalization capabilities are better illustrated later in the paper. While this feedback identifies a potential issue, it lacks specific guidance on how to address it or what alternative approach might be more appropriate. Overall, the comment is somewhat helpful as it highlights areas for improvement but could be more comprehensive with additional guidance or suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of significant difference between the proposed sensitive-layer selection and randomized selection in terms of StableDiffusion, and the absence of mathematical or theoretical justification for Algorithm.1. While the comment identifies these areas for improvement, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to discuss the observed differences and provide a theoretical justification for Algorithm.1, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.5\" and the \"third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed sensitive-layer selection does not make a significant difference in terms of StableDiffusion and that the authors do not discuss this observation. Additionally, it highlights the lack of mathematical or theoretical justification for Algorithm.1. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed sensitive-layer selection does not make a significant difference in terms of StableDiffusion, as shown in Figure 5. It also notes the lack of mathematical or theoretical justification for Algorithm.1. While the comment provides some reasoning by referencing Figure 5, it lacks detailed explanation or examples to fully substantiate the claim about the lack of difference in StableDiffusion. Additionally, the comment does not provide specific references or detailed reasoning for the lack of mathematical or theoretical justification for Algorithm.1. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the proposed sensitive-layer selection does not make a significant difference in terms of StableDiffusion, as shown in Figure 5, and suggests that the authors should discuss this observation further. Second, it highlights the lack of mathematical or theoretical justification for Algorithm.1, indicating that this is an area that needs more attention. While the comment effectively identifies these weaknesses, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to important areas needing clarification or expansion, but it could be more beneficial with additional guidance on how to improve the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuple-like structure rather than as sets. This is a clear and direct action for the authors to take, providing specific guidance on how to improve the presentation of the data. The comment is concrete, as it specifies exactly what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the presentation of triples as tuples rather than sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the presentation of triples as $(e_1, r, e_2)$ should be changed to reflect their tuple-like structure rather than sets. However, the comment does not provide any justification or reasoning for why this change is necessary or how it would improve the clarity or understanding of the content. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the presentation of triples in the paper. By recommending that the triples be shown in a tuple-like structure rather than as sets, the reviewer offers a clear and straightforward way for the authors to improve the clarity and precision of their presentation. This feedback is precise and directly addresses a potential source of confusion, making it highly helpful for the authors to enhance the readability and accuracy of their work. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" suggesting that this is not true for RBF kernels due to their infinite-dimensional RKHS. The reviewer explicitly recommends that the authors make this limitation clearer. While the comment identifies a specific area that needs clarification, it does not provide detailed guidance on how to address the issue or what specific changes should be made to the draft. The action is explicit but somewhat vague, as the authors know they need to clarify the limitation but may not be entirely sure of the exact wording or approach to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about kernels and neural networks, providing a counterexample with RBF kernels and their infinite-dimensional RKHS. The comment further suggests that the limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"every kernel can be described by a feature space parameterized by a neural network\" by providing a counterexample with RBF kernels and their infinite-dimensional RKHS. The reviewer supports their claim with logical reasoning, explaining that an infinite-dimensional RKHS cannot be represented by a neural network with finite width. This reasoning is clear and provides a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific works or studies that discuss this limitation, which would provide a more robust justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels due to their infinite-dimensional RKHS. The reviewer provides a specific example and suggests that the limitation should be made more clear. This feedback is clear and actionable, as it directs the authors to address a specific misunderstanding or misrepresentation in their work. By highlighting this limitation and suggesting a clarification, the comment offers valuable guidance for improving the draft. Therefore, it is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the performance of GPI with noise added in Fig. 4, suggesting that there might be other measures to demonstrate its effectiveness. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should consider additional measures and discuss the approach\\'s applicability, it does not provide explicit instructions or concrete steps on how to address these points. The actions are implicit and somewhat vague, leaving the authors with a general idea of what to explore but without detailed guidance on how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the possibility of GPI with noise added reproducing data similarly well and suggests alternative measures to demonstrate its effectiveness. Additionally, it provides a specific suggestion to discuss the approach\\'s suitability for modeling pattern separation tasks. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and suggestions regarding the performance of GPI with noise added and its suitability for modeling pattern separation tasks. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions and suggestions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance of GPI with noise added, suggesting that there might be other measures to demonstrate its effectiveness. It also acknowledges the suitability of the approach for modeling pattern separation tasks and suggests discussing this aspect. While the comment identifies areas for further exploration and discussion, it lacks specific guidance or suggestions on how to address these points. The feedback is somewhat helpful as it prompts the authors to consider additional analyses and discussions, but it could be more actionable with detailed suggestions or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the performance gains. There is no guidance on potential modifications, additional experiments, or analyses that could be conducted to enhance the results. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the performance gains, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or table where performance metrics are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing the issue of low performance gains. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. This claim is somewhat verifiable as it provides a specific metric (less than 1%) to support the assertion of low performance gains. However, the comment lacks detailed examples or references to specific metrics or experiments, which would provide stronger evidence for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a specific issue with the paper, noting that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. This feedback is somewhat helpful as it highlights a potential limitation in the results, prompting the authors to consider whether the gains are significant enough to justify the proposed approach. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve the performance gains. To be more helpful, the comment could include specific recommendations or guidance on how to enhance the results or interpret the findings more effectively. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the contribution of specific types of information to the feedback network\\'s performance. It asks how much the information about incorrect phrases and corrected phrases, as well as the type of mistake, helps the feedback network. Additionally, it inquires about the performance without each of these types of information and with just natural language feedback. While the questions imply that the authors should conduct experiments to address these points, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to conduct these experiments or what specific analyses to perform. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the contribution of specific types of information to the feedback network\\'s performance. It specifically mentions \"incorrect phrase / corrected phrase\" and \"the type of the mistake,\" suggesting that these pieces of information might be important. However, the comment does not explicitly mention which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in detailing what information is being questioned and what aspects of performance are of interest, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the performance of the feedback network. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the contribution of specific types of information to the feedback network\\'s performance. It asks how much the information about incorrect phrases and corrected phrases, as well as the type of mistake, helps the feedback network. Additionally, it inquires about the performance without each of these types of information and with just natural language feedback. This feedback is somewhat helpful as it prompts the authors to consider the impact of different types of information on their model\\'s performance. However, it lacks specific suggestions or guidance on how to address these questions, such as recommending specific experiments or analyses. To be more helpful, the comment could include suggestions on how to investigate these aspects or provide examples of similar studies that have addressed similar questions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop with the Unary baseline. It suggests that if a better Unary baseline were used, there might still be a performance boost. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters and comparing the performance of LinearTop and NLTop with the Unary baseline. The comment raises a specific concern about the performance of the Unary baseline and suggests considering a better baseline to evaluate the performance boost. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop with the Unary baseline. It references specific tables (Tab 1,2,3) and suggests that the Unary baseline performs worse compared to the numbers reported in [14], where a different and possibly better neural network was used. This provides a logical basis for questioning the performance boost and suggests a potential issue with the baseline comparison. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the referenced literature and the specific comparisons to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop with the Unary baseline. It points out that the Unary baseline performs worse compared to the numbers reported in a referenced study, suggesting that a better baseline might still yield a performance boost. This feedback is valuable as it prompts the authors to reconsider their baseline choice and potentially improve their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative baselines to consider. Overall, the comment is somewhat helpful as it identifies a potential weakness and encourages further exploration, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the learning rates used for the deep models, particularly for CIFAR-10 and CIFAR-100, and suggests that the authors should provide the final used learning rates. It also mentions that the authors only searched 4 different learning rates, which could affect the results if the optimal learning rate was outside the tested interval. However, the comment does not explicitly instruct the authors to provide this information or suggest how to address the potential issue. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the learning rates for the deep models, such as CIFAR-10 and CIFAR-100. It also lacks specificity regarding what needs to be addressed or improved, such as providing the final used learning rates or discussing the implications of the limited search range. Without clear references or detailed guidance, the authors cannot effectively identify the areas needing attention or improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the learning rates used for the deep models, particularly for CIFAR-10 and CIFAR-100. The reviewer suggests that the authors should provide the final used learning rates because the limited search range could affect the results if the optimal learning rate was outside the tested interval. However, the comment lacks specific examples or references to support the claim that the results could be spoiled. The reasoning is somewhat logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the learning rates used for the deep models, particularly for CIFAR-10 and CIFAR-100. It points out that the authors only searched four different learning rates, which could potentially affect the results if the optimal learning rate was outside the tested interval. This is an important consideration that could impact the validity of the experimental results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional learning rates to test or providing a rationale for the chosen range. While it identifies a potential weakness, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The reviewer suggests that the results are insufficient to prove the benefits of the proposed methods and recommends additional experiments or more in-depth analysis to better justify the claims in the paper. While the comment implies that the authors should conduct further experiments or analysis, it does not provide specific guidance on how to proceed or what additional experiments or analysis might be necessary. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The comment further suggests that additional experiments or more in-depth analysis are necessary to better justify the claims in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approaches only outperform the baselines in one setup out of three, and that there is no consistent trend in the results. This claim is supported by the observation that the results presented are insufficient to prove the benefits of the proposed methods. The reviewer suggests that additional experiments or more in-depth analysis are necessary to better justify the claims. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to substantiate the need for further analysis. Therefore, the claim is somewhat verifiable, as it provides a reasonable basis for the suggestion but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback highlights a significant weakness in the paper\\'s claims, suggesting that the results are insufficient to prove the benefits of the proposed methods. The comment provides a clear direction for improvement by recommending additional experiments or more in-depth analysis to better justify the claims. While the comment effectively points out the problem, it could be more helpful by offering specific suggestions on what additional experiments or analyses might be conducted. Overall, the comment is mostly helpful as it provides actionable feedback that can guide the authors in strengthening their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some figures, specifically Figure 4, are not self-explanatory due to overlapping lines. It provides a specific example of the issue, where the lines for \"No adapt\" and \"Finetune\" are covered by other lines. However, the comment does not offer explicit guidance on how to improve the figure or what specific changes should be made to make it more self-explanatory. While the authors can infer that they need to clarify the overlapping lines, the comment lacks concrete instructions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies an issue but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the figure, namely that the lines for \"No adapt\" and \"Finetune\" are covered by other lines, which makes the figure less self-explanatory. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some figures, specifically Figure 4, are not self-explanatory due to overlapping lines. However, it does not provide further details or examples to support this claim, such as explaining how the overlapping lines affect the understanding of the figure or suggesting alternative ways to present the data. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines, making the figure less self-explanatory. This feedback is clear and actionable, as it points out a particular area where the figure could be improved to enhance clarity. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending ways to differentiate the lines or offering alternative visualizations. Overall, the comment is somewhat helpful as it highlights a specific problem but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the sampling performed to obtain different initializations x_0, noting that its importance for convergence to optimum is not experimentally evaluated on the proposed benchmarks. The reviewer points out that this is only evaluated in Table 1 in the supplementary material, where it is compared to sampling from a uniform distribution. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific experiments to conduct. The action is implicit, as the authors can infer that they need to conduct more experiments to evaluate the sampling method, but it remains vague because it lacks concrete steps or details on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not experimentally evaluating the sampling performed to obtain different initializations x_0 on the proposed benchmarks, except for the comparison to sampling from a uniform distribution in Table 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to optimum but is not experimentally evaluated on the proposed benchmarks. The reviewer supports this claim by referencing Table 1 in the supplementary material, where the sampling is compared to sampling from a uniform distribution. This provides a specific example of where the evaluation is conducted, offering some support for the claim. However, the comment could be strengthened by providing more detailed reasoning or additional examples of where the evaluation is lacking. As it stands, the claim is mostly verifiable, as it provides some evidence but lacks comprehensive support. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the sampling performed to obtain different initializations x_0, noting its importance for convergence to optimum. It points out that this aspect is not experimentally evaluated on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. This feedback highlights a gap in the experimental evaluation and suggests that the authors should conduct more thorough experiments to validate the effectiveness of their sampling method. However, the comment could be more helpful by providing specific suggestions on how to design these experiments or what additional benchmarks to consider. Overall, the comment is somewhat helpful as it directs the authors to an important area needing further exploration, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the logic behind the comparison of the proposed method with specific references ([9] and [16]) and the focus on computational cost. It questions the relevance of these comparisons and the significance of computational cost in the context of the paper. While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the rationale behind the comparisons and discuss the importance of computational cost more thoroughly. However, the lack of concrete instructions makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and references [9] and [16], allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the logic behind the comparisons, the focus on computational cost, and the relevance of these comparisons in the context of the paper. The comment highlights the need for further discussion on these points, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the logic and comparisons in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the logic and rationale behind the comparisons made in the paper, specifically between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and the relevance of these aspects to the paper. While the comment identifies areas of confusion and lack of clarity, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback highlights important questions that the authors should consider, but without actionable advice, it offers limited assistance in improving the draft. Therefore, the comment is somewhat helpful, as it points out potential weaknesses but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the PL condition used in the paper compares to those proposed in a specific reference. While it implies that the authors should address this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion where the PL condition is introduced. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for a comparison with the referenced work, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for a comparison between the PL condition used in the paper and those proposed in a specific reference. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference. While it identifies a potential area for improvement by suggesting a comparison with existing work, it lacks depth and does not provide specific guidance or suggestions on how the authors might conduct this comparison or what aspects to focus on. The comment is somewhat helpful as it points out a gap in the literature review or discussion, but it could be more beneficial with additional context or direction. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the need for the authors to discuss the impact of adding additional parameters and additional computational effort due to the multi-stage training and multiple discriminators. It explicitly states that this analysis is necessary for a fair comparison with the baseline. While the comment clearly identifies the action required, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. However, it does not specify which part of the paper this issue is related to, such as specific sections or experiments where these aspects are discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be addressed, namely the analysis of additional parameters and computational effort. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. This claim is somewhat verifiable as it highlights a potential gap in the analysis, but it does not provide specific examples or references to support the assertion. The authors would need to infer the importance of this analysis and how it affects the comparison with the baseline. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It highlights the importance of this analysis for a fair comparison with the baseline. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the analysis should be prioritized. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer detailed, actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It highlights the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. It lacks concrete steps or recommendations for improvement, leaving the authors uncertain about how to enhance their analysis. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, indicating that it is underwhelming. It also mentions the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence. However, the comment does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing what is lacking in the analysis, such as the need for theoretical evidence and clarity across different architectures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It highlights the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. While the comment identifies specific areas of concern, it does not provide detailed reasoning or references to support the claim. The lack of explicit examples or evidence makes it somewhat verifiable, as the authors would need to further explore and substantiate the critique themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that is underwhelming, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence to support the correlation. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance their analysis. The feedback is somewhat helpful as it directs the authors to a critical aspect of their work that needs further exploration, but it could be more actionable with additional guidance. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the potential pitfalls of using AutoAugment as a stronger augmentation strategy, specifically mentioning the possibility of information leaking due to its training on ImageNet. It also questions the implications of the authors\\' conclusion regarding the need for pretraining datasets to match the target dataset in terms of object or scene-centricity, and whether this could be a setback for self-supervised learning (SSL) algorithms. However, the comment does not provide explicit actions or suggestions for the authors to address these concerns. The questions are more like prompts for further exploration rather than actionable steps. As a result, the comment is vague and lacks concrete guidance, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues raised, such as the potential trap of information leaking due to AutoAugment\\'s training on ImageNet and the implications of the authors\\' conclusion regarding pretraining datasets. The comment raises specific questions about the implications of these findings, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the potential pitfalls of using AutoAugment as a stronger augmentation strategy, specifically mentioning the possibility of information leaking due to its training on ImageNet. However, the comment lacks specific evidence or references to support this claim, such as studies or examples of information leaking in similar contexts. The questions about the implications of the authors\\' conclusion regarding pretraining datasets are also not substantiated with detailed reasoning or references. As a result, the claim is somewhat verifiable, as it provides a logical basis for concern but lacks comprehensive evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the potential pitfalls of using AutoAugment as a stronger augmentation strategy, specifically mentioning the possibility of information leaking due to its training on ImageNet. This is a relevant point that could impact the validity of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential problems. Additionally, the comment includes questions about the implications of the authors\\' conclusion regarding pretraining datasets, but again, it lacks actionable feedback or detailed analysis. While the comment identifies potential weaknesses and raises important questions, it does not offer clear directions for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. While the action is explicit, it lacks concrete details on why this change would be beneficial or how it would impact the paper. The authors are given a clear directive to consider moving this content, but without further explanation or justification, they may not fully understand the rationale behind the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to \"the empirical version of the objective (3),\" which provides full grounding as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. However, the comment lacks specificity as it does not explain why putting this version in the supplementary materials might be appropriate or what specific issues it addresses. Without further detail, the authors may not fully understand the rationale behind the suggestion. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. However, the comment does not provide any justification or reasoning for why this change would be beneficial or necessary. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. While it provides a specific suggestion for improvement, it lacks further explanation or justification for why this change would be beneficial. The authors are given a clear action to consider, but without additional context or reasoning, they may not fully understand the rationale behind the suggestion. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the interpretation of Corollary 10, suggesting that it does not necessarily imply that uncertainty sampling is minimizing the expected convex surrogate. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes, if any, are needed to clarify or correct the interpretation. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (ln. 180--182), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that it is minimizing the expected convex surrogate. This provides clear guidance on what aspect of the interpretation needs clarification or correction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the interpretation of Corollary 10, suggesting that it does not necessarily imply that uncertainty sampling is minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out that the corollary only shows descent directions of the expected 0-1 loss, which is a different concept from minimizing the expected convex surrogate. However, the comment lacks specific examples or references to support this reasoning further, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of Corollary 10, suggesting that it does not necessarily imply that uncertainty sampling is minimizing the expected convex surrogate. This feedback is somewhat helpful as it points out a possible misinterpretation or overgeneralization in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the interpretation. Without actionable advice or detailed feedback, the authors are left with a general observation that requires further exploration and clarification. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance improvement of the proposed methods, as shown in Figure 3, does not seem significant, with the biggest improvement in the bank dataset being only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. While the comment implies that the authors should include additional tables to provide more detailed performance data, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to add tables to enhance the clarity and detail of their results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. The comment further suggests using tables to directly show key improvements, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, with the biggest improvement in the bank dataset being only ~0.02. The reviewer suggests using tables to directly show key improvements, which could provide more detailed insights. However, the comment lacks specific examples or detailed reasoning to substantiate the claim about the lack of significance in the performance improvement. Without additional context or references, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides an initial observation but lacks comprehensive support or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the significance of the performance improvement of the proposed methods, as shown in Figure 3. It points out that the biggest improvement in the bank dataset is only ~0.02, which may not be considered significant. The comment suggests using tables to directly show key improvements, which could provide a more intuitive and detailed presentation of the results. This feedback is clear and actionable, offering a specific suggestion for enhancing the clarity and impact of the results presentation. However, it could be more helpful if it provided additional guidance on how to effectively use tables to highlight key improvements. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search strategy for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work in relation to related works. The comment provides explicit actions for the authors to take, such as describing the optimization strategy and considering deeper networks, as well as suggesting a specific reference for layer redundancy. These suggestions are clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses multiple issues, including the lack of convincing experimental validation, the consideration of only shallow networks, and the absence of a description of the optimization strategy, particularly the grid search strategy for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work in relation to related works. The comment provides specific details about what is missing or unclear, such as the need for a description of the optimization strategy and the consideration of deeper networks. However, it does not explicitly mention which sections of the paper these issues pertain to, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental validation is not convincing due to the limited consideration of shallow networks and the lack of description of the optimization strategy, including the grid search strategy for hyperparameter selection. The comment also mentions a minor issue regarding the positioning of the work in relation to related works, specifically referencing layer redundancy in network pruning. While the comment provides some reasoning for the claim, it lacks detailed examples or specific references to substantiate the critique of the experimental validation. The mention of a related work on layer redundancy adds some support but does not fully address the broader critique of the experimental validation. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the experimental validation and methodology of the paper. It points out that only shallow networks are considered, which limits the generalizability of the findings, and highlights the need for a more detailed description of the optimization strategy, including the grid search strategy for hyperparameter selection. Additionally, the comment mentions a minor issue regarding the positioning of the work in relation to related works, specifically referencing layer redundancy in network pruning. While the comment provides valuable insights into the weaknesses of the paper, it could be more helpful by offering specific suggestions on how to address these issues or by providing examples of how to improve the experimental validation. Overall, the feedback is somewhat helpful as it directs the authors to critical areas needing attention, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is limited, indicating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could enhance their technical contribution or what specific aspects need improvement. The feedback lacks actionable details, leaving the authors without a clear understanding of what changes are needed to address the concern. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the technical contribution are lacking. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a perceived limitation in the technical contribution of the paper, stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not identify particular weaknesses or areas that need addressing, leaving the authors without clear guidance on how to enhance their work. As a result, the comment is not helpful at all, as it does not offer any constructive direction for improving the draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This is an explicit suggestion, as it clearly states what the authors should do to improve their draft. However, it does not provide specific guidance on which fully-supervised baselines to include or how to implement this addition. While the action is clear, the lack of detailed instructions makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding fully-supervised baselines for small models to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This feedback is clear and actionable, as it provides a specific recommendation that could enhance the paper\\'s analysis and interpretation of results. By including these baselines, the authors can provide a more comprehensive comparison and insight into the performance of their models. However, the comment could be more helpful if it explained why this addition is important or how it might impact the conclusions drawn from the results. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It also mentions that the results of WeakNAS are similar to BRP-NAS, as shown in Table 2 in Appendix C. However, the comment does not provide any explicit or implicit suggestions for how the authors could address these issues or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the novelty or originality of the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy, which are compared to existing methods. It also references Table 2 in Appendix C, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific because it details the lack of novelty in the approach and compares it to existing methods, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It supports this claim by referencing specific methods (MLP, Regression Tree, Random Forest) and comparing the sampling strategy to epsilon-greedy and BRP-NAS. Additionally, it provides a comparison of results in Table 2 in Appendix C. This detailed comparison and references to existing literature make the claim fully verifiable, as it provides a robust basis for the reviewer\\'s assertion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies specific components of the approach that are not novel, such as the use of weak predictors like MLP, Regression Tree, or Random Forest, which have been used in previous NAS performance prediction studies. It also points out that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the comment notes that the results of WeakNAS are almost identical to BRP-NAS, as shown in Table 2 in Appendix C. While the comment highlights these issues, it does not provide constructive suggestions or guidance on how the authors might address these concerns or differentiate their work from existing methods. The feedback is somewhat helpful as it identifies areas that need attention, but it lacks actionable advice or specific recommendations for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the OT sample selection process in Section 2.4.3, specifically asking whether it runs once or iteratively as the EP module is updated during training steps. It also inquires about the order of operations, such as whether optimizing the loss of equation (10) and solving OT in equation (3) are conducted iteratively. The reviewer suggests adding more details and a flow chart to clarify the process, which is a direct and actionable recommendation. Additionally, the reviewer asks for runtime information for solving the entropic regularized discrete OT problem and the OT sample selection process. These questions provide clear guidance on what additional information should be included in the paper. The comment is explicit and provides concrete details on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10)\" and \"equation (3),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises detailed questions about the OT sample selection process, the order of operations, and the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. The comment provides clear guidance on what additional information is needed to improve the clarity and understanding of the process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the OT sample selection process and its relationship to the EP module and training steps. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the OT sample selection process in Section 2.4.3, specifically whether it runs once or iteratively as the EP module is updated during training steps. It also inquires about the order of operations, such as whether optimizing the loss of equation (10) and solving OT in equation (3) are conducted iteratively. The reviewer suggests adding more details and a flow chart to clarify the process, which would greatly benefit the readers\\' understanding. Additionally, the comment asks for runtime information for solving the entropic regularized discrete OT problem and the OT sample selection process. These questions and suggestions are clear and actionable, providing the authors with specific areas to address and improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of experiments with continuous tasks despite a discussion on how KG handles them, and the absence of empirical performance comparisons for entropy methods derived in Section 7. The reviewer explicitly asks why these methods are not included in the experiments and how their performance compares to ConBO. These questions provide clear and direct actions for the authors to take, such as conducting experiments with continuous tasks and including empirical performance comparisons. The feedback is specific and actionable, as it guides the authors on exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7 in the appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of experiments with continuous tasks and questions why entropy methods derived in Section 7 are not included in the experiments. The comment further asks how the empirical performance of these methods compares to ConBO, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim that the paper discusses handling continuous tasks in KG but lacks experiments with continuous tasks. It also questions why entropy methods derived in Section 7 are not included in the experiments and how their performance compares to ConBO. While the comment highlights a potential gap in the experimental section, it does not provide specific reasoning or evidence to support the claim that the absence of these experiments is a significant issue. The comment lacks detailed justification or references to substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that while the authors discuss handling continuous tasks in KG, there are no experiments conducted with continuous tasks. This feedback highlights a gap in the experimental section that the authors should address to provide a more comprehensive evaluation of their approach. Second, the comment notes that entropy methods derived in Section 7 are not included in the experiments and questions how their performance compares to ConBO. This prompts the authors to consider including these methods in their experiments and to provide a comparison with ConBO, which could enhance the paper\\'s empirical validation. The comment is clear and actionable, offering specific directions for improvement that can significantly enhance the paper\\'s depth and rigor. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density and suggests providing AUC results for comparisons in breast cancer detection. While the comment implies that the authors should clarify their methodology and provide additional results, it does not explicitly instruct them to do so. The action is implicit but concrete, as it suggests specific metrics to include and how to improve the presentation of results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of precision, recall, and F1-score for a 4-class classification of breast density, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of AUC results for comparisons in breast cancer detection, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density, suggesting that providing AUC results for comparisons might be more informative. While the comment highlights a potential gap in the presentation of results, it does not provide specific examples or references to support the claim that AUC results are more informative. The suggestion is logical but lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it raises a specific question about the calculation of precision, recall, and F1-score for a 4-class classification of breast density. It also suggests providing AUC results for comparisons in breast cancer detection, which is a common practice in the field. This feedback is actionable and provides clear guidance on how the authors can enhance the presentation of their results, making it easier for readers to understand and compare the model\\'s performance. However, the comment could be more helpful if it included additional suggestions or examples of how to present the AUC results effectively. Overall, the comment is mostly helpful, as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the novelty of the proposed modification to the transformer, suggesting that it does not bring significant insight into machine learning. It also questions the significance of the improvement brought by the self-cross attention in the ablation study. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these concerns or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the contribution of the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the novelty of the transformer modification, the limited improvement brought by the self-cross attention, and the main improvements coming from using a na\u00efve transformer. This provides clear guidance on what aspects of the paper need attention and improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the modification to the transformer, specifically the cross-layer approach, does not bring significant insight into machine learning and that the improvements from the self-cross attention are limited. The reviewer supports this claim by referencing the ablation study (table 4 and 5) and noting that the self-cross attention brings only a minor improvement (<1%). This provides a logical basis for the claim, as it relies on specific data from the study to support the argument. However, the comment could be strengthened by providing more detailed analysis or examples of how the modification impacts machine learning insights. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment critiques the novelty of the proposed modification to the transformer, suggesting that it does not bring significant insight into machine learning. It also questions the significance of the improvement brought by the self-cross attention in the ablation study, suggesting that the main improvements come from using a na\u00efve transformer rather than the proposed modification. While the comment identifies potential weaknesses in the paper's contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The feedback is somewhat helpful as it points out areas for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, in addition to the current focus on sentence similarity tasks and open domain QA tasks. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional experiments should be conducted to broaden the scope of their evaluation. The comment is explicit and provides detailed guidance on how to implement the suggested improvements, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments and the types of tasks evaluated, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limitation of the experiments to sentence similarity tasks and open domain QA tasks and suggests conducting experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited because they only cover sentence similarity tasks and open domain QA tasks, suggesting that there are many other tasks involving sentence pairs. The reviewer supports this claim by providing specific examples of sentence inference tasks like MNLI and RTE, which are common in the NLP field. This detailed reference to specific tasks and their relevance to the paper's scope makes the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, noting that the authors have only evaluated their model on sentence similarity tasks and open domain QA tasks. It suggests that there are many other tasks involving sentence pairs, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a clear and actionable suggestion for the authors to conduct experiments on more types of sentence pair tasks, offering a concrete way to broaden the evaluation of their model. This feedback is mostly helpful as it directs the authors to expand their experimental scope, which could significantly enhance the comprehensiveness and impact of their work. However, it could be more helpful if it included specific guidance on how to incorporate these additional tasks or discussed the potential benefits of doing so. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include the prompt in the appendix or supplement, if it was not already included. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to identify the part of the paper being addressed. It also specifies the issue by suggesting that the prompt should be included in the appendix or supplement, if it was not already there. Additionally, it provides minor comments about the abstract and Figure 2, which are specific in nature. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the prompt should be included in the appendix or supplement, but it does not provide any reasoning or evidence to support why this is necessary or beneficial. The comment lacks justification or explanation, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the inclusion of the prompt in the appendix or supplement. This feedback is clear and directly addresses a potential issue with the paper\\'s presentation, guiding the authors on how to improve the accessibility and completeness of their work. Additionally, the comment includes minor feedback on the abstract and Figure 2, which are helpful but not as critical as the prompt suggestion. Overall, the comment is mostly helpful as it offers clear guidance on how to enhance the draft, but it could be more comprehensive with additional suggestions for the minor comments. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim in the introduction regarding the need for tuning a free parameter. It suggests that the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to clarify the claim. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to resolve the concern. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the introduction regarding the need for tuning a free parameter. It provides a critique by suggesting that the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This makes the comment specific, as it clearly identifies the issue with the claim and provides a rationale for why it might be considered a hyperparameter. However, the comment does not explicitly mention which part of the introduction this claim is made, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the claim that \"these shape constraints do not require tuning a free parameter\" by suggesting that the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This claim is somewhat verifiable as it provides a logical reasoning that the choice of constraints could be considered a hyperparameter, but it lacks specific examples or references to support the argument fully. The authors would need to further explore and substantiate this reasoning themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim made in the introduction regarding the need for tuning a free parameter. It points out that while the claim is technically true, the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be seen as a hyperparameter that requires selection or tuning. This feedback is somewhat helpful as it highlights a potential inconsistency or oversight in the paper\\'s claims. However, it lacks specific suggestions or guidance on how the authors might address this issue or clarify their claims. To be more helpful, the comment could include recommendations on how to rephrase or substantiate the claim, or suggest ways to demonstrate that these choices are not hyperparameters. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the convergence proof as trivial, suggesting that the assumptions and modifications lead to straightforward adaptations of previous theorems. However, it does not provide specific guidance on how the authors could address this issue or improve the rigor of the proof. The comment lacks actionable details, such as suggesting ways to enhance the proof or recommending additional analyses to strengthen the novelty and rigor. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the convergence proof, explaining that it appears trivial due to the assumptions and modifications leading to straightforward adaptations of previous theorems. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the convergence proof is trivial due to the assumptions and modifications leading to straightforward adaptations of previous theorems. The reviewer provides a logical reasoning by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., which results in a clear covariance matrix for $Z$ as $A^\\top A / np$. This explanation is supported by a specific reference to Modification 1 in Appendix C, which further substantiates the claim. However, the comment could be strengthened by providing more detailed examples or references to similar proofs in the literature. Despite this, the claim is mostly verifiable due to the logical reasoning and specific references provided, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the convergence proof, suggesting that it appears trivial due to the assumptions and modifications leading to straightforward adaptations of previous theorems. It points out that the paper claims $Z$ is non-i.i.d., but Assumption 4.1 indicates that $X$ is i.i.d., resulting in a clear covariance matrix for $Z$. This feedback is valuable as it highlights a potential weakness in the theoretical foundation of the paper. However, the comment could be more helpful if it provided suggestions on how to enhance the rigor or novelty of the proof. While it offers insight into a critical area needing improvement, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a conflict between two statements in the paper regarding the performance of the multi-env model. It explicitly asks the authors to clarify these conflicting statements. This request is direct and provides a clear action for the authors to take, which is to resolve the inconsistency in their claims. The comment is specific and provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the statements about the multi-env model\\'s performance, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of conflicting statements regarding the performance of the multi-env model and asks for clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a potential contradiction in the paper regarding the performance of the multi-env model. It highlights that the model is stated to have an inevitable performance loss and also to outperform the single-env model due to knowledge sharing. This observation is based on the factual statements made in the paper, which are presented as conflicting. However, the comment does not provide additional reasoning or evidence to support why these statements are contradictory or how they could be resolved. The lack of detailed explanation or examples makes it challenging for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it highlights an issue but lacks sufficient support or guidance for the authors to act upon.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential contradiction in the paper regarding the performance of the multi-env model. It points out that the model is stated to have an inevitable performance loss and also to outperform the single-env model due to knowledge sharing. This feedback is valuable as it highlights a critical inconsistency that the authors need to address to ensure clarity and accuracy in their claims. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this contradiction or clarify the statements. While it directs the authors to a significant issue, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper, noting that while it aims to design fast label aggregation algorithms for a streaming setting, it does not adequately motivate the applications where such algorithms are needed. The comment suggests that for the paper to be useful, the problem should be well motivated. However, it does not provide specific guidance on how the authors should motivate the applications or what aspects should be addressed to improve the motivation. The action is implicit and vague, as the authors are left to infer that they need to add a section or discussion on motivating the applications, but without concrete steps or examples, the comment remains somewhat vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation and applicability of the paper, specifically questioning the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the stated objective. However, the comment does not specify which part of the paper should include this motivation or where the datasets are discussed, making it weakly grounded. The comment is specific in its critique of the lack of motivation and the mismatch between the stated objective and the empirical analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting, despite stating this as its objective. The comment highlights a discrepancy between the stated objective and the empirical analysis, which uses static datasets. This claim is somewhat verifiable as it logically points out a gap in the paper\\'s motivation and relevance. However, it lacks specific examples or references to support the claim fully, such as suggesting potential applications or studies that could provide motivation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, noting that while it aims to design fast label aggregation algorithms for a streaming setting, it does not adequately motivate the applications where such algorithms are needed. The comment highlights that the datasets used in the empirical analysis are static, which contradicts the stated objective. This feedback is valuable as it points out a fundamental issue that the authors need to address to make their work more relevant and impactful. However, the comment could be more helpful if it provided specific suggestions on how to motivate the applications or examples of potential applications that could be considered. Overall, the comment is somewhat helpful as it directs the authors to a significant area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the scope of the study, suggesting that the work focuses on injecting a CoT-based approach into small-scale Language Models. It implies that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address the issue or what specific baselines should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the scope and content of their study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scope of the study, suggesting that it focuses on injecting a CoT-based approach into small-scale Language Models. It implies that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. While the comment does not explicitly mention specific sections or tables, the authors can infer that it relates to the discussion or results sections where these tables are likely located. The comment is specific in detailing what is missing and what needs to be addressed, but it is weakly grounded because it does not explicitly mention the sections or tables. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach into small-scale Language Models. It further implies that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. While the comment provides some context and suggests a potential gap in the study, it lacks specific examples or references to support the claim about the missing baselines. The reasoning is somewhat verifiable, as it highlights a potential oversight but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoT-based approach into small-scale Language Models. It suggests that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Table 2 and 3. This feedback is somewhat helpful as it points out a gap in the study that could be addressed to improve its comprehensiveness. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these missing baselines or why they are important for the study. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the mentioned fact in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this connection should be explored further, how it should be addressed, or what specific changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the connection between the mentioned fact about tensor decomposition and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what aspect of the introduction needs further clarification or connection. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the connection between a statement in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the connection between a statement in the introduction regarding tensor decomposition and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. While it identifies a potential gap in the explanation or connection between these two aspects, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or specific advice, leaving the authors with only a vague sense of what needs to be clarified or expanded upon. Therefore, it is rated as barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the method, specifically noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions how the authors might scale up without compromising performance. While the comment identifies a potential issue and suggests a possible solution, it does not provide explicit instructions or detailed guidance on how to address the scalability problem. The authors are left to infer that they should consider scaling strategies, but the comment lacks concrete steps or examples. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of scalability and performance degradation with an increase in the maximum number of identities. The comment further suggests a potential solution by recommending a preset capacity and questions how scalability might be achieved without compromising performance. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the method, specifically noting that performance worsens with an increase in the maximum number of identities. The reviewer suggests that the capacity should be preset to a small number, such as 10, and questions how the authors might scale up without compromising performance. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about performance degradation. The suggestion to preset the capacity is based on the reviewer\\'s observation, but it does not provide detailed evidence or data to substantiate the claim. Therefore, the comment is somewhat verifiable, as it requires additional information or evidence to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the scalability of the method, specifically noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions how the authors might scale up without compromising performance. This feedback is clear and actionable, as it highlights a potential limitation of the method and prompts the authors to consider scalability strategies. However, the comment could be more helpful by offering specific suggestions or examples of how to address this issue. Overall, the comment is mostly helpful, as it provides valuable insights into a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claim and the content of their work, specifically noting that the approach does not appear to be NLP-specific. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending ways to make the approach more NLP-specific or suggesting additional content that could be included to support the claim. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim that the paper is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment also lacks specificity as it does not detail what aspects of the approach are not NLP-specific or how the authors could address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the claim that the paper is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that the approach is not NLP-specific. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to what constitutes an NLP-specific approach, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some initial reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the claim that the paper is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that the approach is not NLP-specific. However, the comment does not provide specific feedback or suggestions on how the authors could address this issue or improve their work. It lacks actionable guidance or detailed critique, leaving the authors without a clear path for improvement. As a result, the comment is not particularly helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment identifies a gap in the justification and discussion of the research, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide a justification for the new method and discuss the limitations of existing methods. However, the comment lacks concrete suggestions on how to do so, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to existing methods that could be applied, making it difficult for the authors to understand the basis of the claim. The absence of detailed reasoning or evidence renders the claim borderline verifiable, as it provides a general critique without concrete support. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is somewhat helpful as it highlights an area where the authors need to provide a clearer rationale for their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or what aspects of the existing methods should be considered. To be more helpful, the comment could include examples of existing methods or suggest ways to justify the need for a new approach. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved in some places, providing two specific examples. It points out that the definition of \"relevant\" auxiliary model weights in Definition 2.1 is difficult to interpret. This feedback is explicit and provides concrete examples of where the writing needs improvement, giving the authors clear guidance on how to enhance the clarity of their draft. The action is direct and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the difficulty in interpreting the definition of \"relevant\" auxiliary model weights, providing clear guidance on what needs to be clarified or improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could be improved, specifically mentioning that the definition of \"relevant\" auxiliary model weights in Definition 2.1 is difficult to interpret. However, the comment does not provide any specific reasoning or examples to support why the definition is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the writing could be improved, providing two examples: the definition of \"relevant\" auxiliary model weights in Definition 2.1 and the difficulty in interpreting the current definition. This feedback is actionable as it points out precise areas where the authors can enhance the clarity and readability of their manuscript. However, the comment could be more helpful if it offered suggestions on how to clarify these definitions or provided examples of clearer phrasing. Overall, the comment is mostly helpful as it directs the authors to specific sections that need improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the quantitative evaluation results presented in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that Figure 4, which illustrates the comparison of final results with a single data sample, is more convincing. The reviewer implies that a quantitative comparison on the final outputs would be more convincing and asks if such a comparison is possible. While the comment identifies a specific issue and suggests a potential improvement, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include a quantitative comparison on the final outputs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the quantitative evaluation results in Figure 3 only reflect middle outputs, whereas Figure 4 illustrates the comparison of final results with a single data sample. The comment further suggests that the current evaluations are not convincing enough to confirm ModelAngelo\\'s superiority and asks for a quantitative comparison on the final outputs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, whereas Figure 4 illustrates the comparison of final results with a single data sample. The reviewer suggests that the current evaluations are not convincing enough to confirm ModelAngelo\\'s superiority over competitors. The comment implies that a quantitative comparison on the final outputs would be more convincing. However, the claim lacks specific examples or detailed reasoning to support why the current evaluations are insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results presented in the paper, noting that they only reflect middle outputs rather than the final outputs. It suggests that Figure 4, which illustrates the comparison of final results with a single data sample, is more convincing. The comment implies that the current evaluations are not sufficient to confirm ModelAngelo\\'s superiority over competitors. The reviewer provides a clear and actionable suggestion by asking for a quantitative comparison on the final outputs. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete step to enhance the credibility of their findings. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific metrics to use. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal descriptions of procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would help clarify the work. Additionally, it recommends including error bars and/or p-values for statistical inferences. While the comment provides explicit actions, such as adding more details and including statistical information, it lacks specific guidance on how to implement these changes. The authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific issues with the explanations, procedures, and figures in the paper, such as the lack of detailed explanations, minimal descriptions of procedures, and confusing figures like \"sample count\" in fig. 2. It also provides specific suggestions for improvement, such as adding more details to the paper and/or supplementary information, and including error bars and/or p-values for statistical inferences. This level of detail and specificity allows the authors to accurately identify the parts of the paper that need attention and how to address them, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, particularly in relation to simulation or experimental evidence. The reviewer also mentions that some figures are confusing, such as the lack of clarity regarding \"sample count\" in fig. 2. The comment suggests that adding more details to the paper and/or supplementary information would help clarify the work. While the comment identifies specific issues, such as the lack of detailed explanations and confusing figures, it does not provide specific examples or references to support these claims. The suggestion to include error bars and p-values for statistical inferences is a logical recommendation but lacks detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, specifically the lack of detailed explanations, minimal descriptions of procedures, and confusing figures. It highlights the need for more detailed information, both in the main text and supplementary materials, to better understand the simulations and their results. Additionally, the comment suggests including error bars and p-values for statistical inferences, which is a standard practice in scientific research. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, it could be more helpful if it offered examples or guidance on how to enhance the explanations or figures. Overall, the comment is mostly helpful as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback provides a clear and explicit action for the authors to take, which is to include specific settings that align with prior work. The comment also explains the potential benefit of this addition, which is to provide a comprehensive review of the advances in this area. The action is concrete and directly stated, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include settings for prior work, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This claim is somewhat verifiable as it provides a logical suggestion for improvement, but it lacks specific examples or references to prior work that would substantiate the need for this explicit comparison. The authors would need to infer the importance of this suggestion based on the general reasoning provided, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by aligning it with existing benchmarks or standards. By doing so, the paper could offer a comprehensive review of the advances in this area, which would benefit the broader research community. However, the comment could be more helpful if it included specific examples or guidance on how to implement these suggestions. Overall, the feedback is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the general applicability of the biases and prediction shift examples presented in the paper. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to clarify the generalizability of these situations. The comment implies that the authors should provide more information or analysis to address this concern, but it does not offer explicit instructions or concrete suggestions. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the general applicability of the biases and prediction shift examples presented. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the paper regarding the general applicability of biases and prediction shift examples. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks references or evidence to substantiate the assertion that the situations are not well-documented or understood. This makes the claim somewhat verifiable, as it highlights an area of concern but does not fully support it with detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the general applicability of the biases and prediction shift examples presented in the paper. It points out that while specific examples are provided, it is unclear how general these situations are. This feedback highlights an important area for improvement, as understanding the generalizability of findings is crucial for the paper\\'s impact. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing additional experiments or analyses to clarify the generalizability. While it offers some insight into a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.1 for 3D Gaussian generation appears to follow the previous work, Luciddreamer, and asks the authors to clarify whether there is any additional novel effort in this part. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide guidance on how to clarify or improve this section. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or justification for the novelty of their approach. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether there is any additional novel effort beyond following the previous work, Luciddreamer, in this section. This provides clear guidance on what the authors need to address regarding the novelty of their approach. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the section on 3D Gaussian generation in Section 3.1 is novel, suggesting that it merely follows the previous work, Luciddreamer. However, the comment does not provide any specific reasoning or evidence to support this claim, such as detailed comparisons or examples of similarities. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with Section 3.1, suggesting that it may not contain any novel contributions beyond following the previous work, Luciddreamer. This feedback is somewhat helpful as it prompts the authors to clarify or justify the novelty of their approach in this section. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance the originality of their work. To be more helpful, the comment could include suggestions for potential novel contributions or improvements that could be made in this section. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with MMD DRO, including the lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for simple kernel ridge regression problems. It also mentions the assumption that the loss \\\\(\\\\ell_f\\\\) belongs to the RKHS, which is already noted by the authors. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their work. The feedback lacks actionable details, such as recommending ways to enhance the tractability or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the MMD DRO method, particularly its lack of a tractable exact equivalent reformulation and the crudeness of the upper bound provided in Theorem 3.1. It also mentions the need for further approximation, even for simple kernel ridge regression problems, and the assumption that the loss \\\\(\\\\ell_f\\\\) belongs to the RKHS. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the theoretical analysis and results discussed in the paper. The comment is specific in detailing the issues with the method and its assumptions, but it lacks explicit grounding as it does not refer to a specific section or part of the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that MMD DRO lacks a tractable exact equivalent reformulation, which is considered a severe drawback. It provides specific reasoning by pointing out the crudeness of the upper bound in Theorem 3.1 and the need for further approximation, even for simple kernel ridge regression problems. Additionally, it mentions the assumption that the loss \\\\(\\\\ell_f\\\\) belongs to the RKHS, which is already noted by the authors. This detailed critique, supported by logical reasoning and specific references to the paper\\'s content, makes the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the critique fully. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the MMD DRO method, specifically its lack of a tractable exact equivalent reformulation. It highlights the crudeness of the upper bound provided in Theorem 3.1 and the need for further approximation, even for simple kernel ridge regression problems. Additionally, it points out the restrictive assumption that the loss \\\\(\\\\ell_f\\\\) belongs to the RKHS, which is already noted by the authors. While the comment effectively identifies key weaknesses and limitations, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it highlights important areas for improvement, but it could be more beneficial with additional actionable advice or alternative approaches. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the Appendix H section should be reorganized because it is difficult to follow. This provides a clear and direct action for the authors to take, which is to restructure the section for better clarity. The comment is specific in its request, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Appendix H,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. However, the comment lacks specificity as it does not detail what aspects of the section are difficult to follow or how it should be reorganized. Without specific guidance, the authors may struggle to determine exactly what changes are needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the Appendix H section is difficult to follow and suggests it should be reorganized. However, the comment does not provide any specific reasoning or examples to support why the section is challenging to follow or how it could be improved through reorganization. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow and suggesting that it should be reorganized. This feedback is somewhat helpful as it points out a clear area for improvement, but it lacks detailed guidance or suggestions on how to reorganize the section for better clarity. The authors are informed of a problem but are not provided with actionable steps to address it, limiting the comment\\'s utility. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern that the paper is not written to be reproducible, despite the inclusion of pseudocode in the supplementary material. It suggests that more details, such as those related to the RNN implementation (e.g., number of units), are needed to facilitate reproduction. While the comment identifies specific areas that require additional detail, it does not provide explicit instructions on how to address these issues or what specific information should be included. The action is implicit and somewhat vague, as the authors know they need to provide more details but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, such as the lack of details about the RNN implementation (like the number of units) and other technical details. This provides clear guidance on what needs to be addressed to improve the reproducibility of the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not written to be reproducible, despite the inclusion of pseudocode in the supplementary material. The reviewer provides a specific example by mentioning the lack of details about the RNN implementation, such as the number of units. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or examples where these details are missing, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically that it is not written to be reproducible, despite the inclusion of pseudocode in the supplementary material. It highlights the need for more detailed information, such as specifics about the RNN implementation, to facilitate reproduction. This feedback is clear and actionable, as it provides a specific area for improvement and suggests what additional details are required. However, the comment could be more helpful if it offered specific examples or guidance on how to present these details effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 would be strengthened by including error bars and conducting more random trials to reduce potential random fluctuations in the results. While the comment provides a clear action\u2014adding error bars and increasing the number of random trials\u2014it does not specify how many trials should be conducted or what specific data should be included in the error bars. This leaves some ambiguity in execution, making the comment somewhat actionable. The authors know what needs to be done but may need to determine the specifics themselves.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding error bars and conducting more random trials to improve the figure\\'s strength. This provides clear guidance on what needs to be addressed to enhance the figure\\'s presentation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 would be strengthened by including error bars and conducting more random trials to reduce potential random fluctuations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support why these changes would enhance the figure\\'s strength. The reasoning is based on common practices in data presentation, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that Figure 1 would be strengthened by including error bars and conducting more random trials. This recommendation is clear and offers a concrete way for the authors to enhance the presentation and credibility of their results. By addressing these suggestions, the authors can improve the robustness and clarity of their findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide a brief introduction to energy models in the related work section. It also points out that Figure 1 lacks labeling for the different learning rates in the left graph and different steps in the right graph. The comment provides explicit actions for the authors to take, which are to introduce energy models in the related work section and to label the points in Figure 1. These instructions are clear and concrete, giving the authors specific tasks to address. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with Figure 1, which is the lack of labeling for different learning rates in the left graph and different steps in the right graph. Additionally, it suggests providing a brief introduction to energy models in the related work section. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide a brief introduction to energy models in the related work section and notes that Figure 1 lacks labeling for different learning rates and steps. The comment does not make any subjective claims or judgments but rather points out specific areas for improvement. It is a request for clarification and additional information, which does not require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors include a brief introduction to energy models in the related work section, which is a clear and actionable recommendation that can help situate the paper within the broader context of the field. Second, it points out that Figure 1 lacks labeling for different learning rates and steps, which is a specific issue that the authors can address to improve the clarity of their presentation. While the comment is helpful in identifying areas for improvement, it could be more comprehensive by offering additional guidance or examples on how to introduce energy models or label the figure effectively. Overall, the feedback is mostly helpful as it provides actionable suggestions for enhancing the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first paragraph of the Introduction is too general and not relevant to the paper\\'s focus on detecting drift types and magnitude. It implies that this paragraph should be revised or removed to better align with the paper\\'s content. However, the comment does not provide explicit instructions on how to revise or what specific information should be added to make it more relevant. The action is implicit and somewhat vague, as the authors are left to infer that they should restructure or remove the paragraph, but without concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paragraph, noting that it is too general and not relevant to the paper\\'s focus on detecting drift types and magnitude. The comment provides a clear suggestion that this paragraph should be revised or removed to improve the paper\\'s relevance and value to readers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is too general and irrelevant to the paper\\'s focus on detecting drift types and magnitude. However, the comment does not provide specific examples or detailed reasoning to support why the DNN-related introduction is not central to the paper. Without concrete evidence or references, the claim lacks sufficient justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is too general and irrelevant to the paper\\'s focus on detecting drift types and magnitude. This feedback is valuable as it highlights a potential disconnect between the introduction and the paper\\'s core content, suggesting that the authors may need to restructure or revise this section to better align with the paper\\'s focus. However, the comment could be more helpful if it provided suggestions on how to restructure the introduction or what specific information should be included to better integrate with the paper\\'s content. Overall, the comment is somewhat helpful as it points out a clear area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should make it easier to distinguish between the different curves in Figure 2. It provides specific actions, such as using styles like dashed lines or adding color, to improve the figure\\'s clarity. The comment is clear and provides concrete guidance on how to implement the suggested changes, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using styles (e.g., dashed lines) or adding color to make it easier to distinguish between the different curves in the figure. This provides clear guidance on how to improve the figure\\'s clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles or adding color to improve clarity. This is a request for clarification or improvement, not a claim or opinion that requires verification. It is a factual observation about the figure\\'s presentation and a suggestion for enhancement, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting improvements to Figure 2 to enhance its clarity. It recommends using styles, such as dashed lines, or adding color to distinguish between the different curves. This guidance is clear and directly addresses a visual issue that could impact the reader\\'s understanding of the figure. By offering concrete suggestions, the comment empowers the authors to make a straightforward improvement to their draft, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors tone down their claims in the introduction, as they are not consistent with the tasks and models evaluated. It explicitly recommends that the authors do not call the task \"language learning\" but rather describe it as a feedback-driven question-answering task in the form of a dialog. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the claims made in the introduction, specifically questioning the labeling of the task as \"language learning\" when it is evaluated on question answering. It suggests that the task is more accurately described as a feedback-driven question-answering task in the form of a dialog. However, the comment does not specify which part of the introduction contains these claims, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the claims are made, the comment lacks full grounding. It is specific about the issue with the claims but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claims made in the introduction are not consistent with the tasks and models evaluated, specifically questioning the labeling of the task as \"language learning\" when it is evaluated on question answering. The reviewer suggests that the task is more accurately described as a feedback-driven question-answering task in the form of a dialog. While the comment provides a logical reasoning for the discrepancy, it lacks specific examples or references to support the claim fully. The authors would need to make a significant effort to understand and address the critique without additional context or evidence. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the claims made in the introduction, specifically that they do not align with the tasks and models evaluated. It points out the discrepancy between calling the task \"language learning\" and evaluating it on question answering, suggesting that it is more accurately described as a feedback-driven question-answering task in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific direction to revise their introduction to better reflect the nature of their work. By addressing this point, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it offered additional suggestions on how to rephrase the introduction or provided examples of similar tasks. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance on REC and RES in Table 4 is lagging behind more recent models, specifically mentioning GLaMM and UNINEXT. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their performance. The comment lacks actionable guidance, such as recommending specific methods or approaches to enhance performance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT. The comment provides specific examples of performance metrics and references to other works, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance on REC and RES in Table 4 is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by providing specific performance metrics from these models, which serves as a clear reference point for comparison. The inclusion of references to GLaMM and UNINEXT provides a robust basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the model in Table 4, noting that it is behind more recent models in terms of REC and RES metrics. It provides examples of models like GLaMM and UNINEXT that achieve better performance, which is a clear and actionable piece of feedback. By highlighting these specific comparisons, the comment helps the authors understand the gap in their results and suggests areas for improvement. However, the comment could be more helpful if it offered additional guidance on how to address these performance issues or suggested specific methods to enhance the model\\'s performance. Overall, the comment is mostly helpful as it provides valuable insights and a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"evidence\" may be too strong in the context of the statement and recommends using a more appropriate term like \"Fig.\" However, it does not provide any guidance on how to determine which term is more appropriate or how to implement this change. The action is explicit in suggesting a change in terminology, but it lacks concrete details on how to make this adjustment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the term \"evidence\" may be too strong and recommending a more appropriate term like \"Fig.\" This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"evidence\" may be too strong in the context of the statement and recommends using a more appropriate term like \"Fig.\" However, the comment does not provide any justification or reasoning for why the term \"evidence\" is inappropriate or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the term \"evidence\" may be too strong in the context of the statement and recommends using a more appropriate term like \"Fig.\" This feedback is specific and actionable, providing the authors with a clear suggestion to modify their wording to improve the accuracy and clarity of their statement. However, the comment could be more helpful if it explained why the term \"evidence\" is inappropriate or how it might be misleading. Despite this, the feedback is mostly helpful as it guides the authors toward a precise and accurate phrasing. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that a full-page explanation of the implementation of kernels with OpenAI\\'s Triton instead of CUDA is unnecessary because of well-known engineering improvements. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific information should be included, if any. The comment lacks actionable details, leaving the authors uncertain about how to respond to this feedback. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the implementation of kernels with OpenAI\\'s Triton instead of CUDA, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that a full-page explanation is unnecessary due to well-known engineering improvements. This provides clear guidance on what aspect of the explanation is considered unnecessary. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a full-page explanation of the implementation of kernels with OpenAI\\'s Triton instead of CUDA is unnecessary due to well-known engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these improvements are well-known or why a full-page explanation is unnecessary. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a full-page explanation of the implementation of kernels with OpenAI\\'s Triton instead of CUDA is unnecessary due to well-known engineering improvements. While it identifies a potential area of redundancy in the paper, it does not provide any constructive feedback or suggestions on how to improve the draft. The comment lacks actionable guidance or specific advice on how the authors might enhance their explanation or address the issue more effectively. As a result, the feedback is not particularly helpful for the authors in terms of improving their draft, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the analysis of neural networks, suggesting that it contributes less due to the trivial extension from linear models to wide fully-connected neural networks. It also mentions that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how the authors might improve their analysis or what specific changes could be made to enhance the contribution of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analysis of neural networks contributes less due to the trivial extension from linear models to wide fully-connected neural networks, and that the work bypasses the core problem of overparametrized neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of neural networks contributes less due to the trivial extension from linear models to wide fully-connected neural networks. It supports this claim by referencing the NTK theorem and stating that the work bypasses the core problem of overparametrized neural networks. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some context, the absence of explicit references or detailed explanations makes the claim somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the analysis of neural networks, suggesting that it contributes less due to the trivial extension from linear models to wide fully-connected neural networks. It points out that the work bypasses the core problem of overparametrized neural networks and only considers the easier case of wide fully-connected neural networks. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This implies that the authors should include results with these larger models to provide a more comprehensive evaluation. However, the comment does not explicitly instruct the authors to do so or provide guidance on how to incorporate these results. The action is implicit and somewhat vague, as the authors need to infer that they should include additional results and may not be entirely sure of the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of results with larger models like ResNet101/152, despite good performance with ResNet50/34/18 on imageNet classification. However, it does not specify which part of the paper this observation is based on, such as a particular section or table where results are presented. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in pointing out the absence of results with larger models, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This claim is somewhat verifiable as it highlights a gap in the experimental results presented in the paper. However, it lacks specific reasoning or evidence to support why the inclusion of results with larger models would be beneficial or necessary. The comment does not provide a rationale for why these larger models are important or how their inclusion would impact the overall evaluation. Therefore, the authors may find it challenging to understand the significance of this feedback without further elaboration. As a result, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment points out a gap in the experimental results, specifically noting the absence of results with larger models like ResNet101/152, despite good performance with ResNet50/34/18 on imageNet classification. This feedback is somewhat helpful as it identifies an area where the paper could be improved by providing additional results with larger models. However, it lacks specific guidance on how to incorporate these results or why they are important, which limits its usefulness. The authors are informed of a potential enhancement but are not given detailed direction on how to implement it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it suggests that the authors should consider the multi-fidelity framework and sequential design for learning quantities of interest, referencing a specific paper for further exploration. This is an explicit suggestion with a concrete reference, making it highly actionable. Second, it points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" suggesting that it should be clarified or corrected. This part of the comment is more implicit but still actionable, as it provides a clear direction for improvement. Overall, the comment offers specific and actionable guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions the \"multi-fidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance),\" which provides some context. However, it does not specify which part of the paper this framework is discussed in, making it weakly grounded. The comment is specific in pointing out the inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes two claims. The first claim suggests that the multi-fidelity framework and sequential design for learning quantities of interest are relevant to the paper, referencing a specific paper for further exploration. This claim is mostly verifiable as it provides a specific reference to support the suggestion. The second claim points out an inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which is a factual observation requiring no verification. Overall, the first claim is mostly verifiable due to the reference provided, while the second is factual, making the overall comment mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors consider the multi-fidelity framework and sequential design for learning quantities of interest, referencing a specific paper for further exploration. This is a valuable suggestion that could enhance the paper\\'s relevance and depth. Second, it points out an inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which could lead to confusion for readers. This feedback is clear and actionable, guiding the authors to clarify their language for improved clarity. Overall, the comment is mostly helpful as it offers specific suggestions and identifies areas for improvement, but it could be more comprehensive by providing additional guidance on how to integrate the suggested framework or clarify the language issue. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare their results on the official COOC leader board on the blind test set, referencing a specific URL and mentioning that several other approaches have improved since the paper was published. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable as it specifies the action and provides a clear direction for implementation.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the need to compare results on the official COOC leader board on the blind test set, providing a specific URL for reference. It also specifies the issue by suggesting that the paper should compare to related work on the official test set and mentions specific examples of approaches that have won the challenge and been evaluated on the blind challenge set. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s comparison to related work is limited to unofficial test sets, suggesting that the final results should be compared on the official COOC leader board on the blind test set. The reviewer supports this claim by referencing specific examples of approaches that have won the challenge and been evaluated on the blind challenge set, as well as mentioning that several other approaches have improved since the paper was published. This provides a robust basis for the claim, making it fully verifiable. The inclusion of specific references and examples from the COOC leader board and the mention of other approaches that have improved since the paper\\'s publication offer a clear and comprehensive justification for the claim, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback regarding the comparison of results in the captioning experiment. It highlights a critical issue that the paper only compares to related work on unofficial test sets or dev sets, rather than the official COOC leader board on the blind test set. The reviewer suggests that the authors should compare their results on this official test set, referencing a specific URL and mentioning that several approaches have improved since the paper was published. This feedback is clear and constructive, offering a direct path for the authors to enhance the credibility and relevance of their work by aligning it with the official evaluation standards. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE, raising concerns about their validity. This feedback provides a clear and direct action for the authors to address, which is to investigate and clarify the reliability of their experimental results, especially in Table 1. The comment is explicit and provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by pointing out that the MSE is significantly smaller than the MAE, raising concerns about the validity of the experimental results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are unreliable, specifically pointing out that the MSE is significantly smaller than the MAE in Table 1. This claim is somewhat verifiable as it highlights a potential issue with the experimental results, but it lacks detailed reasoning or evidence to fully substantiate the claim. The comment does not provide specific examples or references to support why the discrepancy between MSE and MAE is concerning, making it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the validity of the results. This feedback is clear and actionable, as it directs the authors to investigate and address the discrepancy between these metrics, which could significantly impact the interpretation of their findings. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or offered insights into potential causes for the discrepancy. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance the reliability of their experimental results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that there is limited novelty in the methodology, describing the proposed meta algorithm as a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or enhance the novelty of their work. The comment lacks actionable details, such as recommending ways to innovate or differentiate the methodology from existing methods. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the methodology, stating that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on which existing methods are being referred to or how the proposed algorithm lacks novelty. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is \"not much novelty in the methodology\" and describes the proposed meta algorithm as a \"direct extension of existing methods.\" However, the comment does not provide specific examples or references to existing methods that the proposed algorithm is based on, nor does it elaborate on how the extension is direct. This lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a perceived lack of novelty in the methodology, stating that the proposed meta algorithm is a direct extension of existing methods. While this feedback identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify the meaning of \"wrong\" in the context of the paper, suggesting that they should define what constitutes a good, bad, or wrong explanation before using these concepts. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be clarified. The comment is concrete, as it gives a specific term (\"wrong\") and a clear direction for improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to clarify the meaning of \"wrong\" and the concepts of good, bad, and wrong explanations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation before using these concepts. However, the comment does not provide any specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the claim is not verifiable, as it lacks the necessary evidence or explanation to guide the authors in addressing the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by clarifying the meaning of \"wrong\" in the context of the paper. It suggests that the authors should define what constitutes a good, bad, or wrong explanation before using these concepts, which would enhance the clarity and precision of the paper. This feedback is clear and actionable, providing the authors with a direct suggestion on how to improve their draft. However, it could be more helpful if it offered examples or further guidance on how to address this issue. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not provided sufficient information about the types of activities captured in the datasets and their importance in smart homes, particularly in terms of occupant comfort and energy efficiency. However, it does not offer explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific aspects of the activities should be covered or how the authors might enhance their discussion. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific area for improvement regarding the coverage of activities captured in the datasets and their importance in smart homes, particularly in terms of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where this information should be included. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the need for more information on activities and their importance, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not sufficiently covered the types of activities captured in the datasets and their importance in smart homes, particularly in terms of occupant comfort and energy efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a gap in the paper regarding the coverage of activities captured in the datasets and their importance in smart homes, particularly in terms of occupant comfort and energy efficiency. This feedback highlights an area where the authors could provide more depth and context to their work, which is valuable for improving the comprehensiveness of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending particular aspects of activities to focus on or how to integrate this information into the paper. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue in Section 5.3, where a generator equipped with a standard R-GCN as a discriminator tends to collapse after a certain number of iterations. The reviewer suggests that the reason behind this collapse is crucial to understanding the mechanism by which the proposed method differs from previous ones. The comment implies that the authors should include an explanation of why the proposed module prevents the generator from collapsing. While the action is implicit, it is concrete because it clearly identifies the issue and the need for an explanation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the generator collapsing with a standard R-GCN as a discriminator and suggests that the reason behind this collapse is essential for understanding the proposed method\\'s mechanism. The comment further specifies that this explanation is missing in the current submission and requests an explanation of why the proposed module prevents the generator from collapsing. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific observation regarding the behavior of a generator with a standard R-GCN as a discriminator, noting that it tends to collapse after a certain number of iterations. The reviewer suggests that understanding the reason behind this collapse is crucial for demonstrating the mechanism by which the proposed method differs from previous ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the proposed module prevents the generator from collapsing. This lack of detailed justification or examples makes the claim somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper regarding the behavior of a generator with a standard R-GCN as a discriminator, noting that it tends to collapse after a certain number of iterations. The reviewer suggests that understanding the reason behind this collapse is crucial for demonstrating the mechanism by which the proposed method differs from previous ones. The comment highlights a gap in the current submission, specifically the lack of explanation for why the proposed module prevents the generator from collapsing. This feedback is clear and actionable, as it directs the authors to provide an explanation that could significantly enhance the understanding and impact of their work. However, the comment could be more helpful if it offered suggestions on how to approach this explanation or what aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the article, suggesting that its reasoning and writing logic resemble those found in a previous study. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The comment implies that the authors should clarify the novelty of their contributions, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the article, suggesting similarities in reasoning and writing logic to a previous study. However, it does not specify which parts of the article are similar or how they compare to the previous study. This lack of detail makes it difficult for the authors to identify the specific sections that need attention or improvement. Additionally, the comment does not provide specific guidance on how to address these concerns or differentiate the work from the previous study. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the originality of the article, suggesting similarities in reasoning and writing logic to a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The lack of explicit references or detailed reasoning makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of a potential issue but lacks sufficient evidence or detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic resemble those found in a previous study. This is an important point that the authors should address to differentiate their work from existing literature. However, the comment lacks specific guidance or suggestions on how the authors might demonstrate the novelty of their contributions or differentiate their work from the previous study. While it identifies a potential issue, it does not provide actionable feedback or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or improve the clarity. There is no guidance on what specific aspects of the theoretical comparisons need to be clarified or how the authors might enhance their explanation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion where these comparisons are made. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the theoretical comparisons are unclear or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"Theoretical comparisons to adaptive learning of GPRGNN is not clear.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide specific guidance or suggestions on how the authors might improve this aspect of their paper. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to conduct experiments and provide explanations regarding the different queries used in spatio-temporal representation, specifically mentioning spatial, temporal, and summary queries. It also suggests exploring scenarios where only spatial or temporal and summary queries are used. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what experiments and explanations are needed to address the reviewer\\'s concerns. The explicit nature of the instructions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Experiments - Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for experiments and explanations regarding the different queries used in spatio-temporal representation (spatial, temporal, and summary). Additionally, it highlights the importance of this aspect in differentiating the work from VideoChatGPT and other works. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experiments lack components related to the different queries used in spatio-temporal representation, specifically spatial, temporal, and summary queries. The reviewer implies that this is a key difference from other works like VideoChatGPT. However, the comment does not provide specific examples or references to support the claim that these components are missing or necessary for differentiation. The lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks the necessary detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the experimental section regarding the different queries used in spatio-temporal representation. It suggests that the authors should conduct experiments and provide explanations for the spatial, temporal, and summary queries, highlighting the importance of this distinction in differentiating their work from VideoChatGPT and other works. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis. By addressing this point, the authors can improve the comprehensiveness and clarity of their experimental section. However, the comment could be more helpful if it included specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors could mention the potential social impacts of their work, such as increased automation or the risks from dual use of their method. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete details on how to incorporate this information into their draft. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could mention the social impact of increased automation or the risks from the dual use of their method. This provides clear guidance on what the authors could address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of no negative social impact and suggests that they could address potential risks, such as increased automation or dual use. However, the comment does not provide specific examples or references to support the claim that these risks are significant or relevant to the work. The reasoning is somewhat vague and lacks detailed justification, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment addresses the societal impact of the work, specifically questioning the authors\\' claim of no negative social impact. It suggests that the authors could mention potential risks, such as increased automation or dual use, which could have societal implications. While the comment raises an important point, it lacks specific guidance or actionable suggestions on how the authors might address these concerns in their paper. The feedback is somewhat helpful as it prompts the authors to consider the broader societal implications of their work, but it could be more beneficial with additional detail or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the notation used in the paper, specifically the use of \\\\hat v^*_t, which seems unusual given that \\\\hat is typically used for empirical estimates. However, the comment does not provide any explicit guidance or suggestions on how to address this issue. It lacks actionable details, such as recommending alternative notations or explaining why the current notation might be problematic. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L434,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it points out the unusual notation \\\\hat v^*_t and explains that elsewhere, \\\\hat is used for empirical estimates, which is standard practice. This provides clear guidance on what needs to be addressed regarding the notation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the notation \\\\hat v^*_t, suggesting that it seems unusual given the standard use of \\\\hat for empirical estimates. However, the comment does not provide any further explanation or justification for why this notation is problematic or how it deviates from standard practice. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the notation used in the paper, specifically the use of \\\\hat v^*_t, which seems unusual given that \\\\hat is typically used for empirical estimates. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify or revise their notation. However, the comment lacks depth and does not provide suggestions on how to address the issue or why it might be problematic. To be more helpful, the comment could include a recommendation for alternative notation or explain the potential confusion caused by the current notation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to include an explanation of the estimation process and discuss the reliability of the model, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it impacts the model\\'s reliability. The comment lacks detailed explanation or examples that would help the authors understand the importance of this information or how to address the issue. As a result, the claim is unverifiable due to the absence of supporting evidence or reasoning, making it difficult for the authors to act on the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the estimation of the function for the optimal sequence length and the reliability of the model. It points out the lack of information on how this estimation was conducted, which is crucial for understanding the model\\'s reliability. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific information should be included to improve the clarity and robustness of the model. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to modify the phrase \"thousands\" to \"on the subword level\" in line L006. This feedback provides a clear and specific action for the authors to take, ensuring they know exactly what needs to be changed in their draft. The comment is direct and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by pointing out that the term \"thousands\" is not accurate and suggests adding \"on the subword level\" to improve clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"thousands\" is not accurate in the context provided and recommends adding \"on the subword level\" for clarity. However, the comment does not provide any justification or reasoning for why the term \"thousands\" is inaccurate or how the addition of \"on the subword level\" would improve clarity. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the manuscript by pointing out an inaccuracy in the text and offering a correction. By recommending the addition of \"on the subword level,\" the reviewer helps the authors enhance the clarity and accuracy of their writing. This feedback is clear and directly addresses a particular issue, making it highly helpful for the authors to improve their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues that the authors need to address. First, it notes that a number of hyperparameters, such as regularization, are not given, which implies that the authors should include these parameters in their description. Second, it questions why the y value at x=0 is always 0 in the latent path figures and asks for clarification on whether this is normalized or if it was missed in the description. This suggests that the authors should provide a clearer explanation in their description. Third, the reviewer expresses interest in seeing further analysis on the model, possibly using interpolations, which implies that the authors should consider adding such analysis. The comment provides explicit actions and concrete suggestions, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"a number of hyperparameters\" and \"all the latent path figures (e.g., Fig 3),\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details what needs to be addressed, such as providing missing hyperparameters, clarifying the y value at x=0 in the figures, and suggesting further analysis using interpolations. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims: the lack of hyperparameter details, the observation that the y value at x=0 is always 0 in the latent path figures, and the suggestion for further analysis using interpolations. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the reviewer\\'s concerns and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It points out the absence of hyperparameter details, which is crucial for reproducibility and understanding the model\\'s performance. It also questions the rationale behind the y value at x=0 being always 0 in the latent path figures, suggesting that this might be due to normalization or a missed detail in the description. Additionally, the reviewer expresses interest in seeing further analysis using interpolations, which could provide valuable insights into the model\\'s behavior. While the comment highlights important issues, it could be more helpful by offering specific suggestions on how to address these concerns or by providing examples of how to incorporate the suggested analysis. Overall, the feedback is somewhat helpful as it directs the authors to critical areas needing clarification and expansion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, specifically asking if there is an error bound in terms of epsilon. While the comment highlights an area of uncertainty, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should explore or clarify the theoretical effects and error bounds related to epsilon. However, the comment lacks concrete details on how to proceed, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to a specific part of the paper where the core tensors are discussed, allowing the authors to accurately identify the relevant section. It is also specific because it raises a clear question about the theoretical effect of rounding core tensors and asks for an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the theoretical effect of rounding core tensors and the error bound in terms of epsilon. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the theoretical effects of rounding core tensors to smaller ranks with a given accuracy, specifically asking for an error bound in terms of epsilon. This feedback is valuable as it prompts the authors to clarify or provide theoretical justification for their method, which could enhance the rigor and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of similar approaches in the literature. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the test settings mentioned in the paper and the results presented in Table 1. It specifically notes that the table only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer implicitly suggests that the authors should include results for the generative setting as well. While the action is clear and concrete, it is stated implicitly, as the reviewer does not explicitly instruct the authors to add the results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the test settings mentioned in the paper and the results presented in Table 1, and it raises a question about the results on the generative setting. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the omission of results from the generative setting in Table 1, noting that the discriminative setting is known to not apply to real applications. This claim is somewhat verifiable as it highlights a potential gap in the results presented, but it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of including generative setting results based on the reviewer\\'s observation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the presentation of results in the paper, noting that Table 1 only shows results for the discriminative setting, which is known to not apply to real applications. It raises a pertinent question about the results on the generative setting, which is crucial for understanding the applicability of the findings. This feedback is clear and actionable, as it directs the authors to include results for the generative setting, which could significantly enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided suggestions on how to present these additional results or discussed the implications of the generative setting results. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional evidence or examples should be included or how the authors should present this information. The comment is vague and lacks explicit guidance on how to address the issue, leaving the authors uncertain about the specific actions needed to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that more should be done to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. Additionally, the comment lacks specificity regarding what exactly should be done to achieve this conviction or what aspects of the current content are insufficient. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment lacks any supporting evidence, reasoning, or examples to justify why this evidence is necessary or how it would improve the paper. Without such details, the claim remains unverifiable, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it lacks specificity and does not offer any guidance or suggestions on how the authors might achieve this. The comment is vague and does not provide actionable feedback, leaving the authors without a clear understanding of what changes are needed to improve their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the form of p should be described near line 135, as it is currently not explicitly stated. This implies that the authors should add a description of the form of p in that area. The action is explicit but somewhat vague, as it does not specify exactly what kind of description is needed or how it should be integrated into the text. However, the authors can infer that they need to provide more information about the form of p, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the description of the form of \"p\" near line 135. This provides clear guidance on what the authors need to revise. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. The reviewer assumes it is a Gaussian distribution but does not provide any evidence or reasoning to support this assumption. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the form of \"p\" should be described near line 135. This feedback is actionable as it provides a clear direction for the authors to enhance the clarity and completeness of their manuscript. However, the comment could be more helpful if it included additional context or explanation about why this description is important or how it might impact the understanding of the paper. Overall, the comment is mostly helpful as it points out a specific area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' discussion of regret and their proof of achieving T^{1/2} regret. It asks whether the prediction error over the entire horizon T cannot be sublinear. While the comment highlights a potential inconsistency or misunderstanding in the paper, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their discussion or proof, and it is vague because it lacks concrete steps on how to resolve the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the discussion on regret and the proof of achieving T^{1/2} regret, asking whether the prediction error over the entire horizon T cannot be sublinear. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the discussion on regret and the proof of achieving T^{1/2} regret. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the paper, specifically questioning the discussion on regret and the proof of achieving T^{1/2} regret. It raises a valid point about whether the prediction error over the entire horizon T cannot be sublinear, which could be a critical aspect of the paper\\'s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this inconsistency or clarify their argument. While it highlights an important area for clarification, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the details of the forward-prediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic representation of the forward prediction model. Additionally, it notes that it was difficult to connect the text with the figure and equations. This feedback provides a clear and concrete action for the authors to take, which is to redraw Figure 2(b) to improve clarity and alignment with the text and equations. The explicit nature of the suggestion and the specific guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that it does not provide a schematic representation of the forward prediction model and suggesting that it should be redrawn. Additionally, it highlights the difficulty in connecting the text with the figure and equations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details of the forward-prediction model are not well explained, specifically mentioning that Figure 2(b) does not provide a schematic representation of the model. The reviewer suggests that the figure should be redrawn to improve clarity. While the comment identifies a specific issue with the figure, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to redraw the figure is logical, but without additional context or explanation, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the forward-prediction model, noting that Figure 2(b) does not effectively represent the model and that it is difficult to connect the text with the figure and equations. The comment provides a clear and actionable suggestion to redraw the figure to improve its schematic representation. This feedback is valuable as it directs the authors to a concrete area for improvement, which can enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to better connect the text with the figure and equations. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the weakness of the baseline methods and the lack of discussion on limitations. It also raises questions about the differences between the work and reinforcement learning (RL) and suggests discussing similarities and differences in the conclusion. While the comment provides some direction for improvement, it lacks specific guidance on how to address the issues with the baseline methods or how to discuss limitations. The suggestion to discuss similarities and differences in the conclusion is somewhat actionable, but it remains vague without detailed instructions. Overall, the comment is somewhat actionable as it provides a general direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the baseline methods and their comparison to state-of-the-art methods, as well as the lack of discussion on limitations. It also raises questions about the differences between the work and reinforcement learning (RL) and suggests discussing similarities and differences in the conclusion. However, the comment does not specify which part of the paper discusses the baseline methods or limitations, making it weakly grounded. The suggestion to discuss similarities and differences in the conclusion is specific, but the lack of grounding in the main text makes it difficult for the authors to pinpoint where these issues need addressing. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the baseline methods are weak and not state-of-the-art, and it highlights the lack of discussion on limitations. However, the comment does not provide specific examples or references to support the claim about the baseline methods being weak. Additionally, it suggests discussing similarities and differences with reinforcement learning (RL) in the conclusion, but again, lacks detailed reasoning or evidence to substantiate this suggestion. The absence of specific examples or references makes it difficult for the authors to fully understand and address the critique, rendering the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues: the weakness of the baseline methods and the lack of discussion on limitations. It also raises questions about the differences between the work and reinforcement learning (RL) and suggests discussing similarities and differences in the conclusion. While the comment highlights important areas for improvement, it lacks specific guidance or actionable suggestions on how to address these issues. The authors are left with a general direction but without detailed advice on how to strengthen their baseline methods or discuss limitations effectively. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It suggests that this could help determine whether the benefits are due to a better generative model or better inference. Additionally, it provides minor points regarding Figure 3, suggesting keeping the generative model fixed and optimizing only the inference part of the model to compare representations. While the comment implies actions, such as running experiments with VGAE and vamp prior, and optimizing the inference part of the model, it does not provide explicit instructions or detailed guidance on how to implement these suggestions. The actions are somewhat clear but lack concrete steps, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it refers to specific elements, such as \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to identify the parts of the paper being addressed. However, the comment lacks specificity regarding the exact issue with the doubly stochastic construction and how running VGAE with a vamp prior would address it. Additionally, the suggestion to keep the generative model fixed and optimize only the inference part is not clearly connected to the main point of the comment. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It suggests that this could help determine whether the benefits are due to a better generative model or better inference. However, the comment lacks specific reasoning or evidence to support why this approach would be beneficial or how it would address the issue. Additionally, the minor points about Figure 3 are not substantiated with detailed explanations or references. As a result, the claim is not verifiable due to the absence of supporting evidence or detailed reasoning, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting question about the potential benefits of running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This suggestion could help clarify whether the observed benefits are due to a better generative model or better inference. Additionally, the comment provides minor points regarding Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part could help compare representations. While these suggestions are insightful and could lead to valuable insights, they lack detailed guidance or specific instructions on how to implement them. The feedback is somewhat helpful as it prompts the authors to consider alternative approaches and provides some direction for improvement, but it could be more comprehensive with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s claim about the importance of learning long-range dependencies for powerful predictors. It suggests that while this may be true in the context of semantic segmentation, as evidenced by the visualizations in Table 3, the paper does not fully explore or discuss the necessity of this requirement. The reviewer implies that there might be a middle ground between full locality and no locality in the graph structure, and questions the impact of image size on predictions. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their discussion. The feedback is somewhat vague, as it lacks concrete steps or suggestions for the authors to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the paper lacks a discussion on this topic and raises a concern about the impact of image size on predictions if no form of locality is encoded in the graph structure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer supports this claim by referencing the visualizations in Table 3, which demonstrate the occurrence of long-range dependencies. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that long-range dependencies are necessary. The suggestion that the truth lies somewhere in between and the concern about the impact of image size on predictions adds some context, but the overall justification is not robust. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the necessity of learning long-range dependencies for powerful predictors. It acknowledges that this is evident in the context of semantic segmentation, as shown in the visualizations in Table 3, but questions whether this requirement is absolute. The reviewer suggests that there might be a middle ground between full locality and no locality in the graph structure, and raises a concern about the impact of image size on predictions. This feedback is somewhat helpful as it prompts the authors to consider and discuss the necessity of long-range dependencies in their work. However, it lacks specific suggestions or guidance on how to address this issue, such as proposing a framework for exploring the middle ground or discussing the implications of image size. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the notation in Eq. (3) and discusses the theoretical results presented in Corollaries 1, 2, and 3, Theorem 4, and Figure 1. It highlights the exponential dependence of these results on the diameter $M$ of the domain of data and its impact on the required feature size. The comment suggests that this dependence may weaken the proposed approaches or the theoretical results. However, it does not provide explicit guidance on how the authors should address these issues or improve their work. The feedback lacks specific actions or suggestions, leaving the authors uncertain about how to respond to the critique. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, corollaries, and a theorem, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by discussing the exponential dependence on the diameter $M$ and its impact on the required feature size, as well as the performance shown in Figure 1. This provides clear guidance on what needs to be addressed regarding the theoretical results and their implications. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the exponential dependence of the results on the diameter $M$ of the domain of data, which affects the required feature size. The reviewer provides a logical explanation by stating that while the dependence on $M$ does not increase as the required amount of error $\\\\varepsilon$ decreases, it still impacts the constant factor of the required feature size. The comment also references Figure 1 to support the claim that the performance is deteriorating more quickly than standard random features. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to similar studies, which would elevate it to a fully verifiable claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the exponential dependence of the results on the diameter $M$ of the domain of data, which affects the required feature size. It highlights that while this dependence does not increase as the required amount of error $\\\\varepsilon$ decreases, it still impacts the constant factor of the required feature size. The comment also references Figure 1, suggesting that the performance deteriorates more quickly than standard random features, which may indicate a weakness in the proposed approaches or the theoretical results. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address or mitigate this concern. The feedback is somewhat helpful as it points out a critical aspect of the theoretical results that needs attention, but it could be more beneficial with additional direction or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors have observed model collapse in their experiments and whether this is a common issue. It does not provide explicit instructions or suggestions for the authors to address this concern. The action is implicit, as the authors can infer that they might need to include additional analysis or results related to model collapse. However, the comment lacks concrete guidance on how to implement this analysis or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies an area for potential improvement but does not provide detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the demonstration or results related to the model collapsing less than other methods, and it seeks clarification on whether this is a common issue and if it was observed in the experiments. This provides clear guidance on what the authors need to address or clarify. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the model\\'s behavior. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the model\\'s behavior, specifically whether it collapses less than other methods and if this is a common issue. It references a specific line in the paper where the authors mention gradients becoming 0 and collapsing, prompting the reviewer to inquire about the prevalence and observation of this phenomenon in the experiments. This feedback is somewhat helpful as it encourages the authors to provide additional information or analysis regarding the model\\'s stability and performance. However, it lacks specific suggestions or guidance on how to address this issue or improve the draft, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results for linear scalarization combined with the SOTA heuristic solver (e.g., Concorde) for a better comparison, given that the Pareto front is not highly non-convex. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional results should be included to improve the comparison. The comment is highly actionable because it gives concrete guidance on how to enhance the experimental analysis.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Competitive Baselines\" and \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the results for linear scalarization combined with the SOTA heuristic solver (e.g., Concorde) should be included for a better comparison, given the nature of the Pareto front. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the learning-based solvers outperform the heuristic-based solvers in the experimental results, but notes that for the single objective TSP, the SOTA heuristic solver (e.g., Concorde) often performs best. The reviewer suggests including results for linear scalarization combined with Concorde for a better comparison, given the nature of the Pareto front. This claim is somewhat verifiable as it provides a logical reasoning based on the experimental results and the nature of the problem. However, it lacks specific examples or references to support the claim fully, such as detailed comparisons or data from the experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the experimental results section. It acknowledges the superiority of learning-based solvers over heuristic-based solvers but points out that for the single objective TSP, the SOTA heuristic solver (e.g., Concorde) often performs best. The reviewer suggests including results for linear scalarization combined with Concorde for a better comparison, given the nature of the Pareto front. This feedback is clear and constructive, offering a concrete way for the authors to enhance the comprehensiveness and validity of their experimental analysis. By addressing this point, the authors can provide a more balanced and robust comparison, which is highly beneficial for improving the draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide glosses in Figure 2. This is a clear and direct action, leaving no ambiguity about what the authors need to do to improve their draft. The comment is specific and provides a concrete suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 2,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies what needs to be addressed, namely the addition of glosses in Figure 2. This provides clear guidance on what the authors need to do to improve the draft. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that providing glosses in Figure 2 would be helpful. However, it does not provide any justification or reasoning for why glosses are necessary or how they would improve the figure. Without additional context or explanation, the authors may find it challenging to understand the importance of adding glosses. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors provide glosses in Figure 2, which could enhance the clarity and accessibility of the figure for readers. This feedback is specific and actionable, as it directly points out an area where the draft could be improved. By adding glosses, the authors can make their figure more understandable and user-friendly, which is a valuable suggestion for improving the overall quality of the paper. However, the comment could be more helpful if it explained why glosses are necessary or how they would benefit the figure. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about why finer grouping for quantization is not considered instead of per-tensor and per-channel. While it implies that the authors should consider this alternative, it does not provide explicit guidance or suggestions on how to implement it or what specific aspects should be considered. The action is implicit and vague, leaving the authors uncertain about how to address the suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the consideration of finer grouping for quantization instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion where quantization methods are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests an alternative approach, it does not provide specific details or examples of how this finer grouping could be implemented or why it might be beneficial. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question asking for clarification on the choice of quantization method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization method, specifically asking why finer grouping is not considered instead of per-tensor and per-channel. While this question prompts the authors to reconsider their approach, it lacks depth and does not provide specific guidance or suggestions on how to implement finer grouping or what benefits it might offer. The comment is somewhat helpful as it encourages the authors to explore an alternative method, but it does not offer actionable steps or detailed insights that would significantly enhance the draft. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the definition of \"active vertices\" in the context of line 135. While it highlights a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the definition of \"active vertices,\" but it lacks concrete instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a definition, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the definition of \"active vertices,\" prompting the authors to clarify this term in their manuscript. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the definition of \"active vertices\" in the context of line 135. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the manuscript, asking for clarification on the definition of \"active vertices\" in the context of line 135. This feedback is valuable as it highlights a potential area of misunderstanding for readers and prompts the authors to provide a clear definition. However, the comment could be more helpful if it suggested how the authors might clarify this term or provided examples of what an \"active vertex\" might entail. Despite this, the comment is somewhat helpful as it directs the authors to a specific area needing clarification, but it lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of mention of the inapplicability of the theory to the used model in the limitations section and the vague nature of the structural assumptions given in the appendix. The reviewer suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks in general. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the limitations and provide more detail on the structural assumptions, but the comment lacks concrete guidance on how to do so. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitations section and the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue of the theory\\'s inapplicability to the used model and the vagueness of the structural assumptions, which are given in the appendix. Additionally, it suggests providing more elaboration on the potential negative societal impact of graph neural networks. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s theory is not applicable to the used model and that this limitation is not honestly mentioned in the limitations section. The reviewer supports this claim by pointing out the vagueness of the structural assumptions given in the appendix, which makes it difficult to identify the theoretical limitation. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment provides some reasoning, it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a significant oversight in the paper regarding the applicability of the theory to the used model. It points out that this limitation is not honestly mentioned in the limitations section, which is crucial for transparency and credibility. The comment also highlights the vagueness of the structural assumptions given in the appendix, making it difficult for readers to understand the theoretical limitations. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. This feedback is actionable and provides clear directions for the authors to improve their draft by addressing these issues. However, it could be more helpful if it offered specific suggestions on how to clarify the structural assumptions or discuss the societal impacts in more detail. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of specific parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the framework should be discussed. The action is implicit and vague, as the authors are left to infer that they need to add a discussion but without clear instructions on what to include or how to structure it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of specific parts of the framework in using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment suggests that a discussion on this topic is necessary but does not provide specific guidance on what aspects should be addressed or improved. This lack of detail makes it difficult for the authors to identify and address the issue effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the importance of specific parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide any specific reasoning, examples, or references to support the claim that a discussion is needed or to clarify which parts are vital. This lack of detailed justification makes the claim borderline verifiable, as it provides a general suggestion without concrete evidence or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the importance of specific parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion on this topic is necessary to distinguish the paper from related work. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a gap in the discussion but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analogy between HOI analysis and Harmonic analysis is weak, noting that there are only two \"basis\" (human and object) to form an HOI and that the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen this analogy or address the perceived disconnect. The feedback lacks actionable details, such as recommending specific ways to improve the connection or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the analogy between HOI analysis and Harmonic analysis, providing specific feedback on the lack of connection between the decomposition/integration steps and Fourier analysis. However, it does not explicitly mention which part of the paper discusses this analogy, making it weakly grounded. The comment is specific in detailing the issue with the analogy, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, providing specific reasoning by noting that there are only two \"basis\" (human and object) to form an HOI and that the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. This reasoning is based on logical observations and a comparison with established concepts in Harmonic analysis, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the analogy between HOI analysis and Harmonic analysis, noting that the connection is weak. It points out that there are only two \"basis\" (human and object) to form an HOI, which contrasts with the multiple basis functions in Harmonic analysis. Additionally, it critiques the claim that the decomposition/integration steps have a close connection with Fourier analysis. This feedback is somewhat helpful as it highlights a critical area where the paper may need clarification or further justification. However, it lacks specific suggestions or guidance on how the authors might strengthen the analogy or address the perceived disconnect. To be more helpful, the comment could include actionable advice or examples of how to improve the connection. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalization of the model to focusing distances other than those present in the training data. While it does not explicitly instruct the authors to conduct additional experiments or provide specific guidance on how to address this concern, the question implies that the authors should consider testing the model on different focusing distances. The action is implicit but concrete, as it suggests a specific area for further exploration. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalization of the model to focusing distances other than those present in the training data. This provides clear guidance on what aspect of the figure needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the generalization of the model by pointing out that the figure only shows focusing distances of 1m and 5m, which are present in the training data. The reviewer suggests considering other focusing distances to test the model\\'s generalization. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is an important consideration or how it might impact the model\\'s performance. This lack of detailed justification makes the claim somewhat verifiable, as it raises a valid point but lacks the necessary support to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the generalization of the model to focusing distances other than those present in the training data. By pointing out that the figure only shows focusing distances of 1m and 5m, which are both present in the training data, the reviewer prompts the authors to consider whether the model can effectively handle other focusing distances. This feedback is clear and actionable, as it encourages the authors to explore the model\\'s generalization capabilities, which could lead to a more robust and comprehensive evaluation of the model\\'s performance. However, the comment could be more helpful if it provided suggestions on how to test or analyze this aspect. Overall, the comment is mostly helpful, as it directs the authors to an important area for further investigation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, particularly in relation to their specific neural application. It references Gabbay & Hosehn (2018) as an example and questions what \"style\" means in the context of their model, which is not sequential and does not capture temporal dynamics. While the comment implies that the authors should provide a more detailed definition of style and content, it does not explicitly instruct them to do so or offer concrete guidance on how to define these terms in their context. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider defining content and style more broadly, particularly in relation to their specific neural application. It references Gabbay & Hosehn (2018) as an example and questions the meaning of \"style\" in the context of their model. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for a broader definition of content and style, as well as clarification on the meaning of \"style\" in the context of the model. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, particularly in relation to their specific neural application. The reviewer references Gabbay & Hosehn (2018) as an example, but the comment lacks specific details or examples from the referenced work to support the claim. Additionally, the reviewer questions the meaning of \"style\" in the context of the model, which is not fully elaborated upon. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider defining content and style more broadly, particularly in relation to their specific neural application. It references Gabbay & Hosehn (2018) as an example and questions the meaning of \"style\" in the context of their model, which is not sequential and does not capture temporal dynamics. This feedback is somewhat helpful as it prompts the authors to clarify their terminology and provides a reference for consideration. However, the comment could be more helpful if it offered specific suggestions on how to define content and style in the context of the paper or if it provided more detailed guidance on how to address the temporal dynamic aspect. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon, as evidenced by the comparison of values in figures. Additionally, it mentions that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization in NLP. While the comment identifies specific issues and provides examples, it does not offer explicit guidance on how the authors should address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation and address the issues raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and figures (Line 45, Fig1(b), Fig5(b)) that are being addressed, allowing the authors to accurately identify the parts of the paper being discussed. It is also specific because it details the issues with the analysis of vit quantification, particularly the claim about information distortion and the loss of precision due to quantization. The comment provides examples and references to external works (Q-BERT, Q8BERT, BinaryBERT, FullyBinaryBert) to support its claims, offering clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the analysis of vit quantification, specifically questioning the claim that a direct quantization method leads to information distortion. The reviewer provides specific examples from the paper (e.g., comparing values in figures) to support their argument that the proposed approach does not improve this phenomenon. Additionally, the comment references known issues in transformer quantization in NLP, such as Q-BERT, Q8BERT, BinaryBERT, and FullyBinaryBert, to substantiate the claim that the quantization of MHSA introduces a large loss of precision. This detailed reasoning and use of specific examples and references make the claim mostly verifiable, as it provides a robust foundation for the critique. However, the comment could be further strengthened by providing more detailed comparisons or additional references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon, as evidenced by the comparison of values in figures. Additionally, the comment highlights a known issue in transformer quantization in NLP, which is relevant to the quantization of MHSA. This feedback is mostly helpful as it identifies specific areas where the analysis could be improved and provides examples to support the critique. However, it could be more helpful if it offered suggestions on how to address these issues or improve the analysis. Overall, the comment provides valuable insights but lacks comprehensive guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a main weakness in the work, specifically its lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed X-transformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes that PointNet uses a variant of STN in their network architecture. While the comment highlights the need for empirical or conceptual comparisons to STN, it does not provide explicit guidance on how to address this issue or suggest specific comparisons to include. The action is implicit and somewhat vague, as the authors know they need to make comparisons but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a main weakness in the paper regarding its technical novelty compared to spatial transformer networks (STN) and the lack of comparison to STN. It provides specific examples of existing works that use STN or variants, such as PointNet, and suggests that the proposed X-transformation is similar to STN but applied locally. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the lack of comparison to STN. The reviewer provides specific examples of existing works that use STN or variants, such as PointNet, and highlights the local application of the proposed X-transformation. This detailed comparison and reference to existing literature provide a robust foundation for the claim, making it fully verifiable. The reviewer's reasoning is clear and supported by specific examples, ensuring that the authors can understand and address the critique effectively.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically its lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed X-transformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture. This feedback is valuable as it highlights a critical area for improvement and suggests that the authors should address the lack of empirical or conceptual comparisons to STN. However, the comment could be more helpful if it provided specific suggestions on how to enhance the novelty or offered examples of how to incorporate comparisons to STN. Overall, the comment is mostly helpful as it directs the authors to a key area needing attention and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests mentioning that |Y_t - Y_{t-1}| \\leq c_t almost surely at line 384. This is a clear and concrete suggestion that the authors can implement directly. Second, it corrects the notation by stating that \\\\( \\\\mu_t \\\\) should be \\\\( \\\\tilde{\\\\mu}_t \\\\) at line 431. This is also a specific and actionable suggestion. Both comments are explicit and provide concrete guidance on how to improve the draft, making them highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L384 and L431), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for corrections, such as mentioning the almost sure condition for |Y_t - Y_{t-1}| \\leq c_t at line 384 and correcting \\\\( \\\\mu_t \\\\) to \\\\( \\\\tilde{\\\\mu}_t \\\\) at line 431. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims: one regarding the notation at line 384 and another regarding the correction of \\\\( \\\\mu_t \\\\) to \\\\( \\\\tilde{\\\\mu}_t \\\\) at line 431. These claims are factual corrections to the manuscript, not subjective opinions or suggestions. They are verifiable as they provide specific line numbers and corrections, making them clear and actionable for the authors. Therefore, the review point is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out two potential errors in the manuscript. It suggests that the authors should clarify the notation at line 384 by mentioning that |Y_t - Y_{t-1}| \\leq c_t almost surely. Additionally, it corrects the notation at line 431, suggesting that \\\\( \\\\mu_t \\\\) should be \\\\( \\\\tilde{\\\\mu}_t \\\\). These precise suggestions help the authors improve the accuracy and clarity of their manuscript, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights confusion regarding Eq. 12, specifically questioning where the reward comes from at each trial and whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Section 4.2 with equations would improve clarity. The comment provides explicit actions for the authors to take, namely clarifying the source of the reward and using equations to explain the network model. However, it does not provide detailed guidance on how to implement these actions, such as which specific equations to use or how to structure the explanation. Therefore, while the actions are explicit, they are somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Eq. 12, questioning the source of the reward and whether it is derived from Eq. 11. Additionally, it suggests that explaining the network model in Section 4.2 with equations would improve clarity. The comment provides specific guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Eq. 12, questioning the source of the reward and whether it is derived from Eq. 11. The reviewer suggests that explaining the network model in Section 4.2 with equations would improve clarity. However, the comment does not provide specific reasoning or examples to support the claim that the current explanation is confusing. Additionally, while the reviewer mentions external references, these are not directly related to the specific issue raised about Eq. 12. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the exact nature of the confusion and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Eq. 12, questioning the source of the reward and whether it is derived from Eq. 11. It suggests that explaining the network model in Section 4.2 with equations would improve clarity, providing a clear and actionable suggestion for improvement. Additionally, the comment includes references to external sources that could be relevant for the authors to consider, which could further enhance the paper. However, the comment could be more helpful if it provided more detailed guidance on how to clarify the equations or suggested specific equations to include. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and offers a potential solution, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point contains two distinct parts. The first part is a correction regarding a figure reference in the supplementary material, which is explicit and actionable. The second part suggests attaching theorems and corollaries in the main paper to their corresponding proof links, providing a clear action for the authors to take. However, the comment does not specify which theorems and corollaries should be linked, leaving some ambiguity in execution. Overall, the comment is mostly actionable as it provides explicit actions for the authors to take, but it could be more concrete in detailing the second part.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7\" should be \"Fig.12,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also provides a specific suggestion regarding the attachment of theorems and corollaries to their corresponding proof links, which is clear and actionable. The comment further specifies the primary concerns, which are motivation, methodology soundness, and experiment persuasion. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains a factual correction regarding a figure reference in the supplementary material. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific pieces of feedback. First, it corrects a typographical error in the supplementary material, which is a straightforward and actionable suggestion. Second, it suggests attaching theorems and corollaries in the main paper to their corresponding proof links, which would enhance the reader\\'s ability to follow the paper\\'s arguments. This is a clear and actionable suggestion that could improve the paper\\'s readability and clarity. Additionally, the comment acknowledges the paper\\'s strengths, such as novelty, clear theoretical guarantees, and convincing empirical results. However, it does not provide detailed feedback on the primary concerns of motivation, methodology soundness, and experiment persuasion. While the comment is helpful in addressing specific issues, it could be more comprehensive by offering more detailed guidance on these areas. Overall, the comment is mostly helpful, as it provides actionable feedback and acknowledges the paper\\'s strengths, but it could be more comprehensive to fully address the authors\\' needs.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific issues with the manuscript, such as missing determiners in the definition and unclear terminology regarding action verbs and action frames. It raises questions about the selection of classes and action verbs, as well as the definition of action frames. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify these sections, but the comment lacks detailed guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide specific steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it points out missing determiners, unclear terminology regarding action verbs and action frames, and questions about the selection process. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about specific sections of the paper, such as missing determiners and unclear terminology regarding action verbs and action frames. It does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific issues with the manuscript, such as missing determiners in the definition and unclear terminology regarding action verbs and action frames. It raises pertinent questions about the selection of classes and action verbs, as well as the definition of action frames. This feedback is clear and actionable, as it directs the authors to clarify these sections and provide more detailed explanations. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the clarity. Overall, the comment is mostly helpful as it highlights critical areas for improvement and guides the authors toward enhancing the clarity and precision of their manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a minor typographical error, specifically correcting \"Ln 32 on Page 1, \\'Empiically\\' should be \\'Empirically\\'\". This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be corrected. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect spelling of \"Empiically\" in the text. This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a correction of a minor typographical error, which does not contain any subjective claims or opinions. It is purely factual and does not require verification. Therefore, it fits the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor typographical error in the manuscript, specifically correcting the spelling of \"Empiically\" to \"Empirically\" on line 32 of page 1. While this feedback is precise and actionable, it does not address any substantive issues or provide broader insights into the content or methodology of the paper. The comment is limited in scope and does not offer significant value beyond correcting a minor mistake. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the fixed number of entities and the lack of clarity on how to generalize the model to different numbers of entities. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to resolve this concern. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of a fixed number of entities and the lack of clarity on how to generalize the model to different numbers of entities. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fixed number of entities in the model and the lack of clarity on how to generalize it to different numbers of entities. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks detailed explanation or examples that would help the authors understand the issue or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, it falls into Category 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the fixed number of entities and the lack of clarity on how to generalize the model to different numbers of entities. This is a relevant point that could impact the applicability and scalability of the model. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or modifications to the model. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the idea is insufficient and mentions that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or complexity of their work. The comment lacks actionable details, such as recommending ways to make the idea more novel or suggesting alternative approaches to improve the metric or method. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the idea and mentions that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the novelty are lacking or how the metric and method could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is insufficient, stating that both the new metric and method are relatively straightforward. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a perceived lack of novelty in the idea presented in the paper, noting that both the new metric and method are relatively straightforward. However, it does not provide specific examples or detailed feedback on how the authors could enhance the novelty or complexity of their work. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the framing of the paper may oversell the method, making the contribution less clear. However, it does not provide specific guidance on how to address this issue or what aspects of the framing need to be revised. The comment lacks explicit instructions or concrete details on how to improve the clarity of the contribution, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the framing of the paper may oversell the method, making the contribution less clear. However, it does not specify which parts of the paper are problematic or how the framing could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or how to address the issue. The lack of specificity and grounding makes it difficult for the authors to identify and rectify the problem, aligning with a score of 1 for not being grounded at all.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s framing oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, it is difficult for the authors to understand the basis of the critique and address it effectively. As a result, the claim is unverifiable due to the lack of supporting information, making it challenging for the authors to improve their draft based on this feedback.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper may oversell its method, which could obscure the true contribution. However, it does not provide specific examples or detailed guidance on how the authors might address this issue or clarify the contribution. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. While the comment provides a general direction for improvement, it lacks specific guidance on how to implement these suggestions or which parts of the model description should be revised. The action is explicit but somewhat vague, as the authors know they need to improve the model description but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning that the generative process could be better understood if presented in separate steps and that a notation table could be beneficial. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where the model description is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting improvements to the model description, providing some guidance on what could be done to enhance clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. However, the comment lacks specific examples or detailed reasoning to support why these changes would enhance understanding. Without concrete evidence or examples, the claim is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the model description. It suggests that the generative process could be better understood if presented in separate steps and recommends the inclusion of a notation table. This feedback is clear and actionable, providing the authors with concrete suggestions to enhance the clarity and comprehensibility of their model description. However, the comment could be more helpful if it offered additional guidance on how to structure the presentation or examples of effective notation tables. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that identifying rationales is a complex task, particularly for more complicated NLP tasks like machine translation. It also praises the paper for being well-organized and easy to follow. However, it provides a specific suggestion for improving Figure 2 by recommending the use of another color or a bigger font to highlight the human identified rationales. This feedback is explicit and provides concrete guidance on how to enhance the visual presentation of the figure, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is cluttered and that the \"bold\" text is hard to see, suggesting alternative improvements like using another color or a bigger font to highlight the human identified rationales. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the complexity of identifying rationales, particularly for more complicated NLP tasks like machine translation. It also praises the paper for its organization and ease of follow-up. However, the comment primarily focuses on a suggestion for improving Figure 2, which is a minor aspect of the paper. The suggestion to use another color or a bigger font to highlight the human identified rationales is a specific recommendation, but it lacks broader context or justification for why this change would be beneficial. Therefore, the claim is somewhat verifiable, as it provides a suggestion but lacks detailed reasoning or evidence to fully substantiate the need for the change.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the complexity of identifying rationales, particularly for more complicated NLP tasks like machine translation. It also praises the paper for its organization and ease of follow-up. However, it provides a specific suggestion for improving Figure 2 by recommending the use of another color or a bigger font to highlight the human identified rationales. This feedback is actionable and offers a concrete way to enhance the visual presentation of the figure, which could improve the clarity and impact of the paper. While the comment could be more comprehensive by addressing other aspects of the paper, it still provides valuable guidance for the authors. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework by applying it to non-LLM-based models like HiTeA and InternVideo. While the comment implies an action, it does not provide explicit instructions or detailed guidance on how to conduct these verifications or what specific aspects to focus on. The authors can infer that they need to test the framework on different models, but the lack of concrete steps or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should verify the effectiveness and universality of the Flipped-QA framework by applying it to non-LLM-based models like HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where the framework is discussed. The authors can infer that it relates to the evaluation or discussion sections, but this inference is not direct. The comment is specific in suggesting a potential extension of the framework to other models, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Flipped-QA framework should be tested on non-LLM-based models like HiTeA and InternVideo to verify its effectiveness and universality. While the comment implies that the current application to LLM-based models may not fully demonstrate the framework\\'s capabilities, it lacks specific reasoning or evidence to support this claim. The suggestion is based on logical reasoning, but without detailed examples or references, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion, justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, noting that the Flipped-QA framework is applied only to LLM-based models and suggests that its effectiveness and universality should be verified on non-LLM-based models like HiTeA and InternVideo. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to include additional models, which could enhance the robustness and applicability of their findings. However, the comment could be more helpful if it offered additional guidance on how to conduct these verifications or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for further exploration, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. However, it does not provide specific guidance or suggestions on how the authors could address this concern or enhance the theoretical contribution of their work. The comment implies that the authors could improve their score by addressing these concerns, but it does not offer concrete steps or examples of how to do so. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical novelty in the proposed method, which primarily builds upon existing methods like Clopper-Pearson intervals and Gaussian elimination. However, it does not specify which part of the paper this critique is based on, such as a particular section or discussion where the authors claim novelty. While the authors might infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific in pointing out the reliance on existing methods but does not provide detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method primarily builds upon existing methods, such as Clopper-Pearson intervals and Gaussian elimination, and lacks significant theoretical novelty. This claim is supported by specific references to the cited works, which provide a basis for the reviewer\\'s assertion. The inclusion of these references offers a clear and robust foundation for the claim, making it fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment acknowledges that the proposed method primarily builds upon existing methods, such as Clopper-Pearson intervals and Gaussian elimination, and lacks significant theoretical novelty. While it expresses a willingness to improve the score if the authors address these concerns, it does not provide specific guidance or suggestions on how the authors might enhance the theoretical contribution of their work. The comment lacks actionable feedback or detailed advice on how to improve the draft, leaving the authors without a clear path for addressing the identified issues. Therefore, the comment is not particularly helpful, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on what the authors should do with this information or how it relates to the paper\\'s content. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context being addressed. Additionally, the comment lacks specificity regarding what aspect of the text input or object elements is being questioned. Without clear grounding or specificity, the authors cannot effectively understand or address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the text input and its concatenation with the four text elements of an object. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the text input can be concatenated by the four text elements of an object. While it highlights a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or clarify it in their draft. The comment lacks actionable feedback or specific advice, leaving the authors without a clear path to improve their work. As a result, the comment is not particularly helpful in guiding the authors to enhance their draft, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific sentence in the abstract as cumbersome and suggests that it can be made clearer. While it does not provide detailed guidance on how to improve the clarity, it does give a clear action for the authors to take\u2014revising the sentence to make it clearer. This makes the comment somewhat actionable, as the authors know they need to revise the sentence but may not be entirely sure of the exact changes needed to achieve clarity. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific sentence in lines 12-17 of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be improved in the abstract. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a specific sentence in the abstract is cumbersome and suggests that it can be made clearer. However, the comment does not provide any reasoning or examples to support why the sentence is considered cumbersome or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of a sentence in the abstract, suggesting that it is cumbersome and could be improved. This feedback is actionable as it directs the authors to revise the sentence for better clarity. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the sentence or what aspects of it are unclear. Despite this, the comment still offers valuable guidance for improving the draft, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories is not fully investigated for the baselines, suggesting that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues or what changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. Additionally, it highlights the need for a more thorough investigation of the trade-off between head and tail categories for the baselines, suggesting that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also mentions that Table 5 shows a trade-off between head and tail categories, but this trade-off has not been fully investigated for the baselines. The reviewer suggests that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. While the comment provides some reasoning and references Decouple [Kang et al.], it lacks specific examples or detailed comparisons to fully substantiate the claim. The suggestion to continue the work for future submission is based on the current findings, but the justification could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical evaluation of the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories is not fully investigated for the baselines, suggesting that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights specific areas where the paper could be improved, such as conducting a more thorough analysis of the trade-off between head and tail categories for the baselines. However, the comment could be more helpful by offering specific suggestions on how to address these issues or by providing examples of hyper-parameter changes that could be explored. Overall, the comment is mostly helpful as it identifies key areas for improvement and encourages the authors to continue their work for future submission, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the intuition behind the specific choice of $\\\\lambda_t$ for encouraging exploration in the proposed E2W algorithm and questions the use of $\\\\sum_a N(s, a)$ (but not $N(s, a)$) for $\\\\lambda_s$ in Equation (7). While these questions imply that the authors should provide explanations or justifications for these choices, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"E2W algorithm\" and \"Equation (7),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises detailed questions about the intuition behind the choice of $\\\\lambda_t$ for exploration and the use of $\\\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\\\lambda_s$ in Equation (7). These questions provide clear guidance on what aspects of the methodology need further explanation or justification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology and choices made in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the methodology of the proposed E2W algorithm, specifically regarding the intuition behind the choice of $\\\\lambda_t$ for encouraging exploration and the use of $\\\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\\\lambda_s$ in Equation (7). These questions prompt the authors to provide explanations or justifications for their methodological choices, which could enhance the clarity and understanding of their work. However, the comment does not offer specific suggestions or guidance on how to address these questions, which limits its helpfulness. While it identifies areas for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation, noting that it is primarily based on four OCR QA datasets and that the authors themselves acknowledge the potential unreliability of this evaluation. The reviewer suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not provide specific guidance on which datasets to consider or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer the need for additional datasets and determine how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the evaluation, which is primarily based on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included. The comment is somewhat verifiable as it provides a logical reasoning that the current evaluation may be unreliable, given the authors\\' own admission in Fig 4(5). However, it lacks specific examples or references to support the claim that the LLaVA benchmark would be a more appropriate or necessary addition. Including such details would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation section, noting that it is primarily based on four OCR QA datasets. It acknowledges the authors\\' own admission that this evaluation may be unreliable and suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, providing the authors with a specific direction for expanding their evaluation to include additional datasets and scenarios. By addressing this point, the authors can enhance the robustness and generalizability of their evaluation, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two separate comments. The first comment suggests that the authors should clarify that \"pi\" is a function from R^m to Delta^{K+1}, which is a specific and actionable suggestion. The second comment questions the dimensions of X pi(X) in (2) and suggests assuming the first column of X_t is always 0. This is also a specific and actionable suggestion. Both comments provide clear guidance on how to improve the draft, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L75\" and \"(2),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as clarifying the function of \"pi\" and questioning the dimensions of \"X pi(X)\" in (2). The comment suggests assuming the first column of X_t is always 0, offering a clear direction for addressing the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate comments. The first comment suggests clarifying the function of \"pi\" and its dimensions, but it does not provide any justification or reasoning for why this clarification is necessary. The second comment questions the dimensions of \"X pi(X)\" and suggests assuming the first column of X_t is always 0, but again lacks detailed reasoning or evidence to support the suggestion. Both comments are vague and do not provide sufficient justification or examples to support the claims, making them difficult for the authors to address effectively. Therefore, the review point is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two separate issues. First, it suggests clarifying the function of \"pi\" by stating that it is a function from R^m to Delta^{K+1}, which is a clear and direct suggestion for improvement. Second, it questions the dimensions of \"X pi(X)\" in (2) and suggests assuming the first column of X_t is always 0, offering a potential solution to the issue. This feedback is detailed and constructive, guiding the authors on how to enhance the clarity and accuracy of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that weak supervision could be better evaluated, specifically questioning the realism of the evaluated tweets and the prompt requirements. It points out that the prompt may not be the most realistic and mentions that the generation of authors is also not realistic. However, the comment does not provide explicit guidance on how to improve the evaluation of weak supervision or suggest specific actions to make the prompt or generation more realistic. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the prompt requirements. It mentions that the prompt requires \"all of the structured elements for perspectives to be present in the generated tweets,\" which is not the most realistic, and points out that the generation of authors is also not realistic. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the realism of the evaluation, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the realism of the evaluated tweets and the prompt requirements, suggesting that they may not be the most realistic. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides an initial rationale but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the prompt requirements. It points out that the prompt may not be the most realistic and mentions that the generation of authors is also not realistic. This feedback is somewhat helpful as it highlights areas where the evaluation could be improved, prompting the authors to reconsider the realism of their approach. However, the comment lacks specific suggestions or guidance on how to address these issues, such as proposing alternative methods or criteria for evaluating realism. Therefore, while it provides some insight, it could be more helpful with additional detail or actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment does not leave any ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including keypoint detection results in the experiments section. However, it does not specify which experiments or results are being referred to, making it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the authors might have an idea of where keypoint detection results are discussed, the comment lacks full grounding. It is specific about what needs to be included but does not provide detailed guidance on how to integrate these results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any justification or reasoning for why this inclusion is necessary or beneficial. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to include keypoint detection results in the experiments section. This feedback is specific and directly addresses a potential gap in the paper, guiding the authors on how to enhance the completeness and clarity of their experimental results. By following this advice, the authors can improve the comprehensiveness of their work. However, the comment could be more helpful if it explained why including these results is important or how they would impact the overall understanding of the study. Despite this, the feedback is mostly helpful as it offers a concrete step for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This is an explicit suggestion that provides a clear action for the authors to take, which is to conduct a comparative analysis with specific models. The comment is concrete because it specifies the models to be compared and the rationale behind the suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a comparison of the proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or comparison section. The suggestion is specific, as it provides a clear direction for the authors to compare their model with a particular work. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). The suggestion is based on a logical reasoning that the ternary potential is a key component, but it lacks specific evidence or detailed explanation to fully substantiate the claim. The reference to Jabri et al. provides some context but does not directly support the claim about the ternary potential. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific comparison of the proposed model with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This feedback is clear and actionable, providing the authors with a concrete direction for expanding their evaluation to include a relevant benchmark. By suggesting a comparison with a specific model, the comment offers a straightforward way for the authors to enhance the robustness and comprehensiveness of their experimental results. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the interpretation of the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the number of discourse relations in Table A2, asking whether this is an artifact of the colloquial language or if the term \"discourse\" is used differently in the treebank compared to other languages in UD. While the comment implies that the authors should clarify the nature of these relations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank and whether this is an artifact of the colloquial language or if the term \"discourse\" is used differently in the treebank compared to other languages in UD. This provides clear guidance on what aspect of the table needs clarification or further explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of terms. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of terms. This feedback is somewhat helpful as it prompts the authors to consider and clarify the nature of these relations, which could be important for the interpretation and validity of their findings. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending ways to verify or clarify the classification of discourse relations. Therefore, while it provides some insight, it could be more helpful with additional direction or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of soft labels in relation to CRM and Cross Entropy, suggesting that a higher beta value might be more appropriate. It also questions why the authors did not extend the curve further. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their work. The feedback lacks specific instructions or suggestions for action, leaving the authors uncertain about how to respond to the critique. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of soft labels in relation to CRM and Cross Entropy, specifically mentioning the results for iNaturalist19. It suggests that a higher beta value might be more appropriate and questions why the authors did not extend the curve further. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the results and the use of hyperparameters, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of soft labels in relation to CRM and Cross Entropy, suggesting that a higher beta value might be more appropriate. The reviewer questions why the authors did not extend the curve further, implying that the results might not be as impressive as they appear. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the hyperparameters are subpar or that the results are misleading. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the use of soft labels in relation to CRM and Cross Entropy, suggesting that a higher beta value might be more appropriate. It questions why the authors did not extend the curve further, implying that the results might not be as impressive as they appear. However, the comment lacks specificity and actionable guidance on how the authors could address these concerns or improve their work. Without detailed suggestions or examples, the feedback is limited in its usefulness to the authors. Therefore, it is rated as barely helpful, as it identifies potential issues but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two suggestions. First, it implies that the authors should include more evaluations in the direction of classifying unseen words, which is a nice idea but presented as an afterthought. This suggestion is explicit and provides a clear action for the authors to take. Second, it suggests adding translations to Figure 6 for readers who do not speak Chinese, which is also explicit and actionable. Both suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simple/traditional experiment for unseen characters\" and \"Figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests adding more evaluations in the direction of classifying unseen words and provides a clear suggestion to add translations to Figure 6 for readers who do not speak Chinese. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: first, that the simple/traditional experiment for unseen characters is presented as an afterthought, and second, that adding translations to Figure 6 would be beneficial. The first claim lacks specific reasoning or evidence to support why the experiment is considered an afterthought, making it difficult for the authors to understand the basis of the critique. The second suggestion is more actionable but still lacks detailed justification or examples of how translations would enhance Figure 6. Overall, the comment is somewhat verifiable as it provides some direction but lacks comprehensive support or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two actionable suggestions for improving the paper. First, it acknowledges the idea of a simple/traditional experiment for unseen characters as a nice addition but notes that it is presented as an afterthought. The reviewer suggests that more evaluations in this direction, such as classifying unseen words, would be beneficial. This feedback is clear and actionable, guiding the authors to expand their evaluation to strengthen their work. Second, the comment suggests adding translations to Figure 6 for readers who do not speak Chinese, which is a practical and helpful suggestion to enhance accessibility. Overall, the comment is mostly helpful as it offers specific and constructive feedback that can guide the authors in improving their draft. However, it could be more comprehensive by providing additional details or examples on how to implement these suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific and explicit actions for the authors to take. It identifies two issues: the small text in Table 1, which is hard to read, and the missing gradient symbol in Algorithm 1. Additionally, it lists references that the authors should consider including. Each of these points is clear and actionable, giving the authors concrete steps to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and \"algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in table 1 and the missing gradient symbol in algorithm 1, providing clear guidance on what needs to be addressed. Additionally, it lists references that the authors should consider including, further specifying the areas for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and requests for clarification or correction. It does not contain subjective opinions, judgments, or suggestions that require verification. The mention of references is factual and does not constitute a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two issues: the small text in Table 1, which is hard to read, and the missing gradient symbol in Algorithm 1. These observations are clear and directly guide the authors on how to improve the readability and accuracy of their work. Additionally, the comment lists references that the authors should consider including, which can enhance the scholarly context of their paper. This detailed and constructive feedback empowers the authors to make concrete improvements to their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should render \"Wright et al., 1934; Figure 1\" more naturally by using the bracketed arguments in \\\\citep. However, it does not provide specific guidance on how to implement this suggestion or why it would improve the draft. The comment is vague and lacks explicit instructions, leaving the authors uncertain about how to address the issue. Without concrete details on how to execute the suggested action, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Wright et al., 1934; Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the use of bracketed arguments in \\\\citep to render the reference more naturally. However, the comment lacks specificity regarding the exact nature of the issue with the current rendering or how the suggested change would improve it. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should render a reference more naturally by using bracketed arguments in \\\\citep. However, it does not provide any justification or reasoning for why this change would be beneficial or necessary. The comment lacks supporting evidence or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement in the formatting of references, recommending the use of bracketed arguments in \\\\citep to render a reference more naturally. While it provides a clear and actionable suggestion, it lacks further explanation or context regarding why this change would be beneficial or how it might impact the overall presentation of the paper. The comment is somewhat helpful as it offers a concrete step for improvement, but it could be more comprehensive with additional justification or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It points out that the algorithm requires solving several LPs in high dimensions, which involves a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets. While the comment identifies areas of concern, it does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they should provide more detailed discussions and potentially conduct experiments on larger datasets. However, the lack of specific instructions or actionable steps makes the comment somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions that the algorithm requires solving several LPs in high dimensions, which involves a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed regarding computational aspects and the practicality of the methods. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It highlights specific issues, such as the requirement to solve several LPs in high dimensions with a parameter that is not easily calculable, and notes that the experiments are performed on small-scale datasets. While the comment provides some reasoning and specific details, it lacks external references or detailed examples to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more comprehensive evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the proposed methods may not be practically useful due to the requirement of solving several LPs in high dimensions, which involves a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets, which may not adequately address the practicality of the methods in real-world scenarios. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or improve their methodology. Therefore, the feedback is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed, actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take, correcting specific signs in equations and clarifying the definition of B. The reviewer also suggests a correction in Line 504. These instructions are clear and directly guide the authors on how to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (502, 503, and 504) and provides detailed corrections for the equations, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the signs in the equations and the definition of B, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and corrections regarding specific signs in equations and the definition of B. It does not contain subjective opinions, claims, or suggestions that require justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback regarding the equations in the paper. It identifies potential errors in the signs used in the equations, specifically suggesting corrections for the signs after \\\\(\\\\nu_j\\\\) and before \\\\(\\\\sum_{j=1}^m\\\\) in the definition of B. Additionally, it points out a correction needed in Line 504. This level of detail and clarity is highly beneficial for the authors, as it directly guides them on how to improve the accuracy and clarity of their mathematical expressions. The comment is rated as highly helpful, as it offers precise and constructive suggestions that can significantly enhance the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, as this could be equivalent to an ODE net with a fixed time-step Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested baseline or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between residual blocks and suggests a potentially interesting baseline for comparison. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion for a potentially interesting baseline. It does not contain any subjective claims, opinions, or judgments that require verification. The suggestion is more of a hypothesis or a potential direction for further exploration, rather than a claim that needs to be substantiated. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the experimental setup, asking whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, as this could be equivalent to an ODE net with a fixed time-step Euler integrator. This feedback is somewhat helpful as it prompts the authors to consider an additional comparison that could enhance the depth and comprehensiveness of their experiments. However, the comment could be more helpful if it provided more detailed guidance on how to implement this comparison or why it would be beneficial. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, especially since the question model is a bag of words, which is not expensive to encode longer sequences. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or why this choice might be problematic. The comment lacks actionable guidance, leaving the authors without a clear understanding of what changes, if any, are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, particularly since the question model is a bag of words, which is not expensive to encode longer sequences. This provides clear guidance on what aspect of the design choice is being critiqued. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this design choice is problematic or how it affects the model\\'s performance. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. While the comment identifies a potential issue with the design, it lacks depth and does not provide specific suggestions or alternatives for improvement. The authors are left with a general observation but without clear guidance on how to address it. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in Figure 1 regarding how the proposed method produces the type of explanation mentioned. It suggests that additional ad-hoc post-analysis might be needed to extract shared motifs, implying that this analysis is necessary even with the proposed method. While the comment identifies an area of confusion, it does not provide explicit instructions on how to address it or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the explanation process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unclear explanation in the figure and suggests that additional ad-hoc post-analysis might be necessary to extract shared motifs. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the type of explanation mentioned. The reviewer suggests that additional ad-hoc post-analysis might be necessary to extract shared motifs, implying that the proposed method may not fully address this issue. However, the comment lacks specific examples or detailed reasoning to support the claim that the proposed method requires additional analysis. This makes the claim somewhat verifiable, as it provides a basis for the concern but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the explanation produced by the proposed method is unclear. It suggests that additional ad-hoc post-analysis might be necessary to extract shared motifs, implying that the proposed method may not fully address this aspect. While the comment highlights a potential weakness, it lacks detailed guidance or suggestions on how the authors might clarify or improve the explanation process. The feedback is somewhat helpful as it points out an area for improvement, but it could be more beneficial with additional direction or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a statement about the potential non-convexity of the function Z and its impact on the convergence of SGD. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this observation is relevant to the paper, if it needs to be addressed, or how the authors might incorporate this information into their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (182-184), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential non-convexity of the function Z and its impact on the convergence of SGD. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the potential non-convexity of the function Z and its impact on the convergence of SGD. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks detailed explanation or examples that would help the authors understand the basis of the claim or how it relates to their work. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the non-convexity of the function Z and its impact on the convergence of SGD. However, it does not provide any specific suggestions or guidance on how the authors might address this concern or explore the implications of non-convexity in their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues that the authors need to address. It mentions that the authors did not compare any models other than GPT2, which implies that they should include comparisons with other models. It also points out that several sections of the paper are confusing, suggesting that the authors need to clarify these sections. Additionally, it notes a missing citation/reference in Line 99, section 3.1, and an unreferenced notation \\\\(\\\\hat{D}(c)\\\\) in Line 165, section 3.4. The comment provides explicit actions for the authors to take, such as including model comparisons, clarifying confusing sections, and addressing missing citations and notations. The feedback is clear and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions specific lines and sections (Line 99, section 3.1, and Line 165, section 3.4), allowing the authors to identify the parts of the paper being addressed. However, it does not specify what is confusing about the sections or how the authors should address the missing citation or unreferenced notation. The comment is specific about the missing citation and unreferenced notation but lacks specificity regarding the confusing sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims: the lack of model comparisons other than GPT2, the confusing nature of several sections, and the absence of a citation or reference in Line 99, section 3.1. Additionally, it notes an unreferenced notation \\\\(\\\\hat{D}(c)\\\\) in Line 165, section 3.4. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The mention of limitations being acknowledged provides some context, but the overall justification is not robust. Therefore, the comment is somewhat verifiable, as it highlights issues but requires more detailed evidence or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues that the authors need to address to improve their draft. It points out that the authors did not compare any models other than GPT2, which could limit the generalizability of their findings. Additionally, it mentions that several sections of the paper are confusing, suggesting that the authors need to clarify these sections. The comment also highlights a missing citation/reference in Line 99, section 3.1, and an unreferenced notation \\\\(\\\\hat{D}(c)\\\\) in Line 165, section 3.4. Finally, it acknowledges the authors\\' effort to address the limitations of their work. While the comment identifies multiple areas for improvement, it could be more helpful by providing specific suggestions on how to clarify the confusing sections or improve the model comparisons. Overall, the feedback is somewhat helpful as it directs the authors to several specific issues but lacks detailed guidance on how to address them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of a specific expression in Equation (2), \"$:\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$.\" This implies that the authors should clarify or provide an explanation for this expression. While the action is implicit, it is clear and concrete, as it directly points to a specific part of the paper that needs clarification. The authors can infer that they need to address this question to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of a particular expression, \"$:\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$,\" within that equation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about a specific expression in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific expression in Equation (2), which is a clear and actionable piece of feedback. By asking for clarification, the reviewer prompts the authors to provide an explanation or interpretation of the expression, which could help improve the clarity and understanding of the paper. However, the comment could be more helpful if it provided additional context or suggested potential interpretations, which would offer more comprehensive guidance. Overall, the comment is somewhat helpful as it identifies a specific area needing clarification, but it could be more beneficial with further elaboration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete instructions for the authors, specifying that two lines in red should be in green. It also provides specific line numbers and references to the supplementary material (SuppMat) and equations, tables, and algorithms. This feedback is clear and actionable, as it gives the authors precise guidance on what changes to make to improve the draft. The authors know exactly what needs to be done and where to apply the changes, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the supplementary material (SuppMat, L502, L507, and L509) and references equations, tables, and algorithms, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely changing the color of certain lines and referencing equations, tables, and algorithms correctly. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements regarding the color of lines and references to specific lines and equations in the supplementary material. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two lines in red that should be in green in the supplementary material. It also specifies the exact line numbers and references to equations, tables, and algorithms that need to be corrected. This level of detail is highly helpful as it guides the authors precisely on what changes to make to improve the accuracy and clarity of their draft. The comment is clear, actionable, and directly addresses specific issues, making it highly helpful for the authors to enhance their manuscript.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a gap in the paper regarding the comparison of online learning formulations with other approaches, such as reinforcement learning (RL). It explicitly suggests that a proper comparison should be included in the evaluation results to clarify why online learning cannot be used. The reviewer also raises specific questions about the retraining cost, how it compares to incremental updates, and the challenges of including it in the evaluation. These questions provide clear guidance on what the authors need to address to improve their draft. The comment is explicit and provides concrete details on how to implement the suggested action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors discuss online learning formulations, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of a proper comparison against online learning approaches and reinforcement learning (RL) in the evaluation results. The comment further details the specific questions that need to be addressed regarding the retraining cost, comparison, and challenges of including online learning in the evaluation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim that the paper lacks a proper comparison of online learning formulations with other approaches, such as reinforcement learning (RL), in the evaluation results. The reviewer suggests that this omission makes it unclear why online learning cannot be used and questions the rationale behind its exclusion. However, the comment does not provide specific examples or references to support the claim that such a comparison is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the comparison of online learning formulations with other approaches, such as reinforcement learning (RL). It highlights the need for a proper comparison in the evaluation results to clarify why online learning cannot be used. The comment raises specific questions about the retraining cost, how it compares to incremental updates, and the challenges of including online learning in the evaluation. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing the missing comparison and offering insights into the rationale behind their choices. However, the comment could be more helpful if it included suggestions on how to conduct the comparison or examples of relevant studies. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include important references, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages a comprehensive comparison with these works. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the references \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the need for a comprehensive comparison with these works. The comment is specific in detailing the missing references and the importance of their inclusion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages a comprehensive comparison with these works. The comment is fully verifiable as it provides specific references to external works, which can guide the authors in addressing the critique. The inclusion of these references provides a clear basis for the claim, making it easy for the authors to understand and act upon the feedback. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, providing specific references to guide the authors in addressing this gap. Additionally, the comment acknowledges the societal impact discussed in the paper, which is a positive aspect. The feedback is clear, actionable, and constructive, offering the authors a direct path to improve their draft by incorporating relevant references and comparisons. This level of detail and specificity makes the comment highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the claim of the effectiveness of the proposed prompts and the slight improvement shown in the experimental results. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The comment lacks actionable details, such as recommending ways to strengthen the claim or improve the experimental results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of the effectiveness of the proposed prompts, pointing out that the slight improvement shown in the experimental results does not support the claim. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of the effectiveness of the proposed prompts based on the slight improvement shown in the experimental results. However, it does not provide any specific reasoning or evidence to support why the improvement is insufficient to support the claim. The comment lacks detailed analysis or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable due to the absence of supporting evidence or reasoning.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the claim of the effectiveness of the proposed prompts and the slight improvement shown in the experimental results. This is a relevant observation that could help the authors reconsider their claims or provide additional evidence to support them. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their experimental results. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel, is insufficient. It suggests that there could be many different designs of this approach and recommends conducting experiments or analyses with different sampling intervals and sample sizes. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions or what specific designs or sampling intervals to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the Cycle FC, which aligns features at different spatial locations to the same channel, and suggests that the analysis is insufficient. It provides a specific suggestion for improvement by recommending experiments or analysis with different sampling intervals and sample sizes. However, the comment does not explicitly mention which part of the paper discusses the Cycle FC, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential improvement, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of the Cycle FC is insufficient and suggests conducting experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or detailed reasoning to support why these additional analyses would be beneficial or necessary. Without concrete evidence or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. It suggests that the analysis is insufficient and could be improved by conducting experiments or analysis with different sampling intervals and sample sizes. This feedback is somewhat helpful as it points out an area for improvement and provides a general direction for enhancing the analysis. However, it lacks specific guidance or examples on how to implement these suggestions, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of the Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer suggests that the authors provide experimental results to support the practicality of their algorithms. While the comment implies that the authors should conduct experiments, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and the use of the \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the practical performance of the proposed algorithms, particularly highlighting the issue of the Vandermonde matrix being ill-conditioned and numerically unstable. The comment further specifies the concern by mentioning the specific conditions under which the algorithm might fail and suggests providing experimental results to support the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of the Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a logical reasoning by explaining the conditions under which the algorithm might fail, such as small $\\\\alpha$ and large $n$. This reasoning is supported by common knowledge about the properties of the Vandermonde matrix. However, the comment could be strengthened by providing specific examples or references to studies that have encountered similar issues. As it stands, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical performance of the proposed algorithms, specifically highlighting the use of the Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a specific example of how the algorithm might fail in practice, given certain conditions. This feedback is clear and actionable, as it suggests that the authors should provide experimental results to support the practicality of their algorithms. By addressing this concern, the authors can enhance the credibility and applicability of their work. Therefore, the comment is mostly helpful, as it identifies a critical area for improvement and offers a clear path for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of standard deviations, which is crucial for assessing the variability and reliability of the results. The comment implies that the authors should include standard deviations to provide a more comprehensive evaluation of the performance of the best method. However, it does not explicitly instruct the authors to add standard deviations, leaving the action implicit. Additionally, while the comment suggests a clear action, it lacks concrete details on how to implement it, such as which specific results should include standard deviations. Therefore, the comment is mostly actionable, as the action is inferred but concrete in terms of what needs to be done.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the absence of standard deviations in the paper, which is a specific issue that affects the interpretation of the results. However, it does not explicitly mention which part of the paper this issue pertains to, such as specific tables or figures where standard deviations should be included. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what is missing. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the absence of standard deviations makes it difficult to assess the robustness of the results, specifically whether the best method is truly the best or if other configurations perform similarly. This claim is somewhat verifiable as it logically points out the importance of standard deviations in statistical analysis. However, the comment lacks specific examples or references to support the assertion that standard deviations are crucial for evaluating performance. Providing such examples or references would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results, noting the absence of standard deviations. This is a critical aspect that affects the interpretation of the results, as it provides insight into the variability and reliability of the findings. By highlighting this omission, the comment provides the authors with clear and actionable feedback on how to improve their draft. However, the comment could be more helpful if it suggested where or how to include standard deviations in the results section. Despite this, the feedback is mostly helpful as it directs the authors to an important aspect of their work that needs attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the choice of p < 0.4 in Algorithm 1. While it highlights a specific aspect of the algorithm that requires clarification, it does not provide explicit guidance on how the authors should address this question. The action is implicit, as the authors can infer that they need to provide an explanation or justification for their choice of p < 0.4. However, the comment lacks concrete details on how to present this explanation, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by questioning the choice of p < 0.4, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1. While it highlights a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The comment is somewhat helpful as it points out a specific area that needs clarification, but it lacks depth and actionable advice, leaving the authors with only a vague direction for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide explanations and analysis for Figures 1, 2, and 3, as well as to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5\" and refers to specific figures (Figure 1, Figure 2, and Figure 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for these figures and the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have failed to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It specifically mentions the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any reasoning or evidence to support why these explanations or analyses are necessary or how they would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these clarifications. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors have presented figures without providing explanations or analysis. It highlights the need for clarification regarding the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, as it directs the authors to provide additional context and analysis for their figures, which is crucial for the reader to understand the results. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be highlighted. Overall, the comment is mostly helpful as it effectively points out a gap in the manuscript and guides the authors toward improving it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a trend in the data presented in Table 2, noting that the advantage of RLCD over RLAIF decreases as the model size increases from 7B to 30B. It raises a question about the scalability of RLCD (or RLCD-Rescore) to larger language models and suggests that these models might be better at differentiating responses near the decision boundary. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their work. The action is implicit and vague, as it lacks concrete steps or recommendations for the authors to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases from 7B to 30B. Additionally, it raises a question about the scalability of RLCD (or RLCD-Rescore) to larger language models and suggests that these models might be better at differentiating responses near the decision boundary. This provides clear guidance on what needs to be addressed or explored further. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases from 7B to 30B, as shown in Table 2. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment suggests that it remains to be seen whether RLCD (or RLCD-Rescore) can scale to larger language models, but it lacks specific examples or data to support the assertion. This makes the claim unverifiable, as it does not provide sufficient evidence or reasoning to support the argument. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights an interesting observation regarding the shrinking advantage of RLCD over RLAIF as the model size increases from 7B to 30B. It raises a valid question about the scalability of RLCD (or RLCD-Rescore) to larger language models, suggesting that these models might be better at differentiating responses near the decision boundary. This feedback is somewhat helpful as it points out a potential limitation in the current approach and encourages the authors to consider the scalability of their method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their work. To be more helpful, it could include recommendations for further experimentation or analysis to explore the scalability question. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions whether there is a solution to address the scalability issue, particularly for large datasets like ImageNet. While the comment implies that the authors should address the scalability issue, it does not provide explicit guidance or suggestions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore solutions for scalability but without concrete steps or examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scalability issue of the proposed NC measure, which takes the entire training and test datasets as input. However, it does not specify which part of the paper discusses this measure, making it weakly grounded. The comment is specific in its concern about the scalability issue and suggests that addressing this could enhance the practical contribution of the paper. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. The reviewer questions whether there is a solution to address the scalability issue, particularly for large datasets like ImageNet. While the comment highlights a potential limitation, it lacks specific examples or references to support the claim about scalability issues. The suggestion for addressing scalability is also vague, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions whether there is a solution to address this scalability issue, particularly for large datasets like ImageNet. This feedback is valuable as it highlights a potential limitation that could impact the practical contribution of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this scalability issue, such as proposing alternative methods or strategies. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of clarity regarding the performance boost claimed by the proposed CoNO model. It questions whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains. While the comment implies that the authors should include comparisons to UNets, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment provides specific examples of related works (Raonic et al and Gupta et al) to support its point, making it clear and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the source of the performance boost claimed by the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible. The reviewer supports this claim by referencing the strong performance of UNets on regular gridded domains, citing specific works by Raonic et al and Gupta et al. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the cited works, which would fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical question about the source of the performance boost claimed by the proposed CoNO model. It questions whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement, and suggests that comparisons to UNets are necessary. The comment also references relevant works by Raonic et al and Gupta et al, which have shown strong performance on regular gridded domains, providing a basis for the suggestion. This feedback is clear and actionable, as it guides the authors to clarify their claims and provide comparisons that could strengthen their argument. However, it could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and provides some direction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It suggests that the comparison of computation complexity should be included in the experimental part. While the comment implies an action\u2014adding a comparison of computation complexity\u2014it does not provide explicit instructions or detailed guidance on how to conduct this comparison. The authors can infer the need for this addition, but the lack of concrete steps or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and the specific issue of computation complexity when feeding forward in the PSA method. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue of computation complexity and suggests that a comparison of computation complexity should be included in the experiment part. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the need for calculating all the flipped previous layer outputs in algorithm 1. This claim is somewhat verifiable as it provides a specific example of the computational complexity involved in the PSA method. However, it lacks detailed comparisons or references to other methods to fully substantiate the claim. The suggestion to include a comparison of computation complexity in the experiments is a logical step, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computational complexity involved in the PSA method, specifically mentioning the need to calculate all the flipped previous layer outputs during the feed-forward process. The comment suggests that a comparison of computation complexity should be included in the experimental section, which is a clear and actionable recommendation. This feedback is valuable as it directs the authors to address a potential weakness in their method and provides a concrete suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or suggested specific metrics to consider. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific and actionable feedback on several aspects of the figures and the lack of comparison details. It suggests that the fonts in Figure 1 could be larger, particularly for the words in the grey box, and that V_mem, Th_i, and U_i^t are too small. It also recommends providing a long-form explanation for \"CTRL\" and notes that the font in Figure 2 is too small. Additionally, the comment points out the need for more detailed comparisons, such as epochs and number of parameters, with other state-of-the-art Transformer designs. The suggestion to present this information in a table format is also provided. This feedback is explicit and concrete, giving the authors clear guidance on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (\"fig 1\" and \"figure 2\"), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the figures, such as the font size being too small for certain elements and the need for a long-form explanation for \"CTRL.\" Additionally, it suggests improvements in the comparison details, such as including epochs and number of parameters, and recommends presenting this information in a table format. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific feedback on the figures, suggesting that the fonts could be larger and that certain elements, such as V_mem, Th_i, and U_i^t, are too small. It also mentions that the font in Figure 2 is too small and suggests providing a long-form explanation for \"CTRL.\" These suggestions are based on logical reasoning, as larger fonts and clearer explanations would enhance the readability of the figures. Additionally, the comment suggests including more detailed comparisons with other state-of-the-art Transformer designs, which is a reasonable request for improvement. However, the comment does not provide specific examples or references to support the claim about the lack of comparison details, making it somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures, suggesting improvements in font size, clarity, and labeling. It also points out the need for more detailed comparisons with other state-of-the-art Transformer designs, recommending a table format to emphasize the data and justify the improved accuracy. This feedback is clear and constructive, offering the authors concrete steps to enhance the presentation and analysis of their work. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite a sentence that is unclear, providing a specific line number (p. 5, p. 3, l) for reference. This direct request leaves no ambiguity about what the authors need to do to improve their draft. The action is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific sentence that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a rewrite of the sentence, providing clear guidance on what needs to be improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the meaning of a specific sentence. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific sentence that is unclear, prompting the authors to rewrite it for clarity. This feedback is actionable and provides a clear direction for improvement, as it highlights a particular area where the authors can enhance the readability and understanding of their manuscript. By addressing this comment, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to rephrase the sentence. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the main contribution, noting that the performance gain is mostly attributed to PBSD. It questions the motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. However, the comment does not provide explicit guidance or suggestions on how the authors should clarify or address this issue. The action is implicit, as the authors need to infer that they should provide more detailed explanations or motivations for PBSD. Additionally, the comment lacks concrete steps or examples on how to improve the clarity of the main contribution. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically mentioning the ablation study and the performance gain from PBSD. It also questions the motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. However, the comment does not explicitly mention which section or part of the paper discusses the main contribution or PBSD, making it weakly grounded. The comment is specific in its inquiry about the motivations for PBSD, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the main contribution, specifically questioning the motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. The reviewer provides some support by referencing the ablation study, which suggests that the performance gain is mostly from PBSD. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the main contribution being unclear. While the mention of the ablation study provides some context, the comment is not fully verifiable due to the absence of explicit evidence or references. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the main contribution, specifically questioning the motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. It references the ablation study to highlight that the performance gain is mostly attributed to PBSD, which is a valuable observation. However, the comment lacks specific suggestions or guidance on how the authors might clarify or strengthen their contribution. While it points out an area for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the tester for the spread parameter immediately yields an (\\\\(\\\\epsilon, \\\\delta\\\\))-identity tester. It also asks how the tester handles (\\\\(\\\\pi, \\\\phi\\\\)) pairs where \\\\(\\\\phi = \\\\phi_0\\\\) but \\\\(d_K(\\\\pi_0, \\\\pi)\\\\) is large. While the comment highlights a potential issue, it does not provide explicit instructions or concrete suggestions on how the authors should address this concern. The authors are left to infer that they need to clarify or address the issue, but without specific guidance, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the tester for the spread parameter immediately yields an (\\\\(\\\\epsilon, \\\\delta\\\\))-identity tester and provides an example of how it might handle (\\\\(\\\\pi, \\\\phi\\\\)) pairs where \\\\(\\\\phi = \\\\phi_0\\\\) but \\\\(d_K(\\\\pi_0, \\\\pi)\\\\) is large. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the functionality of the tester for the spread parameter, specifically whether it immediately yields an (\\\\(\\\\epsilon, \\\\delta\\\\))-identity tester. The comment provides a specific example of how the tester might handle (\\\\(\\\\pi, \\\\phi\\\\)) pairs where \\\\(\\\\phi = \\\\phi_0\\\\) but \\\\(d_K(\\\\pi_0, \\\\pi)\\\\) is large. This example helps to clarify the issue and provides a basis for the question, making the claim somewhat verifiable. However, the comment could be strengthened by offering more detailed reasoning or references to similar cases in the literature. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the functionality of the tester for the spread parameter, specifically whether it immediately yields an (\\\\(\\\\epsilon, \\\\delta\\\\))-identity tester. It provides a specific example of how the tester might handle (\\\\(\\\\pi, \\\\phi\\\\)) pairs where \\\\(\\\\phi = \\\\phi_0\\\\) but \\\\(d_K(\\\\pi_0, \\\\pi)\\\\) is large. This feedback is somewhat helpful as it identifies a potential gap in the explanation or functionality of the tester, prompting the authors to clarify or address this issue. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or provided additional context or examples. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the authors\\' claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning and suggests that the description might mislead readers if it is not. While the comment implies that the authors should clarify the distinction between their method and traditional active learning, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning and suggests that the description might mislead readers if it is not. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its inquiry about the nature of the active learning method used, providing clear guidance on what needs to be clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about using active learning in step 2, suggesting that the \"active learning pipeline\" method might not be the same as traditional active learning. The comment raises a valid concern about potential misinterpretation by readers if the description is unclear. However, it lacks specific examples or references to clarify the distinction between the two methods, making it somewhat verifiable. The authors would need to further explore the issue to address the concern, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the clarity of the authors\\' claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning, which is a critical point for readers to understand the methodology. By highlighting this potential misinterpretation, the comment provides the authors with a clear area for improvement, prompting them to clarify their description to avoid misleading readers. However, the comment could be more helpful if it offered specific suggestions on how to clarify the description or provided examples of how to differentiate between the two methods. Overall, the comment is somewhat helpful as it identifies a specific issue and encourages the authors to address it, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It implies that a self-supervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation and suggests an alternative approach, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should explore a self-supervised pretraining approach, but the comment lacks detailed guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby restricting its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations, making it weakly grounded. The authors might infer that it relates to sections discussing the method or limitations, but this inference is not direct. The comment is specific in suggesting an alternative approach, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. The reviewer suggests that a self-supervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim about the necessity of annotated labels or the benefits of a self-supervised approach. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed method, specifically its reliance on annotated labels for learning semantic tokens, which restricts its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. This feedback is somewhat helpful as it highlights a potential area for improvement and offers a direction for enhancing the method\\'s applicability. However, the comment lacks specific guidance or suggestions on how to implement a self-supervised approach or what aspects of the current method could be adapted to achieve this. To be more helpful, the comment could include more detailed advice or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit and concrete actions for the authors to take. First, it suggests a specific wording change in the abstract to include a reference to the change in linear regions in output space. This provides clear guidance on how to improve the abstract. Second, it recommends including learning curves for all experiments, at least in an appendix, which is a specific and actionable suggestion. The authors know exactly what changes to make to improve their draft based on these comments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting a specific wording change in the abstract and recommending the inclusion of learning curves for all experiments, at least in an appendix. This level of detail provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a specific wording change in the abstract and recommends including learning curves for all experiments. The claim about the wording change is not supported by any evidence or reasoning, making it difficult for the authors to understand the necessity of the change. The suggestion for learning curves is more specific but lacks detailed justification or examples of how this would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks comprehensive support for the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two specific and actionable pieces of feedback. First, it suggests a precise wording change in the abstract to include a reference to the change in linear regions in output space, which would enhance the clarity and specificity of the abstract. Second, it recommends including learning curves for all experiments, at least in an appendix, which would provide a visual representation of the model\\'s performance over time. This additional information could help readers better understand the results and their implications. The comment is clear, constructive, and offers concrete suggestions for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the paper\\'s motivation and the application of the proposed method. It suggests that the authors should demonstrate the methodology\\'s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide examples or applications to clarify the motivation and utility of their work, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises concerns about the paper\\'s motivation and the applicability of the proposed method. It specifically mentions the domain adaptation aspect, suggesting that the authors demonstrate the methodology\\'s use on actual tasks involving domain adaptation. However, the comment does not explicitly mention which part of the paper it addresses, such as specific sections or experiments. The authors can infer that it relates to the introduction or discussion sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the motivation and application of the method. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation and application of the proposed method, noting a lack of clarity in the paper. It suggests that the authors demonstrate the methodology\\'s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment raises valid concerns about the paper\\'s applicability, it lacks specific examples or references to support the claim. The reasoning is somewhat verifiable, as it provides a logical suggestion for improvement, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clarity regarding its motivation and application. It points out that the proposed method\\'s utility is not clearly demonstrated, as it only shows results mapping one RGB image to another RGB image. The reviewer suggests that the paper would be more impactful if it demonstrated the methodology\\'s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, providing the authors with a specific direction to enhance the relevance and applicability of their work. However, it could be more helpful if it offered additional examples or guidance on how to effectively demonstrate the methodology\\'s utility. Overall, the comment is mostly helpful as it identifies a key area for improvement and provides a constructive suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a major issue with the experimental comparison, noting that the values of the used ranks for all models are omitted, making it impossible to conduct a fair comparison. It clearly states that the authors must compare the tensor completion results for all models with the same number of model parameters to demonstrate the superiority of TW over TT and TR. The reviewer provides a specific method for computing the number of model parameters, which is a concrete action for the authors to take. This feedback is explicit and provides detailed guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and the need for a fair comparison of tensor completion results for all models, including TW, TT, and TR. It specifies the issue of missing values for the used ranks, which is crucial for a fair comparison. Additionally, it provides a clear suggestion on how to address this issue by comparing models with the same number of model parameters. This level of detail and specificity allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison against other models in the experiments is unclear due to the omission of the values of the used ranks, which makes it impossible to conduct a fair comparison. The reviewer suggests that to demonstrate the superiority of TW over TT and TR, the authors should compare tensor completion results with the same number of model parameters. This claim is somewhat verifiable as it provides a logical reasoning for the need to include rank values for a fair comparison. However, it lacks specific examples or references to similar practices in the literature, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental comparison, noting that the values of the used ranks for all models are omitted, which makes it impossible to conduct a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all models with the same number of model parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and fairness of their experimental results. However, the comment could be more helpful if it included specific examples or further details on how to implement this suggestion. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include the ATA method in the comparison with the proposed method under the leave-one-out setting, as it is shown to be better than FP according to the results in Table 1. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the comparison. The comment is concrete, as it identifies a specific method to include and the rationale for doing so, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the ATA method in the comparison with the proposed method under the leave-one-out setting. This provides clear guidance on what the authors need to do to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to the ATA method in addition to \"+LFP\" under the leave-one-out setting. The claim is based on the observation that ATA is better than FP according to the results in Table 1. However, the comment does not provide specific details or references to substantiate why ATA is better or how it compares to \"+LFP\" in the context of Table 2. This lack of detailed justification makes the claim somewhat verifiable, as it provides a logical suggestion but lacks the necessary evidence or explanation to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave-one-out setting. It suggests that including the ATA method in the comparison would make the results more convincing, given that ATA is shown to be better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the robustness and credibility of their experimental results. By addressing this point, the authors can improve the comprehensiveness and validity of their comparisons, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the inconsistency in the normalization module between the two versions and the need for standardization in the pictograms used in the figures. It also mentions a specific issue with Figure 4, where the chosen symbols overlap in the 0/50 latency range and 2.5/4.0 MAE. Additionally, it points out minor textual issues, such as the need for standardization of the pictograms and a problem with the text after equation 4. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific changes needed to standardize the pictograms and resolve the overlapping symbols. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions specific figures (Fig. 4) and a specific page (pag. 4), allowing the authors to identify the parts of the paper being addressed. However, it does not specify which normalization module is different in the two versions, making it challenging for the authors to pinpoint the exact issue. The comment also mentions minor textual issues, but without specific examples or detailed guidance, it remains under-specific. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the normalization module being different in the two versions, despite appearing the same in the text. It suggests that figures are valuable for understanding system operations but notes a need for standardization in the pictograms. Additionally, it mentions a specific issue with Figure 4, where the chosen symbols overlap in the 0/50 latency range and 2.5/4.0 MAE. The comment provides specific examples and observations, which makes the claims mostly verifiable. However, it lacks detailed reasoning or references to support the assertion about the normalization module, which would strengthen the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including inconsistencies in the normalization module between the two versions, the need for standardization in the pictograms used in the figures, and specific problems with Figure 4, such as overlapping symbols in the 0/50 latency range and 2.5/4.0 MAE. Additionally, it points out minor textual issues, such as the need for standardization of the pictograms and a problem with the text after equation 4. While the comment highlights multiple areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it provides a general direction for improvement but could be more actionable with specific recommendations or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of detail in the theoretical part regarding how the proposed algorithm removes subdivision splines. It questions whether the algorithm requires additional computational cost for building space partitions. While the comment highlights an area that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more detail about the algorithm and its computational requirements. However, the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the author\\'s claim about the observation of subdivision splines and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding how the proposed algorithm removes subdivision splines and questioning whether it requires additional computational cost for space partition building. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made by the authors regarding the proposed algorithm\\'s ability to remove subdivision splines. It highlights a lack of detail in the theoretical part of the paper and raises a concern about potential additional computational costs. While the comment identifies a gap in the explanation, it does not provide specific examples or references to support the claim or suggest how the authors might address the issue. This makes the comment somewhat verifiable, as it points out a potential weakness but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim that subdivision splines are useful for decision boundaries but do not provide detailed information on how their proposed algorithm removes these splines. The comment raises a pertinent question about the potential computational cost associated with building space partitions. This feedback is clear and actionable, as it highlights a gap in the theoretical explanation and prompts the authors to address this issue. By doing so, the authors can improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to address the computational cost concern or provided examples of similar approaches. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the paper, including the lack of benefit from output-side layers, unclear illustration of Figure 4, and unclear presentation of Pixel-shuffle details. It also questions the use of pixel-shuffle in the super-resolution field and the dimensionality after upsampling in Figure 2. Additionally, it points out the absence of a discussion on limitations and potential negative societal impact. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Pixel-shuffle,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several detailed questions and observations about the clarity of Figure 4, the presentation of Pixel-shuffle details, and the use of pixel-shuffle in the super-resolution field. Additionally, it points out the lack of discussion on limitations and potential negative societal impact. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and observations about the paper, including the lack of clarity in Figure 4, the presentation of Pixel-shuffle details, and the use of pixel-shuffle in the super-resolution field. It also mentions the absence of a discussion on limitations and potential negative societal impact. These are factual observations and requests for clarification, not subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions and observations about the paper. It questions why the output-side layers do not benefit from the proposed method, and it points out that Figure 4 is not clearly illustrated. Additionally, it notes that the details of Pixel-shuffle are not clearly presented, questioning whether it is the same operation used in the super-resolution field. The comment also highlights the lack of discussion on limitations and potential negative societal impact of the work. While the comment identifies several areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it directs the authors to areas that need clarification and expansion, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, whether it provides an unfair advantage to the proposed method. While the comment highlights a potential issue, it does not provide explicit instructions or concrete suggestions on how to address it. The authors are left to infer that they need to clarify the experimental methodology and potentially address any potential unfair advantages. The action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the 300W-LP dataset in the experimental methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear issue regarding the clarity of the experimental methodology and questions whether the 300W-LP dataset is used in all experiments or just some. This specificity helps the authors understand what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, whether it provides an unfair advantage to the proposed method. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim of unfair advantage. The reasoning is based on logical inference, but without detailed evidence or comparisons, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, whether it provides an unfair advantage to the proposed method. This feedback is valuable as it highlights a potential flaw in the experimental design that could impact the validity of the results. However, the comment could be more helpful by suggesting how the authors might address this issue, such as providing a clear explanation of the dataset usage or conducting additional experiments to ensure fairness. Overall, the comment is somewhat helpful as it points out a significant area for improvement but lacks detailed guidance on how to resolve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It suggests that the data might be aggregated by other procedures, such as summation or population weighted average, which are more common in certain contexts. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1)\" and references specific works, such as \"[Law et al., NeurIPS\\'18]\" and \"[4],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation introduced by the authors, specifically the assumption that observations are obtained by averaging over the corresponding support. The comment further suggests that the data might be aggregated by other procedures, such as summation or population weighted average, which is a common practice in certain contexts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the formulation introduced by the authors assumes observations are obtained by averaging over the corresponding support, but this might not always be the case. The reviewer supports this claim by referencing specific works, such as [Law et al., NeurIPS\\'18] and [4], which discuss alternative aggregation processes like summation or population weighted average. This provides a clear and logical reasoning for the claim, making it fully verifiable. The inclusion of specific references and examples from the literature strengthens the argument, allowing the authors to understand and address the issue effectively.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It points out that this assumption might not always be valid, as data could be aggregated by other procedures such as summation or population weighted average. The comment also provides a relevant example from the context of disease incident data, which are often available in counts or rates per number of residents. This feedback is clear and actionable, as it highlights a specific area where the authors might need to reconsider or clarify their assumptions. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative formulations. Overall, the comment is mostly helpful, as it directs the authors to a critical aspect of their work that requires further consideration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of mathematical definition for architectural details, such as multi-head attention, and questions the use of a split arrow in Figure 2. It suggests that a formal definition would aid readers in understanding the model. While the comment implies that the authors should provide a formal definition, it does not explicitly instruct them to do so. The action is clear but communicated indirectly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right, bottom right,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mathematical definition for architectural details, such as multi-head attention, and questions the use of a split arrow in the figure. The comment provides specific questions about the inputs for the attention layer and requests a formal definition to aid understanding. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of mathematical definition for architectural details, such as multi-head attention, and seeks clarification about the use of a split arrow in Figure 2. The comment suggests that the split arrow might represent inputs for the attention layer, but it does not provide any evidence or references to support this interpretation. The claim is somewhat verifiable as it raises valid questions about the clarity of the figure and the need for a formal definition, but it lacks specific examples or references to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved: the lack of mathematical definition for architectural details, such as multi-head attention. It questions the use of a split arrow in Figure 2 and seeks clarification on whether the same vectors are used for keys and values. The comment provides a clear and actionable suggestion by recommending a formal definition to aid readers in understanding the model. This feedback is valuable as it directs the authors to enhance the clarity and comprehensibility of their work. However, it could be more helpful if it offered additional guidance on how to present the mathematical definitions or examples of similar approaches. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and provides a clear direction for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that each individual\\'s data is iid drawn from the same distribution, questioning the applicability of the \\\\(\\\\sqrt{m}\\\\) argument and the use of Theorem 6 to prove Theorem 7. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The comment highlights a potential problem but lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6\" and \"Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of iid data and how it affects the application of the \\\\(\\\\sqrt{m}\\\\) argument and theorems. The comment provides a clear rationale for why this assumption is problematic and suggests that it may not be justifiable in practice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the assumption that each individual\\'s data is iid drawn from the same distribution, suggesting that this assumption is unjustifiable in practice. The reviewer provides a logical reasoning by pointing out that the \\\\(\\\\sqrt{m}\\\\) argument and the application of Theorem 6 to prove Theorem 7 may not hold under this assumption. However, the comment lacks specific examples or references to support the claim that each user\\'s preferred emojis are indeed different. This makes the claim somewhat verifiable, as it provides a logical basis but requires further evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption that each individual\\'s data is iid drawn from the same distribution, which is crucial for the validity of the proposed algorithm. It questions the applicability of the \\\\(\\\\sqrt{m}\\\\) argument and the use of Theorem 6 to prove Theorem 7 under this assumption. The comment also provides a rationale for why this assumption might be unjustifiable in practice, as users\\' preferred emojis are likely to vary. This feedback is clear and actionable, as it highlights a critical assumption that may need to be addressed or justified in the paper. However, it could be more helpful if it offered suggestions on how to address this issue or alternative approaches to consider. Overall, the comment is mostly helpful, as it provides valuable insights into a potential weakness in the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider making the policy non-fixed to allow for more complex tasks, which would enable a comparison with a reinforcement learning algorithm baseline. While the comment implies a specific action\u2014adding a comparison with a reinforcement learning baseline\u2014it does not provide detailed guidance on how to implement this change or what specific tasks or algorithms should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes a comparison with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the sections discussing the policy or the experimental setup, but this inference is not direct. The comment is specific in suggesting a comparison with a reinforcement learning baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes a comparison with a reinforcement learning algorithm baseline. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the setting is a subset of reinforcement learning. Without such evidence or explanation, the claim remains vague and difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes a comparison with a reinforcement learning algorithm baseline. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a more comprehensive evaluation of the proposed method. However, the comment lacks specific guidance on how to implement this comparison or what aspects of the reinforcement learning baseline should be considered. While it provides a direction for enhancing the paper, it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the comprehensiveness of the analyses of the method and the experimental outcomes, noting that the authors\\' method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their analysis. The feedback lacks specificity and actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comprehensiveness of the analyses and experimental outcomes, specifically questioning the extent to which the performance improvement can be attributed to the authors\\' claim. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique, as it questions the attribution of performance improvement and highlights the need for more comprehensive analysis. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the comprehensiveness of the analyses and experimental outcomes, particularly in light of the authors\\' method underperforming the baseline in some instances. The comment suggests that the performance improvement attributed to the authors\\' claim may not be fully substantiated. However, the claim lacks specific examples or detailed reasoning to support the assertion that the analyses are insufficient. Without concrete evidence or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the comprehensiveness of the analyses and experimental outcomes presented in the paper. It highlights that the authors\\' method underperforms the baseline in some instances, questioning the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. This feedback is valuable as it points out a potential weakness in the paper\\'s claims and suggests that the authors need to provide a more thorough analysis to substantiate their assertions. However, the comment could be more helpful if it offered specific suggestions on how to enhance the analysis or provided examples of what additional information could be included. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area needing improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the literature review in the next section overlooks several relevant papers, specifically mentioning VR-MARINA for online problems from [1] and DASHA-MVR from [2]. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment implies that the authors should include these papers in their literature review to provide a more comprehensive overview. However, it does not explicitly instruct the authors to do so or provide detailed guidance on how to incorporate these references. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"next section\" and the \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of relevant papers VR-MARINA and DASHA-MVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear guidance on what the authors need to do to improve their literature review. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review in the next section overlooks several relevant papers, specifically mentioning VR-MARINA and DASHA-MVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide specific details or references to support these claims, such as how the papers satisfy Assumption 2 or what specific aspects make them better than QSGD. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further investigate the referenced papers to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the literature review, noting that it overlooks several relevant papers, including VR-MARINA and DASHA-MVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. By pointing out these omissions, the comment provides the authors with clear and actionable feedback on how to improve their literature review. However, the comment could be more helpful if it included specific details or examples from these papers to illustrate their relevance and contribution. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation of the paper is difficult to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors can improve the clarity or structure of their paper. Without explicit or implicit actions, the authors are left without direction on how to address the issue. The lack of actionable details makes it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which parts of the paper are problematic or what aspects make it hard to follow. Without specific references to sections, figures, or specific content, the authors cannot effectively identify the areas needing improvement. The lack of detail and specificity makes it difficult for the authors to address the issue, rendering the comment not grounded and highly unspecific. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is difficult to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the presentation of the paper is difficult to follow, which is a significant issue that the authors need to address. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might improve the clarity or structure of their paper. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance the readability of their work. Therefore, the comment is barely helpful, as it identifies a problem but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide a more detailed presentation of the compared models, specifically mentioning the differences between KVAE, DMM, and DVBF. It also asks for a comment on the computation requirements of the three methods listed in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is somewhat clear but lacks concrete guidance on how to present the additional details or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a more detailed presentation of the compared models, particularly highlighting the differences between KVAE, DMM, and DVBF. Additionally, it asks for a comment on the computation requirements of the three methods listed in Table 1. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the reviewer is not familiar with the compared models DMM and DVBF in detail but understands their differences with KVAE. The reviewer requests a more detailed presentation of the compared models and asks for a comment on the computation requirements of the three methods listed in Table 1. While the comment highlights a need for more detailed information, it does not provide specific reasoning or evidence to support the claim that the presentation is insufficient. The request for additional information is logical, but without further elaboration or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the reviewer\\'s lack of familiarity with the compared models DMM and DVBF but expresses a desire for a more detailed presentation of these models. It specifically notes that KVAE is simpler due to its linear state space transition but requires computation of time-dependent LGSSM parameters. The comment requests a comment on the computation requirements of the three methods compared in Table 1. This feedback is somewhat helpful as it identifies a need for more detailed information and prompts the authors to provide additional context or analysis. However, it could be more helpful if it offered specific suggestions on how to present this information or what aspects to focus on. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the action is implied, it is clear and concrete, as it specifies the type of experiments that should be conducted. The authors know exactly what additional experiments are needed to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments conducted on T5, PaLM, and GPT series LLMs, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that more experiments on different famous LLMs like LLaMA and Falcon are needed as benchmark baselines. This provides clear guidance on what additional experiments could be conducted to enhance the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more experiments on different famous LLMs like LLaMA and Falcon are needed as benchmark baselines. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would enhance the study. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experimental setup, noting that the authors have conducted experiments on T5, PaLM, and GPT series LLMs but suggest that more experiments on different famous LLMs like LLaMA and Falcon are needed as benchmark baselines. This feedback is clear and actionable, as it provides a specific direction for expanding the experimental scope to include additional models. However, the comment could be more helpful if it explained why these additional experiments are necessary or how they would enhance the study. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that in addition to the number of queries, the authors should compare the real search cost, such as in terms of GPU days, in Table 3. This comment provides a clear and explicit action for the authors to take, specifying exactly what additional information should be included in the table. The suggestion is concrete, as it outlines a specific metric to consider, making it highly actionable. The authors know exactly what needs to be done to improve their draft based on this feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This provides clear guidance on what additional information should be included in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. However, the comment does not provide any justification or reasoning for why this comparison is necessary or how it would improve the understanding of the results. Without supporting evidence or explanation, the claim is not verifiable, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an additional comparison in Table 3, specifically recommending the inclusion of real search cost metrics, such as GPU days, alongside the number of queries. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the comprehensiveness and depth of their analysis. By including real search cost metrics, the authors can offer a more detailed and meaningful comparison of their results, which could significantly improve the understanding and interpretation of their findings. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the conclusions drawn from the results. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific and explicit correction regarding the use of quotation marks in the phrase \"for 'in-between' uncertainty.\" It clearly instructs the authors to change the first quotation mark on \"in-between\" to a forward mark, rather than a backward mark. This feedback is precise and leaves no ambiguity about what needs to be corrected, making it highly actionable. The authors know exactly what change to make to improve their draft, ensuring a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"for \\'in-between\\' uncertainty,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the quotation marks, providing a precise correction for the authors to make. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the use of quotation marks in the phrase \"for \\'in-between\\' uncertainty.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a correction of a typographical error, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a precise and actionable correction regarding the use of quotation marks in the phrase \"for \\'in-between\\' uncertainty.\" By pointing out the incorrect placement of the quotation mark, the comment helps the authors improve the accuracy and clarity of their manuscript. This feedback is specific and directly addresses a minor but important detail, making it highly helpful for the authors to correct the error. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the content of the paper, specifically regarding the definition of Omega, the need for explicitness regarding OMD, the link function, and the reference to a theorem in [32]. While these questions imply that the authors should provide more detailed explanations or clarifications, they do not explicitly instruct the authors to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. However, the comment does provide some guidance on what needs to be clarified, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions about the content, such as the definition of Omega, the need for explicitness regarding OMD, the link function, and the reference to a theorem in [32]. These questions provide clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about specific elements of the paper, such as the definition of Omega, the need for explicitness regarding OMD, the link function, and the reference to a theorem in [32]. These questions do not contain subjective opinions, judgments, or suggestions that require verification. They are factual requests for clarification, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several specific questions about the content of the paper, particularly regarding the definition of Omega, the need for explicitness regarding OMD, the link function, and the reference to a theorem in [32]. These questions highlight areas where the authors can provide more clarity and detail in their manuscript. By addressing these points, the authors can improve the comprehensibility and rigor of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what explicitness might entail. Overall, the feedback is somewhat helpful as it identifies specific areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the usefulness of the sequence example in the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that this approach is not commonly used and requests references to support this claim. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular practice mentioned in Example 2, namely the use of the Hamming distance over entire parts of the sequence, and suggests that this approach is not commonly used. The comment further requests references to support this claim, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that this approach is not commonly used and requests references to support this claim. While the comment highlights a potential discrepancy, it lacks specific examples or references to substantiate the claim that the Hamming distance is not commonly used in this context. This makes the claim somewhat verifiable, as the authors would need to conduct additional research to address the comment fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the usefulness of the sequence example in the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer points out that this approach is not commonly used and requests references to support this claim. This feedback is somewhat helpful as it identifies a potential inconsistency or lack of clarity in the paper and suggests a specific area for improvement by asking for references. However, the comment could be more helpful if it provided additional context or examples of how this practice is typically used. Overall, the feedback is somewhat helpful as it directs the authors to clarify and substantiate their claims, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general meaning of \"evaluation.\" It also implies that the corresponding sections could be removed and the metrics mentioned briefly alongside the datasets or in the captions of the tables. While the comment provides a clear action to change the name, it lacks specific guidance on how to integrate the metrics into the text or what specific metrics should be mentioned. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and provides a rationale for this change, explaining that \"evaluation\" can have a more general meaning. It also suggests removing the corresponding sections and mentioning the metrics briefly alongside the datasets or in the captions of the tables. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the evaluation or metrics sections. The suggestion is specific, as it provides a clear action and rationale for the change. However, since the comment does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general meaning of \"evaluation.\" It also proposes removing the corresponding sections and mentioning the metrics briefly alongside the datasets or in the captions of the tables. The claim is somewhat verifiable as it provides a logical reasoning for the change, suggesting that the current naming might lead to confusion. However, the comment lacks specific examples or references to support the claim that the metrics are well-known and used as standard practice. This makes it challenging for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" explaining that \"evaluation\" can have a more general meaning. It also suggests removing the corresponding sections and mentioning the metrics briefly alongside the datasets or in the captions of the tables, as most of the metrics are well-known and used as standard practice. This feedback is constructive and offers a specific way to improve the clarity and organization of the paper, making it highly helpful for the authors. However, it could be further improved by providing examples of how to integrate the metrics into the text or suggesting specific metrics to mention. Overall, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It also provides a specific suggestion to avoid characterizing the improvement as \"remarkable\" due to the squished axes. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be changed in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"[218],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on using more objective terms instead of \"remarkable\" and explains why the characterization of the improvement as \"remarkable\" might be inappropriate due to the squished axes. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"remarkable\" is subjective and not appropriate for describing the accuracy improvement, as the axes are squished. The reviewer provides a logical reasoning by pointing out that the improvement is evident but may not be characterized as \"remarkable\" due to the visual representation. However, the comment lacks specific examples or references to support the claim that the term \"remarkable\" is inappropriate. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the term \"remarkable\" is subjective and not appropriate for describing the accuracy improvement. It offers a clear alternative by recommending the use of more objective terms. Additionally, the comment points out that the axes are squished, which could affect the perception of the improvement, and suggests that the characterization of the improvement as \"remarkable\" might be misleading. This feedback is constructive and helps the authors refine their language and presentation, making it mostly helpful. However, it could be further improved by suggesting alternative objective terms or providing more detailed guidance on how to present the data more accurately. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the paper\\'s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the state-of-the-art. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or changes to the methodology. As a result, the authors are left without any guidance on how to enhance their work based on this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the issue of short video sequences, specifically mentioning the UCF-101 dataset and the problems observed in the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. It suggests running the LSTM over many time steps to address these issues. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problems with the synthesized results and suggesting a potential solution, but without clear grounding, it is challenging for the authors to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the paper\\'s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the state-of-the-art. The reviewer provides specific examples of issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. However, the comment does not provide detailed reasoning or references to support these observations or suggest how the authors might address these issues. While the comment highlights areas for improvement, it lacks comprehensive justification or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the paper\\'s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the state-of-the-art. It highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time, and suggests running the LSTM over many time steps to address these problems. However, the comment does not provide specific guidance or actionable suggestions on how to improve the results or address these issues. While it acknowledges the paper\\'s strengths and weaknesses, it lacks depth and actionable feedback, making it somewhat helpful for the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data and that the comparison with a specific reference ([5]) is not fair due to the different complexity of the problems. However, it does not provide explicit guidance on how the authors should address these issues. The comment lacks specific suggestions, such as recommending additional evaluations on real data or suggesting ways to make the comparison more fair. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the numerical evaluation and its comparison with a specific reference ([5]), suggesting that the evaluation is not fully convincing due to the use of synthetic data and the unfair comparison with a method designed for a more complex problem. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison with [5], making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issues with the evaluation and comparison but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data and that the comparison with a specific reference ([5]) is not fair due to the different complexity of the problems. However, the comment lacks specific details or examples to support these claims, such as how the synthetic data affects the evaluation or how the complexity of the problems impacts the comparison. Without these details, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the numerical evaluation of the method, noting that it is only tested on synthetic data and that the comparison with a specific reference ([5]) is not fair due to the different complexity of the problems. This feedback highlights a potential weakness in the evaluation process and suggests that the authors should consider expanding their evaluation to include real data or more complex scenarios. However, the comment does not provide specific guidance on how to address these issues or suggest alternative approaches for a fairer comparison. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether studying the number of bits in logits helps against a larger epsilon in the PGD attack. While it suggests that this experiment could strengthen the paper, it does not explicitly instruct the authors to conduct this experiment. The action is implicit, as the authors need to infer that they should consider this study, and it is somewhat vague because it lacks specific guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the study of the number of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does provide some specificity by suggesting that such an experiment could strengthen the paper, but it lacks detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether the authors studied the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It does not express an opinion, claim, or suggestion that requires verification. The statement is factual and seeks clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about the potential impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that this experiment could strengthen the paper, providing a direction for further exploration. However, the comment lacks specific guidance or actionable steps for the authors to conduct this experiment or incorporate it into their paper. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any specific guidance or suggestions on how the authors might achieve this refinement or what aspects of the work could be improved. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to address the feedback. Since the action is implicit and vague, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the work could be refined. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the observed performance enhancements are modest, suggesting that there is room for further refinement. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without specific data or comparisons to other works, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment notes that the observed performance enhancements are modest, suggesting that there is room for further refinement in the future. However, it lacks specificity and does not provide any actionable guidance or suggestions on how the authors might achieve this refinement. Without detailed feedback or examples, the authors are left with a general observation but no clear direction for improvement. This limits the utility of the comment, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It instructs them to provide references for specific passages in Section 3.2 and to clarify what \"MLP\" is in Figure 2. These instructions are clear and directly guide the authors on what changes to make to improve their draft. The actions are specific and actionable, ensuring that the authors know exactly what steps to take to address the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections (Section 3.2, lines 230-234 and 234-235) and a figure (Figure 2), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing references for the passages mentioned and clarifying what \"MLP\" is in Figure 2. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and references, which are factual and descriptive in nature. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying sections of the paper that require references and clarification. It points out the need for references for two passages in Section 3.2 and asks for clarification on what \"MLP\" is in Figure 2. This feedback is clear and directs the authors to specific areas where they can improve the draft by providing necessary references and explanations. By addressing these points, the authors can enhance the credibility and completeness of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a discrepancy between Equation 9 and Figure 1, suggesting that the output patches may not be cropped parts of the input image but masked versions with most pixels black. It questions the correctness of this interpretation and notes that Figure 1 might be misleading. The reviewer also poses a question about whether bilinear sampling could provide better results. While the comment raises important questions and points out a potential issue, it does not provide explicit instructions or concrete suggestions for the authors to address the discrepancy or improve their work. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and consider alternative methods like bilinear sampling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the interpretation of the output patches in eq. 9 and the potential misleading nature of Figure 1. Additionally, it suggests an alternative approach using bilinear sampling. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about a discrepancy between Equation 9 and Figure 1, suggesting that the output patches may not be cropped parts of the input image but masked versions with most pixels black. The reviewer questions the correctness of this interpretation and notes that Figure 1 might be misleading. The comment provides a logical reasoning by contrasting the description in Equation 9 with the visual representation in Figure 1, which could help the authors understand the issue. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to further investigate the discrepancy themselves to fully address the concern, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It raises a critical point about the potential misleading nature of Figure 1 if the output patches are indeed masked versions of the input image. The comment also suggests an alternative approach using bilinear sampling, which could provide better results. This feedback is clear and actionable, as it directs the authors to clarify the discrepancy and consider an alternative method that could improve their work. However, it could be more helpful if it provided additional guidance on how to address the discrepancy or implement the suggested approach. Overall, the comment is mostly helpful, as it effectively highlights an important issue and offers a potential solution, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the statement about training time reduction should be deleted because it is not revisited in the Discussion section. The action is explicit, as it directly instructs the authors to delete the phrase \"Discussion\" from the sentence. However, the comment does not provide further guidance on why this change is necessary or how it might impact the overall structure of the paper. While the action is clear, the lack of additional context or explanation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pg.5\" and the specific phrase, \"The training time reduction is less drastic than the parameter reduction because most gradients are still computed for early down-sampling layers (Discussion).\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests revisiting the Discussion section and deleting the phrase \"Discussion\" to improve clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement about training time reduction, suggesting that it is not revisited in the Discussion section. The reviewer implies that the statement is incorrect or misleading, but does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that a statement about training time reduction is not revisited in the Discussion section. It suggests that the phrase \"Discussion\" should be deleted, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided additional context or explanation about why the statement is problematic or how its absence affects the overall discussion. Despite this, the feedback is somewhat helpful as it directs the authors to a specific area for improvement, even if it lacks depth. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment explicitly points out that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it instructs the authors to increase the font size in Figure 6 to improve readability. The authors know exactly what needs to be done to address this issue, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the font size in Figure 6 being too small. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable piece of feedback by pointing out that the font size in Figure 6 is too small. This is a clear and straightforward suggestion that the authors can easily implement to improve the readability of their figure. By addressing this issue, the authors can enhance the clarity and accessibility of their visual presentation, which is crucial for effective communication of their results. However, the comment could be more helpful if it included additional context or suggestions on how to adjust the font size or other aspects of the figure to improve its overall quality. Despite this, the feedback is mostly helpful as it directly addresses a specific issue that can be easily resolved, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. This implies that the authors should revise their examples to better illustrate the relevance of their work. While the suggestion is clear, it lacks specific guidance on how to implement this change or which examples to use. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the examples chosen do not convincingly demonstrate the need for a lot of inter-process communication, particularly regarding sampling-based Bayesian methods. The comment further suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the examples provided in the introduction do not convincingly demonstrate the need for a lot of inter-process communication, particularly regarding sampling-based Bayesian methods. The reviewer suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms. While the comment provides some reasoning by mentioning specific examples and suggesting an alternative focus, it lacks detailed justification or references to support the claim fully. The suggestion is somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the introduction, specifically regarding the goal of the paper and the relevance of the examples provided. It suggests that the examples chosen do not convincingly demonstrate the need for a lot of inter-process communication, particularly in the context of sampling-based Bayesian methods. The reviewer provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. This feedback is clear and actionable, offering the authors a concrete direction for improving the clarity and relevance of their work. However, it could be more helpful if it included additional guidance on how to implement this suggestion or why it would be beneficial. Overall, the comment is mostly helpful as it provides valuable insights and a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a lack of fairness in the comparison presented in Figure 3, specifically pointing out that the comparison between CPEF and PMEF is unjustified due to the absence of a pre-training module in PMEF. The reviewer suggests a specific action: comparing CPEF with another pre-trained model, such as ExpertBert, to highlight the advantages of the innovative pre-training module design of CPEF. This feedback provides a clear and concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and specific lines (529-534), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unfair comparison between CPEF and PMEF and suggests a specific alternative comparison with another pre-trained model, such as ExpertBert, to highlight the advantages of the pre-training module design of CPEF. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair due to the absence of a pre-training module in PMEF. The reviewer suggests a fairer comparison with another pre-trained model, such as ExpertBert, to highlight the advantages of CPEF\\'s pre-training module design. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the current comparison and suggests a specific alternative for a fairer comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current comparison is misleading. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison presented in Figure 3, noting that the advantages of CPEF are overstated due to the lack of a pre-training module in PMEF. It provides a clear and actionable suggestion to address this issue by recommending a comparison with another pre-trained model, such as ExpertBert, to highlight the advantages of CPEF\\'s innovative pre-training module design. This feedback is highly helpful as it offers a concrete step for the authors to improve the fairness and validity of their experimental comparisons, allowing them to enhance the credibility and impact of their findings.', 'helpfulness_label': '5'}"}
