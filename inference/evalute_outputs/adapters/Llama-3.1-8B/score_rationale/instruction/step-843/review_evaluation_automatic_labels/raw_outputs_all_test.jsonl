{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that min-max optimization is challenging, especially for PDEs with advective terms, and notes that the methodology provided by the authors appears to outperform the baselines. However, it suggests that the paper would benefit from a revision due to the lack of clarity in the presentation and the precise steps involved. While the comment implies that the authors should revise the paper, it does not provide specific guidance on how to improve the clarity or what aspects need revision. The action is implicit and vague, leaving the authors without clear direction on how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the authors\\' methodology, specifically mentioning the min-max optimization and its challenges, particularly for PDEs with advective terms. It acknowledges that the methodology performs better than the baselines but criticizes the lack of clarity in the presentation and the precise steps involved. However, the comment does not specify which sections or parts of the paper are lacking in clarity, making it difficult for the authors to pinpoint the exact areas needing revision. While the authors might have an idea of where these issues could be, the comment lacks full grounding. It is specific about the need for clarity but does not provide detailed guidance on how to achieve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that min-max optimization is challenging, especially for PDEs with advective terms, and suggests that the paper would benefit from a revision due to the lack of clarity in the presentation and the precise steps involved. However, the comment does not provide specific examples or detailed reasoning to support the claim that the methodology is challenging or unclear. The lack of explicit evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the challenges associated with min-max optimization, particularly for PDEs with advective terms, and notes that the methodology provided by the authors appears to outperform the baselines. However, it also points out a lack of clarity in the presentation and the precise steps involved, suggesting that the paper would benefit from a revision. While the comment identifies a potential area for improvement, it lacks specific guidance or actionable suggestions on how to enhance the clarity or presentation of the methodology. This limits the utility of the feedback for the authors, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical use of the modified TD learning algorithm defined in Definition 5.1 compared to the original proposal (Algorithm 1). While it highlights a potential area of confusion or discrepancy, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the rationale behind using the modified algorithm in practice, but it lacks concrete steps or recommendations for how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the practical use of the modified TD learning algorithm compared to the original proposal. This provides clear guidance on what aspect of the paper needs clarification or justification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the practical use of a modified TD learning algorithm compared to the original proposal. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the practical use of a modified TD learning algorithm compared to the original proposal. It highlights a potential discrepancy between the theoretical analysis and practical application, prompting the authors to clarify their rationale for using the modified algorithm. This feedback is valuable as it encourages the authors to provide a justification or explanation for their choice, which could enhance the clarity and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar decisions have been made in other works. Overall, the comment is somewhat helpful as it identifies a critical area for clarification but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It points out that the claim is not empirically validated, which is a significant concern given the emphasis on Task2Vec and model diversity. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest specific actions to validate the claim. The feedback implies that empirical validation is needed, but it lacks concrete instructions on how to proceed. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed guidance on how to implement the suggested action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It highlights a concern about the lack of empirical validation of this claim, which is a significant issue given the emphasis on Task2Vec and model diversity. However, the comment does not specify which part of the paper discusses the diversity coefficient or where the empirical validation should be included, making it weakly grounded. The comment is specific in identifying the issue of empirical validation but lacks grounding in terms of pinpointing the exact section or context where this issue arises. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper suggests the diversity coefficient as a potential data quality metric but does not empirically validate this claim. This is a significant concern, especially given the emphasis on Task2Vec and model diversity in the paper. The comment highlights the lack of empirical validation as a critical issue, providing a logical reasoning for the claim. However, it does not provide specific examples or references to support the need for empirical validation, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It points out that the claim is not empirically validated, which is a critical issue given the emphasis on Task2Vec and model diversity. This feedback is clear and actionable, as it highlights a specific area that needs further validation and empirical support. However, the comment could be more helpful if it provided suggestions on how to conduct the empirical validation or examples of similar approaches. Overall, the comment is mostly helpful as it directs the authors to a crucial aspect of their work that requires attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, it does not provide explicit guidance on how to address this issue or suggest specific actions to improve efficiency. The comment lacks concrete details on how to implement changes or what specific modifications should be made. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, it does not specify which part of the paper discusses the use of canary clients or examples, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency or resource allocation are being referred to. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that using canary clients is less efficient compared to using canary examples, suggesting that more resources might be needed. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or data to substantiate the assertion, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the efficiency of using canary clients compared to using canary examples, suggesting that more resources might be needed. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. Without detailed feedback or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the relevance of Carefl to the paper and suggests that it may be a standard definition of a nonlinear SEM, similar to what is shown in Equation (4) in another work. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the relevance of Carefl in their paper. The feedback lacks actionable steps or suggestions for improvement, leaving the authors uncertain about how to respond to this point. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (6)\" and references \"Equation (4) in \\\"On Causal Discovery with Cyclic Additive Noise Models,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the relevance of Carefl and suggesting that it may be a standard definition of a nonlinear SEM. This provides clear guidance on what needs to be addressed regarding the relevance and potential overlap with existing work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper, suggesting that it may be a standard definition of a nonlinear SEM. The reviewer provides a reference to Equation (4) in another work, \"On Causal Discovery with Cyclic Additive Noise Models,\" which supports the claim that Carefl is a standard definition. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the paper itself to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the relevance of Carefl to the paper, questioning whether it is a standard definition of a nonlinear SEM. It references another work, \"On Causal Discovery with Cyclic Additive Noise Models,\" to support the claim that Carefl may not be unique to the paper. This feedback is somewhat helpful as it prompts the authors to clarify the novelty and relevance of Carefl in their work. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative ways to highlight the contribution of Carefl. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the approach, noting that it is compute-intensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the approach. The feedback lacks actionable details, such as recommending ways to mitigate the compute-intensive nature of the approach or suggesting alternative methods to ensure the GAA model's performance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the compute-intensive nature of the approach, particularly regarding the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could impact annotation times. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the approach and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the compute-intensive nature of the approach, specifically regarding the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim. The authors would need to further explore and substantiate the assumptions themselves. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires additional evidence or examples for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach, specifically its compute-intensive nature due to the need for pretraining the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. This feedback highlights a critical aspect of the methodology that could impact the claimed speedup of the proposed approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential problems. While it points out an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, noting its high dependence on the server dataset, which significantly reduces its potential use cases and generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method\\'s applicability. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed method, specifically its high dependence on the server dataset, which significantly reduces its potential use cases and generality. However, it does not specify which part of the paper discusses the proposed method or where this limitation is addressed, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the method is discussed, the comment lacks full grounding. It is specific about the limitation but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, it is difficult for the authors to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, specifically its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. This feedback is valuable as it highlights a critical area that the authors need to address to improve the applicability and impact of their work. However, the comment does not provide specific suggestions or guidance on how the authors might mitigate this limitation or enhance the method\\'s versatility. While it points out an important issue, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the choice of using only a single downstream search method (EA) and suggests adding other methods like BO and LS. This feedback implies that the authors should consider including additional methods to enhance the comprehensiveness of their study. While the action is not explicitly stated, it is clear and concrete, as it specifies which additional methods should be considered. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment questions the choice of using only a single downstream search method (EA) and suggests adding other methods like BO and LS. However, it does not specify which part of the paper this critique is based on, such as a particular section or table where the methods are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using only a single downstream search method (EA) and suggests adding other methods like BO and LS. However, the comment does not provide any justification or reasoning for why these additional methods would be beneficial or necessary. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of using only a single downstream search method (EA) and suggests adding other methods like BO and LS. This feedback is somewhat helpful as it points out a potential limitation in the experimental setup and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why the inclusion of additional methods would be beneficial or how it would impact the study\\'s conclusions. Overall, the comment provides some direction for enhancing the draft but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the comparison of FLOPs and FPS in sparse network research. It points out that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback provides a clear and explicit action for the authors to take: include a direct comparison of FLOPs and FPS with other sparse models. The comment is specific and provides a concrete step for the authors to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of a direct comparison of FLOPs and FPS with other sparse models. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. The comment suggests that a direct comparison with other sparse models is missing. While the claim is based on the observation that FLOPs are listed, it lacks specific examples or references to other sparse models that should be compared. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that while FLOPs and FPS are critical in sparse network research, the paper does not sufficiently highlight a comparison with other sparse models. It points out that although FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their draft by including a direct comparison of FLOPs and FPS with other sparse models. However, the comment could be more helpful if it offered specific examples of models to compare against or suggested how to present this comparison effectively. Overall, the comment is mostly helpful, as it directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the metrics used in the paper, noting that they are difficult to understand and unclear in the result tables. It provides an example of how the accuracy metric for binary boolean questions is calculated and points out that reversing the prediction of Dolly-V2-7B would yield an accuracy of 97%, which is clearly wrong. This feedback is explicit and provides a concrete example of how the authors can improve their draft by clarifying the metrics used in the results. The authors are given a clear direction on how to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are difficult to understand and that the numbers in the result tables are unclear. The comment provides a specific example of how the accuracy metric is calculated and points out the incorrect interpretation that could arise from it. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics used in the paper are difficult to understand, leading to unclear results. The reviewer provides a specific example by explaining that reversing the prediction of Dolly-V2-7B would yield an accuracy of 97%, which is clearly wrong. This example provides a concrete illustration of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to standard practices in the field, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity and interpretation of the metrics used in the paper. It highlights that the metrics are difficult to understand, which leads to confusion in the result tables. The comment provides a specific example by explaining that reversing the prediction of Dolly-V2-7B would yield an accuracy of 97%, which is clearly incorrect. This feedback is actionable as it directs the authors to clarify their metrics and ensure that the results are accurately interpreted. By addressing this issue, the authors can improve the transparency and reliability of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the Gaussian assumption and its applicability in practice. It asks whether the situation where r << N is typical, whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in non-ideal cases. While these questions imply that the authors should address these points in their paper, they do not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional analysis or discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption and its applicability in practice, specifically asking whether the situation where r << N is typical, whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in non-ideal cases. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the Gaussian assumption and its implications, but without clear grounding, the authors may struggle to identify where these questions should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and further exploration of the Gaussian assumption. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the Gaussian assumption and its applicability in practice. It asks whether the situation where r << N is typical, whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in non-ideal cases. These questions prompt the authors to consider the practical implications of their assumptions and to explore potential limitations or extensions of their analysis. However, the comment does not provide specific suggestions or guidance on how to address these questions, which limits its helpfulness. While it identifies areas for further exploration, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the approach to the math and science categories, suggesting that an open vocabulary problem is not clearly addressed. However, it does not provide specific guidance on how the authors should tackle this problem or what changes should be made to improve the approach. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to address the issue. As a result, the comment is vague and lacks actionable details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that there is an open vocabulary problem in the approach to the math and science categories, which is not clearly addressed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the issue of an open vocabulary problem and how it is tackled for other categories, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is an open vocabulary problem in the approach to the math and science categories, which is not clearly addressed. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of tackling this issue via Wikipedia and a popularity metric for other categories is vague and lacks sufficient evidence or explanation. As a result, the claim is not well-supported, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach to the math and science categories, suggesting that there is an open vocabulary problem that is not clearly addressed. It contrasts this with the approach to other categories, which is tackled via Wikipedia and a popularity metric. While the comment highlights a specific area of concern, it lacks detailed guidance or suggestions on how the authors might address the open vocabulary problem or improve their approach. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional context or actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the similarity between the current work and stochastic routing, at a more fundamental level, warrants a more thorough discussion. However, it does not provide explicit guidance on how to conduct this discussion or what specific aspects should be explored. The action is implicit and vague, as the authors are left to infer that they need to expand on the discussion but without concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that there is a similarity between the current work and stochastic routing, which warrants a more thorough discussion. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting that a more detailed discussion is needed, but without clear guidance on where to incorporate this discussion, the authors may struggle to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the similarity between the current work and stochastic routing, at a more fundamental level, warrants a more thorough discussion. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that the similarity between the current work and stochastic routing, at a more fundamental level, warrants a more thorough discussion. While it identifies an area that could be expanded upon, it lacks specific guidance or suggestions on how to conduct this discussion or what aspects should be explored. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to the exponential nature of the problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their draft. The comment lacks concrete details on how to implement the suggested action, leaving the authors uncertain about the exact steps to take. As a result, the comment is vague and implies an action but does not provide clear instructions, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests considering convergence in direction as convergence, given the nature of the CE loss. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where convergence is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding how this suggestion should be implemented or why it is necessary. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence due to the nature of the CE loss, which cannot be minimized because of the exponential. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples, references, or detailed explanations to justify why convergence in direction should be considered as convergence. This makes the claim borderline verifiable, as it provides a general idea but lacks the necessary detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss. However, it lacks specificity and does not provide detailed reasoning or examples to support this claim. Without further elaboration or guidance on how this suggestion could be implemented or why it is important, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable advice or detailed guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim flexibility in component replacement but did not attempt any changes or alternatives in the paper to demonstrate the robustness of the proposed framework. While the comment highlights a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The feedback implies that the authors should test the robustness of their framework by experimenting with component replacements, but it lacks concrete instructions on how to proceed. As a result, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim of flexibility in component replacement and questions the lack of experimentation to demonstrate the robustness of the proposed framework. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the need for experimentation to prove robustness, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not attempt any changes or alternatives to demonstrate the robustness of the proposed framework, despite stating that components can be replaced for flexibility. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s experimental validation. However, it lacks specific examples or references to support the assertion that the lack of experimentation undermines the framework\\'s robustness. Providing more detailed evidence or examples would strengthen the claim, making it easier for the authors to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential weakness in the paper, noting that while the authors claim flexibility in component replacement, they did not attempt any changes or alternatives to demonstrate the robustness of their proposed framework. This feedback highlights an area where the paper could be improved by including experiments or analyses to validate the flexibility and robustness claims. However, the comment lacks specific suggestions or guidance on how the authors might conduct these experiments or what aspects to focus on. While it provides some insight into an area needing attention, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it identifies a potential weakness but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be challenging to specify this number for an arbitrary domain. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their methodology. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to enhance their draft. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of 30 disentangled factors and suggests that this might be challenging to specify for an arbitrary domain. This provides clear guidance on what aspect of the methodology needs clarification or justification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of 30 disentangled factors in the Atari game experiments. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of 30 disentangled factors in the Atari game experiments, questioning the rationale behind this decision. It highlights a potential area of concern regarding the generalizability of this choice across different domains. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential weakness, it lacks actionable feedback that would help the authors make improvements to their draft. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a relevant aspect of their work but does not fully support them in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the use of colloquial expressions, such as \"By the way,\" which are considered unprofessional. This feedback provides a clear and direct action for the authors to take, which is to remove or revise such expressions to maintain a more formal tone in their writing. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific example, \"By the way,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of colloquial expressions, which are considered unprofessional. This provides clear guidance on what needs to be revised in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"colloquial expressions are unprofessional\" and provides an example, \"By the way, our training stage \u2026 \u2026\". However, it does not offer any supporting evidence or references to justify why this expression is considered unprofessional. The comment lacks detailed reasoning or examples that would help the authors understand the issue or how to address it. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of colloquial expressions in the paper, which are considered unprofessional. It provides a clear example, \"By the way, our training stage \u2026 \u2026\", allowing the authors to understand the exact expression that needs to be revised. This feedback is actionable and provides a straightforward way for the authors to improve the professionalism of their writing. However, the comment could be more helpful if it offered suggestions on how to replace such expressions with more formal alternatives. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are not defined in the paper, which is crucial for understanding the content. The reviewer highlights the importance of these abbreviations, especially \"ECE,\" which is a pivotal metric in the work. This feedback provides a clear and direct action for the authors to define these abbreviations or provide explanations for them. The comment is specific and actionable, as it guides the authors on exactly what needs to be done to improve the clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abbreviations \"LLH,\" \"OOD,\" and \"ECE,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of undefined abbreviations and the importance of these abbreviations in the context of the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights the lack of definition for the abbreviations \"LLH,\" \"OOD,\" and \"ECE,\" which are crucial for understanding the paper. The comment provides a clear and specific observation about the absence of definitions, making it mostly verifiable. However, it could be further strengthened by suggesting where these definitions should be included or by providing examples of how these abbreviations are used in the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of definitions for important abbreviations such as \"LLH,\" \"OOD,\" and \"ECE.\" These abbreviations are pivotal in the context of the paper, yet they are not defined, making it difficult for readers to understand the content. The comment highlights the importance of these abbreviations and the need for clarity in the paper. By pointing out this oversight, the comment provides actionable feedback that can help the authors improve the clarity and accessibility of their work. However, the comment could be more helpful if it suggested where these definitions should be included or provided examples of how to define them. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure in stochastic/random projection increases. It suggests that the authors should justify the stability of their method and inquire about the impact of stacking more layers. While the comment implies that the authors should address these concerns, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the stability of the proposed method when stacking multiple layers of WLS units, particularly regarding the probability of failure in stochastic/random projection. It suggests that the authors should justify the stability of their method and inquire about the impact of stacking more layers. However, the comment does not explicitly mention which part of the paper discusses the stacking of layers or the stability of the method, making it weakly grounded. The comment is specific in detailing the issue and suggesting a potential solution, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure in stochastic/random projection increases. The reviewer provides a logical reasoning by explaining how the probability of failure could affect the scenario of the proposed method forming deeper GNNs. However, the comment lacks specific examples, references, or detailed explanations to fully substantiate the claim. While the reasoning is sound, the absence of additional evidence or references makes the claim somewhat verifiable, as the authors would need to further explore and justify the stability themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units, particularly regarding the probability of failure in stochastic/random projection. It suggests that the authors should justify the stability of their method and inquire about the impact of stacking more layers. This feedback is clear and actionable, as it prompts the authors to address a potential limitation of their approach and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these concerns. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and encourages the authors to provide additional justification and analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment identifies a specific issue with the clarity of the paper, particularly in the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide any guidance or suggestions on how the authors might improve this clarity or what specific aspects need to be addressed. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to proceed. Without explicit instructions or concrete steps, the authors may struggle to determine what changes are needed to enhance the clarity of this section. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the clarity of the paper, particularly in the computation of the Bottleneck Distance in Definition 4.1. This makes the comment fully grounded, as it clearly points to a specific section of the paper where the issue is located. However, it lacks specificity because it does not detail what aspects of the computation are unclear or how they could be improved. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that \"some sections of the paper lack clarity,\" specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, it is difficult for the authors to understand the exact nature of the lack of clarity or how it could be addressed. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the clarity of the paper, particularly in the computation of the Bottleneck Distance in Definition 4.1. This feedback is somewhat helpful as it points out a particular area where the authors need to improve their draft. However, it lacks depth and does not provide specific suggestions or guidance on how to enhance the clarity of this section. Without detailed advice, the authors may struggle to effectively address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the visualization in the paper, specifically Figure 5, is weaker compared to Balikas COLING16\\'s work. It implies that the authors should provide a longer exemplar and ensure consistent color assignment with the topics listed in Figure 4 to make the results more convincing. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes, such as what specific aspects of the visualization need improvement or how to ensure consistent color assignment. The action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the visualization, noting that it is weaker compared to Balikas COLING16\\'s work and suggesting improvements, such as providing a longer exemplar and ensuring consistent color assignment with the topics listed in Figure 4. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s visualization, specifically Figure 5, is weaker compared to Balikas COLING16\\'s work, which raises doubts about the actual segmenting and assigning results of documents. The reviewer suggests that providing a longer exemplar and ensuring consistent color assignment with the topics listed in Figure 4 would make the results more convincing. While the comment provides a logical basis for the claim by comparing it to a specific work, it lacks detailed examples or references to substantiate the claim fully. The suggestion for improvement is clear, but the justification could be strengthened with more specific evidence or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s visualization, particularly Figure 5, which is weaker compared to Balikas COLING16\\'s work. It suggests that this weakness affects the credibility of the segmenting and assigning results of documents. The comment provides a clear and actionable suggestion to improve the visualization by offering a longer exemplar and ensuring consistent color assignment with the topics listed in Figure 4. This feedback is constructive and offers a concrete way for the authors to enhance the clarity and persuasiveness of their results. However, it could be more helpful if it included specific examples of how to improve the visualization or what aspects need the most attention. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of P5-small as the backbone model and expresses confusion about the necessity of using a parameter-efficient training method. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending alternative models or explaining why parameter-efficient training might be beneficial. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"P5-small\" as the backbone model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of using a parameter-efficient training method with a small model like P5-small. This provides clear guidance on what aspect of the methodology is being questioned. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of using P5-small as the backbone model and expresses confusion about the necessity of using a parameter-efficient training method. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using P5-small as the backbone model and questions the necessity of using a parameter-efficient training method. While it identifies a potential area of confusion or concern, it does not provide any suggestions or guidance on how the authors might address this issue or clarify their methodology. The comment lacks actionable feedback or specific advice that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential issue but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the authors aim to propose a way to create a challenging set, but it describes the approach as specific and not scalable. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the scalability of their approach. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their proposal. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the authors\\' approach to creating a challenging set, describing it as specific and not scalable. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the approach are considered specific or unscalable. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors aim to propose a way to create a challenging set, but it describes the approach as specific and not scalable. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate why the approach is considered specific or unscalable. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the authors\\' approach, noting that it seems specific and not scalable. However, it lacks specificity and actionable guidance on how the authors might address this concern or improve the scalability of their method. Without detailed suggestions or examples, the authors are left with a general critique but no clear path for improvement. This limits the utility of the feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential weakness in the proposed method, noting its reliance on an optimal value function corresponding to a reward function. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this reliance. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the proposed method, specifically its reliance on an optimal value function corresponding to a reward function. However, it does not specify which part of the paper this reliance is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the method\\'s reliance, but without clear grounding, the authors may struggle to pinpoint where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method relies heavily on an optimal value function corresponding to a reward function. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the proposed method, specifically its reliance on an optimal value function corresponding to a reward function. This observation could be valuable for the authors to consider, as it highlights a critical aspect of their approach that may need further exploration or justification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, and states that this is not a problem if the derivative approach works. However, it does not provide any specific guidance or suggestions on how the authors might improve their approach or address any potential issues related to its derivative nature. The comment lacks actionable details, such as recommending ways to enhance the originality or suggesting improvements to the derivative approach. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the approach as derivative, combining two existing approaches, but does not specify which parts of the paper this assessment is based on. It lacks grounding as it does not refer to specific sections, figures, or tables, making it difficult for the authors to identify the exact parts of the paper being addressed. Additionally, the comment does not provide specific guidance on how the authors might address the issue of being derivative or improve the originality of their work. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the approach is derivative, combining two existing approaches. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper\\'s contribution. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, and states that this is not a problem if the derivative approach works. However, it does not provide any constructive feedback or suggestions on how the authors might enhance their approach or address any potential issues related to its derivative nature. Without actionable advice or specific guidance, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of comparisons against other potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method as a potential alternative. While the comment highlights a gap in the evaluation, it does not explicitly instruct the authors to include these comparisons or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should add comparisons and determine which baseline approaches to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of comparisons against other potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method as a potential alternative. However, it does not specify which part of the paper or results section this critique is based on, making it weakly grounded. The comment is specific in its suggestion to include comparisons with other approaches, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no comparisons against other potential baseline approaches in the evaluation, suggesting that a simple photographic style transfer method might achieve similar or better results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the comparison or how to address it. The absence of detailed reasoning or evidence results in the claim being borderline verifiable, as it provides some insight but lacks sufficient support for the authors to fully understand and address the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation section of the paper, specifically the lack of comparisons against other potential baseline approaches. It suggests that a simple photographic style transfer method might achieve similar or better results, which is a valuable insight for the authors to consider. However, the comment does not provide specific guidance on how to incorporate these comparisons or which other methods to consider, leaving the authors with a general direction but without detailed, actionable steps. While it highlights an important area for improvement, the feedback could be more helpful with additional suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the symbols used in Figure 2 and their relationship to the equations and main context. It points out that the authors did not explain the meaning of certain symbols (e.g., C_i, Q_i, R_i, A_i, and S_i) in the main context, making it difficult to understand the proposed method. The reviewer also notes a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, and questions how to compute S_i. This feedback provides explicit actions for the authors to take, such as explaining the symbols and their meanings, and addressing the discrepancy in notation. The comment is clear and provides concrete guidance on how to improve the clarity of the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and specific symbols like \"C_0, C_1, etc.,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the symbols in Figure 2, such as the lack of explanation for C_i, Q_i, R_i, and A_i, and the discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431. The comment provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue with the clarity of symbols in Figure 2 and their relationship to the equations and main context. It provides examples of symbols (C_i, Q_i, R_i, A_i, and S_i) that are not explained, making it difficult to understand the proposed method. The comment also points out a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, questioning how to compute S_i. This detailed critique is mostly verifiable as it identifies specific areas of confusion and provides examples, but it could be further strengthened by suggesting how the authors might clarify these symbols or by referencing similar issues in other works. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the paper, specifically regarding the symbols used in Figure 2 and their relationship to the equations and main context. It points out that the authors did not explain the meaning of certain symbols (e.g., C_i, Q_i, R_i, A_i, and S_i), which makes it difficult to understand the proposed method. Additionally, the comment highlights a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, questioning how to compute S_i. This feedback is clear and actionable, as it provides specific areas where the authors need to clarify their explanations and notation. By addressing these issues, the authors can significantly improve the clarity and comprehensibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study additional parameters, such as the number of backtracking steps and the acceptance rate, in addition to the hyper-parameter $I$. It implies that these parameters should be analyzed to understand their impact on the results. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for further exploration. The action is concrete, as it specifies the parameters to focus on, but it is communicated implicitly. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests studying additional parameters, such as the number of backtracking steps and the acceptance rate, in addition to the hyper-parameter $I$. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in detailing what additional parameters should be studied and why, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study additional parameters, such as the number of backtracking steps and the acceptance rate, in addition to the hyper-parameter $I$. However, the comment does not provide any supporting evidence or reasoning to justify why these parameters are important or how they might impact the results. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the necessity of these additional studies. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should study additional parameters, such as the number of backtracking steps and the acceptance rate, in addition to the hyper-parameter $I$. It questions how much tuning these parameters required to achieve the reported results. This feedback is clear and actionable, as it provides a specific direction for further analysis and exploration. By addressing this point, the authors could gain a deeper understanding of the factors contributing to their results, which could lead to improvements in their methodology or interpretation. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what to look for in the results. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the objective function for GSdyn and FABOLAS, specifically asking whether the accuracy on the validation dataset or on the test dataset is the objective function. This comment implies that the authors should clarify which accuracy is used as the objective function. While the action is not explicitly stated, it is clear and concrete, as it directs the authors to specify the objective function in their paper. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the objective function for GSdyn and FABOLAS and asking which accuracy is used as the objective function. This provides clear guidance on what needs to be clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the objective function for GSdyn and FABOLAS. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the objective function for GSdyn and FABOLAS, asking whether the accuracy on the validation dataset or on the test dataset is used as the objective function. This is a clear and actionable piece of feedback, as it prompts the authors to clarify an important aspect of their methodology. By addressing this question, the authors can improve the clarity and transparency of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information in the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests reorganizing the paper by moving section 3.1 to the related work section and making section 3.2 the new section 3, which would allow for a more appropriate split. This feedback provides a clear and explicit action for the authors to take, specifying exactly how to restructure the paper to improve its organization. The suggestion is concrete, as it outlines a specific change that can be implemented to enhance the paper\\'s structure. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests reorganizing the paper by moving section 3.1 to the related work section and making section 3.2 the new section 3. However, it does not specify which part of the paper is being addressed, such as the exact sections or subsections that need to be moved. This lack of explicit reference makes it difficult for the authors to pinpoint the exact parts of the paper being discussed. Additionally, while the suggestion to reorganize the sections is provided, it lacks specificity regarding why this reorganization would be beneficial or how it would improve the paper. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests reorganizing the paper by moving section 3.1 to the related work section and making section 3.2 the new section 3. However, it does not provide any justification or reasoning for why this reorganization would be beneficial or necessary. The comment lacks supporting evidence or explanation, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests reorganizing the paper by moving section 3.1 to the related work section and making section 3.2 the new section 3. This feedback provides a clear and actionable suggestion for improving the structure of the paper, which could enhance its readability and clarity. However, the comment lacks further explanation or justification for why this reorganization would be beneficial, such as how it might improve the flow or focus of the paper. While the suggestion is helpful in terms of providing a specific structural change, it could be more comprehensive with additional context or rationale. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the efficiency of obtaining the priors and asks for examples. It also suggests that the authors may not have a practical way to obtain the required prior {$U_{k_n}$}. While the comment implies that the authors should provide examples or a practical method for obtaining the priors, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the efficiency of obtaining priors and requests examples, as well as questioning the practicality of obtaining the required prior {$U_{k_n}$}. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and an observation about the practicality of obtaining the required prior {$U_{k_n}$}. It does not contain any subjective claims, opinions, or suggestions that require verification. The statement is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the efficiency of obtaining the priors mentioned in the paper. It specifically asks for examples and expresses concern about the lack of a practical method for obtaining the required prior {$U_{k_n}$}. This feedback is clear and actionable, as it prompts the authors to address a potential weakness in their methodology by providing examples or a practical approach to obtaining the priors. However, the comment could be more helpful if it offered suggestions or guidance on how to address this issue. Overall, the comment is mostly helpful as it identifies a key area for improvement and encourages the authors to provide more detail, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should perform additional evaluation on the VOT dataset to compare the methods using different metrics like Accuracy, Robustness, and EAO. This feedback provides a clear and explicit action for the authors to take, specifying the additional evaluation that is needed. The comment is concrete, as it outlines specific metrics to consider and the dataset to use for the evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the datasets (OTB-50, OTB-100, OTB-2015, and LASOT) and the metrics (AUC and precision) used for evaluation. It also suggests an additional evaluation on the VOT dataset using different metrics like Accuracy, Robustness, and EAO. This provides clear guidance on what needs to be addressed and where, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare methods using different metrics like Accuracy, Robustness, and EAO. The claim is based on the observation that existing benchmarks evaluate competing methods using AUC and precision metrics. This reasoning is logical and provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or benchmarks that use these additional metrics, which would provide a more robust justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to perform additional evaluation on the VOT dataset, using different metrics like Accuracy, Robustness, and EAO. This feedback is helpful as it identifies a specific area for improvement and offers a concrete suggestion for expanding the evaluation of the proposed framework. By suggesting alternative metrics, the comment guides the authors on how to enhance the comprehensiveness and robustness of their evaluation, which can significantly improve the paper. However, the comment could be more helpful if it provided additional context or rationale for why these metrics are important or how they might impact the evaluation. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that the method is not compared to any state-of-the-art unsupervised semantic segmentation techniques, despite claims of comparable performance to supervised semantic segmentation. The reviewer explicitly states that the paper does not report the performance of state-of-the-art supervised or unsupervised segmentation methods. This feedback provides a clear and direct action for the authors to take, which is to include comparisons with state-of-the-art methods in their evaluation. However, it does not specify which specific methods should be considered or how to conduct these comparisons, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of comparison with state-of-the-art unsupervised semantic segmentation techniques, despite claims of comparable performance to supervised semantic segmentation. It points out that the paper does not report the performance of state-of-the-art supervised or unsupervised segmentation methods. However, the comment does not specify which part of the paper this issue pertains to, such as the results or discussion sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed, namely the inclusion of state-of-the-art comparisons. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison with state-of-the-art unsupervised semantic segmentation techniques, despite claims of comparable performance to supervised semantic segmentation. The reviewer points out that the paper does not report the performance of state-of-the-art supervised or unsupervised segmentation methods. This claim is somewhat verifiable as it highlights a gap in the evaluation process, but it lacks specific examples or references to state-of-the-art methods that should be included. Providing such examples or references would strengthen the claim, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of comparison with state-of-the-art unsupervised semantic segmentation techniques. It points out that the paper claims comparable performance to supervised semantic segmentation but does not report the performance of state-of-the-art supervised or unsupervised segmentation methods. This feedback is clear and actionable, as it highlights a critical area for improvement that the authors need to address to strengthen their work. However, the comment could be more helpful if it suggested specific state-of-the-art methods to consider or provided guidance on how to conduct these comparisons. Overall, the comment is mostly helpful, as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses uncertainty about the clarity of the first curve-finding part in explaining the FGE work. It suggests that the cyclical learning rate scheduling may perturb the weight around the initial converged weight but does not guarantee that the weight changes along the curve described. However, the comment does not provide specific guidance or suggestions on how the authors could improve the explanation or address the issue. The feedback lacks explicit instructions or concrete details on how to enhance the clarity or effectiveness of the explanation, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the first curve-finding part of the paper, which is specific, allowing the authors to identify the part being discussed. However, it lacks specificity in detailing what exactly is unclear or how the explanation could be improved. The comment mentions the cyclical learning rate scheduling and its potential impact on weight changes, but it does not provide specific guidance or examples on how to clarify the explanation. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the clarity of the first curve-finding part in explaining the FGE work. It provides a logical reasoning that the cyclical learning rate scheduling may perturb the weight around the initial converged weight, but it does not guarantee that the weight changes along the curve described. However, the comment lacks specific examples or references to support this reasoning, making it somewhat verifiable. The authors would need to further explore the explanation themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment expresses uncertainty about the clarity of the first curve-finding part in explaining the FGE work. It suggests that the cyclical learning rate scheduling may perturb the weight around the initial converged weight, but it does not guarantee that the weight changes along the curve described. However, the comment lacks specific suggestions or guidance on how the authors could improve the explanation or address the issue. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should present a case study, ideally with synthetic datasets, to demonstrate when a distillation strategy is beneficial. It also questions the performance of specific methods in Table 3 and asks for more reasoning or hypotheses. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the case study or what aspects to focus on. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests presenting a case study with synthetic datasets to demonstrate when a distillation strategy is beneficial. The comment further questions the performance of specific methods in Table 3 and asks for more reasoning or hypotheses. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should present a case study with synthetic datasets to demonstrate the benefits of a distillation strategy. It questions the performance of specific methods in Table 3 and asks for more reasoning or hypotheses. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that a case study would be beneficial. The reasoning is somewhat verifiable, as it highlights a potential gap in the paper but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of a case study with synthetic datasets to demonstrate the benefits of a distillation strategy. It specifically questions the performance of certain methods in Table 3 and asks for more reasoning or hypotheses to explain the observed results. This feedback is valuable as it guides the authors to provide additional analysis and insights into their findings, which could enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered specific guidance on how to conduct the case study or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors focus on evaluating LM loss, which is fine for style and topics, but not for factual knowledge. It implies that the authors could create cloze-style or question-answering evaluation sets to better evaluate the generation of factual knowledge. While the comment provides a general direction for improvement, it lacks specific guidance on how to implement these suggestions or what specific changes should be made. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on evaluating LM loss throughout the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending the creation of cloze-style or question-answering evaluation sets to better evaluate the generation of factual knowledge. This level of detail helps the authors understand what needs to be addressed and how to improve their evaluation approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of LM loss is not clean enough for factual knowledge because only a few tokens in a sentence are related to facts. The reviewer proposes creating cloze-style or question-answering evaluation sets to focus on factual knowledge generation. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that LM loss evaluation is insufficient for factual knowledge. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the evaluation of LM loss, noting that it may not be sufficient for evaluating factual knowledge. It suggests a potential improvement by recommending the creation of cloze-style or question-answering evaluation sets to focus on the generation of factual knowledge. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance their evaluation methodology. However, the comment could be more helpful if it included additional details or examples of how to implement these suggestions. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their evaluation approach.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters and its application to network representation. While it implies that the authors should provide a theoretical explanation for the sensitivity of the RTD score, it does not explicitly instruct them to do so. Additionally, it suggests that the authors should clarify why the RTD score is specifically applicable to network representation. The actions are implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation and clarify the application. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the key contribution of the paper, specifically the sensitivity of the RTD score to clusters and its application to network representation. It raises questions about the theoretical or topological aspects of the RTD score\\'s sensitivity and its applicability to network representation. However, the comment does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about the theoretical aspects and application to network representation, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters and its application to network representation. While it raises valid points about the need for theoretical explanation and specificity, it does not provide any supporting evidence, references, or detailed reasoning to substantiate these claims. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters, which is presented as a key contribution of the paper. It suggests that the authors should provide a theoretical explanation for this sensitivity and clarify why the RTD score is specifically applicable to network representation. While the comment identifies an important area for improvement, it lacks specific guidance or suggestions on how the authors might address these questions. The feedback is somewhat helpful as it points out a potential gap in the paper\\'s theoretical foundation, but it could be more beneficial with additional direction or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests that inference timings should be provided to support the claim that ROCK has similar complexity as the original model. Additionally, it recommends conducting ablation experiments to show the contribution of each auxiliary task on object detection performance in ROCK and in standard MTL. These suggestions are clear and concrete, giving the authors specific guidance on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines \"L88-89,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim about ROCK\\'s complexity and suggests providing inference timings to support this claim. Additionally, it provides specific feedback on the need for ablation experiments to show the contribution of each auxiliary task on object detection performance in ROCK and in standard MTL. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that ROCK has similar complexity to the original model, suggesting that inference timings should be provided to substantiate this assertion. The reviewer also highlights the need for ablation experiments to demonstrate the contribution of each auxiliary task on object detection performance. While the comment provides a logical basis for its critique, it lacks specific examples or references to support the claim about the complexity of ROCK. This makes the comment somewhat verifiable, as it requires additional evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two key areas: the complexity claim regarding ROCK and the need for inference timings, and the suggestion for ablation experiments to demonstrate the contribution of each auxiliary task on object detection performance. By identifying these weaknesses and offering clear guidance on how to address them, the comment empowers the authors to significantly improve their draft. The detailed suggestions, such as providing inference timings and conducting ablation experiments, offer concrete steps for enhancing the paper\\'s rigor and clarity. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to add an equation to the paper for clarity, specifically regarding the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) if the part is not autoregressive. This direct request provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 197-198,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) if the part is not autoregressive and suggests adding an equation for clarity. This provides clear guidance on what the authors need to revise. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. The suggestion to add an equation for clarity is a request for clarification, not a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, particularly regarding the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) if the part is not autoregressive. By questioning the methodology and suggesting the addition of an equation for clarity, the reviewer provides actionable feedback that can help the authors improve the clarity and comprehensibility of their work. This guidance is clear and specific, offering a direct path for the authors to enhance their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also raises concerns about how the model might perform on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should include a discussion on these aspects, but without specific guidance on what to cover or how to structure this discussion, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the diversity and quality of the dataset, specifically mentioning rare conditions or imaging variations. It also raises concerns about how the model might perform on noisy or imbalanced real-world medical datasets. However, the comment does not specify which part of the paper should include this discussion, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in detailing what needs to be addressed regarding the dataset and model performance, but the lack of grounding reduces its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limited discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also questions how the model might perform on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that could be improved, it lacks specific examples or references to support the claim. The reasoning is somewhat verifiable, as it highlights potential issues but does not provide detailed evidence or comparisons to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion regarding the diversity and quality of the dataset, particularly in terms of rare conditions or imaging variations. It also raises important concerns about how the model might perform on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it highlights critical areas that need further exploration and clarification in the paper. However, while it points out these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their discussion. To be more helpful, the comment could include recommendations on how to enhance the dataset analysis or model evaluation. Therefore, the comment is somewhat helpful, as it provides insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reproducibility of the results due to the lack of promised code and insufficient training details. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide more detailed training information, but it lacks concrete suggestions on what specific details should be included or how to ensure reproducibility. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the reproducibility of the results, specifically mentioning the lack of promised code and insufficient training details. However, it does not specify which part of the paper discusses the model components or the training stages, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of reproducibility but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of promised code and insufficient training details makes the results non-reproducible. This claim is somewhat verifiable as it logically follows that without access to the code and detailed training information, it would be challenging to replicate the results. However, the comment does not provide specific examples or references to support the assertion, such as instances where similar issues have led to non-reproducibility. The authors would need to infer the importance of these details and how they impact reproducibility. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the reproducibility of the results due to the lack of promised code and insufficient training details. This is an important point that the authors need to address to ensure the credibility and reliability of their work. However, the comment does not provide specific suggestions or guidance on how to improve the reproducibility, such as recommending additional details to include in the training section or suggesting ways to make the code available. While it highlights a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a crucial area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of critical setup information, specifically the total number of agents available in Flow\\'s default configuration. While it identifies a missing element, it does not provide explicit instructions on how to address this issue or suggest where this information should be included in the paper. The action is implicit and somewhat vague, as the authors can infer that they need to add this information, but they are not given specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of critical setup information, specifically the total number of agents available in Flow\\'s default configuration. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying what is missing, namely the total number of agents, but without clear grounding, the authors may struggle to determine where to incorporate this information. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"critical setup information is missing,\" specifically mentioning the total number of agents available in Flow\\'s default configuration. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is critical or how its absence affects the paper. Without additional context or explanation, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of critical setup information, such as the total number of agents available in Flow\\'s default configuration. This feedback is valuable as it highlights a missing piece of information that could be crucial for understanding the experimental setup and its implications. However, the comment does not provide suggestions on how to address this gap or why this information is important, which limits its helpfulness. While it points out an area for improvement, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" pointing out that there are many works that infer structures in an unsupervised way. However, it does not provide specific guidance on how the authors should address this issue or suggest alternative ways to define or support their claim. The feedback lacks explicit instructions or concrete steps for the authors to follow, leaving them uncertain about how to improve their draft in response to this critique. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the novelty of the work, questioning the narrow definition of \"scene graph\" and the claim of being the \"first deep generative model for unsupervised scene-graph discovery.\" However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique of the claim and suggests that there are many works that infer structures in an unsupervised way, which challenges the novelty claim. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery\" by pointing out that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to these works, which would help substantiate the claim. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a logical reasoning but lacks the necessary support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" pointing out that there are many works that infer structures in an unsupervised way. This feedback is somewhat helpful as it challenges the novelty claim made by the authors, prompting them to reconsider their definition and positioning of their work. However, the comment lacks specific examples or references to the existing works that the reviewer believes are relevant, which would provide more actionable guidance for the authors. While it raises an important point, the feedback could be more helpful with additional context or suggestions for improvement. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the ablation study, specifically that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors on how to address this issue or suggest specific actions to take. The authors can infer that they need to include this analysis, but the comment lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the effect of different numbers of projectors on distillation when the feature dimensions are different. This provides clear guidance on what needs to be addressed in the study. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. This feedback is somewhat helpful as it highlights an area where the study could be improved, prompting the authors to consider including this analysis. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending particular experiments or analysis methods. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. While the comment implies that additional experiments are needed, it does not provide specific guidance on which datasets or complex shapes should be used or how to implement these experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the current focus on three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. However, the comment does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments that need expansion. While the authors might infer that it relates to the results or discussion sections, the lack of explicit grounding makes it challenging to pinpoint the exact area for improvement. The suggestion is specific in terms of what additional experiments could be conducted, but the comment is weakly grounded because it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on diverse datasets could demonstrate the generalization capabilities of the model beyond the current focus on three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that additional experiments would be beneficial. This makes the claim somewhat verifiable, as the authors would need to infer the potential benefits and design the experiments themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors conduct more experiments on diverse datasets to demonstrate the generalization capabilities of their model beyond the current focus on three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better illustrate the core idea of the proposed method. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental validation. By suggesting additional datasets and complex shapes, the comment offers a concrete way to enhance the comprehensiveness and robustness of the study. However, it could be more helpful if it included specific examples or references to datasets or shapes that would be particularly relevant. Overall, the comment is mostly helpful as it guides the authors toward meaningful improvements in their experimental validation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison against methods that require more training time is necessary, particularly in light of neural networks that do not necessitate extensive training time. It emphasizes the importance of understanding the implications of low computational requirements during training. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects should be considered. While the action is implied, it lacks concrete details on how to execute it, leaving the authors with a general direction but no clear steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning neural networks proposed by Park & Van Hentenryck (2023) and others. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in detailing the need for understanding the implications of low computational requirements and the potential unnecessary restrictions due to shorter training times. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of neural networks that do not necessitate extensive training time. The comment provides a logical reasoning by highlighting the importance of understanding the implications of low computational requirements during training. However, it lacks specific references or examples of neural networks that meet these criteria, which would strengthen the claim. This makes the comment somewhat verifiable, as it provides a reasonable argument but requires additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting a comparison against methods that require more training time. It highlights the importance of understanding the implications of low computational requirements, particularly in the context of neural networks proposed by Park & Van Hentenryck (2023) and others. The comment provides a clear rationale for why this comparison is necessary, emphasizing the potential impact of shorter training times on the overall methodology. However, while it identifies a key area for improvement, it lacks detailed guidance or specific suggestions on how to implement this comparison or what aspects to focus on. This limits the comment\\'s helpfulness, as it provides a direction but not a comprehensive plan for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies an unfair comparison between DetNAS and ResNet due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It suggests that the authors should provide more comparisons with other networks constructed using efficient blocks, such as the 3.8G FLOPs ShuffleNetv2. The comment explicitly instructs the authors to include the results of a 3.8G FLOPs ShuffleNetv2 in Table 2, providing a clear and concrete action for the authors to take. This level of detail ensures that the authors know exactly what changes to make to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison between DetNAS and ResNet, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The comment further suggests providing more comparisons with other networks constructed using efficient blocks, such as including the results of a 3.8G FLOPs ShuffleNetv2 in Table 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer suggests providing more comparisons with other networks constructed using efficient blocks, such as including the results of a 3.8G FLOPs ShuffleNetv2 in Table 2. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a specific improvement (adding the ShuffleNetv2 results). However, the comment could be strengthened by providing more detailed reasoning or references to support the claim about the efficiency of ShuffleNetv2 blocks. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison between DetNAS and ResNet, noting that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It suggests that the authors provide more comparisons with other networks constructed using efficient blocks, such as including the results of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and actionable, offering a concrete suggestion for improving the fairness and comprehensiveness of the comparisons presented in the paper. By addressing this point, the authors can enhance the validity and robustness of their experimental results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the input and output spaces/representations, noting that they are restricted to specific cases. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or expand their approach to include more general representations. The comment lacks actionable details, such as recommending specific methods or modifications to achieve greater generality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the input and output spaces/representations, noting that they are restricted to certain conditions. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation and comparing it to other works, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific conditions, contrasting this with other works mentioned in point (3). However, the comment does not provide specific details or references to the mentioned papers, making it difficult for the authors to fully understand the basis of the claim. The lack of explicit examples or references results in the claim being somewhat verifiable, as the authors would need to make a significant effort to identify and address the issue without further guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the input and output spaces/representations used in the paper, noting that they are restricted to specific conditions. It contrasts this with other works mentioned in point (3), which can work with any finite-dimensional representation. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their approach to include more general representations. The feedback is somewhat helpful as it points out an area for improvement, but it could be more beneficial with additional direction or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in practical applications of the system, noting that real-world image editing tasks often involve multiple objects and require flexible prompts. It suggests that specifying a source prompt, blend word, and various conditions can complicate the process and limit the system\\'s usability for typical users seeking simpler image adjustments. However, the comment does not provide explicit guidance or suggestions on how the authors might address this complexity or improve the system\\'s usability. The feedback lacks actionable details, such as recommending ways to simplify the process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the complexity of practical applications in real-world image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and potential limitations of the system, providing clear guidance on what aspects might need attention. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential complexity in practical applications of the system, noting that real-world image editing tasks often involve multiple objects and require flexible prompts. It suggests that specifying a source prompt, blend word, and various conditions can complicate the process and limit usability. While the comment provides a logical reasoning for the complexity, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the point.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practical usability of the system, specifically highlighting the complexity involved in real-world image editing tasks. It points out that specifying a source prompt, blend word, and various conditions can complicate the process, potentially restricting the system\\'s usability for typical users seeking simpler image adjustments. While the comment effectively identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this complexity or enhance the system\\'s usability. Providing actionable advice or examples would make the feedback more helpful. Therefore, the comment is somewhat helpful, as it offers insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contributions of the paper are not very significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. The comment lacks guidance on how the authors might enhance the significance of their contributions or how they could effectively contrast their technique with existing literature. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for having limited contributions and a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, it does not specify which sections or parts of the paper should address these issues, making it difficult for the authors to pinpoint where improvements are needed. Additionally, the comment lacks specificity regarding what aspects of the technique are considered novel or how it could be better contrasted with existing literature. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contributions of the paper are not significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence renders the claim unverifiable, as it does not provide sufficient information for the authors to address the concerns effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contributions of the paper are not very significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. While it identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might enhance the significance of their contributions or improve the comparison with existing literature. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but also require more time to compute. The comment implies that the authors should address this trade-off in their discussion. However, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors need to infer the need for a discussion and determine how to address it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It acknowledges the trade-off between dataset size and computational time, and references two external works ([1] and [2]) to support the claim. However, the comment does not specify which part of the paper should include this discussion, making it weakly grounded. The suggestion is specific, as it outlines the need for a discussion on the impact of dataset size on sparsity ratio and computational time. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary, acknowledging the trade-off between dataset size and computational time. The comment references two external works ([1] and [2]) to support the claim, providing a basis for the suggestion. However, the references are not directly integrated into the argument, and the comment could benefit from more detailed explanation or examples of how these works relate to the paper\\'s discussion. Despite this, the references offer some support for the claim, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It acknowledges the trade-off between dataset size and computational time, which is an important consideration in the context of the paper. The comment also references two external works, which could provide valuable insights or examples for the authors to consider. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this discussion into the paper or provided more detailed guidance on what aspects to focus on. Overall, the comment is somewhat helpful as it highlights an important area for discussion but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not illustrated or experimentally verified why it is better to keep representations in the same hidden space. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actions for the authors to take, such as recommending specific experiments or analyses to conduct. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of whether it is better to keep representations in the same hidden space and questions the experimental verification of this choice. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in pointing out the lack of illustration and experimental verification, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that keeping representations in the same hidden space is beneficial, noting that it has not been experimentally verified. This is a somewhat verifiable claim because it highlights a gap in the paper\\'s justification or evidence. However, it lacks specific examples or references to support the assertion that this approach is not well-justified. The authors would need to make a significant effort to address this critique without additional guidance or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the justification and experimental verification of keeping representations in the same hidden space. It points out that the authors have not provided any explanation or evidence to support this choice, which is crucial for understanding the methodology and its effectiveness. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing experiments or analyses to verify the claim. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of novelty in the methodologies presented in the paper, specifically mentioning that the approach introduced is an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the contribution to the NLP community. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of novelty in the methodologies introduced in the paper, specifically mentioning the extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). This provides some grounding as it references specific works, allowing the authors to identify the part of the paper being discussed. However, the comment lacks specificity regarding what aspects of the methodology are considered insufficiently novel or how the authors might address this issue. Without detailed guidance or suggestions for improvement, the comment remains under-specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty in its methodologies, specifically mentioning that it extends Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). This claim is somewhat verifiable as it references specific works, providing a basis for the critique. However, the comment could be strengthened by offering more detailed reasoning or examples of how the proposed approach fails to offer significant advancements. Without these additional details, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of novelty in the methodologies presented. It points out that the paper extends existing work by Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015), which does not seem to offer a substantial advancement. This feedback is valuable as it highlights a potential weakness in the paper\\'s contribution to the NLP community. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed, specifically mentioning S5 as an example. While the comment highlights a gap in the literature review or discussion, it does not provide explicit guidance on how the authors should address this oversight. The action is implicit, as the authors need to infer that they should include these approaches in their review or discussion. However, the comment does not specify which other approaches should be considered or how to integrate them into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific oversight in the paper regarding the lack of consideration for various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed. It mentions S5 as an example, which provides some specificity about what is missing. However, the comment does not explicitly mention which part of the paper this oversight pertains to, such as specific sections or discussions where these approaches should be included. The authors can infer that it relates to the literature review or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the issue. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed. It provides a specific example, \"S5,\" which avoids the issue by computing the input-output via a parallel scan. This example offers a concrete reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional examples or references to other SSM-based approaches, which would fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the paper, noting that it overlooks various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed. It provides a concrete example, \"S5,\" which avoids this issue by computing the input-output via a parallel scan. This feedback is valuable as it highlights a gap in the literature review or discussion that the authors can address to improve the comprehensiveness of their work. However, the comment could be more helpful if it suggested how to integrate these approaches into the paper or provided additional context or references. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues with the paper, including the presentation of 3 as the underlying data generating mechanism, the use of causal graphs instead of the label inference process, and the difficulty in reading definition 4 due to a lack of clarity on the graph considered for determining independencies. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The actions are implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses multiple issues within the paper, including the presentation of 3 as the underlying data generating mechanism, the use of causal graphs instead of the label inference process, and the difficulty in reading definition 4. While it mentions specific elements like \"Fig. 2\" and \"definition 4,\" it does not explicitly state which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the underlying data generating mechanism, causal graphs, and the clarity of definition 4. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including that 3 is not the underlying data generating mechanism and that causal graphs should be used instead of the label inference process. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"Fig. 2\" and \"definition 4\" suggests that the reviewer is pointing out specific issues, but without further elaboration, the claims remain vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of issues but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several issues with the paper, including the presentation of 3 as the underlying data generating mechanism, which the reviewer disputes, and the suggestion that causal graphs should be used instead of the label inference process. It also points out that definition 4 is difficult to read due to a lack of clarity on the graph considered for determining independencies. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it highlights potential weaknesses and areas for improvement, but it could be more beneficial with additional context or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate a dual-free approach. While the comment implies that the authors should provide additional examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these examples or what kind of examples would be most beneficial. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate a dual-free approach. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The suggestion to include more examples is specific, but without clear grounding, the authors may struggle to identify where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and a suggestion to include more examples in machine learning to motivate a dual-free approach. It does not contain any subjective opinions, judgments, or claims that require verification. The statement is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate a dual-free approach, which is a valuable suggestion for enhancing the paper. However, the comment lacks specific guidance or examples of what kind of examples would be most beneficial or how they should be integrated into the paper. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of explanation regarding the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It explicitly asks the authors to explain the reason for selecting from the range [0, Pcj(0)]. This request is clear and direct, providing the authors with a specific action to take\u2014explaining the rationale behind their choice. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"step 3 of the Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of explanation regarding the selection of a probability for the appearance of an unobservable data point and asks for clarification on the reason for selecting from the range [0, Pcj(0)]. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of explanation regarding the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It asks the authors to clarify the reason for selecting from the range [0, Pcj(0)]. While the comment identifies a gap in the explanation, it does not provide any supporting evidence or reasoning to substantiate why this explanation is necessary or how it impacts the methodology. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of this explanation themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that lacks explanation, namely the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It asks the authors to clarify the reason for selecting from the range [0, Pcj(0)]. This feedback is clear and actionable, as it directs the authors to provide a rationale for their methodological choice, which could enhance the clarity and understanding of their approach. However, the comment could be more helpful if it offered suggestions on how to present this explanation or provided examples of similar approaches in the literature. Overall, the comment is mostly helpful as it highlights a critical area for improvement and prompts the authors to address it, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a precise definition or informal description of the spectrum of distributions and their characteristic functions. While the comment implies that the authors should provide this clarification, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, as the authors can infer that they need to add a definition or description. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (line 128 and line 168), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a precise definition or informal description of the spectrum of distributions and their characteristic functions. This provides clear guidance on what the authors need to revise. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a precise definition or informal description of the spectrum of distributions and their characteristic functions. However, the comment does not provide any specific reasoning or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide a precise definition or informal description of the spectrum of distributions and their characteristic functions. This feedback is clear and actionable, as it directly points out a gap in the paper that the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included examples or further guidance on how to present this information. Overall, the feedback is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the AIG-generation task, noting that it is not convincing and lacks clarity. It suggests that more background information should be provided for readers unfamiliar with logic synthesis and recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG. While the comment provides explicit actions, it lacks concrete details on how to implement these suggestions, such as specific background information to include or which datasets to use for benchmarking. The authors are given a clear direction but without detailed guidance on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the AIG-generation task, indicating that it is not convincing and lacks clarity. It suggests providing more background information for readers unfamiliar with logic synthesis and recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the AIG-generation task is discussed. The suggestion to benchmark on existing datasets adds specificity to the comment. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the AIG-generation task is not convincing and suggests that more background information and benchmarking on existing datasets would improve its credibility. However, the comment lacks specific reasoning or evidence to support why the task is not convincing or how the proposed method could be improved through benchmarking. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a lack of clarity and convincing evidence in the AIG-generation task, suggesting that more background information is needed for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG, to enhance the task\\'s credibility. This feedback is clear and actionable, providing specific suggestions for improvement that can help the authors enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it included more detailed guidance on what specific background information to provide or how to effectively benchmark the method. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some statements in the paper lack detail and analysis, but it does not specify which statements or provide guidance on how to address this issue. The feedback is vague and lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about which parts need more detail and analysis. Without specific guidance, the authors may struggle to determine how to enhance the clarity and depth of their statements. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements or sections are being referred to. This makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what kind of detail or analysis is missing. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some statements in this paper lack detail and analysis,\" but it does not provide specific examples or reasoning to support this claim. Without identifying which statements are lacking or explaining why they are insufficient, the comment lacks verifiability. The authors may struggle to understand which parts of their paper need improvement or why. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the paper, noting that some statements lack detail and analysis. However, it does not specify which statements are problematic or provide guidance on how to address this issue. Without specific examples or suggestions for improvement, the authors are left without actionable feedback to enhance their draft. This lack of detail and specificity makes the comment barely helpful, as it points out a potential weakness but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the comparison with other generative models, such as VAE, could be more informative. It explicitly mentions the unique features of diffusion models, such as the diffusion timesteps, and suggests analyzing how these differences affect feature learning. This feedback provides a clear and explicit action for the authors to take, which is to include a more detailed analysis of the differences between diffusion models and other generative models. The comment is specific and provides concrete guidance on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the comparison with other generative models, such as VAE, could be more informative and proposes analyzing how the unique features of diffusion models, like the diffusion timesteps, affect feature learning. However, it does not specify which part of the paper should include this comparison or analysis, making it weakly grounded. The comment is specific in suggesting a particular area for improvement\u2014comparing diffusion models with other generative models and analyzing the impact of their unique features. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with other generative models, such as VAE, could be more informative, particularly in terms of analyzing how the unique features of diffusion models, like the diffusion timesteps, affect feature learning. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that such an analysis would add significant value. The absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending a more detailed comparison with other generative models, such as VAE. It highlights the unique features of diffusion models, such as the diffusion timesteps, and suggests analyzing how these differences affect feature learning. This feedback is specific and offers a concrete direction for enhancing the paper, making it highly helpful for the authors. By addressing this point, the authors can significantly improve the depth and comprehensiveness of their analysis, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of the combination of self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. It also mentions the proposed ICoL method for mitigating insufficient memory and suggests conducting experiments to show the influence of the number of negatives. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should conduct additional experiments to demonstrate the influence of the number of negatives, but the lack of specific guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the combination of self-supervised tasks ICT and DaPI, noting the lack of significant effectiveness despite doubling GPU memory usage. Additionally, it points out the absence of experiments to show the influence of the number of negatives, referencing the TAS-B work. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the combination of self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. It also suggests that the proposed ICoL method should be tested for its influence on the number of negatives, referencing TAS-B as a source for this claim. While the comment provides some reasoning and references, it lacks detailed evidence or specific examples to fully substantiate the claims. The mention of TAS-B provides a direction for further exploration, but the comment could benefit from more explicit comparisons or data to strengthen its argument. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the experimental setup and results presented in the paper. It points out that the combination of self-supervised tasks ICT and DaPI does not seem complementary, as the effectiveness of DaPI is not significant despite doubling GPU memory usage. Additionally, it highlights the lack of experiments to demonstrate the influence of the number of negatives on the proposed ICoL method, which is crucial for understanding its effectiveness. The comment also references TAS-B to support the importance of negative instances quality over quantity. This feedback is mostly helpful as it provides clear and actionable suggestions for improving the experimental design and analysis. However, it could be more helpful if it offered specific guidance on how to conduct these experiments or what metrics to focus on. Overall, the comment provides valuable insights for the authors to enhance their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add a caption to Figure 3 to emphasize the differences between the three plots on the same row. This direct and specific action provides clear guidance on how to improve the clarity of the figure, making it highly actionable. The authors know exactly what needs to be done to enhance the figure\\'s interpretability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of a caption to emphasize the differences between the three plots on the same row. This provides clear guidance on how to improve the figure\\'s clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 3 lacks clarity due to the absence of a caption to differentiate between the three plots on the same row. This is a request for clarification rather than a subjective claim or opinion. It does not require verification or justification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is unclear what the differences are between the three plots on the same row. It suggests that adding a caption could help emphasize these differences, providing a clear and actionable recommendation for improving the figure\\'s clarity. This feedback is specific and offers a straightforward way for the authors to enhance the readability and interpretability of their figure, making it mostly helpful. However, it could be more comprehensive by suggesting how the caption might be structured or what specific information should be included, which would elevate it to a highly helpful comment. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include a deeper analysis of the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. While the comment explicitly states the need for this analysis, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to analyze computational complexity but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of computational complexity, specifically mentioning the limitation of most hand-crafted PSEs and suggesting a deeper dive into GPSE\\'s computational complexity. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in its request for a deeper analysis of computational complexity, particularly when compared to hand-crafted PSEs and other encoding strategies. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a deeper analysis of the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim about the complexity of hand-crafted PSEs or other encoding strategies. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should include a deeper analysis of the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. This feedback is clear and actionable, as it directs the authors to provide a more detailed evaluation of their method\\'s computational efficiency. By addressing this point, the authors can enhance the comprehensiveness and robustness of their analysis, which is crucial for the paper\\'s credibility. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or examples of relevant metrics to consider. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to report results on the test-standard split instead of the test-dev split for the VQA dataset, as per the guidelines provided by the VQA dataset authors. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be changed in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and the \"VQA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported results, namely that they are on the test-dev split instead of the test-standard split, as per the guidelines from the VQA dataset authors. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset should be reported on the test-standard split rather than the test-dev split, as per the guidelines from the VQA dataset authors. This claim is supported by referencing the guidelines provided by the VQA dataset authors, which is a robust source of evidence. The comment provides a clear rationale for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reporting of results in Table 1, noting that the results on the VQA dataset are reported on the test-dev split instead of the test-standard split. It references the guidelines from the VQA dataset authors, which emphasize the importance of using the test-standard split to avoid overfitting. This feedback is clear and actionable, providing the authors with a precise direction to improve the accuracy and credibility of their results. By addressing this point, the authors can ensure their work adheres to established standards and practices, which is highly beneficial for the quality of their draft. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose certain parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to guarantee a specific decision-making loss level while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would enhance the impact of the theoretical result. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to explore ways to control the term $T_i \\\\beta$ and manage the trade-off, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a specific question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to guarantee a certain decision-making loss level while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would enhance the impact of the theoretical result. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the term $T_i \\\\beta$ and how it affects the control of the trade-off. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to guarantee a certain decision-making loss level while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would enhance the impact of the theoretical result. However, the comment lacks specific reasoning or evidence to support why this trade-off is difficult to manage or how the term $T_i \\\\beta$ affects it. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to ensure a specific decision-making loss level while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would enhance the impact of the theoretical result. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing methods or strategies for controlling the term $T_i \\\\beta$. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to follow. Therefore, the comment is somewhat helpful, as it highlights an important consideration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the methods presented in the paper to more structured layers like convolutions, noting that while LBEN can be applied without much modification, its performance trails that of MON. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the applicability of their methods. The feedback lacks actionable details, such as recommending ways to enhance performance or suggesting modifications to make the methods more applicable to non-fully connected architectures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper to more structured layers like convolutions. It mentions that while LBEN can be applied without much modification, its performance trails that of MON, raising questions about the readiness of the methods for non-fully connected architectures. However, the comment does not specify which part of the paper discusses these methods or their performance, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of applicability but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the methods presented in the paper to more structured layers like convolutions. It acknowledges that the methods can be applied without much modification but notes that their performance trails that of MON, which raises questions about their readiness for non-fully connected architectures. While the comment provides a logical reasoning by comparing performance with MON, it lacks specific examples or references to substantiate the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires more detailed evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the applicability of the methods presented in the paper to more structured layers like convolutions. It acknowledges that the methods can be applied without much modification but notes that their performance trails that of MON, which raises questions about their readiness for non-fully connected architectures. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. The feedback provides some insight into a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges a lack of clarity in evaluating the refactoring process and explicitly states that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for evaluation, such as code coverage, test suite size, and test suite complexity. While the comment does not explicitly instruct the authors to use these metrics, it clearly suggests that they should consider them for their next benchmark. The action is implicit but concrete, as the authors can infer that they should explore these metrics to improve their evaluation of the refactoring process. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the refactoring process, specifically questioning the sufficiency of using a pass rate for unit tests. It suggests potential metrics like code coverage, test suite size, and test suite complexity that could be considered for evaluation. However, the comment does not specify which part of the paper discusses the refactoring process, making it weakly grounded. The suggestion to consider these metrics is specific, but without clear grounding, the authors may struggle to identify where these suggestions should be applied. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of using a pass rate for unit tests in evaluating the refactoring process. It suggests that other metrics, such as code coverage, test suite size, and test suite complexity, might be more appropriate. However, the comment does not provide specific examples or references to support why these alternative metrics are better suited for evaluation. The lack of detailed justification or evidence makes the claim somewhat verifiable, as it provides a direction for improvement but lacks the necessary support to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of the refactoring process, noting that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for evaluation, such as code coverage, test suite size, and test suite complexity. This feedback is clear and actionable, offering the authors specific directions for improving their evaluation methodology. However, the comment could be more helpful if it included additional context or examples on how to implement these metrics effectively. Overall, the comment is mostly helpful as it provides valuable guidance for enhancing the evaluation of the refactoring process.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, it does not provide any guidance or suggestions on how the authors could address this issue or enhance their contribution. There is no explicit or implicit action for the authors to take, leaving them without direction on how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main contribution of the paper, stating that the Wiener deconvolution has already been proposed. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the contribution could be improved or what specific aspects are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, it does not provide any constructive feedback or suggestions on how the authors could enhance their contribution or differentiate their work from existing literature. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the connection between the regularization term and spin glasses is considered weak. It points out specific aspects that need further explanation, such as how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. While the comment highlights these areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations, but the lack of specific guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the connection to spin glasses, including how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature. This provides clear guidance on what aspects need further explanation or clarification. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the strength of the connection between the regularization term and spin glasses, specifically highlighting the lack of explanation regarding how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. While the comment identifies specific areas that need further elaboration, it does not provide detailed reasoning or references to support these claims. The lack of explicit examples or references makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the connection between the regularization term and spin glasses, as described in equation 8. It points out that this connection appears weak because it does not explain several key aspects, such as how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed explanations to strengthen their argument. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar connections have been established in other works. Overall, the comment is mostly helpful, as it directs the authors to critical areas needing further elaboration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the self-training scheme is a direct application and notes that the contribution is limited. However, it does not provide any specific guidance or suggestions on how the authors could enhance the contribution or improve the paper. The comment lacks actionable details, such as recommending additional experiments, analyses, or comparisons that could strengthen the contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the self-training scheme and its application in the paper, indicating that it is a direct application rather than a significant contribution. However, it does not specify which part of the paper discusses the self-training scheme, making it weakly grounded. The comment also lacks specificity regarding what aspects of the contribution are limited or how it could be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application and that the contribution is limited. However, it does not provide any supporting evidence, reasoning, or references to justify why the contribution is considered limited. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that the self-training scheme is a direct application and notes that the contribution is relatively limited. However, it does not provide any specific suggestions or guidance on how the authors could enhance the contribution or improve the paper. Without actionable feedback or detailed critique, the authors are left without a clear path for improvement. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality of the results. This is an explicit suggestion, as it directly instructs the authors on what additional information to provide in their paper. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft\u2014adding zoomed-in regions for inspection. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results shown in the paper are low-resolution and recommends including zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, it does not specify which part of the paper this issue pertains to, such as specific figures or sections where the results are presented. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting a potential improvement by zooming in on specific regions. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results shown in the paper are low-resolution and suggests including zoomed-in regions to inspect the quality. However, the comment does not provide specific examples or references to support the claim that the results are indeed low-resolution. Without detailed evidence or comparisons, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the results shown are low-resolution and suggesting that zoomed-in regions of the rendered focal stack or all-in-focus images would help inspect the quality. This feedback is clear and actionable, providing a concrete suggestion for improvement that could enhance the clarity and detail of the results presented in the paper. By addressing this point, the authors could significantly improve the visual quality and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it is important for the overall understanding of the results. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main concerns: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. While it identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they might need to explore ways to reduce inference cost or consider alternative methods for post-hoc calibration, but the comment lacks concrete suggestions or actions to take. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific concerns related to the comparative inference method: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the method, particularly the inference cost and the need for validation data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the comparative inference method, specifically highlighting the significant increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. These claims are somewhat verifiable as they provide logical reasoning about the potential issues with computational resources and data availability. However, the comment lacks specific examples or references to substantiate these concerns fully. Providing more detailed evidence or examples would enhance the verifiability of the claims, making it easier for the authors to understand and address the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant concerns regarding the comparative inference method: the increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. These are important considerations, especially in real-world applications where computational resources and data availability may be limited. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or mitigate their impact. While it highlights critical areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out important issues but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the approach of reinitializing the model to address exploding gradients and suggests an alternative method of performing gradient clipping with a high value for the gradient norm to avoid NaNs. This feedback provides a clear and explicit action for the authors to consider, offering a specific method to address the issue of exploding gradients. The suggestion is concrete, as it outlines a direct modification to the experimental setup. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the approach of reinitializing the model to address exploding gradients and suggests an alternative method of performing gradient clipping with a high value for the gradient norm to avoid NaNs. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approach of reinitializing the model to address exploding gradients and suggests an alternative method of performing gradient clipping with a high value for the gradient norm to avoid NaNs. This claim is somewhat verifiable as it provides a logical suggestion for addressing the issue of exploding gradients. However, it lacks specific examples or references to support why gradient clipping with a high value would be more effective or how it has been successfully implemented in similar contexts. The comment would benefit from additional evidence or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for addressing the issue of exploding gradients in the paper. It questions the approach of reinitializing the model and suggests an alternative method of performing gradient clipping with a high value for the gradient norm to avoid NaNs. This feedback is clear and offers a concrete solution that the authors can consider to improve their methodology. By providing a direct suggestion, the comment empowers the authors to make a meaningful enhancement to their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for a more detailed explanation of the term \"common pattern,\" indicating that the authors should provide a clearer definition or elaboration. This direct request gives the authors a clear action to take, which is to expand on the meaning of \"common pattern\" in their draft. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the exact meaning of \"common pattern,\" indicating that more detailed explanation is needed. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a more detailed explanation of the term \"common pattern,\" but without clear grounding, the authors may struggle to identify where this explanation should be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the term \"common pattern.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper regarding the term \"common pattern.\" It requests a more detailed explanation, which is a specific and actionable piece of feedback. By addressing this point, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to elaborate on the term or what specific aspects of the \"common pattern\" need clarification. Despite this, the feedback is mostly helpful as it directs the authors to a clear area needing improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test the model on these datasets, modify their approach, or provide additional analysis to address this concern. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper discusses the datasets or the pre-trained model, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these datasets are mentioned, the comment lacks full grounding. It is specific about the concern regarding generalizability but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. This is an important consideration for the authors to address, as it could impact the applicability and robustness of their model. However, the comment lacks specific suggestions or guidance on how the authors might test or demonstrate the model\\'s generalizability to these other datasets. While it identifies a potential weakness, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the quality of the generated dataset, given that LLMs are known to hallucinate. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern, such as suggesting methods for quality checking or providing examples of how to verify the dataset. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the quality of the generated dataset, given that LLMs are known to hallucinate. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section where dataset generation is discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the dataset quality need to be addressed or how the authors should verify the dataset. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the quality of the generated dataset, given that LLMs are known to hallucinate. However, it does not provide any specific examples, reasoning, or references to support this claim or suggest how the authors might address it. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the concern and how to respond effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of the generated dataset, given that LLMs are known to hallucinate. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or verify the dataset\\'s quality. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the comparison across four models, suggesting that the fine-tuned wav2vec model is likely to perform best due to its pre-training. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches to make the comparison more meaningful. The comment implies that the authors should consider adjusting their experimental setup or analysis to account for the pre-training effect, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper regarding the comparison across four models, suggesting that the fine-tuned wav2vec model is likely to perform best due to its pre-training. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the comparison across models, highlighting the potential bias due to pre-training. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison across four models might not be meaningful because the fine-tuned wav2vec model is likely to perform best due to its pre-training. However, the comment does not provide specific evidence or reasoning to support this claim, such as data or examples showing the impact of pre-training on model performance. Without such supporting information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison across four models, suggesting that the fine-tuned wav2vec model is likely to perform best due to its pre-training. This observation is valuable as it highlights a potential bias in the experimental setup that could affect the interpretation of results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative comparisons or adjustments to the experimental design. While it points out an important consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper is well-written but notes that it feels dense compared to other pure-math ML papers. It suggests that more examples, such as Figure 2, would be helpful. While the comment implies that the authors should include more examples, it does not specify which examples would be most beneficial or how to integrate them effectively. The action is implicit and somewhat vague, as the authors know they need to add examples but may not be entirely sure of the specifics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper feeling dense compared to other pure-math ML papers and suggests that more examples, such as Figure 2, would be helpful. However, it does not specify which sections or parts of the paper are particularly dense or where additional examples should be included. This lack of explicit reference to specific sections or figures makes it weakly grounded. The comment is somewhat specific in suggesting the inclusion of more examples, but it does not provide detailed guidance on what kind of examples would be beneficial or how they should be integrated. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper feels dense compared to other pure-math ML papers and suggests that more examples, such as Figure 2, would help. However, the comment lacks specific reasoning or evidence to support why the paper is considered dense or how the inclusion of more examples would address this issue. Without detailed justification or examples, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is well-written but notes that it feels dense compared to other pure-math ML papers. It suggests that more examples, such as Figure 2, would be helpful. While the comment identifies a potential issue with the paper\\'s readability, it lacks specific guidance on how to address this density or what kind of examples would be most beneficial. The feedback is somewhat helpful as it points out an area for improvement but does not provide detailed, actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that Section 4.2 starts with high-level intuition, while Section 4.1 does not. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how the authors should address this observation or what changes, if any, are needed to improve the draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"4.2\" and \"4.1,\" allowing the authors to accurately identify the sections being addressed, which provides full grounding. However, the comment lacks specificity as it does not explain why the high-level intuition in 4.2 is preferable or how it could be improved. Without further details, the authors may not know what specific changes are needed to enhance the sections. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point makes a claim about the sections 4.1 and 4.2, stating that 4.2 starts with high-level intuition while 4.1 does not. However, the comment lacks any supporting evidence, reasoning, or examples to justify why this difference is significant or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a discrepancy between Sections 4.1 and 4.2, noting that while Section 4.2 starts with high-level intuition, Section 4.1 does not. However, it does not provide any further explanation or guidance on why this difference is significant or how it could be addressed. Without additional context or suggestions for improvement, the authors are left with only a vague understanding of the issue. This lack of actionable feedback limits the comment\\'s usefulness, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more discussions should be introduced regarding the obtained permutation matrices shown in Figure 3, specifically mentioning Figure (e)(j)(o). While the comment implies that the authors should expand on these matrices, it does not provide specific guidance on what aspects should be discussed or how to enhance the explanation. The action is implicit and somewhat vague, as the authors know they need to add more discussion but may not be entirely sure of the exact content or depth required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting that more discussions should be introduced regarding the obtained permutation matrices shown in Figures (e), (j), and (o). This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more discussions should be introduced regarding the obtained permutation matrices shown in Figure 3. However, it does not provide any specific reasoning or evidence to support why these discussions are necessary or how they would enhance the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more discussions should be introduced regarding the obtained permutation matrices shown in Figure 3, specifically mentioning Figures (e), (j), and (o). While it identifies an area where the paper could be improved by providing additional context or explanation, the comment lacks specificity and does not offer detailed guidance on what aspects should be discussed or how these discussions could be integrated into the paper. Without concrete suggestions or examples, the authors may find it challenging to address this feedback effectively. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the crowd workers, specifically asking about their recruitment and training. While it implies that the authors should provide information on these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the question. The authors can infer that they need to include details about the crowd workers, but the comment does not specify what kind of information should be provided or how it should be structured. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the crowd workers, specifically asking about their recruitment and training. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the crowd workers, but without clear grounding, the authors may struggle to identify where this information should be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the crowd workers, their recruitment, and training. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the crowd workers, specifically asking about their recruitment and training. While this question highlights an area that may need clarification in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or why it is important. As a result, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that human evaluations are more important, but it lacks concrete steps or recommendations for improving the evaluation process. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some specificity by highlighting the importance of human evaluations and questioning the validity and robustness of the conclusions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the correlation between automatic metrics and human evaluations is weak, suggesting that automatic metrics may not fully capture the quality of the simplifications. This claim is supported by logical reasoning, as it highlights the importance of human evaluations in assessing the quality of results. However, the comment lacks specific examples or references to substantiate the claim further, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a potential issue with the evaluation of the models, specifically the weak correlation between automatic metrics and human evaluations. It suggests that the automatic metrics may not fully capture the quality of the simplifications, raising questions about the validity and robustness of the conclusions. The comment emphasizes the importance of human evaluations, which is a valuable insight for the authors to consider. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional human evaluations or alternative metrics. While it provides a useful observation, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific in the \"Chain of Reasoning\" section, particularly in line 276. This provides a clear and direct action for the authors to take, which is to elaborate on the content in that specific line. However, the comment does not provide further guidance on what aspects of the reasoning should be expanded or how to improve the clarity. While the action is explicit, the lack of detailed instructions makes it somewhat vague in terms of execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Chain of Reasoning\" section and a specific line, \"line 276,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more detail on the \"Chain of Reasoning\" section, particularly in line 276, indicating what needs to be clarified or expanded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more specificity in the \"Chain of Reasoning\" section, particularly in line 276. However, it does not provide any justification or explanation for why this specificity is necessary or how it would improve the paper. Without additional context or reasoning, the authors may find it challenging to understand the importance of this request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment requests more specificity in the \"Chain of Reasoning\" section, particularly in line 276. While it identifies a specific area that could benefit from further elaboration, it lacks depth and does not provide guidance on what aspects of the reasoning should be clarified or how the authors might improve this section. Without additional context or suggestions, the authors may struggle to understand what specific changes are needed to enhance the clarity of their argument. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. However, it does not provide explicit instructions on how to implement this suggestion or what specific metrics should be used. The action is implicit and somewhat vague, as the authors need to infer that they should add a sample quality metric and determine which one to use. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a graphical model and likelihood function to condition on goal states and plan latent variables for inference, which allows the authors to identify the specific part of the paper being addressed. It also specifies the need for a sample quality metric on the CARLA data, suggesting the use of minADE or minMSD as a common metric. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there should be a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. However, the comment does not provide a detailed explanation or justification for why this metric is necessary or how it would improve the paper. The suggestion is somewhat vague and lacks specific reasoning or references, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is classified as 2: Borderline Verifiable, as it provides some direction but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the use of a graphical model and likelihood function to condition on goal states and plan latent variables for inference, which can improve forecasting performance. However, it suggests that there should be a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. While the comment identifies a potential area for improvement by suggesting the inclusion of a sample quality metric, it lacks detailed guidance or specific examples on how to implement this metric or why it is necessary. The feedback is somewhat helpful as it points out a specific area for enhancement but could be more beneficial with additional context or actionable suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumptions made in the paper regarding constraints and discriminators. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this assumption is valid, if it needs to be addressed, or how the authors might clarify or revise their assumptions. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the assumptions regarding constraints and discriminators, but it does not specify which part of the paper this question pertains to. The authors might infer that it relates to the methodology or assumptions section, but this inference is not direct. The comment lacks specificity as it does not provide details on why this assumption is important or how it affects the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the assumptions made in the paper regarding constraints and discriminators. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumptions made in the paper regarding constraints and discriminators. While it prompts the authors to clarify their assumptions, it does not provide any specific guidance or suggestions on how to address this issue or improve the draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague indication of a potential area for improvement. Therefore, it is rated as barely helpful, as it provides limited value in guiding the authors to enhance their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss or add Wasserstein GAN (WGAN) as a baseline method, given that the use of Optimal Transport (OT) or the Wasserstein Distance in GANs was first introduced in the WGAN paper. This feedback provides a clear and explicit action for the authors to take, which is to include a discussion or comparison with WGAN. The suggestion is concrete, as it specifies exactly what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of Optimal Transport (OT) and the Wasserstein Distance in the context of GANs, which allows the authors to identify the relevant part of the paper. It also specifies the need to discuss or add Wasserstein GAN (WGAN) as a baseline method, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of Optimal Transport (OT) or the Wasserstein Distance in GANs was first introduced in the Wasserstein GAN (WGAN) paper by Arjovsky et al. (ICML 2017). This claim is supported by a specific reference to the WGAN paper, which provides a clear and verifiable source for the claim. The comment suggests discussing WGAN or adding it as a baseline method, which is a logical recommendation based on the historical context provided. The inclusion of a specific reference and the logical reasoning behind the suggestion make the claim fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is mostly helpful as it provides a specific suggestion for improvement by recommending that the authors discuss or include Wasserstein GAN (WGAN) as a baseline method. This feedback is actionable and offers a clear direction for enhancing the paper by situating the use of Optimal Transport (OT) or the Wasserstein Distance in the context of existing work, particularly the WGAN paper. However, the comment could be more helpful if it elaborated on why discussing or including WGAN is beneficial or how it could impact the paper\\'s contribution. Overall, the comment provides valuable guidance for the authors to consider, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It implies that these should be discussed in the paper. Additionally, the comment provides references to specific works that could be included. While the action is implicit, it is concrete because it specifies the type of related work that should be discussed and provides references to guide the authors. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of important related work on MCMC in discrete spaces, allowing the authors to identify the specific area that needs attention. It also specifies the issue by suggesting that several methods have applied Langevin MCMC to sample discrete sequences and should be discussed. Additionally, it provides references to specific works that could be included, which further clarifies the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important related work on MCMC in discrete spaces is absent, specifically mentioning that several methods have applied Langevin MCMC to sample discrete sequences. The reviewer supports this claim by referencing specific works by Zhang et al. and Sun et al., providing explicit citations and links to these studies. This detailed reference to external sources strengthens the claim, making it fully verifiable. The inclusion of specific references allows the authors to easily verify and address the critique, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of important related work on MCMC in discrete spaces. It specifically mentions that several methods have applied Langevin MCMC to sample discrete sequences and suggests that these should be discussed. This feedback is clear and actionable, as it directs the authors to include relevant literature that could enhance the context and depth of their work. Additionally, the comment provides specific references to works that could be considered, which further aids the authors in addressing the critique. However, the comment could be more helpful if it offered suggestions on how to integrate this related work into the paper or discussed its implications for the authors\\' work. Overall, the comment is mostly helpful as it provides valuable guidance for improving the draft, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, implying that there is a discrepancy or inconsistency in the methods. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this discrepancy is a concern, if it needs to be addressed, or how the authors might investigate or resolve it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, suggesting a discrepancy in the methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the methods used, but without clear grounding, the authors may struggle to identify the exact section or context being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the methods used by DS-FedDRO and FedDRO to estimate $g$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, suggesting a discrepancy in the methods. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this discrepancy or clarify the methods used. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of the problem. Therefore, it is rated as barely helpful, as it points out an area for improvement but does not offer sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it does not provide any context or explanation as to what this difference is or why it is important. The comment lacks specificity and does not offer guidance on how the authors should address this suggestion. Without additional information, the authors may struggle to determine what needs to be discussed or how to incorporate this feedback into their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific element, \"(6) in Nicekl Kiela and l,\" which provides some grounding as it allows the authors to identify the part of the paper being addressed. However, it lacks specificity because it does not explain what the difference between these two elements is or why it is important to discuss. Without further context or guidance, the authors may struggle to understand what needs to be addressed or improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that there should be a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it does not provide any context, reasoning, or examples to support why this discussion is necessary or how it would benefit the paper. Without additional information or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it lacks specificity and context, as it does not explain what the difference is or why it is important to discuss. Without additional details or guidance, the authors may struggle to understand the significance of this suggestion and how to incorporate it into their draft. The lack of clarity and actionable feedback makes the comment barely helpful, as it provides only a vague direction without concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. While it identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they need to conduct multiple experiments and perform a variance analysis, but the comment lacks concrete details on how to implement these actions. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experimental setup, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in identifying the lack of variance analysis and the need for multiple experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is valuable as it highlights a potential weakness in the methodology that could impact the reliability and robustness of the findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending the number of repetitions needed or methods for conducting variance analysis. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop, specifically noting that factors like differing dataset qualities and temporal drifts in data distributions are not considered. However, it does not provide explicit guidance or suggestions on how the authors might address this gap or account for these factors in their experiments. The comment implies that the authors should consider these aspects, but it lacks concrete steps or recommendations for how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the gap and the factors not considered in the experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a gap between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop. It mentions specific factors like differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. While the comment identifies a potential issue, it lacks specific examples or references to support the claim fully. The reasoning is somewhat verifiable, as it provides a logical basis for the claim, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop. It highlights specific factors such as differing dataset qualities and temporal drifts in data distributions, which are not considered in the experiments. This feedback is valuable as it points out a critical area for improvement, prompting the authors to consider how their experiments align with real-world scenarios. However, the comment could be more helpful if it provided suggestions on how to address these gaps or examples of how to incorporate these factors into the experiments. Overall, the comment is somewhat helpful as it directs the authors to an important aspect of their work that needs attention, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the communication cost provided in the paper, either O(SAH^2) or O(MSAH^2), does not seem particularly low or noteworthy compared to other federated Q-learning algorithms that have demonstrated O(H) communication rounds are sufficient. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their communication cost. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the communication cost. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning that it is either O(SAH^2) or O(MSAH^2). It compares this cost to other federated Q-learning algorithms, suggesting that O(H) communication rounds are sufficient. However, the comment does not specify which part of the paper discusses the communication cost, making it weakly grounded. The comment is specific in its critique of the communication cost and its comparison to other algorithms, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper is not particularly low or noteworthy, as other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. The reviewer supports this claim by referencing specific algorithms [2,3], which provides a basis for the assertion. However, the comment could be strengthened by providing more detailed comparisons or examples of how these algorithms achieve lower communication costs. Despite this, the claim is mostly verifiable due to the inclusion of external references, which helps substantiate the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential weakness in the paper regarding the communication cost, noting that the provided cost (O(SAH^2) or O(MSAH^2)) does not seem particularly low or noteworthy compared to other federated Q-learning algorithms that have demonstrated O(H) communication rounds are sufficient. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing a more competitive communication cost. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or modifications to reduce the communication cost. While it identifies a relevant concern, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their work. There is no guidance on potential adaptations, alternative approaches, or specific changes that could be made to enhance the originality or relevance of the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the originality of the paper by stating that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the paper could be improved or what specific adaptations are needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, and that the paper lacks specific adaptation to the homomorphic encryption domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references to similar works, the claim remains unverifiable, as it lacks the necessary justification to help the authors understand or address the critique. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential weakness in the paper, noting that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. While this feedback identifies a lack of originality or novelty in the approach, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding why and how the new model performs better than the previous state-of-the-art model, MH. However, it does not provide explicit guidance or suggestions on how the authors can address this issue. The comment implies that the authors should explain the model\\'s advantages and how they are achieved, but it does not specify what aspects need to be clarified or how to present this information. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding why and how the new model performs better than the previous state-of-the-art model, MH. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a new model for detecting overlapping entities in text, which improves the previous state-of-the-art model, MH, in experiments on benchmark datasets. However, it notes that it is unclear why and how the new model performs better. While the comment identifies a gap in the explanation, it does not provide specific reasoning or evidence to support the claim that the new model is superior. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it highlights an issue but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding why and how the new model performs better than the previous state-of-the-art model, MH. This is a critical area that the authors need to address to strengthen their work. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this aspect, such as by detailing the model\\'s advantages or providing additional analysis. While it highlights an important issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it points out a key area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a critique of the formula used in the Adjective Projection part, suggesting that it is not reasonable. It offers a specific alternative approach for estimating whether an object is large or small, which involves calculating the similarity between the object and the words \"large\" and \"small,\" respectively, and then comparing the differences between these similarities. This feedback is explicit and provides a concrete suggestion for improvement, making it highly actionable. The authors know exactly what needs to be changed and how to implement the suggested alternative approach.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the specific section of the paper being addressed. It is also specific because it clearly specifies the issue with the formula, providing a detailed explanation of why the current approach is not reasonable and suggesting an alternative method for estimating whether an object is large or small. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasonableness of the formula used in the Adjective Projection part, suggesting an alternative approach for estimating whether an object is large or small. The reviewer provides a logical reasoning for their critique, explaining that the current method involves calculating the similarity between the object and the difference between \"large\" and \"small\" embeddings, which is not a direct comparison of the similarities between the object and each adjective. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the proposed alternative method, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the formula used in the Adjective Projection part, suggesting that the current approach is not reasonable. It offers a clear and specific alternative method for estimating whether an object is large or small, which involves calculating the similarity between the object and the words \"large\" and \"small,\" respectively, and then comparing the differences between these similarities. This feedback is highly actionable, as it not only identifies a potential issue with the current method but also provides a concrete suggestion for improvement. By offering a specific alternative approach, the comment empowers the authors to enhance the clarity and accuracy of their methodology. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \\\\( \\\\sigma_k = \\\\text{sigmoid}(\\\\sigma_k) \\\\) in line 121, indicating that \\\\( \\\\sigma_k \\\\) appears on both sides of the equation. This implies that the authors should clarify the meaning of this expression. Additionally, the reviewer expresses interest in the proposed method and suggests that elaborating on the issues mentioned would be informative. While the comment highlights areas for clarification, it does not provide explicit instructions on how to address these issues or what specific aspects need elaboration. The action is implicit and somewhat vague, as the authors know they need to clarify the equation but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \\\\( \\\\sigma_k = \\\\text{sigmoid}(\\\\sigma_k) \\\\) and suggests that the authors elaborate on the issues mentioned. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of a mathematical expression in the paper, specifically \\\\( \\\\sigma_k = \\\\text{sigmoid}(\\\\sigma_k) \\\\). This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a mathematical expression in the paper, specifically \\\\( \\\\sigma_k = \\\\text{sigmoid}(\\\\sigma_k) \\\\), which appears on both sides of the equation. This question highlights a potential ambiguity or error in the manuscript that the authors need to address. Additionally, the comment expresses interest in the proposed method and suggests that elaborating on the issues mentioned would be informative. While the comment identifies a specific area for clarification, it does not provide detailed guidance or suggestions on how to address the issue. The feedback is somewhat helpful as it points out a potential problem and encourages further elaboration, but it could be more beneficial with additional guidance on how to resolve the ambiguity. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss and compare their work on any-resolution generation with more recent works that specifically focus on this area. It provides specific examples of recent works that could be considered for comparison, such as [1] and [2]. This feedback is explicit and provides concrete guidance on how to enhance the paper by including relevant comparisons. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing and comparing the claim of any-resolution generation with more recent works, specifically mentioning [1] and [2]. However, it does not explicitly mention which part of the paper should include this discussion or comparison, making it weakly grounded. The comment is specific in suggesting a particular area for improvement by referencing recent works that could be relevant for comparison. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the claim of any-resolution generation should be discussed and compared with more recent works, specifically mentioning two references ([1] and [2]). This provides a clear direction for the authors to consider additional literature for comparison. However, the comment does not elaborate on why these specific works are relevant or how they relate to the claim, which would strengthen the justification. As it stands, the claim is mostly verifiable, as it provides a basis for comparison but lacks detailed reasoning or examples. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss and compare their work on any-resolution generation with more recent works that specifically focus on this area. It provides specific examples of recent works that could be relevant for comparison, such as [1] and [2]. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft by situating their work within the context of current research. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limitations of the work, specifically mentioning the small sample size in the CT experiment and the need for a more detailed discussion on limitations. It also suggests discussing theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED (Unfold) or RED (Denoising). The reviewer provides specific examples and questions that the authors should address, offering clear guidance on what needs to be improved. The feedback is explicit and concrete, providing the authors with a clear path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6\" and provides a specific DOI reference, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the CT experiment having only one subject in the test set, which could lead to overfitting. The comment further suggests discussing limitations of the work, such as theoretical assumptions and implementation considerations, and questions the relative improvement of ODER over RED (Unfold) or RED (Denoising). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the limitations of the work, specifically mentioning the small sample size in the CT experiment and the need for a more detailed discussion on limitations. It suggests discussing theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED (Unfold) or RED (Denoising). The comment provides logical reasoning by pointing out the potential for overfitting due to the small sample size and the need for a more comprehensive discussion on limitations. However, it lacks specific examples or references to support the claim about the relative improvement of ODER over RED (Unfold) or RED (Denoising). This makes the claim somewhat verifiable, as it provides a reasonable basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the CT experiment, noting that it had only one subject in the test set, which could lead to overfitting. It suggests that Section 6 does not sufficiently discuss the limitations of the work and encourages the authors to address this by discussing theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED (Unfold) or RED (Denoising). The comment also raises a question about the training time comparison with online learning alternatives. This feedback is clear and actionable, providing the authors with specific areas to address and consider in their work. By offering detailed suggestions and questions, the comment empowers the authors to make significant improvements to their draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific error in the paper, noting that the bound on the 2-Wasserstein is stated as $O(\\\\epsilon^2)$, which is incorrect as it should be the bound on the 2-Wasserstein squared. This feedback provides a clear and explicit action for the authors to correct the error in their draft. The comment is specific and leaves no ambiguity about what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific line numbers \"216 and 217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect statement about the bound on the 2-Wasserstein, and provides a correction by stating that it should be the bound on the 2-Wasserstein squared. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific error in the paper, stating that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$, which should be the bound on the 2-Wasserstein squared. This claim is verifiable as it provides a precise correction to the statement, allowing the authors to easily verify and correct the error. The comment is categorized as 5: Fully Verifiable, as it offers a clear and specific correction to the claim.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the paper, pointing out that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$, which should be the bound on the 2-Wasserstein squared. This feedback is clear and actionable, as it provides the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided additional context or explanation about the significance of this error or its impact on the overall results. Despite this, the comment is mostly helpful as it directs the authors to a specific correction that can enhance the quality of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and existing methods like IEConv, CDConv, ProNet, and others. It suggests that the authors should clarify the differences in their work. While the comment implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison to specific methods like IEConv, CDConv, and ProNet, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between the proposed multi-scale hierarchical predictor and these previous methods. The comment provides references to relevant literature, which adds to its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and existing methods like IEConv, CDConv, and ProNet. It references several external works, which provides some support for the claim that these methods use pooling layers and provide hierarchical representations. However, the comment lacks detailed comparisons or specific insights into how the proposed method differs from these existing approaches. This makes the claim somewhat verifiable, as it provides a starting point for the authors to explore differences but requires more detailed analysis to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an important question about the differences between the proposed multi-scale hierarchical predictor and existing methods like IEConv, CDConv, and ProNet. It highlights the need for the authors to clarify how their approach differs from these established methods, which is a critical aspect for situating the novelty and contribution of the work. The comment is somewhat helpful as it points out a gap in the paper\\'s discussion and suggests a direction for improvement. However, it could be more helpful by providing specific aspects or criteria to consider when comparing the methods, or by offering suggestions on how to effectively differentiate the proposed approach. Overall, the comment provides a valuable starting point for the authors to enhance their draft, but it lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide specific examples of where the writing is unclear or how the authors should improve the readability. The action is implicit, as the authors can infer that they need to proofread, but it is vague because it lacks concrete guidance on what aspects of the writing need attention. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment provides a general critique that the paper does not read well and suggests that more careful proofreading is needed. However, it does not specify which parts of the paper are problematic or provide specific examples of where the writing is unclear. This lack of detail makes it difficult for the authors to identify and address the issues effectively. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the paper in general does not read well\" and suggests that more careful proofreading is needed. However, it lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear or problematic, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a general observation that the paper does not read well and suggests that more careful proofreading is needed. However, it lacks specificity and does not identify particular areas or examples where the writing is problematic. Without detailed feedback or actionable suggestions, the authors are left without clear guidance on how to improve the readability of their paper. This lack of specificity and actionable advice makes the comment barely helpful, as it does not provide the authors with a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several specific analyses that could be included in the paper. It explicitly asks for an analysis of the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing, which is important for the synthetic task. It also inquires about the value of the trade-off parameter (Theta) and how it was selected, as well as the performance of a baseline using the attention from the previous question instead of soft attention. These questions provide clear and concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests analyzing the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing, which is a specific and actionable suggestion. It also questions the value of the trade-off parameter (Theta) and how it was selected, as well as the performance of a baseline using the attention from the previous question instead of soft attention. However, the comment does not explicitly mention which part of the paper these analyses should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an analysis of the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing would be beneficial. It also questions the value of the trade-off parameter (Theta) and its selection, as well as the performance of a baseline using the attention from the previous question instead of soft attention. While the comment raises valid points for further analysis, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors would need to infer the importance of these analyses based on the reviewer\\'s suggestions. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback for the authors to consider. It suggests conducting an analysis of the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing, which is crucial for understanding the synthetic task. Additionally, it questions the value of the trade-off parameter (Theta) and how it was selected, as well as the performance of a baseline using the attention from the previous question instead of soft attention. These questions prompt the authors to clarify and potentially expand their analysis, offering a clear path for improvement. The comment is detailed and constructive, making it highly helpful for the authors to enhance their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is expected. The reviewer also expresses a personal opinion that the decorative math is unnecessary, as the paper is already interesting. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should remove proposition 1, revise it, or provide additional context or justification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the necessity of proposition 1 and suggests that it is a standard regression problem, implying that the application of a standard concentration inequality is expected. However, it does not specify which part of the paper discusses proposition 1, making it weakly grounded. The comment does provide some specificity by questioning the need for decorative math and suggesting that it does not contribute to the paper\\'s complexity measure in a statistical learning sense. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is expected. The reviewer also expresses a personal opinion that the decorative math is unnecessary, as the paper is already interesting. However, the comment lacks specific reasoning or references to support why proposition 1 is unnecessary or how it does not contribute to the complexity measure in a statistical learning sense. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is expected. The reviewer also expresses a personal opinion that the decorative math is unnecessary, as the paper is already interesting. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the draft. It lacks actionable feedback or constructive criticism, leaving the authors without a clear path for improvement. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited evaluation of defense techniques in the context of backdooring classification and suggests that the authors should include an evaluation of input perturbation-based defenses. It explicitly mentions specific works by Doan et al. that could be relevant for this evaluation. The comment provides clear and concrete guidance on what needs to be done, including specific references to relevant literature. This makes the action explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of defense techniques in the context of backdooring classification, allowing the authors to identify the relevant part of the paper. It is also specific because it suggests that the evaluation of input perturbation-based defenses is essential for a comprehensive understanding of the attacks, and it provides specific references to relevant works by Doan et al. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of defense techniques is limited, specifically mentioning input perturbation-based defenses. It supports this claim by referencing two specific works by Doan et al. that address these defenses. This provides a clear and explicit reference to external sources, making the claim fully verifiable. The inclusion of specific references and the logical reasoning behind the need for evaluation of these defenses strengthens the argument, ensuring that the authors can effectively address the critique. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the limited evaluation of defense techniques in the context of backdooring classification. It suggests that the evaluation of input perturbation-based defenses is crucial for a comprehensive understanding of the attacks. The comment provides specific references to relevant works by Doan et al., which can guide the authors in expanding their evaluation. This feedback is clear and actionable, offering a concrete direction for enhancing the paper by including a more thorough assessment of defense techniques. However, it could be more helpful if it provided additional guidance on how to incorporate these evaluations or discussed the implications of these defenses. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also points out that the context and evidence-based methods are presented shallowly. While the comment implies that the authors should expand the related work section and provide more depth to the context and evidence-based methods, it does not specify which specific datasets or methods should be included or how to improve the presentation. The actions are implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also criticizes the presentation of context and evidence-based methods as shallow. However, the comment does not specify which part of the related work section is lacking or provide specific examples of what should be included. This makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the related work section could be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also criticizes the presentation of context and evidence-based methods as shallow. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand which aspects of the related work section are insufficient or how they could be improved. The lack of detailed justification or examples results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient evidence or reasoning to support the claims made.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the related work section: the need for a more focused discussion on similar datasets for non-English or underrepresented languages, and the shallow presentation of context and evidence-based methods. While it highlights important aspects that could enhance the paper, the comment lacks specific suggestions or examples of how to address these issues. Without detailed guidance, the authors may find it challenging to implement the suggested improvements effectively. Therefore, the comment is somewhat helpful, as it points out areas for enhancement but does not provide comprehensive or actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding the placement of Batch Normalization (BN) before or after ReLU. It suggests that BN after ReLU can be folded into the next Conv operation, as all activations in the same Conv feature map share the same mean/variance/scale/offset in BN implementation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their argument. The action is implicit and vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment (Table 2)\" and the specific paragraph where the issue is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the placement of Batch Normalization (BN) before or after ReLU, and suggests that BN after ReLU can be folded into the next Conv operation due to shared mean/variance/scale/offset in BN implementation. This provides clear guidance on what aspect of the argument needs clarification or further exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the placement of Batch Normalization (BN) before or after ReLU, suggesting that BN after ReLU can be folded into the next Conv operation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the placement of Batch Normalization (BN) before or after ReLU, suggesting that BN after ReLU can be folded into the next Conv operation. It questions the authors\\' argument that BN can be folded into conv this way, implying that the authors may need to clarify or revise their explanation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their argument. While it identifies a potential area of confusion, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of large-scale experiments in the paper and suggests that the authors should conduct experiments varying the size of the network to determine if the results from small-scale experiments extend to larger scales. While the comment explicitly states the need for larger experiments, it does not provide specific guidance on how to design these experiments or what parameters to vary. The action is explicit but somewhat vague, as the authors know they need to conduct larger experiments but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and the specific models used in the MNIST and SVHN experiments, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of large-scale experiments and the need to vary the size of the network to determine if the results from small-scale experiments extend to larger scales. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models used in the experiments are too small, suggesting that larger-scale experiments would provide more robust results. However, the comment lacks specific examples or references to support the claim that larger models would yield different outcomes. Without detailed evidence or comparisons, the claim remains somewhat speculative, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the lack of large-scale experiments. It points out that the models used in the experiments are quite small, suggesting that the results may not generalize to larger networks. The comment provides a clear and actionable suggestion by recommending that the authors conduct experiments varying the size of the network to determine if the results from small-scale experiments extend to larger scales. This feedback is valuable as it guides the authors to address a critical gap in their experimental validation, which could significantly enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered specific guidance on how to design these larger-scale experiments or what parameters to vary. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what happens when the matrix W is an identity matrix, suggesting that this would reduce the problem to a spherical case and asking how the results compare with prior work. While the comment implies that the authors should address this scenario and compare their results with existing work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the implications of setting the matrix W to an identity matrix, suggesting that this would reduce the problem to a spherical case and asking for a comparison with prior work. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the implications and comparison with prior work, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the implications of setting the matrix W to an identity matrix and how the results compare with prior work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the implications of setting the matrix W to an identity matrix, suggesting that this would reduce the problem to a spherical case. It also asks for a comparison with prior work, which is a relevant point for the authors to consider. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or conduct the comparison. While it identifies a potential area for exploration, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work primarily focuses on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the application scope. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to broaden the applicability of the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the work, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits the application scope. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited application scope but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work primarily focuses on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it impacts the work\\'s applicability. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to help the authors understand or address the issue. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation of the work, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits the application scope. While this observation is relevant, it does not provide any actionable feedback or suggestions for how the authors might address this limitation or broaden the applicability of their work. Without specific guidance or recommendations, the authors are left with a general understanding of the issue but no clear path to improvement. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that learning both low- and high-frequency information in balance is not novel and mentions several works that promote uniformly learning various frequency domains. It suggests that the authors should analyze or compare their work to these related works. However, the comment does not provide specific guidance on how to conduct this analysis or comparison, nor does it specify which aspects of the related works should be considered. The action is implicit and somewhat vague, as the authors are left to infer the need for a literature review and comparison without detailed instructions on how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of learning both low- and high-frequency information in balance, suggesting that this is not novel and that there are existing works that promote uniformly learning various frequency domains. It mentions specific works that the authors should analyze or compare their work to, providing a list of references. However, the comment does not specify which part of the paper should include this analysis or comparison, making it weakly grounded. The comment is specific in its suggestion to analyze or compare the work to existing literature, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that learning both low- and high-frequency information in balance is not novel, as there have been many works that promote uniformly learning various frequency domains. The reviewer supports this claim by referencing specific works that use stochastic frequency masking or frequency space domain randomization. These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or analyses of these works, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, specifically regarding the learning of both low- and high-frequency information in balance. It points out that there have been many works that promote uniformly learning various frequency domains, and suggests that the authors should analyze or compare their work to these related works. The comment provides specific references to relevant literature, which can guide the authors in situating their work within the existing body of research. However, the comment could be more helpful if it offered more detailed guidance on how to conduct this analysis or comparison. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement and provides some direction, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. This is an explicit suggestion, as it directly instructs the authors to include a specific comparison. However, it does not provide detailed guidance on how to conduct this comparison or what specific aspects should be considered. While the action is clear, the lack of detailed instructions makes it somewhat actionable, as the authors know what to do but may need to determine the specifics on their own.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. However, the comment lacks specificity as it does not explain why the compression bandwidth of PC+IDF should be compared with IDF or what specific aspects need to be addressed in this comparison. Without further details, the authors may not fully understand the critique or how to improve the section. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any justification or reasoning for why this comparison is necessary or how it would benefit the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison between the compression bandwidth of PC+IDF and IDF in Section 5. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending a specific analysis or comparison that could enhance the paper. However, the comment lacks depth and does not provide detailed guidance or rationale for why this comparison is important or how it might impact the overall findings. To be more helpful, the comment could explain the significance of this comparison or suggest additional metrics or analyses that could be included. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the model names T5-ind and T5-seq are misleading and suggests alternative names like Desc-ind/seq, Eg-ind, Demo-ind/seq. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the model naming. The suggestion is concrete, as it offers specific alternatives that the authors can implement to improve the clarity and accuracy of their model names. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the model names \"T5-ind\" and \"T5-seq,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model names, suggesting alternative names like \"Desc-ind/seq,\" \"Eg-ind,\" and \"Demo-ind/seq.\" This provides clear guidance on what needs to be revised. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model names \"T5-ind\" and \"T5-seq\" are misleading and suggests alternative names. However, the comment does not provide any justification or reasoning for why these names are misleading or how the suggested alternatives would be more appropriate. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model names \"T5-ind\" and \"T5-seq,\" suggesting that they are misleading. It provides a clear and actionable suggestion by recommending alternative names like \"Desc-ind/seq,\" \"Eg-ind,\" and \"Demo-ind/seq.\" This feedback is valuable as it helps the authors improve the clarity and accuracy of their model naming, which can enhance the understanding and interpretation of their work by readers. The comment is specific and offers concrete suggestions, making it highly helpful for the authors to enhance the clarity of their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its use in line 055. While it highlights a potential issue with the consistency or clarity of the acronym, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should reconsider the choice of acronym or provide clarification, but it lacks concrete instructions on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 055,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of the acronym \"AR\" for \"artificial intelligence\" and points out its use in line 055, prompting the authors to reconsider or clarify this choice. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its use in line 055. However, it does not provide any reasoning or justification for why this choice is problematic or how it affects the paper. The comment lacks supporting evidence or explanation, making it difficult for the authors to understand the basis of the concern. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of the acronym \"AR\" for \"artificial intelligence,\" noting its use in line 055. While it highlights a potential inconsistency or confusion in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it identifies a potential problem but does not offer constructive advice for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the paper\\'s core idea and the motivation behind the gating design for multi-task learning (MTL). It points out that the gating mechanism is not a new concept in MTL. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify the motivation or improve the novelty of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the core idea of the paper, specifically the motivation behind the gating design for multi-task learning (MTL). It points out that the gating mechanism is not a new concept in MTL. However, the comment does not specify which part of the paper discusses the gating design or the motivation, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the critique of the gating mechanism but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the gating mechanism for multi-task learning (MTL) is not a new concept and that the motivation behind the gating design is unclear. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references to existing work, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the core idea of the paper, specifically the motivation behind the gating design for multi-task learning (MTL). It points out that the gating mechanism is not a new concept in MTL, which suggests that the paper may not contribute significantly to the existing literature. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the practicality of the proposed method, noting that the assumptions required for training the model, such as the availability of ground truth and DM\\'s decisions, may hinder its applicability. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or mitigate the impact of these assumptions. The feedback lacks actionable details, such as recommending ways to reduce the reliance on these assumptions or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practicality of the learning to defer approach, highlighting the strong assumptions required for training the model, such as the availability of ground truth and DM\\'s decisions. However, it does not specify which part of the paper discusses these practical scenarios or assumptions, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of strong assumptions but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the practicality of the learning to defer approach is hindered by strong assumptions required for training, such as the availability of ground truth and DM\\'s decisions. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim. The reasoning is somewhat logical, but without detailed evidence or examples, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practicality of the learning to defer approach, noting that the strong assumptions required for training the model, such as the availability of ground truth and DM\\'s decisions, may hinder its applicability. This feedback highlights a critical area for consideration and improvement, as the assumptions may limit the model\\'s real-world applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address these assumptions or mitigate their impact. While it points out an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental part is less convincing due to the weak baselines used, specifically mentioning LR and SVM compared to deep learning approaches. However, it does not provide any explicit or implicit suggestions for how the authors could strengthen their experimental setup or improve the baselines. Without guidance on what specific changes could be made or how to address the issue, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental part of the paper, specifically mentioning the LR and SVM baselines as weak compared to deep learning approaches. However, it does not specify which part of the experimental section this critique is based on, such as specific experiments, results, or discussions. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the baselines, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the weak baselines used, specifically mentioning LR and SVM compared to deep learning approaches. However, the comment lacks specific examples or detailed reasoning to support why these baselines are considered weak or how they compare to deep learning approaches. Without such evidence or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with the experimental part of the paper, noting that the LR and SVM baselines are weak compared to deep learning approaches. This feedback highlights a potential weakness in the experimental design or choice of baselines, which could impact the validity and credibility of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental setup. Without actionable advice or detailed feedback, the authors are left with only a general understanding of the problem, limiting the comment\\'s helpfulness. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the communication cost, which is a key aspect of the GLASU algorithm\\'s motivation. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or analysis of the communication cost in the theorem and experiment sections, but it does not specify what aspects of the communication cost should be considered or how to present this information. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation of the GLASU algorithm, which is to save communication, and points out that neither the theorem nor the experiment discusses the communication cost. This provides a clear indication of what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper should include this discussion, such as specific sections or experiments. The authors can infer that it relates to the theoretical and experimental sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the issue. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the GLASU algorithm\\'s motivation is to save communication, but neither the theorem nor the experiment discusses the communication cost, which undermines the paper\\'s contribution. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion of communication efficiency. However, it lacks specific examples or references to support the assertion that the communication cost is a critical aspect of the algorithm\\'s contribution. Providing more detailed reasoning or evidence would strengthen the claim, making it easier for the authors to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper regarding the communication cost, which is a key aspect of the GLASU algorithm\\'s motivation. By pointing out that neither the theorem nor the experiment discusses the communication cost, the comment highlights a significant weakness that undermines the paper\\'s contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing ways to incorporate communication cost analysis into the theorem or experiment. While it effectively directs the authors\\' attention to an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explicitly state the contributions of the paper. This is a clear and direct action that the authors can take to improve their draft. However, the comment does not provide specific guidance on how to articulate these contributions or what aspects should be emphasized. While the action is explicit, the lack of detailed instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this feedback pertains to, such as the introduction, conclusion, or a specific section. Additionally, it lacks specificity regarding what aspects of the contributions need to be clarified or how they should be articulated. Without explicit references or detailed guidance, the authors cannot effectively identify the areas needing improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, which is a relevant point for improving the clarity and impact of the paper. However, it lacks specificity and does not provide guidance on how the authors might effectively articulate their contributions or what aspects of the paper should be highlighted. Without detailed suggestions or examples, the authors are left with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the motivation and explanation of the work, specifically pointing out that the statement about \"different densities directly causing semantic conflicts\" should be justified experimentally or theoretically. While the comment identifies a specific area that needs improvement, it does not provide explicit guidance on how to address this issue or what specific experiments or theoretical justifications should be included. The action is implicit and somewhat vague, as the authors know they need to provide justification but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation and explanation of the work, specifically mentioning the statement about \"different densities directly causing semantic conflicts.\" This provides full grounding as it allows the authors to identify the specific part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the need for experimental or theoretical justification of this statement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation and explanation of the work are unclear and not convincing. It specifically mentions that the statement about \"different densities directly causing semantic conflicts\" should be justified experimentally or theoretically. However, the comment does not provide any supporting evidence, examples, or references to substantiate why the explanation is lacking or how it could be improved. This lack of detailed justification makes the claim borderline verifiable, as it provides a general critique without specific guidance for improvement.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clarity in the motivation and explanation of the work. It points out that the statement about \"different densities directly causing semantic conflicts\" is not adequately justified, either experimentally or theoretically. This feedback is clear and actionable, as it directs the authors to provide a stronger justification for their claims. However, the comment could be more helpful if it offered specific suggestions on how to improve the justification or provided examples of what a theoretical or experimental justification might entail. Overall, the comment is mostly helpful as it highlights a significant area for improvement and guides the authors toward enhancing the clarity and rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training methodology of the three transformer modules in the proposed approach, asking whether they are trained iteratively or in an end-to-end manner. It also critiques the inclusion of another three cases in Figure 5, suggesting that repeating the visualization without demonstrating new points is unnecessary. While the comment implies that the authors should clarify the training methodology and reconsider the inclusion of certain visualizations, it does not provide explicit instructions or concrete steps on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and the \"three transformer modules,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the repetition of visualization in Figure 5, suggesting that it is unnecessary if no new points are demonstrated. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training methodology of the three transformer modules, asking whether they are trained iteratively or in an end-to-end manner. It also critiques the inclusion of another three cases in Figure 5, suggesting that repeating the visualization without demonstrating new points is unnecessary. The comment provides a logical reasoning for the critique by pointing out the potential redundancy in the visualization. However, it lacks specific examples or references to support the claim about the necessity of the visualization. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the training methodology of the three transformer modules, asking whether they are trained iteratively or in an end-to-end manner. This is a relevant point that could clarify the approach and potentially improve the understanding of the methodology. Additionally, the comment critiques the inclusion of another three cases in Figure 5, suggesting that repeating the visualization without demonstrating new points is unnecessary. This feedback is clear and actionable, as it prompts the authors to reconsider the presentation of their results and to clarify the training methodology. However, the comment could be more helpful if it provided suggestions on how to improve the visualization or offered examples of how to effectively demonstrate new points. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the writing, suggesting that it could benefit from greater precision and clarity. It offers examples of where the language could be improved, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" Additionally, the comment highlights a potential overlap with infoDiffusion and suggests that the authors explicitly outline the unique contributions of ParamReL to distinguish it from infoDiffusion. While the feedback is explicit in terms of the writing improvements, it is somewhat vague regarding how to clearly articulate the unique contributions of ParamReL. The authors are given a clear direction to improve the writing but may need to infer the exact steps to differentiate ParamReL from infoDiffusion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific feedback on the writing, suggesting improvements in precision and clarity, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" This makes the comment specific. However, it does not explicitly mention which part of the paper these issues are found in, such as specific sections or paragraphs. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing could benefit from greater precision and clarity, providing specific examples such as the distinction between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" This feedback is somewhat verifiable as it highlights a specific area for improvement and provides a concrete example. However, the comment does not offer detailed reasoning or evidence to fully substantiate the claim, such as explaining why these distinctions are important or how they impact the paper\\'s clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the writing, suggesting improvements in precision and clarity. It offers examples of where the language could be more precise, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" This guidance is valuable for the authors to enhance the clarity of their manuscript. Additionally, the comment highlights a potential overlap with infoDiffusion and suggests that the authors explicitly outline the unique contributions of ParamReL to distinguish it from infoDiffusion. This feedback is constructive and helps the authors clarify their contributions, making it mostly helpful. However, it could be more comprehensive by providing additional suggestions on how to differentiate ParamReL from infoDiffusion. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the clarity of the authors\\' focus in the discussion section, specifically mentioning lines 60-74. It suggests that the authors should clarify their intention to focus on a situation where the gradient of the sum is not the sum of the individual gradients. Additionally, it points out that the paragraph from lines 70-74 is a setting shared by all ERM approaches and could be discussed in less space. The comment provides a clear direction for the authors to improve the clarity and focus of their discussion, but it does not offer specific guidance on how to achieve this. While the action is explicit, the lack of detailed instructions on how to implement the changes makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines and section (lines 60-74, beginning of Sect. 2) that the reviewer is referring to, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the focus on a situation where the gradient of the sum is not the sum of the individual gradients, and suggests that the paragraph from lines 70-74 could be discussed in less space. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' focus on a specific situation is not clearly communicated in the text, particularly in the paragraph from lines 70-74. The reviewer suggests that this setting is shared by all ERM approaches and could be discussed in less space. While the comment provides some reasoning by highlighting the rarity of the situation discussed, it lacks specific examples or references to support the claim fully. The suggestion to discuss the situation in less space is based on logical reasoning but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the authors\\' focus in the discussion section, specifically regarding the gradient of the sum and its relationship to individual gradients. It points out that the authors\\' intention to focus on a specific situation is not clearly communicated in the text. The comment also suggests that the paragraph from lines 70-74 could be discussed in less space, as it is a setting shared by all ERM approaches. This feedback is somewhat helpful as it highlights a specific area where the authors can improve the clarity and focus of their discussion. However, it lacks detailed suggestions on how to achieve this clarity or how to restructure the discussion, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides detailed analysis, noting that out of 100 passages, 23% become invalid, with 44% of these attributed to unresolved coreference. The comment also mentions that the proposed method rewrites only 12% of the questions for all models, which is considered insignificant. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their strategy. The feedback highlights issues but lacks actionable steps or concrete recommendations, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed question-rewrite strategy\" and references specific data from Table 4 in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the method\\'s effectiveness, particularly the high percentage of invalid questions and the limited impact of the proposed method. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides detailed analysis, noting that out of 100 passages, 23% become invalid, with 44% of these attributed to unresolved coreference. The comment also references specific data from Table 4 in the appendix and mentions that the proposed method rewrites only 12% of the questions for all models, which is considered insignificant. This detailed breakdown and reference to specific data provide a robust basis for the claim, making it fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the proposed question-rewrite strategy, questioning its effectiveness in covering a sufficiently large number of questions. It provides detailed analysis, noting that out of 100 passages, 23% become invalid, with 44% of these attributed to unresolved coreference. The comment also points out that the proposed method rewrites only 12% of the questions for all models, which is considered insignificant. This feedback is valuable as it highlights a potential weakness in the methodology and provides specific data to support the claim. However, the comment could be more helpful if it offered suggestions on how to address these issues or improve the strategy. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides some insight into the problem, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of L2 distance in equation (4) and asks for the benefit of using it instead of the more common earth mover\\'s distance in OT. While the comment raises a valid question, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they might need to justify or explain the choice of L2 distance, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in equation (4) and asks for the benefit of using it instead of the more common earth mover\\'s distance in OT. This provides clear guidance on what aspect of the paper needs clarification or justification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in OT. However, the comment does not provide any supporting evidence or reasoning to justify why the use of L2 distance is problematic or how it differs from the earth mover\\'s distance. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of L2 distance in equation (4), suggesting that earth mover\\'s distance is more common in OT. This feedback is somewhat helpful as it prompts the authors to consider and justify their choice of distance metric, which could lead to a clearer explanation or improvement in the paper. However, the comment lacks depth and does not provide suggestions on how to address this issue or why it might be important. To be more helpful, the comment could include a rationale for why earth mover\\'s distance is preferred or suggest ways to demonstrate the benefits of using L2 distance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section is scattered throughout the paper and recommends a broader discussion on how the algorithm compares to other offline reinforcement learning (RL) algorithms. While the comment implies that the authors should consolidate the related work discussion and provide a more comprehensive comparison, it does not specify which sections need restructuring or how to conduct the comparison. The action is implicit and somewhat vague, as the authors know they need to improve the related work section but lack detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of related work, specifically mentioning that it is scattered throughout the paper and suggests a broader discussion on how the algorithm compares to other offline RL algorithms. However, it does not specify which sections or parts of the paper are problematic, making it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where the related work is discussed, the comment lacks full grounding. It is specific in suggesting a broader discussion but does not provide detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the related work section is scattered throughout the paper and suggests a broader discussion on how the algorithm compares to other offline RL algorithms. However, the comment does not provide specific examples or references to support the claim about the scattered nature of the related work section. Additionally, it lacks detailed reasoning or evidence to substantiate the need for a broader discussion on comparisons. This makes the claim somewhat verifiable, as it provides a general suggestion but lacks the necessary detail to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a structural issue with the related work section, noting that it is scattered throughout the paper. It suggests that a broader discussion on how the algorithm compares to other offline reinforcement learning (RL) algorithms would be beneficial. While the comment highlights an area for improvement, it lacks specific guidance on how to reorganize the related work section or what aspects of the comparison should be emphasized. This limits the comment\\'s helpfulness, as it provides a general suggestion without detailed direction. Therefore, the comment is somewhat helpful, as it points out a weakness but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the final solution changes if all increments are available at the same time. While it implies that the authors should address this question, it does not provide explicit instructions or concrete guidance on how to incorporate this into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect and determine how to address it in their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment poses a question about the final solution and its changes if all increments are available at the same time. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the impact of simultaneous availability of increments on the final solution, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of simultaneous availability of increments on the final solution. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the impact of simultaneous availability of increments on the final solution. This is a relevant inquiry that could help the authors clarify or refine their methodology or results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or what implications it might have for their work. While it points out a potential area for exploration, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the technique of using multiple different feature spaces, describing it as convoluted and potentially circular. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their approach. The comment lacks actionable guidance, such as recommending a simpler approach, providing alternative methods, or suggesting ways to clarify the technique. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the technique of using multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned GloVe model. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity regarding what exactly is convoluted or circular about the technique. It does not provide detailed guidance on how to simplify or clarify the approach. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the technique of using multiple different feature spaces is \"convoluted and potentially circular.\" However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed explanation or references to substantiate why the technique is problematic, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable due to the absence of supporting evidence or justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the technique used in the paper, specifically the use of multiple different feature spaces. It describes the technique as convoluted and potentially circular, which could indicate a lack of clarity or coherence in the approach. However, the comment does not provide specific suggestions or guidance on how the authors might simplify or improve this aspect of their work. Without actionable feedback or detailed advice, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is somewhat helpful, as it points out a potential issue but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and to provide their FLOPs and parameter sizes. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback provides clear and specific actions for the authors to take, including adding comparisons and explaining the omission of certain results. The explicit nature of the instructions and the concrete details on what needs to be done make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and the inclusion of FLOPs and parameter sizes. Additionally, it questions the omission of results from OFA with progressive shrink. This provides clear guidance on what needs to be revised or added to the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 7 should include comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and questions the omission of results from OFA with progressive shrink. While the comment highlights a potential gap in the comparison, it does not provide specific examples or references to support the claim that these comparisons are necessary or beneficial. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out the omission of comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and questioning the absence of results from OFA with progressive shrink. This guidance is clear and directs the authors to include additional comparisons and explanations in their table, which can significantly enhance the comprehensiveness and relevance of their analysis. By addressing these points, the authors can improve the depth and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a brief discussion on why fixing hallucinations is necessary, beyond merely pointing to existing work. While the action is explicit, it lacks concrete guidance on how to structure this discussion or what specific aspects to cover. The authors are given a clear direction to add a discussion, but the lack of detailed instructions on how to implement this suggestion makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a brief discussion on why fixing hallucinations is necessary and points to existing work. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting the need for a discussion on the undesirability of hallucinations and the reference to existing work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a discussion on why fixing hallucinations is necessary, beyond merely pointing to existing work. However, it does not provide any specific reasoning or evidence to support why this discussion is important or how it would enhance the paper. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a brief discussion on why fixing hallucinations is necessary, beyond merely pointing to existing work. This feedback is somewhat helpful as it identifies a potential gap in the paper that could be addressed to provide a clearer rationale for the work. However, the comment lacks specific guidance or examples on how to structure this discussion or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could suggest specific points to cover or references to include. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the ordering of information in the manuscript, specifically noting that terms like \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. However, the comment does not provide explicit guidance on how to address this issue or suggest a specific action, such as reordering the information or providing additional context. The feedback is vague and lacks concrete instructions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (50-54) and terms like \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in stating the null hypothesis before these terms are introduced. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential issue with the ordering of information in the manuscript, noting that terms like \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. However, the comment does not provide any reasoning or justification for why this ordering is problematic or how it affects the understanding of the manuscript. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the ordering of information in the manuscript, noting that terms like \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. This feedback is somewhat helpful as it points out a potential source of confusion for readers, prompting the authors to reconsider the order of their explanations. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the clarity of the presentation. To be more helpful, the comment could include specific guidance on how to reorder the information or provide additional context to enhance understanding. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential uncertainty inherent in estimating a continuous importance weight function, particularly in combination with the regularization process. It asks the authors how they address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might resolve it. The action is implicit, as the authors need to infer that they should address the issue of uncertainty, and it is vague because it lacks concrete steps or methods for doing so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the potential uncertainty in estimating a continuous importance weight function, particularly in combination with the regularization process. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential problem of inherent uncertainty and asks for a solution, but it does not provide detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential uncertainty in estimating a continuous importance weight function, particularly in combination with the regularization process. The comment suggests that this uncertainty could affect the model\\'s reliability in certain cases. However, the claim lacks specific examples, detailed reasoning, or references to support the assertion about the inherent uncertainty and its impact. Without such evidence or explanation, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered borderline verifiable, as it provides a general concern but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the estimation of a continuous importance weight function, particularly in combination with the regularization process. It highlights the concern that this may introduce uncertainty, which could affect the model\\'s reliability in certain cases. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the uncertainty. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the performance of SFAM scorers, which are fundamental components of the LISA embedding, and their correlation with human judgments on more linguistics-relevant styles. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the alignment between the SFAM scorers and human judgments. There is no guidance on potential modifications, additional experiments, or analyses that could be conducted to resolve this discrepancy. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the performance of SFAM scorers, which are fundamental components of the LISA embedding, and their correlation with human judgments on more linguistics-relevant styles. However, it does not explicitly mention which part of the paper discusses these scorers or the LISA embedding, making it weakly grounded. The comment is specific in detailing the issue of poor correlation with human judgments on linguistics-relevant styles, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This claim is supported by the observation that the scorers perform well on styles that are more semantics-relevant, such as sentiment and emotion. The reasoning is logical and provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It highlights that while the scorers correlate well with human judgments on styles that are more semantics-relevant, they do not perform as well on more linguistics-relevant styles. This observation suggests that the LISA embedding might be more content-focused rather than style-focused. The comment provides a clear and actionable insight into a potential weakness in the methodology, prompting the authors to consider how to address this discrepancy. However, it could be more helpful if it offered suggestions on how to improve the alignment with human judgments on linguistics-relevant styles. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their experiments on other real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. This feedback provides a clear and explicit action for the authors to take, which is to include additional datasets and pipelines in their evaluation. The suggestion is concrete, as it specifies the types of datasets and pipelines to consider, giving the authors a direct path to improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the experiments on other real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or a particular table or figure. The authors can infer that it relates to the experimental evaluation, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the inclusion of additional datasets and pipelines, providing clear guidance on what could be improved. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the experiments on other real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. However, the comment does not provide any justification or reasoning for why these datasets or pipelines are necessary or how they would improve the study. Without specific examples or references to support the claim, the comment lacks verifiability. Therefore, it is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests expanding the experimental evaluation by including additional real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. This feedback is clear and actionable, providing the authors with a specific direction to enhance the robustness and applicability of their experiments. By suggesting the inclusion of these datasets and pipelines, the comment offers a concrete way to improve the paper, making it mostly helpful. However, it could be more helpful if it provided additional context or rationale for why these datasets are important or how they might impact the results. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment highlights a lack of explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. While it identifies areas that need clarification, it does not provide specific guidance on how the authors should address these issues or what aspects should be elaborated on. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of explicit explanation regarding important components, such as the design of sequential models and the updating of the attention model. However, it does not specify which sections or parts of the paper these components are discussed in, making it weakly grounded. The comment is specific in identifying what is missing\u2014explicit explanations for these components\u2014but without clear references to specific sections, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation on important components, such as the design of sequential models and the updating of the attention model. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks references or detailed explanations that would help the authors understand why these explanations are critical or how they could be improved. As a result, the claim is not well-supported, making it difficult for the authors to address the feedback effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of explicit explanation regarding important components such as the design of sequential models and the updating of the attention model. This feedback highlights a critical area that needs clarification to enhance the reader\\'s understanding of the proposed work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular sections to expand or examples of what information should be included. While it points out a key weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should make the entire code accessible if the paper is accepted. This is an explicit and concrete action, as it clearly instructs the authors on what they need to do to improve their draft. The comment provides a direct and specific suggestion, ensuring that the authors know exactly how to apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the entire code should be made accessible if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding how making the code accessible would improve the paper or what specific aspects of the code should be accessible. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that making the entire code accessible would be helpful if the paper is accepted. However, it does not provide any justification or reasoning for why this would be beneficial. The comment lacks specific examples or explanations of how access to the code would enhance the paper or its impact. Without these details, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should make their entire code accessible if the paper is accepted. This is a clear and actionable piece of feedback that can significantly benefit the authors by enhancing the reproducibility and transparency of their work. By making the code accessible, the authors can ensure that their findings can be verified and built upon by others, which is a valuable contribution to the research community. However, the comment could be more helpful if it provided additional context or justification for why this is important, such as how it would improve the paper\\'s impact or address potential concerns about reproducibility. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a concrete suggestion to include pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve the clarity of their explanations.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hybrid architecture\" and specific processes like \"spike-driven token selection\" and \"intra- and inter-stage feature fusion,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests that the explanations of these processes could be clearer and provides a concrete suggestion to include pseudo-code or flow diagrams to enhance understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a constructive suggestion to include pseudo-code or flow diagrams to enhance understanding. However, the comment does not provide specific examples or detailed reasoning to support why these explanations are unclear or how the suggested improvements would benefit the reader. This lack of detailed justification makes the claim somewhat verifiable, as it provides a direction for improvement but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the explanations in the paper could be improved, such as the processes of spike-driven token selection and intra- and inter-stage feature fusion. It suggests that including pseudo-code or flow diagrams could enhance the reader\\'s understanding of the model\\'s operation. This feedback is clear and actionable, providing the authors with concrete steps to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate these visual aids or provided examples of similar improvements in other works. Overall, the comment is mostly helpful as it directs the authors toward specific enhancements that can improve the reader\\'s understanding of the model.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides an assessment of the proposed method, noting that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It also mentions that the standard deviation is large, which raises doubts about generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how the authors might improve the method or provide additional evidence to support its generalizability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the proposed method, suggesting that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It mentions specific metrics like the improvement of 0.3 on ImageNet and the large standard deviation, which raises doubts about generalizability. However, the comment does not specify which part of the paper these observations are based on, nor does it provide detailed guidance on how to address these concerns. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It supports this claim by providing specific metrics, such as the 0.3 improvement on ImageNet and the large standard deviation, which raises doubts about generalizability. This detailed comparison with specific metrics makes the claim mostly verifiable, as it provides a clear basis for the reviewer\\'s opinion. However, the comment could be strengthened by referencing specific recent methods or studies for comparison, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critical assessment of the proposed method, noting that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It specifically mentions that the improvement on ImageNet is only 0.3 compared to [18], and it raises concerns about the large standard deviation, which could affect generalizability. While the comment identifies areas for improvement, it lacks specific suggestions or actionable steps for the authors to enhance their work. The feedback is somewhat helpful as it highlights potential weaknesses and areas for further exploration, but it could be more beneficial with additional guidance or recommendations. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison is weak without referencing existing prior arts, such as [1], and mentions that a simple search shows significant performance gaps between the proposed method and the latest methods. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific prior arts to include or how to conduct a more robust comparison. The action is implicit and vague, as the authors are left to infer that they need to improve the comparison but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the comparison in the paper, specifically mentioning the lack of reference to existing prior arts and the significant performance gaps between the proposed method and the latest methods. However, it does not specify which part of the paper this critique is based on, such as the results section or the discussion of related work. This makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its critique of the comparison, it lacks grounding as it does not direct the authors to a particular section or aspect of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison is weak due to the lack of reference to existing prior arts and highlights significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific examples of prior arts or the latest methods, nor does it detail the performance gaps. This lack of detailed evidence or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of comparison to existing prior arts and the existence of significant performance gaps between the proposed method and the latest methods. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to include relevant references and address the performance gaps. However, the comment could be more helpful if it provided specific examples of prior arts or suggested how the authors might conduct a more robust comparison. Despite this, the feedback is clear and actionable, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide quantification of the diversity of the data gathered, noting that this is not difficult to do. It specifically recommends a \"shallow types vs. token statistic\" as a useful starting point. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to include a quantification of the data diversity.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the argument for the diversity of the data gathered and suggests that quantification is needed. However, it does not specify which part of the paper discusses this argument, making it weakly grounded. The comment is specific in suggesting a types vs. token statistic as a way to provide quantification, which adds clarity to the feedback. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but do not provide quantification, suggesting that even a simple types vs. token statistic would be useful. This claim is somewhat verifiable as it highlights a gap in the paper regarding the quantification of data diversity. However, it lacks specific examples or references to support the assertion that quantification is necessary or how it would improve the paper. The authors would need to infer the importance of quantification based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the authors argue for the diversity of the data gathered but do not provide quantification. It suggests that even a simple types vs. token statistic would be useful to support this argument. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by adding quantitative analysis. However, it could be more helpful if it offered additional guidance on how to implement this suggestion or why it is important. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the paper claims to have created a more diverse set of positive (similar) instance pairs but lacks sufficient evidence or comparison with earlier works to support this claim. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific measures of diversity or comparisons that could be included. The action is implicit and vague, as the authors are left to infer that they need to provide more evidence or comparisons, but without concrete steps or examples, the comment is not actionable. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the creation of a more diverse set of positive (similar) instance pairs. It points out that this claim is not sufficiently backed by the paper, as it lacks a suggested measure of diversity and does not compare with earlier works regarding the diversity of examples. However, the comment does not explicitly mention which section or part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing what is missing\u2014measures of diversity and comparisons with earlier works\u2014but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the paper has created a more diverse set of positive (similar) instance pairs, noting that this claim is not sufficiently backed by evidence. The reviewer points out the lack of a suggested measure of diversity and comparison with earlier works regarding the diversity of examples. While the comment identifies a gap in the paper\\'s support for its claim, it does not provide specific examples or references to substantiate the need for such measures or comparisons. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the critique without explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific claim made in the paper regarding the creation of a more diverse set of positive (similar) instance pairs. It points out that this claim is not sufficiently supported, as the paper lacks a suggested measure of diversity and does not compare its results with earlier works on diversity. This feedback is somewhat helpful as it highlights a gap in the paper\\'s justification of its claims. However, it could be more helpful if it provided suggestions on how the authors might measure diversity or compare their work with existing literature. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors think their approach would compare to or work with other inputs, such as structured information, and mentions that AUCROC seems high in other models in literature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address this comparison in their paper, how they might do so, or what specific aspects of their approach should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how the authors think their approach would compare to or work with other inputs, such as structured information, and mentions that AUCROC seems high in other models in literature. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the comparison with other inputs and the AUCROC metric, but without clear grounding, the authors may struggle to identify where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for the authors\\' opinion on how their approach would compare to or work with other inputs, such as structured information. It also mentions that AUCROC seems high in other models in literature, but this is more of an observation than a claim. The comment does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about how the authors\\' approach would compare to or work with other inputs, such as structured information. It also mentions that AUCROC seems high in other models in literature, which could be a point of interest for the authors. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this comparison or improve their work. Without detailed feedback or specific advice, the authors are left with only a general idea of what could be explored, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit and concrete actions for the authors to take. It suggests stating the objective function in experiments, including monte carlo estimates of the expectations, and questions the inequality sign in Eq. 7, suggesting it should be reversed. It also recommends leaving more space in section 4 to explain the training procedure, which is a clear and actionable suggestion. The comment is highly actionable as it provides specific guidance on how to improve the draft, ensuring the authors know exactly what changes to make.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, equations, and parts of the paper, allowing the authors to accurately identify the areas being addressed. It is also specific because it provides detailed feedback on the objective function, the inequality sign in Eq. 7, and the technical aspects of section 3 that may need clarification. The suggestion to leave more space in section 4 to explain the training procedure is also specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the objective function should be stated in experiments, including Monte Carlo estimates of expectations, and questions the inequality sign in Eq. 7. It also mentions that some parts of Section 3 are technical and do not aid in understanding the main method in Section 4. The comment provides specific suggestions for improvement, such as clarifying the objective function and the inequality sign, and suggests leaving more space in Section 4 to explain the training procedure. However, it lacks detailed reasoning or references to support the claims about the technical nature of Section 3 or the need for more explanation in Section 4. This makes the comment somewhat verifiable, as it provides a basis for the suggestions but requires further elaboration to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It explicitly recommends stating the objective function in experiments, including Monte Carlo estimates of expectations, and questions the inequality sign in Eq. 7, suggesting it should be reversed. Additionally, it points out that some parts of Section 3 are technical and do not aid in understanding the main method in Section 4, suggesting that more space in Section 4 could be beneficial for explaining the training procedure. While the comment acknowledges that this might be a personal preference, it still offers a constructive suggestion for improvement. The feedback is clear, specific, and actionable, making it highly helpful for the authors to enhance their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the decreasing trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot) and asks for an explanation. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can deduce that they need to address this issue by providing an explanation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.3, top right plot,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the explanation for the decreasing trend in the Disc. reward for SPACE and f-PCPO in the Grid. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding the decreasing trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the decreasing trend in the Disc. reward for SPACE and f-PCPO in the Grid, as shown in Figure 3. It asks for an explanation, which is a clear and actionable piece of feedback. By addressing this point, the authors can provide a clearer understanding of their results and potentially improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it suggested potential reasons for the observed trend or offered guidance on how to present this information more effectively. Overall, the comment is mostly helpful as it identifies a specific area for improvement and prompts the authors to provide an explanation, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of key implementation details, specifically mentioning the resolutions at which images successfully achieve adversarial effects. This comment implies that the authors should include these details in their draft. While the action is not explicitly stated, it is clear and concrete, as the authors know exactly what information is missing and need to add it to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the absence of key implementation details, specifically mentioning the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying what is missing, namely the resolutions at which adversarial effects are achieved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"key implementation details are missing,\" specifically mentioning the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the importance or relevance of this information. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of key implementation details regarding the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it directs the authors to include this information to enhance the comprehensiveness and transparency of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is crucial for the study. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the effectiveness of using DDIM Inversion for data preprocessing but notes that it does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. While the comment implies that the authors should consider alternative strategies for motion guidance, it does not provide specific guidance on how to implement these improvements or what specific strategies to explore. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"section on data preprocessing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach involving DDIM Inversion and suggests exploring improvements to the motion guidance strategy to enhance training efficiency. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the effectiveness of using DDIM Inversion for data preprocessing but notes that it does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current approach does not simplify complexity. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further detail to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the data preprocessing section, where the authors use DDIM Inversion to obtain motion guidance for training. It acknowledges the effectiveness of this approach in reducing training time but points out that it does not significantly simplify the overall complexity. The comment suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, providing the authors with a direction to consider alternative strategies that could lead to more efficient training. However, it could be more helpful if it offered specific examples or suggestions for improving the motion guidance strategy. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also mentions a potential disadvantage of chunking things into relation phrases, which could lead to the problem of a heavy tail in relations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about how to respond to the concerns raised. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also discusses the potential disadvantage of chunking things into relation phrases, which could lead to a heavy tail in relations. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing methodology or results, but this inference is not direct. The comment is specific in detailing the issues with relation phrases and the potential problem of a heavy tail, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and observations about the statistics of relation phrases and the potential disadvantage of chunking things into relation phrases. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also discusses a potential disadvantage of chunking things into relation phrases, which could lead to the problem of a heavy tail in relations. While the comment identifies a relevant issue, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more beneficial with additional detail or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the statement about robustness in dynamic regions is generally true but highlights the existence of edge cases that require more robust approaches. It provides specific examples, such as the Bonn dataset, where moving objects can occupy a significant portion of the image. The comment suggests potential solutions, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment does not explicitly instruct the authors to implement these solutions, the suggestions are concrete and provide clear guidance on how to address the issue. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement about \"robustness in dynamic regions\" and provides a specific example from the Bonn dataset. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the statement and suggests potential solutions, such as masking out dynamic regions or re-running relative pose estimation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the statement about robustness in dynamic regions is generally true but highlights the existence of edge cases that require more robust approaches. It provides a specific example from the Bonn dataset, where moving objects can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions or re-running relative pose estimation. This provides a logical reasoning and specific example to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to similar cases in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the general truth of a statement regarding robustness in dynamic regions but highlights the existence of edge cases that require more robust approaches. It provides a specific example from the Bonn dataset, where moving objects can occupy a significant portion of the image, and suggests potential solutions such as masking out dynamic regions or re-running relative pose estimation. This feedback is clear and actionable, offering the authors specific directions for addressing the issue of robustness in dynamic regions. By providing concrete examples and solutions, the comment empowers the authors to enhance their work, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only focus on comparing various models proposed by the authors and lack a comparison with other methods. While it identifies a gap in the experimental setup, it does not provide explicit guidance on how to address this issue. The authors can infer that they need to include comparisons with other methods, but the comment does not specify which methods should be considered or how to integrate these comparisons into the existing framework. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, noting that they only focus on comparing various models proposed by the authors and lack a comparison with other methods. However, it does not specify which part of the paper this issue pertains to, such as the results section or the discussion of related work. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for comparisons with other methods, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments only focus on comparing various models proposed by the authors and lack a comparison with other methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this lack of comparison is a concern or how it impacts the paper\\'s conclusions. Without additional context or explanation, the claim is difficult for the authors to address, making it unverifiable. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental design, noting that the experiments only focus on comparing various models proposed by the authors and lack a comparison with other methods. This feedback highlights an area for improvement, as including comparisons with existing methods could enhance the paper\\'s contribution and relevance. However, the comment does not provide specific suggestions on which methods to consider or how to integrate these comparisons into the existing framework. While it points out a clear weakness, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor inconsistency in the labeling of models in Table 3 and 4, noting that the models labeled as \"math specialists\" are not indicated with an asterisk, while the MAVIS models should also be considered math specialists. The comment suggests adding an asterisk to the MAVIS models to align with the labeling of other models. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency in labeling models as \"math specialists\" without an asterisk. The comment suggests adding an asterisk to the MAVIS models to align with the labeling of other models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a minor observation about the labeling of models in Tables 3 and 4, suggesting that the MAVIS models should also be considered math specialists and labeled accordingly. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is a factual observation and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a minor inconsistency in the labeling of models in Tables 3 and 4, noting that the models labeled as \"math specialists\" are not indicated with an asterisk, while the MAVIS models should also be considered math specialists. This feedback is specific and actionable, as it provides a clear direction for the authors to correct the labeling to ensure consistency and clarity in the presentation of their results. However, the comment could be more helpful if it explained why this inconsistency is important or how it might impact the reader\\'s understanding of the results. Overall, the comment is mostly helpful as it guides the authors to make a straightforward improvement to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. It suggests that the work provides few insights into a non-parametric method for text classification. However, the comment does not offer any specific guidance or suggestions on how the authors could enhance the novelty or provide more insights. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical novelty of the work, specifically mentioning that KNN-based methods are widely studied in LM and MT. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the work lack novelty or how it could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. However, the comment does not provide specific examples or references to support this claim, nor does it elaborate on how the work lacks novelty or insights. This lack of detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the technical novelty of the work, noting that KNN-based methods are widely studied in LM and MT. It suggests that the work provides few insights into a non-parametric method for text classification. While the comment identifies a potential weakness, it lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overstates the extent of the improvement in the IM for most existing RL algorithms, as the most recent description of mainstream RL algorithms in the related work is SAC from 2018. It suggests that the paper lacks a comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. While the comment identifies a specific issue with the paper\\'s claims and suggests a need for comparison with more recent work, it does not provide explicit guidance on how to address this issue or which specific approaches should be considered. The action is implicit and somewhat vague, as the authors know they need to update the related work section but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s emphasis on the extensive enhancement of the IM for most existing RL algorithms and critiques the related work section for only mentioning SAC from 2018 as the most recent description of mainstream RL algorithms. It suggests that the paper lacks a comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or table where the related work is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed, namely, the inclusion of more recent work and a comparison with non-pixel-based approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overstates the extent of the improvement in the IM for most existing RL algorithms, as the most recent description of mainstream RL algorithms in the related work is SAC from 2018. The reviewer suggests that the paper lacks a comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. While the comment identifies a potential issue with the paper\\'s claims, it does not provide specific examples or references to the latest work that should be considered for comparison. This makes the claim somewhat verifiable, as it highlights a gap but lacks detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim about the extensive enhancement of the IM for most existing RL algorithms. It points out that the most recent description of mainstream RL algorithms in the related work is SAC from 2018, suggesting that the paper overstates its claims. The comment also highlights the lack of comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. This feedback is somewhat helpful as it directs the authors to reconsider their claims and provide a more current and comprehensive comparison. However, it could be more helpful if it offered specific suggestions on how to incorporate the latest work or provided examples of non-pixel-based approaches to consider. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests expanding the background discussion in Section 2 by including further background knowledge on adversarial examples and threat models. It also recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA). This feedback provides clear and concrete actions for the authors to take, including specific areas to expand and references to consider. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2\" and the related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests expanding the background discussion with further knowledge on adversarial examples and threat models, and it provides a clear direction for improvement by recommending references to relevant surveys. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the background discussion in Section 2 by including further knowledge on adversarial examples and threat models. It recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA). While the comment provides a logical suggestion for improvement, it lacks specific examples or references to the surveys that should be included. This makes the claim somewhat verifiable, as the authors would need to identify and incorporate these references themselves to fully address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending an expansion of the background discussion in Section 2. It specifically suggests including further background knowledge on adversarial examples and threat models, such as white-box, grey-box, and black-box models, to enhance the clarity of the threat model and position at the state-of-the-art (SoA). Additionally, it advises referencing relevant surveys to facilitate understanding for non-expert readers. This feedback is detailed and constructive, offering a concrete way for the authors to enhance the comprehensiveness and accessibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable guidance, such as recommending specific aspects to elaborate on or examples to include. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the essentiality of the proposed setting in real-world applications. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the essentiality of the proposed multiple-span answer setting in real-world applications. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the methodology, specifically asking why the train set examples are not mixed with hypernyms and non-hypernyms. While the comment implies that the authors should consider this mixing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (\"558\" and \"574ff\"), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the methodology of not mixing train set examples with hypernyms and non-hypernyms. This provides clear guidance on what aspect of the methodology needs to be reconsidered. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the methodology. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the methodology, specifically asking why the train set examples are not mixed with hypernyms and non-hypernyms. This question prompts the authors to reconsider their experimental setup and potentially explore alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to implement this change or why it might be beneficial. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to provide results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table-1. This is a clear and direct action, leaving no ambiguity about what the authors need to do. The comment specifies the exact results that are being requested, making it highly actionable. The authors know exactly what additional information to include in their draft, ensuring they can effectively address this feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to \"Table-1\" and the \"AdpCLR_full\" approach, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture. This provides clear guidance on what additional information is needed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional results, specifically asking for the results of the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table-1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests additional results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table-1. This feedback is clear and actionable, as it directly points out a specific area where the authors can enhance their paper by providing additional data. By addressing this request, the authors can improve the comprehensiveness and completeness of their results section, which is valuable for readers seeking a more thorough understanding of the study. However, the comment could be more helpful if it explained why these additional results are important or how they might impact the overall conclusions of the paper. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether this is a point of confusion that needs clarification, a question that requires further exploration, or a suggestion for improvement. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context being addressed. Additionally, the comment lacks specificity regarding what aspect of the N trajectories or the Dyna model is being questioned. Without clear grounding or specificity, the authors cannot effectively understand or address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the similarity between N trajectories and the concept of replay in the Dyna model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. While it highlights a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this issue or clarify the concept in their draft. As a result, the comment is not particularly helpful, as it lacks specificity and actionable advice. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the suspicious nature of some experiment results, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2-hop EG to a 3-hop EG. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending a specific investigation or analysis to verify the results. As a result, the authors are left without a clear understanding of what steps to take to resolve the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the specific parts of the paper being addressed, which provides full grounding. It also specifies the issue by pointing out that the results in these tables are suspicious, particularly noting that they share the same result despite changing the 2-hop EG to a 3-hop EG. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2-hop EG to a 3-hop EG. This claim is somewhat verifiable as it provides a specific example of the issue, which is the identical results in two tables with different experimental conditions. However, the comment lacks further explanation or evidence to fully substantiate the claim, such as additional comparisons or references to similar findings in other studies. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the suspicious nature of some experiment results, specifically pointing out that Tables 16 and 17 share the same result despite changing the 2-hop EG to a 3-hop EG. This observation is valuable as it highlights a potential issue with the experimental setup or analysis that the authors should investigate further. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or verify the results. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the experimental results show some advantages of the proposed algorithms, but these advantages are not significant. It also mentions that the algorithms are still competitive with state-of-the-art algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of insignificant advantages or improve the competitiveness of their algorithms. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the experimental results show some advantages of the proposed algorithms, but these advantages are not significant. It also notes that the algorithms are still competitive with state-of-the-art algorithms. However, the comment does not specify which part of the paper these observations are based on, nor does it provide details on what aspects of the algorithms are considered advantageous or how they compare to state-of-the-art algorithms. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms, but these advantages are not significant. It also notes that the algorithms are still competitive with state-of-the-art algorithms. However, the comment lacks specific examples or detailed reasoning to support the claim that the advantages are not significant. Without concrete evidence or references to compare the proposed algorithms against state-of-the-art ones, the claim remains vague and difficult for the authors to verify. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not significant. It also mentions that the algorithms are still competitive with state-of-the-art algorithms. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or constructive criticism, the authors are left without a clear understanding of how to enhance their work or address the perceived lack of significance in their results. Therefore, the comment is not particularly helpful in guiding the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to overconfidence in the LLM\\'s predictions. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might mitigate the overconfidence issue or improve the protocol. Without specific suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the \"per-sentence assessment protocol\" and mentions its potential issue with overconfidence in the LLM\\'s predictions. However, it does not specify which part of the paper discusses this protocol, making it weakly grounded. The comment does specify the issue of overconfidence, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the per-sentence assessment protocol may be prone to overconfidence in the LLM\\'s predictions, suggesting that the LLM prefers its predictions even if they are incorrect. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to overconfidence in the LLM\\'s predictions. This is a relevant observation that could impact the reliability and accuracy of the protocol. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the protocol. Without actionable feedback or detailed advice, the authors are left with a general concern but no clear path to resolution. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the explanation provided in Appendix C regarding the minimization of $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$. The reviewer asks what makes this reflect only non-semantic diversity and not semantic diversity. While the comment highlights a potential gap in the explanation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the explanation, and it is vague because it lacks concrete steps on how to improve the explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3\" and \"App. C,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning what makes the explanation in Appendix C reflect only non-semantic diversity and not semantic diversity. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the explanation provided in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the explanation provided in the paper regarding the minimization of $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$, as explained in Appendix C. It specifically asks what makes this reflect only non-semantic diversity and not semantic diversity. This feedback is somewhat helpful as it highlights a potential gap in the explanation that the authors need to address. However, the comment does not provide specific suggestions or guidance on how to clarify this point, which limits its helpfulness. The authors are informed of an area needing clarification but are not given detailed direction on how to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential reasons for the promising experimental results, suggesting that it could be due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should investigate or address this concern, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential reasons for the promising experimental results, suggesting that it could be due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry but lacks grounding because it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the potential reasons for the promising experimental results. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the potential reasons for the promising experimental results, suggesting that it could be due to the superiority of the method or an accidental result from a specific kernel function and feature map. This question prompts the authors to consider the robustness and generalizability of their findings, which is a critical aspect of experimental validation. However, the comment does not provide specific guidance or suggestions on how the authors might investigate or address this issue, such as recommending additional experiments or analyses. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. While it implies that the authors should include this description, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on where or how to incorporate this information. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this estimation should be described. The authors might infer that it relates to the algorithmic description, but this inference is not direct. The comment is specific in pointing out the missing description but lacks grounding because it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. While it identifies a potential gap in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the estimation process. The feedback is vague and lacks actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential problem but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is complex, involving modified Gromov-Hausdorff distances and hypergraph structures, which likely increases time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. The comment suggests that a discussion of the computational costs associated with training would be beneficial. While the comment implies that the authors should include a discussion on computational costs, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures, which likely increases time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is discussed in Appendix B. The comment suggests that a discussion of the computational costs associated with training would be beneficial. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where these components are discussed. The suggestion is specific, as it points to a particular aspect that needs further discussion. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is complex, involving modified Gromov-Hausdorff distances and hypergraph structures, which likely increases time complexity. The reviewer acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. While the comment provides some reasoning by referencing the theoretical analysis and inference efficiency, it lacks specific examples or detailed evidence to fully substantiate the claim about the computational costs. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the proposed method, noting that it involves modified Gromov-Hausdorff distances and hypergraph structures, which likely increases time complexity. The comment acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, it suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is somewhat helpful as it points out an area for improvement and provides a direction for the authors to enhance their draft. However, it could be more helpful by offering specific suggestions on how to address the computational costs or by providing examples of how similar methods have handled such issues. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method may not represent a groundbreaking innovation within the field and lacks distinction from existing contrastive decoding techniques. However, it does not provide specific guidance on how the authors could address this issue or improve the clarity of their contributions. The comment implies that the authors should better articulate the uniqueness and advantages of their approach, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s contribution to the field of LLMs, specifically questioning the groundbreaking nature of the proposed method and its distinction from existing contrastive decoding techniques. However, it does not specify which part of the paper this critique is based on, such as particular sections or discussions where the proposed method is described. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing revision. While the comment is specific in its critique of the paper\\'s contribution and distinction, it is not grounded in terms of identifying the specific parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field of LLMs and lacks distinction from existing contrastive decoding techniques. However, the comment does not provide specific examples or references to existing work that the proposed method is similar to, nor does it offer detailed reasoning to support the claim of lack of innovation. This lack of explicit evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the importance of the paper\\'s contribution to addressing challenges in LLMs but questions the groundbreaking nature of the proposed method. It points out that the paper does not adequately distinguish its approach from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new method. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might better articulate their contributions or differentiate their work from existing methods. This limits the comment\\'s usefulness, making it somewhat helpful as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the tabular representation of node agent interactions in Figure 4 is not intuitive. However, it does not provide any guidance or suggestions on how to improve the figure or make it more intuitive. The comment lacks explicit instructions or concrete details on what changes should be made to enhance the figure\\'s clarity or effectiveness. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the tabular representation are not intuitive or how it could be improved. Without specific guidance or examples, the authors may struggle to understand what changes are needed to enhance the figure\\'s intuitiveness. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that \"Figure 4\\'s tabular representation of node agent interactions is not intuitive.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the representation is not intuitive. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the tabular representation of node agent interactions in Figure 4 is not intuitive. However, it lacks specificity and does not provide any suggestions or guidance on how to improve the figure\\'s clarity or make it more intuitive. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the appropriateness of using PU frameworks as baselines and the impact of the PU loss on calibration. While it suggests considering other frameworks like noise-aware losses, it does not explicitly instruct the authors to do so. The comment implies that the authors should explore these alternatives, but it lacks concrete guidance on how to implement this exploration. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the appropriateness of using PU frameworks as baselines and the impact of the PU loss on calibration. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific in its inquiry about the PU loss and its impact on calibration, it lacks grounding as it does not reference a particular section or context in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and suggestions regarding the appropriateness of using PU frameworks as baselines and the impact of the PU loss on calibration. It does not contain any subjective claims, opinions, or judgments that require verification. The questions are factual and seek clarification, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the appropriateness of using PU frameworks as baselines and the impact of the PU loss on calibration. It suggests considering other frameworks like noise-aware losses and highlights the importance of uncertainty estimation for downstream use cases. While the comment identifies potential areas for improvement and raises relevant concerns, it lacks specific guidance or actionable suggestions on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider alternative frameworks and the implications of their choice, but it could be more beneficial with additional detail or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a disagreement with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL). It clarifies that TL is a broader term for the phenomenon of learning from one task benefiting another task, while fine-tuning is a sequential way of doing it. The reviewer also mentions that standard MTL is a parallel means to the same end. However, the comment does not provide explicit guidance or suggestions on how the authors should revise their characterization or improve their explanation. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their description of TL and FT, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. It provides a clear explanation of the differences between TL, FT, and standard MTL, which helps the authors understand the issue. However, the comment does not explicitly mention which part of the introduction it addresses, leaving the authors to infer that it relates to the section discussing TL and FT. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing the issue with the characterization. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. The reviewer provides a logical explanation by distinguishing between TL as a broader term for learning from one task benefiting another and FT as a sequential method, while standard MTL is a parallel approach. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific works or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critique of the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. It clarifies the distinction between TL as a broader term for learning from one task benefiting another task, and FT as a sequential method, while standard MTL is a parallel approach. This feedback is valuable as it helps the authors correct a potential misunderstanding in their explanation, which could lead to a more accurate and precise description of their work. However, the comment could be more helpful if it offered suggestions on how to revise the introduction to better align with the correct terminology and concepts. Overall, the comment is somewhat helpful as it identifies a specific issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a Limitation section, which is considered important. This provides a clear and direct action for the authors to take, namely to include a Limitation section in their draft. However, the comment does not specify what kind of limitations should be discussed or provide guidance on how to structure this section. While the action is explicit, the lack of detailed instructions on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out the absence of a \"Limitation\" section, which is considered important. However, it does not specify which part of the paper should include this section or what specific limitations should be addressed. Without explicit references to sections or detailed guidance, the authors cannot confidently determine where to add the \"Limitation\" section or what specific limitations should be discussed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks a \"Limitation\" section, which is considered important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence affects the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including a Limitation section. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement by pointing out the absence of a Limitation section in the paper. This is an important aspect that can help readers understand the limitations and potential drawbacks of the work. However, the comment lacks depth and does not provide guidance on what specific limitations should be addressed or how the authors might structure this section. While it highlights an important issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests that Section 2.1 requires more detailed explanations of the theory behind diffusion models, and it mentions that the works of Choi et al. (2021) and Meng et al. (2021) are not explained. Additionally, it points out that the captions of figures 3, 4, 7, and 8 are not explanatory. These comments are clear and provide concrete guidance on what needs to be improved, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections (2.1, 2.2, and 3.2) and figures (3, 4, 7, and 8) that need attention. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details what needs to be addressed in each section, such as providing more detailed explanations of the theory behind diffusion models and explaining the works of Choi et al. (2021) and Meng et al. (2021). Additionally, it points out the need for more explanatory captions for the figures mentioned. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims: Section 2.1 requires more detailed explanations, Section 2.2 lacks clarity regarding CLIP guidance, and Section 3.2 does not explain the works of Choi et al. (2021) and Meng et al. (2021). Additionally, it notes that figure captions are not explanatory. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of explicit examples or references to external sources renders the claims unverifiable, as the authors are left without clear guidance on how to improve their draft. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper. It identifies areas where more detailed explanations are needed, such as in Section 2.1 regarding the theory behind diffusion models and in Section 2.2 regarding CLIP guidance. Additionally, it points out that the works of Choi et al. (2021) and Meng et al. (2021) are not explained, which is crucial for situating the current work within the literature. The comment also highlights a common issue with figure captions, noting that they are often not explanatory, which can hinder understanding. This feedback is clear and provides concrete guidance for the authors to improve their draft, making it mostly helpful. However, it could be more comprehensive by suggesting specific ways to enhance the explanations or by providing examples of how to improve the figure captions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This is a clear and direct action for the authors to take, providing them with a specific change to make to improve their draft. The comment is concrete, as it specifies exactly what needs to be added to the title, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the term \"tensor completion\" in the title to reflect the only application of the new model presented in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion that \"tensor completion\" is the only application. The authors might find it helpful to understand the importance of this term in the context of their work, but the comment could be strengthened with more detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the inclusion of the term \"tensor completion\" in the title. This feedback is clear and directly addresses a potential oversight in the paper\\'s presentation, which could enhance its clarity and relevance to readers. By suggesting a straightforward change to the title, the comment empowers the authors to make a concrete improvement to their draft. However, the comment could be more helpful if it explained why this change is important or how it would benefit the paper. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should implement a simple baseline and compare it to their proposed method to make the paper more persuasive. While the suggestion is explicit, it lacks concrete details on how to implement the baseline or what specific aspects should be compared. The authors are given a clear direction to enhance their empirical evaluation, but the lack of detailed guidance on how to implement the baseline makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of comparison between the proposed method and other prior methods, suggesting that the authors should implement a simple baseline for comparison. However, it does not specify which part of the paper this issue pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not direct. The comment is specific in suggesting a way to improve the paper by comparing to a baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s empirical evaluation is insufficient because it only demonstrates statistically significant linear regressions without comparing to other prior methods. The reviewer suggests implementing a simple baseline for comparison to make the paper more persuasive. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to prior methods that could be used for comparison. This makes the claim somewhat verifiable, as the authors would need to infer which prior methods could be relevant and how to implement the suggested baseline. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of comparison with other prior methods. It suggests that the authors should implement a simple baseline for comparison, such as character frequencies, to make the paper more persuasive. This feedback is clear and actionable, providing a concrete suggestion for improvement that could enhance the paper\\'s empirical evaluation and strengthen its claims. However, the comment could be more helpful if it offered specific examples of prior methods to consider or provided guidance on how to implement the suggested baseline. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method in reducing computational load in real applications. It provides a detailed explanation of the challenges, such as the difficulty in applying a uniform activation pattern across all tokens and the potential lack of generalization of precomputed PPL and activation patterns. However, the comment does not offer specific guidance or suggestions on how the authors might address these challenges or improve the method\\'s practicality. While it identifies a significant issue, the lack of actionable advice makes it difficult for the authors to know how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the practicality of the proposed method in reducing computational load in real applications. It provides a detailed explanation of the challenges, such as the difficulty in applying a uniform activation pattern across all tokens and the potential lack of generalization of precomputed PPL and activation patterns. However, the comment does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to sections discussing the method\\'s computational efficiency or implementation details, but this inference is not as direct as it could be. The comment is specific in detailing the potential issues, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may face challenges in reducing computational load in real applications. It provides a detailed explanation of the potential issues, such as the difficulty in applying a uniform activation pattern across all tokens and the lack of generalization of precomputed PPL and activation patterns. This reasoning is logical and provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or studies that have encountered similar challenges, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method in reducing computational load in real applications. It provides a detailed explanation of the challenges, such as the difficulty in applying a uniform activation pattern across all tokens and the potential lack of generalization of precomputed PPL and activation patterns. This feedback is valuable as it highlights a critical aspect of the method\\'s practicality that the authors need to address. However, while the comment clearly identifies the issue, it does not offer specific suggestions or guidance on how the authors might overcome these challenges or improve the method\\'s practicality. To be more helpful, the comment could include recommendations or alternative approaches to enhance the method\\'s applicability. Therefore, the comment is somewhat helpful, as it provides insight but lacks actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the core motivation of the paper is not clear enough, specifically mentioning the abstract\\'s statement about task boundaries and the proposed benchmark, metrics, and gating technique. However, it does not provide explicit guidance on how the authors should clarify the motivation or improve the clarity of the abstract. The comment lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to address the issue. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the core motivation of the paper is not clear enough, particularly regarding the statement about task boundaries and the proposed benchmark, metrics, and gating technique. This provides clear guidance on what needs to be clarified or improved in the abstract. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear enough, specifically criticizing the abstract for its lack of clarity. The reviewer provides a specific example by mentioning the statement about task boundaries and the proposed benchmark, metrics, and gating technique. However, the comment does not provide further elaboration or examples to support why these statements are insufficient to capture the main problem. While the comment identifies a potential issue, it lacks detailed reasoning or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a critical issue with the paper, specifically that the core motivation is not clear enough. It points out that the abstract makes a statement about task boundaries but then introduces new benchmarks, metrics, and a gating technique without clearly articulating the main problem being addressed. This feedback is valuable as it highlights a fundamental weakness in the paper\\'s presentation of its core contribution. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the motivation or improve the clarity of their abstract. While it offers some insight into the problem, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used to filter data and questions what kind of data passes this filter. It suggests that the task of filtering data using the task description differs from the original MNLI distribution and recommends providing examples of the filtered data. While the comment implies that the authors should include examples of filtered data, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises concerns about the sequence inference classifier used to filter data, questioning what kind of data passes this filter and suggesting that the task of filtering data using the task description differs from the original MNLI distribution. It also recommends providing examples of the filtered data. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the classifier is discussed. The comment is specific in detailing what needs to be addressed, namely the inclusion of examples of filtered data. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used to filter data, questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description differs from the original MNLI distribution and recommends providing examples of the filtered data. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include examples is helpful, but the absence of concrete evidence or references makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sequence inference classifier used to filter data, questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description differs from the original MNLI distribution and recommends providing examples of the filtered data. This feedback is clear and actionable, as it identifies a specific area of confusion and offers a concrete suggestion for improvement. By including examples of filtered data, the authors can better demonstrate the effectiveness of their filtering process and address the reviewer\\'s concerns. However, the comment could be more helpful if it provided additional guidance on how to present these examples or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the application experiments, including potential biases due to the use of a single model (DALL-E) and a small dataset. It suggests that the experiment results may not be convincing without comprehensive experiments. The reviewer also recommends an in-depth editorial review to address issues with structure, argumentation, and language clarity. Additionally, specific issues like chaotic equation numbering and a lack of indentation in Algorithm 1 are pointed out. While the comment provides explicit actions for the authors to take, such as conducting more comprehensive experiments and improving the paper\\'s structure and clarity, it lacks detailed guidance on how to address these issues. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the application experiments and the use of a single model (DALL-E) and a small dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the experiments, such as the potential biases and the difficulty in validating the proposed methods without comprehensive experiments. Additionally, it provides specific examples of issues with the paper, such as chaotic equation numbering and a lack of indentation in Algorithm 1. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the application experiments may have biases due to the use of a single model (DALL-E) and a small dataset. This claim is somewhat verifiable as it highlights potential issues with the experimental setup, but it lacks specific examples or references to support the assertion that these biases are significant or detrimental to the results. The comment also suggests that the paper requires an in-depth editorial review and provides specific examples of issues like chaotic equation numbering and a lack of indentation in Algorithm 1. While these examples offer some guidance for improvement, the overall claim about the biases in the experiments remains somewhat vague without detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical issues with the application experiments, including potential biases due to the use of a single model (DALL-E) and a small dataset. It highlights the difficulty in validating the proposed methods without comprehensive experiments, which is a significant concern for the paper\\'s credibility. The comment also provides specific examples of issues, such as chaotic equation numbering and a lack of indentation in Algorithm 1, which are actionable points for improvement. Additionally, it suggests an in-depth editorial review to address broader issues with structure, argumentation, and language clarity. This feedback is clear, actionable, and provides a comprehensive guide for the authors to enhance the quality and credibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of practical applications for the experiments conducted in the paper, noting that the datasets used are artificial and not based on real-world tasks. The reviewer explicitly asks the authors to comment on this aspect, suggesting that they should discuss potential real-world tasks that could benefit from the model. While the comment clearly identifies an area for improvement, it does not provide specific guidance on how the authors should address this issue or what kind of real-world tasks they should consider. The action is explicit but somewhat vague, as it leaves some room for interpretation on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of practical applications for the experiments conducted in the paper, specifically noting that the datasets used are artificial and not based on real-world tasks. However, it does not specify which part of the paper this issue pertains to, such as the introduction, discussion, or results sections. The authors might infer that it relates to the experimental setup or discussion sections, but this inference is not direct. The comment is specific in its request for a comment on practical applications, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of practical applications for the experiments conducted in the paper, noting that the datasets used are artificial and not based on real-world tasks. The reviewer suggests that there might be real-world tasks for which such a model could be useful. However, the comment does not provide specific examples or references to real-world tasks or data that could be used, making it somewhat verifiable. The authors would need to infer the potential applications themselves, which requires more effort to fully address the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of practical applications for the experiments conducted in the paper. It points out that the datasets used are artificial and not based on real-world tasks, which limits the relevance and applicability of the findings. The comment suggests that the authors should discuss potential real-world tasks that could benefit from the model, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific examples of real-world tasks or provided guidance on how to incorporate such applications into the paper. Despite this, the feedback is mostly helpful as it highlights an important aspect of the paper that needs attention and encourages the authors to consider practical implications. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the method used for selecting m\\' in CAL-MIR, specifically asking whether it is done exhaustively over all loss minimizer subsets. While the comment highlights a potential issue with the approach, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to clarify or modify their method, but without concrete instructions, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the method used for selecting m\\' in CAL-MIR, specifically asking whether it is done exhaustively over all loss minimizer subsets. However, it does not specify which part of the paper discusses this method, making it weakly grounded. The comment is specific in its inquiry about the selection process, providing a clear question that the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the method used for selecting m\\' in CAL-MIR. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the method used for selecting m\\' in CAL-MIR, specifically asking whether it is done exhaustively over all loss minimizer subsets. This question highlights a potential area of confusion or lack of clarity in the paper, prompting the authors to provide a clearer explanation of their method. However, the comment does not offer specific suggestions or guidance on how to address this issue, nor does it provide context or background information that would help the authors understand the significance of this question. As a result, while the comment identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider including other backdoor detection methods that are input data-free, such as those using weight matrix statistics or matrix factorization, in their analysis of algorithm performance. While the comment implies a specific action\u2014adding a discussion or comparison of these methods\u2014it does not provide detailed guidance on how to incorporate this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering other backdoor detection methods that are input data-free, such as those using weight matrix statistics or matrix factorization, in the analysis of algorithm performance. This provides clear guidance on what additional content or analysis should be included. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Robustness\" section should consider other backdoor detection methods that are input data-free, such as those using weight matrix statistics or matrix factorization. This claim is somewhat verifiable as it provides a logical suggestion for expanding the analysis by referencing specific types of detection methods. However, the comment lacks detailed examples or references to these methods, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the \"Robustness\" section by suggesting that the authors consider other backdoor detection methods that are input data-free, such as those using weight matrix statistics or matrix factorization. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the analysis of algorithm performance. By incorporating these additional methods, the authors can enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it included specific references or examples of these methods, which would provide even more detailed guidance. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas that need improvement: the relation works section and the problem definition methodology. It explicitly instructs the authors to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be added or clarified in their draft. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This provides clear guidance on what the authors need to add or clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works section\" is incomplete and suggests that the authors should describe which view of the knowledge graph is part of the assumption. However, the comment does not provide specific examples or detailed reasoning to support why the section is incomplete or how describing the view of the knowledge graph would improve the paper. This lack of detailed justification makes the claim borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the \"relation works section\" is incomplete, providing a clear indication of where the authors need to expand their discussion. Second, it suggests that the authors should describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is actionable and provides clear guidance on how the authors can enhance their draft by addressing these gaps. However, the comment could be more helpful if it offered additional suggestions or examples on how to improve the relation works section or described the importance of clarifying the knowledge graph view. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare the accuracy of their method on the task of regression to strong baselines, rather than focusing on the optimization gap. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done\u2014comparing accuracy to baselines\u2014but it is communicated indirectly, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the choice of the optimality gap as a metric, suggesting that the contribution revolves around regression and predicting $\\\\hat{y}$. It implies that the authors should compare the accuracy of their method to strong baselines. However, the comment does not specify which part of the paper discusses the problem setup or the contribution, making it weakly grounded. The suggestion to compare accuracy to baselines is specific, but without clear grounding, the authors may struggle to identify where to make these comparisons. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of the optimality gap as a metric for measuring performance, suggesting that the contribution revolves around regression and predicting $\\\\hat{y}$. The reviewer proposes comparing the accuracy of the method to strong baselines, implying that the optimization is a downstream task that should not affect the regression performance. While the comment provides a logical reasoning for questioning the choice of metric, it lacks specific examples or references to support the claim that the optimization is a downstream task. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the choice of the optimality gap as a metric for measuring performance, suggesting that the contribution revolves around regression and predicting $\\\\hat{y}$. It proposes a specific action for the authors to take, which is to compare the accuracy of their method to strong baselines on the task of regression. This feedback is clear and actionable, providing a concrete suggestion for improving the paper by focusing on the regression task rather than the optimization aspect. However, the comment could be more helpful if it included specific examples of strong baselines or provided more detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of theoretical support for the technical design and questions the update derivation for the intrinsic reward parameters. It acknowledges that the design has been taken from a previous work (Sorg et al. 2010) but suggests that the update derivation is not convincing. However, the comment does not provide specific guidance on how to address this issue or improve the theoretical support. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the technical design and its theoretical support, specifically mentioning the update derivation for the intrinsic reward parameters (i.e., Eq.7-10). This provides full grounding as it explicitly refers to a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific, as it critiques the lack of theoretical support and questions the update derivation, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support, specifically questioning the update derivation for the intrinsic reward parameters. The reviewer acknowledges that the design has been taken from a previous work (Sorg et al. 2010) but suggests that the update derivation is not convincing. While the comment references an external source, it does not provide detailed reasoning or examples to support why the update derivation is problematic. This makes the claim somewhat verifiable, as it points to a potential issue but lacks comprehensive justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical design of the paper, specifically noting the lack of theoretical support and questioning the update derivation for the intrinsic reward parameters. It acknowledges that the design has been taken from a previous work (Sorg et al. 2010) but suggests that the update derivation is not convincing. This feedback is valuable as it highlights a critical area that needs further justification or improvement. However, the comment could be more helpful if it provided specific suggestions on how to enhance the theoretical support or improve the update derivation. Overall, the comment is somewhat helpful, as it points out a key weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the adaptive variance reduction property claimed by the authors, suggesting that it essentially boils down to selecting a \"small enough\" \u03b2 parameter. The reviewer implies that this approach does not truly represent adaptivity, as seen in methods like AdaGrad. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches to demonstrate adaptivity. The feedback lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to respond to the critique. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the adaptive variance reduction property claimed by the authors, suggesting that it essentially boils down to selecting a \"small enough\" \u03b2 parameter. However, it does not specify which part of the paper this claim is made in, nor does it provide details on how the authors could address this issue or improve their explanation. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts need revision. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point challenges the adaptive variance reduction property claimed by the authors, suggesting that it essentially boils down to selecting a \"small enough\" \u03b2 parameter. The reviewer compares this to adaptive methods like AdaGrad, implying that the adaptivity claim is not valid. However, the comment lacks specific examples or detailed reasoning to support the claim that the adaptive variance reduction property is not truly adaptive. Without these elements, the claim remains somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the adaptive variance reduction property claimed by the authors, suggesting that it essentially boils down to selecting a \"small enough\" \u03b2 parameter. The reviewer contrasts this with adaptive methods like AdaGrad, implying that the adaptivity claim may not be valid. While the comment identifies a potential issue with the authors\\' claim, it lacks specific guidance or suggestions on how the authors might address this critique or improve their explanation. The feedback is somewhat helpful as it prompts the authors to reconsider their claim, but it could be more beneficial with additional detail or actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the value of different augmentation techniques and suggests that DINOv2 is the best-performing model most of the time. It implies that further investigation is needed to understand why and how to improve this model. While the comment identifies an area for further exploration, it does not provide specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the steps needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the value of different augmentation techniques and mentions DINOv2 as the best-performing model most of the time. However, it does not specify which part of the paper discusses these augmentation techniques or DINOv2, making it weakly grounded. The comment does specify that further investigation is needed to understand why and how to improve the best-performing model, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and suggests that DINOv2 is the best-performing model most of the time. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or comparisons, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the value of different augmentation techniques and highlights that DINOv2 seems to be the best-performing model most of the time. It suggests that further investigation is needed to understand why and how to improve the best-performing model. While the comment points out an important area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this investigation or what aspects to focus on. The feedback is somewhat helpful as it provides a direction for further exploration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the acronym \"FTL\" for \"follow the top perturbed leader\" is unfortunate because in literature, \"FTL\" typically means \"Follow the Leader.\" The reviewer implies that the authors should consider changing the acronym to avoid confusion. While the action is explicit, it lacks concrete guidance on how to choose a new acronym or what alternative might be more appropriate. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"FTL\" for \"follow the top perturbed leader,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the acronym, noting that \"FTL\" is typically used for \"Follow the Leader\" in literature and suggesting a change to avoid confusion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the acronym \"FTL\" for \"follow the top perturbed leader\" is unfortunate because in literature, \"FTL\" typically means \"Follow the Leader.\" The comment provides a logical reasoning by referencing common usage in literature, which supports the claim that the acronym could lead to confusion. However, it does not provide specific examples or references to substantiate the claim fully. Therefore, the comment is mostly verifiable, as it offers a reasonable suggestion but lacks detailed evidence or references to fully validate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym \"FTL\" for \"follow the top perturbed leader,\" noting that in literature, \"FTL\" typically refers to \"Follow the Leader.\" The comment suggests that changing the acronym might be necessary to avoid confusion. While the feedback is clear and actionable, it could be more helpful by providing alternative acronyms or suggesting how to address the issue more comprehensively. Nonetheless, the comment offers a specific and actionable suggestion that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an issue with the selection of attacks in Table 1, noting that they are not state-of-the-art and suggesting that there are better attacks available. It also provides a specific reference to a survey that can guide the authors in selecting more advanced attacks. Additionally, the comment requests that the authors include information about the number of iterations the attacks are run for and other hyper-parameters. This feedback is clear and provides concrete actions for the authors to take, such as updating the attack selection and providing additional details about the attacks and their parameters. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of attacks, noting that they are not state-of-the-art and suggesting that there are better attacks available. The comment further specifies what needs to be addressed by recommending the inclusion of information about the number of iterations the attacks are run for and other hyper-parameters. This level of detail provides clear guidance for the authors on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and not state-of-the-art, suggesting that there are better attacks available. The reviewer supports this claim by referencing a survey that provides an extensive analysis of attacks, including MIDIFGSM. This reference offers a concrete source for the reviewer\\'s assertion, making the claim mostly verifiable. However, the comment could be strengthened by providing more specific examples or detailed comparisons within the text, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the selection of attacks in Table 1, noting that they are not state-of-the-art and suggesting that there are better attacks available. It provides a reference to a survey that can guide the authors in selecting more advanced attacks. Additionally, the comment requests additional information about the attacks and their hyper-parameters, such as the number of iterations they are run for. This feedback is clear and actionable, offering the authors specific guidance on how to improve the comprehensiveness and relevance of their experimental setup. By addressing these points, the authors can enhance the rigor and credibility of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, specifically that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method\\'s performance with other pre-training methods. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to explore this issue further. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limitations and conclusion\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the method\\'s effectiveness, noting that it primarily works with encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This claim is somewhat verifiable as it provides a logical reasoning based on the limitations and conclusion sections of the paper. However, it lacks specific examples or references to support the claim, which would make it more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation of the method, specifically that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is valuable as it highlights a potential weakness in the paper\\'s claims about the method\\'s effectiveness. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore the performance with other pre-training methods. While it points out an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and requests additional information regarding the qualitative analysis in Section 4.5.5 and Figure 1. It asks how the input sentences for the qualitative analysis were determined, whether these examples occurred during the fine-tuning process, and whether the attribution values in Figure 1 were normalized. Additionally, it inquires about the attribution map for input examples that failed to be classified. While the comment does not explicitly instruct the authors to provide this information, the questions imply that the authors should address these points. The actions are clear and concrete, as the authors know exactly what information is needed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions about the qualitative analysis, including how the input sentences were determined, whether they occurred during fine-tuning, and whether the attribution values were normalized. Additionally, it questions the effectiveness of the attribution map for input examples that failed to be classified. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the qualitative analysis, specifically regarding the determination of input sentences and the normalization of attribution values. It also questions the effectiveness of the attribution map for input examples that failed to be classified. While the comment highlights areas that need clarification, it does not provide any supporting evidence or references to substantiate these questions. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a lack of clarity and detail in the description of the qualitative analysis, specifically regarding the determination of input sentences and the normalization of attribution values. It raises pertinent questions about the methodology and interpretation of the results, prompting the authors to provide more information and justification for their analysis. By addressing these points, the authors can enhance the transparency and robustness of their qualitative analysis. However, the comment could be more helpful if it offered specific suggestions on how to present this information or examples of how similar analyses have been conducted. Overall, the feedback is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. This comment provides a clear and explicit action for the authors to take, specifying exactly what needs to be added to the draft. The suggestion is concrete, as it outlines the type of examples and clarification needed to enhance the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper should include these examples or where the current discussion lacks clarity. The authors might infer that it relates to sections discussing the theoretical framework or applications, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what additional information should be included. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any specific examples or references to support the claim that such examples are necessary or beneficial. Without detailed justification or examples, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of examples of practical applications where specific types of tensors need to be equivariant. It also suggests clarifying how these scenarios validate the advantages of using equivariant tensor functions. This feedback is specific and offers a concrete direction for the authors to enhance their draft by providing real-world examples that can strengthen the paper\\'s relevance and impact. However, the comment could be more helpful if it included specific examples or scenarios to guide the authors in developing these examples. Overall, the comment is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS in Table 2, and the misalignment between Section 3.2.3 and the table. While the comment highlights these problems, it does not provide explicit instructions on how to address them, such as suggesting where to include the references or how to align the section with the table. The authors can infer that they need to clarify these references and ensure consistency, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between Section 3.2.3 and the table. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are issues with the tables, specifically mentioning Table 2, where methods like ERM, cRT, and LWS are not properly referenced. Additionally, it notes a misalignment between Section 3.2.3 and the table. While the comment identifies specific problems, it lacks detailed reasoning or examples to fully substantiate the claim. The authors might understand the general issue but may need more guidance on how to address it. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between Section 3.2.3 and the table. This feedback is clear and actionable, as it points out specific areas where the authors need to improve the clarity and accuracy of their presentation. By addressing these issues, the authors can enhance the comprehensibility and reliability of their work. However, the comment could be more helpful if it provided suggestions on how to properly reference these methods or align the section with the table. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific comments for the authors to address. First, it questions the suitability of the model for sarcastic/non-sarcastic utterances and suggests that the authors should provide more details for further analysis. Second, it asks why eye-movement data would be useful for sarcastic/non-sarcastic sentiment classification beyond textual features and requests more explanations. These comments are explicit and provide concrete guidance on what the authors need to clarify or expand upon. The feedback is clear and actionable, giving the authors specific directions on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback by questioning the suitability of the model for sarcastic/non-sarcastic utterances and asking for more details and explanations regarding the use of eye-movement data. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides a positive assessment of the paper\\'s overall quality, describing it as well-written and organized, and noting that the experiments are conducted carefully for comparison with previous work. However, it also includes specific claims that require further analysis or explanation. The reviewer questions the suitability of the model for sarcastic/non-sarcastic utterances and asks for more details, as well as questioning the utility of eye-movement data for sentiment classification beyond textual features. These claims are somewhat verifiable as they highlight areas that need further exploration or justification, but they lack specific examples or references to support the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a positive assessment of the paper\\'s overall quality, noting that it is well-written and organized, and that the experiments are conducted carefully for comparison with previous work. However, it also offers specific and actionable feedback by questioning the suitability of the model for sarcastic/non-sarcastic utterances and asking for more details and explanations. Additionally, it inquires about the utility of eye-movement data for sentiment classification beyond textual features and requests further explanations. This feedback is clear and constructive, guiding the authors on how to enhance their analysis and provide more comprehensive insights into their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the limited number of experimental results and the inprofessional presentation of tables 1 and 2. The first issue is implicit, as it suggests that more experiments should be conducted, but it does not specify which datasets or additional experiments should be included. The second issue is explicit, as it directly points out the error in labeling DDIM as a sampler method instead of a model. However, the comment does not provide concrete guidance on how to address the first issue or improve the presentation of the tables. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the limited number of experimental results and the inprofessional presentation of tables 1 and 2. It mentions that the paper only conducts experiments on two small-scale/resolution datasets and points out the error in labeling DDIM as a sampler method instead of a model. This provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the paper discusses the experimental results or the tables, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are limited, as the paper only conducts experiments on two small-scale/resolution datasets. Additionally, it points out an inprofessional presentation in tables 1 and 2, where DDIM is labeled as a sampler method instead of a model. While the comment identifies specific issues, it lacks detailed reasoning or evidence to fully substantiate the claim about the limited experimental scope. The mention of DDIM being labeled incorrectly provides some support, but the overall justification is not robust. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed evidence or examples to fully validate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues: the limited number of experimental results and the inprofessional presentation of tables 1 and 2. It points out that the paper only conducts experiments on two small-scale/resolution datasets, which limits the generalizability of the findings. Additionally, it highlights a specific error in the presentation of tables 1 and 2, where DDIM is labeled as a sampler method instead of a model. While the comment effectively identifies these weaknesses, it lacks detailed guidance or suggestions on how to address them, such as recommending additional datasets or providing examples of how to correctly label DDIM. This limits the comment\\'s helpfulness, as it provides insight but not actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more clarification about why their proposed method is important. It implies that the authors should discuss how adjusting the variance level of DPSGD influences utility and what might be lost in terms of privacy level. While the comment identifies areas that need clarification, it does not provide specific guidance on how to address these issues or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more clarification about the importance of their proposed method, specifically mentioning that it adjusts the variance level of DPSGD. It also implies that there should be a discussion on how this adjustment influences utility and what might be lost in terms of privacy level. However, the comment does not specify which part of the paper should include this clarification, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the importance and implications of the proposed method. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method is important but lacks clarity on how it influences utility and privacy levels. The reviewer implies that the method is merely an adjustment to the variance level of DPSGD, which should impact utility but also potentially privacy. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of explicit evidence or detailed explanation makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a need for more clarification about the importance of the proposed method, suggesting that it merely adjusts the variance level of DPSGD. It implies that there should be a discussion on how this adjustment influences utility and what might be lost in terms of privacy level. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address these concerns. The feedback is somewhat helpful as it points out a potential weakness in the paper but does not provide detailed direction for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a larger-scale experiment with a longer-horizon example. The reviewer explicitly states that this example should be presented in tabular form. This feedback provides a clear and concrete action for the authors to take, specifying both the type of experiment and the format in which it should be presented. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a larger-scale experiment with a longer-horizon example. It specifies that this example should be presented in tabular form. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or figures where the empirical results are discussed. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the empirical results are \"illustrative, more than demonstrative\" and suggests that a larger-scale experiment with a longer-horizon example would be beneficial. However, the comment lacks specific examples or references to support why the current results are insufficient or how a larger-scale experiment would improve the study. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the empirical results, noting that they are illustrative rather than demonstrative. It suggests that a larger-scale experiment with a longer-horizon example would be beneficial. The comment is specific in recommending a tabular presentation of the longer-horizon example, which provides clear and actionable guidance for the authors to enhance their work. However, the comment could be more helpful if it included additional details on what specific aspects of the experiment should be expanded or how the longer-horizon example would improve the study. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Equation (13) does not have a closed-form solution in general and suggests that providing details about how it is solved in the experiments and on the computational complexity would be helpful. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides some guidance on what needs to be addressed. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equation (13),\" which allows the authors to accurately identify the specific part of the paper being addressed, providing full grounding. It also specifies the issue by pointing out that the equation does not have a closed-form solution in general and suggests that details about how it is solved in the experiments and on the computational complexity would be helpful. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution in general and suggests that providing details about how it is solved in the experiments and on the computational complexity would be helpful. However, the comment lacks specific reasoning or evidence to support the claim that the equation does not have a closed-form solution. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13), noting that it does not have a closed-form solution in general. It suggests that providing details about how the equation is solved in the experiments and on the computational complexity would be helpful. This feedback is clear and actionable, as it directs the authors to include additional information that could enhance the understanding and reproducibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the choice of \"proximity\" and its relationship to the nature of the task. It provides specific examples and reasoning to illustrate the issue, such as the correlation between proximity in Cartesian positions and the solution space, and the potential failure of proximity metrics in complex tasks like mazes or robotic tasks with obstacles. The comment suggests that the paper would benefit from analyzing which tasks have reasonable proximity metrics and demonstrating failures on those that do not. While the feedback is explicit in identifying the areas needing attention, it does not provide detailed guidance on how to conduct these analyses or demonstrations. Therefore, the comment is mostly actionable, as it gives a clear direction but lacks concrete steps for execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion on the choice of \"proximity\" and its relationship to the nature of the task, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as analyzing which tasks have reasonable proximity metrics and demonstrating failures on those that do not. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of discussion on the choice of \"proximity\" and its relationship to the nature of the task. It provides a logical reasoning by explaining that proximity in Cartesian positions may not always correlate with proximity in the solution space, particularly in complex tasks like mazes or robotic tasks with obstacles. This reasoning is supported by examples, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to substantiate the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper regarding the choice of \"proximity\" and its relationship to the nature of the task. It provides a clear explanation of the issue, noting that proximity in Cartesian positions may not always correlate with proximity in the solution space, particularly in complex tasks like mazes or robotic tasks with obstacles. The comment suggests that the paper would benefit from analyzing which tasks have reasonable proximity metrics and demonstrating failures on those that do not. This feedback is actionable and provides a clear direction for the authors to improve their analysis and discussion. However, it could be more helpful if it offered specific examples or methods for conducting these analyses. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides a general direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of implementation details in the experiments, which is necessary for readers to fully understand and reproduce the results. However, it does not provide specific guidance on what implementation details are missing or how the authors should address this issue. The comment refers to \"Questions for details,\" but without further elaboration, the authors are left without clear instructions on how to improve their draft. The action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of implementation details in the experiments, which is necessary for readers to fully understand and reproduce the results. However, it does not specify which experiments or sections of the paper lack these details, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment refers to \"Questions for details,\" but without further context, it remains unclear what specific questions are being referred to. This lack of explicit grounding and specificity makes it challenging for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. However, it does not provide specific examples or details about what implementation details are missing or how they impact the understanding or reproducibility of the results. Without such specific information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides a general critique but lacks the necessary detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experiments, noting a lack of implementation details that are necessary for readers to fully understand and reproduce the results. This is a critical point that can hinder the reproducibility and transparency of the research. However, the comment does not provide specific examples or guidance on which implementation details are missing or how the authors might address this issue. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential unfairness in the comparison between SSUL and the paper due to the use of different methods for detecting unseen classes. It suggests considering the use of Mask2Former for SSUL or exploring unsupervised methods for generating object proposals. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the comparison between SSUL and the paper, particularly concerning the use of different methods for detecting unseen classes. It mentions the use of an off-the-shelf saliency-map detector and the pretrained Mask2Former, highlighting potential unfairness in data and model size. The comment suggests exploring alternatives, such as using Mask2Former for SSUL or generating object proposals unsupervised. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue and suggesting alternative approaches, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential unfairness in the comparison between SSUL and the paper due to the use of different methods for detecting unseen classes. It highlights that Mask2Former, used in the paper, is pretrained on COCO and has larger parameters than the off-the-shelf detector used by SSUL. The comment suggests exploring alternatives, such as using Mask2Former for SSUL or generating object proposals unsupervised. While the comment provides a logical basis for the claim by comparing the data and model sizes, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could benefit from more detailed evidence or references to strengthen the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between SSUL and the paper due to the use of different methods for detecting unseen classes. It highlights the discrepancy in data and model size between the off-the-shelf saliency-map detector used by SSUL and the pretrained Mask2Former employed in the paper. The comment suggests exploring alternatives, such as using Mask2Former for SSUL or generating object proposals unsupervised, to address this issue. While the feedback is clear and provides actionable suggestions, it could be more helpful by offering specific guidance on how to implement these alternatives or discussing the potential benefits and drawbacks of each approach. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft, but it could be more comprehensive with additional detail.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the metrics used in the experiments, suggesting that they may not adequately validate the performance of the proposed approach. It provides specific examples, such as the style accuracy being based on a style classifier that might not capture the styleness of the proposed algorithm, and the difficulty in verifying transfer results based on styled motion inputs. However, the comment does not offer explicit guidance on how to address these concerns or suggest alternative metrics or methods for validation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their metrics and validation methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the metrics used in the experiments, specifically questioning their ability to validate the performance of the proposed approach. It provides specific examples, such as the style accuracy based on a style classifier and the difficulty in verifying transfer results with styled motion inputs. However, it does not explicitly mention which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in detailing the issues with the metrics but lacks grounding in terms of pinpointing the exact section of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the metrics used in the experiments, specifically the style accuracy based on a style classifier. The reviewer suggests that this metric may not accurately capture the styleness of the proposed algorithm and that verifying transfer results based on styled motion inputs may be challenging. While the comment raises valid concerns, it lacks specific examples or references to support the claim that the metrics are inadequate. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the critique themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the metrics used in the experiments, suggesting that they may not adequately validate the performance of the proposed approach. It provides specific examples, such as the style accuracy based on a style classifier and the difficulty in verifying transfer results with styled motion inputs. This feedback is somewhat helpful as it identifies potential weaknesses in the experimental validation and prompts the authors to reconsider their choice of metrics. However, the comment could be more helpful if it offered suggestions for alternative metrics or methods to address these issues. Overall, the comment provides some insight into areas needing improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how individual preferences are generated in the proposed method. It suggests that the authors clarify whether preferences are interpreted as rules or policies learned from experiences. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the interpretation of preferences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the generation of individual preferences in the proposed method. It questions how these preferences are generated on an individual level and clarifies that the authors may have interpreted \"preference\" as rules or policies learned from experiences. This provides a clear indication of what needs to be clarified, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, leaving the authors to infer that it relates to sections discussing the method or results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the paper regarding how individual preferences are generated in the proposed method. It suggests that the authors may have interpreted \"preference\" as rules or policies learned from experiences, and it asks for clarification. While the comment raises a valid point, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the exact nature of the confusion, making the comment somewhat verifiable. Therefore, the feedback is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the paper\\'s argument about individual preferences in the proposed method. It questions how these preferences are generated on an individual level and clarifies that the authors may have interpreted \"preference\" as rules or policies learned from experiences. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and terminology, which is crucial for the reader\\'s understanding. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of what clarification might look like. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about Figure 4, specifically regarding the meaning of \"1-200 frames,\" how the values are computed, and why precision and recall change with the trajectory length. It also asks about the meaning of \"action repeat.\" These questions imply that the authors should clarify these aspects in their draft. However, the comment does not explicitly instruct the authors to make these clarifications, leaving the action implicit. Additionally, while the questions provide some guidance on what needs to be addressed, they lack concrete instructions on how to present the clarifications. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions about the meaning and computation of values in the figure, as well as the changing precision and recall with trajectory length and the meaning of \"action repeat.\" These questions provide clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about Figure 4, specifically regarding the meaning of \"1-200 frames,\" how values are computed, and why precision and recall change with trajectory length. It also asks about the meaning of \"action repeat.\" These are requests for clarification and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in Figure 4, specifically regarding the meaning of \"1-200 frames,\" how values are computed, and why precision and recall change with the trajectory length. It also questions the meaning of \"action repeat.\" These questions highlight areas where the authors need to provide more detailed explanations or clarifications in their manuscript. While the comment effectively points out these weaknesses, it does not offer specific suggestions or guidance on how to address them, such as proposing ways to improve the figure's clarity or explaining the concepts in more detail. Therefore, the comment is somewhat helpful, as it provides insight into areas needing improvement but lacks comprehensive guidance for the authors to act upon.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that the authors provide justification for these decisions, which would help improve the paper. The reviewer also implies that if the authors could demonstrate the cost-effectiveness of their approach, it might lead to an increase in the soundness score. While the comment does not explicitly instruct the authors to make specific changes, it provides a clear direction for improvement by suggesting a comparison between LLaMAA and finetuning. The action is implicit but concrete, as the authors know they need to provide justification and potentially conduct a specific comparison. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses specific design decisions related to the number of initial ground truth examples and the number of labeled examples, suggesting that these choices seem arbitrary. It also mentions the motivation of cost-effectiveness and proposes a comparison between LLaMAA and finetuning to demonstrate cost-effectiveness. However, the comment does not specify which sections of the paper these design decisions are discussed in, making it weakly grounded. The comment is specific in its critique and provides a suggestion for improvement, but without clear references to the paper, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions seem arbitrary and proposes a comparison between LLaMAA and finetuning to demonstrate cost-effectiveness. The comment implies that providing justification for these decisions could lead to an increase in the soundness score. However, the claim lacks specific examples or detailed reasoning to support the assertion that these decisions are arbitrary. The suggestion to compare LLaMAA and finetuning is a logical one, but without further elaboration or evidence, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design decisions regarding the number of initial ground truth examples and the number of labeled examples, suggesting that these choices seem arbitrary. It proposes a specific comparison between LLaMAA and finetuning to demonstrate cost-effectiveness, which could provide a more robust justification for these design decisions. The comment also suggests that providing such justification could lead to an increase in the soundness score. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the paper\\'s credibility and impact. However, it could be more helpful if it included specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the motivation for investigating a graph structured model, questioning the need for a complex approach when the Transformer already captures global dependencies. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this confusion or clarify their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation behind investigating a graph structured model and its distinction from existing sequence models. It also questions the complexity of the approach when the Transformer already captures global dependencies. However, the comment does not specify which part of the paper discusses the motivation or the complexity of the approach, making it weakly grounded. The authors might infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in questioning the necessity of the complex approach, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for using a graph structured model when the Transformer already captures global dependencies. However, the comment lacks specific reasoning or evidence to support the claim that the approach is unnecessary or overly complex. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some initial reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the motivation behind using a graph structured model when the Transformer already captures global dependencies. It questions the necessity of the complex approach, which is a relevant point for the authors to consider. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern or clarify their approach. Without detailed feedback or constructive advice, the authors are left with only a vague understanding of the issue, limiting the comment\\'s usefulness. Therefore, it is rated as barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide videos showing different policies controlling cars on different tracks to better understand how different methods work. This is an explicit suggestion that provides a clear action for the authors to take. Additionally, the comment points out a lack of implementation details in the main paper, which makes reproducing the results difficult. It also mentions that the policy gradient approach is unclear. While the first part of the comment is explicit and actionable, the second part is more vague, as it does not specify which implementation details are missing or how to address the lack of clarity regarding the policy gradient approach. Overall, the comment is mostly actionable, as it provides a clear action for the authors to take regarding the videos but lacks detailed guidance on the implementation details and policy gradient approach.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing videos to demonstrate different policies controlling cars on different tracks, which would help understand how different methods work. This part of the comment is specific in its request for additional visual aids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The second part of the comment mentions a lack of implementation details and the unclear policy gradient approach, but it does not specify where these issues are located in the paper. This makes it difficult for the authors to pinpoint the exact sections that need attention. Overall, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that providing videos would enhance understanding of different methods and mentions a lack of implementation details, which hinders reproducibility. However, the comment does not provide specific examples or references to support these claims. The mention of unclear policy gradient approach is also not substantiated with detailed reasoning or evidence. This lack of detailed justification makes the claims somewhat verifiable, as the authors would need to infer the specific issues and address them without explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors include videos demonstrating different policies controlling cars on different tracks, which would help readers understand how different methods work. This is a specific and actionable suggestion that could enhance the paper\\'s clarity and reproducibility. Second, the comment points out a lack of implementation details in the main paper, which makes reproducing the results difficult. It also highlights the unclear policy gradient approach used, indicating that this information is missing. While the comment identifies important areas for improvement, it could be more helpful by providing more detailed guidance on what specific implementation details are lacking or how to clarify the policy gradient approach. Overall, the feedback is mostly helpful as it directs the authors to critical areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the approximation in Equation 11, suggesting that the authors should provide more explanation or justification for their approach. It also points out a lack of clarity in Figure 1, specifically regarding the representation of layers, and recommends conducting more experiments and theoretical analyses. While the comment implies that the authors should provide additional information and conduct further research, it does not explicitly instruct them on how to address these issues. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the approximation in Equation 11, noting that it only considers the impact of params in each layer and does not account for the effect of the order of layers with the same params in the network. Additionally, it points out a lack of clarity in Figure 1 regarding the representation of layers and suggests conducting more experiments and theoretical analyses. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the approximation in Equation 11, suggesting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters in the network. The reviewer provides a logical reasoning by pointing out a potential limitation in the approximation method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the approximation in Equation 11, suggesting that the authors should provide a clearer explanation of why this approximation is valid. It points out a specific limitation in the approximation, noting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters in the network. Additionally, the comment highlights a lack of clarity in Figure 1, specifically regarding the representation of layers, and suggests conducting more experiments and theoretical analyses to explore this aspect. This feedback is mostly helpful as it identifies specific areas for improvement and provides a clear direction for the authors to enhance their work. However, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of similar approaches. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment does not provide explicit guidance or concrete steps on how the authors should address this issue or improve their approach. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the topic of offline-to-online learning adaptation and suggests that the approach is incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on how the authors could address this issue or improve their approach. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to act on this feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the approach to offline-to-online learning adaptation is incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable, as it does not provide sufficient information for the authors to address the critique effectively. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment lacks specificity and does not provide actionable guidance or suggestions for improvement. It does not identify particular weaknesses or offer constructive feedback on how the authors might enhance their approach or address the perceived incremental nature of their work. As a result, the comment is barely helpful, as it points out a potential issue but does not assist the authors in making improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction in the results presented in Table 6, specifically noting that AT, which fine-tunes the detection model with emotion classification data, achieves a worse F1 score than BERTsynth, which does not use emotion-awareness. It also points out that GAS, which fine-tunes the model with multiple emotion classification datasets, achieves the lowest F1 score. The reviewer suggests that these results do not support the claim that emotion-awareness is useful for synthetic text detection. While the comment identifies a specific issue with the results, it does not provide explicit guidance on how the authors should address this contradiction or improve their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate or clarify the results related to emotion-awareness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the contradiction in the evidence provided, particularly regarding the F1 scores of AT and BERTsynth, and the performance of GAS. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 6 provides contradicting evidence regarding the usefulness of emotion-awareness for synthetic text detection. It supports this claim by providing specific examples, such as AT achieving a worse F1 score than BERTsynth despite using emotion classification data, and GAS achieving the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This detailed comparison and logical reasoning make the claim mostly verifiable, as it provides a clear rationale for the contradiction. However, the comment could be strengthened by referencing additional studies or data to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 6, pointing out a contradiction in the evidence provided. It highlights that AT, which fine-tunes the detection model with emotion classification data, achieves a worse F1 score than BERTsynth, which does not use emotion-awareness. Additionally, it notes that GAS, which fine-tunes the model with multiple emotion classification datasets, achieves the lowest F1 score. This feedback is valuable as it challenges the claim that emotion-awareness is useful for synthetic text detection, prompting the authors to reconsider or clarify their results. However, the comment could be more helpful if it provided suggestions on how to address this contradiction or improve the analysis. Overall, the comment is mostly helpful as it identifies a critical issue and provides some insight into the problem, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting more experiments to address the research question and test the method\\'s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models. While the comment provides explicit actions, it lacks detailed guidance on how to implement these suggestions, such as specific experimental setups or noise models to consider. The authors are given a clear direction but without concrete steps on how to execute the actions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments to address the research question and test the method\\'s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental or results sections. The suggestion is specific, as it provides clear guidance on what additional experiments or models could be included to enhance the evaluation. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments to address the research question and test the method\\'s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models. The comment provides specific references to external works, which supports the claim by offering examples of models and noise models that could be used for further experimentation. This detailed guidance and the inclusion of references make the claim mostly verifiable, as it provides a clear direction for improvement with sufficient evidence. However, the comment could be strengthened by providing more detailed reasoning or examples of how these experiments would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting additional experiments to address the research question and test the method\\'s generalizability. It specifically recommends testing with various models, such as Vision Transformers (ViT), and including results under more complex input noise models. This guidance is clear and offers a concrete direction for the authors to enhance the comprehensiveness and robustness of their evaluation. By following these suggestions, the authors can significantly improve the depth and validity of their experimental results. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to implement these additional experiments. Overall, the feedback is mostly helpful as it identifies key areas for improvement and provides a general direction for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the D.2 appendix mentions two human annotators, but according to the author responses, the correct number should be four. This feedback provides a clear and direct action for the authors to take, which is to correct the number of human annotators mentioned in the appendix. The comment is specific and leaves no ambiguity about what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy in the number of human annotators mentioned in the appendix. The comment provides clear guidance on what needs to be corrected, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a factual statement about the number of human annotators mentioned in the D.2 appendix, indicating that the authors have clarified that the correct number is four. This is a straightforward observation and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the appendix regarding the number of human annotators mentioned. It provides a clear and actionable piece of feedback, allowing the authors to correct this oversight and ensure accuracy in their work. This level of detail and precision is valuable for the authors, as it directly addresses a factual error that could impact the credibility of their findings. However, the comment could be more helpful if it explained the importance of this correction or its potential impact on the study. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not provide specific guidance on what aspects of the motivation are lacking or how the authors might improve it. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would improve the understanding of the proposed approach. However, it does not specify which part of the paper discusses the encoder and decoder structure, making it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation are lacking or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not provide any specific reasoning, examples, or references to support why the current motivation is insufficient or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might achieve this better motivation. Without detailed suggestions or examples, the authors are left with a general idea of what needs to be improved but without clear steps to take. Therefore, the comment is barely helpful, as it points out a weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited novelty of the explored loss functions, suggesting that they are not new and may be a simple \"plug and play\" of existing functions. It also points out the limitation of conducting only white-box attacks and the absence of black-box evaluation. Additionally, it recommends extending the analysis to include targeted attacks to demonstrate the strength of the proposed attack method. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these concerns. The actions are implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several specific concerns regarding the novelty of the explored loss functions, the limitation of conducting only white-box attacks, and the absence of black-box evaluation. It also suggests extending the analysis to include targeted attacks. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed, such as the novelty of loss functions and the need for black-box evaluation. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions, suggesting that they are not new and may be a simple \"plug and play\" of existing functions. It also criticizes the lack of black-box evaluation and the limitation to untargeted attacks. While the comment provides some reasoning by mentioning the commonality of the loss functions and the absence of black-box evaluation, it lacks specific references or detailed examples to fully substantiate the claims. The authors would need to make a significant effort to understand and address these concerns without additional context or evidence. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical areas for improvement in the paper. It points out the limited novelty of the explored loss functions, suggesting that they are not new and may be a simple \"plug and play\" of existing functions. This feedback is valuable as it encourages the authors to consider the originality and contribution of their work. Additionally, the comment highlights the limitation of conducting only white-box attacks and the absence of black-box evaluation, which is a significant gap in the study. It also suggests extending the analysis to include targeted attacks, which would demonstrate the strength of the proposed attack method. This feedback is clear and actionable, providing the authors with specific directions to enhance their work. However, it could be more helpful if it offered suggestions on how to address the novelty issue or how to incorporate black-box evaluation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results for CIFAR10 are not impressive and suggests that a direct comparison with the approaches mentioned is mandatory. It also requests results for CIFAR100. While the comment explicitly states the need for a direct comparison and additional results, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results for CIFAR10, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the results for CIFAR10 are not impressive and that a direct comparison with the approaches mentioned is mandatory. Additionally, it suggests including results for CIFAR100. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with the approaches mentioned is necessary. However, the comment lacks specific examples or references to the approaches mentioned, making it difficult for the authors to understand the basis of the claim or how to address it. The suggestion to include results for CIFAR100 is more actionable, but the overall claim remains vague and unsupported. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented for CIFAR10, noting that they are not impressive compared to the approaches mentioned. It explicitly suggests that a direct comparison with these approaches is mandatory and also requests results for CIFAR100. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing the lack of comparative results. However, the comment could be more helpful if it offered additional guidance on how to enhance the presentation or interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with further suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that the experiments do not clearly demonstrate the suitability of hyperbolic space for hierarchical datasets, despite the known suitability of hyperbolic space for such datasets. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might demonstrate this suitability or what specific experiments or analyses could be conducted to provide clearer evidence. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the experiments not clearly demonstrating the suitability of hyperbolic space for hierarchical datasets, despite its known suitability. However, it does not specify which experiments or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact parts that need attention. Additionally, the comment lacks specificity regarding what aspects of the experiments are lacking or how they could be improved to demonstrate this suitability. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments do not clearly demonstrate the suitability of hyperbolic space for hierarchical datasets, despite its known suitability. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence from the experiments to substantiate the assertion that the experiments fail to demonstrate this suitability. As a result, the claim is not well-supported, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a potential gap in the paper, noting that while hyperbolic space is known to be well-suited for hierarchical datasets, the experiments do not clearly demonstrate this. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific experiments or analyses could be conducted to demonstrate the suitability of hyperbolic space. Without detailed suggestions or examples, the feedback is limited in its usefulness to the authors. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the main strength of MixBoost, asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While the comment identifies areas of potential strength, it does not provide explicit guidance or suggestions on how the authors should address this question or clarify the main strength of their method. The action is implicit, as the authors can infer that they need to clarify the main strength, but it remains vague because it lacks concrete steps or examples on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the main strength of MixBoost, specifically asking whether it relates to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the main strength of MixBoost, but without clear grounding, the authors may struggle to determine where to address this question in their paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the main strength of MixBoost. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the main strength of MixBoost, asking whether it relates to computational savings, generalization performance, or the use of Random Fourier Features. This feedback is somewhat helpful as it prompts the authors to clarify the key advantages of their method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the wording used in the paper regarding hyperparameter tuning and suggests an alternative approach to avoid using a \"smaller training set.\" While the comment implies that the authors should reconsider their approach to hyperparameter tuning, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The feedback is somewhat actionable as it identifies an area for improvement but lacks detailed guidance on how to address the issue. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"243\" and \"245,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the wording regarding hyperparameter tuning and suggests an alternative approach to avoid using a \"smaller training set.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the wording used in the paper regarding hyperparameter tuning, suggesting that it could be improved. The reviewer agrees that proper hyperparameter tuning is essential but finds the wording to be \"a bit hard.\" Additionally, the comment suggests an alternative approach to avoid using a \"smaller training set\" by training the network with optimal parameters on the complete train+val. However, the comment lacks specific examples or references to support the claim about the wording being hard or to substantiate the suggestion for an alternative approach. This makes the claim somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording used in the paper regarding hyperparameter tuning, suggesting that it could be improved for clarity. It also provides a constructive suggestion for avoiding the use of a \"smaller training set\" by training the network with optimal parameters on the complete train+val. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it included additional guidance on how to implement the suggested approach or provided examples of how to rephrase the wording. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. It recommends that the authors provide more details on how they tokenize parameters and use DDPM to predict actual parameters. This feedback is clear and provides a specific action for the authors to take, which is to elaborate on the implementation details. The suggestion is concrete, as it guides the authors on what specific information to include to improve the clarity of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be improved, such as elaborating on the actual implementation, hinting at how parameters are tokenized, and using DDPM to predict actual parameters. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the writing of the paper needs improvement, specifically mentioning that the introduction is obscure and high-level. It suggests that the authors provide more details on how they tokenize parameters and use DDPM to predict actual parameters. However, the comment lacks specific examples or references to support the claim that the introduction is unclear or how it could be improved. Without detailed justification or evidence, the claim remains somewhat vague, making it somewhat verifiable. The authors may find it challenging to address the feedback without further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s writing, noting that the introduction is obscure and high-level, lacking detailed implementation details. It suggests that the authors provide more clarity on how they tokenize parameters and use DDPM to predict actual parameters. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and depth of their introduction. By offering a specific suggestion, the comment empowers the authors to make targeted improvements to their draft. However, it could be more helpful if it included additional guidance on how to structure the introduction or examples of what specific details to include. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is not good but does not provide any specific examples or suggestions for improvement. It lacks explicit guidance on what aspects of the presentation are problematic or how the authors might enhance it. Without concrete details or actionable advice, the authors are left without a clear understanding of what changes are needed to improve the presentation. As a result, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation is not good but does not specify which aspects of the presentation are problematic or how they could be improved. It lacks grounding as it does not identify specific sections, figures, or tables that need attention. Additionally, it is not specific because it does not provide details on what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the presentation is not good,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment states that the presentation is not good but does not provide any specific examples or detailed feedback on what aspects of the presentation are problematic. Without concrete suggestions or guidance, the authors are left without a clear understanding of how to improve their presentation. This lack of actionable feedback makes the comment unhelpful, as it does not offer any direction for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors have missed a relevant work by Rieck et al. in their discussion of the correlation between topological complexity and generalization ability. This feedback provides a clear and direct action for the authors to take, which is to include the work by Rieck et al. in their literature review. The comment is specific and provides a concrete step for the authors to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section related to the correlation of topological complexity with generalization ability, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the work by Rieck et al. in the literature review. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have missed a relevant work by Rieck et al. in their discussion of the correlation between topological complexity and generalization ability. This claim is supported by providing a specific reference, which allows the authors to verify the omission and address it. The inclusion of a reference provides a clear and direct basis for the claim, making it fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific omission in the related work section, pointing out that the authors have missed the work by Rieck et al. in their discussion of the correlation between topological complexity and generalization ability. This feedback is actionable as it provides a clear direction for the authors to include a relevant reference in their literature review, thereby enhancing the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it explained why this particular work is important or how it relates to the authors\\' work. Despite this, the comment is mostly helpful as it guides the authors to improve their draft by addressing a specific oversight.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the usefulness of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, noting that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it asks whether the analysis, which is based on expectations, can be extended to high-probability bounds on the regret. While the comment implies that the authors should consider these points, it does not explicitly instruct them to make changes or provide detailed guidance on how to address the issues. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the provided upper-bounds on the pseudo-regret and the role of the exploration parameter gamma. The comment suggests a potential improvement by discussing high-probability upper-bounds and the role of gamma, and it raises a question about extending the analysis to high-probability bounds on the regret. This provides clear guidance on what the authors need to address or consider in their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the usefulness of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, noting that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. The comment also asks whether the analysis, which is based on expectations, can be extended to high-probability bounds on the regret. While the comment raises valid questions and suggests areas for improvement, it lacks specific examples or references to support the claim about the uselessness of gamma or the potential for extending the analysis. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the analysis presented in the paper, specifically regarding the exploration parameter gamma in Algorithm 1 and Theorem 3.1. It points out that only upper-bounds on the pseudo-regret are provided, which may render the exploration parameter useless. The comment suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it raises a question about whether the analysis, which is based on expectations, can be extended to high-probability bounds on the regret. This feedback is mostly helpful as it provides clear and actionable suggestions for the authors to consider, such as discussing the role of gamma and exploring high-probability bounds. However, it could be more helpful if it offered specific guidance on how to address these issues or provided examples of similar analyses. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add a restatement of the definition of LCA relaxation from Wang et al. in the body of the paper or to provide a description in the appendix. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add a restatement of the definition of LCA relaxation from Wang et al. or provide a description in the appendix. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LCA relaxation is referenced but not directly defined in line 150. The reviewer suggests adding a restatement of the definition from Wang et al. or providing a description in the appendix. This claim is somewhat verifiable as it highlights a specific issue with the paper\\'s clarity and suggests a potential solution. However, it lacks detailed reasoning or examples to fully substantiate the need for the addition, making it somewhat verifiable. The authors would need to infer the importance of this addition based on the suggestion alone.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the LCA relaxation is referenced but not directly defined in line 150. It provides a clear and actionable suggestion for improvement by recommending that the authors either restatement the definition from Wang et al. in the body of the paper or add a description to the appendix. This feedback is precise and offers a straightforward way for the authors to enhance the clarity and completeness of their manuscript. By addressing this point, the authors can improve the readability and comprehensibility of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more information on how validation and test splits influence model training could enhance reproducibility. While the action is implied, it is clear and concrete, as it specifies exactly what additional information is needed to improve the draft. The authors can infer that they should include details on the validation and test splits to strengthen reproducibility. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could enhance reproducibility. However, it does not specify which part of the paper discusses the dataset or the validation and test splits, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about what additional information could be provided but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more information on how validation and test splits influence model training could enhance reproducibility. However, the comment does not offer specific examples or detailed reasoning to support why this additional information is necessary or how it would improve reproducibility. The lack of explicit justification or references makes it difficult for the authors to understand the basis of the suggestion, rendering the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more information on how validation and test splits influence model training could enhance reproducibility. This feedback is actionable as it provides a clear direction for the authors to improve their draft by including additional details on the validation and test splits. However, the comment could be more helpful if it offered specific examples or guidance on what kind of information should be included. Despite this, the feedback is mostly helpful as it directs the authors to a critical aspect of their work that could benefit from further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the scope of the authors\\' approach to addressing overfitting, specifically questioning why they limit their focus to dropout and not other regularization techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential effects of using ZeroLiers in combination with these techniques. While the comment implies that the authors should consider a broader range of regularization techniques, it does not explicitly instruct them to do so or provide concrete guidance on how to incorporate these techniques into their work. The action is implicit and somewhat vague, as the authors need to infer that they should expand their scope and consider additional techniques. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the scope of the authors\\' approach to addressing overfitting, specifically questioning why they limit their focus to dropout and not other regularization techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential effects of using ZeroLiers in combination with these techniques. However, the comment does not specify which part of the paper discusses the overfitting problem or the use of dropout, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in questioning the scope of the approach and suggesting alternative techniques, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and suggestions regarding the scope of the authors\\' approach to addressing overfitting. It does not contain any subjective claims, opinions, or judgments that require verification. The questions are aimed at prompting the authors to consider additional regularization techniques and their potential interactions. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scope of the authors\\' approach to addressing overfitting, specifically questioning why they limit their focus to dropout and not other regularization techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential effects of using ZeroLiers in combination with these techniques. This feedback is valuable as it prompts the authors to consider a broader range of approaches to address overfitting, which could lead to a more comprehensive and robust solution. However, the comment could be more helpful if it provided specific suggestions or examples of how to incorporate these additional techniques into the study. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that discussing this generalization would be beneficial, given that the authors have already mentioned it in the section about consistency. While the comment implies that the authors should expand on this discussion, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the generalization and how it relates to the consistency section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and the section about consistency, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about generalizing the assumption from a tabular setting to a function approximation setting and suggests discussing this in the paper. This provides clear guidance on what needs to be addressed or expanded upon. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that discussing this generalization would be beneficial, given its mention in the section about consistency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this generalization is necessary or how it might impact the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It acknowledges that the assumption is reasonable in a tabular context but suggests that discussing its generalization would be beneficial. This feedback is clear and actionable, as it directs the authors to consider and address a potential limitation or gap in their work. By prompting the authors to discuss this generalization, the comment provides a concrete step for improving the draft. However, it could be more helpful if it offered specific suggestions or examples on how to approach this discussion. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing their paper by addressing a relevant issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that Table 1 should be one column wide and that the figures, particularly 3, 5, and 6, would benefit from a two-column width. Additionally, it advises that the paper could be improved by straightening up the content. These suggestions are clear and actionable, giving the authors specific guidance on how to enhance the presentation and readability of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that Table 1 should be one column wide and that the figures would benefit from a two-column width. Additionally, it provides a general suggestion for improvement by stating that the paper could be made easier to understand by straightening up the content. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper could be improved by adjusting the layout of tables and figures, specifically recommending that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. However, the comment does not provide any reasoning or evidence to support why these changes would enhance the paper\\'s readability or understanding. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback regarding the layout and presentation of the paper. It suggests that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width, which could improve the overall readability and clarity of the paper. Additionally, the comment mentions that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This feedback is clear and offers concrete steps for the authors to enhance the presentation and readability of their work. However, it could be more helpful if it included specific suggestions on how to straighten up the content. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific modification to the experimental setup, recommending that the authors repeat the Text-DPO baseline but with the generated images used for DPO as images for additional image-question-answer triplets. It also implies that the additional performance benefit might come from training with perturbed images rather than the specific DPO objective. While the comment provides a clear action to take, it lacks detailed guidance on how to implement this change or why it would be beneficial. The authors are given a concrete suggestion but are left to infer the rationale behind it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the \"Text-DPO baseline\" and suggests a specific modification to the experimental setup, including the creation of new image-question-answer triplets using perturbed images. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it provides a clear suggestion for improvement and offers a rationale for why the authors might consider this modification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the additional performance benefit of the method might come from training with perturbed images rather than the specific DPO objective. The reviewer provides a specific suggestion for experimentation by recommending the creation of additional image-question-answer triplets using perturbed images. However, the claim is not fully substantiated with detailed reasoning or evidence, such as data or results from similar experiments. While the suggestion is logical, the lack of comprehensive justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the experimental setup by recommending the creation of additional image-question-answer triplets using perturbed images. This feedback is actionable and offers a clear direction for the authors to explore, potentially leading to a deeper understanding of the method\\'s performance benefits. However, the comment could be more helpful if it included a rationale for why this modification might be beneficial or how it could impact the results. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a final assumption in the paper regarding the expertise levels of Alice and Bob, suggesting that this assumption may not hold in real-world scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this assumption or improve the draft based on this observation. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to enhance their work. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific assumption regarding the expertise levels of Alice and Bob, which is a unique aspect of the paper. However, it does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and provides examples of real-world scenarios where this assumption might not hold. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about a final assumption in the paper regarding the expertise levels of Alice and Bob. It suggests that this assumption may not hold in real-world scenarios and that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical assumption in the paper regarding the expertise levels of Alice and Bob, suggesting that this assumption may not hold in real-world scenarios. It highlights the potential for non-linear interactions between success-rate and speed-up due to varying levels of expertise. While the comment points out an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative assumptions. The feedback is somewhat helpful as it prompts the authors to reconsider their assumptions, but it could be more beneficial with additional direction or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation of the mitigation strategies, such as data sanitization, which are specific to the dataset and may not be applicable more generally. It points out that the framework is not very generalizable and its applicability to other LLMs and datasets might be limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how the authors might improve the generalizability of their framework or suggest alternative strategies. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the mitigation strategies, such as data sanitization, and discusses their limitations in terms of generalizability across datasets and LLMs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the mitigation strategies and the generalizability of the framework, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation strategies, such as data sanitization, are dataset-specific and may not be applicable more generally. It further suggests that the framework is not very generalizable and its applicability to other LLMs and datasets might be limited. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the critique. The reasoning is somewhat verifiable, as it provides a logical argument about the limitations of the mitigation strategies, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the generalizability of the mitigation strategies, such as data sanitization, which are specific to the dataset used. It points out that the framework's applicability to other LLMs and datasets might be limited due to this specificity. While the comment highlights a critical issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their framework. Without actionable advice, the feedback is somewhat helpful as it provides insight into a potential weakness but does not fully support the authors in making improvements. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is not clear in some aspects and provides a list of questions to illustrate this. However, it does not specify which parts of the paper are unclear or how the authors should address these issues. The comment implies that the weaknesses could be fixed, but it lacks explicit guidance or concrete suggestions on how to improve clarity. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the paper is not clear in some aspects and provides a list of questions to illustrate this. However, it does not specify which parts of the paper are unclear or which questions pertain to specific sections. This lack of explicit references makes it difficult for the authors to pinpoint the exact areas needing clarification. Additionally, the comment does not provide specific guidance on how to address the issues, making it challenging for the authors to know what changes are needed. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not sufficiently clear in some aspects, but it does not provide specific examples or detailed reasoning to support this claim. The mention of \"a list of questions\" suggests that there might be more information elsewhere, but without it, the comment lacks the necessary detail to be verifiable. As it stands, the claim is not supported by specific evidence or examples, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the paper is not clear in some aspects, but it does not specify which parts are unclear or provide any examples or suggestions for improvement. Additionally, the comment states that the weaknesses could be fixed, but it lacks actionable guidance or specific feedback on how to address these issues. Without detailed information or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of questions asking for clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task participants are performing. While these questions imply that the authors should provide additional information or clarification, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to Figure 2, which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also raises specific questions about the relationship between natural and synthetic audio signals and the task conditions, as well as the task participants are performing. These questions highlight areas that need clarification, making the comment specific. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task participants are performing. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task participants are performing. While these questions highlight areas that may need clarification, the comment does not provide any suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is somewhat helpful as it points out potential areas of confusion, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors did not address several important issues in open domain dialogue, such as memory registration, personalization to user characteristics, and reasoning over common sense and facts. However, it does not provide explicit guidance or suggestions on how the authors should incorporate these aspects into their work. The comment implies that these areas need attention, but it lacks concrete instructions or examples on how to address them. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that it does not address other problems in open domain dialogue such as memory registration, personalization to user characteristics, and reasoning over common sense and facts. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how these issues could be addressed or improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not address several important issues in open domain dialogue, such as memory registration, personalization to user characteristics, and reasoning over common sense and facts. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general critique without sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that it does not address several important issues in open domain dialogue, such as memory registration, personalization to user characteristics, and reasoning over common sense and facts. This feedback highlights a critical area for improvement, which is crucial for the authors to consider in order to enhance the comprehensiveness and relevance of their work. However, the comment lacks specific suggestions or guidance on how the authors might incorporate these aspects into their research. While it provides a clear direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that Arxiv papers are not peer-reviewed and are often considered informal, which could affect the significance of the results. However, the comment does not provide explicit guidance on how the authors should address this issue, such as recommending specific actions to improve the paper\\'s credibility or suggesting alternative methods for evaluating the results. The feedback is vague and lacks concrete steps for the authors to follow, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that Arxiv papers are not peer-reviewed and are often considered informal, which could affect the significance of the results. However, the comment does not specify which part of the paper discusses these venues or the results, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these issues are discussed, the comment lacks full grounding. It is specific about the concerns regarding Arxiv papers but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers in the study. The reviewer argues that Arxiv papers are not peer-reviewed and are often considered informal, which could affect the significance of the results. However, the comment lacks specific examples or references to support the claim that Arxiv papers are generally of lower quality or that they bias the results. Without concrete evidence or detailed reasoning, the claim remains somewhat verifiable, as it requires more information to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers in the study. It highlights the potential bias that could arise from including non-peer-reviewed papers, which are often considered informal and of lower quality. The comment suggests that this could affect the significance of the results presented in the paper. However, the feedback lacks specific guidance or suggestions on how the authors might address this issue or improve the credibility of their findings. While it identifies a potential weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework rather than devoting significant space to applications. While the action is explicit, it lacks concrete guidance on how to achieve this balance or what specific aspects of the problem and framework should be emphasized. The authors are given a general direction but are left without detailed instructions on how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework rather than devoting significant space to applications. However, it does not specify which parts of the paper should be revised or which applications are being referred to, making it difficult for the authors to identify the exact areas needing attention. The lack of specific guidance or references to particular sections or examples results in weak grounding and specificity. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than on applications. However, it does not provide any specific reasoning or evidence to support why this shift in focus would be beneficial or necessary. The comment lacks detailed justification or examples that would help the authors understand the rationale behind the suggestion. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to address the feedback effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework rather than devoting significant space to applications. While it identifies a potential imbalance in the paper, it lacks specificity and actionable guidance on how to achieve this shift in focus. The comment does not provide details on which aspects of the problem or framework should be emphasized or how the authors might restructure their content to better align with the proposed problem. Without specific suggestions or examples, the feedback offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work, suggesting that the paper is marginally above the acceptance threshold. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their draft or what specific aspects of the paper need further attention. As a result, the comment lacks actionability, leaving the authors without direction on how to enhance their work. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper it addresses, making it not grounded. It also lacks specificity as it does not provide details on what the authors have adequately addressed or how they have addressed the limitations and potential negative societal impact. Without specific references or detailed feedback, the authors cannot effectively understand or respond to the comment. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors have adequately addressed the limitations and potential negative societal impact of their work, suggesting that the paper is marginally above the acceptance threshold. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the work have been addressed, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work, suggesting that the paper is marginally above the acceptance threshold. However, it does not provide any specific feedback or suggestions on how the authors could further improve their work or address any remaining issues. Without actionable advice or detailed guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the simplicity of the dataset could lead to its solution by an agent translating natural language into triples and using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the potential limitations of their research impact or suggestions for enhancing the dataset or methodology. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the simplicity of the dataset, suggesting that it could be easily solved by an agent translating natural language into triples and using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not specify which part of the paper this critique is based on, nor does it provide specific guidance on how the authors might address these concerns. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the simplicity of the dataset could lead to its solution by an agent translating natural language into triples and using code or search libraries. It suggests that the natural language is generated by patterns, making natural language understanding easy. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or comparisons to other datasets or methods, the claim remains vague and difficult for the authors to verify. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the simplicity of the dataset, suggesting that it could be easily solved by an agent translating natural language into triples and using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. While the comment identifies a potential limitation of the dataset, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the research impact of their work. The feedback lacks actionable advice or constructive suggestions, leaving the authors without a clear path for improvement. Therefore, the comment is rated as barely helpful, as it highlights a concern but does not offer meaningful guidance for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests revising a statement about the maximum likelihood estimation, noting that the limitations of the proposed measure are not fairly discussed. It also mentions that the proposed measure does not provide a stronger theoretical connection to generalization and does not outperform other measures experimentally. While the comment implies that the authors should revise the statement and discuss the limitations more thoroughly, it does not provide specific guidance on how to revise the statement or what aspects of the limitations should be addressed. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"25: masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to revise a statement about maximum likelihood estimation and discusses the limitations of the proposed measure. The comment specifies what needs to be addressed, namely the lack of a stronger theoretical connection to generalization and the failure to outperform other measures experimentally. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests revising a statement about maximum likelihood estimation, noting that the limitations of the proposed measure are not fairly discussed. The reviewer provides a specific critique by stating that the proposed measure does not provide a stronger theoretical connection to generalization and does not outperform other measures experimentally. This claim is supported by logical reasoning and a clear explanation of the issue, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the limitations of the proposed measure are not fairly discussed. It points out that the statement about maximum likelihood estimation is not adequately supported by the presentation, which lacks a stronger theoretical connection to generalization and does not demonstrate outperforming other measures experimentally. This feedback is clear and actionable, as it directs the authors to revise their statement and provide a more balanced discussion of the limitations. However, the comment could be more helpful if it offered suggestions on how to address these limitations or improve the presentation. Overall, the comment is mostly helpful, as it provides valuable insights into areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of results from fine-tuned open-source large language models (LLMs) in the domain-specific benchmark. While it implies that the authors should include these results, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to incorporate these results or which specific models to consider. The action is implicit and vague, leaving the authors uncertain about the exact steps to take to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of results from fine-tuned open-source large language models (LLMs) in the domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these results should be included. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in pointing out the lack of fine-tuned LLM results, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of results from fine-tuned open-source large language models (LLMs) is important for a domain-specific benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these results are crucial or how they would impact the benchmark. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of results from fine-tuned open-source large language models (LLMs) in the domain-specific benchmark. This is a relevant point that could enhance the comprehensiveness and relevance of the benchmark. However, the comment lacks depth and does not provide specific guidance on how the authors might incorporate these results or which models to consider. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the training of the regression model, including the input and output, the parameter space for different feature sizes, and the impact of the number of parameters on model performance. While these questions imply that the authors should provide more detailed information about the training process, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the training of the regression model, specifically asking about the input, output, and parameter space for different feature sizes. It also inquires about the impact of the number of parameters on model performance. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the regression model is discussed. The comment is specific in detailing what information is missing or unclear, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the regression model\\'s training process, inputs, outputs, parameter space, and the impact of parameter number on model performance. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the training of the regression model, including the input and output, the parameter space for different feature sizes, and the impact of the number of parameters on model performance. These questions highlight potential areas of confusion or lack of clarity in the paper, prompting the authors to provide more detailed information about their methodology. However, the comment does not offer specific suggestions or guidance on how to address these questions or improve the clarity of the paper. While it identifies key areas for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an issue with the notation in equation 6 and related equations, suggesting that the operator after w_i should be the multiplication of the underlying vector space rather than \\\\cross_g. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be corrected in the equations. The comment is concrete, as it provides a specific change that needs to be made to improve the accuracy of the equations. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"eq 6 and related equations,\" which provides full grounding as it allows the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by suggesting that the operator after w_i should be the multiplication of the underlying vector space rather than \\\\cross_g, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator after w_i should be the multiplication of the underlying vector space rather than \\\\cross_g. This claim is based on the logical reasoning that the operator should be between a scalar and a tensor, not just between two scalars. The comment provides a clear explanation of the issue, making it mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the notation in equation 6 and related equations. It points out that the operator after w_i should be the multiplication of the underlying vector space rather than \\\\cross_g, which is a logical correction based on the nature of the operator. This feedback is clear and directly addresses a potential error in the manuscript, guiding the authors to make a precise correction that could improve the accuracy and clarity of their work. The comment is highly helpful as it offers a concrete suggestion that can significantly enhance the draft, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of the proposed model. It specifies the areas that need further exploration, such as the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This provides clear and concrete guidance on what the authors need to do to improve their draft. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper should include these experiments, making it weakly grounded. The comment is specific in detailing what additional experiments are needed, providing clear guidance on what the authors should address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add more ablation experiments to demonstrate the effectiveness of the proposed model. It specifically mentions the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, the comment does not provide any supporting evidence, examples, or references to justify why these ablation experiments are necessary or how they would improve the paper. Without additional context or reasoning, the claim is not verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the addition of more ablation experiments. It specifically identifies areas where additional experiments could be beneficial, such as exploring the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback is valuable as it guides the authors on how to enhance the depth and robustness of their experimental analysis, which could significantly strengthen the paper. However, the comment could be more helpful if it offered specific examples or methodologies for conducting these experiments. Overall, the comment is mostly helpful, as it provides clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions adaptive mechanisms from Phan et al. (2017, 2019, 2020) and other related works as potential baseline approaches for comparison. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions or which datasets or mechanisms to consider. The authors are left with a general idea of what could be done but without detailed instructions on how to achieve it. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the datasets used in the experiments, such as \"dim=24 in power consumption, dim=6 in real estate valuation, and dim=30 in breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. Additionally, it provides specific references to adaptive mechanisms and related works that could be considered as baseline approaches for comparison. This level of detail provides clear guidance for the authors, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks. It provides specific examples of the current datasets\\' dimensions and mentions the potential use of adaptive mechanisms from Phan et al. (2017, 2019, 2020) as baseline approaches. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific datasets or learning tasks that could be used for comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental results, specifically noting that the datasets used have limited dimensions. It suggests that the work could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. Additionally, it mentions adaptive mechanisms from Phan et al. (2017, 2019, 2020) and other related works as potential baseline approaches for comparison. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their experimental setup and offering a reference for potential improvements. However, the comment could be more helpful if it included specific examples or guidance on how to implement these suggestions. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful enhancements of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the effectiveness of PRESENCE, specifically questioning the justification for the two-stage pre-training based on the relationship between temperature $\\\\tau$ and downstream performance in Figure 5. It suggests that using a positive or negative $\\\\tau$ could lead to improvement over no reweighting, which makes the reviewer curious about the necessity of reweighting. Additionally, the comment points out that the results from Table 4 do not demonstrate the advantage of using PRESENCE for cross-lingual zero-shot transfer. While the comment raises valid questions and concerns, it does not provide explicit actions or concrete suggestions for the authors to address these issues. The authors are left to infer that they should provide further analysis or justification for their claims, but the lack of specific guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of PRESENCE and the justification for the two-stage pre-training, particularly regarding the relationship between temperature $\\\\tau$ and downstream performance. Additionally, it raises concerns about the results from Table 4 not demonstrating the advantage of using PRESENCE for cross-lingual zero-shot transfer. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the effectiveness of PRESENCE by highlighting that the relationship between temperature $\\\\tau$ and downstream performance in Figure 5 does not convincingly justify the two-stage pre-training. It suggests that using a positive or negative $\\\\tau$ could lead to improvement over no reweighting, which makes the reviewer curious about the necessity of reweighting. Additionally, the comment points out that the results from Table 4 do not demonstrate the advantage of using PRESENCE for cross-lingual zero-shot transfer. While the comment raises valid concerns, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to further explore and substantiate the claims themselves to address the feedback effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the effectiveness of PRESENCE, specifically questioning the justification for the two-stage pre-training based on the relationship between temperature $\\\\tau$ and downstream performance in Figure 5. It suggests that using a positive or negative $\\\\tau$ could lead to improvement over no reweighting, which makes the reviewer curious about the necessity of reweighting. Additionally, the comment points out that the results from Table 4 do not demonstrate the advantage of using PRESENCE for cross-lingual zero-shot transfer. While the comment identifies areas of concern and raises valid questions, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it prompts the authors to reconsider their experimental setup and results, but it could be more beneficial with additional direction or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point observes that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this observation should be addressed, investigated further, or if it impacts the interpretation of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation about the results for k=1 being better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. This provides clear guidance on what aspect of the results needs further investigation or clarification. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the results in Table 2, suggesting that the performance gain for k=1 might be due to a reason other than applying Eq.10. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out an interesting observation regarding the results in Table 2, specifically noting that the performance for k=1 is already better than the baselines. It suggests that this might indicate a performance gain due to a reason other than applying Eq.10. While the comment identifies a potential issue or area for further investigation, it lacks specific guidance or suggestions on how the authors might explore or address this observation. The feedback is somewhat helpful as it provides a direction for further analysis, but it could be more beneficial with additional context or actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method lacks solid grounding and that the choice of mixed-integer programming is not fully justified. It also notes that the advantages of this approach over alternative methods are unclear. However, the comment does not provide specific guidance on how the authors should address these issues or suggest alternative approaches or justifications. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method for lacking solid grounding and questions the choice of mixed-integer programming, noting that its advantages over alternative approaches are unclear. However, it does not specify which part of the paper discusses the method or the choice of programming, making it weakly grounded. The comment is specific in identifying the issue with the justification and advantages of the method, but without clear references to specific sections, the authors may struggle to pinpoint where improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding and that the choice of mixed-integer programming is not fully justified. However, it does not provide specific reasoning or evidence to support this claim. The comment lacks detailed explanation or examples that would help the authors understand why the choice is problematic or how it could be improved. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to address the critique effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it lacks solid grounding and that the choice of mixed-integer programming is not fully justified. It also points out that the advantages of this approach over alternative methods are unclear. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or justify their method more effectively. The feedback is somewhat helpful as it directs the authors to a critical area needing clarification, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific issues: the confusing notation in Equation 1, where \"c\" is used instead of \"o,\" and the missing reference to Pedersen et al 2007 in the reference section. These are explicit actions that the authors can take to improve their draft. The comment provides clear guidance on what needs to be corrected, making it highly actionable. The authors know exactly what changes to make to address these issues.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the confusing notation in Equation 1 and the missing reference to Pedersen et al 2007 in the reference section. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims: one regarding the confusing notation in Equation 1 and another about the missing reference to Pedersen et al 2007 in the reference section. The first claim is straightforward and factual, as it points out a specific issue with the notation. The second claim is also factual, as it identifies a missing reference. Neither claim requires additional evidence or justification, making them verifiable. Therefore, the review point is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues: the confusing notation in Equation 1, where \"c\" is used instead of \"o,\" and the missing reference to Pedersen et al 2007 in the reference section. These are precise and actionable pieces of feedback that the authors can easily address to improve the clarity and accuracy of their paper. By correcting these issues, the authors can enhance the professionalism and reliability of their work. Therefore, the comment is mostly helpful, as it provides clear guidance for improvement, but could be more comprehensive by suggesting how to clarify the notation or offering additional references. Overall, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second contribution of the paper, combining SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. It suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. While the comment implies that the authors should address these similarities and differences, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to discuss and ablate the similarities but lack detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second contribution of the paper, the proposal to combine SSMs with Attention, and references specific works like MEGA and Block-state Transformer. It also points out the similarities between the architecture in Figure 5 and the proposed architecture in Mega, providing clear guidance on what needs to be discussed and ablated. This level of detail allows the authors to accurately identify the parts of the paper being addressed and what specific issues need to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second contribution of the paper, combining SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. The reviewer supports this claim by referencing specific works and providing a link to the Block-state Transformer paper. This detailed reference and comparison provide a robust basis for the claim, making it fully verifiable. The comment also suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated, which further strengthens the claim. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality of the paper\\'s second contribution, which involves combining SSMs with Attention. It points out that this approach has been proposed before in MEGA and Block-state Transformer, and suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This feedback is clear and actionable, as it directs the authors to address the novelty of their contribution and provides a specific direction for improvement by suggesting a comparison and ablation study. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable insights for enhancing the paper\\'s originality and clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the rationale behind reporting results on knowledge transfer in only a few select environments. While it implies that the authors should provide a justification for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to \"section 4.3,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not explain why the reporting of results on knowledge transfer in only a few select environments is a concern or what specific issues or improvements are needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point is a question asking for clarification about the reporting of results on knowledge transfer in only a few select environments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind reporting results on knowledge transfer in only a few select environments. While it identifies a potential area of concern, it does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with only a vague sense of what might be problematic. Therefore, it is barely helpful, as it points out a potential issue but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of specific ablation experiments and suggests that the performance improvement could be attributed to pre-trained weights rather than the method proposed in the manuscript. It also points out that the absence of detailed ablation comparisons may lead to confusion. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it, such as which ablation experiments should be conducted or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of specific ablation experiments and suggests that the performance improvement could be attributed to pre-trained weights rather than the method proposed in the manuscript. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment where ablation comparisons should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed\u2014specific ablation experiments to clarify the contribution of the proposed method. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of specific ablation experiments could lead to confusion about whether the performance improvement is due to pre-trained weights or the method proposed in the manuscript. While the comment identifies a potential issue, it does not provide specific examples or detailed reasoning to support the claim. The absence of concrete evidence or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but lacks sufficient justification or evidence to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of specific ablation experiments that could clarify whether the performance improvement is due to pre-trained weights or the method proposed in the manuscript. This is a critical point that could help the authors better understand and communicate the contribution of their work. However, the comment does not provide detailed guidance on how to conduct these ablation experiments or what specific comparisons should be made. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a major concern regarding the lemmatizer\\'s behavior in stripping suffixes from words that are already lemmas but end with a suffix substring. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their draft. The comment lacks actionable guidance, such as recommending ways to mitigate this issue or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation related to the lemmatizer\\'s behavior in stripping suffixes from words that are already lemmas but end with a suffix substring. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in detailing the concern about the lemmatizer\\'s behavior and its implications for real-world texts with evolving vocabularies. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point identifies a limitation in the lemmatizer\\'s behavior, specifically its tendency to strip suffixes from words that are already lemmas but end with a suffix substring. This claim is somewhat verifiable as it highlights a potential issue with the lemmatizer\\'s functionality. However, the comment lacks specific examples or references to support the claim, such as instances where this behavior occurs or its impact on real-world texts. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the lemmatizer\\'s behavior, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a critical observation that could impact the accuracy and applicability of the lemmatizer in real-world texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve their lemmatizer\\'s performance. While it highlights an important issue, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it points out a significant concern but does not offer a clear path for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison in Table 2, noting that using pre-trained DGCNN for semantic segmentation may not provide meaningful results. However, it does not offer any explicit or implicit suggestions for how the authors might address this issue or improve the comparison. The comment lacks actionable guidance, such as recommending alternative methods for comparison or suggesting ways to enhance the analysis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison in Table 2, noting that using pre-trained DGCNN for semantic segmentation may not provide meaningful results. The comment explains why the comparison is not meaningful and suggests that the segmentation of those methods with DGCNN is worse than the proposed method. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison of segmentation metrics in Table 2 is not meaningful because it involves pre-trained DGCNN, which may not provide a fair comparison. The reviewer provides a logical reasoning by stating that the comparison is essentially between the segmentation of other methods with DGCNN versus the proposed method. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison in Table 2, specifically noting that using pre-trained DGCNN for semantic segmentation may not provide meaningful results. It suggests that the comparison is essentially between the segmentation of other methods with DGCNN versus the proposed method, which may not be a fair comparison. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. While it highlights a potential weakness, it lacks actionable feedback that would help the authors make improvements to their draft. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a general observation about the difficulty of obtaining rules in real-world applications and suggests that statistical rules learned from data might be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors\\' work or what specific changes they should consider. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment makes a general observation about the difficulty of obtaining rules in real-world applications and suggests that statistical rules learned from data might be feasible. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on how this observation relates to the paper\\'s content or methodology. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a general observation about the difficulty of obtaining rules in real-world applications and suggests that statistical rules learned from data might be feasible. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or justification makes it difficult for the authors to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment makes a general observation about the difficulty of obtaining rules in real-world applications and suggests that statistical rules learned from data might be feasible. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular weaknesses or offering guidance on how the authors might address the issue, the comment does not assist the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison with dynamic sparse training-based and other sparsity-based methods. While the comment implies an action, it does not explicitly instruct the authors to make this comparison. Additionally, it lacks concrete details on how to implement this comparison or which specific methods to include. The action is implicit and somewhat vague, leaving the authors with a general idea of what to do but without specific guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a comparison with dynamic sparse training-based and other sparsity-based methods. However, it does not specify which part of the paper this comparison should be added to, making it weakly grounded. The comment is specific in suggesting a particular type of comparison that could be included, but without clear grounding, the authors may struggle to determine where to incorporate this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. The lack of supporting evidence or justification makes it difficult for the authors to understand the importance of this comparison or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from including a comparison with dynamic sparse training-based and other sparsity-based methods. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing additional context and comparison. However, the comment lacks depth and does not offer detailed guidance on how to incorporate these comparisons or why they are important. To be more helpful, the comment could suggest specific methods or aspects to focus on in the comparison. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the statement regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model, suggesting that the reasoning is flawed. It offers an alternative explanation and provides an example to illustrate the point. However, the comment does not explicitly instruct the authors to revise their statement or provide guidance on how to address the issue. The action is implicit, as the authors can infer that they need to reconsider or clarify their explanation, but it lacks concrete steps or suggestions for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly references a specific statement from the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the reasoning behind the statement and provides an alternative explanation, along with an example to illustrate the point. This level of detail helps the authors understand what needs to be addressed or clarified in their explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasoning behind the statement regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. The reviewer provides an alternative explanation and an example to support their claim, suggesting that the intractability of $p_\u03b8(y|x)$ may not be solely due to the intractability of $p_\u03b8(z|x)$. This reasoning is logical and provides a clear counter-argument, making the claim mostly verifiable. However, the comment could be strengthened by providing more examples or references to substantiate the point further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critical analysis of a specific statement in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It challenges the reasoning presented in the paper by offering an alternative explanation and providing an example to illustrate the point. This feedback is valuable as it prompts the authors to reconsider their explanation and potentially revise it to be more accurate and comprehensive. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided additional examples to further clarify the concept. Overall, the comment is mostly helpful as it identifies a potential weakness and provides some insight into the problem, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the collected datasets are inaccessible outside of the associated groups, making the work irreproducible. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the datasets more accessible or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the collected datasets are inaccessible outside of the associated groups, making the work irreproducible. However, it does not specify which part of the paper this issue pertains to, such as the methodology, results, or discussion sections. Without explicit references or detailed guidance, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the collected datasets are inaccessible outside of the associated groups, making the work irreproducible. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the reproducibility of the work due to the inaccessibility of the collected datasets outside of the associated groups. This is a critical concern that can hinder the validation and further exploration of the research findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as by making the datasets more accessible or providing alternative methods for verification. Without actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a potential missing equation before a specific statement in section 3.4.1. While it implies that the authors should check for a missing equation, it does not explicitly instruct them to do so or provide guidance on how to identify or address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should check for a missing equation and determine how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the presence of a missing equation before a specific statement, \"where p is the firing rate.\" This provides clear guidance on what needs to be checked or clarified in the manuscript. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about a potential missing equation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue in the manuscript by questioning the presence of a missing equation before a specific statement in section 3.4.1. This feedback is actionable as it prompts the authors to verify and potentially correct the manuscript to ensure clarity and accuracy. However, the comment could be more helpful if it provided additional context or suggested how to address the issue if the equation is indeed missing. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing attention, but it lacks depth and detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments to evaluate the sentiment word detection and correction aspects of SWRM, which are key ideas in the paper. It specifies that experiments should validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of sentiment word detection and correction, which are key ideas in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of sentiment word detection and correction is lacking, as these are key ideas in the SWRM framework. The reviewer implies that experiments should be conducted to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that these evaluations are necessary or how they would improve the paper. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these evaluations and how to implement them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of evaluation for sentiment word detection and correction, which are key ideas in the SWRM framework. It suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work by addressing a critical aspect of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to design these experiments or what metrics to use for evaluation. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the results reported in the tables, specifically questioning the absence of results for KMLM-XLM-R_{large}(ours). It implies that the authors should include these results and provide a logical explanation for why they were not reported. While the comment clearly identifies an issue and suggests that the authors should address it, it does not provide specific guidance on how to present the missing results or what kind of logical reasoning should be provided. The action is explicit but somewhat vague, as the authors know they need to include the results but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the absence of results for KMLM-XLM-R_{large}(ours) and suggesting that the authors did not report all the performance of KMLM-large without logical reasoning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of results for KMLM-XLM-R_{large}(ours) in the result tables, suggesting that the authors did not report all the performance of KMLM-large without logical reasoning. However, the comment does not provide specific examples or detailed reasoning to support why this omission is problematic or how it affects the understanding of the results. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors have not reported the results for KMLM-XLM-R_{large}(ours) in the result tables. This is a clear and actionable piece of feedback, as it highlights a gap in the reporting of results that the authors can address to improve the completeness and transparency of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present these results or why they are important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern regarding the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that this could be due to the large variance of the results or the uncareful design of the baselines. The reviewer explicitly requests more explanations to support the reliability of the claims. While the comment clearly states the need for additional explanations, it does not provide specific guidance on how to address the issue or what aspects of the baselines should be examined. The action is explicit but somewhat vague in terms of execution, as the authors know they need more explanations but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that this could be due to the large variance of the results or the uncareful design of the baselines. The comment implies that more explanations are needed to support the reliability of the claims. However, it does not specify which part of the paper discusses these baselines or where additional explanations should be provided. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for more explanations. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items. It suggests that this could be due to the large variance of the results or the uncareful design of the baselines. The comment requests more explanations to support the reliability of the claims. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for more explanations is logical, but the absence of concrete evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that this could be due to the large variance of the results or the uncareful design of the baselines. The comment requests more explanations to support the reliability of the claims, which is a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it provided specific guidance on how to investigate or address the issue, such as suggesting particular aspects of the baselines to examine or methods to reduce variance. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies an issue with the clarity of the key innovation in the paper, specifically regarding the claim that GFNSeqEditor can produce novel sequences with improved properties. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, which would enhance the reader\\'s understanding of the method\\'s unique value. While the comment clearly states the need for clarification, it does not provide specific guidance on how to achieve this or what aspects of the paper should be revised. The action is explicit but somewhat vague, as the authors know they need to clarify the innovation but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ambiguity in the key innovation of GFNSeqEditor, specifically regarding the claim that it can produce novel sequences with improved properties. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements. However, the comment does not specify which part of the paper lacks clarity or where the key innovation is discussed, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the key innovation is discussed, the comment lacks full grounding. It is specific about the need for clarification but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ambiguity in the key innovation of GFNSeqEditor, specifically regarding the claim that it can produce novel sequences with improved properties. The reviewer suggests that the paper should better articulate what novel techniques or insights lead to these improvements. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim of ambiguity. The authors would need to infer the exact areas that require clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the key innovation in the paper, specifically regarding the claim that GFNSeqEditor can produce novel sequences with improved properties. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, which would enhance the reader\\'s understanding of the method\\'s unique value. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of their innovation, which is crucial for the paper\\'s impact and reader comprehension. However, the comment could be more helpful if it offered specific suggestions on how to articulate these innovations or examples of what aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment to show that their method is less susceptible to biases compared to other methods. While the comment implies a clear action\u2014conducting an experiment\u2014it does not provide specific guidance on how to design or execute this experiment. The authors are left to infer the necessary steps without detailed instructions. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment to show that their method is less susceptible to biases compared to other methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in suggesting a demonstration of faithfulness through an experiment, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment to show that their method is less susceptible to biases compared to other methods. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors demonstrate the faithfulness of their proposed approach through a simple experiment. It challenges the claim that the method is less susceptible to biases compared to others, providing a clear and actionable suggestion for the authors to substantiate their claims with empirical evidence. This feedback is valuable as it directs the authors to a concrete step that can enhance the credibility and robustness of their work. However, the comment could be more helpful if it offered additional guidance on how to design the experiment or what specific biases to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is limited to operating with state-action spaces, which may not be suitable for real-world applications that are typically continuous. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their motivation. The comment lacks actionable guidance, such as recommending ways to adapt the method for continuous applications or suggesting alternative motivations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the manuscript, namely the limitation of the proposed method to operate with state-action spaces, which may not be suitable for real-world applications that are typically continuous. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the motivation provided, but without clear grounding, the authors may struggle to pinpoint where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is limited to operating with state-action spaces, which may not be suitable for real-world applications that are typically continuous. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the manuscript, specifically that the proposed method is restricted to operating with state-action spaces, which may not be suitable for real-world applications that are typically continuous. This feedback highlights a potential weakness in the motivation or applicability of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the motivation for their method. While it points out an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the lack of competitiveness of the experiment results compared to state-of-the-art (SOTA) methods and the unclear presentation of results in Table 1. It suggests that the baseline should be moved to the ablation study and that only the proposed method should be shown. While the comment provides explicit actions, such as moving the baseline and clarifying the presentation of results, it lacks concrete guidance on how to improve the competitiveness of the results or what specific aspects of the presentation need clarification. The actions are explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the competitiveness of the experiment results compared to state-of-the-art methods and the presentation of results in Table 1. It suggests moving the baseline to the ablation study and showing only the proposed method. While the comment does not explicitly mention specific sections or tables, the authors can infer that it relates to the results and discussion sections. The comment is specific in detailing what needs to be addressed regarding the presentation of results and the comparison to baselines. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment results are not competitive with state-of-the-art (SOTA) methods and that the presentation of results in Table 1 is unclear. It suggests moving the baseline to the ablation study and showing only the proposed method. However, the comment lacks specific examples or detailed reasoning to support the claim about the lack of competitiveness or the unclear presentation. Without concrete evidence or references to SOTA methods or specific issues with Table 1, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two main issues: the lack of competitiveness of the experiment results compared to state-of-the-art (SOTA) methods and the unclear presentation of results in Table 1. It suggests moving the baseline to the ablation study and showing only the proposed method. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to enhance the competitiveness of the results or improve the clarity of Table 1. The feedback is somewhat helpful as it points out weaknesses and provides a general direction for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to achieve this clarification. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the manuscript. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to clarify the copyright scenario, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the manuscript. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the manuscript, namely the need for a clearer delineation of the copyright scenario. It suggests that the authors should specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to address this issue. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending specific analyses, experiments, or theoretical frameworks that could be used to provide the necessary justification. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the theoretical justification and intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014namely, a theoretical justification or intuitive explanation for the observed behavior. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. This is a critical observation that could impact the understanding and interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what theoretical frameworks or methodologies could be used to provide the necessary justification. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statement regarding local explanations, specifically questioning why it is true that local models will only be nontrivial if the data point is near a decision boundary. The reviewer suggests an alternative approach, such as measuring differences in probabilities, to address this issue. While the comment implies that the authors should provide a justification or alternative explanation for their statement, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the question or improve the explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the statement about local models and suggests an alternative approach to measuring differences in probabilities. This provides clear guidance on what aspect of the explanation is being questioned and how it could be improved. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification and an alternative suggestion. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the statement regarding local explanations, specifically questioning why local models will only be nontrivial if the data point is near a decision boundary. It suggests an alternative approach, such as measuring differences in probabilities, to address this issue. This feedback is clear and actionable, as it prompts the authors to provide a justification or alternative explanation for their statement. By challenging the authors to consider an alternative perspective, the comment encourages them to refine their explanation and potentially enhance the clarity and depth of their analysis. However, the comment could be more helpful if it offered specific suggestions or examples of how to implement the alternative approach. Overall, the comment is mostly helpful, as it provides valuable insights and prompts for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only report results on ImageNet and suggests that results on classic datasets like CIFAR-10 and CIFAR-100 should also be included. This feedback provides a clear and explicit action for the authors to take, which is to expand their experimental results to include these additional datasets. The suggestion is concrete, as it specifies exactly what additional data should be included to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments and the datasets (ImageNet, CIFAR-10, and CIFAR-100) being discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014results on classic datasets like CIFAR-10 and CIFAR-100. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet and suggests that results on classic datasets like CIFAR-10 and CIFAR-100 should also be included. This claim is somewhat verifiable as it highlights a gap in the experimental coverage, which is a common expectation in research. However, the comment lacks specific reasoning or references to why including results on these datasets would be beneficial or necessary. Providing more context or justification for why these datasets are important would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental section of the paper, noting that the results are only reported on ImageNet and suggesting that results on classic datasets like CIFAR-10 and CIFAR-100 should also be included. This feedback is clear and actionable, as it provides a direct suggestion for expanding the experimental scope, which could enhance the comprehensiveness and generalizability of the results. However, the comment could be more helpful if it explained why including results on these additional datasets would be beneficial or how it might impact the conclusions drawn from the experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the presentation of the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown despite being mentioned in the text description. The reviewer contrasts this with the clarity of the figure in the original DinoSR paper. While the comment highlights a problem, it does not provide explicit guidance on how to address it, such as suggesting ways to clarify the figure or the text description. The action is implicit and somewhat vague, as the authors need to infer that they should improve the clarity of the figure and text description. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and the \"DinoSR part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is the confusion caused by the absence of the softmax layer in the figure, despite its inclusion in the text description. The comment further contrasts this with the clarity of the figure in the original DinoSR paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite being mentioned in the text description. The reviewer contrasts this with the clarity of the figure in the original DinoSR paper. This claim is somewhat verifiable as it provides a logical reasoning that the figure should match the text description, and it references the clarity of the original DinoSR paper. However, the comment could be strengthened by providing more detailed examples or specific elements that are unclear in the current figure. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 1, noting that the softmax layer is not clearly shown despite being mentioned in the text description. It contrasts this with the clarity of the figure in the original DinoSR paper, providing a clear and actionable suggestion for improvement. By highlighting this discrepancy, the comment offers the authors a concrete way to enhance the clarity and consistency of their presentation, which is valuable for improving the overall quality of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific changes to the figure. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should review more related work on causal inference and specifically mentions that works [1], [2], and [3] should be discussed. While the comment explicitly states that additional related work should be reviewed, it does not provide specific guidance on how to integrate these references into the paper or what aspects of these works are particularly relevant. The action is explicit but somewhat vague in terms of execution, as the authors know they need to review more related work but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reviewing more related work on causal inference and mentions specific references ([1], [2], and [3]). However, it does not specify where in the paper these references should be integrated or how they relate to the current work. The authors can infer that this relates to the literature review or discussion sections, but the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the need for additional related work but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more related work on causal inference should be reviewed, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any justification or reasoning for why these specific works are relevant or how they relate to the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of these references or how they should be integrated into the paper. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should review more related work on causal inference, specifically mentioning references [1], [2], and [3]. While it identifies a potential gap in the literature review, the comment lacks specificity and does not provide detailed guidance on how these references should be integrated or what aspects of the current work they relate to. Without further elaboration, the authors may find it challenging to understand the relevance of these references and how to effectively incorporate them into their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that sections 3.1 and 3.2 could have been avoided if the authors had used the LLM2Vec encoder, which is already cited in the paper. It implies that the authors should provide a justification for not adopting this approach and suggests conducting ablation studies to validate the decision. While the comment provides a clear action (to conduct ablation studies), it does not specify how to implement these studies or what specific aspects should be tested. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the reasoning for not adopting the LLM2Vec encoder and the need for validation through ablation studies. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that sections 3.1 and 3.2 could have been avoided if the authors had used the LLM2Vec encoder, which is already cited in the paper. The reviewer suggests that the reasoning for not adopting this approach remains unclear and recommends validating the decision with ablation studies. While the comment provides a logical suggestion for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact issues with the current approach and how ablation studies could address them. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration for full clarity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically questioning the necessity of sections 3.1 and 3.2 given the availability of the LLM2Vec encoder, which is already cited in the paper. It suggests that the authors should provide a clearer rationale for not adopting this approach and recommends conducting ablation studies to validate their decision. This feedback is clear and actionable, as it guides the authors to address a specific concern and provides a method for doing so. However, it could be more helpful if it offered additional guidance on how to conduct the ablation studies or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experimental setup, noting that only synthetic objective functions are used for comparing the proposed Batch BORE method with existing baselines, and there are no real-world problems included. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their experimental design. The comment lacks actionable guidance, such as recommending the inclusion of real-world problems or suggesting ways to incorporate them into the experiments. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments that compare the proposed Batch BORE method with existing baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that only synthetic objective functions are used, indicating a lack of real-world problems in the experiments. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only use synthetic objective functions and lack real-world problems. However, it does not provide any supporting evidence, reasoning, or references to justify why the inclusion of real-world problems is necessary or beneficial. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that only synthetic objective functions are used for comparing the proposed Batch BORE method with existing baselines. This is a relevant point that could impact the generalizability and applicability of the findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of real-world problems or suggesting ways to incorporate them into the experiments. While it highlights an area for improvement, the feedback is not actionable or detailed enough to be fully helpful. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a challenge in distinguishing roles using explanation-focused cues, suggesting that LLMs may rely more on language style than on informational depth. It implies that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify these findings. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer the need for a detailed analysis and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the challenge of distinguishing roles using explanation-focused cues and suggests that LLMs may rely more on language style than on informational depth. It proposes a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, the comment does not specify which part of the paper this analysis should be applied to, making it weakly grounded. The suggestion is specific in terms of what kind of analysis could be conducted, but without clear grounding, the authors may struggle to identify where to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging because LLMs may rely more on language style than on informational depth. The reviewer suggests that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify these findings. While the comment provides a logical reasoning for the challenge, it lacks specific examples or references to support the claim. The suggestion for a detailed analysis is a helpful direction, but the absence of concrete evidence or references makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific challenge in the paper regarding the difficulty of distinguishing roles using explanation-focused cues, suggesting that LLMs may rely more on language style than on informational depth. It proposes a detailed analysis of benchmark sentence differences between explanation and listener-focused parts as a way to clarify these findings. This feedback is clear and actionable, providing a concrete suggestion for further analysis that could enhance the understanding and interpretation of the results. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights an issue with the heavy use of acronyms, specifically mentioning that the acronym \"DU\" is used without a clear definition. This feedback provides an explicit action for the authors to take, which is to define the acronym \"DU\" to improve readability. However, the comment does not provide specific guidance on how to define it or where it should be included in the text. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights an issue with the use of acronyms, specifically mentioning the acronym \"DU\" as an example. This provides a specific issue that the authors need to address. However, the comment does not explicitly mention which part of the paper this issue occurs in, such as a specific section or paragraph where the acronym \"DU\" is used. The authors can infer that it relates to sections where acronyms are used, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the issue with the acronym \"DU.\" This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s heavy use of acronyms affects readability, specifically mentioning the acronym \"DU\" as an example. However, the comment does not provide any supporting evidence or reasoning to justify why the use of acronyms is problematic or how it impacts readability. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper\\'s readability due to the heavy use of acronyms, particularly mentioning the acronym \"DU\" as an example. This feedback is clear and actionable, as it directs the authors to address the lack of clarity by defining the acronym \"DU\" or considering alternative ways to improve readability. However, the comment could be more helpful if it provided additional suggestions on how to manage acronyms effectively or offered examples of best practices. Despite this, the feedback is mostly helpful as it highlights a concrete area for improvement and provides a specific action for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the assumptions and estimation methods related to the variance of the distribution p(q|s) in section 2.3. It explicitly asks how the variance is estimated and whether it is determined using the sample variance of the quality values in the training data. Additionally, it inquires about the assumption of a diagonal covariance matrix and whether this is a reasonable assumption for the problem. While the comment does not directly instruct the authors to make specific changes, it provides clear and concrete questions that the authors can address to improve their draft. The action is implicit but concrete, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises detailed questions about the assumptions and estimation methods related to the variance of the distribution p(q|s), including whether the sample variance of the quality values in the training data is used and whether a diagonal covariance matrix is assumed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the assumptions and estimation methods related to the variance of the distribution p(q|s) in section 2.3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the assumptions and estimation methods related to the variance of the distribution p(q|s) in section 2.3. It seeks clarification on how the variance is estimated, whether it is determined using the sample variance of the quality values in the training data, and whether a diagonal covariance matrix is assumed. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their methodology, which could enhance the clarity and rigor of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or improve the explanation in the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit suggestions for how the authors should address this observation or investigate the reason behind it. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to improve their draft. Since the comment is vague and does not offer a path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further exploration or explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. While it identifies an interesting observation, it does not provide any suggestions or guidance on how the authors might investigate or address this issue. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of the problem. Therefore, it is barely helpful, as it points out an area of interest but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using other datasets in addition to MuAViC to explore the generalization of their proposed method. While the action is implied, it is clear and concrete, as it specifies the need to include additional datasets for a broader evaluation. The authors can infer that they should expand their dataset analysis to include other sources, providing a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should consider using other datasets in addition to MuAViC to explore the generalization of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or discussion sections, but this inference is not direct. The comment is specific in suggesting the need for additional datasets, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should consider using other datasets to explore the generalization of the proposed method. However, it does not provide specific examples of other datasets or detailed reasoning to support why this exploration is necessary. The comment lacks explicit evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is borderline verifiable, as it provides a general suggestion without sufficient justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper should consider using additional datasets beyond MuAViC to explore the generalization of the proposed method. This feedback is clear and actionable, as it provides a specific direction for expanding the evaluation of the method to include other datasets. By doing so, the authors can demonstrate the robustness and applicability of their approach across diverse data sources. However, the comment could be more helpful if it provided examples of other datasets that might be relevant or discussed the potential benefits of such an expansion. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the expectation that the systems investigated in the paper might not be Bayes-optimal, suggesting that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer implies that the current analysis is mostly confirmatory and lacks the necessary experiments to test the hypothesis. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific experiments should be conducted to test the hypothesis. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expectation that the systems investigated in the paper might not be Bayes-optimal, suggesting that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. The authors might infer that it relates to the introduction or the methodology sections, but this inference is not direct. The comment is specific in its critique of the need for alternative hypotheses and discriminatory experiments but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expectation that the systems investigated in the paper might not be Bayes-optimal, suggesting that more work is needed to establish alternative hypotheses and gear the analyses towards ruling them out. The comment implies that the current analysis is mostly confirmatory and lacks experiments to test the hypothesis. However, it does not provide specific examples, references, or detailed reasoning to support the claim that the systems are not Bayes-optimal or to justify the need for alternative hypotheses. This lack of detailed justification makes the claim somewhat verifiable, as it requires the authors to infer the necessary steps to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the expectation that the systems investigated in the paper might not be Bayes-optimal, suggesting that more work is needed to establish alternative hypotheses and gear the analyses towards ruling them out. It points out that the current analysis is mostly confirmatory and lacks experiments to test the hypothesis. The comment provides a clear direction for improvement by suggesting that the authors should lay out alternative hypotheses and design experiments to discriminate between them. This feedback is actionable and constructive, offering a specific area for the authors to focus on to enhance the rigor and impact of their work. However, it could be more helpful if it included specific examples or guidance on how to implement these suggestions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to add confidence intervals to Table 1, which provides results for the performance of different fairness improvement techniques. This direct request leaves no ambiguity about what action the authors should take to improve their draft. The suggestion is clear and concrete, providing specific guidance on how to enhance the table\\'s interpretability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being too close, making it difficult to draw conclusions, and suggests adding confidence intervals to improve the analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported values in Table 1 are very close, making it difficult to draw conclusions. The reviewer suggests adding confidence intervals to improve the analysis. While the comment identifies a potential issue with the data presentation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to add confidence intervals is logical, but the comment could be strengthened with more detailed justification or examples. Therefore, the claim is somewhat verifiable, as it provides a reasonable suggestion but requires additional context for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are very close, making it difficult to draw meaningful conclusions. It suggests adding confidence intervals to improve the analysis, which is a clear and actionable recommendation. This feedback is valuable as it provides a concrete step for the authors to enhance the interpretability and usefulness of their results. However, the comment could be more helpful if it provided additional context or examples of how confidence intervals might be applied or interpreted in this context. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some choices are not justified or unclear, but it does not specify which choices or provide any guidance on how to address these issues. The comment is vague and lacks explicit instructions or concrete details, leaving the authors without a clear understanding of what needs to be done to improve their draft. Without specific examples or suggestions, the authors may struggle to determine which choices are problematic and how to rectify them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some choices are not justified or unclear, but it does not specify which choices or parts of the paper are being referred to. Additionally, it does not provide any details or examples of what is unclear or unjustified, making it difficult for the authors to identify and address the issues. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some choices are not justified/not clear\" but does not provide any specific examples or reasoning to support this claim. It also lacks any references or detailed explanation that would help the authors understand which choices are problematic or how they could be improved. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that some choices in the paper are not justified or unclear, but it does not specify which choices or provide any guidance on how to address these issues. Without identifying specific areas or offering suggestions for improvement, the comment lacks actionable feedback that could help the authors enhance their draft. As a result, it is not helpful at all, as it does not provide the authors with any direction for improvement. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the hyperparameter tuning process, specifically regarding the polarization regularizer compared to the L1 regularizer. It highlights the difficulty in navigating the tuning process due to the presence of two hyperparameters that affect both FLOPs and accuracy. The reviewer suggests that the authors provide a detailed discussion on this issue for reproducibility. While the comment implies that the authors should include a detailed discussion on hyperparameter tuning, it does not explicitly instruct them to do so. The action is somewhat clear but lacks concrete guidance on how to implement the suggested discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the issue of hyperparameter tuning, specifically regarding the polarization regularizer compared to the L1 regularizer. It highlights the difficulty in navigating the tuning process due to the presence of two hyperparameters that affect both FLOPs and accuracy. The comment also suggests that the authors provide a detailed discussion on this issue for reproducibility. This level of detail and specificity allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the hyperparameter tuning process, specifically regarding the polarization regularizer compared to the L1 regularizer. It highlights the difficulty in navigating the tuning process due to the presence of two hyperparameters that affect both FLOPs and accuracy. The comment suggests that the authors provide a detailed discussion on this issue for reproducibility. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the difficulty of tuning. The suggestion for a detailed discussion is a reasonable request, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the hyperparameter tuning process, specifically regarding the polarization regularizer compared to the L1 regularizer. It highlights the difficulty in navigating the tuning process due to the presence of two hyperparameters that affect both FLOPs and accuracy. The reviewer suggests that the authors provide a detailed discussion on this issue for reproducibility, which is a valuable suggestion. However, the comment could be more helpful by offering specific guidance on how to address the tuning challenge or suggesting alternative approaches. While it identifies an important area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing element in Figure 1, specifically the accuracies of the target model using different defenses against the FGSM attack. This implies that the authors should include this information in the figure to clarify the differences between known and unknown attacks. The action is explicit but lacks concrete details on how to present the accuracies or what specific data should be included. While the authors can infer the action, the comment does not provide detailed guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the accuracies of the target model using different defenses against the FGSM attack. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear the difference between known and unknown attacks. This claim is somewhat verifiable as it highlights a specific omission in the figure, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of this omission and how it impacts the understanding of the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1. This omission makes it unclear the difference between known and unknown attacks. The comment highlights a clear area for improvement by suggesting that the authors include this information in their figure to enhance the clarity and comprehensiveness of their results. While the feedback is actionable and points out a specific gap, it could be more helpful if it provided additional guidance on how to present this information effectively. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with further suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider using a log-scale for the y-axis in some figures to improve readability. This is a clear and direct action, providing the authors with a specific recommendation on how to enhance the presentation of their figures. The suggestion is concrete, as it specifies exactly what change should be made to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests using a log-scale for the y-axis to improve readability, providing a clear and actionable recommendation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some figures are hard to read and recommends using a log-scale for the y-axis. However, it does not provide specific examples or detailed reasoning to support why the current figures are difficult to read or how a log-scale would improve readability. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and benefits of the suggested change. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of some figures, suggesting that the authors consider using a log-scale for the y-axis. This feedback is clear and actionable, providing a concrete suggestion that can help improve the presentation of the figures. By addressing this point, the authors can enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided examples of where the log-scale might be beneficial or explained why it would improve readability. Overall, the comment is mostly helpful as it offers a specific recommendation for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the validation of the proposed method, specifically noting that the claims about the usefulness of augmentation information for flowers and birds were not substantiated with experiments using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address this issue or suggest specific experiments to conduct. The action is implicit and somewhat vague, as the authors need to infer that they should include experiments with these datasets to validate their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the claims about the usefulness of augmentation information for flowers and birds were not validated in the experiments. The comment suggests using specific fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method, motivated by the usefulness of augmentation information for flowers and birds, was not validated in the experiment. The reviewer suggests using specific fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. This claim is mostly verifiable as it provides a logical reasoning for the need to validate the claims with specific datasets. However, it lacks detailed examples or references to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the validation of the proposed method, specifically pointing out that the claims about the usefulness of augmentation information for flowers and birds were not substantiated by experiments. It suggests using specific fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. This feedback is clear and actionable, providing the authors with a concrete direction to improve their draft by conducting experiments with relevant datasets. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the theoretical claims and empirical evidence presented in the paper. It highlights that while the paper states that opponents will evolve toward the Nash equilibrium, there are no theoretical analyses and the empirical evaluations do not clearly demonstrate convergence to the Nash equilibrium. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the theoretical and empirical analyses. The feedback lacks concrete steps or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific statement from the paper, \"Over time, those opponents will evolve toward the Nash equilibrium,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of theoretical analyses and unclear empirical evaluations regarding the convergence to Nash equilibrium. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that \"Over time, those opponents will evolve toward the Nash equilibrium\" by pointing out the lack of theoretical analyses and unclear empirical evaluations supporting this assertion. The comment highlights a gap in the paper\\'s justification, which is a valid concern. However, it does not provide specific examples or references to support the claim that the empirical evaluations are insufficient. This makes the claim somewhat verifiable, as it identifies a potential issue but lacks detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that while it claims that opponents will evolve toward the Nash equilibrium, there are no theoretical analyses and the empirical evaluations do not clearly demonstrate convergence to the Nash equilibrium. This feedback highlights a critical gap in the paper that needs to be addressed to strengthen the theoretical and empirical foundations of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing additional analyses or experiments. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with Equation (1), questioning its clarity and suggesting potential misunderstandings. It raises questions about the purpose of the equation, the definition of the optimization variable, and the unusual notation used for constraints. While the comment highlights areas of confusion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the purpose, variable definition, and notation, but without detailed guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks specific instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the equation, such as the unclear purpose, the definition of the optimization variable, and the unusual notation for constraints. Each point is clearly articulated, providing the authors with clear guidance on what needs to be clarified or revised. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of Equation (1), specifically questioning its purpose, the definition of the optimization variable, and the unusual notation for constraints. While the comment identifies specific areas of confusion, it does not provide detailed reasoning or examples to support these claims. The lack of explicit evidence or references makes it somewhat challenging for the authors to fully understand and address the issues raised. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some insight but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with Equation (1), questioning its clarity and purpose. It raises concerns about whether the equation defines a loss function or an optimization problem, and it points out potential misunderstandings regarding the definition of the optimization variable and the unusual notation for constraints. This feedback is clear and actionable, as it provides the authors with specific areas to clarify and revise in their draft. By addressing these points, the authors can improve the clarity and precision of their mathematical presentation. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of clearer notation. Overall, the comment is mostly helpful, as it effectively directs the authors toward improving the clarity of their mathematical content.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide more discussions or explanations regarding the observation that including the collected LIV-EN parallel data for finetuning makes the NMT system perform worse. This direct request provides a clear action for the authors to take, which is to elaborate on this observation. However, while the action is explicit, it lacks concrete guidance on how to conduct the additional discussions or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the strange observation that including the collected LIV-EN parallel data for finetuning makes the NMT system perform worse and requests more discussions or explanations on this. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim that including the collected LIV-EN parallel data for finetuning makes the NMT system perform worse. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific observation in the paper regarding the performance of the NMT system when including the collected LIV-EN parallel data for finetuning. It points out that this inclusion actually makes the system perform worse, which is a surprising result. The comment requests more discussions or explanations on this phenomenon, which is a clear and actionable suggestion for the authors to address. By prompting the authors to provide additional insights into this observation, the comment helps direct the authors toward a meaningful enhancement of their draft. However, it could be more helpful if it offered specific questions or guidance on how to approach this discussion. Overall, the comment is mostly helpful as it highlights an important area for further exploration and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper includes unsubstantiated conjectures about fine-tuning as exposure of existing capabilities in LMs, but it does not provide any reasoning or references to support these claims. The comment highlights a lack of clarity and substantiation in the paper, but it does not offer specific guidance on how the authors can address this issue or improve their draft. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of unsubstantiated conjectures regarding \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not specify which part of the paper these conjectures are found in, making it weakly grounded. The comment does specify the issue of lacking reasoning or references, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper includes unsubstantiated conjectures about fine-tuning as exposure of existing capabilities in LMs. However, it does not provide any specific examples or references to support this claim, nor does it offer reasoning or evidence to substantiate why these conjectures are unsubstantiated. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue, rendering the comment unverifiable. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the presence of unsubstantiated conjectures regarding \"fine-tuning as exposure of existing capabilities in LMs.\" It highlights the lack of reasoning or references to support these claims, which makes it difficult for readers to understand and evaluate the assertions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their arguments. While it points out a critical area for improvement, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when considering the use of FACodec. This is an explicit suggestion, as it directly instructs the authors to add a specific baseline for comparison. However, it does not provide detailed guidance on how to implement this suggestion or why NaturalSpeech 3 would be beneficial. While the action is clear, the lack of detailed instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when considering the use of FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where FACodec is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a particular baseline to include, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when considering the use of FACodec. However, it does not provide any justification or reasoning for why NaturalSpeech 3 would be beneficial or how it compares to other baselines. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when considering the use of FACodec. This feedback is somewhat helpful as it provides a specific suggestion for improving the experimental setup by adding a relevant baseline. However, the comment lacks depth and does not explain why NaturalSpeech 3 would be beneficial or how it compares to other baselines. Additionally, it does not provide guidance on how to integrate this baseline into the existing framework or what specific aspects should be considered. While the suggestion is actionable, the lack of detailed explanation or context limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experiments, suggesting that if the proposed method uses only the first 4 weeks of data for inference, other methods should also use them for training. This implies that the experiments are not fair under the current setting. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to ensure fairness. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the experimental setup to address the fairness concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the fairness of the experiments, particularly regarding the use of data for inference and training. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of fairness and suggests that the experiments should be adjusted to ensure fairness. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experiments, suggesting that if the proposed method uses only the first 4 weeks of data for inference, other methods should also use them for training. This claim is somewhat verifiable as it logically points out an issue with the experimental setup. However, it lacks specific examples or references to support the assertion that the current setting is unfair. The comment also includes a request for clarification, which does not contribute to the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically noting that if the proposed method uses only the first 4 weeks of data for inference, other methods should also use them for training. This feedback highlights a potential issue with the experimental design, which is important for ensuring a fair comparison among methods. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of the experiments. While it identifies a relevant point, the feedback could be more helpful if it provided actionable advice or examples. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity categories. This is a clear and direct action, providing specific guidance on what additional data should be included in the paper. The authors know exactly what needs to be done to address this feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity categories. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these results should be included. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing what additional information should be reported, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity categories. However, it does not provide any justification or reasoning for why this comparison is necessary or how it would enhance the paper. The comment lacks supporting evidence or explanation, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending that the authors report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity categories. This feedback is clear and directly guides the authors on how to enhance their experimental analysis, which could significantly strengthen the paper. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it offers a concrete step for improvement, but it could be more comprehensive with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the extent to which sequential bias affects VisDial results. While it highlights an area of potential concern, it does not provide explicit guidance or suggestions for the authors to address this issue. The question implies that the authors should investigate or discuss the impact of sequential bias, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which sequential bias affects VisDial results. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the sequential bias should be considered or how it might impact the results. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of sequential bias on VisDial results. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the extent to which sequential bias affects VisDial results. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or investigate it further. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential area of interest but does not provide enough direction for the authors to act upon it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between the experimental results and the stated goal of the LTAP method, specifically regarding parameter protection for tail classes. However, it does not provide any explicit or implicit suggestions for how the authors might address this contradiction or improve their draft. There is no guidance on potential modifications, additional experiments, or analyses that could be conducted to resolve the issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results on the ImageNet-LT dataset\" and compares LTAP with ATO and RReg, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the experimental results and the stated goal of strengthening parameter protection for tail classes in LTAP. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims a contradiction between the experimental results and the stated goal of the LTAP method, specifically regarding parameter protection for tail classes. The comment provides a specific observation from the experimental results, which is a direct comparison of performance improvements for head and tail classes. This comparison is based on factual data from the experiments, providing a solid foundation for the claim. However, the comment could be strengthened by referencing specific sections of the paper where these results are discussed or by providing additional context or reasoning to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the experimental results and the stated goal of the LTAP method. It points out that while LTAP achieves a larger performance improvement for head classes compared to ATO and RReg, it seems to contradict the goal of strengthening parameter protection for tail classes. This feedback is valuable as it highlights a critical issue that the authors need to address to ensure the consistency and validity of their claims. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this contradiction or improve their methodology. While it offers insight into a potential weakness, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It suggests that this dependency on LLMs for evaluation may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the reliability of the evaluation process. The feedback lacks actionable details, such as recommending alternative evaluation methods or providing specific steps to mitigate potential biases. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It raises concerns about potential biases or inconsistencies in the quality assessment of generated documentations due to the dependency on LLMs. However, the comment does not specify which part of the paper discusses the reward computation or LLM-based evaluation, making it weakly grounded. The authors might infer that it relates to sections discussing evaluation or methodology, but this inference is not direct. The comment is specific in detailing the potential issue with LLM-based evaluation but lacks grounding in terms of pinpointing the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It suggests that this dependency on LLMs for evaluation may introduce biases or inconsistencies in the quality assessment of generated documentations. The claim is somewhat verifiable as it provides a logical reasoning about the potential issues with LLM-based evaluation, but it lacks specific examples or references to substantiate the claim further. The authors would need to explore this issue more deeply to fully understand and address the concern, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It raises concerns about the introduction of biases or inconsistencies in the quality assessment of generated documentations due to the dependency on LLMs. This feedback is valuable as it highlights a critical aspect of the methodology that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or mitigate the potential biases. While it points out an important area for consideration, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more empirical examples and compare their results to state-of-the-art (SOTA) performance from referenced papers. However, it does not specify which empirical examples should be included or how to effectively compare the results. The comment is explicit in its request for additional empirical evidence and comparison but lacks concrete guidance on how to implement these actions. As a result, the authors know they need to add more empirical examples and comparisons but may struggle with the specifics of how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more empirical examples and compare their results to state-of-the-art (SOTA) performance from referenced papers. It mentions \"Eq 12,\" which provides some grounding by indicating a specific equation in the paper. However, the comment does not specify which part of the paper lacks clarity or how the empirical examples should be integrated, making it under-specific. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the process described in the paper is surprisingly effective but lacks clarity, specifically mentioning Equation 12. However, the comment does not provide any specific reasoning or examples to support why the process is unclear or how it could be improved. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding Equation 12, which is described as being unclear. It suggests that the authors should provide more empirical examples and compare their results to state-of-the-art (SOTA) performance from referenced papers. While the comment highlights an area for improvement, it lacks detailed guidance or specific suggestions on how to enhance the clarity or what kind of empirical examples should be included. This limits the comment\\'s helpfulness, as it provides a general direction but not actionable steps for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically questioning why the problem is challenging given Assumption 1. It provides a detailed explanation of the assumption and its implications, suggesting that the problem might not be as difficult as claimed. However, the comment does not offer any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might clarify or revise their assumptions or analysis to better demonstrate the difficulty of the problem. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the difficulty of the problem and refers to Assumption 1, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it provides a detailed explanation of the assumption and its implications, including the reduction in the number of samples after removal and the conditions for accurate recovery. This level of detail helps the authors understand what needs to be addressed regarding the difficulty of the problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically questioning the validity of Assumption 1. The reviewer provides a detailed explanation of the assumption and its implications, suggesting that the problem might not be as challenging as claimed. This explanation is supported by logical reasoning and a clear explanation of the mathematical conditions involved, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or examples where similar assumptions have been tested, which would provide a more robust foundation for the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a significant concern about the difficulty of the problem, specifically questioning the validity of Assumption 1. It provides a detailed explanation of the assumption and its implications, suggesting that the problem might not be as challenging as claimed. This feedback is valuable as it prompts the authors to reconsider their assumptions and potentially revise their claims about the difficulty of the problem. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided alternative assumptions that might better reflect the complexity of the problem. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between Figure 1 and the last two columns of Table 1, specifically regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, it does not provide any explicit or implicit suggestions for how the authors should address this contradiction or improve their draft. The comment lacks actionable guidance, such as recommending a revision of the figure, table, or explanation to resolve the contradiction. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the last two columns of Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the contradiction between the illustration in Figure 1 and the comparison in the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 contradicts the comparison in the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, the comment does not provide any further explanation or reasoning to support this claim, such as specific details from the figure or table that contradict each other. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific contradiction between Figure 1 and the last two columns of Table 1, which is a valuable observation for the authors to address. However, the comment does not provide any guidance or suggestions on how to resolve this contradiction or clarify the relationship between NNGS and the number of selected k-nearest neighbors. Without actionable feedback or detailed advice, the authors are left with a general observation but no clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the extensibility of the proposed method to a large number of tasks, similar to challenges in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and suggests that the authors address this issue. While the comment implies that the authors should provide an analysis or discussion on the effect of the number of tasks on their approach, it does not explicitly instruct them to do so. The action is implicit but concrete, as it clearly identifies the area of concern and the type of analysis needed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises concerns about the extensibility of the proposed method to a large number of tasks, similar to challenges in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and suggests that the authors address this issue. However, the comment does not specify which part of the paper discusses the proposed method or the experiments, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of extensibility and the impact on shared parameters but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to challenges in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and suggests that the authors address this issue. While the comment identifies a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors are left to infer the implications of the concern without concrete guidance or evidence. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed support to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the extensibility of the proposed method to a large number of tasks, similar to challenges in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and suggests that the authors address this issue. The comment is somewhat helpful as it identifies a potential limitation in the paper and prompts the authors to consider and discuss this aspect. However, it lacks specific suggestions or guidance on how the authors might address this concern, such as proposing potential solutions or alternative approaches. To be more helpful, the comment could include actionable advice or examples of how to explore this issue further. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the eyetracking data selection and filtering process, noting that it appears everything is analyzed with some exclusions. However, it does not provide specific guidance or suggestions on how the authors should address this issue or clarify the process. The comment lacks explicit instructions or concrete details on what changes should be made, leaving the authors uncertain about how to improve their draft. Since the feedback is vague and does not offer actionable steps, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the eyetracking data selection and filtering process, indicating that it appears everything is analyzed with some exclusions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the perplexing nature of the data selection and filtering process, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about the eyetracking data selection and filtering process, noting that it appears everything is analyzed with some exclusions. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential issue with the eyetracking data selection and filtering process, noting that it appears everything is analyzed with some exclusions. However, it does not provide specific guidance or suggestions on how to address this issue or clarify the process. The feedback lacks actionable advice or detailed insights that would help the authors improve their draft. As a result, the comment is barely helpful, as it points out a potential problem but does not offer a clear path for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the credibility of the results in the Appendix for InitNO, specifically regarding the text-image alignment on StableDiffusion-v1-4. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might investigate or resolve the discrepancy between the reported results and those shown in Table 6. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and \"Table 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the credibility of the results by pointing out a discrepancy between the reported improvement in text-image alignment and the actual alignment shown in Table 6. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the credibility of the results in the Appendix for InitNO, specifically regarding the text-image alignment on StableDiffusion-v1-4. The reviewer provides a specific observation from Table 6, which shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4, despite the paper reporting improved alignment. This provides a clear and specific comparison that challenges the validity of the results. The comment is mostly verifiable as it uses a direct comparison from the paper\\'s data to support the claim, but it could be further strengthened with additional context or references to similar studies. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the results presented in the Appendix for InitNO, specifically regarding the text-image alignment on StableDiffusion-v1-4. It points out a discrepancy between the reported improvement in alignment and the actual alignment shown in Table 6. This feedback is valuable as it highlights a potential inconsistency that the authors need to address to ensure the accuracy and reliability of their findings. However, the comment could be more helpful if it provided suggestions on how to investigate or resolve this discrepancy. Overall, the comment is somewhat helpful as it identifies a critical issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take, suggesting that the writing could benefit from additional editing, particularly in terms of language usage and type. It also recommends considering dropping some sub/superscripts in equations for convenience, while noting that this change is being made. The feedback is clear and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the uneven writing and the notation in equations. It suggests that the writing could benefit from additional editing, particularly in terms of language usage and type. Additionally, it recommends considering dropping some sub/superscripts in equations for convenience. While the comment does not explicitly mention specific sections or equations, the authors can infer that it relates to the writing and equation sections. The suggestion to drop sub/superscripts is specific, but the comment lacks full grounding as it does not pinpoint exact sections or equations. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is uneven and could benefit from additional editing, particularly in terms of language usage and type. It also mentions that the notation in equations is exact but can be unwieldy, suggesting the possibility of dropping sub/superscripts for convenience. While the comment provides some reasoning for the need for editing, it lacks specific examples or detailed justification for why the writing is uneven or how the notation could be improved. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides actionable feedback on two specific areas: the writing style and the notation in equations. It suggests that the writing could benefit from additional editing, particularly in terms of language usage and type, which is a clear and constructive suggestion for improvement. Additionally, it recommends considering dropping some sub/superscripts in equations for convenience, providing a practical suggestion that could enhance readability. While the comment does not delve into detailed examples or provide comprehensive guidance, it offers valuable insights into areas that could be improved, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues that the authors need to address. It explicitly asks for an explanation of the dataset\\'s development cost, including the image acquisition cost and the type of manual collection used. Additionally, it points out a minor grammatical error in the text and requests clarification on the content of \"regulatory requirements\" and what is considered \"politically sensitive.\" While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to address these issues, such as specific examples or methods for explaining the dataset\\'s development cost. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (79 and 263) and provides detailed feedback on each line. It addresses the dataset\\'s development cost, the image acquisition cost, and the type of manual collection used, as well as the grammatical error in the text. Additionally, it requests clarification on the content of \"regulatory requirements\" and what is considered \"politically sensitive.\" This level of detail and specificity allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be revised, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the dataset being small relative to the development cost, specifically questioning the image acquisition cost and the type of manual collection used. This claim is somewhat verifiable as it highlights a potential issue with the dataset\\'s development, but it lacks specific examples or references to support the assertion. The comment also includes minor grammatical corrections and requests for clarification, which do not contribute to the verifiability of the claim. Therefore, the overall comment is rated as \"3: Somewhat Verifiable.\"', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment addresses several important aspects of the paper. It raises a concern about the dataset\\'s development cost, specifically questioning the image acquisition cost and the type of manual collection used. This is a critical point that the authors need to clarify to justify the dataset\\'s development. Additionally, the comment points out a minor grammatical error in the text, which is helpful for improving the paper\\'s clarity. However, the comment could be more helpful if it provided suggestions on how to address the dataset\\'s development cost or offered insights into potential improvements. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks detailed guidance or actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses curiosity about how the third column of Fig. 7 is generated, noting that the visualizations do not appear to be normalized. While the comment implies that the authors should clarify or address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to normalize the visualizations or what specific information should be included in the explanation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7\" and the \"third column,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the normalization of the visualizations in the third column, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the generation of the third column in Fig. 7, specifically questioning the normalization of the visualizations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the generation of the third column in Fig. 7, noting that the visualizations do not appear to be normalized. This feedback is somewhat helpful as it prompts the authors to clarify or address a potential issue with their methodology or presentation. However, the comment lacks depth and does not provide suggestions on how to resolve the normalization issue or why it might be important. To be more helpful, the comment could include a rationale for why normalization is crucial or suggest ways to ensure the visualizations are properly normalized. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the advantages of using assignment entropy maximization in their ablation experiment. It also notes that the authors did not discuss potential negative societal impacts of their work. While the comment provides explicit actions for the authors to take, it lacks concrete guidance on how to evaluate the advantages or what specific aspects to consider regarding societal impacts. The actions are clear but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"assignment entropy maximization\" and the \"ablation experiment,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: evaluating the advantages of using assignment entropy maximization in the ablation experiment and discussing potential negative societal impacts of the work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the investigation of assignment entropy maximization is rather heuristic and suggests that the authors should evaluate the advantages of using this method in their ablation experiment. However, the comment lacks specific examples or detailed reasoning to support the claim that the investigation is heuristic. Additionally, it mentions that the authors did not discuss potential negative societal impacts, but again, this is not substantiated with specific examples or references. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the investigation of assignment entropy maximization is rather heuristic and suggests that the authors should evaluate the advantages of using this method in their ablation experiment. This feedback is clear and actionable, providing the authors with a concrete step to enhance the rigor and clarity of their work. Additionally, the comment highlights the absence of a discussion on potential negative societal impacts, which is an important aspect that the authors should address. While the comment could be more helpful by offering specific guidance on how to evaluate the advantages or discussing potential societal impacts, it still provides valuable insights and direction for improvement. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that there is only one baseline model in the experimental section. However, it does not provide any explicit or implicit suggestions for improvement or additional actions. It lacks guidance on whether the authors should add more baseline models, what kind of models they should consider, or how to effectively incorporate them into the experimental section. Without any actionable advice or concrete details, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of having only one baseline model in the experimental section, which is a clear and actionable piece of feedback. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a factual observation about the presence of only one baseline model in the experimental section. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment points out a specific issue with the experimental section, noting that there is only one baseline model included. This is a relevant observation that could impact the comprehensiveness and robustness of the experimental evaluation. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue, such as recommending additional baseline models or explaining why the current choice is insufficient. While it identifies a potential weakness, the feedback is incomplete and does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies missing baselines and literature comparisons for the results, specifically mentioning traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and more recent PTQ baseline such as SpinQuant [2]. It suggests that comparing these baselines would provide valuable insights into the benefits of using additional memory versus relying on fine-tuning low rank adapters. The comment provides clear and concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific baselines and literature comparisons that are missing, such as traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and more recent PTQ baseline such as SpinQuant [2]. This allows the authors to accurately identify the parts of the paper that need to be addressed. The comment is also specific because it clearly specifies what is missing and why it is important to include these comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain baselines and literature comparisons are missing from the results section, specifically mentioning traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and more recent PTQ baseline such as SpinQuant [2]. The reviewer provides specific examples of what is missing, which helps to substantiate the claim. However, the comment could be strengthened by explaining why these comparisons are important or how they would impact the understanding of the results. Despite this, the claim is mostly verifiable due to the specific references provided, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s results section, specifically noting the absence of certain baselines and literature comparisons. It provides specific examples of what is missing, such as traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and more recent PTQ baseline such as SpinQuant [2]. By highlighting these omissions, the comment offers clear and actionable feedback that can guide the authors in expanding their experimental comparisons. Additionally, it suggests a rationale for including these comparisons, emphasizing the importance of understanding the benefits of using additional memory versus relying on fine-tuning low rank adapters. This feedback is detailed and constructive, providing the authors with a clear path to enhance the comprehensiveness and depth of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the definition of \"attribute\" and the differences between attributes, suggesting that more detailed instructions should be provided. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should add more detailed instructions but are not given specific steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the definition of \"attribute\" and the differences between attributes, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these concepts are discussed, the comment lacks full grounding. It is specific in its request for more detailed instructions but does not provide detailed guidance on what those instructions should entail. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification on the definition of \"attribute\" and the differences between attributes. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition of \"attribute\" and the differences between attributes, suggesting that more detailed instructions should be provided. While it identifies a potential area for improvement, it lacks specificity and does not offer actionable guidance on how the authors might address this issue. The comment points out a gap in the paper but does not provide clear steps or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses skepticism about the paper\\'s ability to predict whether a model can be trained to be robust to adversarial perturbations. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve their theory or experiments to better demonstrate the robustness of their models. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the ability of the theory in the paper to predict whether a model can be robust to adversarial perturbations. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the theory are insufficient or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing attention or improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theory in the paper is insufficient to predict whether a model can be robust to adversarial perturbations. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the paper\\'s ability to predict whether a model can be robust to adversarial perturbations. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their theoretical framework. Without actionable feedback or detailed critique, the authors are left without a clear path to enhance their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the terminology used in the paper, specifically asking for clarification on what is meant by \"scenario\" and where the \"agnostic\" part fits in. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to clarify these terms, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the terminology used in the paper, specifically asking for clarification on the meaning of \"scenario\" and the role of \"agnostic\" in the context. However, it does not specify which part of the paper these terms are used in, making it difficult for the authors to pinpoint the exact sections that need clarification. While the authors might have an idea of where these terms are discussed, the comment lacks full grounding. It is specific in its request for clarification but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the terminology used in the paper, specifically regarding the meaning of \"scenario\" and the role of \"agnostic.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper regarding the terminology used, specifically the meaning of \"scenario\" and the role of \"agnostic\" in the context. This feedback highlights an area where the authors need to provide clearer definitions or explanations to improve the understanding of their work. However, the comment does not offer specific suggestions or examples on how to address these issues, which limits its helpfulness. While it points out a potential weakness, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should change the name, provide an introduction, or clarify the reasoning behind the name. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the introduction or explanation are unclear or problematic. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or confusing. The comment lacks any justification or explanation that would help the authors understand the issue or address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. While it identifies a potential issue with the naming convention, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks depth and actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it points out an issue but does not offer constructive advice for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define what \"best\" means within the context of the paper, clarifying whether it refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to define what \"best\" means within the context of the paper, and whether it refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"best\" used in the paper should be explicitly defined, clarifying whether it refers to candidates most relevant for prediction, those with the highest confidence scores, or some other criteria. This is a request for clarification rather than a subjective claim or opinion. It does not express an opinion or require justification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback regarding the clarity of the paper. It identifies a particular area where the authors can improve their draft by explicitly defining what \"best\" means within the context of the paper. The comment suggests clarifying whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This guidance is clear and directly addresses a potential source of confusion for readers, allowing the authors to enhance the precision and comprehensibility of their work. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some claims in the paper are overstated, specifically regarding the proposed method not considering feed-forward layers but describing it as if it includes all components in transformer networks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit, as the authors can infer that they need to revise the claims, but it remains vague because it lacks concrete instructions on how to make the necessary corrections. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, noting that some claims are overstated and that the proposed method does not consider feed-forward layers, despite text suggesting otherwise. However, it does not specify which sections or parts of the paper contain these over-claims, making it difficult for the authors to pinpoint the exact areas needing revision. While the authors might have an idea of where these claims are made, the comment lacks full grounding. It is specific about the issue of over-claiming and the omission of feed-forward layers but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some points in the paper are overstated, specifically regarding the proposed method not considering feed-forward layers but describing it as if it includes all components in transformer networks. This claim is somewhat verifiable as it highlights a potential discrepancy between the claims and the actual scope of the proposed method. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the over-claiming. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that some claims are overstated and do not accurately reflect the scope of the proposed method. It points out that the method does not consider feed-forward layers, yet the text suggests otherwise. This feedback is valuable as it highlights a potential misrepresentation in the paper, prompting the authors to revise their claims and ensure accuracy. However, the comment could be more helpful if it provided specific examples or suggested how to address the over-claiming. Overall, the comment is somewhat helpful as it directs the authors to a critical area needing clarification, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve the clarity of the experiments. The comment lacks explicit instructions or concrete details on what changes should be made to enhance the motivation of the experiments. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not specify which part of the paper these methods are discussed in, making it weakly grounded. The comment is specific in identifying the issue with the motivation of the experiments, but without clear grounding, the authors may struggle to pinpoint where these issues are addressed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these methods are not clearly motivated. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the experiments, noting that they are not clearly motivated. It points out two particular aspects, \"no variations\" and \"Up to 18 games\" finetuning methods, which are mentioned but not explained or justified. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might clarify or improve the motivation of these methods. Without actionable feedback or detailed advice, the authors are left with only a vague understanding of what needs to be addressed. Therefore, the comment is barely helpful, as it highlights an issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the method performance under missing modality cases, such as testing with different missing ratios. It references specific works ([A] and [B]) that could provide guidance on how to address this issue. While the comment implies an action, it does not explicitly instruct the authors to conduct these evaluations or provide detailed guidance on how to implement them. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the evaluation of method performance under missing modality cases, such as testing with different missing ratios. The comment further references specific works ([A] and [B]) that could provide guidance on how to address this issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of the method performance under missing modality cases is necessary, as only Miss-V and Miss-A results are shown in tables 1/2. The reviewer supports this claim by referencing specific works ([A] and [B]) that could provide guidance on evaluating performance under missing modality cases. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific methods or studies that demonstrate the importance of this evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the evaluation of the method, noting that only Miss-V and Miss-A results are shown in tables 1/2. It suggests that the method performance should be well-evaluated under missing modality cases, such as testing with different missing ratios. The comment provides a clear and actionable suggestion for improvement by referencing relevant works ([A] and [B]) that could guide the authors in addressing this issue. This feedback is valuable as it directs the authors to expand their evaluation to include missing modality cases, which could enhance the robustness and applicability of their method. However, the comment could be more helpful if it offered specific guidance on how to implement these evaluations or discussed the potential impact of such evaluations on the results. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study on the effect of using image features should be included, even if the conditions are not changed during web browsing. This comment provides a clear and explicit action for the authors to take, which is to conduct an ablation study on the use of image features. The suggestion is concrete, as it specifies exactly what additional analysis is needed to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including an ablation study on the effect of using image features, even if the conditions are not changed during web browsing. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an additional study, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study on the effect of using image features is needed, even if the conditions are not changed during web browsing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study is necessary or how it would impact the paper. Without additional context or explanation, the claim is not verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an ablation study on the effect of using image features, even if the conditions are not changed during web browsing. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending additional analysis. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be examined. While it points out a relevant area for further exploration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should conduct additional experiments, modify their approach, or provide further analysis in these challenging settings. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" However, it does not specify which part of the paper this question pertains to, such as the experimental section or the results. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its inquiry about challenging settings but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether the approach can perform well in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment prompts the authors to consider the scalability and robustness of their approach in more challenging scenarios, but it does not offer actionable steps or detailed advice on how to test or improve the approach in these settings. As a result, the feedback is somewhat helpful, as it highlights an area for potential improvement but lacks the specificity needed to fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a misunderstanding of the concept of identifiability by the authors, clarifying that identifiability is a property of a model assuming infinite data can be observed. It explicitly states that the authors cannot conclude that a model is not identifiable due to insufficient data. This feedback provides a clear and direct correction to the authors\\' understanding, which is actionable. However, it does not offer specific guidance on how to address this misunderstanding or improve the draft. While the action is explicit, it lacks concrete details on how to implement the correction. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the authors\\' understanding of identifiability, specifically clarifying that it is a property of a model assuming infinite data can be observed. However, it does not specify which part of the paper discusses identifiability, making it weakly grounded. The comment is specific in its critique of the authors\\' understanding of identifiability, providing a clear explanation of what is incorrect. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' understanding of identifiability is incorrect, stating that it is a property of a model assuming infinite data can be observed. The reviewer provides a logical explanation by contrasting the concept of identifiability with the availability of data, which is a common understanding in statistical modeling. This reasoning is clear and straightforward, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses a specific misunderstanding regarding the concept of identifiability, clarifying that it is a property of a model assuming infinite data can be observed. By correcting the authors\\' understanding, the comment provides valuable insight that can help them refine their theoretical framework. However, while it identifies a critical error, it does not offer suggestions on how to address this misunderstanding or improve the draft. The feedback is somewhat helpful as it highlights a significant issue but lacks actionable guidance for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on potential modifications, alternative analyses, or additional experiments that could be conducted to demonstrate a benefit. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not specify which part of the paper this observation is based on, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the results are lacking or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the results do not demonstrate any particular benefit compared to a simple baseline. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying which aspects of the results are lacking or how the authors might address this issue, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues regarding efficiency in the training and inference processes of the method. It notes that the method requires a vocoder pre-trained on 60k-hour LibriLight and does not describe the time cost, such as GPU hours, for this pre-training process. Additionally, it mentions that the inference process incorporates a diffusion-based vocoder, which results in slower inference speed compared to DSP and WarpNet. While the comment identifies these issues, it does not provide explicit guidance on how to address them, such as suggesting ways to optimize the training process or improve inference speed. The authors are left to infer that they should include details on time costs and consider alternative methods for inference. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but lacks concrete instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"training process\" and \"inference process,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues related to efficiency, such as the lack of description of the time cost for the pre-training process and the slower inference speed due to the diffusion-based vocoder. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the efficiency of the method, specifically regarding the training process and inference process. It highlights the lack of information on the time cost, such as GPU hours, for the pre-training process and notes that the inference process with a diffusion-based vocoder results in slower speed compared to DSP and WarpNet. While the comment identifies specific areas of concern, it does not provide detailed evidence or references to support these claims. The authors are left to infer the significance of these issues without additional context or data. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas of concern regarding the efficiency of the method: the lack of information on the time cost of the pre-training process and the slower inference speed due to the diffusion-based vocoder. By highlighting these issues, the comment provides the authors with clear directions for improvement, such as including details on the time cost of the pre-training process and exploring alternative methods for inference that might improve speed. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of efficient methods for comparison. Overall, the feedback is mostly helpful as it directs the authors to important aspects of their work that need clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions the generalization of the scoring function s(\u00b7; G) to multiple goal documents or even without any gold document, but it does not explore this generalization. The comment implies that the authors should address this issue by exploring the generalization of their framework. However, it does not provide specific guidance on how to conduct this exploration or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the generalization aspect, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalization of the scoring function s(\u00b7; G) to multiple goal documents or even without any gold document. However, it does not specify which part of the paper discusses this generalization, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the generalization is mentioned, the comment lacks full grounding. It is specific about the issue of not exploring the generalization, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the generalization of the framework by noting that the paper mentions the potential for generalizing the scoring function to multiple goal documents or even without any gold document, but it does not explore this generalization. The comment highlights a gap in the paper\\'s exploration of this generalization, which could affect the framework\\'s applicability. However, the comment lacks specific examples or references to support the claim that the generalization is questionable. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by pointing out that the generalization of the scoring function s(\u00b7; G) to multiple goal documents or even without any gold document is not explored. This feedback highlights an area where the framework\\'s applicability could be expanded, which is valuable for the authors to consider. However, the comment does not provide specific suggestions or guidance on how to explore this generalization or what aspects should be focused on. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. This feedback is explicit, as it clearly states what additional data should be included to enhance the analysis. However, it does not provide specific guidance on how to collect or present this data, leaving some room for interpretation by the authors. While the action is clear, the lack of detailed instructions on implementation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. It references a specific paper by Yiming Zhang et al. (2022) to support the suggestion. However, the comment does not explicitly mention which part of the paper should include this information, making it weakly grounded. The suggestion is specific, as it outlines a particular data point that could enhance the analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. The comment references a specific paper by Yiming Zhang et al. (2022) to support the suggestion, which adds credibility to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to illustrate how this information would enhance the analysis. As it stands, the claim is mostly verifiable due to the inclusion of an external reference, but it could be more robust with additional explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. This feedback is clear and actionable, as it offers a specific way to enhance the analysis and presentation of results. By including this data, the authors can offer readers a more nuanced assessment of the framework\\'s effectiveness throughout the recommendation process. The reference to a related work further supports the suggestion, providing a concrete example of how such data can be utilized. However, the comment could be more helpful if it provided additional guidance on how to present or analyze this data. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and difficult to read, particularly due to the inclusion of numbered lists within paragraphs. It implies that these lists might be more easily understood if presented as actual lists rather than integrated into the paragraph text. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes, leaving the action somewhat implicit. However, the suggestion is concrete, as it specifies how the authors can improve the readability of their paper. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper\\'s density and suggests that numbered lists within paragraphs might be more easily read as actual lists. However, it does not specify which parts of the paper are particularly dense or where the numbered lists are located, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in suggesting a potential improvement in presentation, it lacks grounding as it does not direct the authors to specific paragraphs or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is \"very dense\" and difficult to read, particularly due to the inclusion of numbered lists within paragraphs. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, it is challenging for the authors to understand the exact issues with the paper\\'s density and how the inclusion of numbered lists affects readability. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s readability, noting that it is dense and difficult to navigate due to the inclusion of numbered lists within paragraphs. It suggests that these lists might be more easily understood if presented as actual lists rather than integrated into the paragraph text. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the readability of their paper. However, the comment could be more helpful if it offered additional guidance on how to structure the paragraphs or lists for better clarity. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement that can enhance the readability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fundamental principles underlying the effectiveness of a simple classifier in detecting fake images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors\\' work or what changes, if any, should be made to address the question raised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fundamental principles underlying the effectiveness of a simple classifier in detecting fake images. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the classifier or the detection process should be examined to address the question. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the fundamental principles underlying the effectiveness of a simple classifier in detecting fake images. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the question or how it relates to their work. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises an interesting question about the fundamental principles underlying the effectiveness of a simple classifier in detecting fake images. It suggests that other \"fake image detectors\" might be using similar spectral cues but in a more opaque manner. However, the comment does not provide any specific guidance or suggestions on how the authors might explore or address this question in their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the visualization results are terrible compared to the ground truth and suggests that the authors should provide analysis of both satisfied and terrible cases. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the draft. Additionally, the comment references a specific work, \"Class-incremental learning for semantic segmentation re-using neither old data nor old labels,\" which could provide a basis for the analysis. The action is explicit and provides concrete guidance, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the visualization results and compares them to the ground truth, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the analysis of satisfied and terrible cases. Additionally, it references a specific work, \"Class-incremental learning for semantic segmentation re-using neither old data nor old labels,\" which could provide context or comparison for the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" compared to the ground truth. However, it does not provide any specific examples, detailed comparisons, or references to support this claim. The suggestion to analyze satisfied and terrible cases is a logical step, but without concrete evidence or reasoning, the claim remains unverifiable. The inclusion of a reference to a specific work, \"Class-incremental learning for semantic segmentation re-using neither old data nor old labels,\" does not directly support the claim about the visualization results. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the visualization results, describing them as \"terrible\" compared to the ground truth. It suggests that the authors should provide an analysis of both satisfied and terrible cases to better understand the performance of their method. This feedback is clear and actionable, as it directs the authors to conduct a detailed analysis that could significantly improve the clarity and robustness of their results. Additionally, the comment references a specific work, \"Class-incremental learning for semantic segmentation re-using neither old data nor old labels,\" which could provide a basis for the analysis. However, the comment could be more helpful if it included specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper builds upon previous work, which could potentially affect its validity and effectiveness. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the potential impact of previous work or improve their implementation process. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the paper\\'s reliance on previous work, which could affect its validity and effectiveness. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where the implementation process is discussed. Additionally, the comment lacks specificity regarding how the limitations or issues in previous works might affect the paper or how the authors could address these concerns. Without explicit references or detailed guidance, the authors cannot effectively identify or address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a claim about the potential impact of previous work on the validity and effectiveness of the paper, specifically mentioning that the implementation process is similar to previous work on GAN. However, the comment lacks specific examples or references to the previous work or the limitations that could affect the paper. This makes the claim somewhat verifiable, as it provides a general observation but lacks detailed justification or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a potential issue with the paper\\'s reliance on previous work, suggesting that any limitations or issues in those previous works could affect the validity and effectiveness of the proposed method. It also notes that the implementation process is similar to previous work on GAN. While the comment identifies a relevant concern, it lacks specific guidance or suggestions on how the authors might address these potential issues or differentiate their work from previous studies. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the design of the policy selection process, specifically questioning whether information unavailable to the policy is used during the partitioning step. It suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. However, the comment does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit, as the authors need to infer that they should clarify or address the use of patient characteristics in their methodology. The lack of explicit guidance and detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the design of the policy selection process, specifically questioning whether information unavailable to the policy is used during the partitioning step. It suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the use of patient characteristics, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the design of the policy selection process, specifically questioning whether information unavailable to the policy is used during the partitioning step. It suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. However, the comment lacks specific examples or references to support the claim that this information should be used. The reasoning is based on logical inference, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the design of the policy selection process, specifically questioning whether information unavailable to the policy is used during the partitioning step. It suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. This feedback is valuable as it prompts the authors to reconsider their methodology and potentially improve it by addressing the use of additional information. However, the comment could be more helpful if it provided specific suggestions on how to incorporate this information or offered examples of similar approaches. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about why NeRF\\'s rendering quality is worse than NeuS / Geo NeuS. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, how the authors might investigate or resolve it, or what specific changes could be made to improve the rendering quality. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why NeRF\\'s rendering quality is worse than NeuS / Geo NeuS. This provides clear guidance on what aspect of the appendix needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the rendering quality of NeRF compared to NeuS / Geo NeuS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rendering quality of NeRF compared to NeuS / Geo NeuS, which is a relevant point for the authors to address. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might investigate or resolve this issue. Without actionable feedback or specific advice, the authors are left with only a vague indication of a potential problem. Therefore, the comment is barely helpful, as it points out an area of concern but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the bold assumption made in Section 3.7 regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. However, it does not provide any explicit or implicit suggestions for how the authors might address this confusion or clarify their assumption. The comment lacks actionable guidance, such as recommending additional experiments, analyses, or explanations to support the assumption. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The comment highlights the lack of understanding regarding how this assumption is supported by the proposed evaluation approach. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer expresses confusion about how this assumption is supported by the evaluation approach. However, the comment does not provide any specific reasoning, examples, or references to substantiate the claim that the assumption is unsupported or unreasonable. This lack of detailed justification makes it difficult for the authors to understand the basis of the reviewer\\'s concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It expresses confusion about how this assumption is supported by the evaluation approach, which is a valid point. However, the comment does not provide any constructive feedback or suggestions on how the authors might address this issue or clarify their assumption. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: the omission of qualitative and quantitative discussions of recent related work, including [A], which achieves higher performance on SUN, and the absence of DCN [18] in Table 3, despite its better performance on CUB. Additionally, it mentions that [B] is relevant for transductive label propagation, although it does not specify how this should be addressed. The comment provides explicit actions for the authors to take, such as including discussions of recent related work and ensuring that relevant studies are mentioned in the appropriate sections. However, it lacks concrete guidance on how to integrate these discussions or which aspects of [A] and [B] should be highlighted. Therefore, while the actions are explicit, the comment is somewhat vague in terms of execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the related work section, including the omission of qualitative and quantitative discussions of recent related work, such as [A], which achieves higher performance on SUN, and the absence of DCN [18] in Table 3, despite its better performance on CUB. Additionally, it mentions that [B] is relevant for transductive label propagation, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims regarding the omission of recent related work, specifically mentioning [A] and DCN [18], which are not discussed in the paper. The reviewer provides specific examples of works that should be included, such as [A] achieving higher performance on SUN and DCN [18] being better than other prior work on CUB. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that these works are relevant and should be discussed. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific weaknesses in the related work section, highlighting the omission of qualitative and quantitative discussions of recent related work, including [A], which achieves higher performance on SUN. It also points out the absence of DCN [18] in Table 3, despite its better performance on CUB. Additionally, the comment suggests that [B] is relevant for transductive label propagation, although it does not specify how this should be integrated into the paper. While the comment provides clear and actionable feedback on areas needing improvement, it could be more helpful by offering specific suggestions on how to incorporate these works or by providing more detailed guidance on the qualitative and quantitative aspects that should be discussed. Overall, the comment is mostly helpful, as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to change the operator in Figure 2 from an addition to a Hadamard product between the DAG and Attention. This is a clear and direct action, providing the authors with specific guidance on how to modify their draft. The comment is concrete, as it specifies exactly what needs to be changed and where, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the operator should be a Hadamard product between the DAG and Attention instead of an addition. This provides clear guidance on what needs to be revised in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the operator in Figure 2 should be a Hadamard product between the DAG and Attention, rather than an addition. However, the comment does not provide any justification or reasoning for this suggestion. It lacks supporting evidence or explanation, making it difficult for the authors to understand the basis of the claim. Without additional context or reasoning, the claim is unverifiable, as it does not provide sufficient information for the authors to address the suggestion effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft by recommending a change in the operator used in Figure 2. It clearly identifies the issue and offers a precise alternative, which is the Hadamard product between the DAG and Attention. This feedback is valuable as it directly addresses a potential error or misunderstanding in the manuscript, allowing the authors to make a concrete improvement to their work. However, the comment could be more helpful if it explained why this change is necessary or how it impacts the overall understanding of the methodology. Despite this, the comment is mostly helpful as it provides clear guidance on how to enhance the draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the authors have addressed the reviewer\\'s concerns in their revision and response, specifically regarding the optimal rates for SOBA under additional smoothness assumptions. The reviewer has increased the score from 7 to 8 due to this improvement. However, the comment also mentions that the limitations are only partially addressed, with the non-standard finite sum assumption discussed in the theoretical analysis section but not anticipated in the abstract, and the discrepancy between theoretical and practical updates of SABA mentioned briefly and not properly addressed. While the comment acknowledges improvements, it does not provide explicit guidance on how the authors should address the remaining limitations. The feedback is somewhat actionable as it highlights areas that need further attention, but it lacks concrete steps for the authors to take. Therefore, it is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.7. 2022. Post authors\\' response,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues that need to be addressed, such as the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the authors have addressed the reviewer\\'s concerns in their revision, specifically regarding the optimal rates for SOBA under additional smoothness assumptions. The reviewer increases the score from 7 to 8 due to this improvement. However, the comment also mentions that the limitations are only partially addressed, with the non-standard finite sum assumption discussed in the theoretical analysis section but not anticipated in the abstract, and the discrepancy between theoretical and practical updates of SABA mentioned briefly and not properly addressed. While the comment acknowledges improvements, it does not provide specific examples or detailed reasoning for the remaining limitations, making it somewhat verifiable. The authors would need to further explore these points to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the authors have addressed the reviewer\\'s concerns in their revision, specifically regarding the optimal rates for SOBA under additional smoothness assumptions. It commends the authors for this improvement and increases the score from 7 to 8. However, the comment also points out that the limitations are only partially addressed. It mentions that the non-standard finite sum assumption is discussed in the theoretical analysis section but could be anticipated in the abstract, and that the discrepancy between theoretical and practical updates of SABA is mentioned briefly and not properly addressed. While the comment provides some direction for further improvement, it lacks specific suggestions or actionable steps for the authors to fully address these limitations. Therefore, the feedback is somewhat helpful, as it highlights areas for improvement but does not provide detailed guidance on how to achieve them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim and the experimental results, specifically noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to resolve the discrepancy. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific tables (Table 2 and Table 3) and provides a clear reference to the claim about UnKE\\'s ability to preserve pre-trained knowledge during the editing process. It also specifies the issue by comparing UnKE\\'s performance with the baseline (MMLU) and the metrics Src-Acc and Tgt-Acc. This provides the authors with clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that UnKE\\'s ability to retain original knowledge is worse than the baseline, as evidenced by the experimental results in Tables 2 and 3. The reviewer supports this claim by referencing a specific study, \"Long-form evaluation of model editing,\" which provides a basis for the comparison. This reference adds a layer of credibility to the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or examples from the referenced study to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper\\'s claim and the experimental results, specifically noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. This is a critical observation that highlights a potential weakness in the paper\\'s claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it points out an important area for improvement, it lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of a clear explanation for the intention of BWTP/GLBW and the placement of many details in the appendix, which makes it difficult to understand them at first sight. While the comment identifies these problems, it does not provide explicit instructions or concrete suggestions on how to address them. The authors are left to infer that they should improve the explanation and consider moving some details from the appendix to the main text. However, the comment lacks specific guidance on how to enhance the explanation or where to relocate the details. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the lack of a clear explanation for the intention of BWTP/GLBW and the placement of many details in the appendix, which makes it difficult to understand them at first sight. However, it does not specify which part of the paper these issues pertain to, such as particular sections or figures where these explanations should be included. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issues but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the explanation for the intention of BWTP/GLBW and the placement of many details in the appendix. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks explicit evidence or references to substantiate the assertion that the explanation is weak or that the appendix placement is problematic. This makes the claims somewhat verifiable, as the authors would need to infer the issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of a clear explanation for the intention of BWTP/GLBW and the placement of many details in the appendix, which makes it difficult to understand them at first sight. While the comment highlights these weaknesses, it does not provide detailed suggestions or guidance on how to address them. The authors are left to infer that they might need to clarify the explanation and consider moving some details from the appendix to the main text. However, without specific advice or examples, the feedback is somewhat helpful, as it points out areas for improvement but lacks depth and actionable steps. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a proof that was omitted due to space constraints, either in the main paper or as supplementary material. The action is clear and direct, providing specific guidance on what the authors need to do to address the issue. The comment is highly actionable as it gives precise instructions on how to implement the suggested change, ensuring the authors know exactly what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of a proof due to space constraints and suggests including it in the revision, either in the main paper or as supplementary material. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a proof was omitted due to space constraints and requests its inclusion, either in the main paper or as supplementary material. The comment does not make any subjective claims or judgments but rather provides a factual observation and a suggestion for improvement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the omission of a proof due to space constraints. It provides a clear and actionable suggestion for improvement by recommending that the authors include the proof, either in the main paper or as supplementary material. This feedback is valuable as it guides the authors on how to enhance their draft by addressing a missing element that could impact the paper\\'s completeness and rigor. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate the proof effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide specific experimental results or references instead of relying on the statement \"Since the NPPs lack any direct dependence on magnitudes\" to explain why NPPs perform worse than ETAS. This feedback implies that the authors should include more detailed evidence or references to support their claims. While the action is implicit, it is concrete because it specifies what the authors should do to improve their draft\u2014provide specific experimental results or references. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing specific experimental results or references to support the claim that NPPs perform worse than ETAS. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or table where this reasoning is discussed. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not direct. The comment is specific in suggesting the need for more detailed evidence or references but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide specific experimental results or references to support the claim that NPPs perform worse than ETAS. The comment critiques the current reasoning, which is based on the lack of direct dependence on magnitudes, as insufficient. However, it does not provide any specific examples or references to substantiate the claim that NPPs perform worse or to suggest what kind of experimental results or references would be more appropriate. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specific improvements needed to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS. By recommending the inclusion of more detailed evidence, the comment offers actionable feedback that can help the authors strengthen their argument and improve the credibility of their findings. However, the comment could be more helpful if it specified what kind of experimental results or references would be most beneficial or how they might be integrated into the paper. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the implementation details, specifically regarding the application of connectivity patterns outlined in Equations 3 and 4 to complex architectures like UNet, ResNet, and MobileNet. The reviewer points out that this lack of guidance raises serious problems when trying to understand the paper\\'s details. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue, such as by providing additional explanations or examples. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the implementation details but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, equations, and tables (Equations 3 and 4, Tables 1, 4, and 5) that are relevant to the discussion. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue of unclear implementation details, particularly regarding the application of connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. It highlights the lack of guidance and incorporation of these details in the Appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically regarding the application of connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. The reviewer provides specific examples by mentioning Equations 3 and 4 and Tables 1, 4, and 5, which helps identify the areas of concern. However, the comment lacks detailed reasoning or examples of how these implementation details are unclear or how they impact the understanding of the paper. While the claim is somewhat supported by the references to specific equations and tables, it could be strengthened with more detailed explanations or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the implementation details in the paper. It points out that while the methodology section outlines connectivity patterns between layers, there is no specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet. This lack of clarity is highlighted as a serious problem, especially when trying to understand the paper\\'s details. Additionally, the comment notes that these details are not incorporated in the Appendix, which further complicates the reader\\'s understanding. The feedback is clear and actionable, as it directs the authors to provide more detailed guidance on implementing their methodology across various architectures. However, it could be more helpful if it offered specific suggestions on how to present this information or examples of what additional details might be needed. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should experiment with other languages and annotations, such as MQM or DA, to verify the scalability of the HTER label calculation. This is an explicit action, as it directly instructs the authors to conduct additional experiments. However, the comment does not provide specific guidance on how to implement these experiments or what specific aspects to focus on. While the action is clear, the lack of detailed instructions makes it somewhat vague in terms of execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the calculation of HTER label and its reliance on automatic scripts, suggesting that it may not be scalable to other annotations like MQM or DA. However, it does not specify which part of the paper discusses this calculation, making it weakly grounded. The comment is specific in its suggestion to experiment with other languages and annotations to verify scalability, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the calculation of HTER label relies on automatic scripts, which may not be scalable to other annotations like MQM or DA. The reviewer suggests that if this is not the case, the authors should experiment with other languages and annotations to verify scalability. However, the comment lacks specific examples or references to support the claim about the limitations of automatic scripts. Without detailed evidence or reasoning, the claim is somewhat verifiable, as it provides a logical suggestion but lacks the necessary support to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the scalability of the HTER label calculation, which relies on automatic scripts. It suggests that the authors should experiment with other languages and annotations, such as MQM or DA, to verify the scalability of their approach. This feedback is clear and actionable, providing a specific direction for the authors to explore and potentially expand their work. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how overall performance depends on $m$ in $G_m$. While it implies that the authors should address this question in their paper, it does not provide explicit guidance or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis or discussion on this dependency. However, the comment does not specify what kind of analysis or discussion is needed, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how overall performance depends on $m$ in $G_m$. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the dependency on $m$, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about how overall performance depends on $m$ in $G_m$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how overall performance depends on $m$ in $G_m$. While it identifies a potential area of interest or confusion, it lacks depth and does not provide specific guidance or suggestions for the authors to address this question. The comment does not offer actionable feedback or context that would help the authors improve their draft. As a result, the comment is barely helpful, as it points out a potential issue but does not assist the authors in resolving it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a theoretical-practical gap in deep learning research and suggests that the authors should comment on this gap, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support the claim. While the comment implies that the authors should address this gap, it does not provide explicit instructions on how to do so or what specific elements of Causal-Stonet should be discussed. The action is implicit and somewhat vague, as the authors need to infer the specific aspects to focus on. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a theoretical-practical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support the claim. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to comment on the key elements that allow Causal-Stonet to learn sparse neural nets, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a theoretical-practical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support the claim, which provides a clear and specific reference to substantiate the argument. This reference helps to verify the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a theoretical-practical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support this claim. The comment provides a clear and actionable suggestion for the authors to address this gap by commenting on the key elements that allow Causal-Stonet to learn sparse neural nets. This feedback is valuable as it directs the authors to a specific area of improvement and provides a reference to support their discussion. However, the comment could be more helpful if it offered additional guidance on how to incorporate this discussion into the paper. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and provides a starting point for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improving the layout of the manuscript. It advises the authors to consider making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are clear and actionable, giving the authors specific steps to take to improve the readability and visual appeal of their paper. The comment also acknowledges that these changes can be addressed in the camera-ready version if the paper is accepted, providing additional context for the authors. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements such as \"Tables\" and \"Figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. This level of detail helps the authors understand what changes are being suggested and why, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is densely packed in terms of space, with figures and tables positioned too closely to the text. The reviewer suggests making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. This claim is somewhat verifiable as it provides a logical suggestion for improving the layout of the paper. However, it lacks specific examples or references to similar practices in other papers, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the layout of the manuscript, suggesting that the paper appears densely packed due to the close positioning of figures and tables. It offers clear recommendations for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. This guidance is constructive and can help the authors enhance the readability and visual appeal of their paper, particularly in the camera-ready version. The comment is mostly helpful as it identifies a specific issue and provides concrete suggestions for addressing it, but it could be more comprehensive by offering additional examples or guidance on how to achieve the suggested improvements. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it suggests that the ReCPE method is too strategic and only proposes solutions intuitively, without a strong theoretical guarantee. This implies that the authors should provide a stronger theoretical foundation for their method. However, the comment does not specify how the authors should achieve this, making the action vague. Second, it points out a spelling error, which is a clear and actionable suggestion. Overall, the comment contains a mix of explicit and implicit actions, with the latter being somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions \"Note 2 on page 7,\" allowing the authors to identify the specific part of the paper being addressed. However, the main critique about the ReCPE method being too strategic and lacking a strong theoretical guarantee is not grounded, as it does not specify which sections or parts of the paper discuss these aspects. The comment is specific in pointing out the spelling error, but the broader critique lacks specificity regarding what aspects of the method need strengthening. Therefore, the comment is partially grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the ReCPE method is too strategic and lacks a strong theoretical guarantee. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions that the method only proposes solutions intuitively, but without further elaboration, it is difficult for the authors to understand the basis of this critique. The comment also includes a minor spelling correction, which is factual and does not require verification. Overall, the claim about the method being too strategic lacks sufficient justification, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a mixed assessment of the research scenario and the ReCPE method proposed in the article. It acknowledges the meaningfulness of the research scenario but criticizes the method as being too strategic and lacking a strong theoretical guarantee. This feedback highlights a potential weakness in the paper that the authors could address to strengthen their work. However, the comment does not offer specific suggestions or guidance on how the authors might enhance the theoretical foundation or provide a stronger guarantee. Additionally, it includes a minor comment about a spelling error, which is a factual observation rather than a critique or suggestion for improvement. Overall, the comment provides some insight but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the applicability of the method to generation tasks, beyond NLU tasks. While it implies that the authors should consider or discuss the potential application to generation tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to explore or address this question. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the method to generation tasks beyond NLU tasks. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion where this topic could be addressed. The authors might infer that it relates to the discussion of potential applications or limitations, but this inference is not direct. The comment is specific in its inquiry about generation tasks, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking about the applicability of the method to generation tasks beyond NLU tasks. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the method to generation tasks beyond NLU tasks. While it prompts the authors to consider an additional application area, it lacks specificity and does not provide any guidance or suggestions on how to explore or address this question. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential area of interest but does not assist the authors in making concrete improvements to their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that $N_d$ is not defined and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, which is to define $N_d$ and clarify the potential variation in observations per task. The comment is specific and actionable, as it gives the authors a concrete step to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of $N_d$ not being defined and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of definition for $N_d$ and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. However, the comment does not provide any supporting evidence or reasoning to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim is not verifiable, making it difficult for the authors to address the issue effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the manuscript, noting that $N_d$ is not defined and suggesting that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can help the authors enhance the clarity and completeness of their draft. By addressing this point, the authors can improve the readability and understanding of their work. However, the comment could be more helpful if it provided additional context or examples of how this clarification would benefit the overall paper. Overall, the comment is mostly helpful, as it effectively directs the authors toward a specific enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a formatting issue, specifically that the appendix is not separated from the main paper and that the PDF provided for the main paper is a 14-page document. However, it does not provide any explicit or implicit action for the authors to take to address this issue. There is no guidance on how to separate the appendix or what the consequences of this formatting issue might be. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Appendix\" and the \"PDF provided for the main paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the appendix not being separated from the main paper and the length of the PDF provided. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the formatting of the paper, specifically noting that the appendix is not separated from the main paper and that the PDF provided is a 14-page document. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a formatting issue with the paper, specifically that the appendix is not separated from the main paper and that the PDF provided for the main paper is a 14-page document. This is a minor technical issue that could be easily addressed by the authors to improve the presentation of their work. However, the comment does not provide any context or explanation as to why this formatting issue is important or how it might impact the reader\\'s experience. Without additional guidance or suggestions on how to address this issue, the feedback is limited in its usefulness. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more insight into the main improvement in the proposed model, specifically the ternary potential. It implies that the authors should explain why the ternary potential is crucial for the model\\'s performance and how it compares to existing models. While the comment explicitly requests additional explanation, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to address the ternary potential but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the main improvement in the proposed model coming from the ternary potential and the comparison with existing models for a 2 modalities setup. The comment provides a clear direction for the authors to explore and explain the significance of the ternary potential. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model is due to the ternary potential, as evidenced by the results in Table 1. It suggests that without the ternary potential, the proposed model does not outperform existing models for a 2 modalities setup, except for HieCoAtt. This claim is somewhat verifiable as it is based on the results presented in Table 1, which provides some evidence for the claim. However, the comment could be strengthened by providing more detailed analysis or specific examples from the table to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of improvement by pointing out that the main improvement in the proposed model appears to be due to the ternary potential. It suggests that without this component, the model does not outperform existing models for a 2 modalities setup, except for HieCoAtt. This feedback is clear and actionable, as it directs the authors to provide further analysis or explanation regarding the role of the ternary potential in their model\\'s performance. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context or examples. Overall, the comment is mostly helpful as it highlights a critical area for improvement and guides the authors toward enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include additional information in their tables to facilitate a more straightforward assessment of the comparisons. Specifically, it recommends noting which methods use data augmentations, what architecture they use, and what objective they employ. While the comment provides explicit actions, it lacks detailed guidance on how to present this information in the tables or what specific aspects should be highlighted. The authors are given a clear direction but without concrete instructions on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests adding specific information to the tables, such as noting which methods use data augmentations, what architecture they use, and what objective they employ. This provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which tables or sections of the paper it pertains to, leaving the authors to infer that it relates to the tables containing method comparisons. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what information should be added. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including information about data augmentations, architecture, and objectives would aid in assessing the comparisons in the tables. While the comment provides a logical reasoning for why this information would be beneficial, it lacks specific examples or references to support the claim that data augmentations were not common practice for few-shot classification. This makes the claim somewhat verifiable, as the authors would need to infer the importance of the suggested additions without explicit evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the clarity and comparability of the tables in the paper. By recommending the inclusion of information about data augmentations, architecture, and objectives used by the methods, the reviewer offers a concrete way to enhance the assessment of the comparisons. This feedback is valuable as it guides the authors on how to present their results more effectively, allowing for a more straightforward evaluation of the methods. However, the comment could be more helpful if it provided specific examples or further elaborated on how this information should be presented. Overall, the comment is mostly helpful, as it offers actionable guidance that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the paper\\'s claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests that it would be interesting to see how LSH performs on actual state-of-the-art models and questions the applicability of the hyperpruning method on more recent benchmarks and architectures. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim about hyperpruning methods beating the state of the art, specifically questioning the use of LSTM and LSH networks, which are not considered state of the art for language modeling. It suggests testing LSH on actual state-of-the-art models and questions the applicability of the method on more recent benchmarks and architectures. The comment is fully grounded as it clearly refers to the claim about hyperpruning methods and the specific architectures used in the paper. It is also specific because it provides clear guidance on what needs to be addressed, such as testing LSH on state-of-the-art models and considering more recent benchmarks. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests testing LSH on actual state-of-the-art models and questions the applicability of the method on more recent benchmarks and architectures. The comment provides logical reasoning by pointing out the potential limitations of the current approach and suggests a direction for further exploration. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to make a significant effort to address these concerns, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the paper\\'s claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests testing LSH on actual state-of-the-art models and questions the applicability of the method on more recent benchmarks and architectures. This feedback is mostly helpful as it provides a clear direction for the authors to consider, specifically by recommending a comparison with more advanced models and datasets. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what additional experiments could be performed to strengthen the paper\\'s claims. Overall, the comment provides valuable insights but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more experimental details, such as neural networks and hyperparameters, in the appendix. This provides a clear and direct action for the authors to take, specifying exactly what needs to be added to improve the draft. The comment is concrete, as it outlines the specific information that should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including more experimental details, such as neural networks and hyperparameters, in the appendix. However, it does not specify which part of the paper currently lacks these details, making it weakly grounded. The comment is specific in its request for additional information, such as neural networks and hyperparameters, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, such as neural networks and hyperparameters, should be included in the appendix. However, it does not provide any justification or reasoning for why these details are necessary or how they would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of more experimental details, such as neural networks and hyperparameters, in the appendix. This feedback is specific and directly addresses a potential area for enhancement, which can help the authors improve the transparency and comprehensiveness of their experimental section. However, the comment could be more helpful if it explained why these details are important or how they would benefit the paper. Overall, the comment is mostly helpful as it offers a concrete step for improvement, but it could be more comprehensive with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that section 5.1 does not provide useful information about why the new model is superior. However, it does not specify what kind of information is missing or how the authors should address this issue. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to improve the section. Since the comment is vague and does not provide a clear path for action, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 5.1,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. However, the comment lacks specificity as it does not detail what kind of information is missing or how the section could be improved to provide useful information about the superiority of the new model. Without specific guidance, the authors may struggle to understand what changes are needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that section 5.1 does not provide useful information about why the new model is superior. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with section 5.1, suggesting that it does not provide useful information about why the new model is superior. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the section. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that the authors should include a comparison to demonstrate this aspect. While the comment explicitly states that a comparison is needed, it does not provide specific guidance on how to conduct this comparison or what aspects should be focused on. The action is explicit but somewhat vague, as the authors know they need to make a comparison but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that the authors should include a comparison to demonstrate this aspect. However, it does not specify which part of the paper should include this comparison or what specific aspects should be compared. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. The lack of specificity and grounding makes it difficult for the authors to identify and respond to the comment effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that it might have transferability but not as strong as other methods. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that it might have transferability but not as strong as other methods. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects should be focused on. The feedback is somewhat helpful as it points out a gap in the analysis but does not offer actionable steps for the authors to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider checking human-factors literature on creating systems that effectively interact with people. While the comment implies that the authors should explore this area, it does not provide specific guidance on how to incorporate this literature or what aspects to focus on. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses. It mentions \"No.03. 2020\" and \"the proposed method,\" but without further context, the authors cannot confidently determine the exact section or aspect of the paper being referred to. Additionally, the comment lacks specificity regarding the ethical concerns or limitations mentioned, as it does not provide detailed feedback or suggestions for improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider human-factors literature to address practical challenges in interacting with humans. The comment is somewhat verifiable as it provides a logical suggestion to explore a specific area of literature, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the suggestion, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider human-factors literature to address practical challenges in interacting with humans. While it provides a general direction for improvement, it lacks specificity and actionable guidance on how to incorporate this literature or what specific aspects to focus on. The comment is somewhat helpful as it points out an area for consideration, but it does not offer detailed advice or examples, leaving the authors with only a vague idea of what to do. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experiments being conducted only in a toy dataset like MNIST-fashion and questions whether the proposed model selection approach scales beyond such datasets. It also suggests comparing the proposed approach with other neural network pruning methods. While the comment implies that the authors should consider expanding their experiments to more diverse datasets and compare their approach with others, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments conducted in the paper, specifically mentioning the use of a toy dataset like MNIST-fashion. It raises a question about the scalability of the proposed model selection approach beyond such datasets and suggests comparing it with other neural network pruning methods. However, the comment does not explicitly mention which part of the paper discusses the experiments or the model selection approach, making it weakly grounded. The comment is specific in its request for scalability testing and comparison with other methods, providing clear guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scalability of the proposed model selection approach by noting that the experiments are conducted only in a toy dataset like MNIST-fashion. It suggests that it would be interesting to compare the approach with other neural network pruning methods. However, the comment lacks specific reasoning or evidence to support the claim about scalability or the need for comparison with other methods. Without detailed justification or references, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed model selection approach, noting that the experiments are conducted only in a toy dataset like MNIST-fashion. It questions whether the approach can be applied to more complex datasets and suggests comparing it with other neural network pruning methods. This feedback is somewhat helpful as it identifies a potential limitation in the experimental scope and provides a direction for further exploration. However, it lacks specific guidance on how to address these concerns or suggestions for alternative datasets or methods to compare against. To be more helpful, the comment could include specific recommendations or examples of datasets or methods to consider. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several specific mathematical formulation issues and inconsistencies in the paper, providing explicit examples of where the authors should make corrections. Each example is accompanied by a clear suggestion for what the correction should be, such as changing \"max\" to \"$max$\" or clarifying the use of indices. This level of detail provides the authors with concrete actions to take, ensuring they know exactly how to address the issues raised. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and equations in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the mathematical formulation issues and inconsistencies, providing examples of where the notation or equations are incorrect or unclear. This level of detail helps the authors understand exactly what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies several specific mathematical formulation issues and inconsistencies in the paper, providing detailed examples and line references. This level of specificity allows the authors to easily identify and address the issues, making the claim fully verifiable. The comment is supported by precise references to specific lines in the paper, which provides a clear path for the authors to verify and correct the errors. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on several mathematical formulation issues and inconsistencies in the paper. It identifies particular lines and equations where the notation or formulation is incorrect or unclear, offering precise suggestions for corrections. This level of detail empowers the authors to make targeted improvements to their draft, ensuring that the mathematical content is accurate and consistent. The comment is thorough and constructive, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting experiments to demonstrate the effect of using different numbers of particles. It highlights the lack of clarity regarding the importance of this choice. While the comment implies a specific action\u2014conducting additional experiments\u2014it does not provide detailed guidance on how to implement these experiments or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to conduct experiments but may not be entirely sure of the exact methodology or parameters to explore. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the importance of this choice is unclear. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where this analysis could be included. The authors might infer that it relates to the experimental setup or results sections, but this inference is not direct. The comment is specific in suggesting a particular experiment but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from experiments demonstrating the effect of using different numbers of particles. However, it does not provide any specific reasoning or evidence to support why this is important or how it would impact the understanding of the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the importance of this choice is unclear. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing additional experimental evidence. However, the comment lacks depth and does not offer detailed guidance on how to conduct these experiments or what specific aspects to focus on. While it provides a direction for improvement, it does not fully empower the authors to make significant enhancements to their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. This provides a clear and direct action for the authors to take, which is to include a comparison using the covariance metric. The comment is specific and provides a concrete example of what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where comparisons should be included. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in identifying the missing comparison but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by recommending the inclusion of a comparison using the covariance metric. By addressing this point, the authors can enhance the comprehensiveness and rigor of their evaluation, which is crucial for demonstrating the effectiveness of their methods. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a better explanation for Table 5, specifically asking about the meaning of A, B, C, and D and why positive paths lead to a monotonic solution. The comment also requests an explanation of the scenarios under which this occurs. These requests are clear and direct, providing the authors with specific actions to take to improve their draft. The feedback is concrete, as it outlines exactly what information needs to be added or clarified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of A, B, C, and D in Table 5 and the reason why positive paths lead to a monotonic solution and under what scenarios. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests clarification on the meaning of A, B, C, and D in Table 5 and seeks an explanation of why positive paths lead to a monotonic solution and under what scenarios. This is a request for additional information and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that requires clarification, namely Table 5. It asks for an explanation of what A, B, C, and D represent and why positive paths lead to a monotonic solution. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the reader\\'s understanding of the results. However, the comment could be more helpful if it suggested how to present this information or provided examples of what kind of explanation would be beneficial. Overall, the comment is mostly helpful as it highlights a critical area for improvement and guides the authors toward enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the feasibility of using a proxy or surrogate method to estimate US accuracy, which is a relevant concern for practical applications. It also notes that early predictions of US accuracy are not reliable predictors of DS accuracy, as evidenced by the saturation of the curve in Figure 1. The reviewer suggests using power law prediction for model selection, referencing specific figures in the Appendix. While the comment implies that the authors should explore alternative methods for model selection, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and specific figures in the Appendix (F6, F7, F8, F9), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the time it takes to obtain a single US accuracy and suggests exploring proxy or surrogate methods for estimation. Additionally, it discusses the reliability of early predictions of US accuracy and the potential use of power law prediction for model selection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the feasibility of using a proxy or surrogate method to estimate US accuracy, which is a relevant concern for practical applications. The reviewer provides some reasoning by noting that the curve in Figure 1 saturates only towards the end, implying that early predictions of US accuracy may not be reliable. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim about the unreliability of early predictions. While the suggestion to use power law prediction for model selection is mentioned, it is not fully elaborated upon. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an important question about the feasibility of using a proxy or surrogate method to estimate US accuracy, which is a relevant concern for practical applications. It also notes that early predictions of US accuracy are not reliable predictors of DS accuracy, as evidenced by the saturation of the curve in Figure 1. The comment suggests exploring the use of power law prediction for model selection, referencing specific figures in the Appendix. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a direction for further exploration. However, it lacks specific guidance or suggestions on how to implement these ideas, such as proposing specific methods or approaches for using power law prediction. To be more helpful, the comment could include more detailed advice or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide ablation studies that isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. This is a clear and direct action, leaving no ambiguity about what the authors need to do. The comment is specific in its request, providing concrete guidance on how to improve the draft by conducting ablation studies. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, it does not specify which part of the paper should include these studies or which factors should be isolated. This lack of explicit reference to a specific section or element of the paper makes it weakly grounded. The comment is specific in its request for ablation studies but lacks grounding in terms of identifying where these studies should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why such studies are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of conducting these studies. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and understanding of their results. By conducting ablation studies, the authors can identify which factors contribute most to the performance of epsilon sampling, which is crucial for improving the robustness and interpretability of their findings. However, the comment could be more helpful if it included specific factors or aspects to focus on in the ablation studies. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed attack against the mode connectivity-based defense proposed in the ICLR paper \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness.\" While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to perform this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, leaving the authors with a general idea of what to explore but without detailed instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which provides a grounding for the critique. It suggests that the authors should compare their proposed attack against the mode connectivity-based defense proposed in the ICLR paper. However, the comment does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in its request for a comparison with the ICLR paper, but without explicit references to sections or parts of the paper, the authors may struggle to identify where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" to support the claim that Fine-Tuning is not the most effective approach to recover backdoor models. The reviewer suggests that the authors should compare their proposed attack against the mode connectivity-based defense proposed in the ICLR paper. This claim is somewhat verifiable as it references a specific work, providing a basis for the critique. However, the comment lacks detailed reasoning or examples from the ICLR paper to fully substantiate the claim, making it somewhat challenging for the authors to understand the exact nature of the comparison needed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" and suggests that the authors compare their proposed attack against the mode connectivity-based defense proposed in that paper. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s evaluation and suggests a specific comparison that could strengthen the work. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects to focus on, which limits its helpfulness. To be more helpful, the comment could include suggestions on how to structure the comparison or what metrics to use. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors' decision not to include the codes during the review process makes the claims less transparent. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve transparency. There is no guidance on whether the authors should include the codes, how they might do so, or what specific aspects of the claims need to be clarified. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' decision not to include the codes during the review process, suggesting that this choice makes the claims less transparent. However, it does not specify which claims are affected by this decision or which parts of the paper are less transparent due to the absence of codes. Without explicit references to specific sections or claims, the authors cannot confidently determine which parts need attention or improvement. The comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific about what needs to be addressed. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' decision not to include the codes during the review process makes the claims less transparent. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how it impacts the transparency of their claims. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the authors\\' decision not to include the codes during the review process, suggesting that this choice makes the claims less transparent. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the transparency of their claims. Without actionable feedback or detailed advice, the authors are left with a general observation that does not offer a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential weakness but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios compared to the current version. While the comment implies that the authors should conduct additional validation, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to implement this validation or what specific aspects should be tested. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests validating the proposed approach in Waymax, which provides more traffic scenarios compared to the current version. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting an additional validation approach but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios compared to the current version. However, the comment does not provide any supporting evidence or reasoning to justify why using Waymax would be beneficial or necessary. It lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable due to the absence of supporting information, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios compared to the current version. This feedback is somewhat helpful as it points out a potential limitation in the current experimental setup and encourages the authors to consider a broader validation. However, the comment lacks specificity and does not provide detailed guidance on how to implement this validation or what specific aspects should be tested in Waymax. While it offers a direction for improvement, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works like RTD-Net. It highlights the main difference between RTD-Net and the proposed method as the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The comment implies that the use of additional features, such as LMA, is not surprising and may not provide significant insights. However, the comment does not offer explicit guidance on how the authors could enhance the contribution or address the critique. The feedback lacks actionable steps or suggestions for improvement, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, specifically comparing it to previous works like RTD-Net and highlighting the use of additional features such as 3D pose and action features obtained by Laban Movement Analysis (LMA). However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the technical contribution and the use of additional features, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is not significant, suggesting that the transformer-based TAPG method has been studied in previous works like RTD-Net. It highlights the main difference between RTD-Net and the proposed method as the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer argues that while LMA has proven effective in dance action recognition, the addition of these features is not surprising and may not provide significant insights. This claim is somewhat verifiable as it references previous work and provides a logical reasoning for the critique. However, it lacks specific examples or detailed comparisons to fully substantiate the claim, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works like RTD-Net. It highlights the main difference between RTD-Net and the proposed method as the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The comment points out that while LMA has proven effective in dance action recognition, the addition of these features is not surprising and may not provide significant insights. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s contribution and suggests that the authors may need to provide more novel insights or features to enhance their work. However, the comment lacks specific guidance on how the authors might address this issue or improve their contribution, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more experimental comparisons regarding the different design choices of merging nodes among adjacent layers in the implementation of tree construction. While the comment implies a specific action\u2014conducting additional experiments\u2014it does not provide detailed guidance on how to carry out these experiments or what specific comparisons should be made. The action is explicit but somewhat vague, as the authors know they need to conduct more experiments but may not be entirely sure of the exact comparisons to make. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the implementation of tree construction and mentions the different design choices of merging nodes among adjacent layers. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment suggests the need for more experimental comparisons, but it lacks specificity regarding what specific comparisons are needed or how they should be conducted. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that more experimental comparisons are needed regarding the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, the comment does not provide specific examples, reasoning, or references to support why these comparisons are necessary or how they would improve the paper. Without additional context or justification, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the implementation of tree construction, specifically the need for more experimental comparisons regarding the different design choices of merging nodes among adjacent layers. This feedback is somewhat helpful as it points out a potential weakness in the paper and suggests a direction for further exploration. However, the comment lacks depth and does not provide detailed guidance or examples on how to conduct these comparisons or what specific aspects should be focused on. To be more helpful, the comment could include suggestions on what types of comparisons would be most beneficial or how to structure the experiments. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include additional baselines from the Re-BART paper in Table 2, even though these baselines have weaker results. This direct and specific suggestion provides clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies exactly which baselines to include and why, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of additional baselines from the Re-BART paper, even though their results are weaker. This provides clear guidance on what the authors need to do to improve the completeness of their table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete because it hides several baselines that outperform it. The reviewer supports this claim by referencing the Re-BART paper, where these baselines are reported. This provides a clear and specific reference to external work, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed information about the specific baselines or their performance relative to the paper\\'s results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete and hides several baselines that outperform it. The reviewer references the Re-BART paper, where these baselines are reported, and suggests that the authors include them for completeness, even though their results are weaker. This feedback is clear and actionable, providing the authors with a direct suggestion to improve the transparency and completeness of their results. By addressing this point, the authors can enhance the credibility and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to present these baselines or why their inclusion is important. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It implies that the authors should consider evaluating performance on other sequences. While the comment raises a valid point about the scope of the evaluations, it does not explicitly instruct the authors to expand their analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more sequences and determine which ones to choose. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation section of the paper, specifically questioning the choice of only three scenes from the HS-ERGB dataset. It suggests that the evaluations could be more thorough and asks about the performance on other sequences. This provides a clear indication of the part of the paper being addressed, making it fully grounded. The comment is also specific as it points out the limitation in the dataset selection and suggests an area for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the thoroughness of the evaluations on real datasets, specifically mentioning the choice of only three scenes from the HS-ERGB dataset. It suggests that the performance on other sequences should be considered. While the comment raises a valid point about the scope of the evaluations, it lacks specific examples or references to support the claim that the choice of scenes is insufficient. The reasoning is somewhat verifiable, as it highlights a potential gap in the evaluation process, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the thoroughness of the evaluations on real datasets. It questions the choice of only three scenes from the HS-ERGB dataset and suggests that the performance on other sequences should be considered. This feedback is clear and actionable, as it directs the authors to expand their evaluation to include more scenes or sequences, which could enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided additional guidance on how to select or evaluate these additional sequences. Overall, the comment is mostly helpful, as it effectively points out a limitation and offers a direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of 44 bits, suggesting that more bits could be used without significantly affecting computation time on GPU. It also questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words rather than their semantic relations. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they might need to explore the use of more bits or clarify the interpretation of bit-embeddings, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the use of 44 bits and the interpretation of bit-embeddings, suggesting that more bits could be used without significantly affecting computation time. It also questions the interpretation of bit-embeddings and the lack of semantic relations for words with odd ranks. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the current approach and the interpretation of bit-embeddings, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of 44 bits and the interpretation of bit-embeddings, suggesting that more bits could be used without significantly affecting computation time. It also questions the interpretation of bit-embeddings as predicting the rank of words rather than their semantic relations. However, the comment lacks specific evidence, examples, or references to support these claims. The reasoning is based on logical assumptions but does not provide detailed justification or evidence to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it requires more detailed explanation or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two specific concerns: the use of 44 bits and the interpretation of bit-embeddings. It suggests that more bits could be used without significantly affecting computation time, which is a valuable observation for the authors to consider. Additionally, it questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words rather than their semantic relations. This prompts the authors to reconsider how they interpret their results. However, the comment lacks specific suggestions or guidance on how to address these issues, such as proposing alternative methods or analyses. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but that the authors do not provide a solution for mitigation. While the comment identifies an issue, it does not offer explicit guidance or suggestions on how the authors might address this limitation or propose a solution. The action is implicit and vague, as the authors are left to infer that they should address this limitation but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the practical use of the method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It mentions that this limitation is discussed in the appendix but notes the absence of a solution for mitigation. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the appendix where this limitation is discussed. The comment is specific in detailing what needs to be addressed, namely the lack of a solution for mitigation. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practical use of the method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. The reviewer acknowledges that this limitation is mentioned in the appendix but notes the absence of a solution for mitigation. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of the appendix provides some context, but the comment could be strengthened with more detailed justification or suggestions for improvement. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires additional information for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a practical limitation of the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It acknowledges that this limitation is mentioned in the appendix but notes the absence of a solution for mitigation. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or mitigate its impact. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take: pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. These instructions are clear and concrete, giving the authors specific tasks to perform. The comment leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach for improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by proposing a method to pretrain a CausalLM using a specific dataset and comparing its performance against ObscuraCoder. This feedback is clear and offers a concrete approach for the authors to explore, which could help them attribute any improvements to the deobfuscation objective. However, the comment could be more helpful if it included additional context or rationale for why this approach might be beneficial or how it could enhance the paper\\'s contributions. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add the geometric loss to the reconstruction loss, rather than having it stand alone. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on how to modify the loss equation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines \"L264-L266,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of the geometric loss to the reconstruction loss. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the geometric loss should be added to the reconstruction loss, rather than standing alone. This claim is based on a specific observation about the loss equation in the paper, which is a factual statement. The comment does not express an opinion, judgment, or suggestion that requires verification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor issue with the loss equation, specifically suggesting that the geometric loss should be added to the reconstruction loss rather than standing alone. This feedback is clear and actionable, providing the authors with a specific correction to make in their draft. By addressing this point, the authors can improve the accuracy and clarity of their loss equation. However, the comment could be more helpful if it explained why this change is necessary or how it impacts the overall model. Despite this, the feedback is mostly helpful as it directly guides the authors on how to enhance their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and lacks concrete details, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where the method could be applied. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential application of the method but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this suggestion is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method should be applied to autoregressive language models, which are more commonly used in real-world applications. While this is a relevant point, the comment lacks specificity and actionable guidance. It does not explain why the method should be applied to autoregressive models or how this would benefit the paper. Without detailed suggestions or examples, the authors are left with a general idea but no clear direction for improvement. Therefore, the comment is barely helpful, as it identifies a potential area for enhancement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the proposed idea compared to GANs and the lack of explanation on how to avoid issues like vanishing gradients and model collapsing. While it highlights areas that need clarification, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and comparisons, but the comment does not specify what aspects to focus on or how to improve the clarity. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the difficulty of optimizing GANs and the proposed idea\\'s advantages over GANs. It also highlights the lack of explanation on how to avoid issues like vanishing gradients and model collapsing in the proposed method. However, the comment does not explicitly mention which part of the paper discusses these claims, making it weakly grounded. The authors can infer that it relates to the method section, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the proposed method\\'s advantages and the avoidance of issues like vanishing gradients and model collapsing. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the proposed method is better than GANs due to the difficulty in optimizing GANs and using adversarial gradient updating. The reviewer highlights the lack of clarity in the paper regarding how the proposed method addresses issues like vanishing gradients and model collapsing. While the comment identifies a gap in the explanation, it does not provide specific examples or references to support the claim or suggest how the authors could address these issues. This makes the claim somewhat verifiable, as it points out a gap but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s claims regarding the difficulty of optimizing GANs and the proposed method\\'s advantages over GANs. It highlights the lack of clarity in explaining how the proposed method addresses issues like vanishing gradients and model collapsing. While the comment points out important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their explanation. This limits the comment\\'s helpfulness, as it offers insight into weaknesses but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the design of the ablation study, specifically why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. While the comment raises a valid question, it does not provide explicit guidance or suggestions for the authors to address this issue. The authors are left to infer that they might need to justify or reconsider the choice of models for the ablation study. However, the comment lacks concrete details on how to implement any changes or improvements. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the models \"BART\" and \"BART+Longformer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of the ablation study, specifically why the ablations are conducted on these models instead of the original model, \"GraphSum.\" This provides clear guidance on what aspect of the study needs clarification or justification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design of the ablation study, specifically why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. This is a request for clarification rather than a subjective claim or opinion. It does not express an opinion or judgment that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the design of the ablation study, specifically why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. This is a relevant point that could help the authors clarify their experimental setup and justify their choices. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their study. While it prompts the authors to consider their experimental design, it lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the previous report of SciBERT was removed, which exacerbates an earlier problem in v1 regarding the cursory and unsupported analyses of model outcomes. However, the reviewer acknowledges that this is not a fair criticism because the current paper does not mention the previous report. The comment does not provide any explicit or implicit actions for the authors to take, such as suggesting how to address the earlier problem or how to incorporate the previous report into the current paper. Without actionable guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the removal of the previous report of SciBERT, which is a specific issue related to the paper. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the problem of cursory and unsupported analyses, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the removal of the previous report of SciBERT exacerbates an earlier problem in v1, where the analyses of model outcomes were cursory and unsupported by deeper analyses. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of explicit evidence or references renders the claim unverifiable, as it does not provide sufficient justification for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the removal of the previous report of SciBERT exacerbates an earlier problem in v1 regarding the cursory and unsupported analyses of model outcomes. However, the comment acknowledges that this is not a fair criticism because the current paper does not mention the previous report. While the comment highlights a potential weakness, it does not provide actionable feedback or suggestions for improvement. The authors are left with a general observation but no guidance on how to address the issue. Therefore, the comment is somewhat helpful, as it points out a potential problem but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the \"Functional connectivity encoder\" section, specifically questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and how they are mixed. While the comment identifies areas of confusion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but without specific guidance on what information to include or how to improve the clarity, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Functional connectivity encoder\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues, such as the unclear origin of the connectivity graph $\\\\cal{G}_{F}$ and the difficulty in discerning the source of patches and how they are mixed. This provides clear guidance on what needs to be clarified or improved in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the \"Functional connectivity encoder\" section, specifically questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion in the \"Functional connectivity encoder\" section, particularly regarding the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and how they are mixed. This feedback is clear and actionable, as it points out exact points of ambiguity that the authors need to clarify. By addressing these issues, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify these points or examples of what information should be included. Overall, the comment is mostly helpful, as it effectively directs the authors to specific areas needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that Figure 4(b) indicates faster training with the proposed method, noting that all networks are trained for the same number of epochs. It suggests that the paper would benefit from a longer discussion of related work in the field of pruning. While the comment implies that the authors should provide a more detailed discussion of related work, it does not explicitly instruct them to do so. Additionally, it does not offer specific guidance on how to improve the discussion or what aspects to focus on. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim that the proposed method results in faster training, noting that all networks are trained for the same number of epochs. Additionally, it suggests that the paper would benefit from a longer discussion of related work in the field of pruning. This provides clear guidance on what needs to be addressed or improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Figure 4(b) indicates faster training with the proposed method, noting that all networks are trained for the same number of epochs. The reviewer suggests that the paper would benefit from a longer discussion of related work in the field of pruning. While the comment provides some reasoning by pointing out the lack of evidence for the claim about faster training, it lacks specific examples or references to support the suggestion for a longer discussion of related work. This makes the claim somewhat verifiable, as it provides a basis for questioning the claim but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim made in Figure 4(b) regarding faster training with the proposed method. It points out that all networks are trained for the same number of epochs, which undermines the claim of faster training. This feedback is valuable as it challenges the authors to provide a more robust justification for their claim. Additionally, the comment suggests that the paper would benefit from a longer discussion of related work in the field of pruning, which is a constructive suggestion for expanding the context and depth of the paper. While the comment effectively highlights areas for improvement, it could be more helpful by providing specific guidance on how to address the issue or what aspects of related work should be discussed. Overall, the comment is mostly helpful, as it provides actionable feedback and a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific mathematical error in the paper, stating that the derivative of the \"Lagrangian\" is incorrect and providing the correct derivative of \\\\(n^{-1/2}\\\\). This feedback is clear and direct, giving the authors precise information on what needs to be corrected in their draft. The explicit nature of the comment and the concrete guidance on how to address the issue make it highly actionable. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"derivative of the \\'Lagrangian\\'\" and the specific issue with the derivative of \\\\(n^{-1/2}\\\\), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the derivative and provides the correct derivative, which is \\\\(-1/2n^{-3/2}\\\\). This level of detail helps the authors understand exactly what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the \"Lagrangian\" is incorrect, providing a specific correction for the derivative of \\\\(n^{-1/2}\\\\). This claim is fully verifiable as it is supported by a precise mathematical correction, which allows the authors to easily verify and address the issue. The clarity and specificity of the correction make the claim fully verifiable, justifying a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific mathematical error in the paper, pointing out that the derivative of the \"Lagrangian\" is incorrect. It provides a precise correction for the derivative of \\\\(n^{-1/2}\\\\), which is \\\\(-1/2n^{-3/2}\\\\), rather than \\\\(1/2n^{-3/2}\\\\). This feedback is clear, actionable, and directly addresses a technical issue in the paper, allowing the authors to make a specific correction. By pinpointing the error and offering a correction, the comment is highly helpful, as it empowers the authors to improve the accuracy and validity of their work. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction part of the paper lacks clarity regarding the background of cognitive models. It implies that the authors should refine their writing to improve clarity. However, the comment does not provide specific guidance on how to achieve this refinement or which aspects of the introduction need more detail. The action is implicit and vague, leaving the authors uncertain about how to address the feedback effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the introduction part of the paper lacks clarity regarding the background of cognitive models. However, it does not specify which sections or elements within the introduction are problematic or how they could be improved. The authors might infer that the issue lies in the background section, but this inference is not directly guided by the comment. Additionally, the comment lacks specificity regarding what aspects of the background need clarification or refinement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the introduction part of the paper lacks clarity regarding the background of cognitive models. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the authors should refine their writing, but without further elaboration, it is difficult for the authors to understand the exact issues or how to address them. This lack of detailed justification makes the claim borderline verifiable, as it provides some indication of a problem but lacks sufficient evidence or guidance for the authors to act upon.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a lack of clarity in the introduction section regarding the background of cognitive models. It suggests that the authors should refine their writing to improve the clarity of the introduction. However, the comment does not provide specific guidance on what aspects of the introduction are unclear or how the authors might enhance the clarity. Without detailed suggestions or examples, the feedback is limited in its usefulness to the authors. Therefore, it is rated as barely helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the performance of DFA and backpropagation on the NLP task, noting that DFA performance lags behind backprop performance. It suggests that this discrepancy is not sufficiently emphasized in the paper, particularly in the abstract, where it gives the impression that DFA performs at near-backprop levels. However, the comment does not provide explicit guidance on how the authors should address this issue, such as by adjusting the abstract or emphasizing the performance differences in the text. The action is implicit and somewhat vague, as it lacks specific instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLP task\" and the \"DFA performance,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that DFA performance lags behind backprop performance and that this discrepancy is not sufficiently emphasized in the paper, particularly in the abstract. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that DFA performance lags behind backprop performance on the NLP task, which is not sufficiently emphasized in the paper. The reviewer supports this claim by pointing out that the abstract gives the impression that DFA performs at near-backprop levels, which is misleading. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific data or examples of the performance discrepancy, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the performance of DFA on the NLP task lags behind backpropagation, which is not sufficiently emphasized in the paper. It points out that the abstract gives the impression that DFA performs at near-backprop levels, which is misleading. This feedback is clear and actionable, as it directs the authors to address the discrepancy in performance and ensure that their claims are accurately reflected in the paper. However, the comment could be more helpful if it provided suggestions on how to effectively communicate the performance differences or offered insights into potential reasons for the discrepancy. Overall, the comment is mostly helpful, as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It provides specific examples, such as SRW and FROT, that should be included as baselines. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The authors know exactly which baselines to include and why they are important, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the baseline and the dimensional reduction methods in optimal transport estimation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking in the baseline, namely the inclusion of SRW and FROT as baselines. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It provides specific examples, such as SRW and FROT, which should be included as baselines. This provides a clear and specific suggestion for improvement, making the claim mostly verifiable. However, the comment could be strengthened by explaining why these specific baselines are relevant or how they would enhance the study. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the lack of a comprehensive baseline for dimensional reduction methods in optimal transport estimation. It provides a clear and actionable suggestion by recommending the inclusion of SRW and FROT as baselines, which would help the authors strengthen their experimental setup. This feedback is valuable as it directs the authors to a concrete area for improvement, making it mostly helpful. However, it could be more helpful if it explained why these specific baselines are important or how they would enhance the study. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the advantage and disadvantage of transductive learning have not been discussed in the paper. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of transductive learning should be discussed or how the authors should present this information. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the advantage and disadvantage of transductive learning have not been discussed in the paper. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in identifying what is missing\u2014namely, a discussion on the advantages and disadvantages of transductive learning. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the advantage and disadvantage of transductive learning have not been discussed in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a gap in the paper by pointing out that the advantage and disadvantage of transductive learning have not been discussed. This is a relevant observation that could help the authors improve their draft by providing a more comprehensive analysis of the method. However, the comment lacks specific guidance or suggestions on how to address this issue, such as what aspects of transductive learning should be discussed or how to present this information. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. While it explicitly states an action, it does not provide specific guidance on how to formally state the invariance or what aspects need to be addressed. The authors are left with a clear direction but without detailed instructions on how to implement the suggestion. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for formalization of the invariance, but without clear grounding, the authors may struggle to identify where this change should be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, which is a specific and actionable piece of feedback. By identifying a particular area for improvement, the comment provides the authors with a clear direction on how to enhance their draft. However, it could be more helpful if it included additional details or examples on how to formally state the invariance, which would provide more comprehensive guidance. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the paper\\'s contribution and the significance of uncertainty saliency maps without an application or evaluation. The reviewer also disagrees with the claim that uncertainty or confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide specific guidance or suggestions on how the authors could address these concerns or improve their work. It lacks actionable details, such as recommending ways to demonstrate the significance of uncertainty saliency maps or suggesting alternative approaches to enhance the paper\\'s contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without an application or evaluation. It also expresses disagreement with the claim that uncertainty or confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the concerns regarding the contribution and the trustworthiness claim but does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the significance of uncertainty saliency maps without an application or evaluation, suggesting that the paper\\'s claims about the trustworthiness of uncertainty or confidence generated from the same mechanism are not substantiated. The reviewer expresses disagreement with the paper\\'s argument and states that it cannot be recommended for acceptance due to these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the paper\\'s arguments are flawed. This makes it difficult for the authors to understand the basis of the reviewer\\'s critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the potential contribution of uncertainty saliency maps, noting that their significance is unclear without an application or evaluation. It also expresses disagreement with the claim that uncertainty or confidence generated from the same mechanism is more trustworthy than the explanation itself. While the comment identifies a critical area for improvement\u2014providing an application or evaluation to demonstrate the significance of the contribution\u2014it does not offer specific suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it highlights a significant issue but lacks actionable advice, leaving the authors with a general direction but without detailed steps to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer and asks what it can provide that other methods cannot. While it highlights an area that could be explored or discussed in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should discuss or explore the benefits of using the diffusion model, and it is vague because it lacks concrete steps or examples on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of using the diffusion model in style transfer and asks what it can provide that other methods cannot. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its inquiry about the unique contributions of the diffusion model, but without clear grounding, the authors may struggle to identify where this discussion should be added or improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer and asks what it can provide that other methods cannot. However, it does not provide any supporting evidence, reasoning, or references to justify why this is an important issue or how it impacts the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the question and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the significance of using the diffusion model in style transfer, asking what it can provide that other methods cannot. This is a relevant point that could help the authors clarify the novelty and contribution of their work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue in their paper. While it identifies a potential area for improvement, it does not offer detailed advice or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion or comparison of the multi-view latent attack in the related work section, highlighting its similarity to task augmentation meta-learning methods. While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to structure the comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to add a discussion but may not be entirely sure of the exact details or how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also mentions that the multi-view training is similar to task augmentation meta-learning methods and recommends a discussion or comparison in the related work section. However, the comment does not specify which part of the paper should include this discussion or comparison, making it weakly grounded. The suggestion to discuss or compare is specific, but without clear grounding, the authors may struggle to identify where to make these additions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. The reviewer supports this claim by comparing the multi-view training to task augmentation meta-learning methods, suggesting that a discussion or comparison in the related work section would enhance understanding. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the cited methods to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the contribution of the multi-view latent attack in enhancing the model\\'s meta generalizability and its outperformance in the cross-domain setting. It also notes the similarity of multi-view training to task augmentation meta-learning methods, suggesting that a discussion or comparison in the related work section would enhance understanding. This feedback is mostly helpful as it provides a clear direction for the authors to improve their draft by including a discussion or comparison in the related work section. However, it could be more helpful if it offered specific examples or guidance on how to structure this discussion or comparison. Overall, the comment is actionable and provides valuable insight for enhancing the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether the authors should include these features in the ablation study, how they should analyze their impact, or any other actionable steps. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of study on the impact of Age and FaceID features in the ablation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these features should be analyzed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of Age and FaceID features should be studied or how they should be integrated into the ablation. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"the impact of Age and FaceID features is not studied in the ablation.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific gap in the paper, noting that the impact of Age and FaceID features is not studied in the ablation. This is a relevant observation that could help the authors improve their draft by addressing this omission. However, the comment lacks depth and does not provide suggestions on how to incorporate these features into the ablation study or why they are important. While it points out a potential area for improvement, it does not offer actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to move the discussion from the appendix to the main manuscript, providing a clear and direct action. It also questions the values in Table 2 and Fig. 5, suggesting that the authors clarify what these values represent. While the comment does not provide specific guidance on how to clarify the values, it does specify that the discussion should be moved to the main manuscript. This makes the action mostly actionable, as the authors know what needs to be done but may need to infer the details of clarifying the values.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the values in these tables and figures and suggests moving the discussion from the appendix to the main manuscript. This provides clear guidance on what needs to be addressed and improved. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inclusion of Table 2 and Fig. 5 in the ablation study and suggests moving the discussion from the appendix to the main manuscript. However, it does not provide any specific reasoning or evidence to support why this change is necessary or how it would improve the manuscript. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, it is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that Table 2 and Fig. 5 are not mentioned in the main text and questioning the values presented in these tables. It also suggests moving the discussion from the appendix to the main manuscript, providing a clear and actionable recommendation for improvement. This feedback is valuable as it directs the authors to clarify the content and structure of their paper, ensuring that important information is not overlooked. However, the comment could be more helpful if it provided additional context or reasoning for why the discussion should be moved, or if it offered suggestions on how to integrate the content more effectively. Overall, the comment is mostly helpful, as it provides actionable guidance that can enhance the clarity and coherence of the manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include more experiments with different LLMs, specifically mentioning llama-3-70B and Mistral-7B. This provides a clear and direct action for the authors to take, as they know exactly which additional experiments to conduct to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Lorta method\" and the \"introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more LLM-related results in the experiments. The comment suggests specific LLMs like llama-3-70B and Mistral-7B that should be included, providing clear guidance on what additional experiments are expected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should include more experiments with different LLMs, specifically mentioning llama-3-70B and Mistral-7B. The claim is based on the stated purpose of the Lorta method, which is to solve the problem of efficient finetuning of LLMs. However, the comment lacks specific reasoning or evidence to support why these particular LLMs should be included or how they would contribute to the study. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a general expectation but lacks the necessary depth to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it provides a clear expectation for the authors regarding the scope of experiments in their paper. It highlights the need for more experiments with different LLMs, specifically mentioning llama-3-70B and Mistral-7B, which are relevant to the focus of the paper. This feedback is actionable, as it guides the authors to expand their experimental section to include additional LLMs, thereby enhancing the comprehensiveness and relevance of their study. However, the comment could be more helpful if it offered additional context or rationale for why these specific LLMs are important or how they might impact the results. Overall, the feedback provides valuable direction for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the performance of DFSDT for other types of LLMs not in the category of LLaMA / GPT / Claude. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The feedback lacks specificity and actionable steps, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) and its performance compared to ReAct prompting. It mentions the related techniques of self-consistency + CoT and Tree-of-thoughts, which provides some context. However, the comment does not specify which part of the paper discusses DFSDT or where these comparisons are made, making it weakly grounded. The comment is specific in its critique, as it questions the performance of DFSDT for other types of LLMs not in the category of LLaMA / GPT / Claude. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also questions the performance of DFSDT for other types of LLMs not in the category of LLaMA / GPT / Claude. However, the comment lacks specific references or detailed reasoning to substantiate these claims. Without explicit examples or comparisons to support the assertions, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, making it challenging to fully verify the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed \"Depth First Search-based Decision Tree\" (DFSDT) by pointing out its close relationship to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the generalizability of DFSDT to other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment highlights important considerations for the authors, it lacks specific suggestions or guidance on how to address these concerns or improve the novelty and applicability of the proposed method. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more beneficial with additional direction or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of acknowledging contributions, particularly when proposing an identical method while claiming originality. However, it does not provide specific guidance on how the authors should address this issue, such as suggesting ways to properly acknowledge the contributions or recommending specific actions to take. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggested improvements. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights an issue with the acknowledgment of contributions, specifically regarding the use of an identical method while claiming originality. However, it does not specify which part of the paper this issue pertains to, such as a particular section or reference where the method is discussed. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. The comment is specific in its critique of the acknowledgment of contributions but lacks grounding as it does not direct the authors to a specific section or context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method while claiming originality, suggesting that acknowledging contributions is important. However, the comment does not provide specific examples or references to support this claim, nor does it elaborate on why this practice is considered inappropriate. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment highlights an important issue regarding the acknowledgment of contributions, particularly in the context of proposing an identical method while claiming originality. It emphasizes the importance of proper attribution and the ethical implications of not acknowledging prior work. However, the comment lacks specific guidance or suggestions on how the authors can address this issue, such as recommending ways to properly acknowledge the contributions or suggesting alternative approaches to differentiate their work. While it identifies a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of MMV compared to XDC and its fully-supervised baseline. It asks the authors to explain why MMV did not exceed its fully-supervised baseline, while XDC outperformed its baseline, and whether MMV\\'s better performance is due to its backbone architecture. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and consider the role of the backbone architecture. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific performance comparisons between XDC and MMV, as well as their respective fully-supervised baselines. It raises a question about the performance differences and suggests a potential reason for them, namely the use of a better backbone architecture. However, the comment does not explicitly mention which sections or results these comparisons are based on, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in its inquiry about the performance differences and the potential role of the backbone architecture, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance differences between XDC and MMV, noting that XDC outperformed its fully-supervised baseline but MMV did not. The reviewer asks for an explanation and suggests a potential reason, namely the use of a better backbone architecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the suggestion. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the question and explore it further. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance differences between XDC and MMV, noting that XDC outperformed its fully-supervised baseline but MMV did not. It also points out that MMV shows better performance than XDC. The comment prompts the authors to explain the reasons behind these performance differences, suggesting a potential explanation related to the use of a better backbone architecture. This feedback is somewhat helpful as it identifies a specific area for further exploration and analysis, encouraging the authors to provide a deeper understanding of their results. However, the comment could be more helpful if it offered specific suggestions or guidance on how to investigate or address the issue. Overall, the comment provides some insight but lacks comprehensive guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant issue with the paper, noting that the writing is verbose and difficult to follow, and suggests that it resembles an implementation paper more than a theoretical or general advancement. The reviewer explicitly recommends focusing on a main idea or two and providing analyses on why they work, rather than emphasizing a well-engineered system with many functions. This feedback provides a clear and direct action for the authors to take, specifying what needs to be improved and how to approach it. The suggestion is concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides a general critique of the paper\\'s writing style, describing it as verbose and difficult to follow. It suggests that the paper resembles an implementation paper more than a theoretical or general advancement. However, it does not specify which sections or parts of the paper are particularly verbose or difficult to follow, nor does it provide specific guidance on how to improve the clarity or focus of the paper. Without explicit references to sections or detailed suggestions, the authors may struggle to identify and address the issues effectively. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is verbose and difficult to follow, suggesting that the paper resembles an implementation paper more than a theoretical or general advancement. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to particular sections or aspects of the paper, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the writing is verbose and difficult to follow, which detracts from its theoretical or general advancement. It suggests that the paper resembles an implementation paper more than a theoretical or general advancement. The reviewer provides a clear and actionable suggestion to focus on a main idea or two and demonstrate why they work, rather than emphasizing a well-engineered system with many functions. This feedback is valuable as it guides the authors to streamline their content and improve the clarity and focus of their paper. However, it could be more helpful if it included specific examples or suggestions on how to achieve this focus. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks the provision of code and supplementary documentation, which would enhance clarity and reproducibility. It clearly suggests that providing these resources would be beneficial for the reader. The action is direct and concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the lack of code and supplementary documentation, which is a specific issue that could enhance clarity and reproducibility. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that these resources are missing, but the comment does not provide explicit grounding to a specific section or element of the paper. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the need for additional resources. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks code and supplementary documentation, which would enhance clarity and reproducibility. This claim is somewhat verifiable as it logically suggests that providing such resources would improve the paper. However, the comment does not provide specific examples or references to support the claim, such as similar papers that include these resources or the impact they have on reproducibility. This lack of detailed justification or examples makes it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of code and supplementary documentation, which could enhance clarity and reproducibility. It provides a clear and actionable suggestion for improvement by recommending the inclusion of these resources. This feedback is valuable as it directly addresses a critical aspect of the paper that could significantly benefit the reader\\'s understanding and ability to replicate the methodology. However, the comment could be more helpful if it offered specific guidance on how to present the code or documentation, such as suggesting formats or platforms. Overall, the comment is mostly helpful as it highlights a key area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss and empirically compare ensembles and uncertainty estimation in the context of offline reinforcement learning (RL), specifically mentioning the use of random ensembles (REM) to outperform DQN/naive ensembling in the offline setting. While the comment implies that the authors should include this discussion and comparison, it does not provide specific guidance on how to conduct the empirical comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address this topic but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation,\" allowing the authors to identify the relevant part of the paper. It also specifies the issue by suggesting that the authors should discuss and empirically compare ensembles and uncertainty estimation in the context of offline reinforcement learning (RL), particularly mentioning the use of random ensembles (REM) to outperform DQN/naive ensembling. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles have been studied in the context of offline reinforcement learning (RL) and that random ensembles (REM) outperform DQN/naive ensembling in the offline setting. The reviewer supports this claim by referencing a specific study on discrete Atari games, which provides a clear basis for the assertion. However, the comment could be strengthened by including more detailed information about the study or its findings, such as specific performance metrics or comparisons. Despite this, the reference to a specific study makes the claim mostly verifiable, as it provides a solid foundation for the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper related to ensembles and uncertainty estimation in the context of offline reinforcement learning (RL). It references prior work on random ensembles (REM) and their performance in offline settings, suggesting that this should be discussed and empirically compared in the paper. This feedback is actionable, as it provides a clear direction for the authors to enhance their work by incorporating relevant literature and conducting comparisons. However, the comment could be more helpful if it offered specific guidance on how to conduct the empirical comparison or discussed potential challenges in implementing this approach. Overall, the comment provides valuable insights and a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses an impression that the combination of methods lacks novelty, but it does not provide any explicit or implicit actions for the authors to take. It does not offer guidance on how the authors might address this concern or suggest ways to enhance the novelty of their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second paragraph of the introduction\" and the \"proposed methodology,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the combination of methods lacks novelty, providing a clear direction for the authors to address. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the combination of methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to what constitutes novelty in the context of the paper, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment expresses a concern about the perceived lack of novelty in the combination of methods, referencing the author\\'s statements in the introduction and the proposed methodology. However, it does not provide specific examples or detailed feedback on how the authors could address this issue or enhance the novelty of their work. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed approach, suggesting that it may require a different model to be fine-tuned for each target language. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the scalability or suggest alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed approach, specifically questioning whether a different model needs to be fine-tuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the potential scalability issue and the need for fine-tuning models for each language. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scalability of the proposed approach, suggesting that it may require a different model to be fine-tuned for each target language. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the concern or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed approach, specifically questioning whether a different model needs to be fine-tuned for each target language. This is an important consideration for the authors to address, as it could impact the practical applicability and efficiency of their method. However, the comment lacks specific suggestions or guidance on how the authors might address this scalability issue or improve their approach. While it identifies a potential weakness, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional details should be provided for readers unfamiliar with bAbI or question answering in relation to Eq.20. It also asks for clarification on what \"valid words\" mean in the context of the equation. While the comment implies that the authors should add more details and clarification, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement by specifying what needs to be addressed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that additional details should be provided for readers unfamiliar with bAbI or question answering, and it clarifies what \"valid words\" mean in the context of the equation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that additional details should be provided for readers unfamiliar with bAbI or question answering, specifically regarding the meaning of \"valid words\" in Eq.20. While the comment identifies a potential area for improvement, it does not provide specific reasoning or evidence to support why this additional detail is necessary or how it would benefit the readers. The suggestion is somewhat verifiable, as it highlights a potential gap in clarity but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where additional details could be beneficial for readers unfamiliar with bAbI or question answering. It suggests that more information should be provided to clarify what \"valid words\" mean in the context of Eq.20. This feedback is clear and actionable, as it directly points out a potential source of confusion and offers a specific suggestion for improvement. By addressing this comment, the authors can enhance the clarity and accessibility of their paper for a broader audience. However, the comment could be more helpful if it provided examples or further elaboration on what additional details would be most useful. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the idea of interested-region-based adversarial attacking is not novel, as it has been proposed earlier by Yao et al. in 2019. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how this information should be used to improve the draft, such as suggesting ways to differentiate the current work from the prior research or how to address the lack of novelty. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the \"interested-region-based adversarial attacking\" by referencing an earlier work by Yao et al. However, it does not specify which part of the paper this critique is based on, such as a particular section or discussion where this idea is presented. Without explicit references to the paper\\'s content, the authors cannot confidently determine which parts need attention or improvement. The comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific because it lacks details on how the current work compares to the referenced work. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the idea of \"interested-region-based adversarial attacking\" is not novel, as it has been proposed earlier by Yao et al. in 2019. This claim is supported by referencing a specific work, which provides a clear and explicit reference to substantiate the assertion. The inclusion of a specific citation allows the authors to verify the claim and understand the basis of the critique. Therefore, the comment is categorized as fully verifiable, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment points out that the idea of interested-region-based adversarial attacking is not novel, as it has been proposed earlier by Yao et al. in 2019. While this information is relevant, the comment does not provide any constructive feedback or suggestions on how the authors might address this issue or differentiate their work from the prior research. It lacks actionable advice or guidance on how to improve the draft, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed methods are comprised of well-known effective components, which may not contribute significantly to the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the significance of their contribution or what specific changes could be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this feedback. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, which may not contribute significantly to the paper. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on which components are considered well-known or how they might be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing attention or improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of well-known effective components, which may not contribute significantly to the paper. However, the comment does not provide specific examples of these components or detailed reasoning to support the claim. Without concrete evidence or references to the well-known components, the claim remains vague and difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, which may not contribute significantly to the paper. However, it does not provide specific examples of these components or offer constructive feedback on how the authors might enhance the significance of their contribution. Without actionable suggestions or detailed guidance, the comment lacks utility for the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with data leakage in the dataset due to the inclusion of multi-turn data and publicly available history conversations. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to mitigate the risk of data leakage or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to improve their draft based on this comment. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of data leakage in the dataset, specifically mentioning the inclusion of multi-turn data and publicly available history conversations. However, it does not specify which part of the paper discusses the test set or the dataset, making it weakly grounded. The comment is specific in identifying the issue of data leakage and its potential impact on the dataset, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the test set includes multi-turn data and publicly available history conversations, which could lead to data leakage when used for training models. This claim is somewhat verifiable as it provides a logical reasoning that data leakage is a potential issue due to the nature of the dataset. However, the comment lacks specific examples or references to substantiate the claim further, such as detailed explanations of how the data leakage occurs or how it affects the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with data leakage in the dataset, specifically mentioning the inclusion of multi-turn data and publicly available history conversations. This is a relevant concern that could impact the validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the risk of data leakage. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an important issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, given that TTUR improves the performance of VSD. While the comment implies that the authors should consider including a comparison with VSD + TTUR, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the comparison or what specific aspects should be considered. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests a comparison with VSD + TTUR to enhance the paper\\'s convincingness. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. The claim is somewhat verifiable as it references an external work (DMD2) and suggests a specific comparison that could strengthen the paper. However, the comment lacks detailed reasoning or evidence from the DMD2 paper to fully substantiate the claim, making it somewhat challenging for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, given that TTUR improves the performance of VSD. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by including a comparison that could strengthen its claims. However, the comment could be more helpful if it offered additional guidance on how to implement this comparison or why it is important. Overall, the comment is mostly helpful, as it identifies a potential area for improvement and provides a clear direction for the authors to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the merit of the theoretical result presented in the paper, given that the authors define out-of-distribution (OOD) actions as those not drawn from \\\\hat{\\\\pi}{\\\\beta}(.,|s) but assume in Assumption 3.1 that \\\\hat{\\\\pi}_{\\\\beta}(a|s) > 0, implying no OOD actions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the theoretical result. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and assumptions in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the merit of the theoretical result presented in the paper, given the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the merit of the theoretical result presented in the paper, given the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. The reviewer provides a logical reasoning by pointing out a potential contradiction between the definition and the assumption, which could undermine the theoretical result. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical result presented in the paper, specifically questioning the merit of the conservative estimate of quantiles when the assumption of no out-of-distribution (OOD) actions is made. This is an important point that could impact the validity and applicability of the paper\\'s findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their assumptions. While it highlights a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a significant concern but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the analysis provided in the paper is shallow and lacks clear takeaways or conclusions. It implies that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it advises that essential details in the appendix, such as dataset splitting justifications, should be integrated into the main text. While the comment provides some guidance on what the authors should consider, it lacks specific instructions on how to improve the analysis or integrate the appendix details into the main text. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the analysis provided in the paper, describing it as shallow and lacking clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it advises that essential details in the appendix, such as dataset splitting justifications, should be integrated into the main text. While the comment provides specific feedback on what needs to be addressed, it does not explicitly mention which sections or parts of the paper contain the shallow analysis or the appendix details. The authors can infer the relevant sections, but the comment lacks full grounding. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper provides a \"shallow linguistic dataset analysis\" without clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it advises that essential details in the appendix, such as dataset splitting justifications, should be integrated into the main text. While the comment provides some reasoning by suggesting that the analysis lacks depth and clarity, it does not offer specific examples or references to support the claim. The suggestion to move the analysis to the appendix is based on a logical reasoning, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the linguistic dataset analysis is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, the comment provides a constructive suggestion to integrate essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, offering the authors specific guidance on how to improve the structure and clarity of their paper. However, it could be more helpful if it provided additional suggestions on how to enhance the analysis or what specific insights could be drawn from it. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of clarity in the metric of Table 1 and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the metric in Table 1 and provide the missing experimental details, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the metric of Table 1 and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the metric used in Table 1 and the lack of experimental details such as backbone choice, learning rate, and optimization schedules. While it identifies specific areas that need clarification, it does not provide detailed reasoning or examples to support why these details are crucial or how their absence affects the interpretation of the results. The comment is somewhat verifiable as it highlights important aspects that need attention, but it lacks the depth and specificity needed to fully substantiate the claim. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the experimental results section: the lack of clarity in the metric used in Table 1 and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. This feedback is clear and actionable, as it directs the authors to provide more detailed information about their experimental setup and results. By addressing these points, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested how to present this information or why it is important. Overall, the feedback is mostly helpful, as it provides clear guidance on areas needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not leverage the advantage of POMDPs, which is the assumption that the decision-maker does not directly observe the target variable Y. It suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, since only outcomes are observed when the positive decision is given. While the comment identifies a specific area for improvement, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they need to discuss the impact of previous decisions on observable data, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the assumption of POMDPs regarding the decision-maker not directly observing the target variable Y and critiques the paper for not leveraging this advantage. It suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, since only outcomes are observed when the positive decision is given. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where discussions about POMDPs or decision-making processes are located, the comment lacks full grounding. It is specific about the issue of not leveraging the advantage of POMDPs but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, which is the assumption that the decision-maker does not directly observe the target variable Y. The reviewer suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, since only outcomes are observed when the positive decision is given. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the paper does not address this aspect. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the critique themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by pointing out that the advantage of POMDPs, which is the assumption that the decision-maker does not directly observe the target variable Y, is not leveraged in the paper. It suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, since only outcomes are observed when the positive decision is given. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work by addressing a critical aspect of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this discussion into the paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the pretraining tokens_per_sample being too small (256) and suggests that batch_size=64 for pretraining might not be sufficient. However, it does not provide explicit guidance on what the authors should do to address these issues. The comment implies that the authors should consider increasing these parameters, but it lacks concrete suggestions on how to determine appropriate values or what specific changes should be made. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"pretraining tokens_per_sample\" and \"batch_size,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by stating that the current settings are too small and may not be sufficient for a regular-size program. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pretraining tokens_per_sample is too small (256) and suggests that batch_size=64 for pretraining might not be sufficient. However, the comment lacks specific reasoning or evidence to support these claims. It does not provide details on why these settings are inadequate or how they impact the results. Without additional context or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pretraining parameters, namely the small number of tokens_per_sample (256) and the batch_size of 64. It suggests that these settings might not be sufficient for a regular-size program. While the comment highlights a potential weakness, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The feedback points out a concern but does not offer a clear path for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of ablation experiments in the paper, suggesting that the authors should conduct more experiments to help readers understand the proposed method. It provides specific examples of what could be explored, such as replacing the clustering algorithm with other approaches like K-Means and testing the model\\'s performance on different-sized descendant models. While the comment implies that these experiments should be conducted, it does not explicitly instruct the authors to do so. However, the concrete examples provided give a clear direction for the authors to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights a lack of ablation experiments in the paper, suggesting that more experiments are needed to help readers understand the proposed method. It provides specific examples of what could be explored, such as replacing the clustering algorithm with other approaches like K-Means and testing the model\\'s performance on different-sized descendant models. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Despite this, the comment is specific in detailing what additional experiments could be conducted. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples, such as replacing the clustering algorithm with other approaches like K-Means and testing the model\\'s performance on different-sized descendant models. These examples offer a clear direction for additional experiments that could enhance the paper\\'s comprehensiveness. However, the comment does not reference any specific studies or literature that support the need for these experiments, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks detailed evidence or references. This aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of sufficient ablation experiments to help readers understand the proposed method. It provides specific examples of what could be explored, such as replacing the clustering algorithm with other approaches like K-Means and testing the model\\'s performance on different-sized descendant models. This feedback is clear and actionable, offering the authors concrete steps to enhance the comprehensiveness and robustness of their experimental analysis. By addressing these points, the authors can significantly improve the clarity and depth of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks and recommends comparing it against the proposed interaction modules and many-to-many formulation for all tasks. While the comment explicitly states the need for this comparison, it does not provide detailed guidance on how to implement it or what specific aspects should be focused on. The action is explicit but somewhat vague, as the authors know they need to make this comparison but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks and recommends comparing it against the proposed interaction modules and many-to-many formulation for all tasks. It explicitly mentions Table 1, which provides some grounding by indicating the part of the paper where the comparison is currently made. However, it does not specify which other tasks should be compared, leaving the authors to infer additional comparisons. The comment is specific in suggesting the need for a more comprehensive comparison but lacks full grounding as it does not explicitly mention other sections or tasks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks and criticizes the current comparison in the paper. The reviewer provides a logical reasoning by explaining that comparing against the vanilla transformer may not fully capture the benefits of the proposed interaction modules and many-to-many formulation. However, the comment lacks specific examples or references to support the claim that the Talking Heads Transformer is the most relevant baseline. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by recommending that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper. It highlights the importance of comparing the proposed interaction modules and many-to-many formulation against this baseline, rather than against the vanilla transformer, to better gauge the benefits of the proposed approach. This feedback is valuable as it directs the authors to a specific comparison that could significantly enhance the paper\\'s evaluation and understanding of the proposed method. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or suggested specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using the HI-MIA dataset, which is recorded in a real-time environment with noise setup and microphone array, for benchmarking speaker identification. This is an explicit suggestion, as it directly instructs the authors to include a specific dataset in their evaluation. However, the comment does not provide detailed guidance on how to integrate this dataset into the study or what specific aspects to focus on. While the action is clear, the lack of detailed instructions makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests checking the HI-MIA dataset and benchmarking speaker identification on it, referencing a scenario that is simulated and mentioning datasets like HI-MIA. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular dataset for benchmarking, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the scenario is simulated and proposes using the HI-MIA dataset for benchmarking speaker identification. The comment references a specific dataset, HI-MIA, and mentions that it is recorded in a real-time environment with noise setup and microphone array. This provides some support for the suggestion, but it lacks detailed reasoning or examples of how using this dataset would improve the study. The reference to HI-MIA is a starting point, but more detailed justification or examples would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires additional information for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider using the HI-MIA dataset for benchmarking speaker identification, as it is recorded in a real-time environment with noise setup and microphone array. This feedback is somewhat helpful as it provides a specific suggestion for improving the experimental setup, which could enhance the validity and applicability of the study. However, the comment could be more helpful if it explained why using this dataset is important or how it would impact the results. Additionally, it lacks detailed guidance on how to integrate this dataset into the study. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the framing of the paper, particularly in the Introduction, may not be appropriate. It points out that while the Introduction focuses on breast cancer, the paper and its contributions are not specifically focused on breast cancer. The comment implies that the paper should be framed to emphasize the loss function and its applications to semantic segmentation networks, rather than being centered on breast cancer. However, it does not provide explicit guidance on how to reframe the paper or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary changes without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting an alternative framing that focuses on the loss function and its applications, rather than solely on breast cancer. This provides clear guidance on what aspect of the framing could be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the framing of the paper, particularly in the Introduction, may not be appropriate. It notes that while the Introduction focuses on breast cancer, the paper and its contributions are not specifically focused on breast cancer. The comment provides a logical reasoning by pointing out that the paper evaluates the loss function over multiple datasets, including breast cancer and others, and that the primary contribution is a loss function applicable to any semantic segmentation network. Additionally, it mentions that the loss function can be extended to solve other problems in semantic segmentation, such as handling distribution shifts. This reasoning is clear and provides a basis for the suggestion of an alternative framing. However, the comment could be strengthened by referencing specific examples or studies where this framing has been successful. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a thoughtful critique of the paper\\'s framing, specifically noting that while the Introduction focuses on breast cancer, the paper\\'s contributions are not solely focused on breast cancer. It points out that the paper evaluates the loss function over multiple datasets, including breast cancer and others, and that the primary contribution is a loss function applicable to any semantic segmentation network. The comment suggests an alternative framing that emphasizes the loss function and its applications, which could be more appropriate for the paper\\'s scope. This feedback is clear and actionable, offering a specific direction for reorienting the paper\\'s focus to better align with its contributions. However, it could be more helpful if it provided additional guidance on how to implement this framing change. Overall, the comment is mostly helpful, as it effectively directs the authors toward a more appropriate framing of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the inclusion of agreement statistics for the corpus in section 3.1 or 3.2. This is a clear and direct action for the authors to take, providing them with a specific task to improve their draft. The comment is concrete, as it specifies exactly what needs to be added and where, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1 or 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of agreement statistics for the corpus. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for agreement statistics for the corpus in section 3.1 or 3.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional data, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion for improving the paper. By requesting the inclusion of agreement statistics for the corpus in section 3.1 or 3.2, the reviewer offers a clear direction for enhancing the draft. This feedback is valuable as it guides the authors to provide additional data that could strengthen their analysis and presentation. The specificity of the suggestion ensures that the authors know exactly what needs to be added, making it highly beneficial for improving the draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point discusses the novelty of the paper, specifically mentioning the use of LLMs and the concept of cross-trajectory chaining. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the concerns raised or improve the novelty of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the novelty of the paper, specifically mentioning the use of LLMs and the concept of cross-trajectory chaining. It provides some context by referencing existing LLMs and the inspiration from goal-conditioned RL approaches. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is somewhat specific in its critique of the novelty, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point discusses the novelty of the paper, specifically mentioning the use of LLMs and the concept of cross-trajectory chaining. It acknowledges that the use of existing LLMs might not be novel but highlights the novelty of cross-trajectory chaining, noting that its techniques are inspired by goal-conditioned RL approaches. The comment provides a logical reasoning by referencing existing literature, such as Chebotar et al., 2021, to support the claim. However, it could be more fully verifiable by providing more detailed comparisons or examples of how the techniques are similar or different. Therefore, the comment is categorized as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses the novelty of the paper, specifically mentioning the use of LLMs and the concept of cross-trajectory chaining. It acknowledges that the use of existing LLMs might not be novel but highlights the novelty of cross-trajectory chaining, noting that its techniques are inspired by goal-conditioned RL approaches. However, the comment lacks specific guidance or suggestions on how the authors could enhance the novelty of their work or differentiate it from existing approaches. While it provides some insight into the novelty aspect, it does not offer actionable feedback or detailed advice for improvement. Therefore, the comment is somewhat helpful, as it identifies a potential area for enhancement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It suggests that more discussion is needed on this topic. While the comment implies that the authors should provide additional discussion, it does not explicitly instruct them to do so or specify what aspects should be covered. The action is implicit and somewhat vague, as the authors are left to infer the need for more discussion without clear guidance on how to approach it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It suggests that more discussion is needed on this topic. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for more discussion on the identity mapping and its implications, but without clear grounding, the authors may struggle to identify where this discussion should be integrated. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional discussion. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is purely factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the identity of the attention map and its potential to enhance the expressive power of the attention module. It suggests that more discussion is needed on this topic, which is a valuable point for the authors to consider. However, the comment lacks specific guidance or suggestions on how to conduct this discussion or what aspects should be explored. While it identifies an area for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explain why they are considering decoder-only transformers in line 235. This is a clear and direct action, providing the authors with a specific task to address in their draft. The comment is concrete, as it specifies exactly what needs to be done\u2014provide an explanation for the choice of decoder-only transformers. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests an explanation for the consideration of decoder-only transformers, providing clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the choice of decoder-only transformers. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests an explanation for the consideration of decoder-only transformers, which is a specific and actionable piece of feedback. By asking for clarification, the reviewer prompts the authors to provide additional context or justification for their choice, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present this explanation or why it is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the qualitative analysis lacks important details, such as the proportion of each error category. It implies that the authors should include more fruitful thoughts or speculations about the underlying causes of observed issues and potential ways to mitigate them. The comment references a specific paper, [Turpin et al.], which could provide insights or examples for the authors to consider. While the action is not explicitly stated, it is clear and concrete, as the authors can infer that they need to add more detailed analysis and potentially draw on the referenced work for guidance. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the qualitative analysis section, specifically mentioning the lack of details about the proportion of each error category. It suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of observed issues and potential ways to mitigate them. The comment references a specific paper, [Turpin et al.], which could provide insights or examples for the authors to consider. However, it does not explicitly mention which part of the qualitative analysis is lacking, making it weakly grounded. The comment is specific in suggesting what could be improved, such as including more detailed analysis and speculations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the qualitative analysis lacks important details, such as the proportion of each error category. It suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of observed issues and potential ways to mitigate them. The comment references a specific paper, [Turpin et al.], which could provide insights or examples for the authors to consider. However, the comment does not provide specific examples or detailed reasoning from the paper itself, making it somewhat verifiable. The authors would need to explore the referenced work to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the qualitative analysis, noting the absence of important details such as the proportion of each error category. It suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of observed issues and potential ways to mitigate them. The comment references a specific paper, [Turpin et al.], which could provide insights or examples for the authors to consider. This feedback is clear and actionable, as it guides the authors on how to enhance their analysis and contribute more effectively to the field. However, it could be more helpful if it provided specific suggestions or examples of how to incorporate the referenced work into the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should empirically validate the claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete, small data by applying these methods to data filled by simple methods. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to address the concern. The suggestion is concrete, as it outlines a specific approach to validate the claim. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, where the authors discuss the applicability of Reinforcement Learning, RNNs, and Wasserstein GANs to their proposed approach. It also references a specific baseline comparison with a Markov chain approach from Klausen et al. (2018b). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests a way to empirically validate the claim that these methods are not suitable for incomplete, small data by applying them to data filled by simple methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete, small data. The reviewer suggests that the authors could empirically validate this claim by applying these methods to data filled by simple methods. This provides a logical reasoning for the claim, suggesting a method to test it. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the suggestion to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to empirically validate their claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete, small data. It proposes a method for the authors to test this claim by applying these methods to data filled by simple methods. This feedback is clear and actionable, offering a concrete way for the authors to address the concern raised in the paper. By suggesting a specific empirical validation, the comment empowers the authors to improve their draft by providing a direct path to strengthen their argument. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of baseline comparison in the paper, specifically noting that the G-EVAL method is based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompt for these LLMs. The reviewer suggests comparing this performance with the G-EVAL method. While the comment implies an action\u2014adding a baseline comparison\u2014it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The authors can infer the need for additional comparisons, but the lack of concrete steps or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"G-EVAL method\" and its reliance on GPT-3.5 and GPT-4, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of baseline comparison using the simplest prompt for these LLMs and comparing it with the G-EVAL method. This provides clear guidance on what the authors need to consider or add to their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the G-EVAL method lacks a baseline comparison by not demonstrating its performance using the simplest prompt for GPT-3.5 and GPT-4, and then comparing it with the G-EVAL method. This claim is somewhat verifiable as it logically suggests that a baseline comparison would provide a more comprehensive evaluation of the method. However, the comment does not provide specific examples or references to support the claim, such as similar studies or established practices in the field. This lack of detailed justification or evidence makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of baseline comparison for the G-EVAL method. It highlights the need to demonstrate the performance of GPT-3.5 and GPT-4 using the simplest prompt and compare it with the G-EVAL method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including a baseline comparison. However, the comment could be more helpful if it suggested how to implement this comparison or provided examples of similar studies that have successfully incorporated baseline comparisons. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed explanation of the requirements for updating weights in multiagent environments, specifically mentioning the need for expected rewards or NE gaps for different perturbations. It also highlights the difference between this process and the base policies, which only use observed rewards. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this information should be integrated into the paper or suggestions for improvement. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to updating weights in multiagent environments, specifically mentioning the need for expected rewards or NE gaps for different perturbations. It highlights the difference between this process and the base policies, which only use observed rewards. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the requirements for updating weights and the implications of computing NE gaps. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the requirements for updating weights in multiagent environments, specifically mentioning the need for expected rewards or NE gaps for different perturbations. The reviewer provides a logical explanation by contrasting this process with the base policies, which only use observed rewards. Additionally, the comment highlights the requirement for knowledge of other agents\\' policies to compute NE gaps. This reasoning is clear and provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed explanation of the requirements for updating weights in multiagent environments, specifically mentioning the need for expected rewards or NE gaps for different perturbations. It highlights the distinction between this process and the base policies, which only use observed rewards. Additionally, it points out the requirement for knowledge of other agents\\' policies to compute NE gaps. This feedback is clear and provides the authors with a deep understanding of the complexities involved in their approach. However, while it identifies a potential issue, it does not offer specific suggestions or guidance on how to address it. Therefore, the comment is somewhat helpful, as it provides valuable insights but lacks actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether this comparison is sufficient, if additional comparisons are needed, or how the authors might improve the comparison. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper primarily compares the proposed methods with DiffUCO. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison are inadequate or how it could be improved. Without explicit references or detailed feedback, the authors cannot effectively address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a factual statement about the paper\\'s comparison with DiffUCO. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a brief observation that the paper primarily compares the proposed methods with DiffUCO. However, it lacks depth and specificity, as it does not elaborate on why this comparison is significant, what insights it provides, or how it could be improved. Without additional context or guidance, the authors are left without actionable feedback to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, the absence of a complete proof of the claimed equivalence, and the superficial nature of the exposition. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The feedback lacks actionable details, such as recommending how to improve the exposition or what specific aspects of the proof need to be clarified. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution section of the paper, specifically focusing on the value decomposition and the claim of equivalence between the local policy product and the globally optimal policy. It critiques the paper for being too repetitive and superficial in its exposition of the decomposition method, noting the lack of explicit definitions and relationships between local subtasks and their corresponding policies. However, the comment does not specify which parts of the paper are overly repetitive or where the definitions and relationships are missing, making it challenging for the authors to pinpoint the exact areas needing improvement. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what is missing or unclear. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is too repetitive and superficial in its exposition of the decomposition method, and it lacks explicit definitions and a complete proof of the claimed equivalence. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of concrete evidence or references to specific sections of the paper makes the claim borderline verifiable, as it requires significant effort from the authors to identify and rectify the issues. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, specifically regarding the contribution section. It points out that the paper is too repetitive and superficial in its exposition of the decomposition method, lacking explicit definitions of local subtasks and their corresponding policies, as well as a complete proof of the claimed equivalence. This feedback is valuable as it highlights specific areas where the paper is lacking in clarity and depth, providing the authors with clear directions for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of what a complete proof might entail. Despite this, the feedback is mostly helpful as it directs the authors to critical areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of a performance curve for each algorithm during training. This is an explicit request for the authors to include this information, which is clear and actionable. The comment provides a specific action for the authors to take, namely adding the performance curve for each algorithm during training. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out the absence of a performance curve for each algorithm during training. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the performance curves should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of performance curves are missing or how they should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"the performance curve of each algorithm during the training is missing.\" However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific omission in the paper, namely the absence of a performance curve for each algorithm during training. This is a clear and actionable piece of feedback that can help the authors improve their draft by ensuring that all relevant performance data is included. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a computational expense associated with the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which has a time complexity of O(N^2) for large-scale graphs. However, the comment does not provide any explicit or implicit suggestions for addressing this issue, such as alternative methods, optimizations, or trade-offs that could be considered. Without actionable guidance or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed Gaussian kernel-based graph construction method, specifically the computational expense of computing the full adjacency matrix and its time complexity. This provides clear guidance on what aspect of the method is problematic. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the computational expense of the proposed Gaussian kernel-based graph construction method, specifically noting the requirement to compute the full adjacency matrix and its time complexity of O(N^2) for large-scale graphs. This claim is supported by logical reasoning, as the statement about the time complexity is based on a well-known fact about adjacency matrix computation. However, the comment could be strengthened by providing additional context or references to similar methods or studies that address this issue. Therefore, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. This is a relevant observation that could impact the practicality and scalability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as alternative methods, optimizations, or trade-offs that could be considered. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy between the results presented in Table 2e and the default method used in Eq. (5). It suggests that the authors should reconsider their choice of default method, as case (3) achieves better performance for most widths. The reviewer provides a clear rationale for this suggestion, questioning the justification for using case (1) by default. This feedback is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the results shown in Table 2e and the default method used in Eq. (5). The comment provides a clear rationale for questioning the authors\\' explanation and suggests that all sub-networks with different widths should be equally important. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' choice of default method in Eq. (5), suggesting that case (3) achieves better performance for most widths. The reviewer provides a specific example by referencing Table 2e, which shows the results of the four cases of loss reweighting. This provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' choice of default method in Eq. (5), which conflicts with the results shown in Table 2e. It points out that case (3) achieves better performance for most widths, questioning the rationale behind using case (1) by default. The comment provides a clear and actionable suggestion for improvement by questioning the authors\\' explanation and suggesting that all sub-networks with different widths should be equally important. This feedback is valuable as it directs the authors to reconsider their methodology and provides a logical basis for doing so. However, the comment could be more helpful if it offered additional guidance on how to address this issue or suggested alternative approaches. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and provides a clear direction for the authors to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the paper for claiming to address a specific issue (fine-tuning multiplicity in tabular LLMs) but finding that the main results are general and do not leverage the unique characteristics of tabular data or LLMs. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their work. It lacks actionable guidance, such as recommending specific ways to incorporate tabular data or LLM characteristics into the results or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the exploration of fine-tuning multiplicity in tabular LLMs. It critiques the paper for claiming to address a specific issue but finding that the main results are general and do not leverage the unique characteristics of tabular data or LLMs. This provides a clear indication of what the authors need to address, making the comment specific. However, the comment does not explicitly mention which part of the paper this critique is based on, such as specific sections or results. The authors can infer that it relates to the main results or conclusions, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its critique. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the paper\\'s claim by stating that the main results are general and do not leverage the unique characteristics of tabular data or LLMs, making them irrelevant to the paper\\'s scope. The comment provides a logical reasoning by contrasting the claim with the actual results, suggesting a mismatch between the paper\\'s claims and its findings. However, it lacks specific examples or references to support the claim that the results are general or irrelevant. This makes the comment somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that while it claims to address a specific topic (fine-tuning multiplicity in tabular LLMs), the main results are general and do not leverage the unique characteristics of tabular data or LLMs. This critique highlights a disconnect between the paper\\'s claims and its actual contributions, which is crucial for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might better align their results with the paper\\'s scope or incorporate the unique characteristics of tabular data and LLMs. While it points out a critical weakness, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the manuscript. It questions the summation notation and asks for clarification on the function \\\\( f(\\\\cdot) \\\\) in the line above equation 3. Additionally, it suggests comparing the manuscript to existing works like TailorNet and Patel et al. 2021, and asks for details on the challenges of simulating multiple layers versus single-layered clothing. While the comment raises important points, it does not provide explicit actions or concrete guidance on how to address these issues. The authors are left to infer that they should clarify the notation, compare their work to existing literature, and provide details on the challenges of simulating multiple layers. However, the lack of explicit instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 3\" and the line above it, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the summation notation and asking for clarification on the function \\\\( f(\\\\cdot) \\\\). Additionally, it suggests comparing the work to existing works like TailorNet and Patel et al. 2021 and requests details on the challenges of simulating multiple layers. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the manuscript, such as the summation notation and the function \\\\( f(\\\\cdot) \\\\) in the line above equation 3. It also references existing works like TailorNet and Patel et al. 2021 and asks for details on the challenges of simulating multiple layers. These are factual observations and requests for clarification, not subjective claims or opinions. Therefore, the review point does not contain any claims and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions and observations that could help the authors improve their draft. It questions the summation notation and asks for clarification on the function \\\\( f(\\\\cdot) \\\\) in the line above equation 3, which is crucial for understanding the methodology. Additionally, it suggests comparing the work to existing works like TailorNet and Patel et al. 2021, which use PBS to drape garments on human bodies, and asks for details on the challenges of simulating multiple layers versus single-layered clothing. This feedback is mostly helpful as it identifies specific areas for clarification and comparison, providing the authors with actionable steps to enhance their manuscript. However, it could be more helpful if it offered more detailed guidance on how to address these issues. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a confusion in the theoretical analysis, specifically questioning the use of the supremum in Definition 1 and how it relates to the proposed GRADE. The reviewer asks for clarification on the definition and how it impacts the proof of the proposed GRADE. While the comment highlights an area of confusion, it does not provide explicit instructions or concrete steps for the authors to address the issue. The authors are left to infer that they need to clarify the definition and its implications, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of the supremum in the definition and how it relates to the proposed GRADE. This provides clear guidance on what needs to be clarified or addressed in the theoretical analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical analysis, specifically questioning the use of the supremum in Definition 1 and how it relates to the proposed GRADE. The comment does not make a subjective claim or suggestion but rather seeks clarification and understanding. It is a request for information and does not require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the theoretical analysis, specifically questioning the use of the supremum in Definition 1 and how it relates to the proposed GRADE. It raises a pertinent question about the proof of the proposed GRADE, which is crucial for understanding the theoretical foundations of the work. However, the comment does not provide any suggestions or guidance on how the authors might clarify or address this confusion. While it highlights an important issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether performance drops on these samples. This is an explicit suggestion, as it clearly states what additional information should be included in the draft. However, it does not provide concrete guidance on how to conduct this analysis or what specific metrics to use, leaving some room for interpretation. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples and asks whether performance drops on these samples. However, it does not specify which part of the paper should include this analysis or where the current results and analysis are located. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in suggesting what additional analysis could be beneficial, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results and analysis on lengthy dialogue samples to assess whether performance drops. However, it does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it might impact the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including results and analysis on lengthy dialogue samples to assess whether performance drops. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment provides a useful suggestion but lacks depth and actionable details, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the datasets used in the paper only contain the visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. The reviewer provides specific references to support this suggestion, which adds to the actionability of the comment. However, while the suggestion is clear, the comment does not explicitly instruct the authors to include these modalities or provide detailed guidance on how to implement this change. Therefore, the comment is mostly actionable, as it provides a concrete suggestion but leaves some details to be inferred by the authors.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the paper only contain the visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. It provides specific references to support this suggestion, which adds to the specificity of the comment. However, the comment does not explicitly mention which part of the paper discusses the datasets, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the datasets used in the paper only contain the visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. The reviewer supports this claim by referencing three external works that discuss the importance of including multiple modalities in evaluation. These references provide a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that the datasets used only contain the visual modality and suggests that including more natural modalities, such as audio and visual, would lead to better evaluation. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by expanding the modalities considered. The comment is further strengthened by referencing relevant literature, which offers a solid foundation for the suggestion. However, the comment could be more helpful if it provided additional guidance on how to incorporate these modalities or discussed the potential impact of doing so. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to existing works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. This implies that the authors should include a discussion of these related works to provide context and differentiate their model from existing ones. However, the comment does not explicitly instruct the authors to make this addition, and it lacks specific guidance on how to integrate the discussion or what aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and existing works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper this comparison should be made, making it weakly grounded. The comment is specific in pointing out the omission of discussing these related works, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to existing works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. This claim is somewhat verifiable as it provides a logical comparison and references specific works that could be relevant. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as how the models are similar or how their inclusion would enhance the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the paper, noting that the oracle-context model is similar to existing works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models, yet these works are not discussed in the paper. This feedback is valuable as it highlights a gap in the literature review or context provided by the authors, which could help situate their work within the existing body of research. However, the comment does not offer detailed guidance on how to incorporate these references or discuss them effectively, nor does it suggest specific aspects of the existing works that could be relevant to the authors\\' work. While it points out an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived limitation in the paper, noting that it only discusses observed phenomena without providing deeper insights into how these observations could be used to design better resilient systems. The reviewer suggests a potential action by asking whether a proposed defense method could be joined with a hierarchical system to demonstrate the usefulness and significance of the observed results. While the comment implies a specific direction for further exploration, it does not provide concrete steps or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper for only discussing observed phenomena without providing deeper insights into how these observations could be used to design better resilient systems. It suggests a potential direction for further research by asking whether a proposed defense method could be joined with a hierarchical system to demonstrate the usefulness and significance of the observed results. However, the comment does not specify which part of the paper this critique is based on, nor does it provide detailed guidance on how to address the issue. The authors might infer that it relates to the discussion or conclusions sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential direction for further research. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only discusses observed phenomena without providing deeper insights into how these observations could be used to design better resilient systems. The reviewer suggests a potential direction for further research by asking whether a proposed defense method could be joined with a hierarchical system to demonstrate the usefulness and significance of the observed results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the paper does not provide sufficient insights. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks the necessary evidence or explanation to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it only discusses observed phenomena without providing deeper insights into how these observations could be used to design better resilient systems. The reviewer suggests a potential direction for further research by asking whether a proposed defense method could be joined with a hierarchical system to demonstrate the usefulness and significance of the observed results. This feedback is somewhat helpful as it points out a gap in the paper and offers a specific suggestion for improvement. However, it lacks detailed guidance or examples on how to implement this suggestion, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the authors aim to evaluate reliability or trust by examining what LLMs \"know,\" but it notes the absence of rigorous definitions. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The feedback lacks concrete details on what definitions should be included or how the evaluation should be structured. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of rigorous definitions related to evaluating reliability or trust by examining what LLMs \"know.\" However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for rigorous definitions but does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors aim to evaluate reliability or trust by examining what LLMs \"know,\" but it lacks rigorous definitions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a lack of rigorous definitions related to evaluating reliability or trust by examining what LLMs \"know.\" This is a relevant observation that could help the authors improve their draft by clarifying their approach and ensuring that their definitions are robust and well-defined. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing potential definitions or methodologies for evaluation. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse, as well as its potential impact on computational efficiency. While these questions imply that the authors should address these issues, they do not explicitly instruct them to do so or provide specific guidance on how to investigate or resolve these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should explore these questions further. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse, as well as its potential impact on computational efficiency. However, it does not specify which part of the paper these questions pertain to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the necessity and impact of masked self-attention and ProbSparse, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and further explanation regarding the use of masked self-attention in the Y-Future encoder and the preference for ProbSparse. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse, as well as its potential impact on computational efficiency. These questions prompt the authors to consider and justify their design choices, which could lead to a more robust and efficient model. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for further exploration, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the theoretical analysis are missing. The comment leaves the authors without clear direction on how to improve their draft, making it unactionable. Without concrete steps or examples, the authors are unable to determine what changes are needed to enhance their theoretical analysis. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion where this analysis should be included. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. The comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking.\" However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the critique or how to address it. As a result, the claim is unverifiable, making it difficult for the authors to improve their work based on this feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper lacks theoretical analysis, specifically regarding why deep layer parameters are more suitable for distillation. This is a relevant observation that could help the authors improve their theoretical foundation. However, the comment does not provide any suggestions or guidance on how to address this issue or what specific aspects of the theoretical analysis are missing. Without actionable feedback or detailed advice, the authors may struggle to determine how to enhance their theoretical analysis. Therefore, the comment is somewhat helpful, as it points out a weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that many important details are in the appendix, suggesting that the paper is not sufficiently self-contained. However, it does not provide explicit guidance on how to address this issue or what specific details should be included in the main text. The action is implicit, as the authors can infer that they need to move important details from the appendix to the main text, but the comment lacks concrete instructions on which details to prioritize or how to effectively integrate them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a concern about the paper\\'s self-containment, noting that important details are in the appendix. However, it does not specify which details are missing or which sections of the paper are affected by this issue. This lack of specificity makes it difficult for the authors to identify and address the problem effectively. Additionally, the comment does not provide grounding as it does not mention specific sections, figures, or tables, leaving the authors to infer the relevant parts. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a lot of the important paper details are in the appendix,\" suggesting that the paper is not sufficiently self-contained. However, the comment lacks specific examples or references to the details that are missing or where they should be included in the main text. This makes the claim somewhat verifiable, as it provides a general critique but lacks detailed justification or evidence to support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a significant issue with the paper\\'s structure, noting that important details are relegated to the appendix, which makes the paper less self-contained. This is a critical observation that can impact the paper\\'s accessibility and comprehensibility. However, the comment lacks specific guidance on which details should be moved from the appendix to the main text or how to effectively integrate them. While it points out a clear area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the argument for using gradient descent methods for clustering and notes that the largest dataset used is about 50K points. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this observation is a concern, if it needs addressing, or how the authors might improve their approach to handle larger datasets. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the argument for using gradient descent methods for clustering and notes that the largest dataset used is about 50K points. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment also lacks specificity regarding what needs to be addressed or improved, such as suggestions for handling larger datasets or alternative methods. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the argument for using gradient descent methods for clustering and notes that the largest dataset used is about 50K points. However, it questions whether this dataset size is \"large enough,\" implying that the authors might need to consider larger datasets for their argument to be fully convincing. The comment lacks specific reasoning or evidence to support the claim that 50K points are insufficient, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is borderline verifiable, as it provides some insight but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment acknowledges the argument for using gradient descent methods for clustering and notes that the largest dataset used is about 50K points. However, it questions whether this dataset size is \"large enough\" for the argument to be fully convincing. While the comment identifies a potential limitation in the dataset size, it does not provide specific suggestions or guidance on how the authors might address this issue or what alternative approaches or datasets could be considered. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions, specifically questioning the difficulty of overloading the library with ASD subroutines. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the clarity or justification of the assumptions. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"assumption 3.2,\" which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the assumption is problematic or how it could be improved. It raises a question about the practicality of the assumption but does not provide specific guidance or suggestions for addressing the issue. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the practicality of the assumptions, specifically mentioning \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any supporting evidence, reasoning, or examples to justify why this assumption might be problematic or impractical. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions, specifically questioning the difficulty of overloading the library with ASD subroutines. While it identifies a potential issue, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the clarity of their assumptions. Without actionable feedback or detailed advice, the authors are left with only a vague understanding of the problem, limiting the utility of the comment. Therefore, it is rated as barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the methodology used is commonly employed in data augmentation, suggesting a lack of novelty or excitement. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting alternative methodologies or ways to enhance the novelty of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the methodology used is commonly employed in data augmentation, implying a lack of novelty or excitement. However, it does not specify which part of the paper this observation pertains to, such as a particular section or experiment where the methodology is discussed. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the methodology are considered common or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the methodology used is \"commonly used in data augmentation,\" suggesting a lack of novelty or excitement. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the methodology used is commonly employed in data augmentation, suggesting a lack of novelty or excitement. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the paper, pointing out that some statements are incorrect. It provides a direct example by referencing section 4 and Fig. 4, where the authors claim that multi-image IMP significantly improves the quality of LIPs in the cross-domain setting. However, the reviewer notes that Fig. 4 shows that multi-IMP performs essentially the same as others. This feedback is explicit and provides a clear action for the authors to correct the incorrect statement in their paper. The comment is highly actionable as it gives precise guidance on what needs to be revised.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the statement in section 4 is incorrect, as the results in Fig. 4 show that multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically mentioning a statement in section 4 regarding the results presented in Fig. 4. The reviewer provides a specific example by stating that the multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting, as shown in Fig. 4. This claim is supported by a direct reference to the figure, which provides a clear basis for the assertion. The comment is mostly verifiable as it offers a specific example and reference to support the claim, but it could be further strengthened with additional reasoning or evidence. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, pointing out that some statements are incorrect. It provides a clear example by referencing section 4 and Fig. 4, where the authors claim that multi-image IMP significantly improves the quality of LIPs in the cross-domain setting. However, the reviewer notes that the results in Fig. 4 show that multi-IMP performs essentially the same as others. This feedback is actionable as it directs the authors to correct the inaccurate statement in their paper. By addressing this point, the authors can improve the accuracy and credibility of their claims. Therefore, the comment is mostly helpful, as it provides clear guidance for improvement but could be more comprehensive by suggesting how to revise the statement or provide additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not outperform existing methods, as evidenced by its rank in the VLN Leaderboard. However, it does not provide specific guidance on how the authors might improve their method to achieve better results. The comment references existing methods but does not suggest ways to incorporate their approaches or address the identified shortcomings. Without concrete actions or suggestions, the authors are left without clear direction on how to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the rank in the VLN Leaderboard, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results of the proposed method are not better than existing methods, and it provides references to specific works ([1,2,3]) for comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not outperform existing methods, as evidenced by its rank in the VLN Leaderboard. It supports this claim by referencing specific existing methods ([1,2,3]) and providing citations to these works. This detailed comparison and the inclusion of references make the claim fully verifiable, as it provides a clear basis for the reviewer\\'s assertion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment highlights a significant issue with the paper, noting that the proposed method does not outperform existing methods, as evidenced by its rank in the VLN Leaderboard. It provides specific references to existing methods that have achieved better results, which is valuable for the authors to consider. However, the comment lacks depth and does not offer actionable suggestions or guidance on how the authors might improve their method to achieve better results. While it identifies a critical area for improvement, it does not provide detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide specific guidance on what aspects of the discussion are lacking or how the authors could improve it. The feedback is vague and lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 2.2,\" which allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. However, the comment lacks specificity as it does not detail what aspects of the discussion are not convincing or how the modeling of semantic similarity could be improved. Without specific guidance or examples, the authors may struggle to understand what changes are needed to enhance the discussion. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the discussion in section 2.2, noting that it is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it lacks depth and does not provide any guidance or suggestions on how the authors might improve this section or clarify their explanation. Without actionable feedback or specific advice, the authors are left with only a vague understanding of what needs to be addressed. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to reliably estimate with limited real-world observations. It suggests that modeling these parameters as time-varying further complicates the estimation process. The comment explicitly instructs the authors to discuss the uncertainty in fitted parameter values and to provide a sensitivity analysis. This feedback is clear and provides specific actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of over 10 parameters being difficult to estimate reliably and suggests that modeling these parameters as time-varying exacerbates the challenge. Additionally, it provides a clear action for the authors to discuss the uncertainty in fitted parameter values and conduct a sensitivity analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to reliably estimate with limited real-world observations. The comment further highlights the challenge of modeling these parameters as time-varying, which exacerbates the estimation issue. The suggestion to discuss the uncertainty in fitted parameter values and provide a sensitivity analysis is a logical recommendation to address the identified problem. However, the comment lacks specific examples or references to support the claim about the difficulty of estimation, making it somewhat verifiable. The authors would benefit from more detailed evidence or examples to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to reliably estimate with limited real-world observations. It highlights the additional challenge of modeling these parameters as time-varying, which further complicates the estimation process. The comment provides a clear and actionable suggestion for the authors to discuss the uncertainty in fitted parameter values and conduct a sensitivity analysis. This feedback is valuable as it directs the authors to address a critical aspect of their model's reliability and estimation challenges. However, the comment could be more helpful if it offered specific methods or approaches for conducting the sensitivity analysis, which would provide even more detailed guidance. Overall, the comment is mostly helpful, as it effectively identifies a key area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the assumption that causal parameters across domains are random samples and questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC test. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, such as recommending specific analyses or modifications to test the assumptions or performance. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the assumption that causal parameters across domains are random samples and questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC test. However, it does not specify which part of the paper these concerns pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while the comment provides some specific questions about the assumptions and performance, it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be valid due to the absence of latent confounders. The reviewer also raises concerns about the reliability of the proposed method and the relative performances of MC, IB, and HSIC test, questioning the trustworthiness of the results if the parameters are not known to change. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The reasoning is somewhat logical but lacks the necessary evidence or explanation to fully substantiate the claims, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the assumption that causal parameters across domains are random samples, questioning its validity in the absence of latent confounders. It also highlights the potential dependence of the proposed method\\'s performance on the changing parameters across domains, questioning the reliability of the results if the parameters are unknown. While the comment identifies important issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it prompts the authors to reconsider their assumptions and the robustness of their method, but it could be more beneficial with additional actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the structural optimization method and notes that it is unclear whether it is new or not. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending ways to clarify the novelty or suggesting alternative approaches to strengthen the narrative. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the structural optimization method and suggests that it is unclear whether it is new or not. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the concern about the novelty of the method, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it is unclear whether it is new or not. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the structural optimization method, questioning whether it is indeed new or not. It also points out that the method is mentioned in the paper title, which could weaken the narrative. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or clarify the novelty of their work. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proof, specifically that the assumption may not be correct due to the possibility of generating mixed samples with a lambda value of 0.5 in standard mixup. However, it does not provide explicit guidance on how the authors should address this issue or suggest any specific actions to take. The comment lacks concrete details on how to resolve the problem or improve the proof, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the proof, specifically the assumption that lambda cannot be 0.5. This allows the authors to identify the part of the paper being discussed, making it fully grounded. The comment is also specific as it clearly specifies the issue with the assumption and its implications for the proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof requires lambda not to be 0.5, but in standard mixup, mixed samples can be generated with lambda being 0.5. This claim is somewhat verifiable as it provides a logical reasoning that the assumption in the proof may not be correct due to the possibility of generating mixed samples with a specific value of lambda. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically the assumption that lambda cannot be 0.5. It points out that in standard mixup, mixed samples can be generated with lambda being 0.5, which may invalidate the assumption in the proof. This feedback is somewhat helpful as it highlights a critical area that needs clarification or correction in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the proof. To be more helpful, the comment could include recommendations on how to resolve the discrepancy or provide examples of how to strengthen the proof. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests highlighting which set of equations have the same form as the Riccati equation, which is a clear and concrete action. Second, it recommends extracting some of the inlined math into environments to facilitate symbol lookup, also providing a specific page where this could be applied. These suggestions are direct and offer clear guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paragraph above Theorem 3.1\" and \"page 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests highlighting which set of equations have the same form as the Riccati equation and recommends extracting some inlined math into environments to facilitate symbol lookup. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and suggestions for improvement, such as highlighting specific equations and extracting math into environments. It does not contain subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting two improvements. First, it asks the authors to highlight which set of equations have the same form as the Riccati equation, which could enhance the clarity and understanding of the theoretical content. Second, it recommends extracting some of the inlined math into environments to facilitate symbol lookup, particularly on page 6. This feedback is clear and constructive, offering the authors concrete steps to improve the readability and accessibility of their manuscript. By addressing these suggestions, the authors can enhance the overall quality and usability of their draft. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain sections of the paper could benefit from clearer structure and transitions, and it provides a specific example of a subjective term, \"significant,\" that could be clarified with statistical evidence. While the comment identifies areas for improvement, it does not provide detailed guidance on how to achieve these improvements, such as specific suggestions for restructuring or examples of how to incorporate statistical evidence. The action is explicit but somewhat vague, as the authors know they need to improve clarity but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the clarity in writing, specifically mentioning that certain sections would benefit from clearer structure and transitions. It also provides an example of a subjective term, \"significant,\" which could be clarified with statistical evidence. However, it does not specify which sections or lines are problematic, making it weakly grounded. The comment is specific in suggesting how to improve clarity, such as using statistical evidence to support subjective terms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that certain sections of the paper lack clarity in structure and transitions, and it provides a specific example of a subjective term, \"significant,\" which could be clarified with statistical evidence. While the comment identifies areas for improvement, it does not provide detailed examples or references to support the claim about the need for clearer structure or the use of statistical evidence. This makes the claim somewhat verifiable, as it offers a direction for improvement but lacks comprehensive justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement: clarity in writing and the use of subjective terms. It suggests that certain sections could benefit from clearer structure and transitions, which is a specific and actionable piece of feedback. Additionally, it provides a concrete example of a subjective term, \"significant,\" and suggests that it could be clarified with statistical evidence, such as p-values. This guidance is clear and actionable, offering the authors a direct path to enhance the clarity and rigor of their writing. However, the comment could be more helpful if it provided additional examples or detailed suggestions for restructuring the sections. Overall, the feedback is mostly helpful as it effectively directs the authors toward specific improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of detailed information regarding graph construction, specifically mentioning the definition of edges and the construction of graphs for non-Euclidean datasets. While the comment identifies a specific area that needs attention, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they need to include this information, but without detailed guidance, the action remains somewhat vague. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of detailed information regarding graph construction, specifically mentioning the definition of edges and the construction of graphs for non-Euclidean datasets. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this information should be included. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what information is missing. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"the detailed information for graph construction is missing,\" specifically mentioning the definition of edges and the construction of graphs for non-Euclidean datasets. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the detailed information for graph construction, particularly for non-Euclidean datasets. It highlights the absence of information on defining edges and constructing graphs, which is crucial for understanding the methodology. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations in this area. However, the comment could be more helpful if it suggested specific aspects of graph construction that need to be addressed or provided examples of how to present this information. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$ are determined. It references a specific paper by En-Hui Yang et al. that might provide insights or guidance on this topic. While the comment implies that the authors should clarify or justify their hyper-parameter settings, it does not explicitly instruct them to do so or provide concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about their hyper-parameter selection process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hyper-parameters $\\\\alpha$ and $\\\\beta$, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking how the default settings for these hyper-parameters are determined, providing a clear direction for the authors to address. The comment further references a specific paper, which adds context and potential guidance for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$ are determined. It does not contain any subjective claims, opinions, or suggestions that require verification. The reference to a specific paper is included for context but does not influence the classification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. It references a specific paper that might provide insights or guidance on this topic, which could be helpful for the authors. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue in their paper. While it points out an area for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the visual or textual representations used in each method presented in Table 4. It suggests that without this information, it is unclear whether the end-to-end performance gain is due to the proposed attention model. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the visual or textual representations used in each method, which is crucial for understanding the end-to-end performance gain. This specificity helps the authors understand what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the visual or textual representations used in each method presented in Table 4. It suggests that without this information, it is unclear whether the end-to-end performance gain is due to the proposed attention model. While the comment identifies a potential gap in the explanation, it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it somewhat verifiable, as the authors would need to infer the importance of this information and address it themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the visual or textual representations used in each method presented in Table 4. It highlights the need for clarity on whether the end-to-end performance gain is due to the proposed attention model or other factors. This feedback is clear and actionable, as it points out a critical aspect of the paper that needs clarification. By addressing this point, the authors can improve the transparency and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of what might be missing. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper and the appendix, as well as specific problems with the proof. It points out that notations like D,G are not clearly presented, the assumption about $\\\\alpha_k$ converging to $\\\\alpha$ is missing, and Eq. (15) is not well justified. While the comment highlights multiple areas that need improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to clarify the convergence analysis and improve the proof, but without specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the convergence analysis and the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the convergence analysis, such as the lack of clarity in the main part, the simple proof in the appendix, and the unclear presentation of notations like D,G. Additionally, it points out missing assumptions and the lack of justification for Eq. (15). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the convergence analysis is unclear and lacks sufficient detail in the main part of the paper. It supports this claim by pointing out specific issues, such as the lack of clarity in the proof, the absence of certain notations, and the missing presentation of assumptions like $\\\\alpha_k$ converging to $\\\\alpha$. While the comment identifies specific areas of concern, it does not provide detailed examples or references to support the claim fully. The authors are given a general direction to improve the clarity of the convergence analysis, but the comment could be strengthened with more specific examples or references. Therefore, the claim is mostly verifiable, as it provides a reasonable basis for the critique but lacks comprehensive evidence or detailed guidance.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the convergence analysis, noting that it is unclear and lacks sufficient detail in the main part of the paper. It points out that the authors provide only a simple proof in the appendix, which is not related to the convergence analysis in the main part. Additionally, the comment highlights specific issues with the proof, such as the lack of clarity in presenting notations like D,G, the absence of a presentation of the assumption that $\\\\alpha_k$ converges to $\\\\alpha$, and the lack of justification for Eq. (15). This feedback is mostly helpful as it clearly identifies areas where the authors need to improve their analysis and presentation, providing specific examples of what needs to be addressed. However, it could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how to present the convergence analysis more effectively. Overall, the comment is mostly helpful, as it directs the authors to critical areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the study, including insufficient description of uncertainty calibration and the need for better organization and summary of the studied issues. However, it does not provide specific guidance on how to address these issues or what changes should be made to improve the clarity and organization. The feedback is vague and lacks concrete steps for the authors to follow, leaving them uncertain about how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the study\\'s problems, specifically mentioning the insufficient description of uncertainty calibration and the need for better organization and summary of the studied issues. However, it does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be improved, such as the description of uncertainty calibration and the organization of studied issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the studied problems are not well-driven and illustrated, specifically mentioning the insufficient description of uncertainty calibration. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, it is difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed justification makes the claim borderline verifiable, as it provides some insight but insufficient evidence to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically regarding the clarity and organization of the studied problems. It points out that the description of uncertainty calibration is insufficient, which could be challenging for new readers to understand. Additionally, it suggests that the studied issues, such as small datasets, heterogeneous data distribution, uncertainty calibration, and new clients, should be better organized and summarized. While the comment highlights important areas for improvement, it lacks specific suggestions or examples on how to achieve these improvements. The feedback is somewhat helpful as it provides a general direction for enhancing the clarity and organization of the paper, but it could be more actionable with detailed guidance. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. While it identifies a gap in the experimental analysis, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including such an exploration, but it lacks concrete details on how to implement it or what specific aspects to focus on. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not specify which part of the paper this omission pertains to, such as specific sections or experiments where these results could be included. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in identifying the missing aspect of the paper\u2014exploring the incorporation of PAC-tuning with other fine-tuning techniques. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide any supporting evidence, reasoning, or references to justify why this exploration is necessary or how it would benefit the paper. The comment lacks detailed explanation or examples that would help the authors understand the importance of this omission or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the experimental results by pointing out the absence of exploration into the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. This feedback highlights an area where the paper could be improved by expanding its experimental analysis. However, the comment does not provide specific suggestions or guidance on how the authors might incorporate these additional techniques or what specific outcomes to expect. While it offers a direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into an area for enhancement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the experimental analysis is insufficient and suggests that it should be validated on more models. However, it does not provide specific guidance on which models should be used or how to validate the analysis. The comment refers to a question below, but without access to that question, the authors are left without concrete steps to take. The action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the experimental analysis is insufficient and suggests that it should be validated on more models. However, it does not specify which part of the paper this critique pertains to, such as specific sections or experiments. Additionally, it does not provide details on what aspects of the analysis are insufficient or how the validation on more models should be conducted. Without specific references or detailed guidance, the authors cannot effectively identify the areas needing improvement. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and suggests that it should be validated on more models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a weakness in the experimental analysis, noting that it is insufficient and should be validated on more models. This feedback highlights an area for improvement, suggesting that the authors expand their experimental validation to include additional models. However, the comment lacks specificity and does not provide detailed guidance on which models should be considered or how the validation should be conducted. Without actionable suggestions or detailed advice, the authors are left with a general direction for improvement but without clear steps to take. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the proposed method\\'s performance on ImageNet experiments, noting that it only shows marginal improvement over baselines. It suggests that the authors should conduct experiments with networks having various normalization layers to better demonstrate the method\\'s effectiveness. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to perform them. The action is inferred and somewhat vague, as it lacks specific guidance on how to conduct these experiments or what specific normalization layers to test. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and its comparison with the original initialization, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method only shows marginal improvement over baselines in ImageNet experiments, particularly when applied to networks with various normalization layers. The comment further supports its claim by referencing specific works, such as [1] and [2], which provide additional context and evidence for the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method only shows marginal improvement over baselines in ImageNet experiments, particularly when applied to networks with various normalization layers. The reviewer supports this claim by referencing specific works, such as [1] and [2], which provide examples of similar experiments and results. This use of external references helps substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific data from the referenced works to fully validate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critique of the proposed method, noting that while it shows improvement over the original initialization, its effectiveness is limited to networks with 100 layers on CIFAR. The comment highlights a concern about the lack of significant improvement over baselines in ImageNet experiments, particularly when applied to networks with various normalization layers. This feedback is somewhat helpful as it identifies a specific area where the paper\\'s claims may not be fully substantiated, prompting the authors to consider additional experiments or analyses to strengthen their results. However, the comment could be more helpful if it offered specific suggestions on how to address these limitations or provided examples of alternative approaches. Overall, the feedback is somewhat helpful, as it points out a potential weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This is an explicit suggestion, as it directly instructs the authors to include a specific comparison. However, it does not provide detailed guidance on how to conduct this comparison or what specific aspects should be highlighted. While the action is clear, the lack of concrete details on how to implement the comparison makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its request for a comparison between the proposed method and the method in Yu et al. 2021, but without clear grounding, the authors may struggle to determine where to incorporate this suggestion. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This feedback is clear and actionable, as it identifies a specific area where the authors could enhance their paper by providing a comparative analysis. However, the comment could be more helpful if it included specific aspects or criteria to focus on in this comparison, such as particular robustness or immunizability metrics. Despite this, the suggestion is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the proposed algorithm for adaptive top-k decoding, asking whether it produces \"better\" samples. The reviewer expresses openness to revising their assessment based on the authors\\' response. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their work. The request for a plot of time complexity is a specific suggestion, but it is not directly related to the initial question about the algorithm\\'s effectiveness. The action is implicit and somewhat vague, as the authors are left to infer that they should provide additional information or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the algorithm for adaptive top-k decoding and its potential to produce \"better\" samples. However, it does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a plot of time complexity as a function of m, which provides clear guidance on what additional information would be beneficial. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the claim that the proposed algorithm produces \"better\" samples. It does not contain any subjective opinions, judgments, or suggestions that require verification. The reviewer expresses openness to revising their assessment based on the authors\\' response, which is a factual statement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the claim that the proposed algorithm for adaptive top-k decoding produces \"better\" samples. It expresses openness to revising the assessment based on the authors\\' response, which is a constructive approach to seeking clarification. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not identify particular weaknesses or areas where the authors could enhance their work. While it encourages dialogue, it does not offer enough guidance for the authors to make significant improvements to their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the postprocessing effort mentioned in footnote 2 is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect. The comment lacks specificity and does not offer actionable steps for the authors to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 2\" and the \"postprocessing effort,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the postprocessing effort. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the postprocessing effort mentioned in footnote 2, indicating that it is unclear. However, it does not provide any supporting evidence, reasoning, or examples to justify why the postprocessing effort is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. While it identifies a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness in the paper but lacks actionable feedback or detailed advice, leaving the authors with only a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, as it provides limited value in guiding the authors toward enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have run the codes for multiple seeds and reported the mean. While it implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about whether the authors have run the codes for multiple seeds and reported the mean. However, it does not specify which part of the paper this question pertains to, such as the methodology or results section. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific guidance on what needs to be addressed or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking whether the authors have run the codes for multiple seeds and reported the mean. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the authors have run the codes for multiple seeds and reported the mean. While this is a relevant point that could impact the robustness and reliability of the results, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer actionable feedback or context for improvement, leaving the authors with only a vague indication of a potential area of concern. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient direction for the authors to act upon it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of certain models like InceptionV3 and ResNet in Table 3. While the comment highlights areas of confusion and inconsistency, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify the differences between the datasets and the experimental setup, as well as ensure consistency in the results presented. The action is implicit and somewhat vague, as it lacks concrete guidance on how to resolve the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It specifically mentions Table 3 and notes the absence of results for models like InceptionV3 and ResNet, which are present in Table 2. This provides full grounding as it explicitly references specific tables and models, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the differences in datasets and experimental setups, and the inconsistency in results presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3. These are factual observations and requests for clarification, not subjective claims or opinions. Therefore, the comment does not contain any claims and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of certain models like InceptionV3 and ResNet in Table 3. This feedback is valuable as it highlights potential inconsistencies and areas that need clarification or additional explanation. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into why these differences might matter. Overall, the comment is somewhat helpful as it identifies specific areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Figure 4. This is a clear and direct action that the authors can take to improve their draft. However, the comment does not specify what aspects of the results need further elaboration or how the authors should enhance the description. While the action is explicit, the lack of concrete guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 4,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies what needs to be addressed, namely, a more thorough description of the results shown in Figure 4. This provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the description of the results in Figure 4 is insufficient and requests a more thorough explanation. However, it does not provide any specific reasoning or examples to support why the current description is inadequate or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors provide a more thorough description of the results shown in Figure 4. While it identifies an area for improvement, it lacks specificity and does not offer guidance on what aspects of the results should be elaborated upon or how the description could be enhanced. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it points out a potential issue but does not provide actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their work more extensively with the relevant literature, specifically mentioning [11]. While the comment implies that the authors should include more detailed comparisons in the method section, it does not provide specific guidance on how to conduct these comparisons or which aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the work with a specific reference, [11], which provides some grounding by indicating a potential area for improvement. However, it does not specify which part of the paper should include this comparison or how it should be integrated, making it weakly grounded. The comment is specific in suggesting a particular work to compare with, but it lacks detailed guidance on how to implement this comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their work more extensively with a specific reference, [11], in the method section. However, the comment does not provide any reasoning or justification for why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their work more extensively with a specific reference, [11], particularly in the method section. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft by including a more detailed comparison with relevant literature. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Additionally, it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It suggests that there might be legitimate shared words between the English and language-specific vocabulary. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to justify their process. The reference to a survey paper might imply that the authors should consider the findings discussed in that paper, but this is not directly stated. The action is implicit and somewhat vague, leaving the authors with a general direction but without concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific process in the paper related to removing words with identical English counterparts in the class label translation and cleaning. However, it does not explicitly mention which part of the paper this process is discussed in, making it weakly grounded. The comment is specific in its critique, as it questions the justification for this process and suggests that there might be legitimate shared words between the English and language-specific vocabulary. The reference to a specific survey paper provides some context but does not directly link it to the paper being reviewed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It suggests that there might be legitimate shared words between the English and language-specific vocabulary. The reviewer supports this claim by referencing a specific survey paper, \"Ten Years of BabelNet: A Survey,\" by Roberto Navigli et al. (IJCAI 2021). This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the survey paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It suggests that there might be legitimate shared words between the English and language-specific vocabulary, referencing a specific survey paper for further context. This feedback is somewhat helpful as it identifies a potential issue with the methodology and provides a reference that could guide the authors in addressing this concern. However, the comment could be more helpful if it offered specific suggestions on how to justify or refine the process, or if it provided more detailed guidance on how to incorporate the referenced survey paper into the discussion. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should consider studying more models to verify the findings, implying that the authors should expand their analysis to include additional models beyond LLaVA and InstructBLIP. However, the comment does not specify which models should be included or how this additional analysis should be conducted. The action is implicit and vague, leaving the authors without clear guidance on how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the study should consider studying more models to verify the findings, specifically mentioning LLaVA and InstructBLIP. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the study\\'s scope or analysis, but the lack of explicit grounding makes it difficult to pinpoint the exact area for improvement. The comment is specific in suggesting the need for additional models, but it is weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the study should consider studying more models to verify the findings, specifically mentioning LLaVA and InstructBLIP. However, the comment lacks specific reasoning or evidence to support why studying additional models would be beneficial or necessary. It does not provide examples of other models that could be included or explain how the current findings might be affected by considering more models. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the potential benefits of expanding the study to other models. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the study should consider studying more models to verify the findings, specifically mentioning LLaVA and InstructBLIP. While it identifies a potential limitation in the scope of the study, it lacks specific guidance or suggestions on which additional models should be included or how the analysis could be expanded. The feedback is somewhat helpful as it points out an area for improvement, but it could be more beneficial with detailed suggestions or examples of models to consider. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the results shown in Figure 7 and Table 3, specifically noting that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization in Table 3. The reviewer suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption. While the comment implies that the authors should investigate and clarify this discrepancy, it does not provide specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address the discrepancy but may not be entirely sure of the steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the significant reduction in norm for OpenCLIP in Figure 7 and the lack of significant improvement for object localization in Table 3. The comment suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the results shown in Figure 7 and Table 3, specifically noting that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization in Table 3. The comment suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption. While the comment identifies a potential issue, it lacks specific reasoning or evidence to support the claim that the discrepancy is significant or requires further exploration. The suggestion for further explanation is logical, but without additional context or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the results shown in Figure 7 and Table 3, specifically noting that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization in Table 3. This observation is valuable as it highlights a potential inconsistency in the paper\\'s findings. The comment suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption of the method. While the comment points out an important issue, it lacks specific guidance or suggestions on how the authors might address this discrepancy or what aspects to focus on in their explanation. Therefore, the feedback is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the use of 3D renders with G and the combination of 3D rendering and the GAN objective. It explicitly requests more details on how the 3D rendering and the latent code z are used in the rendering network and how they are combined with the GAN objective. This feedback provides a clear and direct action for the authors to take, which is to provide additional details in the paper. The comment is specific and actionable, as it guides the authors on what information to include to improve the clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unclear use of 3D renders with G and requests more details on how the 3D rendering and the GAN objective are combined. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how 3D renders are used with G, specifically questioning the use of the latent code z to modulate the rendering network and the integration of the Point cloud. The comment requests more details on how the 3D rendering and the GAN objective are combined. While the comment identifies a specific area of confusion, it does not provide any supporting evidence or references to substantiate the claim. The lack of detailed explanation or examples makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it highlights a potential gap but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the use of 3D renders with G, particularly in Section 3.3. It questions how the latent code z is used to modulate the rendering network and how the Point cloud is integrated into this process. The comment requests more details on how the 3D rendering and the GAN objective are combined, which is a clear and actionable suggestion for improvement. By addressing this feedback, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to present this information. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, noting that the supporting evidence relies on simple architectures and datasets. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the evidence. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of increased hyperparameter complexity in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, noting that the supporting evidence relies on simple architectures and datasets. However, the comment does not specify which part of the paper discusses these claims or where the evidence is presented, making it weakly grounded. The comment is specific in detailing the issue with the evidence provided, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model, questioning the claim of parameter insensitivity. The reviewer supports this claim by noting that the supporting evidence relies on simple architectures and datasets, which is considered insufficient. However, the comment lacks specific examples or references to substantiate the claim further, making it somewhat verifiable. The authors would need to explore the evidence provided to fully understand and address the critique, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the QIF model, specifically the increased complexity of hyperparameters compared to the traditional LIF model. It questions the claim of parameter insensitivity, noting that the supporting evidence relies on simple architectures and datasets, which may not be convincing. This feedback highlights a critical area for improvement, as it suggests that the authors need to provide more robust evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to strengthen the evidence or what additional experiments or analyses could be conducted to address this concern. Overall, the comment is somewhat helpful as it points out a significant weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with other PLMs like RoBERTa, T5, vicuna, or llama-2. It also recommends discussing aspects such as computational costs and real-world scenarios in the context of LLMs. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of marginal improvements over baselines and suggests that further improvements might be achievable with other PLMs. It mentions specific PLMs like RoBERTa, T5, vicuna, and llama-2, which provides some specificity. However, the comment does not explicitly mention which part of the paper discusses these improvements or the proposed method, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the marginal improvements achieved by the proposed method over baselines, suggesting that further improvements might be possible with other PLMs. The reviewer provides specific examples of PLMs that could potentially yield better results, such as RoBERTa, T5, vicuna, and llama-2. This provides a logical basis for the claim, as it highlights the potential for improvement and suggests a direction for further exploration. However, the comment could be strengthened by providing more detailed reasoning or evidence on why these specific PLMs might offer better results. Overall, the claim is mostly verifiable, as it is supported by specific examples but could benefit from additional justification or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a valid concern about the marginal improvements achieved by the proposed method over baselines, questioning the necessity of a sophisticated framework to achieve these results. It suggests that further improvements might be possible with other PLMs, such as RoBERTa, T5, vicuna, or llama-2. The comment also recommends discussing aspects like computational costs and real-world scenarios in the context of LLMs. This feedback is mostly helpful as it provides a clear direction for the authors to consider alternative approaches and to discuss the relevance of their method in the era of LLMs. However, it could be more helpful if it offered specific suggestions on how to incorporate these discussions or comparisons into the paper. Overall, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the explanation of using soft assignment instead of hard assignment and questions whether the authors have conducted an experiment to support their conjecture. While the comment implies that the authors should provide evidence or results to substantiate their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of the methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the authors have reported an experiment to support their conjecture regarding the use of soft assignment instead of hard assignment. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the use of soft assignment instead of hard assignment, suggesting that the authors have not provided an experiment to support their conjecture. However, the comment does not offer any specific reasoning or evidence to support why this explanation is unclear or how it could be improved. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explanation of using soft assignment instead of hard assignment in the methodology. It questions whether the authors have conducted an experiment to support their conjecture, which is a relevant point that could impact the clarity and validity of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their explanation. While it highlights a potential weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the methods presented, noting that they are primarily applicable to the cross-silo setting and may not be suitable for general federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to broaden the applicability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the methods presented, noting that they are primarily applicable to the cross-silo setting and may not be suitable for general federated learning problems with a larger number of clients. However, it does not specify which part of the paper discusses the methods or their applicability, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the methods are discussed, the comment lacks full grounding. It is specific about the limitation but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the methods presented are primarily applicable to the cross-silo setting, which limits their applicability to general federated learning problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the methods presented, noting that they are primarily applicable to the cross-silo setting and may not be suitable for general federated learning problems with a larger number of clients. This feedback highlights a potential weakness in the paper\\'s applicability and suggests that the authors consider expanding their methods to address a broader range of federated learning scenarios. However, the comment does not provide specific suggestions or guidance on how to achieve this expansion, such as proposing alternative methods or approaches that could be applied to a larger number of clients. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what constitutes distributional generalization in the setting of regression. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or improve their draft based on it. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about what constitutes distributional generalization in the setting of regression. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about distributional generalization in regression, but without clear grounding, the authors may struggle to identify where this question should be addressed in their paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the concept of distributional generalization in the context of regression. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression, suggesting that it might not be as surprising in that setting. However, it does not provide any specific feedback or suggestions for improvement, nor does it identify any weaknesses or areas for enhancement in the paper. The comment lacks actionable guidance or constructive criticism, leaving the authors without a clear path to improve their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the references and baselines are out of date and suggests that more recent research should be covered. It also provides a specific suggestion for finding additional results by searching for \"Item Frequencies of Data Streams.\" This feedback is clear and provides concrete guidance on how to improve the draft by updating the references and baselines. The authors know exactly what needs to be done to address the issue, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of outdated references and baselines, suggesting that more recent research should be included. However, it does not specify which references or baselines are outdated or which recent research should be considered. Additionally, the suggestion to search for \"Item Frequencies of Data Streams\" is vague and does not provide specific guidance on how to incorporate this into the paper. The authors cannot confidently determine which parts of the paper are being addressed, making the comment weakly grounded. The lack of specificity in suggesting how to address the issue further weakens the comment. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the references and baselines are out of date and suggests that more recent research should be covered. However, the comment lacks specific examples or references to recent studies that should be included, making it difficult for the authors to understand which specific updates are needed. Additionally, the suggestion to search for \"Item Frequencies of Data Streams\" is vague and does not provide a clear rationale for how this would improve the paper. As a result, the claim is not well-supported and lacks the necessary detail to be verifiable, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the outdated nature of the references and baselines. It suggests that more recent research should be included to keep the work relevant and current. Additionally, the comment provides a specific suggestion for finding additional results by searching for \"Item Frequencies of Data Streams,\" which could help the authors expand their literature review. This feedback is clear and actionable, offering the authors a concrete way to improve the comprehensiveness and relevance of their work. However, it could be more helpful if it provided specific examples of recent studies that should be included or discussed. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the introduction, which discusses computational challenges in high-dimensional action spaces, and the experimental analysis in Section 5, which focuses on lower-dimensional action spaces. The reviewer suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies an area for improvement, it does not provide explicit instructions or concrete steps on how to conduct this analysis. The action is implicit and somewhat vague, as the authors know they need to address the discrepancy but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and Section 5, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the introduction\\'s focus on computational challenges in high-dimensional action spaces and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. The comment further suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the introduction, which discusses computational challenges in high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. The reviewer suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a potential gap in the paper, it lacks specific examples or references to substantiate the claim about the need for more analysis in high-dimensional action spaces. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires additional evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the introduction, which highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in relatively lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by expanding the analysis to include high-dimensional action spaces. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to an important area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the experimental results are good, there is no information on the additional computation required to achieve these results. The reviewer suspects that the extra performance is due to additional parameters or computation. The comment implies that the authors should provide information on the extra computation needed and suggests a comparison with the original transformers to verify the performance. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer the need for additional analysis and comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and raises a concern about the additional computation required to achieve the reported performance. However, it does not specify which part of the paper discusses the experimental results, making it weakly grounded. The comment is specific in its critique, as it questions the extra parameters or computation needed and suggests a comparison with the original transformers. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the experimental results by suggesting that the extra performance might be due to additional parameters or computation. However, it lacks specific evidence or references to support this claim. The reviewer does not provide examples or detailed reasoning to substantiate the suspicion about the extra computation needed. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the good experimental results but points out a significant gap in the paper: the lack of information on the additional computation required to achieve these results. It suggests that the extra performance might be due to additional parameters or computation, and proposes a comparison with the original transformers to verify this. This feedback is clear and actionable, as it directs the authors to provide a critical piece of information that could significantly enhance the transparency and credibility of their findings. However, the comment could be more helpful if it offered specific suggestions on how to present this information or what metrics to use for comparison. Overall, the comment is mostly helpful, as it identifies a key area for improvement and provides a direction for further analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation and results are not convincing due to inconsistent trends and lack of statistical significance in the improvements. However, it does not provide specific guidance on how the authors can address these issues or improve the evaluation and results. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Since the feedback is vague and does not offer actionable steps, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the evaluation and results, noting that they are not convincing due to inconsistent trends and lack of statistical significance in the improvements. However, it does not specify which part of the paper these issues pertain to, such as specific sections, figures, or tables. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and lack of statistical significance in the improvements. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the inconsistent trends or improvements, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation and results of the paper, noting that they are not convincing due to inconsistent trends and a lack of statistical significance in the improvements. This feedback highlights a critical area for improvement, as the authors need to ensure that their results are robust and statistically significant. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending additional analyses or statistical tests. While it points out a key weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should highlight the percentage of the error rate that is due to subjective questions, by considering agreement among humans. This implies that the authors should conduct an analysis to determine the proportion of subjective questions and their impact on the error rate. While the action is not explicitly stated, it is clear and concrete, as it provides a specific method for addressing the issue. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"several questions require subjective answers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests highlighting the percentage of the error rate due to subjective questions and provides a method for doing so, such as looking at agreement among humans. This provides clear guidance on what needs to be addressed and how to do so. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the inclusion of subjective questions in the study could be problematic if a significant portion of the error rate is due to these questions. The reviewer agrees that subjective questions are plausible but proposes a method to verify this by examining the percentage of error rate attributable to subjective questions and comparing it to human agreement. This suggestion is somewhat verifiable as it provides a logical reasoning for the claim and suggests a method for verification. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the inclusion of subjective questions in the study, suggesting that it could be problematic if a significant portion of the error rate is due to these questions. The reviewer provides a constructive suggestion by recommending that the authors highlight the percentage of the error rate attributable to subjective questions and consider agreement among humans as a method to assess this. This feedback is clear and actionable, offering a specific approach for the authors to address the concern raised. By suggesting a way to quantify and evaluate the impact of subjective questions, the comment empowers the authors to improve their draft. Therefore, it is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the evaluation section, noting that only a single dataset and limited NLP tasks (intent recognition) are considered. It suggests that the paper would benefit from including additional NLP tasks, such as sentiment classification and named-entity recognition. While the comment implies that the authors should expand their evaluation to include more tasks, it does not provide specific guidance on which additional tasks to consider or how to incorporate them into the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the evaluation section, noting that it is weak due to the use of only a single dataset and limited NLP tasks (intent recognition). It suggests that the paper would improve by considering additional NLP tasks, such as sentiment classification and named-entity recognition. However, the comment does not specify which part of the evaluation section this critique pertains to, making it weakly grounded. The comment is specific in detailing what additional tasks could be considered, providing clear guidance on how to enhance the evaluation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is weak due to the use of only a single dataset and limited NLP tasks, specifically mentioning intent recognition. The comment suggests that the paper would benefit from considering additional NLP tasks like sentiment classification and named-entity recognition. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support why these additional tasks would enhance the evaluation. The suggestion is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation section, noting that the paper only uses a single dataset and focuses on a limited set of NLP tasks (intent recognition). It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition, to provide a more comprehensive evaluation. This feedback is clear and actionable, as it offers specific areas for improvement that the authors can address to enhance the robustness and generalizability of their evaluation. However, the comment could be more helpful if it provided additional guidance on how to incorporate these additional tasks or why they are important. Overall, the comment is mostly helpful, as it directs the authors toward meaningful enhancements of their evaluation section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to label the class semantic feature as \"s\" instead of \"c\" in Figure 3. This is a clear and direct action, providing the authors with specific guidance on how to correct the labeling in the figure. The comment is concrete, as it specifies exactly what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, the labeling of the class semantic feature as \"s\" instead of \"c.\" This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the labeling of a figure, specifically suggesting that \"class semantic feature\" should be labeled as \"s\" instead of \"c.\" It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the labeling of a figure, specifically recommending that the class semantic feature should be labeled as \"s\" instead of \"c.\" This feedback is clear and directly addresses a potential error or inconsistency in the figure, allowing the authors to make a precise correction. By offering a concrete suggestion, the comment empowers the authors to improve the accuracy and clarity of their figure, which is crucial for the reader\\'s understanding. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the distinction between de-identification and face swapping, noting that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology. The reviewer suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the boundary between the two approaches. While the comment implies an action\u2014comparing the method with existing face swapping algorithms\u2014it does not provide specific guidance on how to conduct this comparison or which algorithms to consider. The action is explicit but somewhat vague, as the authors know they need to make comparisons but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the distinction between de-identification and face swapping, specifically mentioning the method proposed in the paper as a form of face swapping. It provides a clear explanation of the difference between the proposed method and deepfake technology, noting that the target face is derived from a 3DMM. However, the comment does not specify which part of the paper this distinction is discussed in, making it weakly grounded. The comment is specific in its suggestion to compare the method with state-of-the-art face swapping algorithms, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology, and suggests that the distinction between the two approaches is not clear. The reviewer provides a logical reasoning by explaining the difference between the target face being a real individual in deepfake technology versus a 3DMM in the proposed method. However, the comment lacks specific references or examples of state-of-the-art face swapping algorithms that the authors should compare their method with. This makes the claim somewhat verifiable, as it provides a logical basis but requires additional detail to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the distinction between de-identification and face swapping, noting that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology. It highlights a key difference between the two approaches, namely that in deepfake technology, the target face is a real individual, while in this work, the target face is derived from a 3DMM. The comment suggests that this distinction does not create a clear boundary between the two approaches and recommends that the authors compare their method with state-of-the-art face swapping algorithms. This feedback is clear and actionable, providing a specific direction for the authors to enhance the clarity and differentiation of their work. However, it could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which are the chief baseline from the literature. However, it does not provide any explicit or implicit suggestions for how the authors might improve these results or address the issue. There is no guidance on potential modifications, alternative approaches, or additional analyses that could be conducted to enhance the results. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the experimental results on word embeddings are not very compelling compared to Gaussian embeddings, which are the chief baseline from the literature. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which are the chief baseline from the literature. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential weakness in the experimental results, specifically noting that the results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which are the chief baseline from the literature. This feedback highlights an area where the authors might need to improve their experimental results or provide a more compelling comparison. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance their results. While it identifies a potential weakness, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method does not seem to differ significantly from previous studies, except for the change in task to text summarization and the modification of the reward function. While it acknowledges that this finding is valuable, it suggests that the contribution may be limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might enhance the novelty or significance of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method by comparing it to previous studies, specifically mentioning Shi et al., 2018, and Ghosh et al., 2021. It highlights that the only significant difference is the change in task to text summarization and the modification of the reward function. However, it does not specify which part of the paper this comparison is based on, making it weakly grounded. The comment is specific in detailing the differences and the potential impact on the contribution, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method does not differ significantly from previous studies, except for the change in task to text summarization and the modification of the reward function. This claim is supported by referencing specific previous studies (Shi et al., 2018; Ghosh et al., 2021) and providing a reference to Ramakanth Pasunuru and Mohit Bansal (2018). The inclusion of these references helps substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method aligns with the previous studies. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, noting that it does not differ significantly from previous studies except for the change in task to text summarization and the modification of the reward function. While it acknowledges that the finding of IRL\\'s effectiveness in text summarization is valuable, it suggests that the contribution may be limited if this is the only difference. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty or significance of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited and suggests that the main contribution is a new IT-related dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty or improve the paper\\'s contributions. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, suggesting that it consists of multiple pieces combined to create the paper. It specifically mentions that the main contribution is a new IT-related dataset. However, the comment does not specify which sections or parts of the paper these observations pertain to, making it difficult for the authors to pinpoint where improvements are needed. While the authors might have an idea of where the dataset is discussed, the lack of explicit references makes the comment weakly grounded. The comment is somewhat specific in identifying the main contribution as a dataset, but it lacks detailed guidance on how to address the perceived lack of novelty. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, suggesting that it consists of multiple pieces combined to create the paper. The main contribution is identified as a new IT-related dataset. However, the comment lacks specific examples or detailed reasoning to support the claim about the limited novelty. Without concrete evidence or references to substantiate the assertion, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a perceived limitation in the novelty of the paper, suggesting that it consists of multiple pieces combined to create the paper. It specifically mentions that the main contribution is a new IT-related dataset. While the comment highlights a potential weakness, it lacks depth and does not provide actionable suggestions or guidance on how the authors might enhance the novelty or contributions of their work. Without specific feedback or recommendations, the authors are left with only a general critique, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the paper should include an ablation study related to query embedding. This direct request provides a clear action for the authors to take, which is to conduct an ablation study to understand the significance and impact of the query embedding component. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of an ablation study related to query embedding, providing clear guidance on what is missing in the paper. However, it does not specify where in the paper this study should be included or how it should be structured, making it weakly grounded. The comment is specific in identifying the need for an ablation study on query embedding, but without explicit references to sections or parts of the paper, the authors may struggle to determine where to incorporate this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study related to query embedding, suggesting that such a study would provide insights into the significance and impact of this component. However, the comment does not provide any specific reasoning, examples, or references to support why an ablation study is necessary or how it would benefit the paper. Without additional context or justification, the claim is not verifiable, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of an ablation study related to query embedding. This feedback is clear and actionable, as it suggests a concrete step the authors can take to enhance their paper by conducting an ablation study. By doing so, the authors can gain insights into the significance and impact of the query embedding component, which is crucial for understanding the contribution of their work. However, the comment could be more helpful if it provided additional guidance on how to design or interpret the ablation study. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying which aspects of the contribution are considered marginal or how the authors could enhance their work to align with previous works. Without concrete steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the paper compared to previous works, but it does not specify which part of the paper this opinion is based on. It lacks grounding as it does not refer to any specific sections, figures, or tables in the paper. Additionally, it does not provide specific details on what aspects of the contribution are considered marginal or how they compare to the cited works. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal compared to previous works, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the comparison or how their work differs from the cited works. This lack of supporting information makes the claim unverifiable, as it does not provide sufficient evidence or justification for the authors to address the critique effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper is marginal compared to previous works, but it does not provide any specific details or examples to support this claim. It lacks actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of what aspects of their work are considered marginal or how they could enhance their contribution. Without specific guidance or constructive criticism, the comment does not aid the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a question asking the authors to explain the loss of performance of w2gm against w2g in the analysis of SWCS. While the question implies that the authors should provide an explanation, it does not explicitly instruct them to do so. Additionally, the comment lacks concrete guidance on how to address the issue or what specific aspects of the analysis should be focused on. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the analysis should be addressed or how the authors might provide an explanation. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of a question asking the authors to clarify the loss of performance of w2gm against w2g in the analysis of SWCS. While it prompts the authors to provide an explanation, it does not offer any specific guidance or suggestions on how to address this issue or improve the draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for improvement. Therefore, it is rated as barely helpful, as it identifies a potential area of confusion but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the paper should directly evaluate for overoptimization rather than focusing on calibration and human evaluation. The reviewer points out that current works address overoptimization through early stopping, such as AlignProp, and recommends evaluating without early stopping to understand the tradeoffs. Additionally, the reviewer suggests discussing the benefits of not using early stopping. These suggestions are clear and provide specific guidance on how to improve the evaluation and discussion sections of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of overoptimization, calibration, and human evaluation, allowing the authors to identify the relevant parts of the paper. It is also specific because it suggests that the paper should directly evaluate for overoptimization and discusses the benefits of not using early stopping, as seen in current works like AlignProp. The comment provides clear guidance on what needs to be addressed and improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not directly evaluate for overoptimization, despite mentioning it as a motivation, and instead focuses on calibration and human evaluation. The reviewer supports this claim by referencing current works like AlignProp, which address overoptimization through early stopping, and suggests that the paper should evaluate without early stopping to understand the tradeoffs. This reasoning is mostly verifiable as it provides a logical basis for the claim and references an external work (AlignProp) to support the argument. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that while overoptimization is mentioned as a motivation, it is not directly evaluated. Instead, the paper focuses on calibration and human evaluation. The reviewer suggests that current works address overoptimization through early stopping, such as AlignProp, and recommends that the paper evaluate without early stopping to understand the tradeoffs. Additionally, the comment advises discussing the benefits of not using early stopping. This feedback is clear and actionable, providing the authors with a concrete direction for improving their evaluation and discussion sections. By addressing these points, the authors can enhance the comprehensiveness and rigor of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include an analysis and discussion comparing the proposed TW model with TR, noting that the TW model is equivalent to TR if the core tensor C is represented by a TR. The reviewer explicitly requests a justification for using TW over TR. This feedback provides a clear and direct action for the authors to take, specifying what needs to be added to the paper. The suggestion is concrete, as it outlines the specific analysis and discussion that should be included. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed TW model\" and the \"TR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should include an analysis and discussion comparing the TW model with TR, noting that the TW model is equivalent to TR under certain conditions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed TW model is equivalent to TR, providing a logical reasoning by stating that if the core tensor C is represented by a TR, then by fusing this TR with the cores G_n, the resulting representation is equivalent to the TW model. This reasoning is based on a logical connection between the models, which is a common practice in mathematical modeling. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed TW model, suggesting that it may be equivalent to TR under certain conditions. It provides a logical reasoning by explaining that if the core tensor C is represented by a TR, then by fusing this TR with the cores G_n, the resulting representation is equivalent to the TW model. The comment also expresses a desire to see this analysis included in the paper, along with a discussion justifying the use of TW over TR. This feedback is clear and actionable, as it directs the authors to include a specific analysis and discussion that could enhance the paper\\'s depth and clarity. However, it could be more helpful if it offered suggestions on how to present this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the transferability of their toolset, noting that the toolsets for the VQA task and the reasoning task are not the same. It implies that the authors could experiment with creating a general toolset for all tasks and observe the results. While the comment provides a clear direction for the authors to explore, it does not specify how to implement this suggestion or what specific experiments to conduct. The action is explicit but somewhat vague in terms of execution details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the transferability of the toolset and notes that the toolsets for the VQA task and the reasoning task are not the same. It implies that the authors should consider creating a general toolset for all tasks. However, the comment does not specify which part of the paper should include this discussion or where the current toolsets are described. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting a potential improvement by discussing transferability and experimenting with a general toolset. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the transferability of the toolset should be discussed, noting that the toolsets for the VQA task and the reasoning task are not the same. The reviewer implies that the authors could experiment with creating a general toolset for all tasks. However, the comment lacks specific examples or references to support the claim about the differences in toolsets or the potential benefits of a general toolset. This makes the claim somewhat verifiable, as it provides a suggestion but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the transferability of the toolset used in the paper, noting that the toolsets for the VQA task and the reasoning task are not the same. It suggests that the authors could experiment with creating a general toolset for all tasks and observe the results. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for further exploration. However, it lacks detailed guidance on how to implement this suggestion or what specific aspects of the toolsets should be considered. To be more helpful, the comment could include more detailed suggestions or examples of how to approach this task. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders as a baseline to assess the impact of feature order variability. It implies that this baseline could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the action is not explicitly stated, it is clear and concrete, as the authors can infer that they should implement this baseline to test their hypothesis. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests evaluating the model\\'s performance using multiple random feature orders as a baseline to assess the impact of feature order variability. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to evaluate the model\\'s performance, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders as a baseline to assess the impact of feature order variability. The claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which is to determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment lacks specific examples or references to similar studies that have used this approach, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific approach to evaluate the model\\'s performance by using multiple random feature orders as a baseline. This suggestion is clear and actionable, as it provides a concrete method for assessing the impact of feature order variability without relying on a complex controller. By proposing this baseline, the reviewer offers a way for the authors to determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. This feedback is highly helpful as it provides a practical and constructive suggestion that can significantly enhance the paper\\'s experimental rigor and clarity. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the related work section, noting that it is severely lacking and missing references to lexically constrained decoding methods. It also points out that these methods are not included as baselines for comparison. This feedback provides a clear and direct action for the authors to take, which is to include references to lexically constrained decoding methods in both the related work and as baselines for comparison. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of missing references to lexically constrained decoding methods, both in the related work and as baselines for comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is severely lacking and specifically mentions the omission of lexically constrained decoding methods. This claim is somewhat verifiable as it identifies a specific area where the paper is lacking, but it does not provide detailed examples or references to support the assertion that these methods are relevant or should be included. The comment suggests that the authors should consider including these methods as baselines for comparison, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the related work section, specifically noting the omission of lexically constrained decoding methods. It highlights that these methods are not only missing from the related work but also as baselines for comparison. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. By including these methods, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested specific references or examples of lexically constrained decoding methods to include. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the comparison is incomplete due to the absence of important baseline models and datasets. It explicitly mentions two specific models, SimVLM and OFA, that should be included in the comparison. This provides a clear and direct action for the authors to take, which is to incorporate these models into their analysis. The comment is explicit and concrete, giving the authors precise guidance on how to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of important baseline models and datasets, which affects the comprehensiveness of the comparison. It explicitly mentions two specific models, \"SimVLM\" and \"OFA,\" that should be included. However, the comment does not specify which part of the paper this issue pertains to, such as the results or discussion sections. While the authors can infer that it relates to the comparison section, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying what is missing but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison is incomplete due to the absence of important baseline models and datasets. It supports this claim by mentioning specific models, \"SimVLM\" and \"OFA,\" which should be included in the comparison. This provides a clear and explicit reference to external works, making the claim fully verifiable. The inclusion of these models would help substantiate the paper\\'s findings and comparisons, thus justifying the need for their inclusion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of important baseline models and datasets in the comparison. By mentioning specific models like SimVLM and OFA, the reviewer provides clear guidance on what is missing and why the comparison is incomplete. This feedback is actionable, as it directs the authors to include these models in their analysis to enhance the comprehensiveness of their study. However, the comment could be more helpful if it explained why these particular models are important or how their inclusion would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present any new data that is collected or will be released. It highlights that the paper actually presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers hoping to find a new data source. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve the paper to better align with its claimed purpose or suggest alternative approaches. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the framing of the manuscript as a dataset paper, noting that it does not present new data but rather derivative data from existing datasets. However, it does not specify which sections or parts of the paper this critique pertains to, making it difficult for the authors to pinpoint where improvements are needed. Additionally, while the comment provides some specificity in terms of the issue with the data being derivative, it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present any new data, instead using derivative data from existing datasets. This claim is somewhat verifiable as it provides a logical critique of the paper\\'s framing and expectations. However, it lacks specific examples or references to existing datasets or standards that would fully substantiate the claim. The authors might find it challenging to address the critique without additional details or evidence, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the manuscript, noting that it is framed as a dataset paper but does not present any new data. It points out that the paper actually uses derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers expecting a new data source. This feedback is clear and highlights a critical misalignment between the paper\\'s claims and its actual content. However, the comment does not provide suggestions on how the authors might address this issue or improve the paper\\'s value. While it effectively identifies a problem, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential inconsistency in the authors\\' critique of L-softmax and A-softmax, noting that these methods also have a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this inconsistency or improve their critique. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific critique of the authors regarding the training procedure of L-softmax and A-softmax, noting that these methods also have a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on how this learning rate schedule affects the critique. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors criticize L-softmax and A-softmax for requiring an annealing-like training procedure, but it also notes that these methods have a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential inconsistency in the authors\\' critique of L-softmax and A-softmax, noting that these methods also have a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any constructive feedback or suggestions on how the authors might address this inconsistency or improve their critique. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a focus on the comparison between AE and diffusion, suggesting that the analysis should also delve deeper into the results themselves. It provides specific questions about the visualizations, such as whether the handle is consistently transformed across different chairs and if it is the most prominent feature. While the comment implies that the authors should analyze the results more thoroughly, it does not explicitly instruct them to do so or provide concrete steps on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the need for a more detailed analysis and determine how to approach it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the quantitative and qualitative analysis, allowing the authors to identify the part of the paper being addressed. It is also specific because it provides clear questions about the analysis, such as what can be learned from the visualizations about the crucial elements for detecting a chair, and it questions the consistency and prominence of the handle across different chairs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the depth of the analysis, suggesting that the focus is primarily on comparing AE to diffusion rather than analyzing the results themselves. It provides specific questions about the visualizations, such as whether the handle is consistently transformed across different chairs and if it is the most prominent feature. While the comment raises valid points, it lacks specific examples or references to support the claim that the analysis is insufficient. The reasoning is somewhat verifiable, as it highlights areas for further exploration, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the analysis, noting that the focus is primarily on comparing AE to diffusion rather than analyzing the results themselves. It provides specific questions about the visualizations, such as whether the handle is consistently transformed across different chairs and if it is the most prominent feature. This feedback is clear and actionable, as it encourages the authors to delve deeper into the analysis of their results, which could lead to a more comprehensive understanding of the method\\'s effectiveness. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a potential error in the manuscript, suggesting that the phrase \"must incur a competitive ratio of at most $b$\" should be changed to \"at least $b$\" in Section 2.2. The reviewer provides a clear rationale for this change, explaining that in the worst case (x=1), the ratio would be b/1=b, but in other cases, the ratio is either b/x or eventually b/b=1. This feedback is explicit and provides concrete guidance on how to correct the error, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Beginning of Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that \"must incur a competitive ratio of at most $b$\" should be changed to \"at least $b$\" and provides a rationale for this change. This level of detail helps the authors understand what needs to be revised, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a correction in the manuscript, specifically that the phrase \"must incur a competitive ratio of at most $b$\" should be changed to \"at least $b$.\" The reviewer provides a logical reasoning for this change by explaining that in the worst case scenario (x=1), the ratio would be b/1=b, but in other cases, the ratio is either b/x or eventually b/b=1. This reasoning is clear and provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the reasoning further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential error in the manuscript, specifically in Section 2.2, where the phrase \"must incur a competitive ratio of at most $b$\" is suggested to be changed to \"at least $b$.\" The reviewer provides a clear rationale for this correction, explaining that in the worst case scenario (x=1), the ratio would be b/1=b, but in other cases, the ratio is either b/x or eventually b/b=1. This feedback is actionable and provides a specific suggestion for improvement, making it highly helpful for the authors to correct the error and enhance the accuracy of their draft. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the notation used in Theorem 1, specifically asking what D^{alpha}_{x} denotes and whether it represents the derivatives of the probabilistic measure \\\\mu. This question implies that the authors should clarify the notation used in the theorem. While the action is implicit, it is clear and concrete, as the authors can directly address the question by providing an explanation or clarification. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the notation \"D^{alpha}_{x}\" and whether it denotes the derivatives of the probabilistic measure \\\\mu. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the notation used in Theorem 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the notation used in Theorem 1, specifically asking what D^{alpha}_{x} represents and whether it denotes the derivatives of the probabilistic measure \\\\mu. This feedback is somewhat helpful as it identifies a potential area of confusion or lack of clarity in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the notation. While it prompts the authors to consider revising their notation or providing additional explanations, it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing proper expression for the third face image in Figure 2. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be addressed in the draft. The comment provides concrete guidance on how to implement the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the \"proper expression for the third face image.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the missing expression for the third face image in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of a proper expression for the third face image in Figure 2. This feedback is clear and actionable, as it directly points out a missing element that the authors can easily address to improve the clarity and completeness of their draft. By correcting this omission, the authors can enhance the visual presentation of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including an example created by BERT and comparing it with an example created by the proposed model. This is an explicit suggestion, as it directly instructs the authors on what additional analysis or comparison could be beneficial. However, it does not provide specific guidance on how to implement this suggestion or what aspects of the comparison should be focused on. While the action is clear, the lack of detailed instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be integrated. The authors might infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular comparison, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any justification or reasoning for why this comparison would be beneficial or necessary. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an example created by BERT and comparing it with an example created by the proposed model. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper by offering a comparative analysis. However, the comment lacks depth and does not explain why this comparison would be beneficial or how it could improve the paper. It also does not provide guidance on how to implement this suggestion or what specific aspects should be focused on in the comparison. While the suggestion is actionable, the lack of detailed explanation or context limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the dataset size for the code summarization task and the code search task should be the same in order to demonstrate that Vault is better in terms of data quality compared to CSN. This provides a clear and direct action for the authors to take, ensuring that the dataset sizes are consistent across tasks. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"code summarization task\" and the \"code search task,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the dataset size for Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dataset size for the code summarization task and the code search task should be the same to demonstrate that Vault is better in terms of data quality compared to CSN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would demonstrate Vault\\'s superiority. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to help the authors understand or address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It points out that the dataset sizes for the code summarization task and the code search task should be the same to demonstrate that Vault is better in terms of data quality compared to CSN. This feedback is clear and directly addresses a potential issue in the experimental setup, guiding the authors on how to strengthen their claims and improve the validity of their results. By suggesting a straightforward adjustment, the comment empowers the authors to enhance the rigor and clarity of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a need for better explanation of certain important concepts, such as \"action-repeat\" and \"dithering phenomenon,\" which are mentioned throughout the paper. The reviewer suggests that these terms should be explained more carefully. This feedback provides a clear and direct action for the authors to take, which is to expand on the explanations of these concepts. The comment is specific and actionable, as it gives the authors a clear direction on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies specific concepts that are not well-explained, such as \"action-repeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully, indicating that the authors need to provide a clearer explanation of these concepts. However, the comment does not specify where in the paper these concepts are discussed, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that these terms are mentioned throughout the paper, the comment lacks full grounding. It is specific about the need for better explanation but does not provide detailed guidance on how to improve the explanations. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some important concepts are not explained well,\" specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence or reasoning to justify why these concepts are not well-explained or how they should be clarified. Without specific examples or detailed explanations, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some important concepts are not well-explained. It provides examples of these concepts, such as \"action-repeat\" and \"dithering phenomenon,\" which are mentioned throughout the paper. By pointing out these specific terms, the comment offers clear and actionable feedback for the authors to improve their draft by providing more detailed explanations. This guidance is valuable as it directs the authors to specific areas that need clarification, allowing them to enhance the comprehensibility of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an alternative approach to the current method, which involves creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text and re-encoding it. The reviewer provides a rationale for why this might be beneficial, mentioning the potential issue of discretization and wrong decoding. While the comment implies a specific action, it does not explicitly instruct the authors to implement this alternative approach. The authors can infer the action but may not be entirely sure of the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to the current method, which involves creating an instruction embedding from the state encoding and passing it directly to the executor. It provides a rationale for why this might be beneficial, mentioning the potential issue of discretization and wrong decoding. However, the comment does not explicitly mention which part of the paper it addresses, such as specific sections or experiments where this approach could be applied. The authors can infer that it relates to the methodology or experimental design, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting an alternative approach. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an alternative approach to the current method, which involves creating an instruction embedding from the state encoding and passing it directly to the executor. The reviewer provides a rationale for why this might be beneficial, mentioning the potential issue of discretization and wrong decoding. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim that this alternative approach would be more effective. While the suggestion is logical, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the methodology by proposing an alternative approach to the current method. It suggests creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text and re-encoding it. The comment explains why this might be beneficial, mentioning the potential issue of discretization and wrong decoding. This feedback is clear and offers a concrete way for the authors to enhance their work, making it highly helpful. The authors can use this suggestion to potentially improve the effectiveness and robustness of their approach. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the novelty of the proposed model is not significant, but it does not provide any guidance or suggestions on how the authors could address this issue or improve the novelty of their model. There is no explicit or implicit action for the authors to take, leaving them without direction on how to enhance the novelty of their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the proposed model but does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model lack novelty. Without explicit references to sections, figures, or specific elements of the model, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the novelty of proposed model is not significant,\" but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the novelty of the proposed model is not significant, but it does not provide any specific reasons or examples to support this claim. Without further elaboration or suggestions for improvement, the authors are left without actionable feedback on how to enhance the novelty of their model. This lack of detail and guidance makes the comment unhelpful, as it does not offer a clear path for the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the dataset, specifically noting that the proportion of each class used for the pool subset may make the dataset easier rather than harder. It provides an example of how the dataset might be biased, with very few observations of 9 and many more of 1, which could lead to poor classification of smaller classes. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the dataset. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about how to apply this information to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the dataset, specifically the proportion of each class used for the pool subset. It provides a detailed explanation of how this aspect might affect the dataset\\'s difficulty and the accuracy measure. However, the comment does not explicitly mention which part of the paper discusses the dataset or the pool subset, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the dataset\\'s composition and its impact on accuracy, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset\\'s composition, particularly the proportion of each class used for the pool subset, makes it easier rather than harder. The reviewer provides a logical reasoning by explaining how the dataset\\'s structure, with fewer observations of certain numbers like 9 and more of others like 1, could lead to poor classification of smaller classes. This reasoning is based on common sense and logical deduction, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar datasets or studies that support this claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the study, specifically noting that the proportion of each class used for the pool subset may make the dataset easier rather than harder. It provides a specific example of how the dataset might be biased, with very few observations of 9 and many more of 1, which could lead to poor classification of smaller classes. This feedback is valuable as it highlights a critical aspect of the dataset that could affect the accuracy measure, prompting the authors to reconsider their evaluation metrics. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as adjusting the dataset or using alternative metrics. Overall, the comment is somewhat helpful as it provides insight into a potential weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the main contribution of the paper, specifically regarding the strategic aspects of prediction. It also questions the \"true\" payoff in Table 1 and suggests that the test set payoff should be included. Additionally, it mentions the work by Vapnik and compares it to the current study. While the comment raises important points, it does not provide explicit actions or concrete suggestions for the authors to address these issues. The authors are left to infer that they need to clarify the main contribution and possibly include additional information in Table 1, but without specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it refers to specific elements such as \"Table 1\" and mentions the \"main contribution\" of the paper, allowing the authors to identify the general areas being addressed. However, it lacks full grounding as it does not specify the exact sections or parts of the paper where these issues are discussed. The comment is specific in its request for clarification about the \"true\" payoff in Table 1 and suggests including the test set payoff. It also references the work by Vapnik, providing a specific example for comparison. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point initially agrees with the statement that \"prediction is not done in isolation\" but questions the main contribution of the paper regarding the strategic aspects of prediction. The reviewer then raises specific questions about the \"true\" payoff in Table 1 and suggests that the test set payoff should be included. Additionally, the reviewer mentions the work by Vapnik and compares it to the current study. While the comment raises valid points and questions, it lacks detailed reasoning or evidence to fully substantiate the claims. The references to Vapnik and the comparison are not fully developed, making the comment somewhat verifiable. The authors would need to further explore these points to fully understand and address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the paper\\'s assertion that prediction is not done in isolation but questions the main contribution of showing that the task of prediction may have strategic aspects. It also raises specific questions about the \"true\" payoff in Table 1, suggesting that the test set payoff should be included. Additionally, the reviewer mentions the work by Vapnik and compares it to the current study, which could provide a useful reference for the authors. While the comment identifies areas for clarification and suggests a potential comparison with existing work, it lacks detailed guidance or actionable steps for the authors to improve their draft. The feedback is somewhat helpful as it points out specific areas of concern and provides a reference for further exploration, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training, in addition to the domain-alignment methods they currently focus on. While the comment explicitly states that the authors should consider another UDA method, it does not specify which method or how to implement this exploration. The action is explicit but lacks concrete details on how to execute it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, in addition to the current focus on domain-alignment methods. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where self-training could be applied. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in suggesting an additional approach, it is weakly grounded because it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method solely focuses on domain-alignment methods within the context of unsupervised domain adaptation (UDA) and recommends exploring another UDA method based on self-training. The claim is somewhat verifiable as it references self-training as a prominent and effective approach within the field of UDA. However, the comment lacks specific examples or references to other UDA methods based on self-training, which would provide a more robust justification for the suggestion. The authors would need to make an effort to identify and explore these methods themselves, making the claim somewhat verifiable but not fully supported with detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by noting that the proposed method solely focuses on domain-alignment methods within the context of unsupervised domain adaptation (UDA). It suggests that the authors explore another UDA method based on self-training, which is a prominent and effective approach within the field. This feedback is clear and actionable, providing a specific direction for the authors to consider expanding their work. However, the comment could be more helpful if it offered examples of other UDA methods based on self-training or provided guidance on how to integrate such methods into the current framework. Despite this, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the reliability diagrams (Fig 1, top) and notes that they do not make the proposed methods look better. It points out specific issues, such as high-accuracy spikes in low confidence regimes, and questions whether these are due to dataset pathologies or reflect variance in the proposed methods. While the comment identifies areas of concern, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The authors are left to infer that they should investigate the causes of these pathologies and potentially make adjustments to their methods. However, the lack of concrete instructions or suggestions makes the comment somewhat vague in terms of actionability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the reliability diagrams do not make the proposed methods look better and highlights specific concerns such as high-accuracy spikes in low confidence regimes. The comment further questions whether these issues are due to dataset pathologies or reflect variance in the proposed methods. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reliability of the proposed methods based on the reliability diagrams (Fig 1, top), noting that they do not make the methods look better and exhibit notable pathologies such as high-accuracy spikes in low confidence regimes. The reviewer suggests that these issues could be due to dataset pathologies or reflect variance in the proposed methods. While the comment identifies specific concerns, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion that a perfect system would have an identity function in the reliability diagram is a logical point, but without further elaboration or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reliability diagrams (Fig 1, top), noting that they do not make the proposed methods look better and exhibit notable pathologies such as high-accuracy spikes in low confidence regimes. The comment raises a pertinent question about whether these issues are due to dataset pathologies or reflect variance in the proposed methods. This feedback is somewhat helpful as it points out a potential weakness in the paper and prompts the authors to investigate the underlying causes of these pathologies. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into potential solutions. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the evaluation of advanced attacks beyond those considered. It suggests that the authors should consider the possibility of the attacker fine-tuning on a partial subset of the dataset, which could still contain poisoned data, and the implications of this for customer verification. Additionally, it points out that the paper only discusses detection of backdoors and does not address state-of-the-art (SOTA) methods for backdoor removal. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should expand their evaluation to include more advanced attacks and discuss SOTA methods for backdoor removal. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of advanced attacks and the consideration of fine-tuning on a partial subset of the dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of potential misbehavior verification and the lack of evaluation of advanced attacks and backdoor removal methods. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of advanced attacks beyond those considered in the paper. It provides a specific example of an advanced attack scenario, where the attacker could fine-tune on a partial subset of the dataset, which could still contain poisoned data. This reasoning is logical and provides a clear example to support the claim that the paper does not evaluate this scenario. Additionally, the comment points out that the paper only discusses detection of backdoors and does not address state-of-the-art (SOTA) methods for backdoor removal. This provides a comprehensive critique of the paper\\'s scope and evaluation. However, the comment could be strengthened by referencing specific SOTA methods or providing more detailed examples of advanced attacks. Overall, the claim is mostly verifiable, as it is well-supported by logical reasoning and examples, but could benefit from additional references or examples to be fully verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper regarding the evaluation of advanced attacks beyond those considered. It provides a specific example of an advanced attack scenario, where the attacker could fine-tune on a partial subset of the dataset, which could still contain poisoned data. This insight highlights a potential gap in the paper\\'s evaluation and suggests that the authors should consider this scenario to strengthen their analysis. Additionally, the comment points out that the paper only discusses detection of backdoors and does not address state-of-the-art (SOTA) methods for backdoor removal, which is an important aspect that could enhance the paper\\'s contribution. While the comment effectively identifies areas for improvement, it could be more helpful by offering specific suggestions on how to incorporate these considerations into the paper. Overall, the feedback is mostly helpful as it provides clear directions for expanding the scope and depth of the analysis, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper uses the original adjacency matrix without explanation or an ablation study, questioning the rationale behind not using the conventional graph convolutional operation. While the comment implies that the authors should provide an explanation or conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the original adjacency matrix in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the rationale behind not using the conventional graph convolutional operation and the lack of explanation or ablation study. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of using the original adjacency matrix without explanation or an ablation study, as opposed to the conventional graph convolutional operation. While it highlights a potential issue, it does not provide specific reasoning or evidence to support why this choice might be problematic. The comment lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is somewhat verifiable, as it raises a valid point but requires more detailed explanation or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methodology used in the paper, noting that the original GCN (Kipf and Welling) uses a normalized adjacency matrix with a renormalization trick, while the current paper uses the original adjacency matrix without explanation or an ablation study. The comment raises a valid question about the rationale behind this choice, which is important for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or why it is important. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the inclusion of a link for the WMT'15 training corpora but not for WMT'14. While it highlights a potential inconsistency, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors can infer that they might need to provide a link for WMT'14, but the comment lacks concrete details on how to implement this change or why it is important. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the inclusion of a link for the WMT\\'15 training corpora but not for WMT\\'14. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the missing link for WMT\\'14, but without clear grounding, the authors may struggle to identify the exact section or context where this issue is relevant. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the inclusion of a link for the WMT\\'15 training corpora but not for WMT\\'14. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the inclusion of a link for the WMT\\'15 training corpora but not for WMT\\'14. While it identifies a potential inconsistency in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or why it is important. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that upper and lower bounds for adaptive matrices A t and B t are needed to select other hyperparameters. However, it does not provide any explicit guidance or suggestions on how the authors should determine these bounds or what specific hyperparameters should be adjusted. The comment lacks concrete details on how to implement the suggested action, leaving the authors uncertain about the exact steps to take. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"upper and lower bounds for adaptive matrices A t and B t,\" which provides some grounding as it suggests a specific aspect of the paper that needs attention. However, it does not specify where in the paper these matrices are discussed, making it weakly grounded. The comment is also not specific because it does not provide details on what needs to be done to address the issue or how these bounds should be determined. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that \"upper and lower bounds for adaptive matrices A t and B t need to be known in order to pick other hyperparameters,\" but it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks detailed explanation or references that would help the authors understand the necessity or implications of determining these bounds. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to address the feedback effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue regarding the need for upper and lower bounds for adaptive matrices A t and B t in order to select other hyperparameters. This feedback is somewhat helpful as it points out a potential area for improvement in the methodology or experimental setup. However, it lacks depth and does not provide detailed guidance or suggestions on how the authors might address this issue or why it is important. The comment could be more helpful if it included specific examples or recommendations for determining these bounds or adjusting hyperparameters. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the techniques used is not particularly high, as they were previously proposed and demonstrated. It also suggests considering experimental results on the PDBbind dataset. While the comment implies that the authors should provide experimental results on this dataset, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to present these results or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the techniques used is not particularly high, as they were previously proposed and demonstrated. It also mentions the PDBbind dataset, implying that experimental results on this dataset could be considered. However, the comment does not specify which part of the paper discusses the novelty or the techniques used, making it weakly grounded. The suggestion to consider the PDBbind dataset is specific, as it provides a clear direction for potential improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the techniques used is not particularly high, as they were previously proposed and demonstrated. However, the comment lacks specific examples or references to substantiate this claim. Without detailed evidence or references to the prior work, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the techniques used in the paper, noting that they were previously proposed and demonstrated. It suggests considering experimental results on the PDBbind dataset, which could provide additional context or evidence for the novelty of the work. While the comment identifies a relevant area for improvement, it lacks specific guidance or suggestions on how to address the issue of novelty or how to incorporate the PDBbind dataset into the study. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer detailed, actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests adding error bars to the results of comparing pairs of models to demonstrate that the differences are significant and not merely due to noise. This is a clear and concrete action for the authors to take, providing specific guidance on how to enhance the presentation of their results. The comment leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding error bars to the results of comparing pairs of models to demonstrate the significance of differences. However, it does not specify which part of the paper this suggestion pertains to, such as specific figures or tables where comparisons are made. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed\u2014adding error bars to show the significance of differences. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding error bars to results comparing pairs of models would help demonstrate the significance of differences. However, the comment does not provide specific examples or references to support why error bars are necessary or how they would enhance the analysis. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of this suggestion. Therefore, the claim is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of results in the paper. By recommending the addition of error bars to the comparisons between pairs of models, the reviewer highlights a way to enhance the clarity and robustness of the analysis. This feedback is clear and directly addresses a potential weakness in the paper, offering a concrete step for the authors to take to improve their draft. However, the comment could be more helpful if it explained why error bars are particularly important in this context or how they might impact the interpretation of the results. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the full state is not defined properly and asks what is included in a full state. This provides a clear and direct action for the authors to take, which is to define the full state in their draft. The comment is specific and leaves no ambiguity about what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of the \"full state\" and asks for clarification on what is included in it. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation and a request for clarification regarding the definition of \"full state.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of \"full state\" on page 2, line 81. By pointing out this omission, the comment provides the authors with clear and actionable feedback on where to improve their draft. However, while it highlights the problem, it does not offer suggestions on how to address it or provide additional context that might help the authors understand the importance of this definition. Therefore, the comment is somewhat helpful, as it directs the authors to a specific area needing clarification but lacks depth in terms of guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the empirical study as good but points out the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insights but also include new initial proposals based on the analysis. However, the comment does not provide specific guidance on how the authors could develop new proposals or what aspects of their analysis could be expanded to include such proposals. The feedback is implicit and lacks concrete details on how to implement the suggested action, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the empirical study as good but criticizes it for lacking new proposals for neural architecture encoding. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what kind of new proposals are expected or how the current analysis could be improved. Without specific references or detailed guidance, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the empirical study as good but criticizes it for lacking new proposals for neural architecture encoding. The comment suggests that a good empirical analysis should not only provide insights but also include new initial proposals. However, the comment does not provide specific examples or references to support the claim that new proposals are necessary or how the current analysis could be improved. This lack of detailed justification or evidence makes the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment acknowledges the empirical study as good but points out a limitation: the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insights but also include new initial proposals based on the analysis. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might develop new proposals or what aspects of their analysis could be expanded to include them. This limits the comment\\'s usefulness, as it provides a general critique without actionable advice. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a clear and explicit recommendation for the authors to include empirical comparisons with existing algorithms. This direct suggestion gives the authors a specific action to take to improve their draft. Additionally, the comment highlights a concern about the practical usefulness of the algorithm, suggesting that SGD may require many iterations for convergence, which could lead to increased communication costs. However, the comment does not provide detailed guidance on how to address this concern or how to conduct the empirical comparisons. While the action is explicit, the lack of concrete details on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.5\" and the undefined terms \"\u0394_i, \u0394_med, and \u2207_i,\" allowing the authors to accurately identify the sections being addressed. It also provides specific feedback on the need for empirical comparisons with existing algorithms and raises concerns about the practical usefulness of the algorithm, particularly regarding the communication cost of SGD. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims: the lack of empirical comparison with existing algorithms, the theoretical nature of the paper, and the need for practical evaluation. The comment suggests that the theoretical comparison with existing algorithms is comprehensive but raises concerns about the practical usefulness of the algorithm due to the high communication cost of SGD. However, the review point lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the concerns. The mention of undefined terms in the paper is factual and does not constitute a claim. Therefore, the overall comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a mix of feedback, including a recommendation for empirical comparison with existing algorithms, a suggestion for the paper's evaluation, and detailed comments on specific issues. The suggestion to evaluate the paper as 'Marginally above the acceptance threshold' is a clear and actionable piece of feedback that can guide the authors in refining their work. The comment also highlights the lack of empirical results and the need for practical evaluation, which is crucial for the paper's impact. Additionally, it points out specific undefined terms in the paper, providing clear guidance on what needs to be addressed. However, the comment could be more helpful if it offered suggestions on how to conduct the empirical comparisons or provided examples of existing algorithms for comparison. Overall, the feedback is mostly helpful as it identifies key areas for improvement and provides actionable suggestions, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed approach performs well in simulations but struggles with real data, questioning its practical advantage. The reviewer implies that including more real data analyses or comparisons could help support the method. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these analyses or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to include more real data analyses but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed approach in various simulations and its lack of effectiveness in real data, questioning the practical advantage of the method. However, it does not specify which part of the paper discusses these simulations or real data analyses, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in suggesting the inclusion of more real data analyses or comparisons to support the method, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach performs well in simulations but struggles with real data, questioning its practical advantage. The comment suggests including more real data analyses or comparisons to support the method. While the claim is based on an observation of performance differences, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include more real data analyses is a logical step, but the comment could be strengthened with additional evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence to fully validate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed approach, noting that while it performs well in simulations, it struggles with real data, questioning its practical advantage. The comment suggests including more real data analyses or comparisons to support the method, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these analyses or comparisons. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing further exploration and validation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the claim regarding the solution\\'s low discrimination risk and improved fairness, while also mentioning the importance of maintaining the underlying data distribution after imputation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue of maintaining the data distribution or improve the fairness of their models. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim regarding the solution\\'s low discrimination risk and improved fairness, while also mentioning the importance of maintaining the underlying data distribution after imputation. However, it does not specify which part of the paper these claims are made in, nor does it provide details on how the authors can address the issue of maintaining the data distribution. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to identify and address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the claim regarding the solution\\'s low discrimination risk and improved fairness, while also mentioning the importance of maintaining the underlying data distribution after imputation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it raises valid concerns but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' claim regarding the solution\\'s low discrimination risk and improved fairness, while also mentioning the importance of maintaining the underlying data distribution after imputation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address these issues. It points out a potential weakness but does not guide the authors on how to improve their work or clarify their claims. As a result, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could exploit more data from the ReferIt dataset before moving on to other datasets. However, it does not provide specific guidance on how to exploit this data or what aspects of ReferIt should be used. The action is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792 \\\"larger test sets\\\"\" and provides a specific suggestion to exploit more data from the ReferIt dataset before moving on to other datasets. This allows the authors to accurately identify the part of the paper being addressed and understand the specific suggestion being made. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors could exploit more data from the ReferIt dataset before moving on to other datasets. However, it does not provide any supporting evidence, reasoning, or examples to justify why this suggestion would be beneficial or necessary. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the suggestion and how it might improve their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could exploit more data from the ReferIt dataset before moving on to other datasets. While it provides a specific suggestion for improvement, it lacks depth and does not explain why using more data from ReferIt would be beneficial or how it could enhance the paper. The comment is somewhat helpful as it offers a direction for improvement but does not provide detailed guidance or justification, leaving the authors with only a partial understanding of how to address the suggestion. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific sections of the paper (243-245 and 247) that are unclear and requests elaboration on certain aspects. It explicitly asks for clarification on why the explanation is unclear and why specific choices were made, such as using 5*3 instead of 5*2 and why KNN was used instead of another classifier. These questions provide clear and direct actions for the authors to take, as they know exactly what information needs to be clarified and why. The feedback is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (243-245 and 247), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the explanation of why 5*3 is used instead of 5*2 and the rationale behind using KNN instead of another classifier. This provides clear guidance on what the authors need to clarify or elaborate on. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding specific sections of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific sections of the paper (243-245 and 247) that are unclear and requests elaboration on certain aspects. It asks for clarification on why the explanation is unclear and why specific choices were made, such as using 5*3 instead of 5*2 and why KNN was used instead of another classifier. This feedback is clear and actionable, as it guides the authors to provide more detailed explanations and rationale for their choices. By addressing these points, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present the information more clearly or provided examples of what additional details might be helpful. Overall, the comment is mostly helpful, as it directs the authors to specific areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a detailed description of the background of Sharpness-Aware Minimization (SAM). This is a clear and direct action that the authors can take to improve their draft. However, the comment does not specify what aspects of SAM should be covered in the detailed description, leaving some room for interpretation. While the action is explicit, the lack of concrete guidance on how to implement it makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper currently lacks this description or where it should be added. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the background is discussed, the comment lacks full grounding. It is specific in suggesting that more detail is needed but does not provide detailed guidance on what aspects of SAM should be covered. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not provide any justification or reasoning for why this is necessary or how it would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. While it identifies a specific area that could be improved, it lacks depth and does not provide guidance on what aspects of SAM should be covered or how the description should be structured. This limits the comment\\'s usefulness, as it does not offer actionable steps for the authors to enhance their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the experimental setup lacks comprehensive comparisons between language-assisted and vision-assisted approaches. It provides a specific example of how to enhance the comparison by incorporating image guidance using related reference normal images or color-augmentation for the kNN baseline. This guidance is clear and concrete, giving the authors a direct action to take to improve their draft. The comment also emphasizes the importance of a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup\" and suggests specific comparisons between language-assisted and vision-assisted approaches. It provides a clear example of how to enhance the comparison by incorporating image guidance using related reference normal images or color-augmentation for the kNN baseline. This specificity helps the authors understand what needs to be addressed in the experimental setup. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup lacks comprehensive comparisons between language-assisted and vision-assisted approaches. It suggests incorporating image guidance by utilizing related reference normal images or color-augmentation for the kNN baseline to provide valuable insights. The comment provides a specific example of how to enhance the comparison, which adds to the verifiability of the claim. However, it could be strengthened by referencing similar studies or providing more detailed reasoning about why these comparisons are necessary. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental setup, noting the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides a concrete suggestion for improvement by recommending the incorporation of image guidance using related reference normal images or color-augmentation for the kNN baseline. This feedback is clear and actionable, offering the authors a specific direction to enhance their evaluation of LAFT\\'s efficacy. By addressing this point, the authors can significantly strengthen their experimental analysis. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing related work, specifically collective entity linking, which the reviewer suggests is closely related to the proposed model. The reviewer implies that the authors should include this line of work in their paper to provide a more comprehensive context. While the comment is explicit in identifying the missing related work, it does not provide detailed guidance on how to integrate this information into the paper. The action is clear but lacks concrete instructions on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a missing related work, specifically collective entity linking, which the reviewer suggests is closely related to the proposed model. However, it does not specify which part of the paper should include this related work, making it weakly grounded. The comment is specific in identifying the missing reference and suggesting that the proposed model is a special case of collective entity linking. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is a special case of collective entity linking, which is a closely related line of work. However, the comment does not provide specific references or detailed reasoning to support this claim. While it suggests that the paper should mention this related work, the lack of explicit evidence or examples makes it difficult for the authors to fully understand and address the critique. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, specifically the lack of related work on collective entity linking. It suggests that the proposed model is a special case of collective entity linking, which is a closely related line of work. By pointing out this gap, the comment provides the authors with a clear direction for improving their draft by including relevant references and discussing the connection to existing work. However, the comment could be more helpful if it offered specific examples or references to guide the authors in integrating this related work into their paper. Overall, the feedback is mostly helpful as it highlights a critical area for improvement and provides a general direction for enhancement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main issues. First, it suggests that truncating the log likelihood function might lower sensitivity and recommends comparing this to see the impact. This is an explicit suggestion for an additional analysis, providing a clear action for the authors to take. Second, it points out a discrepancy between the algorithm and the general framework regarding query functions for different data sources. The reviewer questions how to design customized query functions and suggests either designing them or removing the subscript for clarity. While the first part is explicit and actionable, the second part is more implicit and lacks concrete guidance on how to address the issue. Overall, the comment is mostly actionable as it provides clear actions for the authors to consider.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and the \"general framework,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of truncating the log likelihood function and its potential impact on sensitivity, as well as the discrepancy between the algorithm and the general framework regarding query functions for different data sources. The comment provides clear guidance on how to address these issues, such as comparing the impact of truncation or clarifying the query function design. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about truncating the log likelihood function potentially lowering sensitivity and suggests comparing this to see the impact. However, the comment lacks specific reasoning or evidence to support this claim, such as examples or references to studies where truncation has affected sensitivity. Additionally, the minor comments about the query functions in Algorithm 1 and the general framework are more factual observations rather than claims. Overall, the lack of detailed justification or evidence makes the claim unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment addresses two main points. First, it suggests that truncating the log likelihood function might lower sensitivity and recommends comparing this to see the impact. This is a clear and actionable suggestion that could lead to a deeper understanding of the method\\'s sensitivity. Second, it points out a discrepancy between the algorithm and the general framework regarding query functions for different data sources. The reviewer questions how to design customized query functions and suggests either designing them or removing the subscript for clarity. This feedback is specific and provides actionable guidance for the authors to improve the clarity and consistency of their work. Overall, the comment is mostly helpful as it identifies areas for improvement and offers constructive suggestions, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation should be expanded to include a larger and more diverse dataset, encompassing more complex molecules and materials. While the action is implied, it is clear and concrete, as it specifies the type of dataset that should be used for evaluation. The authors can infer that they need to test their method on a broader range of molecules and materials to improve the evaluation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights a limitation in the evaluation, specifically noting that it is restricted to a small set of molecules from the MD17 dataset. It suggests expanding the evaluation to include a larger and more diverse dataset, encompassing more complex molecules and materials. However, the comment does not specify which part of the paper discusses the evaluation, making it weakly grounded. The authors can infer that it relates to the evaluation section, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting what needs to be addressed\u2014expanding the dataset\u2014but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is limited to a small set of molecules from the MD17 dataset and suggests expanding the evaluation to include a larger and more diverse dataset. However, the comment does not provide specific examples or references to support the claim that a larger dataset would be beneficial or necessary. The reasoning is somewhat vague, as it lacks detailed justification or evidence to substantiate the need for a broader evaluation. Therefore, the claim is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation section, noting that it is restricted to a small set of molecules from the MD17 dataset. It suggests that the method should be tested on a larger and more diverse dataset, including more complex molecules and materials. This feedback is clear and actionable, as it provides a specific direction for expanding the evaluation to enhance the robustness and generalizability of the results. However, the comment could be more helpful if it offered additional guidance on how to select or access such datasets. Overall, the comment is mostly helpful as it highlights an important area for improvement and provides a clear suggestion for expanding the evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the differences between their work and the StreamingLLM paper, which is similar in some aspects. It explicitly states that the StreamingLLM paper has recently been uploaded, making it unlikely to compare the two works. The comment provides a clear action for the authors to take, which is to clarify the differences between their work and the StreamingLLM paper. However, it does not provide specific guidance on how to identify and articulate these differences, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"StreamingLLM paper\" and its authors, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors clarify the differences between their work and the StreamingLLM paper, particularly in terms of sink tokens and local attention. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the StreamingLLM paper is similar to the current work, particularly in terms of sink tokens and local attention. It suggests that the authors clarify the differences between their work and the StreamingLLM paper. The comment is mostly verifiable as it references a specific paper, \"Efficient Streaming Language Models with Attention Sinks,\" which provides a basis for the claim. However, the comment could be strengthened by providing more detailed comparisons or specific differences between the two works. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential overlap between the current work and the StreamingLLM paper, noting similarities in the use of sink tokens and local attention. It suggests that the authors clarify the differences between their work and the StreamingLLM paper, given that the latter has recently been uploaded. This feedback is clear and actionable, as it directs the authors to address a specific area of potential confusion or overlap in their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the differences or offered insights into the unique contributions of the current work. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that there is no significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be considered to enhance the qualitative results. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results and compares them to ConceptWeaver, which can handle more than two concepts. However, it does not specify which part of the paper discusses the qualitative results, making it weakly grounded. The comment does specify the issue of lacking significant improvement compared to ConceptWeaver, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. The reviewer supports this claim by referencing a specific paper, \"Concept Weaver,\" by Gihyun Kwon et al. This reference provides a clear basis for the claim, making it fully verifiable. The inclusion of a specific reference allows the authors to understand the context and basis of the comparison, ensuring that the claim is well-supported. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment points out a potential issue with the qualitative results, noting that there is no significant improvement compared to ConceptWeaver, which can handle more than two concepts. This feedback highlights a specific area where the paper may need to strengthen its claims or provide additional analysis. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. While it identifies a potential weakness, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider this approach, but without specific guidance on how to apply it, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper it addresses, making it not grounded. It also lacks specificity as it does not provide details on what aspect of the problem is being addressed or how the suggested approach could be implemented. Without clear references or detailed guidance, the authors cannot effectively understand or respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. While this provides a potential direction for improvement, the comment lacks specificity and does not offer detailed guidance or examples on how to implement this approach. It also does not address any specific weaknesses or areas for improvement in the current draft. As a result, the feedback is somewhat helpful, as it offers a general suggestion but lacks depth and actionable steps for the authors to follow.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with CCKT-Det++\\'s reliance on the quality and alignment of teacher models, noting that limitations or biases in these models could affect performance and introduce unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or mitigate the potential risks. It lacks specific actions or recommendations for improvement, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance of CCKT-Det++ on the quality and alignment of teacher models, highlighting potential issues if the teacher models have limitations or biases. However, it does not specify which part of the paper discusses CCKT-Det++ or the teacher models, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the potential issues with reliance on teacher models but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that CCKT-Det++\\'s performance is heavily reliant on the quality and alignment of teacher models, and that limitations or biases in these models could affect performance and introduce unintended biases. This claim is somewhat verifiable as it provides a logical reasoning about the potential impact of teacher model quality on the performance of CCKT-Det++. However, the comment lacks specific examples or references to substantiate the claim further, such as instances where teacher model limitations have affected performance in similar contexts. This makes the claim somewhat verifiable, as it requires additional evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the reliance of CCKT-Det++ on the quality and alignment of teacher models. It highlights the risk of performance issues and unintended biases if the teacher models have limitations or biases. This feedback is valuable as it prompts the authors to consider the robustness and reliability of their method, especially in terms of the quality of the teacher models. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending ways to mitigate the impact of teacher model limitations or biases. Overall, the comment is somewhat helpful as it points out a critical area for consideration but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the comparison objects in the comparison experiment are old and that the performance has not been significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their comparison. There is no guidance on selecting more relevant comparison objects, updating the experiment, or providing additional context or analysis to justify the chosen comparisons. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comparison objects used in the comparison experiment, noting that they are old and have not led to significant performance improvements. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the comparison objects and their performance, but without clear grounding, the authors may struggle to identify the exact section or experiment being referred to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison objects in the comparison experiment are old and have not led to significant performance improvements. However, the comment lacks specific examples or references to support this claim, such as naming the comparison objects or providing data on their performance. Without this information, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a potential issue with the comparison objects used in the comparison experiment, noting that they are old and have not led to significant performance improvements. While this feedback identifies a specific area for improvement, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment could be more helpful if it offered recommendations on selecting more relevant comparison objects or suggested ways to enhance the experimental setup to demonstrate improved performance. As it stands, the feedback is somewhat helpful, as it highlights a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how masks are handled in CNN layers, specifically in the representation block. While it highlights an area that may need clarification, it does not provide explicit guidance or suggestions for the authors to address this issue. The question implies that the authors should provide information on this topic, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how masks are handled in CNN layers, specifically in the representation block. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where masks are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about masks in CNN layers, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about how masks are handled in CNN layers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how masks are handled in CNN layers, specifically in the representation block. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is somewhat helpful as it points out a specific area that may need clarification, but it lacks depth and actionable advice, leaving the authors with only a vague direction for improvement. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about Figure 8, specifically asking for an explanation why \"without dropout\" has a larger training loss. It also mentions that activation clipping may reduce model capacity, suggesting a potential reason for the observed result. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation regarding why \"without dropout\" has a larger training loss, and it provides a potential reason for this observation (activation clipping reducing model capacity). This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding a specific observation in Figure 8. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about Figure 8, asking for an explanation why \"without dropout\" has a larger training loss. It also mentions a potential reason, such as activation clipping reducing model capacity, which could contribute to this observation. While the comment identifies a potential issue and provides a possible explanation, it lacks depth and does not offer actionable suggestions or guidance on how the authors might address this observation or improve their analysis. The feedback is somewhat helpful as it prompts the authors to consider and clarify this aspect of their results, but it could be more beneficial with additional context or suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the significance of the paper in establishing a large-scale matting dataset, which is not adequately discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes they should make to improve the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the significance of the paper in establishing a large-scale matting dataset, which is not adequately discussed. However, it does not specify which part of the paper should include this discussion or where the authors should focus their efforts. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s most significant contribution is in establishing a large-scale matting dataset, which is not adequately discussed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential significance of the paper, which is the establishment of a large-scale matting dataset. However, it does not provide any specific guidance or suggestions on how the authors could better highlight or discuss this aspect in their paper. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the number of adversarial examples is too small to demonstrate some distribution, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting ways to increase the number of adversarial examples or providing alternative methods to demonstrate the distribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the number of adversarial examples is too small to demonstrate some distribution, but it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspect of the distribution is not being demonstrated or how the number of examples could be increased. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the number of adversarial examples is too small to demonstrate some distribution.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the number of examples is insufficient. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the number of adversarial examples being too small to demonstrate some distribution. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit and concrete actions for the authors to consider. It suggests that the proposed channel-sparse gradients may not save time or memory in practice, as most frameworks only support dense gradients. The reviewer recommends conducting the analysis experiments or \"Qualitative Studies\" of Section 5.2 with the full set of common corruptions to ensure thoroughness and comparability with other results. These suggestions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2\" and the \"analysis experiments or \"Qualitative Studies\" of Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the proposed channel-sparse gradients, explaining why they may not save time or memory in practice and suggesting that the analysis experiments should be conducted with the full set of common corruptions for thoroughness and comparability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the practicality of the proposed channel-sparse gradients, suggesting that they may not save time or memory due to most frameworks only supporting dense gradients. The reviewer provides a logical reasoning by explaining that zeroing out a particular channel may not alter the computation performed. Additionally, the comment suggests that the analysis experiments in Section 5.2 should be conducted with the full set of common corruptions to ensure thoroughness and comparability with other results. This reasoning is mostly verifiable, as it provides a logical basis for the claim but lacks specific examples or references to support the assertion about frameworks and their limitations. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the proposed channel-sparse gradients, questioning their practicality and suggesting that they may not save time or memory in practice. It explains why this might be the case, noting that most frameworks only support dense gradients. The comment also points out that the analysis experiments in Section 5.2 are limited to a subset of common corruptions, which may not generalize to the full set. The reviewer offers a clear and actionable suggestion to conduct the experiments with the full set of corruptions for thoroughness and comparability with other results. This feedback is highly helpful as it identifies specific weaknesses and provides a concrete recommendation for improvement, empowering the authors to enhance the robustness and validity of their analysis.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the authors\\' claims regarding sparsity and low rank, suggesting that the proof may be using concentration-of-measure principles, which have connections to low rank. However, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The comment implies that the authors should reconsider their claims and possibly provide more detailed justification or analysis, but it lacks concrete steps or suggestions for how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the proof\\'s reliance on concentration-of-measure principles, which are related to low rank. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the proof and the connection to low rank, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the proof\\'s reliance on concentration-of-measure principles, which are related to low rank, and questions the strength of the claim regarding the lack of consideration for low rank. The reviewer provides a logical reasoning by suggesting that the proof may be using concentration-of-measure principles, which have connections to low rank. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is somewhat clear, the absence of explicit evidence or references makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' claim of not considering sparsity or low rank, suggesting that the proof may be using concentration-of-measure principles, which are related to low rank. This observation challenges the authors\\' assertion that low rank is not considered, providing a critical perspective on the paper\\'s claims. Additionally, the comment questions the novelty of the results, suggesting that they may be a simple extension of existing work. While the comment identifies potential weaknesses and raises important questions, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is somewhat helpful as it prompts the authors to reconsider their claims and possibly provide more detailed justification or analysis, but it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide specific guidance on how to expand the Limitations section or what aspects should be included. The feedback is vague and lacks explicit instructions, leaving the authors uncertain about how to address the issue. Since the action is not clearly stated and lacks concrete details, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Limitations section,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, the comment lacks specificity as it does not detail what aspects of the limitations section are considered too concise or how they could be improved. Without specific guidance, the authors may struggle to understand exactly what changes are needed to enhance the clarity and detail of the limitations section. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the \"Limitations section is too concise\" compared to the detailed writing style in the main body of the paper. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. While it identifies a potential issue, it lacks specificity and does not provide actionable guidance on how to improve the section. The authors are informed of a problem but are not given clear steps to address it, making the feedback somewhat helpful. It highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is weak, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty of their method or differentiate it from existing work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the proposed method, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on how the proposed method differs from PatchCore or what specific aspects of the denoising process are lacking in novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment lacks specific details or references to support this claim. It does not provide examples or evidence of how the proposed method is similar to PatchCore or how the denoising process is not novel. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique without additional information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the proposed method, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. While this feedback identifies a weakness in the originality of the method, it lacks specific guidance or suggestions on how the authors might address this issue or differentiate their work from existing literature. Without actionable advice or detailed critique, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two specific issues: the lack of clear instructions for installing the software and running the code, and the need for more details about each challenge and the prompts used in the evaluation. The reviewer suggests providing these details in an extensive version of Table 1 or in the appendix, similar to binpwn. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what changes are needed to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the repository and the lack of clear instructions for installing the software and running the code. It also suggests providing more details about each challenge in an extensive version of Table 1 or in the appendix, similar to binpwn. Additionally, it recommends listing all prompts used in the evaluation in the appendix or on GitHub. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the repository lacks clear instructions for installing the software and running the code, which is why the reviewer could not run the code. The suggestion to provide more details about each challenge and list all prompts used in the evaluation is based on the need for clarity and completeness. However, the comment does not provide specific examples or references to support the claim about the lack of clarity in the instructions. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the issue without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clear instructions for installing the software and running the code, which prevented the reviewer from testing the code. It provides a clear and actionable suggestion to improve the paper by recommending the inclusion of more detailed instructions, either in an extensive version of Table 1 or in the appendix, similar to binpwn. Additionally, it suggests listing all prompts used in the evaluation in the appendix or on GitHub. This feedback is specific, constructive, and offers a clear path for the authors to enhance the usability and reproducibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v may be more crucial than other components. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this discrepancy or improve their draft based on this information. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the global representation g_v seems more crucial than other components, which departs from the major claim of interpretable VQA. This provides clear guidance on what aspect of the results is being questioned. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the global representation g_v is more crucial than other components, as evidenced by the model ablation results in Table 3. This claim is somewhat verifiable as it references specific results in the paper, which provides some support for the assertion. However, the comment does not provide detailed reasoning or examples from the table to fully substantiate the claim, leaving the authors to infer the significance of g_v based on the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v may be more crucial than other components. This observation is valuable as it highlights a potential issue with the paper\\'s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this discrepancy or improve their interpretation of the results. While it points out an important area for consideration, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion regarding the notation in Section 3, specifically recommending the use of \"left inverses\" instead of the notation $f^{-1} = g$. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what change to make to improve their draft. The comment is also concrete, as it specifies the alternative notation that should be used. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"notation paragraph in sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the notation used, suggesting that the notation $f^{-1} = g$ should be avoided due to the domain restriction and the potential for $f$ to not be an invertible function. The comment further suggests using the language of left inverses instead. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the notation used in the paper, specifically the statement $f^{-1} = g$, suggesting that it should be avoided due to the domain restriction of $f$ being $\\mathbb{R}^D$. The reviewer provides a logical reasoning by explaining that when $d<D$, $f$ cannot be an invertible function, and suggests using the language of left inverses instead. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the suggestion of using left inverses. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the notation used in the paper. It points out a potential issue with the notation $f^{-1} = g$ when $d<D$, where $f$ is defined as a function on $\\mathbb{R}^D$. The reviewer suggests that this notation should be avoided and recommends using the language of left inverses instead. This feedback is clear and constructive, offering a precise direction for the authors to improve their notation and potentially enhance the clarity of their work. By addressing this comment, the authors can make a concrete improvement to their draft. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask, in their ablation studies on the motion tokenizer. This feedback provides a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve their draft. The comment is concrete, as it outlines the specific models to compare against and the purpose of these comparisons, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for comparisons with state-of-the-art RVQ-VAE models, such as MoMask, in the ablation studies on the motion tokenizer. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation studies on the motion tokenizer in Table 4 should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask, to provide a more comprehensive understanding of the model\\'s effectiveness. The claim is somewhat verifiable as it logically argues that such comparisons would enhance the understanding of the model\\'s performance relative to existing benchmarks. However, the comment lacks specific examples or detailed reasoning to fully substantiate the need for these comparisons, leaving some gaps in the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending comparisons with state-of-the-art RVQ-VAE models, such as MoMask, in the ablation studies on the motion tokenizer. This feedback is clear and constructive, as it highlights a gap in the current analysis and suggests a way to enhance the understanding of the model\\'s effectiveness. By following this advice, the authors can provide a more comprehensive evaluation of their approach, which is crucial for strengthening the paper\\'s contribution. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but its difference from nuclearity is unclear and not precisely defined. While the comment identifies an area that needs clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The authors are left to infer that they need to define and differentiate between these concepts, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that the \"primary-secondary\" relationship is mentioned frequently but its difference from nuclearity is unclear and not precisely defined. This provides a clear indication of what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper discusses this relationship, leaving the authors to infer where this issue might be present. Therefore, the comment is weakly grounded because it does not specify the exact section, but it is specific in identifying the issue. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently but its difference from nuclearity is unclear and not precisely defined. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the \"primary-secondary\" relationship is mentioned frequently but its difference from nuclearity is unclear and not precisely defined. This feedback highlights a potential area of confusion or lack of clarity in the paper, which is valuable for the authors to address. However, the comment does not provide specific suggestions or guidance on how to clarify or define this relationship, leaving the authors with a general direction but without detailed actionable steps. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the effect of the mask ratio across different datasets, which could lead to more tuning, as mentioned in the limitations. It also points out that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should include a discussion on the impact of the mask ratio and provide guidance on choosing it. The action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the impact of the mask ratio on different datasets, which is a specific issue that the authors should consider. However, it does not explicitly mention which part of the paper discusses the mask ratio, making it weakly grounded. The comment is specific in its request for an intuitive guide for choosing the mask ratio and highlights the need for more discussion on this aspect. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, which could lead to more tuning, as mentioned in the limitations. However, the comment lacks specific examples or detailed reasoning to support this claim. It also suggests that the impact of the mask ratio is missing from the discussions and that an intuitive guide for choosing this ratio would be helpful. While the comment identifies a potential issue, it does not provide sufficient evidence or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore and justify the impact of the mask ratio themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the impact of the mask ratio on different datasets, which could lead to more tuning, as mentioned in the limitations. It points out that the discussion on the impact of the mask ratio is missing, and suggests that an intuitive guide for choosing this ratio would be beneficial. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address to improve their draft. However, it could be more helpful if it provided specific suggestions or examples on how to develop such a guide. Overall, the comment is mostly helpful, as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading due to sections that are difficult to follow. While the action is explicit, it lacks concrete guidance on which sections are particularly problematic or how to improve them. The authors are left with a general suggestion to proofread but without specific instructions on what needs to be addressed. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading due to sections that are difficult to follow. However, it does not specify which sections are problematic or provide details on what makes them difficult to follow. This lack of specificity and grounding makes it challenging for the authors to identify and address the issues effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proof-reading due to sections that are difficult to follow. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the sections are problematic, the authors may find it challenging to identify and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading due to sections that are difficult to follow. While it identifies a potential issue, it lacks specificity and does not provide detailed guidance on which sections are problematic or how the authors might improve them. Without concrete examples or suggestions for improvement, the feedback is limited in its usefulness to the authors. Therefore, the comment is barely helpful, as it points out a general area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"STG layer\" in Figure 2 has not been mentioned anywhere else in the manuscript, and the reviewer guesses it refers to stochastic gates. This feedback implies that the authors should clarify the meaning of \"STG layer\" in the manuscript, either by defining it or providing context. However, the comment does not explicitly instruct the authors to make this clarification, and it lacks concrete guidance on how to address the issue. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of the term \"STG layer\" not being mentioned elsewhere in the manuscript and suggests that it might refer to stochastic gates. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the term \"STG layer\" in Figure 2, noting that it has not been mentioned elsewhere in the manuscript. The reviewer speculates that it might refer to stochastic gates but expresses uncertainty. This comment is somewhat verifiable as it highlights a potential inconsistency in the manuscript, but it lacks specific examples or references to support the claim. The authors would need to make an effort to verify and address the issue themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the term \"STG layer\" in Figure 2 has not been mentioned elsewhere in the text. This is a clear and actionable piece of feedback, as it prompts the authors to clarify the meaning of this term or provide context for its use. By addressing this point, the authors can improve the coherence and clarity of their manuscript. However, the comment could be more helpful if it suggested how to integrate this term into the text or provided examples of how similar terms have been handled in other papers. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the improvements resulting from the proposed methodology are limited in some instances and that it even underperforms compared to the baseline in the cases of FiQA and CONALA. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their methodology. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the performance. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the proposed methodology, noting that its improvements are limited in some instances and that it even underperforms compared to the baseline in the cases of FiQA and CONALA. However, it does not specify which part of the paper discusses these instances or provides details on why the improvements are limited or how the baseline outperforms. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements resulting from the proposed methodology are limited in some instances and that it even underperforms compared to the baseline in the cases of FiQA and CONALA. However, the comment lacks specific examples, detailed comparisons, or references to support these claims. Without such evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methodology, noting that its improvements are limited in some instances and that it even underperforms compared to the baseline in the cases of FiQA and CONALA. This feedback highlights a potential weakness in the paper that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their methodology or address the underperformance issues. Without actionable advice or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparisons with a specific reference, \"[1] Differentially private model personalization. NeurIPS 2021,\" are not clear. It asks what the contributions or advantages are beyond this reference. While the comment implies that the authors should clarify the comparisons and highlight their contributions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer comparison and highlight their contributions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for clearer comparisons with a specific reference, \"[1] Differentially private model personalization. NeurIPS 2021,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the contributions or advantages beyond this reference, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of comparisons with a specific reference, \"[1] Differentially private model personalization. NeurIPS 2021,\" and asks for the contributions or advantages beyond this reference. While the comment highlights a potential issue with the paper\\'s comparisons, it does not provide specific reasoning or examples to support why the comparisons are unclear or how they could be improved. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that comparisons with a particular reference, \"[1] Differentially private model personalization. NeurIPS 2021,\" are not clear. It asks for clarification on the contributions or advantages beyond this reference, which is a relevant point for the authors to address. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might improve the clarity of their comparisons or highlight their contributions. While it points out an area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It explicitly instructs the authors to provide a well-explained rationale for why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the re-balancing step method, which is used to make multi-modal learning less greedy. It points out that this method is not well described and analyzed in the full text. The comment also specifies that the authors should provide a well-explained rationale for why using the average feature of previous samples can stop the training of the uni-modal branch. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where the re-balancing step is discussed. The comment is specific in detailing what needs to be addressed, providing clear guidance on what the authors should focus on improving. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the re-balancing step method, used to make multi-modal learning less greedy, is not well described and analyzed in the full text. The reviewer suggests that the authors should provide a well-explained rationale for why using the average feature of previous samples can stop the training of the uni-modal branch. While the comment identifies a gap in the explanation, it lacks specific examples or detailed reasoning to support the claim. The authors are left to infer the necessary improvements without clear guidance. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the description and analysis of the re-balancing step method used to make multi-modal learning less greedy. It suggests that the authors should provide a well-explained rationale for why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that requires further explanation. By addressing this point, the authors can improve the comprehensibility and robustness of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of similar approaches. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and whether harmful OOD instances can be identified using an entropy metric instead of an energy one. While these questions imply that the authors should clarify these aspects in their paper, they do not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or what information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and the \"Reduce\" part, allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issues by questioning the differences and advantages of the \"Reduce\" part compared to EATA and whether harmful OOD instances can be identified using an entropy metric instead of an energy one. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and comparison with existing work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is purely factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the differences and advantages of the \"Reduce\" part compared to EATA, as well as whether harmful OOD instances can be identified using an entropy metric instead of an energy one. While it highlights areas that need clarification, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their draft. The comment prompts the authors to consider these aspects, but without actionable advice, it offers limited assistance in improving the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it explicitly states that this comparison is not necessary to support the main claims of the paper. The comment implies that the authors could consider including such a comparison, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a potential comparison, but it does not provide detailed guidance on how to implement this comparison or what specific aspects should be considered. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable due to the absence of supporting information.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. While it acknowledges that this comparison is not necessary to support the main claims of the paper, it still provides a direction for potential improvement. The comment is somewhat helpful as it offers a suggestion for further exploration, but it lacks depth and does not provide specific guidance on how to conduct this comparison or what aspects to focus on. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the naming of a column in Table 4, specifically questioning whether the 3r column should be named ATE. It also mentions that Corr is also Cau-Ant. However, the comment does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether this is a suggestion for correction or a request for clarification. Without any actionable advice or specific instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and the specific column \"3r,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the naming of the column and clarifies that \"Corr\" is also \"Cau-Ant,\" providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the naming of a column in Table 4, specifically questioning whether the 3r column should be named ATE and clarifying that Corr is also Cau-Ant. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the naming of a column in Table 4, specifically questioning whether the 3r column should be named ATE. It also clarifies that Corr is also Cau-Ant. While this feedback identifies a potential inconsistency in the naming of the column, it does not provide any actionable suggestions or guidance on how to address this issue. The comment lacks depth and does not offer a clear path for the authors to improve their draft. As a result, the feedback is barely helpful, as it points out a minor issue but does not assist the authors in making meaningful improvements to their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the mechanism is not clearly anchored in prior work, even after the experiments section, and recommends that more clarity on the methods' foundations would be helpful. This is an implicit suggestion to provide a clearer connection to prior work, which is somewhat actionable as it gives a direction but lacks concrete steps on how to achieve this. Second, the comment suggests annotating or zooming in on the figures to help clarify the differences in the curves. This is an explicit and concrete suggestion, providing a clear action for the authors to take. Overall, the comment offers a mix of implicit and explicit actions, with varying levels of concreteness, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions the \"mechanism\" and the \"methods section,\" allowing the authors to infer the parts of the paper being addressed. However, it does not specify which figures or sections are problematic, making it challenging for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting that the mechanism is not clearly anchored in prior work and that more clarity is needed, particularly in the methods section. It also provides specific feedback on the figures, recommending annotation or zooming to clarify the differences in the curves. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the mechanism being anchored in prior work and suggests that the authors provide more clarity on the methods' foundations. It also critiques the figures, stating that it is difficult to see the differences in the curves and recommends annotating or zooming in to ground them quantitatively. While the comment identifies areas for improvement, it lacks specific examples or references to prior work or other studies that could help substantiate the claim about the mechanism not being clearly anchored. The suggestion to annotate or zoom in on the figures is a practical recommendation, but it is not supported by detailed reasoning or evidence. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks comprehensive justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it points out a lack of clarity in anchoring the mechanism in prior work, suggesting that more clarity on the methods' foundations would be beneficial. This is a clear and actionable suggestion that can help the authors improve the context and relevance of their work. Second, the comment critiques the clarity of the figures, noting that it is difficult to see the differences in the curves and suggesting that annotating or zooming in could help ground the results quantitatively. This feedback is also actionable, as it provides a specific way to enhance the visual presentation of the results. Both pieces of feedback are clear and offer constructive suggestions for improvement, making the comment mostly helpful. However, it could be more comprehensive by providing additional guidance or examples on how to anchor the mechanism in prior work or how to effectively annotate the figures. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the limited novelty of the paper, noting that the key contribution is the application of a pre-trained mechanism to the task of few-shot graph learning. However, it does not provide any specific guidance or suggestions on how the authors could address this concern or enhance the novelty of their work. The comment lacks actionable details, such as recommending ways to improve the novelty or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the limited novelty of the paper, specifically mentioning the pre-trained mechanism applied to the task of few-shot graph learning. However, it does not specify which part of the paper this concern is based on, such as a particular section or experiment. The authors might infer that it relates to the introduction or discussion of the main contribution, but this inference is not direct. The comment is specific in its critique of the novelty but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s novelty is limited, specifically mentioning the pre-trained mechanism applied to few-shot graph learning. However, the comment lacks specific examples or references to support this claim, such as comparisons to existing works or detailed explanations of what makes the contribution less novel. Without these elements, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the limited novelty of the paper, specifically pointing out that the key contribution is the application of a pre-trained mechanism to the task of few-shot graph learning. While the comment acknowledges that the idea seems plausible, it suggests that it is not particularly exciting or straightforward. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty or complexity of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the theoretical understanding of why certain setups or parameters do not collapse during test time training. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include theoretical analysis, but it lacks concrete steps or specific areas to focus on. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the empirical validation of setups and parameters for test time training but notes the absence of theoretical understanding regarding why they do not collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of theoretical understanding, but without clear grounding, the authors may struggle to pinpoint where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper empirically validates setups and parameters for test time training but lacks theoretical understanding of why they do not collapse. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the theoretical understanding of why certain setups or parameters do not collapse during test time training. While it highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this gap. The comment points out a potential weakness but does not provide actionable steps or detailed feedback, leaving the authors with a general direction but without clear instructions on how to enhance their draft. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, questioning whether it is based on training or test images. However, it does not provide explicit guidance on how the authors should address this issue or clarify the analysis. The comment implies that the authors should clarify the source of the visual analysis, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the visual analysis in Section 4.4 is based on training or test images, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the visual analysis in Section 4.4, specifically whether it is based on training or test images. This is a request for clarification rather than a subjective claim or opinion. It does not suggest changes or express judgments, making it a factual inquiry. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the visual analysis in Section 4.4, questioning whether it is based on training or test images. This is a relevant point that could impact the interpretation of the results, as the method does not require pose estimation in the inference. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this aspect or improve the clarity of their analysis. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors apply the DEER method to other methods like LEM or UnICORNN to explore potential performance improvements. It raises questions about whether these methods could maintain the same performance or achieve better performance when trained with DEER, and whether faster training could lead to better hyperparameter tuning. While the comment implies that such an exploration would strengthen the paper and broaden its impact, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests applying the DEER method to other methods like LEM or UnICORNN to explore potential performance improvements. It raises questions about whether these methods could maintain the same performance or achieve better performance when trained with DEER, and whether faster training could lead to better hyperparameter tuning. However, the comment does not specify which part of the paper should include this exploration, making it weakly grounded. The suggestion is specific in terms of what could be explored, but without clear grounding, the authors may struggle to identify where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that applying the DEER method to other methods like LEM or UnICORNN could provide insights into their performance and potential for improvement. The comment raises logical questions about whether these methods could maintain the same performance or achieve better performance when trained with DEER, and whether faster training could lead to better hyperparameter tuning. However, the comment lacks specific examples or references to support the claim that these methods could be trained with DEER or that faster training would lead to better performance. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting exploration by proposing the application of the DEER method to other methods like LEM or UnICORNN. It raises thought-provoking questions about the potential performance improvements and faster training that could result from using the DEER method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by broadening its scope and impact. However, the comment could be more helpful if it included specific guidance on how to conduct this exploration or what aspects to focus on. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the presentation is difficult to follow due to the excessive use of notations. However, it does not provide specific guidance on which notations are problematic or how the authors should address this issue. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the clarity of their presentation. Since the comment is vague and does not offer actionable steps, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the presentation is difficult to follow due to the excessive use of notations. However, it does not specify which part of the paper this issue occurs in, nor does it provide details on which notations are problematic or how they could be improved. Without specific references or detailed guidance, the authors cannot effectively identify the areas needing revision. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation is difficult to follow due to the excessive use of notations. However, it does not provide specific examples of which notations are problematic or how they contribute to the difficulty in understanding the content. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the presentation of the paper, noting that it is difficult to follow due to the excessive use of notations. This feedback is valuable as it highlights a potential barrier to understanding the content. However, the comment lacks depth and does not provide specific examples of which notations are problematic or suggestions on how to simplify the presentation. Without actionable guidance, the authors are left with a general idea of what needs to be improved but without clear steps to take. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results from GPT-4V, despite the API not being released yet. The reviewer provides a specific action by recommending that the authors conduct quick experiments through ChatGPT\\'s UI. This feedback is explicit and provides a clear direction for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including results from GPT-4V, which is a specific model. However, it does not specify where in the paper these results should be included or how they would fit into the existing content. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of GPT-4V results but lacks grounding as it does not pinpoint a particular section or context in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results from GPT-4V, despite the API not being released yet. The reviewer provides a rationale by suggesting that quick experiments through ChatGPT\\'s UI could be sufficient. However, the comment lacks specific examples or references to support the claim that such experiments would be beneficial or necessary. The suggestion is somewhat verifiable, as it provides a logical reasoning for including GPT-4V results, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including results from GPT-4V, despite the API not being released yet. The reviewer provides a practical suggestion by recommending that the authors conduct quick experiments through ChatGPT\\'s UI. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating additional results. However, the comment could be more helpful if it explained why including GPT-4V results would be beneficial or how they might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it provides a specific suggestion for improvement, but it could be more comprehensive with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the implications of their theoretical analysis more thoroughly, specifically comparing CoPur with baselines to understand why it performs better. While the comment implies that the authors should provide a deeper analysis and comparison, it does not explicitly instruct them to do so or offer specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the implications of their theoretical analysis more thoroughly, specifically comparing CoPur with baselines to understand why it performs better. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a deeper analysis and comparison, providing clear guidance on what the authors should address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis and recommends discussing the implications of this analysis further. It also questions why CoPur performs better compared to baselines. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the analysis is extensive or to justify why CoPur performs better. Without such supporting information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the extensive theoretical analysis provided in the paper and suggests that the authors should discuss the implications of this analysis more thoroughly. It also questions why CoPur performs better compared to baselines, indicating a need for further explanation and comparison. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out a potential weakness and encourages a deeper analysis, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the evaluation metrics used in the paper, specifically noting that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics, keypoint distance, does not assess the quality of the motions. It also questions the clarity of the evaluation protocol, specifically asking whether the camera parameters are the same for all frames when generating the videos. While the comment identifies areas of concern, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the evaluation protocol and potentially add additional metrics to assess motion quality. However, the lack of specific guidance on how to implement these changes makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the evaluation section, allowing the authors to identify the part of the paper being discussed. It is also specific because it details the issues with the reported metrics, particularly the lack of assessment of motion quality beyond keypoint distance, and questions the clarity of the evaluation protocol regarding camera parameters. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics used in the paper, specifically noting that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics, keypoint distance, does not assess the quality of the motions. The reviewer also questions the clarity of the evaluation protocol, specifically asking whether the camera parameters are the same for all frames when generating the videos. While the comment identifies potential issues, it lacks specific examples or references to support the claims about the evaluation protocol or the inadequacy of the metrics. This makes the comment somewhat verifiable, as it provides a basis for the critique but requires further detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metrics used in the paper, noting that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics, keypoint distance, does not assess the quality of the motions. It also questions the clarity of the evaluation protocol, specifically asking whether the camera parameters are the same for all frames when generating the videos. This feedback is clear and actionable, as it highlights a potential gap in the evaluation process and suggests a specific area for improvement. By addressing these concerns, the authors can enhance the robustness and clarity of their evaluation, making the comment mostly helpful. However, it could be more comprehensive by offering suggestions on how to improve the evaluation protocol or additional metrics to consider. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the presentation of the two parts of pretraining and regularization is disjointed, suggesting that this detracts from the coherence of the paper. However, it does not provide specific guidance on how the authors should address this issue or what changes should be made to integrate these components more naturally. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to improve the coherence of their paper. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the presentation of two parts of pretraining and regularization, suggesting that they appear as incremental additions rather than integrated components. However, it does not specify which sections or parts of the paper this issue pertains to, making it weakly grounded. The comment does specify the problem of disjointed presentation, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation of pretraining and regularization is disjointed, suggesting that these components are presented as incremental additions rather than integrated components. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to illustrate how the presentation is disjointed, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the coherence of the paper, specifically noting that the presentation of pretraining and regularization appears disjointed. This feedback highlights a structural problem that could affect the reader\\'s understanding and engagement with the paper. However, the comment lacks specific suggestions or guidance on how the authors might integrate these components more naturally or improve the coherence of their presentation. While it points out an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the importance of Renyi divergence is not well explained and that it is unclear why Renyi divergence is special for a reader unfamiliar with differential privacy. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the explanation. The comment lacks concrete details on what aspects of the explanation need clarification or how the authors should enhance the explanation. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of explanation regarding the importance of Renyi divergence, specifically for a reader unfamiliar with differential privacy. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of why Renyi divergence is significant, providing some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the importance of Renyi divergence is not well explained, particularly for a reader unfamiliar with differential privacy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is lacking or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved: the explanation of the importance of Renyi divergence. It highlights the lack of clarity for readers unfamiliar with differential privacy, indicating that the authors need to provide a more detailed explanation. While the comment points out a relevant issue, it does not offer specific suggestions or guidance on how to enhance the explanation or what aspects should be emphasized. This limits the comment\\'s usefulness, as the authors are left with a general idea of what needs to be improved but without detailed direction on how to achieve it. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying heavily on mathematical theories. However, it does not provide specific guidance on how to achieve this simplicity and clarity or which parts of the paper should be revised. The action is implicit and vague, leaving the authors without clear steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should prioritize simplicity and clarity over mathematical complexity. However, it does not specify which parts of the paper are overly complex or lack clarity, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment does not provide specific examples or guidance on how to achieve the desired simplicity and clarity. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity rather than relying on mathematical theories. However, it does not provide any specific examples, reasoning, or evidence to support why this shift is necessary or how it would improve the paper. The lack of detailed justification or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should prioritize simplicity and clarity over mathematical complexity, which is a valid point. However, it lacks specificity and does not provide actionable guidance on how to achieve this goal or which parts of the paper are overly complex. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the ablation study in the work is limited and suggests that the impact of the pre-defined threshold \\\\(\\\\epsilon\\\\) should be further studied. While the comment identifies an area for improvement, it does not provide specific guidance on how to conduct this study or what aspects of \\\\(\\\\epsilon\\\\) should be examined. The action is implicit and somewhat vague, as the authors are left to infer the details of how to expand the ablation study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ablation study in the paper, specifically mentioning the impact of the pre-defined threshold \\\\(\\\\epsilon\\\\) as an area that needs further study. However, it does not specify which part of the ablation study this pertains to, such as a particular section or table. The authors can infer that it relates to the ablation study section, but this inference is not as direct as it could be. The comment is specific in suggesting that the impact of \\\\(\\\\epsilon\\\\) should be further studied, but it lacks full grounding because it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the ablation study is limited, specifically mentioning the need for further study on the impact of the pre-defined threshold \\\\(\\\\epsilon\\\\). However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this aspect of the study is insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the ablation study, specifically pointing out that the impact of the pre-defined threshold \\\\(\\\\epsilon\\\\) has not been sufficiently explored. This feedback is somewhat helpful as it highlights an area where the authors could expand their analysis to provide a more comprehensive understanding of their results. However, the comment lacks specific suggestions or guidance on how to conduct this additional study, such as what aspects of \\\\(\\\\epsilon\\\\) should be examined or how to present the findings. To be more helpful, the comment could include actionable steps or examples to guide the authors in addressing this issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that only Rouge-L is used for evaluation, suggesting that this choice may not be reliable, especially for classification tasks where Rouge-L might not be sensitive enough. However, the comment does not provide explicit guidance on what alternative evaluation metrics should be considered or how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should consider additional evaluation metrics but without specific suggestions on which ones to use or how to implement them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the evaluation methodology, noting that only Rouge-L is used, which may not be reliable, especially for classification tasks where Rouge-L might not be sensitive enough. However, it does not specify which part of the paper discusses the evaluation methodology, making it weakly grounded. The comment is specific in pointing out the issue with the choice of evaluation metric and its potential limitations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using only Rouge-L for evaluation is not reliable, especially for classification tasks where Rouge-L might not be sensitive enough. This claim is somewhat verifiable as it provides a logical reasoning that Rouge-L might not be suitable for certain tasks. However, the comment lacks specific examples or references to support the claim that Rouge-L is insufficient for classification tasks. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation methodology, noting that only Rouge-L is used, which may not be reliable, especially for classification tasks where Rouge-L might not be sensitive enough. This feedback is clear and actionable, as it highlights a potential weakness in the evaluation process and suggests that alternative metrics should be considered to ensure a more robust evaluation. However, the comment could be more helpful if it provided specific examples of alternative metrics or discussed how to incorporate them into the evaluation framework. Despite this, the feedback is mostly helpful as it directs the authors to reconsider their evaluation approach, which can lead to significant improvements in the draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the definitions of variables not matching the formula in lines 580-588, specifically pointing out that the variable $n_k$ is missing from Equation 3. This feedback provides a clear and direct action for the authors to take, which is to ensure that the definitions of variables align with the formulas in the paper. The comment is specific and provides concrete guidance on what needs to be corrected, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula, particularly the absence of $n_k$ in Equation 3. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables do not match the formula, specifically mentioning the absence of $n_k$ in Equation 3. This is a precise observation that can be verified by checking the alignment of variables in the text with the equation. The comment provides a clear and specific example, making it fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables not matching the formula, particularly the absence of $n_k$ in Equation 3. This feedback is clear and actionable, as it provides the authors with a precise area to correct in their draft. By addressing this discrepancy, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or provided additional context on why this mismatch is important. Overall, the comment is mostly helpful as it directs the authors to a critical area needing correction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, questioning whether this approach conflicts with the whole sample-specific assumption the paper rests upon. Additionally, it mentions the absence of key experiments. While the comment implies that the authors should address these concerns, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the approach and conduct the missing experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, questioning whether this conflicts with the whole sample-specific assumption the paper rests upon. It also mentions the absence of key experiments. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors might infer that it relates to sections discussing the methodology or results, but this inference is not direct. The comment is specific in its critique of the approach and the missing experiments, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and observations about the methodology and assumptions of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the sufficiency of a single vector for each class with large variances in the semantic space, questioning whether this approach conflicts with the paper\\'s assumption of whole sample-specificity. This is a valuable point that could lead to a deeper exploration of the methodology. Additionally, the comment notes the absence of key experiments, which is a critical observation that could guide the authors in strengthening their experimental section. However, the comment lacks specific suggestions or guidance on how to address these issues, such as proposing alternative approaches or additional experiments. While it identifies important areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known intent classes during graph construction. It questions whether the IntenDD experiments reported in Table 1 are comparable to the cited baselines under this assumption. The reviewer suggests that further clarification is needed on the intent discovery experiment setting to ensure a fair comparison with baselines. While the comment highlights an important issue, it does not provide explicit instructions or concrete steps for the authors to address this limitation. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the experiment setting and its implications for comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"intent discovery evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the assumption of known intent classes during graph construction and questions the comparability of the IntenDD experiments to the cited baselines. The comment further suggests that the authors need to clarify the intent discovery experiment setting to ensure a fair comparison with baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a limitation in the work, specifically the assumption of known intent classes during graph construction. It questions the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, given this assumption. The comment acknowledges that the authors have identified this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting to ensure a fair comparison. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the comparability of the experiments. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires additional detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known intent classes during graph construction. It questions the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, given this assumption. The comment acknowledges that the authors have identified this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting to ensure a fair comparison with baselines. This feedback is somewhat helpful as it highlights a critical area for improvement and encourages the authors to provide additional details to strengthen their claims. However, it could be more helpful if it offered specific suggestions on how to address this limitation or improve the clarity of the experiments. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment appreciates the rigorous experimentation in the work but criticizes the limited significance of the results due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. However, the comment does not provide specific guidance on how the authors could address these issues or improve the significance of their results. The references provided do not offer actionable steps either. As a result, the comment lacks explicit or implicit actions for the authors to take, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the rigorous experimentation in the work but criticizes the limited significance of the results due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions the experiments on corrupted CIFAR and ImageNet, requiring knowledge of corruption labels, which simplifies the problem. However, the comment does not specify which sections or experiments these issues pertain to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, while references are provided, they do not directly address the issues raised in the comment. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. The reviewer supports this claim by referencing two external works that discuss similar issues. However, the comment could be more robustly verified by providing specific examples or detailed explanations of how the cited works relate to the current work. As it stands, the claim is mostly verifiable, as it provides some support but lacks comprehensive evidence or detailed reasoning. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the rigorous experimentation in the work but criticizes the limited significance of the results due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. The comment references two external works that discuss similar issues, providing some context for the critique. However, the feedback lacks specific suggestions or actionable steps for the authors to address these limitations or improve the significance of their results. While it identifies areas for improvement, the comment does not offer detailed guidance or constructive advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliance on gradient-based saliency methods for evaluating the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or suggest alternative methods or approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reliance on gradient-based saliency methods for evaluating the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this concern pertains to, such as specific sections or experiments where these methods are discussed. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. The comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific because it lacks detailed guidance on how to address the concern. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the reliance on gradient-based saliency methods for evaluating feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. However, the comment lacks specific evidence, references, or detailed reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered borderline verifiable, as it provides an initial rationale but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the reliance on gradient-based saliency methods for evaluating the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper uses Pythia, which is not state-of-the-art (SOTA), but acknowledges its advantage of having available checkpoints. However, it does not provide any explicit or implicit suggestions for alternative models or actions for the authors to take. The comment lacks guidance on whether the authors should consider using a different model or how they might address this issue. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model choice, specifically mentioning Pythia as the model used in the paper. This provides full grounding as it clearly identifies the part of the paper being discussed. However, the comment lacks specificity as it does not provide detailed feedback or suggestions on how to address the issue of using a non-state-of-the-art model. It merely states the fact without offering guidance on potential improvements or alternatives. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper uses Pythia, which is not state-of-the-art (SOTA), but acknowledges its advantage of having available checkpoints. The claim is somewhat verifiable as it provides a logical reasoning that Pythia is not SOTA, but it lacks specific references or detailed comparisons to other SOTA models. This makes it challenging for the authors to fully understand the basis of the claim and address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential issue with the model choice, noting that Pythia is not state-of-the-art (SOTA) but acknowledges its advantage of having available checkpoints. While this feedback highlights a relevant concern, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment does not offer actionable steps or alternative models that could be considered, leaving the authors with only a general understanding of the problem. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggests that more information or resources should be provided to challenge the community in solving the image observation version of the Franka Kitchen task. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. Additionally, it asks if the task can be completed solely with the provided offline data and whether there are alternative data sources that could be leveraged. While the comment raises important questions, it does not provide explicit actions or concrete suggestions for the authors to address these issues. The authors are left to infer that they should provide more information or resources, but the lack of specific guidance makes the comment somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the image observation version of the Franka Kitchen task and seeks more information or resources to challenge the community. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about the task and potential data sources but does not provide detailed guidance on how to address these questions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for more information, rather than making subjective claims or suggestions. It does not express opinions, judgments, or requests for changes that require verification. Therefore, it is purely factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the image observation version of the Franka Kitchen task, specifically questioning whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. It also asks if the task can be completed solely with the provided offline data and whether there are alternative data sources that could be leveraged. While the comment identifies key areas for consideration, it lacks specific suggestions or guidance on how the authors might address these questions or improve their work. The feedback is somewhat helpful as it prompts the authors to consider these important aspects, but it could be more beneficial with additional direction or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to provide insight into why the multilingual model is \"noticeably weaker\" on specific evaluations, specifically ET\u2192En and LV\u2192EN. While the comment explicitly requests additional information, it does not specify what kind of insight or analysis is expected. The authors are left to determine the depth and nature of the explanation needed, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for insight into why the multilingual model is \"noticeably weaker\" on specific evaluations, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the performance of the multilingual model on specific evaluations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on why the multilingual model is \"noticeably weaker\" on specific evaluations, specifically ET\u2192En and LV\u2192EN. This feedback is somewhat helpful as it identifies a specific area where the authors could provide additional insight or explanation. However, the comment does not offer suggestions or guidance on how the authors might address this issue or improve their draft. While it prompts the authors to consider an important aspect of their work, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the meaning of the numbers in brackets in Tables 1 and 2. This is a direct request for the authors to provide an explanation, making the action clear and concrete. The authors know exactly what information is needed to improve their draft, ensuring they can take a specific action to address the comment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the meaning of the numbers in brackets \"(1),(4).\" This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the meaning of numbers in brackets in Tables 1 and 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the meaning of numbers in brackets in Tables 1 and 2. By pointing out this issue, the reviewer provides the authors with a clear and actionable piece of feedback. This allows the authors to address the confusion and improve the clarity of their presentation. However, the comment could be more helpful if it included a suggestion on how to clarify this information or provided an example of what the numbers might represent. Despite this, the comment is mostly helpful as it directs the authors to a specific area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the connection between the presented RDRO results and the listed limitations of previous fairness notions, specifically in the context of long-term fairness. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the connection between their results and the listed limitations, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented RDRO results and the listed limitations of some previous fairness notions, specifically in the context of long-term fairness. However, it does not specify which part of the paper discusses these limitations or where the RDRO results are presented, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of parsing the results in the context of long-term fairness but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connection between the presented RDRO results and the listed limitations of previous fairness notions, specifically in the context of long-term fairness. The reviewer acknowledges the paper\\'s consideration of RDRO and its convergence analysis but expresses uncertainty about how these results relate to the listed limitations. The comment highlights a gap in the explanation or connection between the results and the listed limitations, but it does not provide specific examples or references to support the claim. This makes the comment somewhat verifiable, as it identifies a potential issue but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the connection between the presented RDRO results and the listed limitations of previous fairness notions, specifically in the context of long-term fairness. It acknowledges the paper\\'s consideration of RDRO and its convergence analysis but questions how these results relate to the listed limitations. This feedback is somewhat helpful as it identifies a potential gap in the paper\\'s explanation or connection between its results and the listed limitations. However, it lacks specific suggestions or guidance on how the authors might address this issue or clarify the connection. To be more helpful, the comment could include examples or detailed feedback on how to improve the explanation or presentation of the results. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the accuracy and error units reported in the paper, specifically noting that the 29% accuracy with table assembly tasks is low and that the Euclidean distance error units in Table 1 seem very high. The reviewer questions whether these errors are normalized to per datapoint position errors and expresses skepticism about an error of 5 cm with HDR-IL being unreasonable. While the comment highlights issues that need addressing, it does not provide explicit instructions or concrete suggestions on how to improve the accuracy or normalize the error units. The authors are left to infer that they need to clarify or adjust these aspects, but without specific guidance, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the accuracy and error units reported in the table, questioning whether the Euclidean distance error units are normalized to per datapoint position errors and expressing skepticism about an error of 5 cm with HDR-IL. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the accuracy and error units reported in the paper, specifically noting that the 29% accuracy with table assembly tasks is low and that the Euclidean distance error units in Table 1 seem very high. The reviewer asks whether these errors are normalized to per datapoint position errors and expresses skepticism about an error of 5 cm with HDR-IL being unreasonable. While the comment raises valid concerns, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issues raised, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific concerns with the accuracy and error units reported in the paper, particularly noting that the 29% accuracy with table assembly tasks is low and that the Euclidean distance error units in Table 1 seem very high. The reviewer questions whether these errors are normalized to per datapoint position errors and expresses skepticism about an error of 5 cm with HDR-IL being unreasonable. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and provide more detailed explanations regarding the normalization and interpretation of the error units. However, the comment could be more helpful if it offered suggestions on how to address these issues or improve the accuracy. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the article does not reach a conclusion and suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the lack of conclusion or improve the article to better support their claims. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the article for not reaching a conclusion and suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper lacks a conclusion or where the suggestion about existing models is made. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of not reaching a conclusion and the suggestion about existing models, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article does not reach a conclusion and suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without such evidence or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the article\\'s fresh perspective but criticizes it for not reaching a conclusion. It suggests that the article implies existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. Without actionable feedback or detailed critique, the authors are left without a clear path to enhance their work. Therefore, the comment is not particularly helpful in guiding the authors to improve their draft, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the theoretical results do not provide much surprising information and have limited contribution to the algorithm design, as the design is based on a pre-defined labeler\\'s strategy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the contribution of the theoretical results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the theoretical results, suggesting they lack surprising information and have limited contribution to the algorithm design. However, it does not specify which part of the paper discusses these theoretical results, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the theoretical results are considered unremarkable or how they could be improved. Without explicit references or detailed feedback, the authors cannot effectively address the critique. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results do not provide much surprising information and have limited contribution to the algorithm design. The reasoning is based on the assertion that the algorithm design is primarily based on a pre-defined labeler\\'s strategy. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the critique. The absence of concrete evidence or references leaves the claim somewhat verifiable, as it requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the theoretical results, suggesting they lack surprising information and have limited contribution to the algorithm design. It implies that the algorithm design is primarily based on a pre-defined labeler\\'s strategy, which may limit the novelty and impact of the theoretical results. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the theoretical contribution or improve the algorithm design. Without actionable feedback or detailed insights, the authors are left without a clear path to address the critique. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the lack of detailed explanation on how reverse chain proved to be effective in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable details, such as recommending specific sections to expand or suggesting ways to enhance the research contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two concerns: the lack of detailed explanation on how reverse chain proved to be effective in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not specify which sections or parts of the paper these issues pertain to, making it difficult for the authors to pinpoint where improvements are needed. Additionally, the comment lacks specificity in detailing what aspects of the explanation or research contribution are lacking. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes two claims: first, that the effectiveness of reverse chain in multi-API planning is not delineated in detail, and second, that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these critiques and address them effectively. Therefore, the claims are considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper. First, it points out that the effectiveness of reverse chain in multi-API planning is not detailed, which is a critical aspect of the research that needs clarification. Second, it notes that the paper focuses on comparing multiple tools or methods in API calling and planning, which may reduce the research contribution. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity and depth of their research. While it highlights areas for improvement, the feedback is not actionable or detailed enough to be fully helpful. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends rejecting the paper due to the weaknesses identified in the review. It suggests that the issues with experimental rigor cannot be fixed within the available time and space, and that the significant editing required for other issues is also unrealistic. However, the comment does not provide any specific guidance or suggestions on how the authors might address these weaknesses or improve their draft. The action is explicit but lacks concrete details on how to implement the recommendation, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed. It makes a general recommendation for rejection due to weaknesses in experimental rigor and significant editing required, but it does not provide specific details or examples of these weaknesses. Without clear references to sections or specific issues, the authors cannot effectively identify the areas needing improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a claim that the paper should be rejected due to weaknesses in experimental rigor and significant editing required to address other issues. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks evidence or references to substantiate why the weaknesses are insurmountable or why the editing is unrealistic. Without such justification, the claim remains unverifiable, as it does not provide sufficient evidence or reasoning to support the recommendation. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a recommendation for rejection due to the identified weaknesses in the paper, specifically mentioning issues with experimental rigor and the need for significant editing. However, it does not offer any constructive feedback or suggestions on how the authors might address these weaknesses or improve their draft. The comment lacks actionable guidance or specific advice that could help the authors understand what changes are needed to enhance their work. As a result, the comment is not helpful at all, as it does not provide any actionable insights or direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the fairness of the competition between standalone Medusa and Medusa+ParallelSpec. It suggests that a baseline should be provided where the only alteration is the draft model architecture, to isolate the impact of the architecture change from the parallel prediction. Additionally, it recommends giving the modified setting a different name to avoid confusion. The comment provides explicit actions for the authors to take, including setting up a baseline and renaming the modified setting. These instructions are clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (266-267) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unfair competition between standalone Medusa and Medusa+ParallelSpec, and it provides a clear suggestion for improvement by recommending the inclusion of a baseline with only the draft model architecture altered. Additionally, it suggests renaming the modified setting to avoid confusion. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is unfair competition between standalone Medusa and Medusa+ParallelSpec due to a change in the draft model architecture. The reviewer suggests providing a baseline with only the draft model architecture altered to isolate the impact of the architecture change from the parallel prediction. This claim is somewhat verifiable as it logically points out the potential issue of unfair competition and suggests a method to address it. However, the comment lacks specific examples or references to support the claim fully, such as data or studies that demonstrate the impact of the architecture change. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue of unfair competition between standalone Medusa and Medusa+ParallelSpec due to a change in the draft model architecture. It suggests providing a baseline with only the draft model architecture altered to isolate the impact of the architecture change from the parallel prediction. Additionally, the comment recommends renaming the modified setting to avoid confusion regarding the draft model architecture. This feedback is clear and actionable, offering specific suggestions for improving the clarity and fairness of the experimental setup. By addressing these points, the authors can enhance the rigor and transparency of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the focus on Masked Language Models (MLMs) in the paper, inquiring whether experiments with an autoregressive Language Model (LM) were unsuccessful. While the question implies that the authors should consider including results with an autoregressive LM, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue or what specific changes to make. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the focus on Masked Language Models (MLMs) in the paper, inquiring whether experiments with an autoregressive Language Model (LM) were unsuccessful. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where MLMs are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the choice of MLMs, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the focus on Masked Language Models (MLMs) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the focus on Masked Language Models (MLMs) in the paper, inquiring whether experiments with an autoregressive Language Model (LM) were unsuccessful. While this question prompts the authors to consider the rationale behind their choice of MLMs, it does not provide specific guidance or suggestions for improvement. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for further exploration. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer detailed guidance on how to address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"How is the map encoded?\" and \"Should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" The first question is explicit and provides a clear action for the authors to take, which is to clarify how the map is encoded. The second question is also explicit but lacks concrete guidance on how to demonstrate the effectiveness of the method on the experiments proposed in YNet. While the action is clear, the lack of detailed instructions on how to address the second question makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: \"How is the map encoded?\" and \"Should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the encoding of the map and the need to demonstrate the method\\'s effectiveness on specific experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions: \"How is the map encoded?\" and \"Should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" These are requests for clarification or additional information, which do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the review point is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions: \"How is the map encoded?\" and \"Should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" While these questions identify areas that could be clarified or expanded upon in the paper, the comment lacks depth and does not provide specific guidance or suggestions for improvement. It points out potential weaknesses but does not offer actionable advice or detailed feedback on how to address them. As a result, the comment is somewhat helpful, as it prompts the authors to consider these aspects but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting improvements to the model or providing additional analysis to demonstrate its superiority. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not specify which part of the paper this assessment is based on, such as a particular section, table, or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what aspects of the model or comparison are lacking, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation of the proposed model, noting that it is not significantly better than the MSA Transformer in terms of r2. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without further elaboration or guidance on how the authors might address this issue or enhance their model, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more mathematical details to clarify the concept of \"ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. This direct request provides a clear action for the authors to take, which is to expand on the mathematical explanation in the paper. The comment is specific in its request for additional details, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"top of page 6\" and references specific text, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for more mathematical details to clarify the concept of \"ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation provided in the paper regarding the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures on the full feature space. The reviewer expresses confusion about the meaning of this concept and its relation to the scaling observed in Fig. 2. However, the comment does not provide any specific reasoning or evidence to support the claim that the explanation is insufficient or unclear. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, particularly regarding the explanation of the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures on the full feature space. The reviewer requests more mathematical details to clarify this concept and its relation to the scaling observed in Fig. 2. This feedback is clear and actionable, as it directs the authors to provide additional mathematical explanations to enhance the clarity and understanding of their work. However, the comment could be more helpful if it suggested specific aspects of the explanation that need clarification or offered examples of how to present the mathematical details. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider using BlenderBot 2.0 with incorporated knowledge and explore how dialogues can be improved by using domain ontologies from the SGD dataset. While the comment implies a specific action, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The authors are left to infer that they should conduct an experiment with these specific components, but the lack of concrete steps or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an experiment using BlenderBot 2.0 with incorporated knowledge and mentions the SGD dataset. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential improvement by using domain ontologies, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an experiment using BlenderBot 2.0 with incorporated knowledge and mentions the SGD dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this would be an interesting or beneficial approach. The comment lacks detailed explanation or examples that would help the authors understand the potential impact or significance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting experiment by proposing the use of BlenderBot 2.0 with incorporated knowledge and the exploration of how dialogues can be improved using domain ontologies from the SGD dataset. This feedback is somewhat helpful as it provides a specific direction for further exploration and could lead to an enhancement of the paper. However, the comment lacks depth and does not provide detailed guidance or rationale for why this approach might be beneficial or how it could be implemented. To be more helpful, the comment could include more detailed suggestions or examples of how to incorporate the proposed approach into the existing framework. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. However, the comment does not explicitly instruct the authors to clarify this information or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to address the overlap issue, but they are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the clarity of the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. However, the comment does not provide specific evidence or references to support this assumption or to justify why the overlap is necessary. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. This is an important point, as it relates to the validity of the Krippendorff $\\\\alpha$ calculation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the overlap. While it highlights a potential weakness, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between arg-wise consistency and accuracy, suggesting that the intuition is that label annotation agreement should be lower due to inconsistent predicates. However, it does not provide explicit guidance or suggestions on how the authors should address this confusion or improve their draft. The comment lacks actionable details, such as recommending specific changes or clarifications to make the distinction clearer. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the difference between arg-wise consistency and accuracy, suggesting that the intuition is that label annotation agreement should be lower due to inconsistent predicates. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the distinction between arg-wise consistency and accuracy, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difference between arg-wise consistency and accuracy, suggesting that the intuition is that label annotation agreement should be lower due to inconsistent predicates. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the distinction between arg-wise consistency and accuracy, suggesting that the intuition is that label annotation agreement should be lower due to inconsistent predicates. While it identifies a potential area of confusion, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or address this issue in their draft. The feedback is somewhat helpful as it points out a potential area of confusion, but it does not offer actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two actions: providing more details on the neural network parametrization of the reverse process, particularly regarding position embeddings, and sharing the code for their implementation. Both suggestions are explicit and provide clear guidance on what the authors need to do to improve reproducibility. The comment is specific in its requests, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, particularly regarding position embeddings, to enhance reproducibility. It also recommends sharing the code for their implementation. However, the comment does not specify which part of the paper discusses the neural network parametrization or where the code is located, making it weakly grounded. The suggestion to provide more details and code is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly regarding position embeddings, could enhance reproducibility. It also recommends sharing the code for their implementation. While the comment logically suggests that more details and code would aid reproducibility, it lacks specific examples or references to support the claim. The reasoning is sound but could be strengthened with additional evidence or examples, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors enhance reproducibility by providing more details on the neural network parametrization of the reverse process, particularly regarding position embeddings. It also recommends sharing the code for their implementation, which is a straightforward and effective way to improve transparency and replicability. This feedback is clear and offers concrete steps for the authors to take, making it highly helpful in guiding them to improve the draft. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue in the paper, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback provides a clear and direct action for the authors to take, which is to remove the repeated paragraph. The comment is explicit and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of a repeated paragraph, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of section 3.3 contains a repeated paragraph. However, it does not provide any supporting evidence or explanation to substantiate this claim. Without additional context or examples, the authors may find it challenging to verify the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is actionable as it directs the authors to correct a specific error in their draft, which can improve the clarity and coherence of the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to avoid such repetitions in the future. Overall, the comment is mostly helpful as it points out a clear issue that the authors can address, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly, which is a relevant concern for the authors to address. However, it does not provide explicit guidance or suggestions on how the authors should investigate or address this issue. The comment implies that the authors should consider the reusability and sustainability of their synthetic data, but it lacks concrete steps or recommendations for how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the reusability and sustainability of synthetic data generated on-the-fly, which is a relevant concern for the authors to address. However, it does not specify which part of the paper this concern pertains to, making it weakly grounded. The comment is specific in its inquiry about the reusability and sustainability of synthetic data, but without clear grounding, the authors may struggle to identify where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly, which is a relevant concern for the authors to address. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the reusability and sustainability of synthetic data generated on-the-fly, which is a relevant concern for the authors to address. By questioning the long-term viability of this approach, the comment prompts the authors to consider the implications of their method and potentially explore alternative strategies. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. While it identifies a potential weakness, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two areas for improvement: the authors should examine the likelihood of alternative RNA structures arising under biological circumstances and consider RNA abundance when building datasets. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer the actions needed, such as conducting additional analyses or incorporating specific data considerations. The lack of detailed guidance makes the comment somewhat actionable, as the authors know they need to address these points but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to solving the challenge of RNA folding. It highlights two specific issues: the authors\\' failure to examine the likelihood of alternative RNA structures arising under biological circumstances and the need to consider RNA abundance when building datasets. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact location. The comment is specific in detailing what needs to be addressed regarding the model\\'s limitations and considerations for dataset construction. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not examine the likelihood of alternative RNA structures arising under biological circumstances and suggests considering RNA abundance when building datasets. While the comment identifies a potential gap in the paper, it lacks specific examples, references, or detailed reasoning to support the claim. The authors may find it challenging to understand the basis of the critique without further elaboration. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks sufficient evidence or justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising under biological circumstances, which is a critical aspect of the model\\'s application. Second, it suggests considering RNA abundance when building datasets, which could enhance the model\\'s relevance and applicability. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. Providing more specific advice or examples would make the feedback more actionable. Therefore, the comment is somewhat helpful, as it offers insights but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the use of a single entropic regularization coefficient in the numerical results, suggesting that it may be a weak regularization term that leads to sparse couplings. The reviewer acknowledges that this may be favorable to the method but emphasizes the need to acknowledge this in the paper. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so, such as suggesting specific ways to acknowledge or discuss the regularization coefficient. The action is implicit and somewhat vague, as the authors know they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical results\" and the \"entropic regularization coefficient\" (\\u03b7=1200), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the single entropic regularization coefficient and suggests that it may be a weak regularization term, which could lead to sparse couplings. The comment further advises that this should be acknowledged in the paper and not overlooked. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of a single entropic regularization coefficient (\\u03b7=1200) in the numerical results, suggesting that it may be a weak regularization term that leads to sparse couplings. The reviewer acknowledges that this may be favorable to the method but emphasizes the need to acknowledge this in the paper. The comment provides a logical reasoning by suggesting that the authors should address the potential limitations of their method in the strong-regularization regime. However, it lacks specific examples or references to support the claim about the weak regularization term or its impact on the results. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\u03b7=1200). It suggests that this may be a weak regularization term, which could lead to sparse couplings and favor the method being evaluated. The reviewer acknowledges that this may not be an issue if the method is not beneficial in the strong-regularization regime, but emphasizes the need for the authors to acknowledge this in their paper. This feedback is clear and actionable, as it directs the authors to address a specific aspect of their results and their implications. However, it could be more helpful if it provided suggestions on how to acknowledge or discuss this issue in the paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the transparency and completeness of their analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It explicitly points out that the dataset is stated to have no Evidence in Table 1, while the paper mentions that sources were collected for the analysis. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or clarify the information. The action is implicit, as the authors can infer that they need to reconcile the conflicting information, but it remains vague because it lacks specific instructions on how to resolve the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. The comment clearly specifies what needs to be addressed, namely, the need to reconcile the conflicting information. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the dataset is stated to have no Evidence in Table 1, while the paper mentions that sources were collected for the analysis. This claim is somewhat verifiable as it identifies a specific inconsistency in the paper, but it lacks further explanation or evidence to fully substantiate the claim. The authors would need to investigate the discrepancy themselves to address it, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the dataset is stated to have no Evidence in Table 1, while the paper mentions that sources were collected for the analysis. This feedback is clear and actionable, as it directs the authors to reconcile the conflicting information in their paper. However, the comment could be more helpful if it provided suggestions on how to address this discrepancy or offered guidance on clarifying the information in the paper. Overall, the comment is mostly helpful as it highlights a critical issue that the authors need to address, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include details of the parameters for each simulator, such as whether the GPU pipeline in IsaacGym was used or just the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This feedback provides clear and specific actions for the authors to take, ensuring they know exactly what information to include in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the need to include details of parameters for each simulator, such as whether the GPU pipeline in IsaacGym was used or just the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what details are missing and need to be included. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that including details of parameters for each simulator is necessary due to the potential impact on overall performance. However, the comment does not provide specific examples or references to support why these details are crucial or how they might affect performance. The suggestion is logical but lacks detailed justification or evidence, making it somewhat verifiable. The authors would need to infer the importance of these details themselves, which requires more effort to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement by suggesting that the authors include details of the parameters for each simulator. This feedback is actionable and provides clear guidance on what additional information should be included to enhance the transparency and reproducibility of the study. However, the comment could be more helpful if it explained why these details are crucial or how they might impact the results, which would provide the authors with a deeper understanding of the importance of this information. Overall, the comment effectively directs the authors toward a meaningful enhancement of their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue with the choice of hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL method, noting that their selection is crucial for the effectiveness of the method. However, it points out that the empirical selection of these hyperparameters based on cross-validation in Supplementary Material A.3 reduces the generalizability of the proposed loss function. The comment implies that the authors should provide a more robust justification or method for selecting these hyperparameters, such as through theoretical analysis or additional experiments. While the action is implicit, it is concrete in suggesting that the authors need to address the generalizability issue. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the choice of hyperparameters $s$ and $k$, noting that their selection is crucial for the method\\'s effectiveness but that the empirical selection based on cross-validation reduces the generalizability of the proposed loss function. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of hyperparameters $s$ and $k$ is crucial for the effectiveness of the proposed method, but their empirical selection based on cross-validation reduces the generalizability of the loss function. The comment provides a logical reasoning by highlighting the importance of hyperparameter selection and its impact on generalizability. However, it lacks specific examples or references to support the claim about the reduction in generalizability. This makes the claim somewhat verifiable, as it provides a basis for the argument but requires more detailed evidence or examples to fully substantiate the point.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the choice of hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL method. It highlights the importance of these hyperparameters in determining the effectiveness of the method and points out that their empirical selection based on cross-validation in the supplementary material reduces the generalizability of the proposed loss function. This feedback is clear and actionable, as it prompts the authors to reconsider their approach to selecting hyperparameters and potentially provide a more robust justification or method for their choice. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as through theoretical analysis or additional experiments. Overall, the comment is mostly helpful, as it directs the authors to a significant area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the optimization times of their approach with OpenTuner, which can adaptively use different search techniques. This implies an action for the authors to take, namely conducting a comparison to demonstrate the effectiveness of their approach. However, the comment does not provide specific guidance on how to conduct this comparison or what metrics to use, leaving the authors with a clear action but without detailed instructions on execution. Therefore, the comment is mostly actionable, as it identifies a specific area for improvement but lacks detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing optimization times with OpenTuner, which can adaptively use different search techniques. This provides clear guidance on what the authors should address in their paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should compare the optimization times of their approach with OpenTuner, which can adaptively use different search techniques. However, the comment does not provide specific evidence or reasoning to support why this comparison is necessary or how it would benefit the paper. The suggestion is based on a general observation about OpenTuner\\'s capabilities, but it lacks detailed justification or examples to make the claim more robust. As a result, the comment is somewhat verifiable, as it provides a direction for improvement but lacks the necessary support to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors compare the optimization times of their approach with OpenTuner, which can adaptively use different search techniques. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by demonstrating the effectiveness of the authors\\' approach in comparison to a well-known benchmark. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work introduces a diffusion model into anomaly detection, which is not an original idea, and that it only makes minor adjustments to the NCSN model by combining popular techniques. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how the authors might enhance the novelty or originality of their work, nor are there suggestions for improving the adjustments made to the NCSN model. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work by pointing out that it introduces a diffusion model into anomaly detection, which is not an original idea. It references specific works ([1], [2], [3]) that have previously introduced diffusion models into this area. Additionally, it mentions that the work only makes minor adjustments to the NCSN model by combining popular techniques. However, the comment does not specify which part of the paper these observations pertain to, such as specific sections or experiments. While the authors might infer that it relates to the introduction or discussion of novelty, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the critique of novelty but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks novelty, as it introduces a diffusion model into anomaly detection, which is not an original idea. The reviewer supports this claim by referencing specific works ([1], [2], [3]) that have previously introduced diffusion models into the anomaly detection area. This provides a clear and specific reference to external sources, making the claim fully verifiable. The inclusion of these references allows the authors to understand the context and rationale behind the critique, ensuring that the claim is well-supported and actionable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment critiques the novelty of the work by pointing out that it introduces a diffusion model into anomaly detection, which is not an original idea. It references specific works ([1], [2], [3]) that have previously explored this concept, suggesting that the current work only makes minor adjustments to the NCSN model by combining popular techniques. While the comment identifies a potential weakness in the originality of the work, it lacks actionable suggestions or guidance on how the authors might enhance the novelty or originality of their contribution. The feedback is somewhat helpful as it highlights an area for improvement but does not provide detailed direction on how to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific issues: grammar errors in the paper and unlabeled axes in Figure 2. The comment explicitly states these problems, providing clear and concrete actions for the authors to take. The authors know exactly what needs to be corrected, making the feedback highly actionable. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific examples of grammar errors and the unlabeled axes in Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear examples of the grammar errors and the issue with the figure, offering precise guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific grammar errors in the paper, providing examples of incorrect phrases. This is a factual observation and does not contain subjective claims or opinions that require verification. Additionally, the comment about unlabeled axes in Figure 2 is a factual observation. Therefore, the review point is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues: grammar errors in the paper and unlabeled axes in Figure 2. By pointing out these issues, the comment provides actionable feedback that can help the authors improve the clarity and professionalism of their draft. However, the comment could be more helpful if it included suggestions on how to correct the grammar errors or provided examples of how to label the axes. Despite this, the feedback is clear and actionable, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the error analysis in section 5.2 is \"crappy\" and suggests that a more quantitative error analysis would be beneficial. This provides a clear and direct action for the authors to take, which is to improve the error analysis in their draft. However, the comment does not specify what aspects of the current error analysis are problematic or how to implement a more quantitative approach. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Error analysis in 5.2,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies that the error analysis is \"crappy\" and suggests that a more quantitative error analysis would be beneficial. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that a more quantitative error analysis would be beneficial. However, the comment does not provide any specific examples or detailed reasoning to support why the current analysis is inadequate or how a more quantitative approach would improve it. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in section 5.2, describing it as \"crappy\" and suggesting that a more quantitative error analysis would be beneficial. This feedback is somewhat helpful as it points out a clear area for improvement in the paper. However, the comment lacks depth and does not provide specific guidance or examples on how to enhance the error analysis or what aspects should be focused on. While it highlights a potential weakness, it does not offer actionable steps for the authors to take, limiting its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should not rely solely on t-SNE to evaluate distribution alignment and recommends measuring the Proxy-A distance between the distributions. It also points out a potential issue with Figure 6c and 6d, suggesting they might be identical, and advises checking the Proxy-A distance. While the comment provides a clear action to measure the Proxy-A distance, it lacks specific guidance on how to implement this measurement or what specific aspects of the Proxy-A distance should be considered. The authors are left with a general idea of what to do but without detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of Proxy-A distance to evaluate distribution alignment and questioning the similarity of Figure 6c and 6d. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that t-SNE alone may not be sufficient for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. However, the comment does not provide specific reasoning or references to support why Proxy-A distance is a better alternative or how it would improve the evaluation. Additionally, the mention of Figure 6c and 6d being identical is not substantiated with evidence or explanation. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to further explore the suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the evaluation of distribution alignment by recommending the use of Proxy-A distance in addition to t-SNE. This is a clear and actionable piece of feedback that can help the authors enhance the robustness and validity of their analysis. Additionally, the comment points out a potential issue with Figure 6c and 6d, suggesting they might be identical, which could be a source of confusion. This feedback is helpful as it directs the authors to a specific area for improvement and provides a concrete suggestion for enhancing their work. However, the comment could be more helpful if it included additional guidance on how to implement the Proxy-A distance measurement or why it is a better choice than t-SNE. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind using cross entropy for the first phrases and the performance when using a reinforcement algorithm for all phrases. While it highlights areas that need clarification, it does not provide explicit instructions or suggestions for the authors to follow. The authors can infer that they need to provide a rationale for their choice of cross entropy and potentially explore the performance of a reinforcement algorithm, but the comment lacks concrete guidance on how to address these issues. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines \"L216-217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind using cross entropy for the first phrases and asks about the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind using cross entropy for the first phrases and the performance when using a reinforcement algorithm for all phrases. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the rationale behind using cross entropy for the first phrases and inquires about the performance when using a reinforcement algorithm for all phrases. This feedback is somewhat helpful as it prompts the authors to clarify their methodology and potentially explore alternative approaches. However, the comment lacks depth and does not provide suggestions or guidance on how to address these questions or improve the draft. While it points out an area for further exploration, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed cross-modality adaptation has been validated in two specific works, BEVDepth [1] and 2DPASS [2], and notes that these works are not discussed in the related work section. This implies that the authors should include a discussion of these works in their related work section. However, the comment does not explicitly instruct the authors to do so or provide guidance on how to integrate these references into the related work section. The action is implicit and somewhat vague, as the authors need to infer that they should add these references but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed cross-modality adaptation\" and references specific works, \"BEVDepth [1]\" and \"2DPASS [2],\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the omission of a discussion of these works in the related work section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in specific works, BEVDepth [1] and 2DPASS [2], and notes that these works are not discussed in the related work section of the paper. This claim is somewhat verifiable as it provides references to external works that could support the assertion. However, the comment lacks detailed reasoning or explanation about why these works are relevant or how they relate to the paper\\'s contributions. Providing more context or justification would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the proposed cross-modality adaptation has been validated in two specific works, BEVDepth [1] and 2DPASS [2], but these works are not discussed in the related work section. This feedback is clear and actionable, as it directly points out a gap in the literature review that the authors need to address to provide a comprehensive overview of their work. By including these references, the authors can enhance the context and relevance of their research within the existing body of literature. However, the comment could be more helpful if it provided suggestions on how to integrate these references or discussed their potential impact on the paper\\'s contributions. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides some direction for the authors.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Table 1 only presents test loss as a metric for performance degradation, without including any generation results such as BLEU scores to assess the quality of output. This implies that the authors should include generation results like BLEU scores in their analysis. While the action is not explicitly stated, it is clear and concrete, as it specifies exactly what additional information should be included. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing from the table, namely the inclusion of generation results such as BLEU scores to assess the quality of output. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation, without including any generation results such as BLEU scores to assess the quality of output. This claim is somewhat verifiable as it highlights a specific omission in the table, which could be addressed by including additional metrics. However, the comment does not provide specific examples or references to support why including generation results like BLEU scores would be beneficial or necessary. This lack of detailed justification or examples makes it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that Table 1 only presents test loss as a metric for performance degradation, without including any generation results such as BLEU scores to assess the quality of output. This feedback is clear and actionable, as it highlights an area where the paper could be improved by including additional metrics to provide a more comprehensive evaluation of the model\\'s performance. However, the comment could be more helpful if it suggested specific ways to incorporate these additional metrics or discussed the importance of including them. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments to validate the theoretical analysis, particularly for discussions on different regimes. While the suggestion is explicit, it lacks concrete details on what specific experiments should be conducted or how they should be designed. The authors are given a clear direction to enhance their draft with experimental validation, but the lack of detailed guidance on how to implement this suggestion makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include experiments to validate the theoretical analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to validate the analysis, but without clear grounding, the authors may struggle to identify where these experiments should be integrated. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments to validate the theoretical analysis would be beneficial, particularly for discussions on different regimes. However, the comment does not provide specific reasoning or examples to support why this addition would be valuable or necessary. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include experiments to validate the theoretical analysis, particularly for discussions on different regimes. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of experimental validation. However, the comment lacks specificity regarding which experiments should be conducted or how they should be designed to effectively validate the theoretical analysis. Without detailed guidance, the authors may struggle to implement the suggestion effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. While the suggestion is explicit, it lacks concrete details on how to implement these baselines or what specific insights they might provide. The authors are given a clear action to take but without detailed guidance on how to execute it. Therefore, the comment is somewhat actionable, as it provides a direct suggestion but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting the inclusion of certain baselines, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, it does not provide any justification or reasoning for why these baselines would be beneficial or how they might contribute to the study. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the necessity or impact of including these baselines. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. This feedback is somewhat helpful as it offers a specific suggestion for enhancing the experimental setup, which could potentially offer valuable insights into the benchmark. However, the comment lacks depth and does not explain why these baselines would be beneficial or how they might impact the study. It also does not provide guidance on how to implement these baselines or what specific insights they might reveal. Therefore, while the suggestion is actionable, the lack of detailed explanation or context limits its helpfulness, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description of advantage-weighted regression, noting that the Q function is with respect to \\\\( \\\\mu \\\\), which is the key piece that makes Equation 4 solve the constrained optimization of Equation . However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve clarity. The action is implicit, as the authors can infer that they need to clarify this aspect, but it remains vague because it lacks concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of advantage-weighted regression\" and \"Eq. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the explanation of how the Q function is with respect to \\\\( \\\\mu \\\\), which is the key piece that makes Eq. 4 solve the constrained optimization of Eq. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression is incomplete, specifically mentioning that the Q function is with respect to \\\\( \\\\mu \\\\), which is the key piece that makes Eq. 4 solve the constrained optimization of Eq. This claim is somewhat verifiable as it provides a specific detail about the missing explanation, which could help the authors understand the issue. However, the comment lacks further elaboration or references to support the claim fully, such as explaining why this detail is crucial or how it impacts the understanding of the method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, particularly in the description of advantage-weighted regression. It points out that the Q function is with respect to \\\\( \\\\mu \\\\), which is the key piece that makes Equation 4 solve the constrained optimization of Equation . This feedback is clear and actionable, as it directs the authors to clarify this crucial aspect of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information more clearly or offered examples of how similar issues have been addressed in other works. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance the clarity of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is cumbersome due to its multiple stages, in contrast to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. There is no guidance on potential modifications, alternative approaches, or specific actions the authors could take to simplify the algorithm. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the overall algorithm of the proposed method, describing it as cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. However, the comment does not specify which part of the paper discusses the proposed method or its stages, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides a general critique, it lacks specificity in detailing what aspects of the algorithm are cumbersome or how they could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is cumbersome due to its multiple stages, contrasting it with existing pruning methods that do not require fine-tuning. However, the comment lacks specific examples or references to existing pruning methods that are more efficient, making it difficult for the authors to understand the basis of the comparison. The absence of detailed reasoning or evidence renders the claim borderline verifiable, as it provides a general critique without concrete support. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential weakness in the proposed method, noting that it is cumbersome due to its multiple stages, in contrast to existing pruning methods that do not require fine-tuning. This feedback highlights an area for improvement, suggesting that the authors might consider simplifying their algorithm to enhance its efficiency. However, the comment lacks specific suggestions or guidance on how to achieve this simplification, such as which stages could be streamlined or combined. While it provides some insight into a potential issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the advantage of the new quantile function (3) compared to the existing function (2) is not well justified. It explains that the new function changes the multiplicative factors containing the up and down tail parameters into an additive term, which makes the function less sensitive to the tail parameters when they are large. However, the comment notes that the paper lacks supporting data on why this reduced sensitivity is desired. While the comment identifies a specific issue with the justification of the new function, it does not provide explicit guidance on how the authors should address this gap. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide supporting data or further justification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the new quantile function (3) and the existing function (2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by explaining the change in the multiplicative factors and the lack of supporting data on why the reduced sensitivity is desired. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is unjustified. The reviewer provides a logical explanation by describing the change in the multiplicative factors and how it affects sensitivity to tail parameters. However, the comment lacks specific examples or references to support the claim that the reduced sensitivity is not desired. While the reasoning is clear, the absence of detailed evidence or data makes the claim somewhat verifiable. The authors would need to further explore the rationale themselves to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the advantage of the new quantile function (3) compared to the existing function (2) is not well justified. It explains that the new function changes the multiplicative factors containing the up and down tail parameters into an additive term, which makes the function less sensitive to the tail parameters when they are large. However, the comment points out that the paper lacks supporting data on why this reduced sensitivity is desired. This feedback is somewhat helpful as it highlights a gap in the justification of the new function and suggests that the authors provide supporting evidence or rationale. However, it could be more helpful if it offered specific suggestions on how to present this data or what kind of evidence would be convincing. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with Figure 3 and the contribution of the paper over SWE-Bench. It provides explicit actions for the authors to take, such as improving Figure 3 and addressing the low contribution over SWE-Bench. The reviewer also offers concrete suggestions for how to improve the contribution, such as clarifying the role of fault localization and LLMs in the benchmark. These detailed instructions give the authors clear guidance on how to enhance their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the contribution over SWE-Bench, providing clear guidance on what needs to be improved. The comment specifies the confusion regarding Figure 3 and provides reasoning for the low contribution over SWE-Bench, including the role of fault localization and LLMs in the benchmark. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is confusing and that the contribution over SWE-Bench is low. It provides specific reasoning for the latter claim, stating that the authors\\' benchmark includes testing fault localization and LLM\\'s capability of discovering issues, but these are already inherent in the repair benchmarks. The reviewer also points out that unit tests can be automatically passed to an LLM, making the LLM unnecessary for issue generation. This reasoning is logical and provides a clear explanation for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or studies that support the claim about the low contribution over SWE-Bench. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with Figure 3, describing it as confusing and suggesting that the authors improve its contribution. It also critiques the contribution over SWE-Bench, providing a detailed explanation of why the authors\\' claims about new additions to the benchmark, such as testing fault localization and LLM\\'s capability of discovering issues, may not be valid. The reviewer offers concrete reasoning and examples to support their critique, which is highly helpful for the authors. By addressing these points, the authors can significantly improve the clarity and validity of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing description related to topic control experiments, specifically asking how to select topics to constitute the complementary attribute for each topic. While the comment identifies a gap in the explanation, it does not provide explicit instructions or suggestions on how to address this issue. The authors are left to infer that they need to include this information, but the comment lacks concrete guidance on how to implement this addition. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the description of topic control experiments, particularly the selection of topics to constitute the complementary attribute. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely the explanation of how to select topics for the complementary attribute. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about missing key descriptions related to topic control experiments. It specifically asks how to select topics to constitute the complementary attribute for each topic. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is crucial or how it impacts the study. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the description of the topic control experiments, noting that the selection of topics to constitute the complementary attribute is missing. This feedback is clear and actionable, as it points out a particular area where the authors need to provide more detail. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar experiments have been described in other works. Despite this, the comment still provides valuable insight into an area that requires clarification, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the real-world manipulation section only includes a single case, which may not be sufficient to demonstrate the effectiveness of the system identification method in improving sim-to-real policy deployment. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the section. There is no guidance on potential additional cases to include, alternative methods to demonstrate effectiveness, or any specific actions for the authors to take. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the section on \"Real-world manipulation,\" which is specific, allowing the authors to identify the part of the paper being discussed. However, it lacks specificity in detailing what aspects of the single case are insufficient or how the described system identification method could be improved for sim-to-real policy deployment. Without specific guidance or examples, the authors may struggle to understand what changes are needed to strengthen the argument. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the real-world manipulation section only includes a single case, which may not be sufficient to demonstrate the effectiveness of the system identification method in improving sim-to-real policy deployment. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation in the paper, specifically that the real-world manipulation section only includes a single case. It suggests that this may not be sufficient to convincingly demonstrate the effectiveness of the system identification method in improving sim-to-real policy deployment. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the section. Without actionable feedback or detailed advice, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the quality of ShortcutQA, questioning whether the edits might introduce ambiguity and degrade performance. It asks for details on the \"answerability\" of distracted texts and requests examples and qualitative results. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, as the authors can infer that they need to address the concerns raised. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises concerns about the quality of ShortcutQA, specifically questioning whether the edits might introduce ambiguity and degrade performance. It requests details on the \"answerability\" of distracted texts and asks for examples and qualitative results. However, the comment does not specify which part of the paper discusses ShortcutQA, making it weakly grounded. The authors can infer that it relates to sections discussing the evaluation or results, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper. The comment is specific in detailing what additional information is needed, such as examples and qualitative results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses skepticism about the quality of ShortcutQA, questioning whether the edits might introduce ambiguity and degrade performance. The reviewer acknowledges that the edits are manually verified to not change semantics but suggests that this does not guarantee the absence of ambiguity. The comment requests additional details, examples, and qualitative results to address this concern. While the comment logically questions the robustness of the method, it lacks specific examples or references to substantiate the claim. This makes the comment somewhat verifiable, as it provides a logical basis for the concern but requires further evidence or examples to fully validate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of ShortcutQA, questioning whether the edits might introduce ambiguity and degrade performance. It requests additional details, examples, and qualitative results to address this concern. This feedback is clear and actionable, as it prompts the authors to provide more information that could help clarify and substantiate their claims. By asking for specific examples and qualitative results, the comment guides the authors on how to enhance the transparency and robustness of their work. However, it could be more helpful if it suggested specific aspects to focus on or provided examples of what constitutes ambiguity. Overall, the comment is mostly helpful, as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be clearer if there was a forward pointer to the definition of \"deep\" in the text. While the comment implies that the authors should add a forward pointer, it does not explicitly instruct them to do so. Additionally, it does not specify where this forward pointer should be placed or how it should be integrated into the text. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"41,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a forward pointer to the definition of \"deep\" would improve clarity. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any justification or reasoning for why this would improve clarity or how it would benefit the reader. Without additional context or explanation, the authors may find it challenging to understand the necessity of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" While this is a specific and actionable suggestion, it lacks context or explanation as to why this addition would improve the clarity of the paper. Without further elaboration on how this change would benefit the reader or the overall structure of the paper, the comment provides limited guidance for the authors. Therefore, it is rated as barely helpful, as it offers a small but clear suggestion for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical interest in the number of archetypes (k) and asks whether there is a way to perform model selection to identify an appropriate k within the presented framework. While the comment implies that the authors should consider model selection for k, it does not explicitly instruct them to do so or provide guidance on how to implement this. The action is implicit and somewhat vague, as the authors need to infer the need for model selection and determine how to approach it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the practical interest in the number of archetypes (k) and whether there is a way to perform model selection to identify an appropriate k within the presented framework. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion where model selection is addressed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about model selection for k, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification on whether there is a way to perform model selection to identify an appropriate number of archetypes (k) in the presented framework. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the practical interest in the number of archetypes (k) and whether there is a way to perform model selection to identify an appropriate k within the presented framework. This feedback is valuable as it prompts the authors to consider an aspect of their methodology that could impact the effectiveness and applicability of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing methods for model selection or providing examples of how to implement it. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to ensure that Theorem 1 is included in the paper, as it is currently missing. It also suggests keeping a clear separation between assumptions, lemmas, and theorems. This feedback provides a direct and concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, ensuring they can effectively address the comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper, \"the beginning of page 6,\" where Theorem 2 is located but Theorem 1 is missing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of Theorem 1 and the need for clear separation between assumptions, lemmas, and theorems. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the absence of Theorem 1 and the need for clear separation between assumptions, lemmas, and theorems. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the paper, noting the absence of Theorem 1 and the need for clear separation between assumptions, lemmas, and theorems. This feedback is actionable as it directs the authors to correct the omission of Theorem 1 and to ensure proper categorization of theorems, assumptions, and lemmas. By addressing these points, the authors can improve the clarity and organization of their paper. However, the comment could be more helpful if it provided additional guidance on how to effectively structure these elements or why this separation is important. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, particularly in the context of QA. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this assumption should be reconsidered, tested, or addressed in the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption regarding the necessity and sufficiency of a shorter subsequence within a longer text for performing a target task, particularly in the context of QA. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and questions its generalizability to tasks like long document summarization. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, particularly in the context of QA. The reviewer provides a logical reasoning by suggesting that this assumption might not generalize to tasks like long document summarization. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the assumption made in the paper regarding the necessity and sufficiency of a shorter subsequence within a longer text for performing a target task. It questions the generalizability of this assumption to tasks like long document summarization, which is a relevant concern for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might test or validate this assumption, or how they might address the potential limitations. While it identifies an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the proposed method, specifically questioning how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to resolve the identified problems. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 180,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the proposed method, particularly regarding the generation of multiple different graphs and the implications of learning different weights for edges. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is straightforward and has marginal novelty, and it questions the clarity of certain aspects, such as the generation of multiple different graphs and the implications of learning different weights for edges. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the clarity and novelty of the proposed method, specifically questioning how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. While it identifies areas of confusion, the comment lacks specific suggestions or guidance on how the authors might clarify these aspects or enhance the novelty of their work. The feedback is somewhat helpful as it points out potential weaknesses, but it could be more beneficial with additional detail or actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are limited in scope, mentioning that there are only two simulation experiments and one example using time of travel by taxis. It suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold, such as a unit sphere. While the comment implies that the authors should expand their experiments to include more complex examples, it does not provide specific guidance on how to do so or which manifolds to consider. The action is implicit and somewhat vague, as the authors know they need to expand their experiments but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific experiments being discussed, including the unit sphere, spiral curves, and time of travel by taxis. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it points out the limitation of the experiments in scope and suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. This provides clear guidance on what the authors could consider adding to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited in scope, specifically mentioning the use of a unit sphere and spiral curves as examples. The reviewer suggests that these examples are not representative of more complex manifolds and that it would be beneficial to include examples of learning geometry on more complicated manifolds. While the comment provides some reasoning by highlighting the simplicity of the unit sphere example, it lacks specific examples or references to more complex manifolds that could be used for comparison. This makes the claim somewhat verifiable, as the authors would need to further explore and justify the inclusion of more complex examples to address the critique effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, noting that they are restricted to two simulation experiments and one example using time of travel by taxis. It points out that the unit sphere is a special case where geometry can be easily learned with first-order information, suggesting that it would be beneficial to include an example of learning geometry on a more complicated manifold. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a direction for expanding the scope of the experiments. However, it lacks detailed guidance or suggestions on how to implement this expansion, such as which manifolds to consider or how to design the experiments. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges a weakness in the paper, specifically the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the template or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a weakness in the paper related to the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding how this weakness could be addressed or improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges a weakness in the paper, specifically the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges a weakness in the paper, specifically the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. This is a relevant observation that could impact the paper\\'s overall effectiveness. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their approach. Without specific advice or examples, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it identifies a weakness but lacks depth and actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the number of baselines is small, which affects the universality and generality of the study. However, it does not provide explicit guidance on how to address this issue or suggest specific actions to increase the number of baselines. The feedback lacks concrete details on what additional baselines should be included or how to effectively expand the baseline set. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the number of baselines being small, which affects the universality and generality of the study. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section. Without explicit references, the authors cannot confidently determine which sections need attention or improvement. Additionally, the comment lacks specificity regarding what additional baselines should be considered or how the current baselines could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of baselines is small, which affects the universality and generality of the study. However, the comment does not provide specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate why the number of baselines is insufficient or how it impacts the study\\'s universality and generality. Without this information, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the number of baselines used in the study, suggesting that this could affect the universality and generality of the findings. However, it lacks specificity and does not provide actionable guidance on how to address this issue or suggest additional baselines that could be included. Without concrete suggestions or examples, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer sufficient direction for the authors to enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of information regarding the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack, which are known to be important in practice. While the comment identifies a gap in the information provided, it does not explicitly instruct the authors to include this information or provide guidance on how to address it. The action is implicit, as the authors can infer that they need to add this information, but it remains vague because it lacks concrete details on how to implement the suggested changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where this information should be included. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in detailing what information is missing, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack, which are known to be important in practice. However, the comment does not provide any references or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of specific examples or evidence results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient justification for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific gap in the paper regarding the lack of information about the tokenizer training, particularly the mixture of corpus size used and the software stack. This feedback is valuable as it highlights an area that needs clarification or additional detail to improve the comprehensiveness of the paper. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending the inclusion of specific metrics or methodologies for tokenizer training. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It questions whether the additional complexity is warranted and suggests that the authors should clarify whether the co-training, positive mining, and alternate optimization steps are necessary. While the comment implies that the authors should address this question, it does not provide explicit guidance on how to do so or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the need for additional analysis or justification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed positive mining framework and its comparison to prior work, specifically mentioning the need for clarity on whether the additional complexity is warranted. It also mentions the co-training, positive mining, and alternate optimization steps as the main contributions of the paper. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the complexity and contributions, but without clear grounding, it is challenging for the authors to pinpoint where these issues need addressing. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the additional complexity introduced by the proposed positive mining framework compared to a simple multi-view contrastive objective. It suggests that the paper does not address whether the added complexity is justified. However, the comment lacks specific reasoning or evidence to support this claim, such as examples of where the complexity is unnecessary or how it could be simplified. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical question about the necessity of the additional complexity introduced by the proposed positive mining framework compared to a simpler multi-view contrastive objective. It highlights a gap in the paper regarding whether the added complexity is justified, which is an important consideration for the authors to address. The comment also acknowledges the intuitive nature of the proposed method and its good results, but it emphasizes the need for clarity on the necessity of the co-training, positive mining, and alternate optimization steps. While the comment identifies a key area for improvement, it could be more helpful by providing specific suggestions on how the authors might address this issue or by offering examples of how to justify the added complexity. Overall, the feedback is somewhat helpful as it directs the authors to a critical aspect of their work that requires further clarification.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the computational complexity of multi-marginal OT and spline calculations, suggesting that this could limit the scalability of the approach for large datasets. It explicitly states that a more comprehensive discussion is required, providing a clear action for the authors to take. However, it does not offer specific guidance on how to address this issue or what aspects of the discussion should be expanded upon. While the action is explicit, the lack of detailed instructions on how to implement the suggested discussion makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational cost of multi-marginal OT and spline calculations, suggesting that this could limit the scalability of the approach for large datasets. It implies that a more comprehensive discussion is needed, but it does not specify which part of the paper should include this discussion or how it should be expanded. The authors might infer that it relates to sections discussing computational complexity or scalability, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific about what needs to be addressed in the discussion. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the computational complexity of multi-marginal OT and spline calculations, suggesting that this could limit the scalability of the approach for large datasets. The comment implies that a more comprehensive discussion is needed to address this issue. However, it lacks specific examples, detailed reasoning, or references to support the claim about the computational complexity. Without these elements, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed approach, specifically the computational complexity of multi-marginal OT and spline calculations, which could hinder its scalability for large datasets. It suggests that a more comprehensive discussion is needed to address this issue, providing a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered specific suggestions on how to improve the discussion or provided examples of how to address the computational complexity. Despite this, the feedback is actionable and encourages the authors to consider an important aspect of their work, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point challenges the authors\\' claim that non-uniform label noise is not common in practice by referencing a specific dataset, Clothing1M, where non-uniform label noise has been verified. The reviewer provides a citation to support their claim, which is a concrete action for the authors to take if they wish to address this critique. However, the comment does not explicitly instruct the authors to revise their claim or provide additional evidence, leaving the action somewhat implied. Nonetheless, the authors can infer that they need to address this issue by either revising their claim or providing additional evidence. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding the prevalence of non-uniform label noise in practice. It references a specific dataset, \"Clothing1M,\" and provides a citation to support the claim that non-uniform label noise does exist in real-world datasets. This makes the comment fully grounded, as it clearly identifies the part of the paper being addressed (the claim about label noise) and provides a specific reference to substantiate the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim that non-uniform label noise is not common in practice by referencing a specific dataset, Clothing1M, where non-uniform label noise has been verified. The reviewer supports this claim by citing a relevant study by Kun Yi and Jianxin Wu, providing a concrete example and reference to substantiate the assertion. This detailed reference and specific example make the claim fully verifiable, as it offers a robust basis for the reviewer\\'s argument. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment challenges the authors\\' claim that non-uniform label noise is not common in practice by referencing a specific dataset, Clothing1M, where non-uniform label noise has been verified. This feedback is valuable as it provides a concrete example and reference to support the claim, prompting the authors to reconsider or provide evidence for their assertion. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or integrate the referenced work into their paper. Despite this, the comment is mostly helpful as it directs the authors to a relevant dataset and provides a basis for reconsidering their claim. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation in Section 6.2 was based on only 10 samples, which may have resulted in biased findings due to the small sample size. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should consider increasing the sample size or providing additional analysis to mitigate potential bias, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional analysis or more samples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of using only 10 samples for evaluation, which may lead to biased findings due to the small scale of the experiment. This provides clear guidance on what aspect of the evaluation needs to be reconsidered or expanded. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 is based on only 10 samples, which may lead to biased findings due to the small sample size. This claim is somewhat verifiable as it logically suggests that a small sample size could affect the reliability of the findings. However, the comment lacks specific examples or references to studies that have demonstrated the impact of sample size on bias, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation in Section 6.2, noting that it was based on only 10 samples. This limitation could lead to biased findings due to the small sample size. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or providing insights into how to mitigate the potential bias. The feedback is somewhat helpful as it points out a significant concern, but it could be more beneficial with actionable advice or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method is tailored to similar MILP tasks, which may limit its generalizability to significantly different combinatorial optimization problems. The reviewer acknowledges that the paper discusses this limitation but does not address it experimentally. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or improve the generalizability of their method. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Since the comment is vague and does not offer a clear path for action, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the method to different combinatorial optimization problems, acknowledging that the paper discusses this limitation but does not address it experimentally. However, it does not specify which part of the paper discusses this limitation or where the authors should add experimental validation. This makes it weakly grounded, as the authors cannot confidently determine the exact section being referred to. The comment is specific in identifying the issue of generalizability and the need for experimental validation, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, which limits its generalizability to significantly different combinatorial optimization problems. The reviewer acknowledges that the paper discusses this limitation but does not address it experimentally. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim about the method\\'s generalizability. The reasoning is somewhat verifiable, as it highlights a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks, which may restrict its generalizability to significantly different combinatorial optimization problems. The comment acknowledges that the paper discusses this limitation but does not address it experimentally. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the scope of their experiments. This limits the comment\\'s usefulness, making it somewhat helpful as it provides insight but not actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the description of the baselines in the Results section, specifically mentioning lines 256-261. It points out that the authors have attempted to bridge this gap but that the reviewer still struggles to understand how these baselines work and their relationship to InterFair. The comment implies that the authors should provide a clearer explanation of these baselines and their competitiveness. However, it does not explicitly instruct the authors to make these improvements, nor does it offer specific guidance on how to enhance the explanation. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Results section, L256-261,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the difficulty in understanding how the baselines work, their relationship to InterFair, and whether they are sufficiently competitive. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not sufficiently explained how their baselines work, their relationship to InterFair, or their competitiveness. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or evidence that would help the authors understand the basis of the reviewer\\'s concerns. As a result, the claim is not well-supported, making it difficult for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the baselines in the Results section, particularly regarding the \"Rerank and Adv\" baselines. It points out that the reviewer struggles to understand how these baselines work, their relationship to InterFair, and whether they are sufficiently competitive. While the comment highlights a critical area for improvement, it lacks detailed suggestions or guidance on how the authors might clarify these aspects. Providing more specific feedback or examples could enhance the comment\\'s helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors to a specific area needing attention but does not fully support them in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any explicit or implicit suggestions on how to improve this comparison or what specific aspects are lacking. Without additional guidance or details, the authors are left without a clear understanding of what changes are needed to address this issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where the comparison is discussed. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the comparison are insufficient or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it lacks depth and does not provide any guidance or suggestions on how the authors might address this issue or improve the comparison. Without actionable feedback or specific examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a weakness but does not offer meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This is an explicit suggestion, as it directly instructs the authors to provide an explanation. However, it does not specify what aspects of the combination should be highlighted or how the authors should approach this explanation. While the action is clear, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not specify which part of the paper this explanation should be added to, making it weakly grounded. The comment is specific in identifying the need for an explanation regarding the effectiveness of the mask snippets, but without clear grounding, the authors may struggle to determine where this explanation should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide a clear explanation of why a particular combination of mask snippets is effective, while most similar ones are not. This feedback is actionable as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it offered suggestions on how to approach this explanation or what specific factors to consider. Overall, the comment is somewhat helpful as it highlights a clear area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of SLQ compared to previous CRD methods, specifically noting that SLQ shows worse performance in Figure 3 and only a small improvement over ACL in Figure 4. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the performance of SLQ. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the competitiveness of SLQ. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the performance of SLQ (quantified by F1 score and conductance values) with previous CRD methods, noting that SLQ shows worse performance in Figure 3 and only a small improvement over ACL in Figure 4. This provides clear guidance on what needs to be addressed regarding the performance comparison. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, quantified by F1 score and conductance values, appears to have limited competitiveness compared to previous CRD methods. It supports this claim by referencing specific figures, Figure 3 and Figure 4, where SLQ shows worse performance than CRD and only a small improvement over ACL, respectively. This provides a clear and specific comparison that helps substantiate the claim. However, the comment could be strengthened by providing more detailed numerical data or additional context to fully verify the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of SLQ compared to previous CRD methods, as quantified by F1 score and conductance values. It points out that SLQ shows worse performance than CRD in Figure 3 and only a small improvement over ACL in Figure 4. This feedback is valuable as it highlights a potential weakness in the paper\\'s results, prompting the authors to reconsider or clarify their performance claims. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional experiments or analyses to improve the competitiveness of SLQ. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important aspect of their work but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more baselines to their performance comparisons, as the current selection is limited to naive or old models. This direct suggestion provides a clear action for the authors to take, which is to expand the set of baselines used in their experiments. However, the comment does not specify which additional baselines should be included or how they should be chosen, leaving some room for interpretation. Despite this, the action is explicit and provides a general direction for improvement, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines in the paper, suggesting that it is limited to naive or old models. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the addition of more baselines for robust performance comparisons, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive or old models, suggesting that more baselines should be added for robust performance comparisons. However, the comment does not provide specific examples of what additional baselines could be included or why the current selection is inadequate. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the specific improvements needed to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a limitation in the selection of baselines, noting that the current choices are limited to naive or old models. It suggests that the authors should add more baselines to perform robust performance comparisons. This feedback is clear and actionable, providing a specific direction for improvement that can enhance the comprehensiveness and rigor of the experimental evaluation. However, the comment could be more helpful if it included specific examples of additional baselines that could be considered or explained why the current selection is insufficient. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the choice of target structure in Table 2, questioning why only one structure was selected for evaluation. It suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. The comment explicitly states the need for justification or additional experiments, providing clear guidance on what the authors should do to address the concern. However, it does not specify which aspects of the justification or experiments should be included, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it provides a clear action but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the choice of \"target structure (2816, 7680, 8),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structure and suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of target structure in Table 2, suggesting that the authors should either justify their selection or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. While the comment raises a valid concern about the generalizability of the method, it lacks specific reasoning or evidence to support why this choice is problematic or how it impacts the study\\'s conclusions. The suggestion for additional experiments is logical, but without further elaboration or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of target structure in Table 2, questioning the authors\\' rationale for selecting only one structure for evaluation. It raises a valid concern about the generalizability of the proposed method to other target structures with different dimensions. The comment provides actionable feedback by suggesting that the authors should either justify their choice or conduct additional experiments to demonstrate the method\\'s adaptability to various target structures. This guidance is clear and constructive, offering a concrete way for the authors to enhance the robustness and applicability of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the scope of the research, which primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would enhance the paper\\'s impact and relevance. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to expand the scope or suggest specific applications in healthcare. The action is implicit and somewhat vague, as the authors know they need to broaden the scope but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a limitation in the scope of the research, which primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would enhance the paper\\'s impact and relevance. However, the comment does not specify which part of the paper discusses the knapsack problem or where the authors should consider expanding the scope. While the authors might infer that this relates to the introduction or discussion sections, the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a potential expansion of the scope but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the research has a limited application scope, primarily focusing on the knapsack problem and neglecting more realistic scenarios like medical diagnosis. The suggestion to explore applications in critical areas like healthcare is made to enhance the paper\\'s impact and relevance. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim that medical diagnosis is a more realistic scenario or how it would significantly increase the paper\\'s impact. This makes the claim somewhat verifiable, as it provides a logical suggestion but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the research, which primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would significantly increase the paper\\'s impact and relevance. This feedback is clear and actionable, as it provides a specific direction for the authors to consider expanding their research to include more relevant and impactful applications. However, the comment could be more helpful if it offered suggestions on how to integrate these applications or provided examples of how to frame such an expansion. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the method for not improving robustness and sensitivity as claimed, specifically noting that in Figure 3, the new method is noisier in two domains and equally noisy as competitors in the rest. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the robustness and sensitivity of their method. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method does not improve robustness and sensitivity as claimed, and provides specific observations about the noise levels in Figure 3. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed, specifically noting that in Figure 3, the new method is noisier in two domains and equally noisy as competitors in the rest. This claim is somewhat verifiable as it provides specific observations from Figure 3 to support the assertion. However, the comment lacks detailed reasoning or references to substantiate why these observations indicate a lack of improvement in robustness and sensitivity. Additional explanation or examples would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the method, noting that it does not improve robustness and sensitivity as claimed in the motivation. It provides a concrete example by comparing the noise levels in Figure 3, indicating that the new method is noisier in two domains and equally noisy as competitors in the rest. This feedback is clear and actionable, as it directs the authors to address the robustness and sensitivity issues in their method. However, the comment could be more helpful if it offered suggestions on how to improve these aspects or provided additional context or examples. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. While it implies that the authors should consider testing their conclusion against these methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to test or what specific methods to consider. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, such as a particular section, experiment, or conclusion. The authors might infer that it relates to the conclusions or results sections, but this inference is not direct. The comment is specific in its inquiry about the robustness of the conclusion, but it lacks grounding because it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the robustness of the conclusion against more sophisticated or aggressive removal methods. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This is a relevant point that could impact the validity and applicability of the findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or test the conclusion against these methods. While it prompts the authors to consider an important aspect of their work, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the introduction of explainable AI and the focus on interpretable methods in the paper. It points out that the authors do not define interpretability or explain the difference between explainable AI and interpretable methods. Additionally, it notes that the authors do not provide relevant work in this area. While the comment identifies specific areas that need clarification and additional content, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to define interpretability, explain the difference between explainable AI and interpretable methods, and include relevant work. However, the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the paper, specifically the topic of explainable AI and interpretable methods. It points out the lack of definition and explanation of interpretability and the difference between explainable AI and interpretable methods. Additionally, it notes the absence of relevant work in this area. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the introduction or background section. The comment is specific in detailing what needs to be addressed, such as defining interpretability and explaining the difference between concepts. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, and it criticizes the lack of definition and explanation of interpretability and the difference between explainable AI and interpretable methods. The comment highlights a gap in the paper\\'s explanation and suggests that the authors should clarify these concepts. However, the comment does not provide specific examples or references to support the claim or to guide the authors on how to address the issue. This lack of detailed justification or evidence makes the claim somewhat verifiable, as it requires the authors to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity and definition regarding the concepts of explainable AI and interpretable methods. It points out that the paper introduces explainable AI in the introduction but focuses on interpretable methods, and it highlights the absence of a clear explanation of the difference between these concepts. Additionally, the comment notes the lack of relevant work in this area. This feedback is valuable as it directs the authors to clarify and define key terms, provide a clear distinction between concepts, and situate their work within the existing literature. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or examples of how to define and differentiate the concepts. Overall, the comment is mostly helpful as it identifies critical areas for improvement and provides a general direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the training data for the probes in the compositionality and transitivity experiments. While it implies that the authors should provide information about the training data, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question or what details to include. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"compositionality and transitivity experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks a clear question about the training data for the probes, which is a specific aspect that needs clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the training data for probes in specific experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the training data for probes in the compositionality and transitivity experiments. While it highlights a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment is somewhat helpful as it points out a specific area that may need clarification, but it lacks actionable feedback or detailed advice on how to resolve the issue. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation of \"not only the complete captions but also parts thereof\" is unclear and that the argument about why filling in the blanks is hard is unconvincing. It suggests that there are ways to do bi-directional beam search for fill-in-the-blanks applications, referencing a source \"[C].\" However, the comment does not provide specific guidance on how to clarify the explanation or improve the argument. The reference to a source is implicit and lacks concrete details on how to implement the suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the explanation of \"not only the complete captions but also parts thereof,\" and the unconvincing argument about why filling in the blanks is hard. Additionally, it suggests considering bi-directional beam search for fill-in-the-blanks applications, providing a specific direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding \"not only the complete captions but also parts thereof,\" and it challenges the argument about why filling in the blanks is hard. The reviewer suggests considering bi-directional beam search for fill-in-the-blanks applications, referencing a source \"[C].\" However, the comment does not provide specific details or examples from the referenced source to support the claim, making it somewhat verifiable. The authors would need to follow up on the reference to fully understand the critique and its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the explanation regarding \"not only the complete captions but also parts thereof,\" and questions the argument about why filling in the blanks is hard. It suggests considering bi-directional beam search for fill-in-the-blanks applications, referencing a source \"[C].\" While the comment highlights a potential area for improvement, it lacks detailed guidance or examples on how to clarify the explanation or implement the suggested approach. The reference to a source is a positive step, but without further elaboration, the comment remains somewhat vague. Therefore, it is somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of reverse KL for training flows, specifically mentioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that covering all modes of a density is crucial for rare event sampling and references recent work to address this limitation. While the comment highlights potential issues and suggests considering recent work, it does not provide explicit instructions or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the differentiability assumption and consider recent work to overcome the mode-seeking issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of reverse KL for training flows, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the differentiability assumption of the function $g$ and the mode-seeking nature of reverse KL, suggesting that covering all modes of a density is crucial for rare event sampling. The comment further references recent work to address this limitation, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL for training flows, specifically mentioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. The reviewer suggests that covering all modes of a density is crucial for rare event sampling and references recent work to address this limitation. While the comment provides some logical reasoning and references recent work, it lacks specific examples or detailed explanations of how these issues impact the study. This makes the claim somewhat verifiable, as the authors would need to further explore the implications and references provided to fully understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of reverse KL for training flows, specifically highlighting the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that covering all modes of a density is crucial for rare event sampling and references recent work to address this limitation. This feedback is somewhat helpful as it identifies a potential issue with the methodology and points the authors to relevant literature that could help them address it. However, the comment could be more helpful if it provided specific suggestions on how to incorporate the referenced work or offered additional guidance on addressing the mode-seeking issue. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the annotations in the visual event detection stage of ViStruct Suite, noting that they might contain noise due to the use of an off-the-shelf semantic role labeling system. The reviewer suggests that a detailed analysis of the curated dataset is needed to address this concern. While the comment implies that such an analysis should be conducted, it does not provide specific guidance on how to perform it or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ViStruct Suite\" and the \"visual event detection stage,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the annotations might contain noise due to the use of an off-the-shelf semantic role labeling system. The comment suggests that a detailed analysis of the curated dataset is needed to address this issue. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the annotations in the visual event detection stage of ViStruct Suite might contain noise due to the use of an off-the-shelf semantic role labeling system. The reviewer suggests that a detailed analysis of the curated dataset is needed to address this issue. However, the comment lacks specific examples or references to support the claim about the noise in the annotations. Without detailed evidence or reasoning, the claim remains somewhat vague, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the annotations in the visual event detection stage of ViStruct Suite, noting that they might contain noise due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset is needed to address this concern. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a general direction for further analysis. However, it lacks detailed guidance or specific suggestions on how to conduct this analysis or what aspects to focus on, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model implementation should be better justified, specifically mentioning the stopping rule with \"n consecutive identical samples\" as arbitrary and lacking discussion on sensitivity with regard to \"n.\" This feedback provides a clear and explicit action for the authors to improve their draft by justifying the stopping rule and discussing its sensitivity. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the model implementation and specifically mentions the stopping rule with \"n consecutive identical samples,\" which provides full grounding as it allows the authors to identify the exact part of the paper being discussed. It also specifies the issue by pointing out that the stopping rule seems arbitrary and lacks discussion on its sensitivity, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model implementation should be better justified, specifically mentioning the stopping rule with \"n consecutive identical samples\" as arbitrary and lacking discussion on sensitivity with regard to \"n.\" While the comment identifies a potential issue, it does not provide specific examples or references to support why this stopping rule is arbitrary or how it could be improved. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the critique themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model implementation, specifically the stopping rule with \"n consecutive identical samples,\" which is described as arbitrary and lacking discussion on its sensitivity. This feedback is clear and actionable, as it directs the authors to provide a better justification for their stopping rule and to discuss its sensitivity, which could significantly improve the robustness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar rules are typically justified in the literature. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of time complexity analysis for the proposed algorithms and the need for a comparison of search time with state-of-the-art algorithms. The reviewer explicitly suggests that the authors provide time complexity analysis and report the running time of the proposed method. Additionally, they imply that a comparison of search time with state-of-the-art algorithms would be interesting. While the comment provides clear actions, it does not offer detailed guidance on how to conduct the time complexity analysis or the comparison. Therefore, the comment is explicit in its requests but somewhat vague in execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"maximum common subgraph detection problem\" and the \"proposed algorithms,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of time complexity analysis and the need to report running times for the proposed method. Additionally, it suggests an interesting comparison between the proposed method and state-of-the-art algorithms regarding search time. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the importance of providing time complexity analysis for the proposed algorithms, given the NP-hard nature of the maximum common subgraph detection problem. The reviewer supports this claim by pointing out the absence of time complexity analysis and running time reports in the paper. Additionally, the comment suggests an interesting comparison between the proposed method and state-of-the-art algorithms regarding search time. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that include time complexity analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a significant gap in the paper regarding the time complexity analysis of the proposed algorithms. It highlights the importance of providing this information, given the NP-hard nature of the problem, and points out the absence of such analysis in the paper. Additionally, the comment suggests an interesting comparison between the proposed method and state-of-the-art algorithms in terms of search time, which could provide valuable insights into the efficiency of the proposed approach. While the comment effectively directs the authors to address a critical aspect of their work, it could be more helpful by offering specific suggestions on how to conduct the time complexity analysis or examples of similar studies. Overall, the feedback provides clear and actionable guidance, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of quality control or manual evaluation on the quality of data collected through an automatic model-based approach. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement quality control or manual evaluation. The comment lacks concrete details on what kind of quality control or manual evaluation should be conducted, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the absence of quality control or manual evaluation on the quality of data collected through an automatic model-based approach. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where data quality is discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quality control or manual evaluation, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control or manual evaluation on the quality of data collected through an automatic model-based approach. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the lack of quality control or manual evaluation on the quality of data collected through an automatic model-based approach. This is a critical issue that could impact the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might implement quality control or manual evaluation, nor does it explain why this is important. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting comparison between a confidence interval from a small development set and the Frechet bound. It implies that the authors should consider this comparison to provide a bound on the performance of a classifier. However, the comment does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific steps needed to conduct the comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an interesting comparison between a confidence interval from a small development set and the Frechet bound. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare these two methods, but without clear grounding, the authors may struggle to identify where this comparison should be included in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the availability of a small set of labeled data for most tasks and references the use of a small development set in snorkel to tune hyperparameters. It suggests an interesting comparison between a confidence interval from a small development set and the Frechet bound. However, the comment lacks specific examples, references, or detailed reasoning to support the claim or suggestion. The absence of concrete evidence or detailed explanation makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between a confidence interval from a small development set and the Frechet bound, which could provide a bound on the performance of a classifier. This feedback is somewhat helpful as it offers a potential direction for further exploration or analysis in the paper. However, it lacks specific guidance or actionable steps for the authors to implement this comparison, such as how to integrate it into the existing framework or what specific insights it might provide. While the suggestion is intriguing, it could be more beneficial with additional detail or context. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It also explains the reason for this limitation, which is due to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method to higher-dimensional problems. Without actionable advice or specific guidance, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the proposed method to problems with low-dimensional input spaces, specifically mentioning that the largest dimensionality in the experiments is 3. This provides full grounding as it clearly identifies the part of the paper being discussed, likely the methodology or results section. The comment is also specific, as it explains the limitation due to the curse of dimensionality and the use of a finite set of points in the surrogate modeling. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces, citing the largest dimensionality in the experiments as 3. The reviewer provides a logical explanation for this limitation, attributing it to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or studies that support the concept of the curse of dimensionality in this context. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It provides a clear explanation for this limitation, attributing it to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. This feedback is valuable as it highlights a critical aspect of the method that the authors need to address. However, the comment does not offer specific suggestions or guidance on how to overcome this limitation or improve the method\\'s applicability to higher-dimensional problems. While it provides insight into a key weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the results presented in Tables 1 and 2, noting that the methods' outcomes are typically within their standard deviations. The reviewer expresses skepticism about the claim that the presented method is significantly better than others due to this observation. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might improve their claims or present their results more convincingly. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results, namely that they are typically within their standard deviations, which challenges the claim that the presented method is significantly better than others. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Tables 1 and 2 are typically within their standard deviations, which undermines the claim that the presented method is significantly better than others. This claim is somewhat verifiable as it provides a logical reasoning based on the standard deviations of the results. However, it lacks specific examples or detailed comparisons to substantiate the claim fully. The authors would need to further explore the data to understand the implications of the standard deviations on the method\\'s significance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential issue with the results presented in Tables 1 and 2, noting that the methods\\' outcomes are typically within their standard deviations. This observation challenges the claim that the presented method is significantly better than others. While the comment identifies a critical aspect of the results that could impact the paper\\'s conclusions, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback highlights a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the non-trivial nature of generating synthetic tabular data due to various factors, providing two examples. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these factors or improve their approach to generating synthetic tabular data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the difficulty in generating synthetic tabular data due to various factors, specifically mentioning that multiple entries in a table can be associated with the same entity, resulting in additional relationships. However, it does not specify which part of the paper this issue pertains to, nor does it provide detailed guidance on how to address this challenge. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that generating synthetic tabular data is non-trivial due to several factors, providing two examples. The first example, regarding multiple entries in a table associated with the same entity, is a logical observation that could be considered common knowledge in data generation. However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the examples provide some support, the lack of additional evidence or references makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the challenge of generating synthetic tabular data, providing two examples of factors that make it non-trivial. However, it lacks specific guidance or suggestions on how the authors might address these challenges or improve their approach. Without actionable feedback or detailed advice, the comment does not provide the authors with a clear path for improvement. As a result, it is rated as barely helpful, as it identifies a potential issue but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment highlights a potential issue with the overemphasis on the AmbiQT benchmark without providing a broader context or validation on other datasets. However, it does not explicitly instruct the authors to address this issue or suggest how they might do so. The action is implicit, as the authors can infer that they need to provide a broader context or validation, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to implement the suggested changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark and raises concerns about its overemphasis without a broader context or validation on other datasets. However, it does not specify which part of the paper discusses the benchmark, making it weakly grounded. The comment is specific in its critique, as it highlights the need for a broader context and validation on other datasets to ensure applicability and relevance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the overemphasis on the AmbiQT benchmark without a broader context or validation on other datasets could lead to questions about its applicability and relevance. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The reasoning is somewhat vague, as it does not provide detailed justification or evidence for the potential issues with the benchmark. Therefore, the comment is classified as \"2: Borderline Verifiable,\" as it provides some insight but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the value of the AmbiQT benchmark but raises a concern about its overemphasis without a broader context or validation on other datasets. This feedback highlights a potential limitation in the paper\\'s approach, suggesting that the authors should consider providing a more comprehensive evaluation across multiple datasets to ensure the benchmark\\'s applicability and relevance. While the comment identifies an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or methods for validation. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but does not offer detailed, actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of annotation training details and guidelines, which are crucial for professional translators dealing with non-standard tasks. It also mentions the lack of information about the tool used. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should include these details, but without specific guidance on what information to provide or how to present it, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of annotation training details and guidelines, which are crucial for professional translators dealing with non-standard tasks. It also mentions the lack of information about the tool used. However, the comment does not specify which part of the paper should include these details, making it weakly grounded. The authors might infer that it relates to sections discussing methodology or tools, but this inference is not direct. The comment is specific in identifying what is missing, namely annotation training details and tool information. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"no annotation training details and guidelines are shared,\" which is important for professional translators dealing with non-standard tasks. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the lack of annotation training details and guidelines, which are crucial for professional translators dealing with non-standard tasks. It also points out the absence of information about the tool used. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to an important aspect of their work that needs attention, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the presentation of data in Table 1, specifically questioning whether the bold-facing of \"EX/NORB\" is appropriate and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. While the comment implies that the authors should reconsider the presentation of these values, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should review the presentation and statistical significance of the data. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the appropriateness of bold-facing \"EX/NORB\" and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the presentation and statistical significance of data in Table 1. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the presentation of data in Table 1, questioning whether the bold-facing of \"EX/NORB\" is appropriate and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. While the comment identifies a potential issue with the presentation of data, it does not provide any guidance or suggestions on how the authors might address these concerns. The feedback is somewhat helpful as it prompts the authors to reconsider their presentation choices, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the metric used for the video level supervision experiment, suggesting that it may not be using tracklet-based metrics. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should clarify the metric used, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"video level supervision experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the metric used in the experiment and points out that the paper does not provide details on the tracklet-based metrics. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the metric used in the video level supervision experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the metric used in the video level supervision experiment, suggesting that it may not be using tracklet-based metrics. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s explanation or methodology. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify their methodology. While it prompts the authors to consider an important aspect of their work, it does not offer actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of \"person blocking\" on the models shown in Figure 4. It suggests a possible reason, which is that the models might learn person-related features, which could be undesirable. The reviewer explicitly asks the authors to comment on this issue. While the comment does not provide specific guidance on how to address the concern, it clearly identifies an area that needs clarification. The action is explicit but somewhat vague, as it leaves the authors to determine the exact nature of the comment they should provide. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the impact of \"person blocking\" on the models and suggests a possible reason, which is that the models might learn person-related features. The comment asks for a comment on this issue, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the impact of \"person blocking\" on the models shown in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the impact of \"person blocking\" on the models, as shown in Figure 4. It suggests a possible reason for this effect, which is that the models might learn person-related features, which could be undesirable. By asking the authors to comment on this, the reviewer encourages them to provide an explanation or analysis of this phenomenon. This feedback is somewhat helpful as it prompts the authors to consider and address a potential issue with their models. However, it lacks specific guidance or suggestions on how to investigate or resolve this issue, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. While it implies that the authors should consider this combination, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement or evaluate this combination. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment poses a question about the combination of TF-IDF and dense retrieval for evidence sentence extraction. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this combination could be applied. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about a particular technique but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking whether the authors tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the authors tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. While it highlights a potential area for exploration, it lacks depth and does not provide any guidance or suggestions on how this combination could be implemented or evaluated. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential area of interest but does not provide enough information for the authors to act upon it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include examples where the time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were found to be highly correlated despite not being neighboring countries. It also asks whether there were countries where the predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. While the comment provides a clear direction for the authors to include additional examples and analysis, it does not specify how to conduct this analysis or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include examples where the time-series prediction did not perform well, specifically mentioning the COVID-19 dataset and the correlation between UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where these examples and analyses are typically presented. The comment is specific in detailing what additional information should be included, but it is weakly grounded because it does not explicitly point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include examples where the time-series prediction did not perform well, specifically mentioning the COVID-19 dataset and the correlation between UK and Russia. The comment provides a specific example and asks for further exploration of countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the suggestion is logical and provides a direction for further analysis, it lacks detailed reasoning or references to support the claim that these examples are necessary or significant. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires more detailed justification or evidence to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from including examples where the time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were found to be highly correlated despite not being neighboring countries. It also asks whether there were countries where the predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. This feedback is somewhat helpful as it identifies a potential gap in the paper and provides a direction for further exploration. However, it lacks specific guidance on how to address these issues or what specific analyses should be conducted. To be more helpful, the comment could suggest ways to present these examples or provide more detailed insights into the analysis. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment criticizes the claims of proposing a \"learning framework\" as being overblown, stating that it is not a new framework but rather a modified loss and architecture. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might revise their claims or improve their framework description. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims made about proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not specify which parts of the paper make these claims, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the framework are considered overblown or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the claims of proposing a \"learning framework\" are overblown, suggesting that it is not a new framework but rather a modified loss and architecture. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the claims made in the paper regarding the proposed \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. While the comment identifies a potential overstatement in the claims, it lacks specific guidance or suggestions on how the authors might address this issue or improve their framework description. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the approach, noting that the learned prompts are customized for specific transformer-based architectures, which may not translate effectively to other models or even slight variations. It suggests exploring the possibility of designing prompts with more universal features or optimizing them independently of model architecture for broader applicability. While the comment identifies an area for improvement, it does not provide explicit instructions or concrete steps on how to achieve this goal. The authors are left to infer that they should explore the suggested approach, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of learned prompts being customized for specific transformer-based architectures, which may limit their generalization to other models or variations. It suggests exploring the design of prompts with more universal features or optimizing them independently of model architecture for broader applicability. However, the comment does not specify which part of the paper discusses the learned prompts, making it weakly grounded. The authors can infer that it relates to sections discussing the prompt learning process, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in detailing the issue and suggesting a potential solution, but the grounding is not fully provided. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the specificity of learned prompts being customized for individual transformer-based architectures, which may limit their generalization to other models or variations. The comment suggests exploring the design of prompts with more universal features or optimizing them independently of model architecture for broader applicability. While the claim is logical and provides a rationale for the potential limitation, it lacks specific examples or references to support the argument fully. The suggestion is based on common knowledge in the field, but the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the approach, specifically the customization of learned prompts for individual transformer-based architectures, which may hinder their generalization to other models or variations. It suggests exploring the design of prompts with more universal features or optimizing them independently of model architecture for broader applicability. This feedback is clear and actionable, providing the authors with a specific direction for improving the generalizability and applicability of their work. However, the comment could be more helpful if it offered specific examples or methodologies for achieving this broader applicability. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence of the current methodology\\'s effectiveness or novelty for fMRI forecasting. The reviewer explicitly recommends evaluating the model against advanced time-series forecasting models, such as those available in the \"Time-Series Library\" repository. This feedback provides a clear and concrete action for the authors to take, which is to include comparisons with contemporary models to strengthen their claims. The explicit nature of the suggestion and the specific reference to potential baselines make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence of the current methodology\\'s effectiveness or novelty. The comment provides a specific suggestion to evaluate the model against advanced time-series forecasting models, such as those available in the \"Time-Series Library\" repository. However, it does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the model\\'s comparison to contemporary models. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence of the current methodology\\'s effectiveness or novelty for fMRI forecasting. The reviewer provides a specific suggestion to evaluate the model against advanced time-series forecasting models available in the \"Time-Series Library\" repository. This provides a clear direction for improvement and supports the claim with a specific reference to a potential resource. However, the comment could be strengthened by providing more detailed examples or references to specific models that could be used as baselines. Overall, the claim is mostly verifiable due to the logical reasoning and the suggestion of a potential solution, but it lacks comprehensive evidence or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the absence of baselines and the antiquated nature of the model architecture used. It highlights the need for comparisons to other models to demonstrate the effectiveness and novelty of the current methodology for fMRI forecasting. The comment provides a specific suggestion by recommending potential baselines, such as those available in the \"Time-Series Library\" repository, which could be evaluated on fMRI data. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by including comparisons with contemporary models. However, it could be more helpful if it provided additional guidance on how to implement these comparisons or discussed the potential impact of using these baselines. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include at least one strong baseline in one of the tasks, beyond the standard MLPs presented in the paper. While the comment explicitly states that a strong baseline should be included, it does not specify which task should include this baseline or provide guidance on how to select or implement it. The action is explicit but somewhat vague, as the authors know they need to add a strong baseline but may not be entirely sure of the specifics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that only standard MLPs are presented as baselines. It suggests that at least one strong baseline should be included in one of the tasks, even though the paper is primarily theoretical. However, the comment does not specify which part of the paper this issue pertains to, such as the results or discussion sections, making it weakly grounded. The comment is specific in its request for a strong baseline, but without clear grounding, the authors may struggle to identify where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only presents standard MLPs as baselines, suggesting that at least one strong baseline should be included. However, the comment does not provide specific examples of what constitutes a strong baseline or how the current baselines fall short. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the specific improvements needed to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that only standard MLPs are presented as baselines. It suggests that, despite the paper being primarily theoretical, at least one strong baseline should be included in one of the tasks. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the inclusion of a strong baseline. However, the comment could be more helpful if it offered suggestions on which strong baselines to consider or how to integrate them into the study. Overall, the comment is mostly helpful as it directs the authors to enhance the robustness of their work by including stronger baselines.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to more clearly compare their proposed method to the prior works cited by the authors, specifically mentioning references [3] and [5]. It also suggests including these prior works for comparison in the tables of experimental results. This feedback provides a clear and direct action for the authors to take, specifying both the need for a clearer comparison and the inclusion of prior works in the experimental results. The comment is explicit and concrete, ensuring the authors know exactly what changes to make to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the prior works cited by the authors ([3, 5]), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed comparison of the proposed method with the prior works and the inclusion of these prior works in the tables of experimental results. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is similar to two prior works cited by the authors and suggests that the paper should more clearly compare the proposed method to these prior works. However, the comment does not provide specific details or examples of how the proposed method is similar to the prior works, nor does it reference specific aspects of the prior works that should be compared. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the proposed method is similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the tables of experimental results. This feedback is clear and actionable, providing the authors with a concrete step to enhance the clarity and comprehensiveness of their work. By addressing this point, the authors can improve the transparency and context of their research, making the comment mostly helpful. However, it could be more helpful if it offered additional guidance on how to effectively compare the methods or suggested specific aspects to focus on in the comparison. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the broader goals that have been identified, which are necessary for evaluating the claim about the non-existence of visualization systems for interpretable reinforcement learning. However, it does not provide explicit guidance on how the authors should address this issue or what specific information should be added to clarify the broader goals. The action is implicit, as the authors can infer that they need to provide more details about these goals, but it remains vague because it lacks concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to a specific quote from the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the broader goals that have been identified, which are necessary for evaluating the claim about the non-existence of visualization systems for interpretable reinforcement learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim about the non-existence of visualization systems for interpretable reinforcement learning, noting that it is unclear what the broader goals are that have been identified. This highlights a lack of clarity in the paper, making it difficult for the authors to address the claim effectively. The comment does not provide any supporting evidence or reasoning to substantiate the claim, nor does it suggest how the authors might clarify the broader goals. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper regarding the broader goals that have been identified, which are necessary for evaluating the claim about the non-existence of visualization systems for interpretable reinforcement learning. This feedback is somewhat helpful as it points out a specific area where the paper is unclear, prompting the authors to provide more detailed information about their broader goals. However, the comment does not offer suggestions on how to clarify these goals or improve the clarity of the paper, which limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the independence of AAL and SLS and questions the stability of their improvements when applied separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their draft. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"Table (1-4),\" which provides some grounding as it allows the authors to identify the specific part of the paper being addressed. However, it does not specify which improvements are slight or how the independence of AAL and SLS affects the stability of the improvements. The comment lacks specificity regarding what aspects of the tables or the independence of AAL and SLS need further exploration or clarification. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the introduced AAL and SLS appear to be independent and questions the stability of their improvements when applied separately. However, the comment does not provide specific evidence or reasoning to support this claim. It references \"Table (1-4),\" but without detailed analysis or examples, the claim remains vague and difficult for the authors to verify or address. This lack of supporting information makes the comment borderline verifiable, as it provides some indication of concern but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the independence of AAL and SLS and questions the stability of their improvements when applied separately. It references specific tables (1-4) to support this observation, suggesting that the improvements are slight. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or improve their work. While it identifies a potential issue, it does not offer actionable feedback or detailed insights, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should expand their experiments to include different tasks or multiple datasets for the same task, such as sentiment classification. This feedback provides a clear and explicit action for the authors to take, which is to diversify their experimental setup to gain deeper insights. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a limitation in the scope of the experiments, specifically mentioning the use of only one task (sentiment classification) and one dataset (SST2). This provides full grounding as it clearly identifies the specific aspect of the paper being addressed, allowing the authors to pinpoint the relevant sections. The comment is also specific, as it suggests exploring the effects on different tasks or utilizing multiple datasets for the same task to gain deeper insights. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited to only one task and one dataset, suggesting that exploring different tasks or multiple datasets would provide deeper insights. This claim is somewhat verifiable as it logically points out the potential limitations of the current experimental setup. However, the comment lacks specific examples or references to support the claim or to illustrate how exploring different tasks or datasets could enhance the study. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, noting that they are restricted to only one task (sentiment classification) and one dataset (SST2). It suggests that exploring different tasks or utilizing multiple datasets for the same task could provide deeper insights. This feedback is clear and actionable, as it guides the authors to expand their experimental setup to gain a broader understanding of their findings. However, the comment could be more helpful if it provided specific examples of additional tasks or datasets to consider. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of simulated data instead of real-world data in the experiments involving the Heat Equation, Damped Wave, and Navier-Stokes. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should consider using real-world data, how they might address this issue, or what specific changes they should make to improve their experimental design. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this feedback to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific experiments involving the Heat Equation, Damped Wave, and Navier-Stokes, suggesting that these are simulated rather than real-world data. This provides full grounding as it clearly identifies the parts of the paper being discussed. However, the comment lacks specificity regarding what needs to be addressed or improved in these experiments. It does not provide details on how the use of simulated data affects the results or suggest alternative approaches. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the use of simulated data instead of real-world data in experiments involving the Heat Equation, Damped Wave, and Navier-Stokes. However, it does not provide any supporting evidence, reasoning, or references to justify why real-world data would be preferable or how the use of simulated data affects the results. The comment lacks detailed explanation or examples, making it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the use of simulated data instead of real-world data in experiments involving the Heat Equation, Damped Wave, and Navier-Stokes. It suggests that simulated data might be easier to fit, implying a potential limitation in the generalizability of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their experimental design. Without detailed feedback or recommendations, the authors are left with only a vague understanding of the problem, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests including metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. While the comment provides a clear action\u2014adding specific metrics\u2014it does not offer detailed guidance on how to implement these metrics or what specific aspects should be evaluated. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation. However, the comment does not explicitly mention which part of the paper this limitation pertains to, such as the evaluation or results sections. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the evaluation. While the comment provides a specific suggestion for improvement, it does not offer detailed reasoning or examples to support why these metrics are necessary or how they would enhance the study. The suggestion is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification or evidence. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the rigor and depth of their evaluation. By addressing this point, the authors can significantly enhance the robustness and credibility of their results. However, the comment could be more helpful if it included additional guidance on how to implement these metrics or discussed the potential impact of their inclusion. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the mechanism discussed in the paper could be applied to vision transformers. While it implies that the authors should consider this possibility, it does not explicitly instruct them to explore this application or provide guidance on how to do so. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for the authors to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the mechanism discussed in the paper to vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the mechanism might be relevant or how it could be applied to vision transformers. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification or exploration of an application. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the applicability of the mechanism discussed in the paper to vision transformers. While it prompts the authors to consider a potential extension or application of their work, it lacks specificity and does not provide any guidance or suggestions on how to explore this possibility. The comment is vague and does not offer actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it identifies a potential area for exploration but does not provide sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the precision of IMLE compared to the proposed Adaptive IMLE and asks whether the authors have tried applying the method in different domains. While the questions imply that the authors should address these points, they do not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or what kind of analysis or application should be considered. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the precision of IMLE compared to the proposed Adaptive IMLE and asks whether the authors have tried applying the method in different domains. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the precision comparison and the potential application of the method in different domains. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the precision of IMLE compared to the proposed Adaptive IMLE and whether the authors have applied the method in different domains. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the paper: why the precision of IMLE is better than the proposed Adaptive IMLE, and whether the authors have tried applying the method in different domains. These questions highlight areas where the authors could provide additional clarification or evidence to strengthen their work. However, the comment does not offer specific suggestions or guidance on how the authors might address these questions or improve their paper. While it prompts the authors to consider these aspects, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are lacking and questions whether all the modules are necessary. However, it does not provide specific guidance on how the authors should address this issue or what specific changes should be made to improve the experimental results. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the experimental results are lacking and questions whether all the modules are necessary. However, it does not specify which part of the paper this assessment is based on, such as specific sections, figures, or tables. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the experimental results are lacking or how the authors might address the question about module necessity. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental results are lacking and questions whether all the modules are necessary. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically questioning whether all the modules are necessary. This is a relevant point that could help the authors refine their experimental setup and potentially improve the clarity and efficiency of their work. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It raises a valid concern but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider adding more layers to their network, specifically mentioning 32 and 64 layers. This is an explicit suggestion, as it directly instructs the authors to expand their experiments to include additional layers. However, the comment does not provide specific guidance on how to implement this suggestion or what specific outcomes to expect. While the action is clear, the lack of detailed instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the consideration of a few layers, up to 8 layers, in the paper. It mentions the known issue of GNNs oversmoothing with more layers and suggests exploring the network behavior with more layers, such as 32 and 64. However, the comment does not specify which part of the paper discusses the number of layers, making it weakly grounded. The suggestion to explore more layers is specific, but without clear grounding, the authors may struggle to identify where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should explore the behavior of their network with more layers, specifically mentioning 32 and 64 layers. The claim is based on the known issue of GNNs oversmoothing with more layers, which is a common understanding in the field. However, the comment does not provide specific references or detailed reasoning to support the claim, such as examples of studies that have observed this issue or how it relates to the specific network architecture being discussed. This lack of detailed justification makes the claim somewhat verifiable, as it provides a logical suggestion but lacks comprehensive evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the authors\\' experimental setup, specifically the consideration of only a few layers (up to 8). It points out a known issue with GNNs, which tend to oversmooth with more layers, and suggests exploring the network behavior with more layers, such as 32 and 64. This feedback is somewhat helpful as it highlights an area for further exploration and provides a specific suggestion for expanding the experiments. However, it lacks detailed guidance on how to conduct these additional experiments or what specific outcomes to expect, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform significance tests to ensure the reliability of the experimental results, given that the improvement of MT over ST is limited. This is a clear and direct action for the authors to take, providing them with a specific task to improve their draft. The comment is concrete, as it specifies exactly what needs to be done to address the concern. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement of MT over ST and suggests performing significance tests to ensure the reliability of the experimental results. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to perform significance tests, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is limited and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific examples, data, or references to support the claim about the limited improvement or the necessity of significance tests. Without such supporting evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that the improvement of MT over ST is limited. It suggests performing significance tests to ensure the reliability of the experimental results, which is a clear and actionable piece of feedback. This guidance can help the authors strengthen their experimental analysis and provide more robust evidence for their claims. However, the comment could be more helpful if it provided specific examples or methodologies for conducting significance tests, which would offer even more detailed guidance. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that the proposed framework is model-agnostic, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which employ LSTM-like aggregation. While the comment implies that the authors should evaluate their framework on these additional architectures, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct these evaluations or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5\" and the specific models employed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of model-agnosticism and suggests evaluating the framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to demonstrate its versatility. This provides clear guidance on what needs to be addressed or expanded in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the proposed framework is model-agnostic, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which employ LSTM-like aggregation. This claim is somewhat verifiable as it highlights a potential limitation in the evaluation and suggests a specific area for further exploration. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as specific examples or references to similar frameworks. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that the proposed framework is model-agnostic, as it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which employ LSTM-like aggregation. This feedback is clear and actionable, as it suggests a specific area for further evaluation and exploration that could strengthen the paper\\'s claims. By prompting the authors to consider additional GNN architectures, the comment provides valuable guidance for improving the comprehensiveness and robustness of the framework\\'s evaluation. However, it could be more helpful if it included specific suggestions on how to conduct these evaluations or what aspects to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an error analysis regarding how the method would perform if one of its components, such as GPT-4o, makes a mistake. This is an explicit request for additional analysis, providing a clear action for the authors to take. However, the comment does not specify how this analysis should be conducted or what specific aspects should be examined, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an error analysis regarding the method\\'s components, specifically questioning what happens if GPT-4o misses some details. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an error analysis, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and questions the robustness of the approach if one of these components, such as GPT-4o, makes a mistake. However, the comment lacks specific examples or detailed reasoning to support the claim that an error analysis is necessary. Without concrete evidence or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides an initial idea but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the method has many components and suggests that an error analysis would be beneficial. It specifically questions what would happen if one of the components, such as GPT-4o, makes a mistake. This feedback is somewhat helpful as it highlights an area for improvement and provides a direction for further analysis. However, the comment could be more helpful if it offered specific suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the computational cost of the reversible version during training, questioning its practicality given the affordability of memory. It also suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. The comment provides explicit actions for the authors to take, such as comparing the computational cost and including specific scores. These suggestions are clear and concrete, giving the authors specific tasks to perform to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses two distinct points. The first part discusses the computational cost of the reversible version, questioning its practicality given the affordability of memory. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The second part suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. This suggestion is specific but also lacks grounding as it does not reference a particular section or part of the paper. Overall, the comment is weakly grounded and specific, as it provides a clear suggestion but does not specify where in the paper it should be addressed. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the computational cost of the reversible version during training, as stated in the paper, and questions its practicality given the affordability of memory. This is a factual observation about the paper\\'s acknowledgment and does not contain an opinion or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment addresses two distinct points. First, it acknowledges the computational cost of the reversible version during training, questioning its practicality given the affordability of memory. This is a relevant observation that prompts the authors to consider the practical implications of their approach. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as exploring alternative methods to reduce computational cost or discussing the trade-offs involved. Second, the comment suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. This is a specific and actionable suggestion that could help the authors substantiate their claims. Overall, the comment provides some helpful insights but lacks depth and actionable guidance in the first part, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of an error analysis, suggesting that it would be beneficial for understanding the limitations of SetCSE in specific scenarios. While the comment implies that an error analysis should be included, it does not explicitly instruct the authors to add it or provide guidance on how to conduct such an analysis. The action is implicit and somewhat vague, as the authors need to infer the need for an error analysis and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests the inclusion of an error analysis to understand the limitations of SetCSE in specific scenarios. However, it does not specify which part of the paper should include this analysis or where the current draft lacks this information. The authors might infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in suggesting the need for an error analysis but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an error analysis would be beneficial for understanding the limitations of SetCSE in specific scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why an error analysis is necessary or how it would improve the understanding of SetCSE. Without additional context or explanation, the claim is not verifiable, making it difficult for the authors to address the suggestion effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of an error analysis in the paper. This feedback is valuable as it highlights a potential gap in understanding the limitations of SetCSE in certain scenarios. However, the comment does not provide detailed guidance or suggestions on how to conduct such an analysis or what specific aspects should be considered. While it offers a clear direction for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for enhancing the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge by prompting, suggesting that in scenarios where model weights are shared, there might be unintentional fine-tuning that recovers tool-knowledge. It also mentions the possibility of other prompts that could elicit the model\\'s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The feedback lacks concrete steps or recommendations, leaving the authors uncertain about how to respond to the critique. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge by prompting, suggesting that in scenarios where model weights are shared, there might be unintentional fine-tuning that recovers tool-knowledge. It also mentions the possibility of other prompts that could elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing the potential issue with measuring tool-knowledge by prompting but lacks grounding in terms of identifying the exact section or context in the paper where this concern arises. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge by prompting, suggesting that in scenarios where model weights are shared, there might be unintentional fine-tuning that recovers tool-knowledge. The comment also mentions the possibility of other prompts that could elicit the model\\'s ability to use a tool. However, the claim lacks specific examples, references, or detailed reasoning to support the assertion that prompting might not suffice. Without such evidence or examples, the claim remains somewhat vague and difficult for the authors to fully understand and address. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge by prompting, suggesting that in scenarios where model weights are shared, there might be unintentional fine-tuning that recovers tool-knowledge. It also mentions the possibility of other prompts that could elicit the model\\'s ability to use a tool. While the comment identifies a potential issue with the current approach, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative methods. The feedback is somewhat helpful as it prompts the authors to consider the limitations of their current methodology, but it could be more beneficial with additional direction or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the experimental results, noting that the improvement of HA3C over baseline algorithms on MuJoCo control tasks is marginal. The reviewer suggests that the benefit of HA3C may rely on the structure of the problem, where the causal relationship based on the current state is complex but the causal relationship based on history can be simple. The reviewer recommends finding other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. While the comment implies that the authors should explore different tasks, it does not provide specific guidance on how to identify or create these tasks. The action is implicit and somewhat vague, as the authors are left to infer the steps needed to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the experimental results and the improvement of HA3C over baseline algorithms on MuJoCo control tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it provides a rationale for why the improvement might be marginal, suggesting that the benefit of HA3C relies on the structure of the problem and that MuJoCo tasks may not be ideal for demonstrating its effectiveness. The reviewer further suggests finding other tasks or even artificial tasks to better demonstrate HA3C\\'s effectiveness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the experimental results by stating that the improvement of HA3C over baseline algorithms on MuJoCo control tasks is marginal. The reviewer provides a rationale for this observation by suggesting that the benefit of HA3C may rely on the structure of the problem, where the causal relationship based on the current state is complex but the causal relationship based on history can be simple. This reasoning is logical and provides a basis for the claim, but it lacks specific examples or references to support the suggestion that MuJoCo tasks may not be ideal for demonstrating HA3C\\'s effectiveness. Therefore, the comment is mostly verifiable, as it provides a logical basis but could benefit from additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critical analysis of the experimental results, noting that the improvement of HA3C over baseline algorithms on MuJoCo control tasks is marginal. The reviewer offers a rationale for this observation, suggesting that the benefit of HA3C may rely on the structure of the problem, where the causal relationship based on the current state is complex but the causal relationship based on history can be simple. This insight could help the authors understand the limitations of their approach in the context of MuJoCo tasks. The comment also offers a constructive suggestion by recommending that the authors explore other tasks or even artificial tasks to better demonstrate the effectiveness of HA3C. This feedback is clear, actionable, and provides a direction for further exploration, making it highly helpful for the authors to improve their draft. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus on the insights derived from the data to deepen our understanding of LLM capabilities, rather than solely on the dataset itself. It criticizes the paper for primarily reporting aggregate numbers without clearly presenting key takeaways. The reviewer explicitly requests to see key insights or takeaways derived from the experiments that are generalizable and hold broader significance for the community. This feedback provides a clear and explicit action for the authors to take, specifying what needs to be addressed and improved in the paper. The comment is highly actionable as it gives concrete guidance on how to enhance the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the novelty and key contributions of the paper, specifically focusing on the insights derived from the data rather than the dataset itself. It critiques the paper for primarily reporting aggregate numbers without clearly presenting key takeaways. The comment suggests that the authors should provide insights or takeaways that are generalizable and hold broader significance for the community. However, it does not explicitly mention which sections or parts of the paper should be revised to include these insights, making it weakly grounded. The comment is specific in detailing what is missing and what is needed to improve the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not fully address the key contributions, focusing on aggregate numbers without clearly presenting insights or takeaways. The reviewer suggests that the paper should focus on insights derived from the data to deepen our understanding of LLM capabilities. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the paper does not adequately present insights. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the lack of focus on insights derived from the data to deepen our understanding of LLM capabilities. It points out that the paper primarily reports aggregate numbers without clearly presenting key takeaways beyond the general message that LLM performance does not align with human abilities. The comment provides a clear direction for the authors to enhance their work by suggesting that they should present key insights or takeaways that are generalizable and hold broader significance for the community. This feedback is actionable and constructive, offering a clear path for the authors to improve their draft. However, it could be more helpful if it included specific examples or guidance on how to derive these insights. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a false claim in the paper regarding the de facto choice of GAN for vocoders and highlights the omission of other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. The reviewer provides a clear and specific action for the authors to take, which is to correct the false claim and include a more comprehensive discussion of the various vocoder choices. The feedback is explicit and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim about GAN being the de facto choice for vocoders and highlights the omission of other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"GAN has been the de facto choice for vocoders\" by stating that it is a false claim and ignores a large array of active and important works in the community. The reviewer provides specific examples of other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches, which serve as a counterpoint to the original claim. This detailed critique supports the claim with logical reasoning and specific references, making it fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific claim in the paper that is considered false and highlights the omission of other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This feedback is clear and actionable, as it directs the authors to correct the false claim and provide a more comprehensive overview of the vocoder landscape. By addressing this point, the authors can improve the accuracy and completeness of their work. However, the comment could be more helpful if it suggested how to incorporate these additional vocoders into the discussion or provided examples of how to present them effectively. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the approach contains design choices that are not fully explained or empirically justified, such as the choice of token similarity metric. While it identifies areas that need further explanation, it does not provide specific guidance on how the authors should address these issues or what aspects need to be clarified. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a general issue with the approach, noting that it contains design choices that are not fully explained or empirically justified. However, it does not specify which part of the paper this issue pertains to, such as specific sections or design choices mentioned in the paper. This lack of explicit reference makes it weakly grounded. The comment is specific in identifying the issue of design choices not being fully explained or justified, but without clear grounding, the authors may struggle to pinpoint where these issues are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach contains design choices that are not fully explained or empirically justified. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the choice of token similarity metric as an example is vague and lacks context, making it difficult for the authors to understand the basis of the critique. Without further elaboration or references, the claim remains unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the approach, noting that it contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. While this feedback highlights areas that need further clarification, it lacks specific guidance or suggestions on how the authors might address these issues. The comment points out a potential weakness but does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific inconsistencies in the notation, pointing out that Equation (4) has \"T and W\" on the left-hand side (LHS) but not on the right-hand side (RHS), and that Equation (6) has \"j\" on the LHS but not on the RHS. This feedback is explicit and provides clear guidance on what needs to be corrected in the manuscript. The authors know exactly which equations and elements of the notation are incorrect and how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, \"Equation (4)\" and \"Equation (6),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out inconsistencies in the presence of \"T and W\" on the left-hand side (LHS) of Equation (4) but not on the right-hand side (RHS), and the presence of \"j\" on the LHS of Equation (6) but not on the RHS. This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific inconsistencies in the notation of equations, such as the presence of \"T and W\" on the left-hand side (LHS) of Equation (4) but not on the right-hand side (RHS), and the presence of \"j\" on the LHS of Equation (6) but not on the RHS. This is a factual observation about the manuscript\\'s content, which does not require any subjective claims or opinions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific inconsistencies in the notation of equations, pointing out that Equation (4) has \"T and W\" on the left-hand side (LHS) but not on the right-hand side (RHS), and that Equation (6) has \"j\" on the LHS but not on the RHS. This feedback is clear and actionable, as it provides precise guidance on where the authors need to correct their notation to ensure consistency. By addressing these minor but important details, the authors can improve the clarity and accuracy of their manuscript. However, the comment could be more helpful if it provided additional context or explained why these inconsistencies are important. Overall, the comment is mostly helpful, as it effectively directs the authors to make specific improvements to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the evaluation is insufficient, including the number of models constructed, the lack of evaluation on image distortion after warping, and the absence of discussion on potential countermeasures. While the comment identifies specific issues, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they need to construct more models, evaluate image distortion, and discuss countermeasures, but the comment does not offer concrete steps or suggestions on how to implement these actions. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses multiple issues related to the evaluation of the paper. It points out that only a small number of models were constructed during the evaluations, which is insufficient to demonstrate the approach\\'s effectiveness. It also mentions the lack of evaluation regarding the distortion of the image after warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the evaluation and results sections. The comment is specific in detailing what is missing or insufficient in the evaluation, providing clear guidance on what needs to be addressed. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient due to the small number of models constructed and the lack of evaluation on image distortion after warping. It also mentions the absence of discussion on potential countermeasures. While the comment identifies specific areas where the evaluation could be improved, it lacks detailed reasoning or examples to support why these aspects are crucial for demonstrating the approach\\'s effectiveness. The claim is somewhat verifiable, as it highlights important evaluation gaps but requires more detailed justification or evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the evaluation of the paper is insufficient. It points out that only a small number of models were constructed during the evaluations, which is insufficient to demonstrate the approach\\'s effectiveness. Additionally, it highlights the lack of evaluation regarding the distortion of the image after warping and the absence of discussion on potential countermeasures against the proposed approach. This feedback is clear and actionable, as it provides specific areas for the authors to expand their evaluation and discussion. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what a more comprehensive evaluation might entail. Overall, the comment is mostly helpful, as it directs the authors to important areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the content of Table A3, specifically whether all the discourse particles are discourse particles or a combination of discourse particles and imported vocab. It suggests that if the latter is the case, the table should be separated, and glosses would be helpful. While the comment implies that the authors should consider restructuring the table and providing glosses, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the discourse particles in the table and suggests separating them if they include imported vocab. Additionally, it recommends providing glosses, which offers clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the content of Table A3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the organization of Table A3. It questions whether all the discourse particles are discourse particles or a combination of discourse particles and imported vocab, and suggests separating them if the latter is the case. Additionally, it recommends providing glosses to aid in understanding the content. This feedback is clear and offers a concrete way for the authors to improve the clarity and presentation of their data, making it mostly helpful. However, it could be further improved by explaining why separating the discourse particles and imported vocab might be beneficial or how glosses would enhance the table\\'s utility. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the idea behind formula (4), specifically questioning why the maximum is taken over all possible pieces for unoccupied squares. While the comment highlights a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify or justify the rationale behind this formula, but without specific instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"formula (4),\" allowing the authors to accurately identify the specific part of the paper being addressed, which provides full grounding. It also specifies the issue by questioning the rationale behind taking the maximum over all possible pieces for unoccupied squares. This provides clear guidance on what aspect of the formula needs clarification or justification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the rationale behind a specific formula. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the rationale behind formula (4), particularly the choice of taking the maximum over all possible pieces for unoccupied squares. This feedback is valuable as it highlights a potential gap in the explanation or justification provided in the paper. However, the comment does not offer suggestions or guidance on how the authors might clarify or improve this aspect of their work. While it points out a weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments lack a comparison to state-of-the-art subset selection methods. While it identifies a specific area for improvement, it does not provide explicit guidance on which state-of-the-art methods should be included or how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should add comparisons to state-of-the-art methods but are not given detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, noting the lack of comparison to state-of-the-art subset selection methods. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for comparison to state-of-the-art methods, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any specific examples or references to these state-of-the-art methods, nor does it explain why this comparison is necessary or how it would improve the paper. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, noting the lack of comparison to state-of-the-art subset selection methods in the experiments. This feedback is valuable as it highlights an area where the paper could be improved by including relevant comparisons to strengthen its contribution. However, the comment does not provide specific suggestions on which state-of-the-art methods should be considered or how to incorporate them into the experiments. While it points out a clear area for enhancement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the novelty of the paper is vague and needs to be more concise. It also mentions that the primary components integrate elements from previous works, such as SCL, Aligned, and CLNN. However, it does not provide specific guidance on how the authors should make the novelty more concise or differentiate their work from the previous works mentioned. The feedback lacks explicit instructions or concrete details on how to improve the paper, leaving the authors uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it is somewhat vague and needs to be more concise. It mentions that the primary components integrate elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which sections or parts of the paper need to be revised to improve the novelty. While the authors might infer that this relates to the introduction or literature review sections, the lack of explicit grounding makes it challenging to pinpoint the exact areas needing attention. The comment is specific in identifying the need for clarity on novelty but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is vague and needs to be more concise. It supports this claim by mentioning that the primary components integrate elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific examples or detailed reasoning to substantiate why these components are not novel or how they could be differentiated. This lack of detailed justification makes the claim somewhat verifiable, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a potential issue with the paper\\'s novelty, noting that it is somewhat vague and needs to be more concise. It also points out that the primary components of the paper integrate elements from previous works, such as SCL, Aligned, and CLNN. While this feedback highlights a critical area for improvement, it lacks specific guidance or suggestions on how the authors might enhance the novelty or differentiate their work from existing literature. Without actionable advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. This implies that the authors should include such benchmarks to make the evaluation more usable and accessible to the community. While the action is not explicitly stated, it is clear and concrete, as it specifies what needs to be done to improve the draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use such benchmarks to make the evaluation more usable and accessible to the community. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. However, it does not provide any specific examples, references, or detailed reasoning to support why this would be important or how it would benefit the community. The lack of supporting evidence or justification makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a way to make the evaluation more usable and accessible to the community. However, the comment lacks specific guidance on how to implement these benchmarks or what criteria should be used for evaluation. While it provides a direction for improvement, it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. While it highlights an important aspect that the authors should address, it does not provide explicit guidance or suggestions on how to investigate or report this impact. The action is implicit, as the authors need to infer that they should explore and discuss the effect of open-set detectors. However, the comment lacks concrete details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies an area for further exploration but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in its inquiry about the impact of open-set detectors, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of open-set detectors on the performance of the proposed method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the impact of open-set detectors on the performance of the proposed method. This is a relevant point that could help the authors understand and address potential limitations or strengths of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or report on this impact. While it identifies a potential area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues regarding the tables in the paper. First, it notes the presence of a star (*) next to \"oracle goals\" in Table 1 but points out that there is no explanation for this symbol anywhere in the paper. Second, it questions the meaning of \"from-scratch\" in Table 5, asking whether the model was randomly initialized or if it was pre-trained on a text corpus. The reviewer explicitly asks the authors to clarify or fix these issues, providing clear and concrete actions for the authors to take. The feedback is explicit and detailed, ensuring that the authors know exactly what needs to be addressed and how to do so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the lack of explanation for the star (*) next to \"oracle goals\" in Table 1 and the confusion regarding the meaning of \"from-scratch\" in Table 5. The comment provides clear guidance on what needs to be clarified or fixed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and requests for clarification regarding the symbols and terminology used in the tables. It does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper: the lack of explanation for the star (*) next to \"oracle goals\" in Table 1 and the confusion regarding the meaning of \"from-scratch\" in Table 5. It asks for clarification on whether the model was randomly initialized or pre-trained on a text corpus. This feedback is clear and actionable, as it directs the authors to provide additional information or clarification in their manuscript. By addressing these points, the authors can improve the clarity and accuracy of their work. Therefore, the comment is mostly helpful, as it effectively guides the authors toward enhancing the comprehensibility of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point observes that transferability appears to increase with higher noise intensity, as shown in Table 1. It suggests that this result might be expected due to the activation of different neurons to reduce confidence in source samples, leading to increased misclassification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve the draft based on this feedback. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the relationship between noise intensity and transferability, suggesting that the results might be expected due to the activation of different neurons. However, the comment lacks specificity in terms of what the authors should do to address this observation or how they might improve the results. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point makes a claim about the relationship between noise intensity and transferability, suggesting that as noise intensity increases, transferability should also increase due to the activation of different neurons. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or verify the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of results presented in Table 1, specifically regarding the relationship between noise intensity and transferability. It suggests that as noise intensity increases, different neurons might be activated to reduce confidence in source samples, leading to increased misclassification. However, the comment does not provide any constructive feedback or suggestions on how the authors might address this observation or improve their analysis. While it points out a possible area of concern, it lacks actionable guidance or specific advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit and concrete actions for the authors to take. It suggests adding ablation studies with only importance weighting or the rejection to better understand their effects. It also points out that the fonts in the figures are too small to read and requests an explanation for the ChopperCommand results in Fig. 6 (a), which seem to indicate that the reward becomes large very quickly but decreases along the training. The comment is highly actionable because it clearly identifies specific areas for improvement and provides guidance on how to address them.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the lack of ablation studies and the issue with the fonts in the figures, and it references Fig. 6 (a) for further discussion. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, such as adding ablation studies, improving the readability of the figures, and explaining the ChopperCommand results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding ablation studies to better understand the effects of importance weighting and rejection. However, it does not provide specific reasoning or evidence to support why these studies are necessary or how they would improve the paper. The comment also mentions issues with the readability of figures and the ChopperCommand results, but again lacks detailed justification or examples to substantiate these claims. As a result, the claims are not fully supported, making the comment somewhat verifiable. The authors would need to make a significant effort to understand and address these points without further elaboration from the reviewer.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable points for improvement. It suggests adding ablation studies to better understand the effects of importance weighting and rejection, which is a clear and specific recommendation that can enhance the paper\\'s analysis. Additionally, it points out an issue with the readability of the figures, which is a practical concern that the authors can address. The comment also raises questions about the ChopperCommand results in Fig. 6 (a), prompting the authors to provide an explanation for the observed behavior. This feedback is detailed and constructive, offering the authors a clear path to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of technical clarity, specifically mentioning that Equation (18) is not explained and questions how to implement the balancing term and the penalty term. While the comment highlights areas that need clarification, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and implementation details, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer detailed instructions on how to achieve them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (18),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the main learning framework and the implementation details of the balancing term and the penalty term. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning that Equation (18) is not explained and questioning how to implement the balancing term and the penalty term. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the technical clarity is weak or how the implementation details are unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of weakness in the paper, namely the lack of technical clarity regarding the main learning framework, specifically Equation (18). It highlights the need for an explanation of how to implement the balancing term and the penalty term. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations in their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or examples of what information should be included. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides some direction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the decision boundary generation process, noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite feature vectors updating during training. It suggests that the authors clarify how well these fixed tessellations capture the model\\'s behavior and questions the use of 2D projections to represent high-dimensional decision boundaries. While the comment identifies areas of concern, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the methodology and potentially explore alternative methods, but the lack of specific guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures\" and the \"projection results and the Voronoi tesselation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the fixed nature of the projection results and Voronoi tessellation across multiple rounds, despite feature vectors updating during training. Additionally, it raises concerns about the use of 2D projections to represent high-dimensional decision boundaries and questions how well these fixed tessellations capture the model\\'s behavior. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation process, noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite feature vectors updating during training. The reviewer suggests that these fixed tessellations may not accurately capture the model\\'s behavior and questions the use of 2D projections to represent high-dimensional decision boundaries. While the comment identifies potential issues, it lacks specific examples, detailed reasoning, or references to support the claims. This makes the comment somewhat verifiable, as it provides a basis for the concern but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the decision boundary generation process, noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite feature vectors updating during training. It highlights the importance of clarifying how well these fixed tessellations capture the model\\'s behavior and questions the use of 2D projections to represent high-dimensional decision boundaries. This feedback is valuable as it identifies a potential issue with the methodology and prompts the authors to address it. However, the comment could be more helpful by providing specific suggestions or examples on how to address these concerns, such as alternative methods or analyses to consider. Overall, the comment is somewhat helpful as it directs the authors to a significant area needing clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study and a comparison to methods from the past decade. While it identifies specific areas that need to be addressed, it does not provide explicit instructions or concrete details on how to conduct these studies or which methods to compare. The authors can infer that they need to include an ablation study and comparisons, but the comment lacks guidance on how to implement these actions. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an ablation study and a comparison to methods from the past decade. However, it does not specify which part of the paper should include these elements, making it weakly grounded. The comment is specific in identifying what is missing\u2014namely, an ablation study and comparisons to past methods\u2014but without clear references to sections or parts of the paper, the authors may struggle to determine where to incorporate these improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is \"No ablation study\" and \"No comparison to methods in the past decade.\" These are factual statements describing the absence of certain elements in the paper. They do not express opinions, judgments, or suggestions that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two significant gaps in the paper: the absence of an ablation study and a comparison to methods from the past decade. These are important aspects that can help the authors strengthen their work by providing insights into the effectiveness and novelty of their approach. However, the comment lacks specific guidance or suggestions on how to conduct these studies or which methods to compare. While it highlights critical areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, as it provides some direction but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not specify which models should be considered or provide guidance on how to develop these theoretical results. The action is implicit and vague, as the authors are left to infer which models to focus on and how to expand the theoretical content. Without concrete details or examples, the authors may struggle to determine the exact steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what specific models or theoretical results should be included. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion or how it would improve the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which models should be considered or how to develop these theoretical results. The feedback is vague and does not offer actionable steps for the authors to enhance their draft. As a result, the comment is barely helpful, as it points out a general area for improvement but does not provide sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It also points out that the current results in Fig. 11 are insufficient for this purpose. This feedback provides a clear and direct action for the authors to take, which is to conduct additional ablation studies to strengthen their argument. The comment is specific and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It explicitly mentions \"Fig. 11,\" which allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific as it clearly specifies what needs to be addressed, namely the need for more ablation studies to demonstrate the necessity of the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more ablation studies are needed to demonstrate the necessity of the proposed DA Inversion. The reviewer critiques the existing results in Fig. 11 as insufficient, but does not provide specific examples or detailed reasoning to support why additional studies are necessary. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific aspects that need further exploration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more ablation studies should be conducted to demonstrate the necessity of the proposed DA Inversion. It points out that the current results in Fig. 11 are insufficient, providing a clear direction for the authors to enhance their work. This feedback is actionable and offers a concrete step for the authors to take to strengthen their paper. However, it could be more helpful if it included specific suggestions on what aspects of the DA Inversion should be tested or how the ablation studies should be structured. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of clustering in the second phase of training if a linear regressor is used for evaluation. It explicitly suggests that a clear ablation study should be presented to address this issue. The action is explicit, as it directly instructs the authors to conduct an ablation study to clarify the role of clustering. However, while the action is clear, it lacks detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of clustering in the second phase of training and suggests that a clear ablation study should be presented to address this issue. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of clustering in the second phase of training, given that a linear regressor is used for evaluation. The comment suggests that a clear ablation study should be conducted to address this issue. However, the claim lacks specific reasoning or evidence to support why clustering might not be necessary or how it impacts the evaluation. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the necessity of clustering in the second phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be conducted to address this issue, providing a specific and actionable recommendation for the authors to improve their draft. By highlighting the need for a clear explanation or demonstration of the role of clustering, the comment offers valuable guidance that can help the authors enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided additional context or examples of how such an ablation study might be conducted. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the figures, specifically mentioning Fig2a, where the forgetting is not as drastic as in class incremental learning and shows a slight increase near epoch 150. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this observation or improve the figures, leaving the authors without any actionable steps to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the specific part of the paper being addressed, which provides full grounding. It also specifies the issue with the figures, noting that the forgetting is not as drastic as in class incremental learning and that a slight increase is seen near epoch 150. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the figures, specifically Fig2a, suggesting that the forgetting is not as drastic as in class incremental learning and that a slight increase is seen near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures, particularly Fig2a, where the forgetting is not as drastic as in class incremental learning and shows a slight increase near epoch 150. This feedback is somewhat helpful as it points out a potential discrepancy or limitation in the analysis presented in the figures. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the figures. Without additional context or specific advice, the authors may struggle to fully understand or resolve the problem. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. While the comment implies that this should be done in the abstract, it does not explicitly instruct the authors to make this change. The action is clear and concrete, but it is communicated indirectly, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. However, it does not specify where in the paper this should be highlighted, such as in the abstract or a particular section. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed regarding the data dependency of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it impacts the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. This is a relevant point that could help readers understand the limitations and applicability of the results. However, the comment lacks specific guidance on how to incorporate this information into the abstract or other sections of the paper. While it identifies an area for improvement, it does not provide actionable steps or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on the meaning of RMSD in Figure 3. It asks whether RMSD refers to the difference between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This direct request provides a clear action for the authors to take, which is to clarify the meaning of RMSD in their figure. The comment is specific and provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD, distinguishing between its use in comparing a docking pose to ground truth from PDB and its use in quantifying consensus between docking poses obtained with different methods. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the meaning of RMSD in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion in the paper regarding the meaning of RMSD in Figure 3. By asking whether RMSD refers to the difference between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus, the reviewer provides clear and actionable feedback. This guidance allows the authors to clarify their methodology and improve the clarity of their presentation, which is crucial for the understanding and reproducibility of their work. The comment is highly helpful as it directly addresses a critical aspect of the paper, offering a precise suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It also poses a question about whether there could be a smooth regret scaling without phase transitions while still maintaining the proven bounds. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete steps on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be explored but without detailed guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a question about whether there could be a smooth regret scaling without phase transitions while still maintaining the proven bounds. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a more thorough treatment and the question it poses, but without clear grounding, the authors may struggle to identify where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide a more thorough analysis of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. The reviewer questions whether there could be a smooth regret scaling without phase transitions while maintaining the proven bounds. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that such an analysis is necessary or beneficial. Without these elements, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides an initial idea but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests a more thorough analysis of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises an important question about whether there could be a smooth regret scaling without phase transitions while still maintaining the proven bounds. This feedback is somewhat helpful as it identifies a potential area for improvement and encourages the authors to explore an alternative scenario. However, the comment lacks specific guidance or suggestions on how to conduct this analysis or what aspects to focus on, which limits its helpfulness. To be more helpful, the comment could include examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of a comparison to previous robust reinforcement learning (RL) methods, despite citing them, such as RARL. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. The comment provides a clear and explicit action for the authors to take: either include a comparison or clarify if it is already included. The suggestion is concrete, as it specifies what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that there is a missing comparison to previous robust reinforcement learning (RL) methods, despite citing them, such as RARL. It implies that the authors should either include a comparison or clarify if GAD or EG already include these prior works. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for a comparison or clarification regarding prior works, but without clear grounding, the authors may struggle to pinpoint where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a missing comparison to previous robust reinforcement learning (RL) methods, despite citing them. The reviewer suggests that if these prior works are already included in GAD or EG, the authors should be explicit about it. While the comment identifies a potential gap in the paper, it lacks specific examples or references to the cited works that should be included in the comparison. This makes the claim somewhat verifiable, as the authors would need to infer which prior works are missing and how to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of a comparison to previous robust reinforcement learning (RL) methods, despite citing them. It suggests that if these prior works are already included in GAD or EG, the authors should be explicit about it. This feedback is clear and actionable, as it directs the authors to either include a comparison or clarify the inclusion of prior works. By addressing this point, the authors can improve the comprehensiveness and transparency of their work. However, the comment could be more helpful if it provided specific examples of the prior works that should be included or compared. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. This is a clear and direct action for the authors to take, specifying exactly what needs to be expanded upon in the draft. The comment provides concrete guidance on what information should be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where these details are discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what additional information is needed, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not provide any specific reasoning or evidence to support why these details are necessary or how they would improve the paper. The comment lacks justification or examples that would help the authors understand the importance of these details or how they might impact the paper\\'s contribution. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to address the feedback effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. This feedback is clear and actionable, as it directs the authors to include additional information that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples or guidance on what kind of details should be included. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about why HIS is proportional to the negative inverse of mean response time. While it highlights an area of confusion, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this observation is a concern, if it needs addressing, or how the authors might clarify or resolve it. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the relationship between these two elements, but without clear grounding, the authors may struggle to identify where this issue is discussed in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the relationship between HIS and the negative inverse of mean response time. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might address this issue or clarify it in their paper. The comment lacks depth and actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it points out a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the choice of the sparse representation learning method and suggests that FTA should be compared as a baseline, particularly in the RL setting. It also points out the inconsistency in comparing FTA in a supervised learning setting but not in a RL setting. The comment implies that a rigorous comparison is necessary, but it does not explicitly instruct the authors to make these comparisons or provide guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for additional comparisons and the reasoning behind them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of the sparse representation learning method and suggests comparing FTA as a baseline, particularly in the RL setting. It also points out the inconsistency in comparing FTA in a supervised learning setting but not in a RL setting. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed regarding the choice of methods and the need for a rigorous comparison. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the choice of the sparse representation learning method and suggests that FTA should be compared as a baseline. It also points out an inconsistency in the comparison of FTA in a supervised learning setting but not in a reinforcement learning (RL) setting. The comment implies that a rigorous comparison is necessary for an empirical paper. While the comment identifies potential issues, it lacks specific reasoning or evidence to support why the choice of method is questionable or why the comparison is necessary. The absence of detailed justification or references makes the claim somewhat verifiable, as the authors would need to further explore the rationale themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important points that can help the authors improve their draft. It questions the rationale behind the choice of the sparse representation learning method, suggesting that a justification or comparison with other methods might be necessary. Additionally, it points out an inconsistency in the comparison of FTA as a baseline, noting that it is included in a supervised learning setting but not in a reinforcement learning (RL) setting. The comment emphasizes the importance of a rigorous comparison, especially in an empirical paper, to validate the findings. While the feedback is clear and identifies specific areas for improvement, it could be more helpful by providing suggestions on how to address these issues or by offering examples of comparable methods. Overall, the comment is mostly helpful as it directs the authors to critical areas needing clarification and comparison, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors describe a particular choice of shift and scaling but do not explain why this choice is considered more appropriate. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide an explanation, and it is somewhat vague because it lacks specific instructions on what aspects of the choice should be explained. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it points out the lack of explanation for the choice of shift and scaling, which is described as \"the more appropriate.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors describe a particular choice of shift and scaling but do not explain why this choice is considered more appropriate. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the explanation for a particular choice of shift and scaling described on page 4, line 154. By pointing out the absence of an explanation, the comment highlights a gap in the paper that the authors need to address. However, while it effectively draws attention to the issue, it does not provide specific suggestions or guidance on how the authors might clarify this choice. To be more helpful, the comment could include potential reasons or examples that could be used to justify the choice, or suggest ways to present the explanation more clearly. As it stands, the feedback is somewhat helpful, as it directs the authors to an area needing improvement but lacks detailed guidance on how to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors revise the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. This direct instruction provides a clear action for the authors to take, ensuring they know exactly what needs to be revised. The comment is specific and leaves no ambiguity about the required change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be revised, namely the use of \"partial inference\" in the title and elsewhere. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a concern about the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that it should be revised. However, the comment does not provide any justification or reasoning for why this term is problematic or how it could be improved. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that it should be revised. This feedback is clear and actionable, as it directly points out a potential problem with the terminology used in the paper. By recommending a revision, the comment provides the authors with a concrete step to improve the clarity and accuracy of their work. However, the comment could be more helpful if it explained why the current terminology is problematic or suggested alternative phrasing. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only uses bertscore to measure the similarity of newly generated text and suggests that there are other matrices that could measure the stealthiness of the generated content. However, it does not explicitly instruct the authors to include these additional matrices or provide specific guidance on which matrices to consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore and discuss other matrices, but they are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the measurement of similarity in newly generated text, specifically mentioning \"bertscore\" and suggesting that there are other matrices that could measure stealthiness. However, it does not specify which part of the paper discusses bertscore or where additional matrices should be considered. This makes the comment weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting that other matrices should be discussed, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only uses bertscore to measure the similarity of newly generated text and suggests that there are other matrices that could measure the stealthiness of the generated content. However, the comment does not provide specific examples or references to these alternative matrices, making it difficult for the authors to understand which other methods should be considered or how they might be applied. The lack of detailed justification or examples results in the claim being somewhat verifiable, as it provides a general suggestion but lacks the necessary support to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically noting that the paper only uses bertscore to measure the similarity of newly generated text and fails to discuss other matrices that could measure the stealthiness of the generated content. This feedback highlights an area for improvement by suggesting that the authors consider additional metrics or methods to assess the stealthiness of the generated content. However, the comment does not provide specific examples of these alternative matrices or detailed guidance on how to incorporate them into the paper. While it points out a relevant issue, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the clarity and completeness of the paper, specifically mentioning the lack of basic notation definition and the need to clearly highlight issues with existing estimators. It also provides examples of notation that are unclear, such as the dimensionality \"p,\" the unit ball \"S_p,\" and the constant \"d_2.\" Additionally, it requests clarity about the heuristic nature of Algorithm 1. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The authors can infer that they need to define basic notation and clarify the issues with existing estimators, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.2 or Eq. 3,\" \"Alg. 1,\" \"Alg. 2,\" \"Thm. 2, Eq. 5,\" and \"Clarity about the heuristic nature of Alg.\" This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details the issues with the clarity of basic notation, the need to highlight issues with existing estimators, and the lack of clarity about the heuristic nature of Algorithm 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity and completeness of the paper, specifically mentioning the lack of basic notation definition and the need to highlight issues with existing estimators. The reviewer provides examples of unclear notation, such as \"p,\" \"S_p,\" and \"d_2,\" and suggests that these terms are only inferred from referenced material. However, the comment does not provide specific examples or references to support the claim that these issues are problematic or how they impact the paper\\'s quality. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the concerns raised. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks comprehensive support for the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper lacks clarity and completeness, specifically mentioning the need to highlight issues with existing estimators and the lack of basic notation definition. It provides examples of unclear notation, such as \"p,\" \"S_p,\" and \"d_2,\" and suggests that these terms are only inferred from referenced material. Additionally, it requests clarity about the heuristic nature of Algorithm 1. While the comment highlights important areas for improvement, it could be more helpful by offering specific suggestions on how to address these issues or by providing examples of how to clarify the notation. Overall, the feedback is somewhat helpful as it points out specific weaknesses but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should elaborate on which parts of the loss functions are new, as they are not unheard of in the field of medical imaging. This feedback implies an explicit action for the authors to take, which is to provide more details on the novelty of the loss functions. However, it does not specify how the authors should elaborate on this point or what specific aspects need clarification. While the action is clear, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the claim about the loss functions is made, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, elaborating on which parts of the loss functions are new. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty of the loss functions used in the paper, suggesting that they are not entirely new in the field of medical imaging. The reviewer points out that the paper claims that \"three perceptual loss functions for PSR, two of which are new,\" but does not specify which parts of the loss functions are new. This claim is somewhat verifiable as it highlights a potential issue with the paper\\'s claims of novelty, but it lacks specific examples or references to substantiate the assertion. The authors would need to further investigate and clarify the novelty of their loss functions to address this point, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim regarding the novelty of the loss functions used. It points out that while the paper states that two of the loss functions are new, the neural network and the loss functions used (reconstruction error, TV, perceptual loss, dice) are not unheard of in the field of medical imaging. The comment suggests that the authors should elaborate on which parts of the loss functions are new, providing a clear and actionable direction for improvement. This feedback is mostly helpful as it highlights a specific area where the paper\\'s claims need clarification and suggests a way to address it. However, it could be more helpful if it offered examples or guidance on how to effectively communicate the novelty of the loss functions. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental results, noting that they justify theoretical statements but do not show significant improvements in real-life datasets. It also points out a specific issue with the comparison on the ZINC dataset, referencing Table 5 in a cited source. While the comment identifies areas of concern, it does not provide explicit guidance on how to address these issues or improve the experimental results. The authors are left to infer that they need to enhance the experimental results and provide a more robust comparison on the ZINC dataset, but without specific suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Results\" and references \"Table 5 in [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the experimental results do not exhibit significant improvement in real-life datasets and that the comparison on the ZINC dataset is lacking. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results, like those in many GNN papers, justify theoretical statements but do not show significant improvements in real-life datasets. It also mentions a specific issue with the comparison on the ZINC dataset, referencing Table 5 in a cited source. While the comment provides some reasoning by comparing the results to other GNN papers, it lacks detailed evidence or specific examples from the cited source to fully substantiate the claim. The mention of Table 5 provides some direction, but the comment could be strengthened with more detailed analysis or references. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires additional information for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental results, noting that they justify theoretical statements but do not demonstrate significant improvements in real-life datasets. It also points out a specific concern with the comparison on the ZINC dataset, referencing Table 5 in a cited source. This feedback is valuable as it highlights a potential weakness in the paper\\'s experimental validation and provides a specific example for the authors to address. However, the comment could be more helpful if it offered suggestions on how to enhance the experimental results or improve the comparison on the ZINC dataset. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that the SLM performs better than larger models due to limited data availability. It provides examples from various experiments, such as Figure 3 (b), where larger models perform better than smaller models. However, the comment does not explicitly instruct the authors to address this issue or suggest how they might do so. The action is implicit, as the authors can infer that they need to clarify or revise their claims about the SLM\\'s performance. The comment is somewhat actionable because it points out a potential issue but lacks explicit guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3 (b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the claim that the SLM performs better than larger models due to limited data availability. The comment supports this critique by referencing specific examples from various experiments, such as LucaOne performing better than BSM models and BSM-270M performing better than BSM-110M. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that larger models typically perform better than smaller models, providing specific examples from various experiments, such as Figure 3 (b), where LucaOne performs better than BSM models, and BSM-270M performs better than BSM-110M. This detailed reference to specific experiments and models provides a robust basis for the claim, making it fully verifiable. The use of concrete examples and data from the paper itself strengthens the argument, allowing the authors to understand and address the critique effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment addresses a potential issue with the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from various experiments, such as Figure 3 (b), where larger models like LucaOne and BSM-270M outperform smaller models like BSM-110M. This feedback is clear and actionable, as it challenges the authors to reconsider their claim and potentially revise their conclusions. By pointing out specific examples and providing a logical reasoning, the comment offers valuable insights that can help the authors improve the accuracy and validity of their findings. However, it could be more helpful if it suggested ways to address this issue or provided additional context. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an inconsistency in the notation, specifically mentioning the use of \"nu\" and its inconsistency across Figures 2 & 3, Algorithm 1, and Page 4 & Figure 4. This feedback is explicit and provides clear guidance on where the inconsistency occurs, allowing the authors to identify and address the issue directly. The comment is specific and actionable, as it gives the authors a concrete step to take to improve the clarity and consistency of their notation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, including Figures 2 & 3, Algorithm 1, and Page 4 & Figure 4, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue of inconsistent notation, particularly with the use of \"nu,\" and provides examples of where the inconsistency occurs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, specifically mentioning the use of \"nu\" and its inconsistency across Figures 2 & 3, Algorithm 1, and Page 4 & Figure 4. This claim is somewhat verifiable as it identifies specific instances where the notation changes, providing some evidence of inconsistency. However, the comment lacks detailed examples or explanations of how these inconsistencies affect the understanding of the paper, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the consistency of notation in the paper, particularly regarding the use of \"nu.\" It points out inconsistencies across Figures 2 & 3, Algorithm 1, and Page 4 & Figure 4, which is a clear and actionable piece of feedback. By highlighting these inconsistencies, the comment provides the authors with a precise area to address, which can significantly improve the clarity and readability of their manuscript. However, the comment could be more helpful if it offered suggestions on how to resolve the inconsistencies or provided examples of how to maintain consistent notation throughout the paper. Despite this, the feedback is mostly helpful as it directs the authors to a critical aspect of their draft that needs attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should conduct more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. This provides a clear and direct action for the authors to take, along with a specific example of a task to explore. The comment is concrete, as it specifies exactly what additional experiments should be conducted to validate the effectiveness of the proposed method. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting a particular task for experimentation, but it lacks grounding as it does not pinpoint a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. While the suggestion is logical and provides a specific example, it lacks detailed reasoning or evidence to support why these experiments would be beneficial or necessary. The reference to Adroit provides some context, but without further elaboration or justification, the claim remains somewhat verifiable. The authors would need to infer the full rationale behind the suggestion, making it somewhat challenging to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. This feedback is clear and actionable, providing a specific direction for the authors to enhance the validation of their proposed method. By recommending a particular task and referencing a relevant study, the comment offers concrete guidance that can help the authors expand their experimental scope and strengthen their work. However, the comment could be more helpful if it included additional details or suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the summary of certain papers in the introduction, specifically noting that some papers assume linearly separable data. It questions whether the statement about \"the feature direction of each arbitrary training sample could act as a perfect linear classifier\" refers to orthogonally separable data. While the comment identifies a specific issue with the summary, it does not provide explicit guidance on how to address it or suggest any specific actions for the authors to take. The authors are left to infer that they need to clarify or revise the summary, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and the summary of specific papers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the summary is not fair, as some papers assume linearly separable data, and it questions the strength of the assumption made in the summary. The comment further asks whether the statement about \"the feature direction of each arbitrary training sample could act as a perfect linear classifier\" refers to orthogonally separable data, providing a specific aspect of the summary that needs clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary in the introduction, specifically regarding the assumption of linearly separable data in some papers. It challenges the strength of the assumption made in the summary and asks whether it refers to orthogonally separable data. While the comment raises a valid point about the assumptions made in the summary, it lacks specific references or detailed reasoning to fully substantiate the claim. The mention of orthogonally separable data provides some context, but the comment could be strengthened with more explicit examples or references to the original works. Therefore, the claim is somewhat verifiable, as it requires additional information for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the summary of certain papers in the introduction, specifically noting that some papers assume linearly separable data. It questions the strength of the assumption made in the summary and asks whether it refers to orthogonally separable data. This feedback is somewhat helpful as it points out a possible inaccuracy or misrepresentation in the summary, prompting the authors to review and potentially revise their description. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to clarify the assumptions. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the validity of the influence function when the upweight is not close to zero, which could affect the reliability of the weights produced. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their method. The comment highlights a potential problem but lacks actionable steps or concrete details on how to resolve it. As a result, the authors are left without a clear understanding of what changes, if any, are needed to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific method in the paper, namely the per-sample weight tuning method that relies on the influence function. It provides a detailed explanation of the limitations of the influence function when the upweight is not close to zero, which affects the validity of the theoretical approximation. However, the comment does not explicitly mention which section or part of the paper discusses this method, making it weakly grounded. The comment is specific in detailing the issue with the influence function and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the validity of the influence function when the upweight is not close to zero, which affects the reliability of the weights produced. The comment provides a logical explanation based on the theoretical approximation of the influence function using Taylor\\'s first-order expansion. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. It explains that the theoretical approximation of each sample\\'s contribution is valid only when the upweight is close to zero. If the weights are far from zero during training iterations, the influence function might not accurately reflect each sample\\'s influence, potentially leading to unreliable weights. This feedback is valuable as it highlights a critical aspect of the method that could affect its reliability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it points out a significant concern, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of centering as a canonicalization method for partial shapes or scenes, suggesting that the authors should address this issue. It also mentions that the experiment with up to 50% missing points is merely an augmentation with the ground-truth center provided, which may not be the case in general. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should explore the applicability of centering in partial shapes and scenes and consider the implications of training with partial shapes. The action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of centering in partial shapes and scenes, suggesting that it may not be well-defined for these contexts. It also mentions an experiment with up to 50% missing points, but notes that this is merely an augmentation with the ground-truth center provided. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the potential problem with centering in partial shapes and scenes, but without clear grounding, it is challenging for the authors to pinpoint where to address these concerns. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of centering as a canonicalization method for partial shapes or scenes, suggesting that it may not be well-defined in these contexts. The reviewer provides a logical reasoning by explaining that while centering can be effective for complete shapes, it may not be suitable for partial shapes or scenes. Additionally, the reviewer mentions an experiment with up to 50% missing points, suggesting that this is merely an augmentation with the ground-truth center provided, which may not be the case in general. This reasoning is somewhat verifiable as it provides a logical basis for the claim, but it lacks specific examples or references to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the applicability of centering as a canonicalization method for partial shapes or scenes. It suggests that the authors should address this concern, which is a clear and actionable piece of feedback. Additionally, the comment provides a specific example of an experiment with up to 50% missing points, noting that this is merely an augmentation with the ground-truth center provided, which may not be the case in general. This additional insight is valuable for the authors to consider when designing their experiments. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of alternative methods. Overall, the feedback is mostly helpful as it highlights a critical area for improvement and provides some context, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an experiment to test the effectiveness of the proposed negative augmentations by ensembling models trained with and without them. This is an explicit suggestion, as it provides a clear action for the authors to take. However, it lacks concrete details on how to implement this suggestion, such as specific parameters or methodologies to use. While the action is explicit, the lack of detailed guidance makes it somewhat actionable, as the authors know what to do but may need to determine the specifics on their own.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method of learning less about texture semantics by adding negative samples that share texture semantics with anchor images. It also references a specific study ([1]) that could be relevant for comparison. This allows the authors to accurately identify the part of the paper being addressed. The comment is specific as it suggests an experiment to ensemble models trained with and without the proposed negative augmentations to see if it improves performance. This provides clear guidance on what the authors could do to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method of learning less about texture semantics by adding negative samples might not be effective in all cases. It references a similar study ([1]) and suggests an experiment to ensemble models trained with and without the proposed negative augmentations to assess performance. This provides a logical reasoning and a specific suggestion for further exploration, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific critique of the paper\\'s approach to learning less about texture semantics by adding negative samples. It acknowledges that texture semantics can still be beneficial in some cases and suggests an experiment to ensemble models trained with and without the proposed negative augmentations to assess performance. This feedback is clear and actionable, offering a concrete suggestion for further exploration that could enhance the paper\\'s contribution. However, it could be more helpful if it included additional details or examples of how to implement this suggestion. Overall, the comment is mostly helpful as it provides a valuable direction for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the guarantee of D_i sufficiently covering all possible transition probabilities, referencing page 6. It also mentions a claim about the sample efficiency of Eq. 7 over Eq. on page 5 and in Appendix B. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question about transition probabilities or clarify the sample efficiency claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, such as a specific section, equation, or figure. It raises a question about the guarantee of D_i sufficiently covering all possible transition probabilities, but it does not provide enough context or detail to allow the authors to identify the exact part of the paper being referred to. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of questions and observations about the methodology and claims made in the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. The questions seek clarification and understanding, while the observations are factual and descriptive. Therefore, the review point is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the guarantee of D_i sufficiently covering all possible transition probabilities, which is a relevant concern for the methodology described in the paper. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or improve their methodology. Additionally, the comment mentions a claim about the sample efficiency of Eq. 7 over Eq. without providing further context or explanation. This lack of clarity and actionable feedback makes the comment barely helpful, as it identifies potential issues but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the method used to form clusters for tokens in Figure 1, specifically noting that this is unclear in Section 3. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or suggestions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the clustering process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the method used to form clusters for tokens, which is unclear in Section 3. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the method used to form clusters for tokens in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the method used to form clusters for tokens in Figure 1, which is unclear in Section 3. This feedback is somewhat helpful as it points out a potential gap in the explanation that the authors need to address. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might clarify this aspect of their work. To be more helpful, the comment could include specific questions or examples that the authors should address to improve the clarity of their explanation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, limiting its applicability to large language models in real-world settings. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or mitigate the complexity. There is no guidance on potential solutions, such as automating the hyperparameter adjustment process or providing recommendations for optimal settings. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with SimNPO, namely the introduction of two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, limiting the method\\'s applicability to large language models in real-world settings. However, the comment does not specify which part of the paper discusses these hyperparameters or where the authors should address this issue, making it weakly grounded. The comment is specific in detailing the problem with the hyperparameters but lacks grounding in terms of identifying the exact section or context in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that require manual adjustment, leading to increased complexity and time cost in experiments. This limitation is said to restrict the method\\'s applicability to large language models in real-world settings. The claim is somewhat verifiable as it provides a logical reasoning for the potential issue with the method\\'s scalability and applicability. However, it lacks specific examples or references to support the claim fully, such as detailed comparisons with other methods or studies that highlight similar challenges. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of SimNPO, specifically the introduction of two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, which could be a major barrier to its application in real-world settings, particularly with large language models. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this limitation, such as proposing alternative methods for hyperparameter tuning or discussing potential workarounds. The feedback is somewhat helpful as it points out a significant weakness, but it lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the emphasis on affordance prompting and suggests that it is overengineered, specifically mentioning the Pick&place example as lacking in demonstrating the advantages of affordance prompting. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve the demonstration of affordance prompting. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the emphasis on affordance prompting and suggests that it is overengineered, using the Pick&place example as a specific instance. However, it does not explicitly mention which part of the paper discusses this example, making it weakly grounded. The comment is specific in its critique of the affordance prompting and the Pick&place example, providing clear guidance on what aspect of the work is being questioned. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is overengineered, and provides an example of the Pick&place example not demonstrating the advantages of affordance prompting. However, the comment lacks specific details or evidence to support the claim that the prompting is overengineered or how the Pick&place example fails to demonstrate the advantages. Without concrete examples or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it places too much emphasis on affordance prompting, which is considered overengineered. It provides a concrete example, such as the Pick&place example, to illustrate the point that the advantages of affordance prompting are not adequately demonstrated. This feedback is somewhat helpful as it highlights a potential weakness in the paper and suggests a specific area for improvement. However, it lacks detailed guidance or suggestions on how the authors might address this issue or demonstrate the advantages of affordance prompting more effectively. To be more helpful, the comment could include recommendations or examples of how to better illustrate the benefits of affordance prompting. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This is a clear and direct action for the authors to take, as it specifies exactly what kind of analysis is required to strengthen the paper. The comment provides concrete guidance on how to improve the draft by conducting ablation studies, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting ablation studies to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not specify which parts of the paper or the methodology need these studies, making it difficult for the authors to pinpoint the exact areas that require attention. While the authors might have an idea of where ablation studies could be relevant, the comment lacks full grounding. It is specific in suggesting the need for ablation studies but does not provide detailed guidance on which parts should be tested. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation studies are necessary to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, the comment does not provide specific reasoning or examples to support why ablation studies are crucial or how they would improve the paper. Without detailed justification or examples, the claim is not fully substantiated, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests conducting ablation studies to demonstrate the necessity of each part of the proposed algorithmic pipeline. This feedback is clear and actionable, as it provides a specific method for the authors to strengthen their paper by verifying the importance of each component. However, the comment could be more helpful if it included examples of how to conduct these ablation studies or suggested which parts of the pipeline might be most critical to test. Despite this, the comment still offers valuable guidance for improving the draft, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the necessity of the instruction-tuning stage in MoE models, questioning whether the performance improvement could be attributed to the additional training cost rather than the instruction-tuning stage itself. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or demonstrate the necessity of the instruction-tuning stage. The comment implies that the authors should provide a more convincing demonstration of the stage\\'s necessity, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the necessity of the instruction-tuning stage in MoE models, questioning whether the performance improvement could be attributed to the additional training cost rather than the instruction-tuning stage itself. However, it does not specify which part of the paper discusses the instruction-tuning stage, making it weakly grounded. The comment is specific in its critique, as it questions the necessity of the instruction-tuning stage and suggests an alternative explanation for the performance improvement. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the instruction-tuning stage in MoE models, suggesting that the performance improvement could be attributed to additional training costs rather than the instruction-tuning stage itself. The comment provides a logical reasoning by pointing out the potential trade-off between training costs and performance gains. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the reasoning themselves to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the necessity of the instruction-tuning stage in MoE models, questioning whether the performance improvement could be attributed to additional training costs rather than the instruction-tuning stage itself. This is a relevant point that could impact the interpretation of the results and the overall conclusion of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or provide a more convincing demonstration of the instruction-tuning stage\\'s necessity. While it identifies a potential issue, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies an issue with the evaluation setup, noting that it is outdated due to the release of newer models and the advancement of existing models. It suggests testing the approach on more challenging and representative fine-tuning setups, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback provides a clear and explicit action for the authors to update their evaluation setup to reflect current advancements in the field. The suggestion is concrete, as it specifies the types of datasets to consider for testing. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the evaluation setup, specifically mentioning the outdated nature of the models used (Llama-1 and Mistral-v0.1) and suggesting testing on more recent models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. It also recommends testing on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or results section. The suggestion is specific, as it provides clear guidance on how to update the evaluation setup. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated due to the release of newer models and advancements in existing models. It provides specific examples of newer models, such as Llama-3, Llama-3.1, Qwen-2.5, and gemma-2, which have improved significantly since the evaluation was conducted. Additionally, it suggests testing the approach on more challenging and representative fine-tuning setups, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies that highlight the advancements in these models. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation setup, noting that it is outdated due to the release of newer models and advancements in existing models. It suggests testing the approach on more challenging and representative fine-tuning setups, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets, to fully appreciate the efficacy of SparseMeZO. This feedback is clear and actionable, providing the authors with a specific direction to update their evaluation to reflect current advancements in the field. By suggesting a more relevant and challenging evaluation setup, the comment offers valuable guidance for improving the draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second section presents many related works but lacks logical coherence, resulting in disorganized content. However, it does not provide specific guidance on how to improve the logical coherence or suggest ways to organize the content more effectively. The feedback is vague and lacks explicit instructions, leaving the authors uncertain about how to address the issue. Since the comment is implicit and lacks concrete details, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions the \"second section\" and notes that while many related works are presented, there is a lack of logical coherence, resulting in disorganized content. This provides some grounding as it allows the authors to identify the general area of the paper being addressed. However, it lacks specificity regarding which aspects of the logical coherence are problematic or how the content could be better organized. Without specific details, the authors may struggle to determine exactly what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the second section lacks logical coherence, resulting in disorganized content. However, it does not provide specific examples or detailed reasoning to support this claim. The comment is vague and lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the second section of the paper, noting that while many related works are presented, there is a lack of logical coherence, resulting in disorganized content. This feedback is somewhat helpful as it points out a structural weakness in the paper, prompting the authors to reconsider the organization and coherence of their content. However, the comment lacks detailed guidance or suggestions on how to improve the logical coherence or reorganize the content, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention the language they focus on when retrieving Reddit posts. This is a clear and direct action, leaving no ambiguity about what the authors need to do to improve their draft. The comment is specific and provides a concrete step for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment requests the authors to mention the language they focus on when retrieving Reddit posts. However, it does not specify where in the paper this information should be included, making it weakly grounded. The comment is specific in its request for the authors to provide this information, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification regarding the language used in the study. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on the language used in the study, specifically asking the authors to mention the language they focus on when retrieving Reddit posts. While this is a straightforward request for additional information, it does not provide any context or reasoning behind why this information is important or how it might impact the study. The comment lacks depth and does not offer actionable feedback or suggestions for improvement. As a result, it is barely helpful, as it points out a potential gap but does not guide the authors on how to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of comparisons with recent works, specifically mentioning [1]. However, it does not provide explicit guidance on which recent works should be included or how these comparisons should be conducted. The action is implicit, as the authors can infer that they need to add comparisons, but it remains vague because it lacks specific details on which works to compare or how to structure the comparisons. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of comparisons with recent works, specifically mentioning \"[1].\" However, it does not specify which part of the paper this omission pertains to, such as the literature review or results section. This makes it difficult for the authors to pinpoint the exact location that needs revision. Additionally, the comment lacks specificity regarding which recent works should be included or how they should be integrated into the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning \"[1].\" However, it does not provide any further details or examples of the recent works that should be included for comparison. Without specific references or detailed reasoning, the claim is not verifiable. The authors may struggle to understand which recent works are relevant or how to incorporate them into their paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the lack of comparisons with recent works. This is a relevant point that could enhance the paper\\'s contribution by situating it within the current literature. However, the comment does not provide any guidance on which recent works should be considered or how these comparisons should be conducted. Without specific suggestions or examples, the authors are left with a general idea of what needs to be improved but without actionable steps to take. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether TSG (Timestep-Specific Guidance) will work in diffusion models that do not embed class labels into timesteps, such as UViT. While the question implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide guidance on how to address it. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of TSG (Timestep-Specific Guidance) in diffusion models that do not embed class labels into timesteps, such as UViT. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the compatibility of TSG with a particular type of diffusion model, but without clear grounding, the authors may struggle to identify where this question should be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the applicability of TSG in diffusion models that do not embed class labels into timesteps. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG (Timestep-Specific Guidance) in diffusion models that do not embed class labels into timesteps, such as UViT. While this question highlights a potential limitation or consideration for the authors, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address this issue or explore its implications. As a result, the comment is barely helpful, as it points out a potential area of interest but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to release their training code, dialogue dataset, and model checkpoints to enhance reproducibility. It also suggests attaching these resources via anonymous repositories in the paper submission. This feedback provides a clear and concrete action for the authors to take, ensuring that reviewers can verify the claims and try out the model. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of reproducibility, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. It suggests attaching these resources via anonymous repositories in the paper submission. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these resources would be relevant. The comment is specific in detailing what needs to be addressed to improve reproducibility. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks reproducibility due to the absence of training code, dialogue dataset, and model checkpoints. The reviewer suggests that these resources should be made available to facilitate verification of claims and experimentation with the model. While the comment logically highlights the importance of reproducibility, it does not provide specific examples or references to support the claim that the current lack of resources hinders reproducibility. This makes the claim somewhat verifiable, as it requires additional evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s reproducibility, noting that without access to the training code, dialogue dataset, and model checkpoints, it is challenging to verify the claims made in the paper. The reviewer provides a clear and actionable suggestion by encouraging the authors to attach these resources via anonymous repositories in the paper submission. This feedback is highly helpful as it directly addresses a critical aspect of the paper\\'s evaluation and provides a concrete step for the authors to improve the transparency and verifiability of their work. By following this advice, the authors can significantly enhance the reproducibility and credibility of their research.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the main result is \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on potential modifications, alternative approaches, or additional analysis that could be conducted to enhance the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main result of the paper, stating that it is \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the result are considered obvious or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result is \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this observation is considered obvious. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the main result of the paper is considered \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, it does not provide any constructive feedback or suggestions on how the authors might address this perceived lack of novelty or significance. Without actionable advice or specific guidance, the comment does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment criticizes the paper for having an insufficient contribution that is not explicitly expressed and for being incomplete. It points out that the details provided do not adequately explain the specifics of the proposed model and that there is limited related work mentioned and no appropriate analysis. However, the comment does not provide specific guidance on how the authors can address these issues or improve the clarity and completeness of their work. The feedback lacks actionable steps or suggestions, leaving the authors uncertain about how to enhance their draft. Since the comment is vague and does not offer a clear path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for having an insufficient contribution that is not explicitly expressed and for being incomplete. It points out that the details provided do not adequately explain the specifics of the proposed model and that there is limited related work mentioned and no appropriate analysis. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these issues could be present, the comment lacks full grounding. It is specific about the issues but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the work is insufficient and not explicitly expressed, describing the paper as incomplete. It further critiques the lack of detailed explanation of the proposed model and limited related work mentioned, as well as the absence of appropriate analysis. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence renders the claim unverifiable, as it does not provide a clear path for the authors to address the concerns raised. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, including an insufficient contribution that is not explicitly expressed, an incomplete presentation of details, limited related work, and a lack of appropriate analysis. While it highlights significant weaknesses, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their draft. Without actionable feedback or detailed advice, the authors are left with a general sense of what needs improvement but without a clear path to enhance their work. Therefore, the comment is somewhat helpful, as it points out important areas for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the presentation of results, specifically regarding the x-axis labels in Figures 2a and 2b. It suggests that Figure 2a should be given with iterations or training steps as the x-axis, and it questions what the training steps refer to in Figure 2b. While the comment provides explicit actions for the authors to take\u2014clarifying the x-axis labels and potentially adding iterations or training steps\u2014it does not provide detailed guidance on how to implement these changes. The actions are clear but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity in the x-axis labels and the need for iterations or training steps to be included in Figure 2a. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the results presented in Figures 2a and 2b, specifically questioning the labeling of the x-axis as \"item\" in Figure 2b and suggesting that it should be labeled as \"iterations\" or \"training steps.\" The comment provides a logical reasoning for the suggestion, as it aims to improve the clarity and understanding of the results. However, it lacks specific examples or references to similar practices in the field, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed justification or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Figures 2a and 2b, noting that the x-axis is labeled as \"item\" in Figure 2b, which is unclear. It suggests that the x-axis should be labeled as \"iterations\" or \"training steps\" to provide clarity. Additionally, the comment points out that Figure 2a should also be given with iterations or training steps as the x-axis. This feedback is clear and actionable, as it directly addresses a specific area for improvement in the presentation of results. By following this suggestion, the authors can enhance the clarity and comprehensibility of their figures, which is valuable for improving the draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the choice of cost metrics for different devices, suggesting that the same cost metric could be used instead of flops, latency, and 1/FPS. While the comment implies that the authors should reconsider their cost metrics, it does not provide explicit guidance on how to implement this change or what specific metric should be used. The action is implicit and somewhat vague, as the authors need to infer the need for a change and determine the appropriate metric themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of cost metrics for different devices, suggesting that the same metric could be used instead of flops, latency, and 1/FPS. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion where these metrics are used. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the choice of metrics but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the choice of cost metrics for different devices. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of cost metrics for different devices, suggesting that the same metric could be used instead of flops, latency, and 1/FPS. This feedback is somewhat helpful as it prompts the authors to reconsider their approach to evaluating costs across different hardware. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this change or why it might be beneficial. While it encourages the authors to think critically about their methodology, it does not offer actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of the two-dimensional Wasserstein distance and the Sinkhorn algorithm in the paper. It specifically asks for the maximum number of iterations set in the experiments and whether these iterations significantly slow down the training speed. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks concrete guidance on how to address the issue. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"two-dimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a clear question about the maximum iterations set in the experiments and whether these iterations significantly slow down the training speed. This provides the authors with a clear direction on what needs to be addressed or clarified in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of the two-dimensional Wasserstein distance and the Sinkhorn algorithm, specifically asking for the maximum number of iterations set in the experiments and whether these iterations significantly slow down the training speed. While the comment highlights a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the iterations might slow down the training speed. This lack of justification makes the claim borderline verifiable, as it requires further evidence or explanation to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of the two-dimensional Wasserstein distance and the Sinkhorn algorithm in the paper. It specifically asks for the maximum number of iterations set in the experiments and whether these iterations significantly slow down the training speed. This feedback is clear and actionable, as it prompts the authors to provide specific details about their experimental setup, which could help address concerns about the efficiency of their method. However, the comment could be more helpful if it offered suggestions on how to optimize the iterations or improve the training speed. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their methodology that requires clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major weakness in the paper regarding the soundness of the teacher policy. It points out that the teacher policy is trained to maximize distribution matching, but it is unclear whether the student policy can still perform correct distribution matching. The reviewer suggests that theoretical results would be beneficial to address this concern. While the comment implies that the authors should provide theoretical results, it does not explicitly instruct them to do so. The action is somewhat clear but lacks concrete guidance on how to achieve the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a major weakness in the paper regarding the soundness of the teacher policy. It provides a detailed explanation of the issue, specifically questioning whether the student policy can still perform correct distribution matching. The comment suggests that theoretical results would be beneficial to address this concern. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue and suggesting a potential improvement, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s major weakness lies in its soundness, specifically regarding the teacher policy\\'s ability to ensure correct distribution matching. The reviewer provides a detailed explanation of the method used, which involves training the teacher policy to maximize distribution matching and using its output probability as a reward for the student policy. However, the comment lacks specific references or examples to support the claim that the method is not theoretically sound. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. The authors would need to further explore the theoretical aspects themselves to address the critique fully.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper regarding the soundness of the teacher policy. It highlights a concern about whether the student policy can still perform correct distribution matching, given that the teacher policy is trained to maximize distribution matching. The reviewer suggests that the method appears more like a heuristic rather than a theoretically sound approach. This feedback is valuable as it points out a critical area that needs clarification or theoretical justification. However, the comment could be more helpful by providing specific suggestions or examples of how the authors might address this issue. While it offers a clear direction for improvement, it lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should analyze and discuss the reasons why the proposed method does not perform well in some classes, as indicated in Table 3. While the comment implies a clear action\u2014conducting an analysis and discussion\u2014it does not provide specific guidance on how to perform this analysis or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to analyze and discuss the performance issues but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the analysis and discussion of why the proposed method does not perform well in some classes. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not perform well in some classes and suggests that reasons should be analyzed and discussed. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand which classes are underperforming or why. This makes the claim borderline verifiable, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in Table 3, noting that it does not perform well in some classes. It suggests that the authors should analyze and discuss the reasons behind this underperformance. While the comment highlights an important area for improvement, it lacks depth and does not provide specific guidance or suggestions on how the authors might conduct this analysis or what factors to consider. The feedback is somewhat helpful as it points out a potential weakness and encourages further exploration, but it could be more beneficial with additional direction or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of rigor in the experimental settings, specifically mentioning that MTT should test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. While the comment implies that the authors should address these issues, it does not provide specific guidance on how to improve the experimental design or what aspects of the results should be discussed. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the experimental rigor and discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental settings, specifically mentioning that MTT should test on unseen tasks and that the experimental results could be further discussed or explained. However, it does not specify which part of the paper these issues pertain to, such as a particular section or experiment. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting that the experimental settings need improvement and that the results should be further discussed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some experimental settings are not rigorously designed\" and suggests that MTT should test on unseen tasks. It also mentions that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that they are not rigorously designed. It provides a concrete example by suggesting that MTT should test on unseen tasks, which is a clear and actionable suggestion for improvement. Additionally, the comment suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. This feedback is clear and actionable, offering the authors a direct path to enhance the rigor and comprehensiveness of their experimental design and analysis. However, it could be more helpful if it included specific guidance on how to conduct these additional analyses or discussions. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their experimental section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify or address the potential learning effects, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the potential learning effects and the need for clarification on the data collection process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed explanation or examples that would help the authors understand the issue or address it. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification for the authors to act upon. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. This is a relevant point that could impact the validity of the results, as learning effects could influence the outcomes. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a randomized data collection process or discussing the implications of the current order. While it identifies a potential weakness, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of considering node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their draft. The comment lacks actionable guidance, such as recommending alternative approaches or providing specific steps for the authors to take. As a result, the authors are left without a clear understanding of what changes, if any, are needed to address the reviewer\\'s concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, \"In order to cover the random ordering of the atoms in a specific point in the composition space,\" allowing the authors to accurately identify the section being addressed. However, the comment lacks specificity as it does not provide details on why node ordering should not play a role or how it could be addressed. Without specific guidance or suggestions for improvement, the authors may struggle to understand the exact issue or how to resolve it. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the necessity of considering node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, the comment does not provide any supporting evidence, reasoning, or references to justify why node ordering should not be relevant. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the necessity of considering node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any explanation or reasoning as to why node ordering might not be relevant or how it could be addressed. Without specific suggestions or examples, the authors are left without actionable feedback to improve their draft. The lack of clarity and guidance makes the comment unhelpful, as it does not assist the authors in understanding or addressing the issue raised. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous work [5], which presents a dexterous manipulation benchmark with musculoskeletal hands, and suggests that it detracts from the novelty of the current work. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the issue of novelty and provides references to other works that may be relevant. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. The reviewer supports this claim by providing references to other works ([1-5]) that are similar or related to the current work. This provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or explanations of how these works differ from the current work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the current work, noting that a previous study ([5]) presents a similar dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. Without actionable feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights a potential issue but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the selection of datasets should be made more clear, including the pool of datasets considered and the selection process. It provides specific examples of datasets and references to works that could guide the authors in making their selection process more transparent. Additionally, the comment points out the lack of detail in the selection of the splitting procedure and split ratios, suggesting that these aspects should also be clarified. The feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection of datasets as a main contribution, allowing the authors to identify the part of the paper being addressed. It also specifies the issues that need to be addressed, such as the selection process, the pool of datasets considered, and the selection of splitting procedures and split ratios. The comment provides specific examples of datasets and references to works that could guide the authors, making it clear and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of datasets is a main contribution and suggests that the selection process should be made more clear. The reviewer provides examples of datasets, such as OpenML100 and OpenML CC-18, and references Bischl et al. and Gijsbers et al. as examples of works that detail the selection process. This provides a clear and specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current selection process is lacking. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the selection of datasets, which is identified as a main contribution of the paper. It suggests that the selection process should be made more clear, including details on the pool of datasets considered and the criteria for selection. The comment references specific datasets and references to works that could guide the authors in making their selection process more transparent. Additionally, it points out the lack of detail in the selection of the splitting procedure and split ratios, which are also identified as areas needing improvement. This feedback is detailed and constructive, offering the authors clear directions for enhancing the clarity and rigor of their work. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a gap in the ablation study, specifically the lack of a critical comparison involving an unconditional diffusion model refined using efficient architectural changes, followed by either consistency distillation or progressive distillation. The reviewer suggests that comparing the proposed method to these conventional baselines under the same computational constraints would be valuable. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what additional comparisons should be included in the ablation study. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the ablation study, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what is missing in the ablation study, namely the inclusion of a baseline where an unconditional diffusion model is first refined using efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment further explains the importance of this comparison and why it would be valuable. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison, specifically the inclusion of a baseline where an unconditional diffusion model is refined using efficient architectural changes, followed by either consistency distillation or progressive distillation. The reviewer suggests that this comparison would be valuable to determine if the proposed method outperforms conventional baselines under the same computational constraints. While the comment provides a logical reasoning for the necessity of this comparison, it lacks specific examples or references to support the claim. The suggestion is based on a logical argument but requires more detailed evidence or examples to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a reasonable suggestion but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the ablation study, specifically the lack of a comparison with a baseline where an unconditional diffusion model is refined using efficient architectural changes, followed by either consistency distillation or progressive distillation. It suggests that such a comparison would be valuable to determine if the proposed method outperforms conventional baselines under the same computational constraints. This feedback is clear and actionable, providing the authors with a specific direction for improving their study by including a relevant benchmark. However, the comment could be more helpful if it offered additional guidance on how to implement this comparison or discussed potential challenges in doing so. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks in the paper are based on grasping and are too homogeneous in terms of difficulty. It implies that the authors should consider designing more diverse tasks, possibly by referring to specific projects mentioned in the comment. While the suggestion to refer to other projects is explicit, the comment does not provide concrete guidance on how to design these additional tasks or what specific aspects should be considered. The action is explicit but somewhat vague, as the authors know they need to diversify the tasks but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are based on grasping and are too homogeneous in terms of difficulty. It implies that the authors should consider designing more diverse tasks, possibly by referring to specific projects mentioned in the comment. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on how the tasks could be diversified or what specific aspects are lacking. Without explicit references to sections, figures, or specific tasks, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the tasks in the paper are based on grasping and are too homogeneous in terms of difficulty. The reviewer suggests that the authors should consider designing more diverse tasks by referring to specific projects, such as those mentioned in the comment. However, the comment lacks specific examples or detailed reasoning to support the claim that the tasks are too homogeneous. Without explicit references or detailed justification, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary evidence or examples to fully substantiate the critique. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, noting that all the tasks are based on grasping and are too homogeneous in terms of difficulty. It suggests that the authors consider designing more diverse tasks by referencing specific projects, such as those mentioned in the comment. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for expanding the scope of the paper. However, the comment could be more helpful if it offered more detailed guidance on how to design these additional tasks or why the current tasks are too homogeneous. Overall, the comment provides some insight but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the comparison in Table 2, suggesting that the LEPA\\'s training data may be larger than the \"Without Plan/Without Self-Reflection\" settings. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to ensure fairness in the comparison. The comment implies that the authors should consider aligning the settings with lines 349-360, but it lacks concrete instructions on how to achieve this alignment or what specific changes are needed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"lines 349-360,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the comparison in Table 2 may be unfair due to the potential difference in training data size between LEPA and the \"Without Plan/Without Self-Reflection\" settings. The comment further supports this claim by referencing an external work, \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPEN-SOURCE LLMS,\" which could provide additional context or justification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair due to potential differences in training data size between LEPA and the \"Without Plan/Without Self-Reflection\" settings. The reviewer supports this claim by referencing lines 349-360, suggesting that the settings are aligned with these lines. However, the comment does not provide specific details or evidence from Table 2 to substantiate the claim about the training data size. While the reference to an external work, \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPEN-SOURCE LLMS,\" could provide additional context, the lack of explicit evidence or detailed reasoning in the review point makes it somewhat verifiable. The authors would need to further investigate the claim themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison in Table 2, suggesting that the LEPA\\'s training data may be larger than the \"Without Plan/Without Self-Reflection\" settings. This is a relevant observation that could impact the validity of the results presented in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or ensure fairness in the comparison. While it points out a potential problem, it does not provide actionable feedback or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results from real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. While the comment implies that the authors should expand their experiments to include these datasets, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on how to implement these changes or what aspects of the results should be focused on. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without detailed instructions on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of synthetic datasets in the experiments and suggests using real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. However, it does not specify which part of the paper discusses the datasets used, making it weakly grounded. The comment is specific in suggesting the use of particular datasets and tasks, providing clear guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of synthetic datasets in the experiments and suggests using real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. While the comment raises a valid concern about the generalizability of the results, it lacks specific examples or references to support the claim that using real datasets would be beneficial. The suggestion is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the authors have only used synthetic datasets and have not shown results with real datasets. It suggests using datasets from the GLUE benchmark, specifically mentioning the QQP task, and also recommends showing results on real-world diversity datasets. This feedback is clear and actionable, providing specific examples of datasets that could be used to enhance the generalizability and applicability of the results. By suggesting these additional datasets, the comment offers a concrete direction for the authors to improve their work. However, it could be more helpful if it included additional guidance on how to integrate these datasets into the existing framework or discussed potential challenges in doing so. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their experimental setup.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper, indicating that this information is currently lacking. The action is clear and direct, providing the authors with a specific task to address. However, the comment does not provide guidance on what specific details should be included or how to present them, which makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, indicating that this information is currently lacking. However, it does not specify which part of the paper should include these details, making it weakly grounded. The comment is specific in identifying what needs to be addressed\u2014adding details on optimization\u2014but lacks grounding in terms of where in the paper these details should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks details on how to solve the optimization, which is an important aspect of the work. However, the comment does not provide specific examples or references to support the claim that this information is missing. Without detailed justification or examples, the authors may find it challenging to understand the exact nature of the omission and how to address it. Therefore, the claim is considered borderline verifiable, as it provides a general suggestion but lacks sufficient evidence or reasoning to fully substantiate the need for additional details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of details on how to solve the optimization in the main paper. This is an important aspect that could enhance the clarity and comprehensiveness of the paper. However, the comment does not provide specific suggestions or guidance on what details should be included or how to present them, which limits its helpfulness. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully beneficial. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions why certain models, such as LLaVA-series and Qwen-VL, are not included in the evaluation, noting that they are commonly adopted LVLMs. The comment explicitly suggests including these models to provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and provides a direct action for the authors to take, which is to include these models in their evaluation. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment questions the absence of LLaVA-series and Qwen-VL in the evaluation, suggesting that including these models would provide a more comprehensive comparison. However, it does not specify which part of the paper should include this evaluation, making it weakly grounded. The comment is specific in its request for inclusion of these models, providing clear guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the absence of LLaVA-series and Qwen-VL in the evaluation, suggesting that including these models would provide a more comprehensive comparison. The claim is somewhat verifiable as it references commonly adopted LVLMs, implying that their inclusion would enhance the study. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, such as why these models are particularly relevant or how they would impact the study. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the evaluation by questioning the absence of LLaVA-series and Qwen-VL, which are commonly adopted LVLMs. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it directly points out a specific area for improvement and offers a concrete suggestion for enhancing the study. By addressing this point, the authors could significantly improve the comprehensiveness and robustness of their evaluation. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include some caption/description and OCR heavy datasets. While it explicitly states that these should be included, it does not provide specific guidance on which datasets to consider or how to incorporate them into the paper. The action is explicit but somewhat vague, as the authors know they need to add these elements but may not be entirely sure of the exact details or how to implement them effectively. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including some caption/description and OCR heavy datasets, but it does not specify which part of the paper this addition should be made to. The authors might infer that it relates to the literature review or the datasets section, but this inference is not direct. The comment is specific in suggesting what additional content should be included, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include some caption/description and OCR heavy datasets. However, it does not provide any justification or reasoning for why these additions are necessary or how they would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include some caption/description and OCR heavy datasets. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which datasets to include or how they should be integrated into the paper. The comment is somewhat helpful as it points out a gap in the literature review or dataset section, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and eqn.7, suggesting that the loss of TKD is assumed to be less than IYOR, but eqn.7 tells a different story. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or clarify the issue. The action is implicit, as the authors can infer that they need to resolve the contradiction, but it remains vague because it lacks specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the assumption and the equation, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and eqn.7, suggesting that the loss of TKD is assumed to be less than IYOR, but eqn.7 tells a different story. However, the comment does not provide further explanation or evidence to support this claim, such as specific details from Assumption 3.1 or eqn.7 that contradict each other. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy between Assumption 3.1 and eqn.7, pointing out that the loss of TKD is assumed to be less than IYOR, but eqn.7 tells a different story. This feedback is valuable as it highlights a potential inconsistency in the paper that the authors need to address. However, the comment does not provide further guidance or suggestions on how to resolve this discrepancy or clarify the issue. While it points out an important area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether question 3, which is mentioned in relation to weaknesses 2 and 4, indicates other limitations. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks clarity and does not offer guidance on how the authors should address this issue or what specific changes, if any, are needed. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"question 3\" and \"weakness 2 and 4,\" which are mentioned in the context of the review. However, it does not specify where these questions or weaknesses are located in the paper, making it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment also lacks specificity regarding what needs to be clarified or addressed regarding these questions or weaknesses. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about whether question 3 indicates other limitations. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether question 3, which is mentioned in relation to weaknesses 2 and 4, indicates other limitations. However, it does not provide any context or explanation about what these weaknesses are or how they relate to question 3. The comment lacks specificity and does not offer actionable feedback or suggestions for improvement. Without additional information or guidance, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider using middle layers instead, but it lacks concrete details on how to implement this change or why it would be beneficial. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the classifier is discussed, the comment lacks full grounding. It is specific about the issue of using last-layer hidden states but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, the comment does not provide any references or examples of studies that support the claim about middle layers being more effective. Without specific evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as \"1: Unverifiable,\" as it does not provide sufficient support for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. This is a relevant point that could impact the performance and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or explore the use of middle layers. While it prompts the authors to reconsider their approach, it does not offer actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the motivation behind using GUE to determine tokenization, model architecture, and training objective for the generative model. It suggests that these decisions may be arbitrary and potentially incongruous, as the representations learned might be optimized for a narrow set of tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their approach. The feedback lacks actionable details, such as recommending alternative methods or providing specific criteria for evaluating the generalizability of the learned representations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation behind using GUE to determine tokenization, model architecture, and training objective for the generative model. It raises concerns about the arbitrariness and potential incongruity of these decisions, suggesting that the representations learned might be optimized for a narrow set of tasks. However, the comment does not specify which part of the paper discusses these decisions, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issues with the motivation and potential limitations but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of GUE to determine tokenization, model architecture, and training objective for the generative model is arbitrary and potentially incongruous. The reviewer supports this claim by suggesting that the representations learned using these modeling decisions may be optimized for a narrow set of tasks, limiting their generalizability. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the absence of detailed evidence or comparisons makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the critique without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the motivation behind using GUE to determine tokenization, model architecture, and training objective for the generative model. It points out that these decisions may be arbitrary and potentially incongruous, which could limit the generalizability of the learned representations. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it highlights an important concern, the feedback does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper has significant grammar and spelling errors and requires a major editing pass. This direct instruction provides a clear action for the authors to take, which is to revise the paper to improve its readability. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper reading \"clunkily\" due to grammar and spelling errors, suggesting the need for a major editing pass. However, it does not specify which sections or parts of the paper are affected by these errors, making it difficult for the authors to pinpoint the exact areas needing attention. While the authors might have an idea of where these errors could be, the comment lacks full grounding. It is specific in identifying the issue of grammar and spelling errors but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper reads \"clunkily\" due to significant grammar and spelling errors, suggesting the need for a major editing pass. However, the comment does not provide specific examples or detailed evidence of these errors, making it difficult for the authors to identify and address the issues effectively. The lack of concrete examples or references to specific sections of the paper renders the claim unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant issue with the paper, noting that it reads \"clunkily\" due to grammar and spelling errors. It suggests that the paper requires a major editing pass to improve its readability. While this feedback highlights a critical area for improvement, it lacks specific examples or guidance on which parts of the paper are particularly problematic or how to address the issues. The comment provides a general direction for improvement but does not offer detailed, actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the oddball objective function used in the regression. While these questions highlight areas of concern, they do not provide explicit actions or suggestions for the authors to address these issues. The authors can infer that they need to clarify these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises several questions about the SITE estimator, specifically questioning its consistency as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also points out that the loss function is only defined over minibatches, leaving the objective function for the regression implicit. The comment is specific in detailing the issues with the estimator and the assumptions, but it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or equations. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and further explanation regarding the SITE estimator and its assumptions. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the SITE estimator, specifically questioning its consistency as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also points out that the loss function is only defined over minibatches, leaving the objective function for the regression implicit. The comment further inquires about the implications of this oddball objective function, if SGD converges, and whether it causes any issues. While the comment identifies critical areas for clarification and improvement, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their work. The feedback is somewhat helpful as it highlights key areas of concern, but it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limitations of OIS (Object-level Interactive Segmentation) in handling interactive segmentation for multiple objects simultaneously. It suggests that the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or improve the method\\'s practical utility. The feedback lacks actionable details, such as recommending ways to mitigate the issue or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the ability of OIS (Object-level Interactive Segmentation) to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation related to the reliance on mask guidance from previous interactions, which could hinder the method\\'s ability to shift focus to a new target object if the target changes between clicks. The comment provides a specific example of a related work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which could help the authors understand the context of the issue. However, the comment does not explicitly mention which part of the paper this concern is related to, such as specific sections or experiments. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the issue and providing a reference, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limitations of OIS (Object-level Interactive Segmentation) in handling interactive segmentation for multiple objects simultaneously. The claim is based on the observation that OIS relies on mask guidance from previous interactions, which could hinder its ability to shift focus to a new target object if the target changes between clicks. The comment references a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which provides a context for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how this limitation affects the method\\'s practical utility. As it stands, the claim is mostly verifiable due to the reference provided, but it lacks comprehensive evidence or detailed explanation. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the OIS (Object-level Interactive Segmentation) method, specifically its ability to handle interactive segmentation for multiple objects simultaneously. It highlights a concern that the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. This feedback is valuable as it points out a specific area where the method\\'s practical utility could be limited. However, the comment could be more helpful by providing suggestions on how the authors might address this limitation or improve the method\\'s flexibility. While it raises an important issue, the lack of actionable guidance limits its usefulness to the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption made by the proposed system regarding the alignment of anomalies with concepts. It questions the realism of this assumption and notes that the knowledge of concepts implies a certain level of domain expertise. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The feedback lacks actionable details, such as recommending ways to validate or refine the assumption or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption made by the proposed system regarding the alignment of anomalies with concepts. It questions the realism of this assumption and notes that the knowledge of concepts implies a certain level of domain expertise. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and its implications, but without clear grounding, the authors may struggle to identify where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the realism of an assumption made by the proposed system regarding the alignment of anomalies with concepts. It provides a logical reasoning by referencing common scenarios where anomaly detection systems are used, such as intrusion and fraud detection, where anomalies are rare and might be attacks. This reasoning is based on common knowledge and practices in the field, making the claim somewhat verifiable. However, the comment could be strengthened by providing specific examples or references to support the assertion about the alignment of anomalies with concepts. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the assumption made by the proposed system regarding the alignment of anomalies with concepts. It highlights a potential limitation in the system\\'s applicability, noting that the assumption may not be realistic in many scenarios where anomalies are rare and might be attacks. The comment also points out that the knowledge of concepts implies a certain level of domain expertise, which could be a barrier for some users. While the comment identifies an important issue, it lacks specific suggestions or guidance on how the authors might address this concern or test the assumption. Providing more detailed feedback or suggestions would make the comment more actionable and helpful for the authors. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a significant limitation but does not fully support them in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to include a discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. This feedback provides a clear and direct action for the authors to take, specifying what needs to be addressed in the paper. The comment is concrete, as it outlines specific areas that require further discussion, ensuring the authors know exactly what changes to make to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the discussion on limitations and tradeoffs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. It suggests that the authors include a discussion on these aspects to help readers better understand the tradeoffs between using HLOP and other approaches. This feedback is clear and actionable, providing the authors with a specific area to address in order to improve the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it offered specific examples or guidance on how to structure this discussion. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the prominence of their contribution. While the comment explicitly states the need for additional evaluation, it does not provide specific guidance on how to conduct this evaluation or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to evaluate these models but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the contribution of the work. However, it does not specify which part of the paper should include this evaluation or where the proposed gating scheme is discussed, making it weakly grounded. The comment is specific in suggesting the inclusion of these models for evaluation, providing clear guidance on what could be added to the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should evaluate the proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the contribution. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which is to include more recent models for a comprehensive evaluation. However, the comment lacks specific examples or references to support why these models are particularly relevant or how their inclusion would significantly impact the paper. Providing more detailed justification or examples would strengthen the claim, making it easier for the authors to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that many more language models have been released since GPT-2, which have not been studied in the work. It specifically mentions FlanT5 and Llama as examples and suggests that evaluating the proposed gating scheme on these models would enhance the contribution of the paper. This feedback is clear and actionable, providing the authors with a concrete direction for expanding their evaluation to include recent language models. By addressing this suggestion, the authors can significantly improve the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct these evaluations or discussed potential challenges. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should cite and compare their work with more recent studies that might be highly correlated. It provides a specific example of a work by Wang et al. that could be relevant for comparison. This feedback gives the authors a clear and concrete action to take, which is to include additional citations and comparisons in their draft. The explicit nature of the suggestion and the specific example provided make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more recent works that might be highly correlated need to be cited and compared against, providing a specific example of a work by Wang et al. This makes the comment specific, as it clearly identifies what needs to be addressed\u2014citing and discussing a particular work in context. However, the comment does not explicitly mention which part of the paper should include this comparison, leaving the authors to infer that it relates to the literature review or discussion sections. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more recent works that might be highly correlated need to be cited and compared against, providing a specific example of a work by Wang et al. This claim is somewhat verifiable as it identifies a potential gap in the literature review and suggests a specific reference for comparison. However, the comment lacks detailed reasoning or evidence on how this particular work is highly correlated or how it should be integrated into the discussion. Providing more context or explanation would strengthen the claim, making it easier for the authors to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should cite and compare their work with more recent studies that might be highly correlated. It provides a concrete example of a relevant work by Wang et al. that could be considered for comparison. This feedback is clear and actionable, as it guides the authors on how to enhance the context and relevance of their work by including additional references and discussions. However, the comment could be more helpful if it provided more detailed guidance on how to integrate these comparisons into the paper or explained why these specific works are relevant. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more detail about how UNKs (unknown words) are handled by the neural decoder or include a citation to the dictionary-based replacement strategy being used. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes. The action is implicit but concrete, as it specifies what additional information or citation should be included. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder or citing the dictionary-based replacement strategy used. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional detail or a citation, but without clear grounding, the authors may struggle to identify where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from additional detail about how UNKs (unknown words) are handled by the neural decoder or by citing the dictionary-based replacement strategy used. However, the comment does not provide specific examples or references to support the claim that more detail or a citation is necessary. Without such supporting information, the claim remains vague and lacks verifiability. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks the necessary justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder or citing the dictionary-based replacement strategy used. This feedback is clear and actionable, as it provides a specific area for improvement and a potential direction for the authors to enhance their draft. By addressing this point, the authors could provide a clearer explanation of their methodology, which would benefit both the understanding of the paper and its overall quality. However, the comment could be more helpful if it included specific examples or further guidance on how to incorporate this detail or citation. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. This is an explicit suggestion, as it directly instructs the authors to include additional comparisons in their experiments. However, the comment does not specify which specific SOTA methods or pre-trained models should be used for comparison, leaving some room for interpretation. While the action is clear, the lack of detailed guidance on how to implement the comparison makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. However, it does not specify which part of the paper this comparison should be included in, such as the experimental section or a specific table or figure. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting a particular comparison that could be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that other state-of-the-art (SOTA) code summarization methods, particularly those using pre-trained models, should be compared in the experiments. However, the comment does not provide specific examples or references to these SOTA methods or pre-trained models, making it difficult for the authors to understand which comparisons are being suggested. The lack of detailed justification or examples results in the claim being borderline verifiable, as it provides some direction but lacks the necessary support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental section by including comparisons with existing methods. However, the comment could be more helpful if it provided examples of specific SOTA methods or pre-trained models to consider, which would offer more detailed guidance. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides a general direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the results presented in Table 3, specifically questioning the reason for AttendOut having lower variance compared to Scheduled Bernoulli and asking for the statistical significance value when comparing the two methods. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to investigate or report the statistical significance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the results presented in Table 3, specifically questioning the reason for AttendOut having lower variance compared to Scheduled Bernoulli and asking for the statistical significance value when comparing the two methods. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the results presented in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the results presented in Table 3, specifically questioning why AttendOut has lower variance compared to Scheduled Bernoulli and asking for the statistical significance value when comparing the two methods. This feedback is clear and actionable, as it prompts the authors to provide additional analysis or explanation regarding the results. By addressing these questions, the authors can enhance the clarity and robustness of their findings. However, the comment could be more helpful if it suggested ways to investigate or present this information, such as conducting additional statistical tests or providing more detailed comparisons. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should follow the same prediction lengths as the original dataset, such as {96, 192, 336, 720}, instead of the current {24, 36, 48, 60}. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what changes to make to align their experimental results with the original dataset. The suggestion is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results and the prediction lengths, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the suggestion to follow the same prediction lengths as the original dataset. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction lengths used in the experimental results do not reflect the setting of \"long-term,\" suggesting that the authors should follow the same settings as the original dataset. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to the original dataset\\'s settings. The authors would need to make an effort to understand the context of the original dataset and its settings to fully address the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically noting that the prediction lengths used do not reflect the setting of \"long-term.\" It suggests that the authors should follow the same settings as the original dataset, providing specific examples of prediction lengths that could be used. This feedback is clear and actionable, offering a concrete suggestion for improvement that can help the authors align their experimental setup with the original dataset. By addressing this point, the authors can enhance the validity and comparability of their results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the difference between confidence and accuracy for one sample when using it in an equation. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or what specific changes should be made to improve the draft. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Without concrete steps or suggestions, the authors are unable to determine what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to an equation where the difference between confidence and accuracy for one sample is discussed. However, it does not specify which equation or section of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the issue of unreasonable differences between confidence and accuracy, but without clear grounding, the authors may struggle to locate and address the problem. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"the difference between the confidence and the accuracy for one sample is not reasonable when using it in Eq.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this difference is unreasonable. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of confidence and accuracy in an equation, noting that the difference between them is unreasonable. However, it does not provide any further explanation or suggestions on how to address this issue or why it is problematic. Without additional context or guidance, the authors may struggle to understand the significance of this observation and how to improve their draft. The lack of actionable feedback or detailed explanation makes the comment barely helpful, as it points out a potential problem but does not offer a clear path for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential failure of the method when the sample is shifted from the data distribution. It questions whether there is a way to adapt the method to account for such shifts. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how to address it. The authors are left to infer that they might need to explore alternative methods or adjustments to their approach. The action is implicit and somewhat vague, as it lacks concrete steps for implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the calculation of divergence between a sample and the data, specifically mentioning the use of residuals. However, it does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique, as it questions the applicability of the method in cases where the sample is shifted from the data distribution and suggests considering ways to account for such shifts. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the method\\'s applicability when the sample is shifted from the data distribution. It questions whether there is a way to adapt the method to account for such shifts. However, the comment does not provide any supporting evidence, examples, or references to substantiate this concern or suggest potential solutions. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the method used to calculate divergence between a sample and the data, specifically noting that the approach may fail when the sample is shifted from the data distribution. It raises a relevant question about whether there is a way to adapt the method to account for such shifts. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue or adapt their method. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, leaving the authors with a general direction for improvement but without detailed guidance on how to achieve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the methodology, specifically asking whether replacing a word independent of context could lead to incoherent text. The reviewer suggests that it might be better to replace the whole phrase instead of individual words. While the comment implies that the authors should consider this aspect of their methodology, it does not explicitly instruct them to make changes or provide concrete guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach to word replacement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 076-079,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the methodology regarding the replacement of words independent of context, and it provides a suggestion to replace the whole phrase instead of individual words to avoid incoherent text. This level of detail helps the authors understand what needs to be addressed in their work. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion regarding the methodology of replacing words independent of context. It does not contain any subjective claims, opinions, or judgments that require verification. The comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the methodology used in the paper, specifically regarding the replacement of words independent of context. It suggests that replacing individual words might lead to incoherent text and proposes an alternative approach of replacing entire phrases. This feedback is clear and actionable, providing the authors with a specific area to consider and a potential solution to address the issue. By offering a constructive suggestion, the comment empowers the authors to improve their draft, making it mostly helpful. However, it could be more comprehensive by explaining why the suggested approach might be beneficial or by providing additional context or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods. While the action is explicit, it lacks concrete details on how to implement this comparison or which specific methods should be included. The authors are given a clear direction but without specific guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where such a comparison could be included. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding which methods should be compared or how this comparison should be structured. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is desirable or necessary. The lack of detailed explanation or references makes it difficult for the authors to understand the importance or relevance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this comparison or which methods should be included. The comment is somewhat helpful as it points out a direction for enhancing the paper, but it could be more beneficial with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare and explore ECG-specific architectures using SSL or transformer-based architectures for the ECG encoder, similar to how different methods were explored for the other two parts of the framework. This feedback provides a clear and explicit action for the authors to take, specifying that they should compare and explore alternative architectures for the ECG encoder. The suggestion is concrete, as it outlines a specific area for improvement and provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the three parts of the MEIT framework: the ECG encoder, modality alignment, and LLM backbone. It specifies the issue with the ECG encoder, noting that it only uses several 1-D CNN layers and average pooling, and suggests that ECG-specific architectures using SSL or transformer-based architectures could significantly improve it. The comment also provides a clear suggestion to compare and explore these architectures, similar to how different methods were explored for the other two parts of the framework. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder in the MEIT framework could be improved by comparing it to ECG-specific architectures using SSL or transformer-based architectures. The claim is somewhat verifiable as it provides a logical reasoning for the improvement by referencing the potential benefits of such architectures. However, the comment lacks specific examples or references to these architectures, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the MEIT framework, noting that the ECG encoder uses only a few 1-D CNN layers and average pooling, which may not be optimal for the task. It suggests that ECG-specific architectures using SSL or transformer-based architectures could significantly improve the encoder. The comment provides a clear and actionable recommendation to compare and explore these architectures, similar to how different methods were explored for the other two parts of the framework. This feedback is highly helpful as it offers a concrete direction for enhancing the framework, allowing the authors to make a meaningful improvement to their work. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rephrase the abstract to accurately reflect the focus of the paper, which is on a model-agnostic explainability technique for deep neural networks rather than a defense methodology. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be changed in their abstract. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the abstract, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to rephrase the abstract to accurately reflect the focus on a model-agnostic explainability technique rather than a defense methodology. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract inaccurately suggests a defense methodology is proposed, when in fact, the paper presents a model-agnostic explainability technique for deep neural networks. The reviewer provides a clear and specific suggestion to rephrase the abstract to reflect the correct focus on explainability. This claim is fully verifiable as it is supported by a logical reasoning and a clear suggestion for improvement. The comment is precise and provides a straightforward solution, making it easy for the authors to understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it inaccurately suggests a defense methodology is proposed when, in fact, the paper presents a model-agnostic explainability technique for deep neural networks. The reviewer provides a clear and actionable suggestion to rephrase the abstract to reflect the correct focus on explainability. This feedback is valuable as it helps the authors correct a potential misrepresentation of their work, ensuring that the abstract accurately reflects the content of the paper. The comment is highly helpful as it offers a precise and constructive suggestion that can significantly improve the clarity and accuracy of the abstract.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks comparisons to recent methods, specifically mentioning FINER, Incode, and SL2A-INR, which propose new activation (and in some cases adaptive activation) functions for INRs. While the comment identifies a gap in the comparison, it does not explicitly instruct the authors to include these comparisons or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should add these comparisons but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper\\'s comparison section, noting that it lacks comparisons to recent methods, such as FINER, Incode, and SL2A-INR, which propose new activation functions for INRs. This provides a clear indication of what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, such as a particular section or table where comparisons are made. The authors can infer that it relates to the comparison section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the issue. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods, specifically mentioning FINER, Incode, and SL2A-INR, which propose new activation functions for INRs. This claim is somewhat verifiable as it provides specific examples of recent methods that could be included in the comparison. However, the comment does not provide detailed reasoning or evidence on why these comparisons are necessary or how they would impact the paper\\'s conclusions. The authors would need to make a significant effort to understand the importance of these comparisons and how to incorporate them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper\\'s comparison section, noting that it lacks comparisons to recent methods that propose new activation functions for INRs. By mentioning specific methods like FINER, Incode, and SL2A-INR, the comment provides clear guidance on which recent works should be considered for comparison. This feedback is actionable and constructive, as it directs the authors to expand their comparative analysis to include these relevant methods, thereby enhancing the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these comparisons into the paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation setting could be improved, implying that the authors should reconsider their evaluation methodology. However, it does not provide specific guidance on how to improve the evaluation setting or what aspects of the current evaluation are problematic. The comment lacks explicit instructions or concrete details on how to implement the suggested improvements, leaving the authors uncertain about the exact steps to take. As a result, the comment is vague and lacks actionable guidance, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the evaluation setting could be improved, implying that the authors should reconsider their evaluation methodology. However, it does not specify which part of the paper this suggestion pertains to, such as the evaluation section or the discussion of the method\\'s limitations. Additionally, while it mentions a straightforward method that works well in practice, it does not provide specific guidance on how to improve the evaluation setting. This lack of detail makes it difficult for the authors to identify the exact areas needing improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that a straightforward method works well in practice and challenges the value of research on length extrapolation, suggesting that the evaluation setting could be improved. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the straightforward method or the need for improvement in the evaluation setting. Without these elements, the claim remains vague and difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the evaluation setting could be improved, implying that the authors should reconsider their approach to evaluating the method. It references a straightforward method that works well in practice, which challenges the value of research on length extrapolation. However, the comment lacks specific guidance or suggestions on how to improve the evaluation setting, such as what aspects of the current evaluation are problematic or how the authors might incorporate the referenced method into their evaluation. While it identifies a potential area for improvement, the feedback is vague and does not provide actionable steps for the authors to follow. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the training and testing environments for the autoencoder, specifically asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. While the comment implies that the authors should clarify these aspects and consider cross-validation, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the training and testing environments for the autoencoder and suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. This provides the authors with a clear direction on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training and testing environments for the autoencoder, suggesting that cross-validation testing would be preferable to demonstrate the robustness of the results. However, the comment does not provide any specific reasoning or evidence to support why cross-validation is necessary or how it would improve the robustness of the results. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the training and testing environments for the autoencoder, specifically asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. This feedback is clear and actionable, as it prompts the authors to clarify their experimental setup and consider a more robust testing approach. However, the comment could be more helpful if it provided additional guidance on how to implement cross-validation or discussed the potential benefits of doing so. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their methodology that could be improved, but it could be more comprehensive with further suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison to demonstrate how refinement during inference improves generation quality. While it acknowledges the inclusion of statistics on the number of refinements, it suggests that this alone does not prove an improvement. However, the comment does not provide explicit guidance on how to address this issue or what specific comparisons or analyses should be included to substantiate the claim of improvement. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to demonstrate how refinement during inference improves generation quality. It mentions the inclusion of statistics on the number of refinements, but it does not specify which part of the paper this issue pertains to, such as a particular section or table. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in identifying the need for a comparison to show improvement, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of a comparison to show how refinement during inference improves generation quality is a weakness. The reviewer acknowledges the inclusion of statistics on the number of refinements but suggests that this alone does not prove an improvement. However, the comment does not provide specific examples or references to support the claim that refinement during inference is necessary for improvement. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of a comparison to demonstrate how refinement during inference improves generation quality. It acknowledges the inclusion of statistics on the number of refinements but notes that this alone does not prove an improvement. While the comment highlights a relevant issue, it lacks detailed guidance or suggestions on how the authors might address this gap or what specific comparisons or analyses could be included to substantiate the claim of improvement. This limits the comment\\'s usefulness, making it somewhat helpful as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate questions. The first question, \"something missing (threshold?)\", is vague and does not provide explicit guidance on what is missing or how to address it. The second question, \"did you do this partitions randomly?\", is also vague and lacks context or explanation. Neither question provides clear actions or concrete details for the authors to follow. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses. It consists of two questions: \"something missing (threshold?)\" and \"did you do this partitions randomly?\" without providing context or references to specific sections or elements of the paper. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper being addressed. Additionally, the comment lacks specificity as it does not provide details on what is missing or what the authors should address regarding the threshold or the partitions. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions: \"something missing (threshold?)\" and \"did you do this partitions randomly?\" These are requests for clarification and do not contain subjective opinions, judgments, or suggestions that require verification. They are factual inquiries, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions: \"something missing (threshold?)\" and \"did you do this partitions randomly?\" These questions indicate areas of potential confusion or missing information in the manuscript. However, the comment lacks context and does not provide any guidance or suggestions on how the authors might address these issues. Without additional context or specific feedback, the authors may find it challenging to understand the significance of these questions and how to improve their draft. Therefore, the comment is barely helpful, as it identifies potential areas of concern but does not offer actionable advice or detailed guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: how long the MDP will take and whether the training time comparison of MDP and ImageNet pretraining plus individual dataset fine-tuning could be provided. While these questions imply that the authors should include this information, they do not explicitly instruct them to do so. The action is implicit, as the authors need to infer that they should provide the requested information. However, the comment does not specify how to conduct the comparison or what specific details to include, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the training time of the MDP and compares it with ImageNet pretraining and individual dataset fine-tuning. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table where this information might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for a training time comparison, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the training time of the MDP and a comparison with ImageNet pretraining and individual dataset fine-tuning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training time of the MDP and suggests comparing it with ImageNet pretraining and individual dataset fine-tuning. While this question identifies a potential area for improvement, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment prompts the authors to consider an additional analysis but does not offer actionable steps or detailed advice on how to conduct it. Therefore, the feedback is somewhat helpful, as it points out a potential area for enhancement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the author\\'s claim regarding the design of G-PDE, suggesting that it is an incremental improvement over GraphCON rather than a novel approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as by clarifying their claim or providing additional context. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the design of G-PDE, suggesting that it is an incremental improvement over GraphCON. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue with the claim and provides a reference to GraphCON, which is a specific external work. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the author\\'s claim about the design of G-PDE, suggesting that it is an incremental improvement over GraphCON rather than a novel approach. The comment provides a specific reference to GraphCON, which supports the claim by pointing out the similarity in structure. This reference helps substantiate the critique, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or additional references to fully validate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the originality of the G-PDE method by pointing out that it is an incremental improvement over GraphCON, where the static encoder is replaced by SNN. This feedback is somewhat helpful as it challenges the authors to clarify the novelty of their approach and possibly differentiate it more clearly from existing work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. To be more helpful, the comment could include recommendations on how to better articulate the contributions or suggest ways to highlight the unique aspects of G-PDE. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not significantly outperform Jiang et al. in certain metrics, such as Penetration(Dep) and Sim-Disp(Mean). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the performance. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific metrics such as \"Penetration(Dep),\" \"In CR,\" and \"Sim-Disp(Mean),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the performance comparison between the proposed method and Jiang et al., highlighting the small margin of improvement in certain metrics. This provides clear guidance on what needs to be addressed in terms of performance evaluation. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not significantly outperform Jiang et al. in certain metrics, providing specific numerical comparisons to support this claim. It mentions that in Penetration(Dep) and In CR, the proposed method only outperforms Jiang et al. by a small margin, and in Sim-Disp(Mean), the proposed method is even worse. This detailed comparison provides a clear and verifiable basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment highlights a specific issue with the proposed method, noting that it does not significantly outperform Jiang et al. in certain metrics. It provides detailed numerical comparisons, such as the small margin of improvement in Penetration(Dep) and the worse performance in Sim-Disp(Mean). This feedback is clear and specific, allowing the authors to understand the areas where their method falls short and potentially consider ways to improve their results. However, the comment could be more helpful if it offered suggestions on how to address these performance issues or alternative approaches to enhance the method. Overall, the comment is mostly helpful as it provides valuable insights into the method\\'s performance, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues. First, it notes that the term \"vFSAD\" refers to OOD detection in time-series data, which includes a large body of work that has not been compared with or even mentioned. This implies that the authors should include a comparison or discussion of this existing work. Second, it points out that the related work subtitles for \"Policy\" and \"Evaluation tasks\" are not descriptive and seem unrelated to the actual content. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should include comparisons and improve the related work subtitles. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"vFSAD,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issue by pointing out that the term refers to OOD detection in time-series data, which includes a large body of work that has not been compared with or even mentioned. Additionally, it highlights the lack of descriptive related work subtitles for \"Policy\" and \"Evaluation tasks,\" suggesting that these subtitles are unrelated to the actual content. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims. First, it suggests that the term \"vFSAD\" refers to OOD detection in time-series data, which includes a large body of work that has not been compared with or even mentioned. This claim is somewhat verifiable as it highlights a potential gap in the literature review, but it lacks specific examples or references to the existing work that should be considered. Second, it criticizes the related work subtitles for \"Policy\" and \"Evaluation tasks\" as being non-descriptive and unrelated to the actual content. This claim is somewhat verifiable as it points out a lack of clarity in the related work section, but it does not provide specific suggestions for improvement. Overall, the review point provides some justification but lacks detailed evidence or examples, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it points out that the term \"vFSAD\" refers to OOD detection in time-series data, which includes a large body of work that has not been compared with or even mentioned. This is a critical oversight that the authors should address to provide a more comprehensive literature review. Second, it notes that the related work subtitles for \"Policy\" and \"Evaluation tasks\" are not descriptive and seem unrelated to the actual content. This feedback highlights the need for more descriptive and relevant subtitles to improve the clarity and organization of the related work section. While the comment effectively identifies areas for improvement, it could be more helpful by offering specific suggestions on how to incorporate the missing literature or improve the related work subtitles. Overall, the comment is mostly helpful as it provides clear directions for enhancing the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an ablation study should be conducted to examine the effect of memory size on the results. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is concrete, as it outlines a specific type of study that should be included to justify the memory size selection. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an ablation study to examine the effect of memory size, which is a specific and actionable recommendation. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment where memory size is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting an improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any specific examples, reasoning, or references to support why the current analysis is insufficient or how an ablation study would address the ambiguity. This lack of detailed justification makes the claim borderline verifiable, as it provides a suggestion but lacks the necessary evidence or explanation to fully substantiate the need for an ablation study.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the ambiguity in the effect of memory size. It suggests adding an ablation study to justify the memory size selection, which is a clear and actionable recommendation. This feedback is valuable as it directs the authors to conduct additional analysis to strengthen their work. However, the comment could be more helpful if it provided additional guidance on how to design the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue regarding the placement of the abbreviation \"GNN\" and its full definition in the paper. It explicitly states that the abbreviation appears at the end of page 1, while the full definition is only mentioned much later in Section 2, at the end of page 2. This feedback provides a clear and direct action for the authors to take, which is to ensure that the full definition is placed closer to where the abbreviation is first used. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the end of page 1 and the end of page 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of the abbreviation \"GNN\" appearing before its full definition, which is later in Section 2. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the placement of an abbreviation and its full definition in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the placement of an abbreviation and its full definition in the paper. It points out that the abbreviation \"GNN\" appears at the end of page 1, while the full definition is only mentioned much later in Section 2, at the end of page 2. This feedback is actionable as it highlights a potential source of confusion for readers and suggests that the authors should consider reordering or clarifying the placement of these terms to improve the readability and coherence of the paper. However, the comment could be more helpful if it provided additional guidance on how to address this issue, such as suggesting specific placement or offering examples of best practices. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing improvement but lacks detailed guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms does not guarantee its effectiveness on top-performing methods. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The feedback lacks actionable details, such as recommending specific actions or modifications to enhance performance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the DAVIS dataset and the performance of baseline methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by comparing the performance with state-of-the-art results and questioning the effectiveness of the proposed loss function on top-performing methods. The reference to a specific paper ([1]) provides additional context and support for the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is low compared to state-of-the-art results, citing a specific example of 65.6% J mean on 2019-val by a referenced study. This provides a clear and specific comparison, making the claim verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional references to support the assertion about the effectiveness of the proposed loss function on top-performing methods. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It questions the effectiveness of the proposed loss function on these algorithms, suggesting that its performance may not be as strong on top-performing methods. While the comment highlights a potential weakness, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their results. Without specific advice or examples, the feedback is limited in its utility for the authors, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results for the proposed two-step decoding method, specifically asking whether the results in Table 1 with decoder downsampling were obtained with or without the two-step method. It also inquires about the performance difference between the two-step method and the baseline. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the results for the proposed two-step decoding method, specifically asking if the results in Table 1 with decoder downsampling were obtained with or without the two-step method. It also inquires about the performance difference between the two-step method and the baseline. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the results section or Table 1. The comment is specific in detailing what needs to be clarified regarding the results and their comparison. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the results presented in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the results for the proposed two-step decoding method, specifically asking whether the results in Table 1 with decoder downsampling were obtained with or without the two-step method. It also inquires about the performance difference between the two-step method and the baseline. While the comment identifies a potential gap in the presentation of results, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out an area of confusion, but it lacks actionable advice or detailed guidance on how to improve the clarity or presentation of the results. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to increase the font size in the figures to improve readability. This is a clear and direct action that the authors can take to enhance the legibility of their figures. The comment provides a specific and concrete suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small and provides a direct suggestion to increase it for improved readability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for improvement regarding the font size in the figures, suggesting that it is too small and should be increased for better readability. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the readability of the figures by increasing the font size. This feedback is clear and directly addresses a concrete issue, allowing the authors to make a straightforward enhancement to their draft. By following this advice, the authors can enhance the legibility of their figures, which is crucial for effective communication of their results. The comment is highly helpful as it offers a precise and easy-to-implement suggestion that directly benefits the clarity and presentation of the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that only synthetic problems are considered in the experiments, but it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should include real-world problems, expand their experiments to include them, or discuss the implications of focusing solely on synthetic problems. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that only synthetic problems are considered in the experiments, but it does not specify which part of the paper this observation is based on, such as a particular section or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific guidance on how to address this issue or what changes might be needed. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"only synthetic problems are considered in the experiments.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the experimental setup, noting that only synthetic problems are considered. While this observation highlights an area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment does not offer actionable steps or examples for expanding the experiments to include real-world problems, which would be more beneficial for the authors. Therefore, the feedback is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include NLE (natural language explanation) baselines in their comparison, as their explainer generates natural language explanations. This feedback provides a clear and direct action for the authors to take, which is to compare their work with other NLE interpretability tools. The comment is specific and provides a concrete suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include NLE (natural language explanation) baselines in their comparison, as their explainer generates natural language explanations. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where comparisons are made. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting the inclusion of NLE baselines, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should include NLE (natural language explanation) baselines in their comparison, as their explainer generates natural language explanations. This claim is somewhat verifiable as it logically suggests that a comparison with other NLE interpretability tools would be appropriate. However, the comment lacks specific examples or references to other NLE interpretability tools that could be used for comparison, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that the authors have only compared their work to feature attribution-type explanations, despite their explainer generating natural language explanations. It suggests that the authors should include comparisons with other natural language explanation (NLE) interpretability tools. This feedback is clear and actionable, providing a concrete direction for the authors to enhance their evaluation by including additional baselines. However, the comment could be more helpful if it offered specific examples of NLE interpretability tools to consider or discussed the potential benefits of such comparisons. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in Eq. (5), noting that only one pertinent positive data point is used, while many other data points satisfy Eq. (1) and Eq. (2). It suggests that these data points contribute equally to Eq. (3) but are not included in the exhaustive test over the diversity of all these data points. The comment implies that the authors should consider including more data points in their analysis, but it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, \"Eq. (5),\" \"Eq. (1),\" and \"Eq. (2),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the use of only one pertinent positive data point in Eq. (5), while many other data points satisfy the other equations. The comment further explains that these data points contribute equally to Eq. (3) but are not included in the exhaustive test over the diversity of all these data points. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Eq. (5) uses only one pertinent positive data point, while many other data points satisfy Eq. (1) and Eq. (2). It argues that these data points contribute equally to Eq. (3) but are not included in the exhaustive test over the diversity of all these data points. The comment provides a logical reasoning by highlighting the potential oversight in the analysis, which could impact the validity of the results. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methodology, specifically in Eq. (5), where only one pertinent positive data point is used. It points out that there are many other data points that satisfy Eq. (1) and Eq. (2), which contribute equally to Eq. (3) but are not included in the exhaustive test over the diversity of all these data points. This feedback is clear and actionable, as it highlights a potential limitation in the analysis that the authors can address by including more data points or conducting a more comprehensive test. However, the comment could be more helpful if it provided suggestions on how to incorporate these additional data points or what specific aspects of the analysis might be affected by this omission. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their results with the supervision data, specifically mentioning InPars-V2 and Promptagator, which are not included in the comparison due to the authors\\' justification. The reviewer implies that it would be beneficial to demonstrate how document augmentation could enhance performance on top of existing supervised retrievers. While the comment provides a clear direction for the authors to include additional comparisons, it lacks specific guidance on how to implement these comparisons or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison of results without using supervision data, which allows the authors to identify the relevant part of the paper. It also specifies what needs to be addressed, namely, the potential benefits of document augmentation on top of existing supervised retrievers. The comment provides a clear direction for improvement by suggesting a comparison with InPars-V2 and Promptagator, which are not included in the current comparison. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results are compared without using supervision data, which is why InPars-V2 and Promptagator are not included in the comparison. The reviewer proposes that it would be beneficial to demonstrate how document augmentation could enhance performance on top of existing supervised retrievers. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that document augmentation would provide additional performance boosts. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison of results, noting that the authors have not used supervision data, which is why InPars-V2 and Promptagator are not included in the comparison. The reviewer suggests that it would be beneficial to demonstrate how document augmentation could enhance performance on top of existing supervised retrievers. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including additional comparisons and demonstrating the potential benefits of document augmentation. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct these comparisons. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the cache hierarchy is not discussed, specifically mentioning the order in which the three dimensions are applied and the potential data sharing among them. It also notes a contradiction between the discussion of individual levels and the initial claim of a hierarchy. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to discuss the cache hierarchy and its application, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"cache hierarchy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the discussion of the order in which the three dimensions are applied, potential data sharing, and how the individual levels are applied together. The comment provides clear guidance on what aspects of the cache hierarchy are missing or contradictory, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed, specifically regarding the order in which the three dimensions are applied and potential data sharing. The comment provides a logical reasoning by pointing out a contradiction between the discussion of individual levels and the initial claim of a hierarchy. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from more detailed explanation or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the discussion of the cache hierarchy, noting that the order in which the three dimensions are applied and potential data sharing are not addressed. It points out a contradiction between the discussion of individual levels and the initial claim of a hierarchy. This feedback is clear and actionable, as it directs the authors to clarify and integrate the discussion of the cache hierarchy, which is crucial for understanding the methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how to structure the discussion. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the management of GPU memory during pretraining, specifically regarding the need for three forward propagations before one backpropagation. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how to address it. The authors are left to infer that they should consider optimizing their GPU memory management to prevent out-of-memory (OOM) issues. However, the comment lacks concrete details on how to implement this optimization, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the management of GPU memory during pretraining, particularly regarding the need for three forward propagations before one backpropagation. This provides the authors with a clear direction on what aspect of their methodology needs further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the management of GPU memory during pretraining. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the management of GPU memory during pretraining, particularly in relation to the need for three forward propagations before one backpropagation. This question highlights a potential issue that the authors may need to address to ensure the stability and efficiency of their model training. However, the comment does not provide any suggestions or guidance on how the authors might resolve this issue or optimize their memory management. While it identifies a potential area of concern, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a relevant issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite and better present their contributions in the abstract. This direct request provides a clear action for the authors to take, ensuring they know exactly what is expected of them. However, while the action is explicit, it lacks concrete guidance on how to improve the abstract or what specific aspects need attention. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Abstract,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It specifies the issue by stating that the contributions are not well presented and recommends rewriting the abstract to better convey them. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract is not well-written and difficult to understand the contributions. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the abstract, noting that it is not well-written and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite and better present the contributions, which is valuable feedback for the authors. However, the comment could be more helpful if it offered specific guidance on how to improve the abstract or what aspects need clarification. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing improvement, providing a clear path for enhancing their draft. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point continues from a previous comment and mentions that ADE is a dataset for image parsing that may be biased among different scenes and favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the potential bias in the dataset or how it might affect the performance of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is a continuation of a previous point and mentions the ADE dataset, which is likely a specific dataset mentioned in the paper. However, it does not explicitly reference a particular section or part of the paper where this issue is discussed, making it weakly grounded. The comment does specify the potential bias of the dataset and its impact on the proposed method, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the ADE dataset may be biased among different scenes and favor the performance of the proposed method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment continues from a previous point and mentions that the ADE dataset may be biased among different scenes, potentially favoring the performance of the proposed method. While it identifies a potential issue with the dataset, it does not provide any specific suggestions or guidance on how the authors might address this bias or mitigate its impact on the results. The comment lacks actionable feedback or detailed advice, leaving the authors with only a vague understanding of the problem. Therefore, the comment is barely helpful, as it points out an issue but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the matrices might be redundant. The reviewer also notes that many matrices are not used in the following text. While the comment implies that the authors should clarify the purpose of using two matrices and possibly simplify their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of two matrices to represent each relation (edge type) and notes that many matrices are not used in the following text. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of using two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the matrices might be redundant. The reviewer also notes that many matrices are not used in the following text. While the comment raises a valid point about potential redundancy, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the issue and determine how to address it without explicit guidance. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the representation of relations in section 2.1.2, noting that each relation is represented by two matrices (A, B, C, D, E, F) but suggesting that these matrices might be redundant. The reviewer also points out that many matrices are not used in the following text. This feedback is somewhat helpful as it highlights a specific area of the paper that may need clarification or simplification. However, it lacks detailed guidance or suggestions on how the authors might address this issue, such as proposing a more efficient representation or explaining the purpose of the matrices. To be more helpful, the comment could include specific recommendations or examples of how to improve the clarity or efficiency of the representation. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of understanding regarding a statement in Section 2, specifically the phrase \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any guidance or suggestions on how the authors might clarify this statement or improve its explanation. The comment lacks explicit instructions or concrete details on how to address the issue, leaving the authors uncertain about what steps to take to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the end of Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of understanding regarding the statement about the semantics of the upsampled feature map. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about a statement in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific point of confusion in the paper, specifically regarding the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This feedback is valuable as it highlights a potential area of misunderstanding for readers, prompting the authors to clarify or revise this section to ensure clarity. However, the comment does not provide suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the differences between their method and other methods for predicting user personality, specifically mentioning a reference ([1]). This provides a clear and direct action for the authors to take, which is to compare their method with the referenced work. The comment is specific and provides a concrete example of what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests clarifying the differences between the proposed method and other methods for predicting user personality, specifically mentioning a reference ([1]). However, it does not specify which part of the paper should include this clarification, making it weakly grounded. The comment is specific in its request for clarification on the differences, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is necessary to clarify the differences between the proposed method and other methods for predicting user personality, specifically referencing a work by Yang et al. ([1]). This claim is somewhat verifiable as it provides a specific reference to an external work, which can guide the authors in understanding the context of their work. However, the comment lacks detailed reasoning or examples of how the proposed method differs from the referenced work, which would provide a more robust justification for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for the authors to clarify the differences between their method and other methods for predicting user personality. It specifically references a relevant work ([1]) to provide context and guidance for the authors. This feedback is clear and actionable, as it directs the authors to compare their method with existing approaches, which can help strengthen the paper\\'s contribution and clarity. However, the comment could be more helpful if it provided additional guidance on how to effectively present these comparisons or suggested specific aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the theoretical justification for imposing certain constraints in LoRA tuning and suggests that step size tuning might still be necessary for the experiments. While the comment identifies areas of confusion and potential improvements, it does not provide explicit instructions or concrete steps for the authors to follow. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the theoretical basis and consider step size tuning. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific points: the theoretical justification for imposing constraints in LoRA tuning and the need for step size tuning in the experiments. However, it does not explicitly mention which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified or addressed regarding the theoretical justification and the potential need for step size tuning. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the theoretical justification for imposing constraints in LoRA tuning, suggesting that it should not accelerate convergence. The reviewer provides a logical reasoning by stating that both B and A should cover the same $X$ space ($X=BA$) and that vanilla LoRA parameters might have more freedom. However, the comment lacks specific examples, references, or detailed explanations to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two specific points. First, it questions the theoretical justification for imposing constraints in LoRA tuning, specifically why imposing B to be the basis and A to be coordinate would accelerate convergence. The comment provides a logical reasoning by pointing out that both B and A should cover the same $X$ space ($X=BA$) and that vanilla LoRA parameters might have more freedom. This feedback is clear and prompts the authors to clarify or justify their theoretical claims. Second, the comment suggests that while the authors theoretically show that a constant step size is sufficient, it appears that step size tuning might still be needed for the experiments. This is a valuable observation that could lead to improvements in the experimental setup. Overall, the comment is mostly helpful as it identifies specific areas for clarification and improvement, providing actionable feedback for the authors to enhance their draft. However, it could be more comprehensive by offering suggestions on how to address these issues. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more ablation studies or analyses on problems other than shortest path problems to make their design more convincing. While the comment implies that the authors should expand their experimental scope, it does not provide specific guidance on which other problems to consider or how to structure the additional analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental environments and the design of the architecture (PathGNN), specifically mentioning the bias towards the shortest path problem. It suggests conducting more ablation studies or analyses on problems other than shortest path problems to make the design more convincing. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for more ablation studies or analyses on different problems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem, and the design of the architecture (PathGNN) is biased towards this kind of problem. The reviewer recommends conducting more ablation studies or analyses on problems other than shortest path problems to make the design more convincing. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the bias or the need for additional studies. This makes the claim somewhat verifiable, as the authors would need to further develop the reasoning themselves to fully understand and address the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential bias in the experimental design, noting that most environments are related to the shortest path problem and that the architecture (PathGNN) is designed to align with this kind of problem. It suggests conducting more ablation studies or analyses on problems other than shortest path problems to make the design more convincing. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and address a potential limitation in their work. However, the comment could be more helpful if it offered examples of alternative problems or suggested specific analyses to conduct. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. While the comment implies that the authors should expand their comparison to include more recent models, it does not specify which models should be considered or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer the specific models to include and how to integrate them into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the section discussing the baselines or the methodology. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, the comment does not provide specific examples of these recent models or detailed reasoning to support why they are necessary. The lack of explicit references or detailed justification makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary detail to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. This feedback is somewhat helpful as it identifies a potential area for improvement by encouraging the authors to expand their comparison to include more relevant models. However, the comment lacks specific guidance on which models to consider or how to incorporate them into the analysis. While it provides a direction for enhancement, it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of visualization of the learned context token and the absence of analysis for the insight of the approach. While it identifies these areas as needing attention, it does not provide explicit guidance on how to address them. The authors are left to infer that they should include visualizations and analysis, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights two specific issues: the lack of visualization of the learned context token and the absence of analysis for the insight of the approach. However, it does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is missing, namely the visualization and analysis, but without clear references to sections or figures, the authors may struggle to pinpoint where these additions should be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token and analysis for the insight of the approach, suggesting that this limits the paper\\'s novelty. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed justification or evidence results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient support for the claims made.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement: the lack of visualization of the learned context token and the absence of analysis for the insight of the approach. While it highlights these weaknesses, it does not provide detailed guidance or suggestions on how to address them. The comment points out the need for visualization and analysis but lacks actionable advice or examples, leaving the authors with a general idea of what needs to be improved but without clear steps to take. This limits the utility of the feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should report results for other models besides MetaOptNet to emphasize the generality of their method and demonstrate its effectiveness across multiple baseline models. This feedback provides a clear and direct action for the authors to take, specifying exactly what additional experiments should be conducted to strengthen their paper. The comment is concrete, as it outlines a specific way to enhance the experimental section, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, reporting results for other models besides MetaOptNet to emphasize the generality of the method and demonstrate its effectiveness across multiple baseline models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results show only small benefits over the baseline model and suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper. However, the comment lacks specific examples or detailed reasoning to support the claim that the current results are insufficient. Without concrete evidence or references to other models that could demonstrate the method\\'s generality, the claim remains somewhat vague. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a suggestion but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the experimental section, noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and convincingly demonstrating its effectiveness across multiple baseline models. This feedback is clear and actionable, providing the authors with a specific direction to enhance the robustness and impact of their findings. By addressing this suggestion, the authors can significantly improve the comprehensiveness and credibility of their experimental results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. This implies that the authors should expand their comparison to include these methods. While the action is not explicitly stated, it is clear and concrete, as it specifies the additional methods that should be included in the comparison. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. However, it does not specify which part of the paper this comparison should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of particular methods for comparison, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. The claim is somewhat verifiable as it provides a specific suggestion for improvement by naming particular methods that could be included. However, the comment lacks detailed reasoning or evidence on why these specific comparisons would be beneficial or how they would enhance the evaluation of the proposed method. Providing more context or justification for the importance of these comparisons would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s comparison section, noting that while comparisons with recent baselines are made, the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. This feedback is clear and actionable, as it suggests a specific way to enhance the evaluation of the proposed method by broadening the comparison. However, the comment could be more helpful if it provided additional context or rationale for why these specific comparisons would be beneficial. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the underperformance of the proposed CRF variants compared to hierarchical transformers (HiTRF) and the limited utility of location embeddings for specific types of datasets. It suggests that the focus on modeling the task using a CRF should be downgraded and that the paper should discuss the limitations of location embeddings. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should revise the focus of the paper and discuss the limitations of location embeddings, but the lack of detailed guidance makes the comment somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed CRF variants\" and the \"hierarchical transformers (HiTRF),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the underperformance of the CRF variants and the limited utility of location embeddings, providing clear guidance on what needs to be addressed. The comment suggests downgrading the focus on modeling the task using a CRF and discusses the need for further analysis regarding the utility of location embeddings. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This claim is supported by the observation that location embeddings provide additional information on the main dataset but not in the extra dataset, suggesting a potential limitation in the utility of location embeddings. However, the comment lacks specific numerical or statistical evidence to substantiate the claim of underperformance, which would provide a more robust basis for the argument. Additionally, the suggestion that the focus on modeling the task using a CRF should be downgraded is not fully supported by detailed reasoning or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive evidence or detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF), both on the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded, which is a clear and actionable piece of feedback. Additionally, the comment points out that location embeddings provide additional information on the main dataset but not in the extra dataset, suggesting a potential limitation in their utility. However, the comment does not provide specific suggestions on how to address these issues or improve the paper, such as proposing alternative approaches or further analysis. While it highlights important areas for consideration, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency but does not provide any guidance or suggestions on how the authors should address this issue. It lacks explicit instructions or concrete details on what specific actions the authors should take to clarify or mitigate the impact of this inconsistency. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the impact of training-testing inconsistency but does not specify which part of the paper this issue pertains to, making it weakly grounded. Additionally, it lacks specificity as it does not provide details on what aspects of the training-testing inconsistency are unclear or how they could be addressed. Without clear guidance or references to specific sections, the authors may struggle to identify and resolve the issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency but does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is an issue or how it affects the study. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the paper regarding the impact of training-testing inconsistency. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without further elaboration or actionable feedback, the authors are left without a clear understanding of what needs to be improved or how to resolve the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the condition for y membership and mentions that the sets S are disjoint, as defined above. It also notes that some claims are not backed up, specifically referencing the second line after Eq. However, the comment does not provide explicit guidance on how to clarify the condition for y membership or which claims need further support. The authors are left to infer that they need to clarify these points, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"condition for y membership\" and the \"Second line after Eq.,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the sets S are disjoint and that some claims are not backed up, providing clear guidance on what needs to be clarified or supported. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. It also mentions that some claims are not backed up, specifically referencing the second line after Eq. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or explanation, it is difficult for the authors to understand the basis of the reviewer\\'s concerns or how to address them. Therefore, the comment is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the condition for y membership, noting that the sets S are disjoint as defined above. It also points out that some claims are not backed up, referencing the second line after Eq. This feedback is somewhat helpful as it highlights areas where the paper lacks clarity and requires further justification. However, the comment does not provide detailed guidance or suggestions on how to address these issues, such as recommending specific ways to clarify the condition or provide evidence for the claims. While it offers some direction for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that a few key references that are highly related are not compared and explained. However, it does not specify which references are missing or how they should be integrated into the paper. The action is implicit, as the authors need to infer that they should include these references and explain their relevance. Additionally, the comment lacks concrete guidance on how to incorporate these references or what aspects should be highlighted. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that a few key references that are highly related are not compared and explained. However, it does not specify which references are missing or where in the paper these comparisons should be made. This lack of detail makes it difficult for the authors to identify the specific parts of the paper that need attention or improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a few key refererences that are highly related are not compared and explained.\" However, it does not provide specific examples of these references or explain why they are important or relevant to the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that a few key references that are highly related are not compared and explained. This feedback highlights a potential gap in the literature review or analysis section, which is important for situating the work within the existing body of knowledge. However, the comment lacks specificity and does not provide guidance on which references should be included or how they should be integrated into the paper. Without detailed suggestions or examples, the authors may struggle to address this feedback effectively. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the analysis of SCL in section 5.2 regarding its few-shot ability, suggesting that the results in Figure 7(c) and (d) do not support the claim that a more regularized representation space leads to better generalization. The reviewer also suggests checking if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment identifies specific areas of concern and suggests additional analysis, it does not provide explicit instructions on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the analysis of SCL regarding its few-shot ability, noting that the results do not meet expectations and suggesting that the authors check if COCO-LM brings benefits to sentence retrieval tasks. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the claim that a more regularized representation space by SCL leads to better generalization in few-shot scenarios. It references specific results in Figure 7(c) and (d), noting that COCO-LM achieves more improvements with fewer labels but that these improvements diminish with more labels. This provides a logical basis for the critique, as it challenges the claim with specific data points. However, the comment could be strengthened by providing more detailed analysis or additional references to support the claim further. As it stands, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the analysis of SCL in section 5.2 regarding its few-shot ability. It challenges the claim that a more regularized representation space leads to better generalization, pointing out that the results in Figure 7(c) and (d) do not support this assertion. The comment also suggests that the authors check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This feedback is clear and actionable, as it identifies specific areas of concern and provides a direction for further analysis. However, it could be more helpful if it offered suggestions on how to address these issues or improve the analysis. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing their draft by questioning the validity of their claims and suggesting additional analyses.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. While the action is implied, it is clear and concrete, as it specifies the need for additional experiments to validate the framework\\'s applicability across different LLMs. The authors can infer that they should design and perform these experiments to strengthen their work. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments that could be expanded. The authors might infer that it relates to the experimental results or discussion sections, but this inference is not direct. The comment is specific in suggesting additional experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to justify why this additional experimentation would be beneficial or necessary. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion and how it would improve their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on other LLMs to demonstrate the generalization of the proposed framework. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending more comprehensive experimentation. However, the comment lacks specificity and does not provide detailed guidance on which LLMs to consider or how to design these experiments. While it points out a direction for enhancing the paper, it does not offer actionable steps or detailed suggestions, limiting its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that the authors need to clarify what is considered \"short\" and \"long\" video to determine the downsampling layers. This is an explicit request for clarification, providing a clear action for the authors to take. The second part suggests an apple-apple comparison of SOTA VLM/Video-LLM outputs for the qualitative examples added. While this is also an explicit suggestion, it lacks specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment provides explicit actions but varies in specificity, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is partially grounded as it refers to \"Line 223,\" allowing the authors to identify the specific part of the paper being addressed. However, it does not specify what needs to be clarified about the short and long video to determine the downsampling layers. The second part of the comment suggests an apple-apple comparison of SOTA VLM/Video-LLM outputs for the qualitative examples, but it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of two parts. The first part requests clarity on what constitutes \"short\" and \"long\" video for determining downsampling layers, which is a factual request for clarification. The second part suggests an apple-apple comparison of SOTA VLM/Video-LLM outputs for qualitative examples, but it does not provide specific reasoning or evidence to support why this comparison is necessary or beneficial. The lack of detailed justification or examples makes the claim somewhat verifiable, as it provides a suggestion but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement. First, it requests clarity on what constitutes \"short\" and \"long\" video for determining downsampling layers, which is a precise and actionable suggestion that can help the authors clarify their methodology. Second, it suggests an apple-apple comparison of SOTA VLM/Video-LLM outputs for the qualitative examples added, which could provide a more comprehensive evaluation of the model\\'s performance. While the comment is clear and actionable, it could be more helpful by offering additional guidance or examples on how to conduct these comparisons. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing clarification and improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the efficiency of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential limitation regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation related to efficiency, but without clear grounding, the authors may struggle to pinpoint where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed explanation or examples that would help the authors understand the basis of the claim or how it could be addressed. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This is a relevant observation that could impact the practical application of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the efficiency of their approach. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issue but no clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical contribution is thin and that the algorithm proposed is incremental, as the interpolative decomposition is not original. It recommends focusing on finding additional applications and deeply evaluating the approach to uncover additional properties of the representation. While the comment provides a clear direction for improvement, it lacks specific guidance on how to identify and evaluate these additional applications or properties. The authors are left with a general idea of what to do but without detailed instructions on how to implement the suggested actions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, suggesting that the algorithm proposed is incremental because the interpolative decomposition is not original. It recommends focusing on finding additional applications and deeply evaluating the approach to uncover additional properties of the representation. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on how to implement the suggested improvements. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is thin and that the algorithm is incremental, as the interpolative decomposition is not original. The reviewer suggests focusing on finding additional applications and deeply evaluating the approach to uncover additional properties of the representation. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the algorithm is incremental. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a perceived weakness in the technical contribution of the paper, noting that the algorithm proposed is incremental as it does not introduce a novel interpolative decomposition. It suggests that the authors focus on finding additional applications and deeply evaluating the approach to uncover additional properties of the representation. This feedback is somewhat helpful as it provides a direction for the authors to enhance the value of their manuscript by exploring the potential of their approach in different contexts. However, the comment could be more helpful if it offered specific examples or guidance on how to identify and evaluate these additional applications or properties. Overall, the feedback is somewhat helpful, as it provides a general direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for details about the neural network library used for implementation, indicating that this information is missing from the paper. This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the neural network library used for implementation, indicating that there is a lack of details on the implementation. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the implementation details, but this inference is not as direct as it could be. The comment is specific in its request for information about the neural network library, but it lacks grounding because it does not pinpoint the exact section of the paper where this information should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification regarding the neural network library used for implementation. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry, so \"No\" is the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the lack of details on the neural network library used for implementation. This is a relevant point that could help the authors provide more transparency and reproducibility in their work. However, the comment does not offer suggestions on how to address this issue or provide guidance on which libraries might be appropriate for the study. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with clarity, such as undefined math notations and missing details in figure illustrations. However, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The comment implies that the authors should clarify these points, but it lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies specific issues with clarity, such as undefined math notations and missing details in figure illustrations. However, it does not specify which sections or figures contain these issues, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. While the authors might have an idea of where these issues could be, the comment lacks full grounding. It is specific about the types of issues but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some descriptions are unclear\" and provides specific examples, such as undefined math notations and missing details in figure illustrations. This claim is somewhat verifiable as it identifies specific areas of the paper that need clarification. However, it lacks detailed examples or references to support the claim fully, making it challenging for the authors to understand the exact nature of the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with clarity in the paper, such as undefined math notations and missing details in figure illustrations. By pointing out these areas, the comment provides the authors with clear and actionable feedback on where to improve the clarity and completeness of their work. However, the comment could be more helpful if it included specific examples or suggestions for how to address these issues, such as recommending where to define the math notations or what details are missing in the illustrations. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\\\(\\\\nu\\\\) in the text, in addition to its explanation in Algorithm 1. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the suggestion to mention the meaning of the notation \\\\(\\\\nu\\\\) in the text. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of notation \\\\(\\\\nu\\\\) in Algorithm 1 is insufficient and recommends mentioning its meaning in the text. However, the comment does not provide any reasoning or evidence to support why this is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of notation \\\\(\\\\nu\\\\) is only provided in Algorithm 1 and suggesting that it should also be mentioned in the text. This feedback is clear and actionable, as it directly points out a gap in the paper that the authors can easily address by including the explanation in the main text. By doing so, the authors can improve the clarity and accessibility of their work for readers. However, the comment could be more helpful if it provided additional context or suggested how the explanation might be integrated into the text. Overall, the comment is mostly helpful, as it effectively guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting observation about the performance of noise robust loss on pseudo-labels compared to positive learning from Equation 9. It questions whether the model underfit is caused by the pseudo-labels being too accurate, suggesting that positive learning might provide better feedback than a toned-down robust loss. However, the comment does not provide explicit guidance or suggestions for the authors on how to address this issue or improve their draft. The authors are left to infer that they might need to investigate the cause of underfitting and consider alternative approaches, but the lack of concrete steps or recommendations makes the comment somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4\" and \"Eq 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the performance of noise robust loss on pseudo-labels with positive learning and questioning whether the model underfit is caused by the pseudo-labels being too accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes an observation about the performance of noise robust loss on pseudo-labels compared to positive learning from Equation 9. It questions whether the model underfit is caused by the pseudo-labels being too accurate, suggesting that positive learning might provide better feedback than a toned-down robust loss. While the comment raises an interesting point, it lacks specific evidence or references to support the claim or provide a detailed explanation of the observed performance differences. The reasoning is somewhat logical but not fully substantiated, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies an interesting observation regarding the performance of noise robust loss on pseudo-labels compared to positive learning from Equation 9. It questions whether the model underfit is caused by the pseudo-labels being too accurate, suggesting that positive learning might provide better feedback than a toned-down robust loss. This feedback is somewhat helpful as it prompts the authors to consider the potential causes of underfitting and explore alternative approaches. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing experiments or analyses to investigate the cause of underfitting. Therefore, while it provides some insight, it could be more helpful with additional direction or actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about a claim made in the paper regarding the impact of an additional exponentiation on runtime. However, it does not provide any explicit or implicit suggestions for how the authors might clarify or address this confusion. The comment lacks actionable guidance, such as recommending additional explanations, examples, or experiments to support the claim. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248\" and the specific phrase \"requires an extra exponential,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly expresses confusion about the claim regarding the impact of an additional exponentiation on runtime and asks for clarification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a claim made in the paper regarding the impact of an additional exponentiation on runtime. The reviewer questions the validity of this claim, suggesting that it may not be a significant consideration for attackers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the reviewer\\'s concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a specific claim made in the paper regarding the impact of an additional exponentiation on runtime. It highlights a potential misunderstanding or lack of clarity in the explanation provided by the authors. However, the comment does not offer any suggestions or guidance on how the authors might clarify or address this issue. Without actionable feedback or specific advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of comparison with state-of-the-art (SOTA) methods in the experiments. It explicitly asks why these methods are not compared and suggests that the experiments are lacking in this regard. While the comment clearly identifies an area for improvement, it does not provide specific guidance on how to incorporate these comparisons or which SOTA methods should be considered. The action is explicit but somewhat vague, as the authors know they need to compare their methods with SOTA but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and abstract, allowing the authors to identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements of the proposed methods and why they are not compared with existing related works, such as \"Rubi\" and \"Removing bias in multi-modal classifiers.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison with state-of-the-art (SOTA) methods in the experiments. It references specific related works, such as \"Rubi\" and \"Removing bias in multi-modal classifiers,\" to highlight the need for comparison. However, the comment does not provide detailed reasoning or examples of how these comparisons could be conducted or what specific improvements are expected. While it identifies a gap in the experimental section, the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to infer the specific comparisons and improvements that are being suggested, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of comparison with state-of-the-art (SOTA) methods in the experiments. It highlights the importance of comparing the proposed methods with existing works, such as \"Rubi\" and \"Removing bias in multi-modal classifiers,\" to demonstrate the improvements or contributions of the research. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including comparisons with relevant SOTA methods. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the proposed method enhances performance but notes that this is not surprising, as it introduces more learnable parameters, such as the temperature, which have been proven effective in previous works. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results of the proposed method, noting that the enhancement in performance is not surprising due to the introduction of more learnable parameters, such as the temperature, which have been proven effective in previous works. However, the comment does not specify which part of the paper discusses these experiments or the introduction of learnable parameters, making it weakly grounded. It does specify the issue of the method\\'s performance enhancement not being surprising, but it lacks detailed guidance on how to address this observation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the enhancement in performance is not surprising because the proposed method introduces more learnable parameters, such as the temperature, which have been proven effective in previous works. However, the comment lacks specific references or detailed explanations of these previous works, making it difficult for the authors to fully understand the basis of the claim. The absence of explicit evidence or references results in the comment being somewhat verifiable, as it provides a general rationale but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the proposed method enhances performance but notes that this is not surprising, as it introduces more learnable parameters, such as the temperature, which have been proven effective in previous works. While the comment provides a rationale for the observed performance enhancement, it lacks actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this observation or enhance the novelty of their work. As a result, the comment is barely helpful, as it provides some insight but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment criticizes the inclusion of neuroscience research as an inspiration, describing it as unnecessary and distracting to the main processing pipeline of the main work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should remove the neuroscience inspiration, integrate it more effectively, or address any potential issues related to its inclusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the inclusion of neuroscience research as an inspiration, describing it as unnecessary and distracting to the main processing pipeline of the main work. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the neuroscience research is integrated or what specific aspects are distracting. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research is unnecessary and distracting to the main processing pipeline of the main work. However, the comment lacks any supporting evidence, reasoning, or examples to justify why this inspiration is considered unnecessary or distracting. Without specific details or references to substantiate the claim, it remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment criticizes the inclusion of neuroscience research as an inspiration, describing it as unnecessary and distracting to the main processing pipeline of the main work. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the integration of neuroscience research into their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add information about the source dataset in the caption of Table 3. This direct request provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment also suggests that image and table captions should include all necessary information, providing additional guidance on how to enhance the clarity of the paper. The feedback is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, adding information about the source dataset in the caption. The comment provides clear guidance on what information is missing and how to improve the clarity of the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the caption of Table 3 is unclear about the source dataset used. The reviewer provides a specific request to add information about the source dataset in the caption, which is a clear and actionable suggestion. However, the comment does not provide further justification or examples to support why this information is necessary or how it would improve the clarity of the table. While the suggestion is logical, the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific issue with Table 3, namely the lack of clarity regarding the source dataset in the caption. It suggests that the authors add information about the source dataset to the caption, ensuring that all necessary details are included in the table or image captions. This guidance is valuable as it helps the authors improve the clarity and completeness of their presentation, making it easier for readers to understand the experimental setup. The comment also acknowledges the overall quality of the paper, which adds a positive note to the feedback. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive by suggesting how to present this information effectively. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of explicit descriptions of the specific architectures of the value network, policy networks, and uncertainty aware networks used in the paper. This makes it difficult for readers to replicate and evaluate the approach. The comment implies that the authors should provide detailed descriptions of these architectures to improve the clarity and reproducibility of their work. However, it does not explicitly instruct the authors to include these descriptions, nor does it provide guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer the need for detailed descriptions and may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the lack of explicit descriptions of the specific architectures of the value network, policy networks, and uncertainty aware networks used in the paper. This makes it difficult for readers to replicate and evaluate the approach. However, the comment does not specify which sections or parts of the paper should include these descriptions, making it weakly grounded. The comment is specific in identifying the issue of missing architectural details, but without clear grounding, the authors may struggle to determine where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of explicit descriptions of the specific architectures of the value network, policy networks, and uncertainty aware networks makes it difficult for readers to replicate and evaluate the approach. This claim is somewhat verifiable as it highlights a potential issue with the clarity and reproducibility of the paper. However, the comment does not provide specific examples or detailed reasoning to support why these descriptions are necessary or how they would improve the paper. The authors would need to infer the importance of these descriptions and how to address them, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of explicit descriptions of the specific architectures of the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the applicability of the approach. The comment highlights a critical area for improvement, which is crucial for the paper\\'s reproducibility and impact. However, it does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending where to include these descriptions or what level of detail is necessary. While the feedback is clear in identifying a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the assumptions made in the paper, specifically regarding the applicability of EMCTS to real complex problems. It highlights three assumptions: that the transition model P is true, that $Q^\\\\pi$ is linear, and that the learned models are consistent. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to make the assumptions more reasonable. The feedback lacks concrete steps or recommendations, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific assumptions made in the paper, such as the assumption that the transition model P is true and that $Q^\\\\pi$ is linear. It also mentions the assumption that the learned models are consistent. However, it does not explicitly mention which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing the assumptions that are considered unreasonable in many cases, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the assumptions made in the paper, specifically regarding the applicability of EMCTS to real complex problems. It highlights three assumptions: that the transition model P is true, that $Q^\\\\pi$ is linear, and that the learned models are consistent. The reviewer suggests that these assumptions may not be reasonable in many cases. However, the comment lacks specific examples, references, or detailed reasoning to support why these assumptions are problematic or how they impact the applicability of EMCTS. This makes the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific assumptions made in the paper, such as the assumption that the transition model P is true and that $Q^\\\\pi$ is linear, and questions their applicability to real complex problems. It also points out that the learned models are assumed to be consistent, which may not be reasonable in many cases. While the comment highlights potential weaknesses in the assumptions, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their assumptions. The feedback is somewhat helpful as it prompts the authors to reconsider their assumptions, but it lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider the relationship between explicitness (E) and size (S) in relation to the given dataset. It also implies that the different capacity requirements mentioned in the third paragraph might be due to input modality differences. The comment provides a clear direction for the authors to evaluate disentanglement by ensuring sufficient capacity and training time, which is powerful enough to achieve the DCI evaluation. Additionally, it suggests considering the training time, cost, and learning rate if the capacity of probing needs to be evaluated. While the comment provides a clear action, it lacks specific guidance on how to implement these suggestions, such as which specific aspects of the dataset or evaluation process to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as the relationship between explicitness (E) and size (S) in relation to the dataset, the potential influence of input modality differences on capacity requirements, and the need to consider training time, cost, and learning rate when evaluating disentanglement. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a relationship between explicitness (E) and size (S) in relation to the given dataset, and it provides a logical reasoning for this claim by mentioning the different capacity requirements due to input modality differences. The comment also suggests that the evaluation of disentanglement should provide sufficient capacity and training time to achieve the desired outcome. However, the claim lacks specific examples or references to support the reasoning, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a thoughtful analysis of the relationship between explicitness (E) and size (S) in the context of a given dataset. It suggests that the different capacity requirements mentioned in the third paragraph might be due to input modality differences. The comment also offers a clear and actionable suggestion for evaluating disentanglement, recommending that sufficient capacity and training time be provided to achieve the desired outcome. Additionally, it advises considering factors like training time, cost, and learning rate if the capacity of probing needs to be evaluated. This feedback is detailed and constructive, offering the authors specific guidance on how to improve their analysis and evaluation process. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper title should not include abbreviations. This is a clear and direct action for the authors to take, leaving no ambiguity about what needs to be changed. The comment is specific and provides a concrete suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the paper title, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of abbreviations in the title. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper title should not include abbreviations. However, it does not provide any reasoning or justification for why this is the case. Without supporting evidence or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a straightforward and actionable suggestion regarding the paper title, advising against the use of abbreviations. This feedback is clear and specific, offering a simple yet effective way for the authors to improve the presentation of their work. By following this advice, the authors can enhance the readability and accessibility of their paper. However, the comment could be more helpful if it explained why abbreviations are not recommended or suggested alternative ways to present the title. Despite this, the feedback is mostly helpful as it directly addresses a specific aspect of the paper that can be easily improved.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: whether the discriminator can transfer to other tasks and domains without further training, and whether it can be effectively trained with very little data. It also mentions an important insight at line 400 regarding the discriminator\\'s size. However, the comment does not provide explicit actions or suggestions for the authors to address these points. The questions are implicit, and while the comment highlights an important insight, it lacks concrete guidance on how to incorporate this insight or address the questions. As a result, the authors may struggle to determine what specific changes or additions are needed to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, such as a particular section, figure, or table. It raises questions about the discriminator\\'s transferability and training with limited data, but it does not provide specific details or examples to guide the authors in addressing these issues. Additionally, the comment mentions an important insight at line 400, but it does not specify what that insight is or how it relates to the broader discussion. Without clear references or detailed guidance, the authors cannot effectively understand or respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the discriminator\\'s transferability and training with limited data, and mentions an important insight at line 400. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claims or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two questions about the discriminator\\'s capabilities: whether it can transfer to other tasks and domains without further training, and whether it can be effectively trained with very little data. It also mentions an important insight at line 400 regarding the discriminator\\'s size, which is a positive observation. However, the comment lacks specificity and actionable guidance on how the authors might address these questions or incorporate the insight into their work. Without detailed suggestions or examples, the feedback is limited in its utility for improving the draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the current SOTA GNN-QE as a baseline and to compare it with their approach. This direct and specific suggestion provides clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies exactly which baseline should be added and how it should be compared. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the omission of the current SOTA GNN-QE from the baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition and comparison of the GNN-QE baseline. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current SOTA GNN-QE is omitted from the baselines, despite being the closest work in terms of components to the approach. This claim is somewhat verifiable as it highlights a potential oversight in the paper\\'s comparison to relevant work. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, such as why the GNN-QE is considered the closest work or how its inclusion would impact the study. Providing more detailed justification or examples would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, specifically the lack of comparison with the current state-of-the-art GNN-QE. It highlights that this baseline, which is the closest work in terms of components, should be included and compared. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by expanding their baseline comparisons. By addressing this point, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional guidance on how to integrate this comparison or discussed its potential impact on the results. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of pretraining data for GPT-2, questioning whether it can truly understand language and suggesting that the setting may not be reasonable if the facts were learned before training. The reviewer expresses a willingness to raise the score to strong accept if these concerns are addressed successfully. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The action is implicit and vague, as the authors are left to infer what specific changes or clarifications are needed to address the reviewer\\'s concerns. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the use of pretraining data for GPT-2, questioning whether it can truly understand language and suggesting that the setting may not be reasonable if facts were learned before training. However, it does not specify which part of the paper these concerns pertain to, such as specific sections, experiments, or results. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the concerns about the pretraining data and its implications but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of pretraining data for GPT-2, questioning whether it can truly understand language and suggesting that the setting may not be reasonable if facts were learned before training. The reviewer acknowledges the interest of the topic but emphasizes the importance of addressing these concerns to validate the findings. However, the comment lacks specific examples, references, or detailed reasoning to support the claims about the pretraining data and its implications. This makes the claim somewhat verifiable, as it provides a logical basis for concern but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of pretraining data for GPT-2, questioning whether it can truly understand language and suggesting that the setting may not be reasonable if facts were learned before training. The reviewer acknowledges the interest of the topic but emphasizes the importance of addressing these concerns to validate the findings. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it highlights a critical area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the explanation of the proposed method, noting the absence of computation details for some terms in equation (4) and the optimization algorithm. It suggests that if mathematical expressions are used, every term should be clearly explained, except for obvious cases. This feedback provides explicit actions for the authors to take, such as clarifying the computation of terms in (4) and explaining the optimization algorithm. The comment is specific and provides clear guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific equation, \"(4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the explanation, such as the missing computation of some terms and the optimization algorithm, particularly the calculation of $p(x_k|d)$. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of terms in equation (4) and the optimization algorithm. The reviewer provides a logical reasoning by stating that if mathematical expressions are used, every term should be clearly explained, except for obvious cases. This reasoning is based on a common expectation in academic writing, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar works where such explanations are provided, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the proposed method, particularly in the explanation of equation (4) and the optimization algorithm. It highlights the need for detailed explanations of all terms used, except for obvious cases. This feedback is clear and actionable, as it provides the authors with a direct area to improve their draft by ensuring that all mathematical expressions are thoroughly explained. By addressing this point, the authors can enhance the comprehensibility and rigor of their work. However, the comment could be more helpful if it offered suggestions on how to present the explanations or provided examples of clear explanations. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where implementation details are lacking, such as the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It emphasizes the importance of providing these details to ensure reproducibility and to assess the fairness and significance of the experimental results. The comment explicitly states that a thorough description of the implementation details is needed to address these issues. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific aspects of the paper that need improvement, such as the implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details that affect reproducibility and the ability to assess fairness and significance of comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details makes the experimental results non-reproducible and difficult to assess the fairness of comparisons. The reviewer provides a logical reasoning by highlighting the importance of implementation details for reproducibility and fairness assessment. However, the comment does not provide specific examples or references to support the claim, such as which implementation details are missing or how they affect the comparisons. This makes the claim somewhat verifiable, as it requires further detail to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. This omission makes the experimental results non-reproducible and hinders the ability to assess the fairness and significance of the comparisons. The comment provides clear and actionable feedback by recommending a thorough description of the implementation details to address these issues. This guidance is valuable for the authors as it directs them to a specific area needing improvement, which is crucial for the credibility and impact of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides an observation about the concept of using a mixture of experts (MoE) for a task, noting that it is not groundbreaking in terms of its fundamental idea. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors\\' work or suggestions for improvement. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the concept of using a mixture of experts (MoE) in various tasks, such as general LLM, summarization, and machine translation. It mentions that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not specify which part of the paper this observation pertains to, making it weakly grounded. Additionally, while it provides some context about the concept of MoE, it lacks specificity regarding what aspects of the paper need improvement or clarification. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the concept of using a mixture of experts (MoE) for a task is not groundbreaking, as it has been extensively applied in various tasks like general LLM, summarization, and machine translation. The comment provides a logical reasoning by referencing the widespread use of MoE in different domains, which supports the claim that the application of MoE in text detection is not novel. However, the comment could be strengthened by providing specific examples or references to studies where MoE has been used in these other tasks, which would make the claim fully verifiable. As it stands, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a general observation about the concept of using a mixture of experts (MoE) in various tasks, noting that its application in text detection is relatively new but not groundbreaking. While this comment offers some context, it lacks specificity and actionable feedback that would help the authors improve their draft. It does not identify any particular weaknesses or suggest ways to enhance the originality or impact of the work. As a result, the comment is not particularly helpful for guiding the authors in making improvements to their paper.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim significant performance improvement for SpaceTGN over other baselines but do not provide a statistical analysis to support this claim. While the comment identifies a gap in the paper, it does not explicitly instruct the authors to conduct a statistical analysis or suggest how to do so. The action is implicit, as the authors can infer that they need to include a statistical analysis to support their claim, but it remains vague because it does not specify what kind of analysis is required or how to conduct it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the performance improvement of SpaceTGN over other baselines. However, it does not explicitly mention which part of the paper this claim is made in, such as a particular section or table where the performance comparison is discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in pointing out the lack of statistical analysis to support the claim of significance, but it lacks full grounding as it does not pinpoint the exact location in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim of significant performance improvement by SpaceTGN over other baselines, noting the absence of a statistical analysis to support this claim. While the comment identifies a gap in the paper, it does not provide specific examples or references to substantiate the need for a statistical analysis. This makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim significant performance improvement for SpaceTGN over other baselines but do not provide a statistical analysis to support this claim. This feedback is valuable as it highlights a gap in the paper that needs to be addressed to strengthen the argument. However, the comment could be more helpful if it suggested how the authors might conduct a statistical analysis or what specific metrics or tests could be used to support their claim. While it points out an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment identifies a potential source of confusion regarding the scores in the paper, specifically questioning why some scores are excerpted versus reproduced. However, it does not provide explicit guidance on how the authors should address this issue or clarify the confusion. The action is implicit, as the authors can infer that they need to provide more information or clarification, but it remains vague because it lacks specific instructions on how to resolve the confusion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a potential source of confusion regarding the scores in the paper, specifically questioning why some scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact location that needs attention. While the comment is specific in its critique of the scores, it is not grounded because it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about potential confusion regarding the scores in the paper, specifically questioning why some scores are excerpted versus reproduced. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this confusion might arise or how it could be addressed. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion regarding the scores in the paper, specifically questioning why some scores are excerpted versus reproduced. This feedback highlights an area that may need clarification, which is valuable for the authors to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to resolve the confusion or improve the clarity of the presentation. While it points out an issue, it does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to elaborate on the novelty of consistency models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the method by comparing it to consistency models and generative models. However, it does not specify which part of the paper discusses these models or where the authors should provide additional commentary. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment does specify what needs to be addressed, namely, how consistency models achieve something that previous generative models cannot, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is \"somewhat simply applying consistency models in place of other generative models for learning target distributions,\" suggesting limited novelty. The reviewer supports this claim by stating that consistency models are a recent trend and implying that the method does not offer significant innovation. However, the comment lacks specific examples or references to substantiate the claim about the lack of novelty. Without detailed evidence or comparisons to other generative models, the claim remains somewhat verifiable, as it provides a logical basis but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the method, suggesting that it is merely an application of consistency models in place of other generative models. It encourages the authors to provide more commentary on how consistency models achieve something that previous generative models cannot. This feedback is somewhat helpful as it highlights a specific area where the paper could be improved by providing a clearer justification for the novelty of the approach. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation metric used in Table 2, MSE, does not adequately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for alternative metrics or improvements. The authors are left without guidance on how to address this issue or what specific changes they should make to improve the evaluation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that MSE does not adequately reflect the accuracy of nowcasting. This provides clear guidance on what aspect of the evaluation needs to be reconsidered or improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric used in Table 2, MSE, does not adequately reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why MSE is insufficient for this purpose. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that MSE (Mean Squared Error) may not adequately reflect the accuracy of nowcasting. This is a relevant observation that could impact the interpretation of the results. However, the comment does not provide any suggestions or guidance on alternative metrics or how the authors might address this issue. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the empirical evaluation does not adequately support the claimed benefit of FFA-LoRA on differential privacy (DP). It notes that the performance gap between vanilla LoRA and FFA-LoRA remains the same across various privacy budgets, including zero, suggesting that the impact of DP noise is the same for both methods. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the empirical evaluation. The feedback lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP), specifically noting the lack of performance gap between vanilla LoRA and FFA-LoRA across various privacy budgets, including zero. This provides a clear indication of the part of the paper being discussed, allowing the authors to identify the relevant section. The comment is also specific in detailing the issue with the empirical evaluation and the implications of the observed results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well-supported by empirical evaluation. It provides specific observations about the performance gap between vanilla LoRA and FFA-LoRA across various privacy budgets, including zero, suggesting that the impact of DP noise is the same for both methods. This reasoning is based on empirical observations and logical deductions, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the claim fully. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the empirical evaluation of the proposed method, FFA-LoRA, in the context of differential privacy (DP). It points out that the performance gap between vanilla LoRA and FFA-LoRA remains the same across various privacy budgets, including zero, suggesting that the impact of DP noise is the same for both methods. This feedback is valuable as it highlights a potential flaw in the empirical evaluation that could affect the interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their empirical evaluation. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add specific components to the ablation study of ENGINE, namely \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" based on the overview model of ENGINE. It also suggests that the authors provide more detailed analysis of the ablation results. The actions are clear and concrete, giving the authors specific guidance on how to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study of ENGINE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding specific components to the ablation study, namely \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" and requests more detailed analysis of the ablation results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study of ENGINE is incomplete and suggests adding specific components to it. However, the comment does not provide any reasoning or evidence to support why these additions are necessary or how they would improve the study. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the ablation study of ENGINE, noting that it is incomplete. It provides a clear and actionable suggestion by recommending the addition of specific components, such as \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" based on the overview model of ENGINE. Additionally, it advises the authors to provide more detailed analysis of the ablation results. This feedback is constructive and offers a concrete direction for improving the draft, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN. It suggests that the authors provide results on more challenging high-resolution datasets like LSUN and ImageNet to make their findings more convincing. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to present the results or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN. It suggests that the authors provide results on more challenging high-resolution datasets like LSUN and ImageNet to make their findings more convincing. The comment is specific in its request for additional results on specific datasets, which provides clear guidance on what needs to be addressed. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. The claim is somewhat verifiable as it references common knowledge that methods that work well with CIFAR-10/Celeb-64 might struggle with LSUN/ImageNet. However, the comment lacks specific examples or references to studies that have demonstrated this challenge, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN. It suggests that the authors provide results on more challenging high-resolution datasets like LSUN and ImageNet to make their findings more convincing. The comment is somewhat helpful as it identifies a potential gap in the experimental validation and suggests a direction for improvement. However, it lacks specific guidance on how to conduct these additional experiments or what aspects to focus on, which limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of a specific statement in Section 5.1, asking, \"Each attribute of the table feature represents a scene\" -- what does this mean? While the comment highlights a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The authors can infer that they need to clarify the meaning of this statement, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1\" and the specific phrase, \"Each attribute of the table feature represents a scene,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for clarification on the meaning of the statement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about a specific statement in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific statement in the paper, specifically, \"Each attribute of the table feature represents a scene.\" This feedback highlights a potential area of confusion or lack of clarity in the manuscript, prompting the authors to clarify their explanation. However, the comment does not provide suggestions or guidance on how to address this issue, nor does it offer insights into why this clarification might be important. While it points out a potential weakness, it lacks actionable advice or depth, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It questions the effectiveness of the logsumexp aggregation compared to direct addition, which would correspond to basic prototype comparison with reweighted averages. Additionally, it notes the compatibility of the token reweighting scheme with existing token-to-token classifiers and expresses uncertainty about the comparison with the logsumexp aggregator. While the comment identifies specific areas that need further exploration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study and provide comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It also raises specific questions about the effectiveness of the logsumexp aggregator compared to direct addition and its compatibility with existing token-to-token classifiers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It questions the effectiveness of the logsumexp aggregator compared to direct addition and expresses uncertainty about its compatibility with existing token-to-token classifiers. While the comment identifies a gap in the paper, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this comparison and how it might impact their work. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It raises a pertinent question about the effectiveness of the logsumexp aggregator compared to direct addition, which is crucial for understanding the contribution of the proposed method. Additionally, the comment highlights the compatibility of the token reweighting scheme with existing token-to-token classifiers, suggesting that the authors should clarify this aspect. This feedback is clear and actionable, providing the authors with specific areas to explore and improve their draft. However, it could be more helpful if it offered suggestions on how to conduct the ablation study or what specific comparisons to make. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using larger-scale datasets to evaluate the effectiveness of ECGs, specifically mentioning datasets from [2]. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on how to incorporate these datasets or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the paper are insufficient and recommends considering larger-scale datasets mentioned in a reference. However, it does not specify which part of the paper discusses the datasets, making it weakly grounded. The comment is specific in suggesting the use of larger-scale datasets and provides references to external works, which could guide the authors in making improvements. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the datasets used in the paper are insufficient to evaluate the effectiveness of ECGs. It suggests considering larger-scale datasets mentioned in a reference, providing a specific citation. This claim is mostly verifiable as it is supported by a reference to external work, which offers a basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how these larger-scale datasets would improve the evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the number of datasets used to evaluate the effectiveness of ECGs. It suggests that the authors should consider larger-scale datasets, specifically referencing a study mentioned in [2]. This feedback is clear and actionable, providing a specific direction for the authors to expand their evaluation by incorporating additional datasets. However, the comment could be more helpful if it included specific guidance on how to integrate these datasets or discussed the potential impact of using larger datasets on the results. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clearly state the limitation of only analyzing fully connected ResNets, which is typically not the case in practice. It also suggests including this limitation in the Broader Impact section. This feedback provides a clear and direct action for the authors to take, specifying both what needs to be done (state the limitation) and where it should be included (Broader Impact section). The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of fully connected ResNets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the limitation of only analyzing fully connected ResNets and the need to clearly state this limitation in the Broader Impact section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is a limitation as ResNets typically use convolutional layers in practice. The reviewer suggests that the paper should clearly state this limitation and include it in the Broader Impact section. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim that convolutional layers are more common in practice. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that it only analyzes fully connected ResNets, which is not typical in practice where ResNets often use convolutional layers. The comment suggests that the paper should clearly state this limitation and include it in the Broader Impact section. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. By highlighting the need to acknowledge the limitation and its implications, the comment offers valuable guidance for enhancing the paper\\'s transparency and relevance. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a general observation about the training of a student model on the training set, specifically mentioning the use of a medium-sized model like ResNet18. It also references standard KD methods that have surpassed reported KD performance. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how this information should influence the authors\\' work or what specific changes or improvements should be made. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the training of a student model on the training set, specifically mentioning the use of a medium-sized model like ResNet18. It provides examples of performance on MNIST, SVHN, and CIFAR10, which helps the authors understand the context. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the training approach and references to standard KD methods, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the performance of training a student model on the training set, specifically mentioning the use of a medium-sized model like ResNet18. It provides examples of performance on MNIST, SVHN, and CIFAR10, which supports the claim. Additionally, it references standard KD methods that have surpassed reported KD performance, providing further evidence. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. Therefore, the comment is mostly verifiable, as it provides some evidence but could benefit from more detailed references or examples to fully support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a general observation about the training of a student model on the training set, specifically mentioning the use of a medium-sized model like ResNet18. It references examples of performance on MNIST, SVHN, and CIFAR10, which could be relevant for the authors to consider. Additionally, it mentions standard KD methods that have surpassed reported KD performance, suggesting that the authors might want to consider these methods. However, the comment lacks specific guidance or actionable suggestions on how to incorporate these observations into the paper or improve the training process. While it provides some insight, it does not offer detailed or constructive feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the causal graph assumption in the proposed framework, specifically questioning whether the assumption that only node attributes affect causal factors would hold for GCN variants like Geniepath or Gated GNN. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or test the robustness of their framework. The comment implies that the authors should consider the impact of these variants on their assumptions, but it lacks concrete steps or recommendations for investigation. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific assumption made by the authors regarding the causal factors and the direction of influence between node attributes and the causal graph. It questions whether this assumption holds for certain GCN variants, such as Geniepath and Gated GNN, which learn messages and passing routes in a coupled manner. However, the comment does not explicitly mention which part of the paper discusses this assumption, making it weakly grounded. The comment is specific in detailing the concern about the causal graph assumption and its potential breakage due to the coupled learning approach of certain GCN variants. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the causal graph assumption in the proposed framework, questioning whether it holds for certain GCN variants like Geniepath and Gated GNN. The reviewer provides a logical reasoning by explaining that these variants learn messages and passing routes in a coupled manner, which could potentially break the causal graph assumption. However, the comment lacks specific references or detailed examples from the cited works (Geniepath and Gated GNN) to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the causal graph assumption in the proposed framework, specifically questioning whether it holds for certain GCN variants like Geniepath and Gated GNN. It highlights a potential issue with the assumption that only node attributes affect causal factors, suggesting that the coupled learning approach of these variants might break the causal graph assumption. This feedback is valuable as it prompts the authors to consider and address a potential limitation of their framework. However, the comment could be more helpful if it provided suggestions on how to test or mitigate this issue or offered examples of how similar assumptions have been addressed in other works. Overall, the comment is somewhat helpful as it identifies a significant area for consideration but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider listing the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This would help readers understand the gap between NAS models and human-engineered SOTA architectures. The comment provides a clear and explicit action for the authors to take, specifying exactly what information should be included to address the concern. The suggestion is concrete, as it outlines a specific way to enhance the paper\\'s analysis and understanding. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim about message-passing being the most important part of GNN, suggesting that different tasks may use different pre-/post-processing modules. The comment further specifies that listing the performance of SOTA algorithms in each dataset discussed would help readers understand the gap between NAS models and human-engineered SOTA architectures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that message-passing is the most important part of GNN, suggesting that different tasks may use different pre-/post-processing modules. The reviewer supports this claim by pointing out that the authors only considered message-passing layers and by suggesting that listing the performance of SOTA algorithms in each dataset discussed would help readers understand the gap between NAS models and human-engineered SOTA architectures. This provides a logical reasoning and a specific suggestion for improvement, making the claim mostly verifiable. However, the comment could be strengthened by providing examples or references to support the assertion about the importance of pre-/post-processing modules. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that message-passing is the most important part of GNN, suggesting that different tasks may use different pre-/post-processing modules. It provides a clear and actionable suggestion by recommending that the authors list the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This would help readers understand the gap between NAS models and human-engineered SOTA architectures, offering a more comprehensive analysis. The feedback is constructive and provides a concrete way for the authors to enhance their draft, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to demonstrate whether learning the advantage directly is useful. It questions the importance of learning the advantage directly compared to other methods, despite the authors making a case for the advantage being a quantity of interest. However, the comment does not provide explicit guidance on how to show this or what specific evidence or analysis should be included to support the claim. The action is implicit and vague, as the authors are left to infer that they need to provide additional evidence or analysis but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests showing whether learning the advantage directly is useful and questions the importance of learning it directly compared to other methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for evidence on the importance of learning the advantage directly, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should demonstrate the usefulness of learning the advantage directly, questioning the importance of this approach compared to other methods. However, the comment lacks specific examples, references, or detailed reasoning to support why learning the advantage directly is considered important. The claim is somewhat verifiable as it raises a valid point but requires more detailed evidence or explanation to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should demonstrate the usefulness of learning the advantage directly, questioning the importance of this approach compared to other methods. While it identifies a potential gap in the paper regarding the justification for learning the advantage directly, it lacks specific guidance or suggestions on how the authors might address this issue. The comment points out a relevant area for improvement but does not provide actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide explanations for the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. This feedback is explicit, as it directly instructs the authors to add explanations for these symbols. However, it does not specify how detailed these explanations should be or what specific information should be included. While the action is clear, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding explanations for the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. However, it does not specify which part of the paper these symbols are used in, making it weakly grounded. The comment is specific in its request for additional explanations, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding explanations for variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. However, it does not provide any specific reasoning or examples to support why these explanations are necessary or how they would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the importance of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding explanations for the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing clarity for readers. However, the comment lacks depth and does not offer detailed guidance on how to present these explanations or why they are important. While it points out a potential weakness, it does not fully support the authors in addressing it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation and that the method may only represent incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the innovation or differentiate their method from existing ones. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the limited performance gains indicate a lack of innovation and that the method may only represent incremental changes to established methods. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what specific aspects of the method are considered incremental or lacking in innovation. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest a lack of innovation and that the method represents only incremental changes to established methods. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or comparisons to other methods, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that the limited performance gains indicate a lack of innovation and that the method may only represent incremental changes to established methods. While it identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback lacks actionable advice or detailed insights that would help the authors understand what aspects of their method need to be enhanced or how they might differentiate their work from existing methods. As a result, the comment is barely helpful, as it points out a concern but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback implies that the authors should include a more comprehensive comparison to better illustrate the strengths and weaknesses of their proposed system. While the action is not explicitly stated, it is clear and concrete, as it specifies the need for a comparative analysis. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where comparisons could be made. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting a particular area for improvement\u2014comparative analysis with existing methods. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not provide specific examples or references to existing methods or systems that could be used for comparison. The claim lacks detailed justification or evidence to support the need for a more comprehensive comparative analysis, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion without sufficient support or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is clear and actionable, as it identifies a specific area for improvement that could enhance the paper\\'s contribution by providing a clearer picture of the proposed system\\'s strengths and weaknesses relative to others. However, the comment could be more helpful if it included specific examples of methods or systems to consider for comparison or suggested how to conduct such an analysis. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the theoretical guarantees of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ and its practical performance on a real dataset, suggesting that its usefulness is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the practical performance or enhance the usefulness of the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"$\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$\" and the \"real dataset (long-range graph benchmark),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods, limiting its practical usefulness. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods, limiting its practical usefulness. However, the comment lacks specific examples or references to existing methods that have better performance, making it difficult for the authors to understand the basis of the claim. Without concrete evidence or comparisons, the claim remains somewhat verifiable, as it requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a discrepancy between the theoretical guarantees of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ and its practical performance on a real dataset, specifically the long-range graph benchmark. It suggests that the method\\'s usefulness is limited due to its inability to outperform existing methods. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the practical performance of their method. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that the target of those algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their draft. The comment lacks actionable guidance, such as recommending alternative comparisons or adjustments to the analysis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that the target of those algorithms is not to find an equilibrium. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how this comparison is unfair or how it should be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents, as the target of those algorithms is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is inappropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the comparison of the proposed algorithm with offline RL algorithms for single agents, suggesting that the target of those algorithms is not to find an equilibrium. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s methodology or analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their comparison. Without actionable advice, the authors are left with a general critique but no clear path to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights an issue with the paper\\'s overlap with prior work, specifically mentioning that the three tasks have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, and recommends more detailed comparisons to similar works. While the comment implies that the authors should provide more detailed comparisons, it does not specify which aspects of the methodology or purpose need clarification or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors know they need to address the overlap but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the overlap with prior work, specifically mentioning three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and suggests that the paper should clarify its unique contributions and provide more detailed comparisons to similar works. However, it does not specify which sections of the paper discuss these tasks or where the comparisons should be made, making it weakly grounded. The comment is specific in its request for more detailed comparisons and clarification of unique contributions, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three tasks mentioned\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. However, it does not provide specific references or examples of these prior benchmarks, making it difficult for the authors to verify the claim. The suggestion to clarify the paper\\'s unique contributions and provide more detailed comparisons to similar works is a logical recommendation, but the lack of specific references or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the overlap with prior work in terms of the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014being partially covered in existing benchmarks. It suggests that the paper should clarify its unique contributions and provide more detailed comparisons to similar works. This feedback is clear and actionable, as it directs the authors to address the overlap and differentiate their work from existing literature. However, the comment could be more helpful if it provided specific examples of how to make these comparisons or suggested areas where the paper could offer novel insights. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and originality of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Section 1 lacks support materials for the statement \"human perception is usually invariant to the texture resampling.\" However, it does not provide specific guidance on what kind of support materials are needed or how the authors should address this issue. The action is implicit, as the authors can infer that they need to add support materials, but it is vague because it does not specify what kind of materials or how to incorporate them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of support materials for the statement \"human perception is usually invariant to the texture resampling.\" This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 1 lacks support materials for the statement \"human perception is usually invariant to the texture resampling.\" However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 1, noting the lack of support materials for the statement \"human perception is usually invariant to the texture resampling.\" This feedback is somewhat helpful as it points out a gap in the paper that needs addressing. However, it lacks depth and does not provide suggestions on how the authors might address this issue or what kind of support materials would be appropriate. To be more helpful, the comment could include examples of what kind of support materials would be beneficial or suggest ways to strengthen the argument. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the applicability of MiPKD to other computer vision (CV) tasks beyond single image super-resolution (SR). It encourages the authors to conduct additional experiments on a broader range of tasks to enhance the method\\'s perceived generalizability. While the comment implies a clear action\u2014conducting additional experiments\u2014it does not provide specific guidance on which tasks to consider or how to design these experiments. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generality of the paper, specifically discussing the applicability of MiPKD to other computer vision (CV) tasks beyond single image super-resolution (SR). However, it does not explicitly mention which part of the paper this discussion is based on, making it weakly grounded. The comment is specific in suggesting that additional experiments on a broader range of tasks could enhance the method\\'s perceived generalizability. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that MiPKD\\'s performance in single image super-resolution (SR) tasks may not be due to its specific design for SR tasks. It encourages the authors to demonstrate the method\\'s applicability to other computer vision (CV) tasks through additional experiments. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that MiPKD is not specifically designed for SR tasks. This makes the claim somewhat verifiable, as it requires further evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s focus on MiPKD\\'s performance in single image super-resolution (SR) tasks, suggesting that MiPKD may not be specifically designed for this task. It encourages the authors to demonstrate the method\\'s applicability to other computer vision (CV) tasks by conducting additional experiments on a broader range of tasks. This feedback is clear and actionable, providing a specific direction for the authors to enhance the perceived generalizability of their method. However, it could be more helpful if it offered suggestions on which additional tasks to consider or how to design these experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Equations 21 and 22, which describe an alternative scheme, may be omitted without affecting the flow of the section. This is an explicit suggestion, as it directly instructs the authors to consider removing these equations. However, the comment does not provide further details on why these equations are not used or how their omission might impact the section. While the action is clear, the lack of additional context or rationale makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the specific parts of the paper being addressed, which provides full grounding. It also specifies the issue by suggesting that these equations may be omitted without affecting the flow of the section, providing clear guidance on what could be revised. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equations 21 and 22 describe an alternative scheme that is not used and suggests they may be omitted without affecting the flow of the section. However, the comment does not provide any supporting evidence or reasoning to justify why these equations are unnecessary or how their omission would not impact the section. Without additional context or explanation, the claim is not verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Equations 21 and 22 describe an alternative scheme that is not used and suggesting that they may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it provides a direct suggestion for simplifying the manuscript by removing unnecessary content. However, the comment could be more helpful if it explained why these equations are not used or how their omission might impact the overall structure or understanding of the section. Despite this, the comment still offers valuable guidance for improving the draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is based on traditional approaches, making it seem incremental. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the concern about the model being incremental or suggest improvements to make it more innovative. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the optimization module and its use of a simple iteration strategy to optimize two loss functions. It suggests that the overall model is based on traditional approaches and appears incremental. However, the comment does not specify which part of the paper discusses the optimization module, making it weakly grounded. The comment is specific in its critique of the model\\'s reliance on traditional approaches, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the optimization module relies on a simple iteration strategy and suggests that the overall model is based on traditional approaches, making it seem incremental. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or comparisons to other models, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions, suggesting that the overall model is based on traditional approaches and appears incremental. While this observation identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from traditional approaches. The comment does not provide actionable feedback or detailed insights that would help the authors improve their draft. As a result, the comment is barely helpful, as it highlights a concern but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper can be improved and questions the choice of F(X) for the E(d) case. It asks for elaboration on how to construct F(X) in the main paper and suggests that the authors do the same for the other two cases in the appendix. While the comment provides a clear action\u2014elaborating on the construction of F(X)\u2014it does not specify how the authors should present this information or what specific aspects need clarification. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper can be improved and questions the choice of F(X) for the E(d) case. It also asks for elaboration on how to construct F(X) in the main paper and suggests doing the same for the other two cases in the appendix. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where these concepts are discussed. The comment is specific in detailing what needs to be addressed, such as providing more detailed examples on constructing F(X). Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing of the paper can be improved and questions the choice of F(X) for the E(d) case. It asks for elaboration on how to construct F(X) in the main paper and suggests doing the same for the other two cases in the appendix. However, the comment lacks specific reasoning or examples to support why the current explanation is unclear or how the suggested elaboration would improve the paper. Without detailed justification or examples, the claim is not verifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the writing and clarity of the paper. It questions the choice of F(X) for the E(d) case and asks for elaboration on how to construct F(X) in the main paper, suggesting that the authors provide detailed examples for the other two cases in the appendix. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and comprehensibility of their work. By addressing these points, the authors can significantly improve the readability and understanding of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the implicit assumptions the paper adopts to make few-shot learning successful. While it suggests that assumptions like meta-distribution or distribution-closeness might be relevant, it does not explicitly instruct the authors to address these assumptions or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and clarify these assumptions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the assumptions, such as meta-distribution or distribution-closeness, but it does not provide detailed guidance on how to address these assumptions or where they might be discussed in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the implicit assumptions the paper adopts for few-shot learning to be successful. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the implicit assumptions the paper adopts to make few-shot learning successful. It mentions potential assumptions like meta-distribution or distribution-closeness, which are relevant to the field. However, the comment does not provide specific guidance or suggestions on how the authors might address these assumptions or clarify them in their paper. While it prompts the authors to consider these assumptions, it lacks actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks in the literature to facilitate comparison with prior work. While the comment implies specific actions, such as expanding the scope of comparisons and including additional benchmarks, it does not provide detailed guidance on how to implement these suggestions. The authors can infer the need for additional comparisons and benchmarks, but the lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks in the literature to facilitate comparison. However, the comment does not specify which part of the paper this feedback pertains to, such as specific sections or tables where comparisons are made. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed\u2014expanding the scope of comparisons and including more standard benchmarks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks in the literature to facilitate comparison. While the comment identifies areas for improvement, it lacks specific examples or references to prior work that could be used for comparison. This makes the claim somewhat verifiable, as the authors would need to infer which tasks or benchmarks should be included to enhance the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the comparison to prior work could be more thorough. It recommends considering other tasks and large-scale models, as well as providing results for more standard benchmarks in the literature. This feedback is clear and actionable, as it guides the authors on how to enhance the comprehensiveness and relevance of their comparisons. By following this advice, the authors can strengthen the context and impact of their work within the existing literature. However, the comment could be more helpful if it provided specific examples of tasks or benchmarks to consider, which would offer even more detailed guidance. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment describes the manuscript as an experimental discovery paper and notes that the proposed method is similar to a traditional removal method. However, it does not provide any specific guidance or suggestions on how the authors could improve the contribution of their manuscript. The comment lacks actionable details, such as recommending ways to enhance the contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the manuscript as being more like an experimental discovery paper and notes that the proposed method is similar to a traditional removal method. However, it does not specify which sections or parts of the paper this assessment is based on, making it difficult for the authors to identify the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution need improvement or how it could be enhanced. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the manuscript for being more like an experimental discovery paper and notes that the proposed method is similar to a traditional removal method. It suggests that the contribution of the manuscript could be improved. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the contribution or differentiate their work from existing methods. Without detailed guidance or constructive criticism, the authors are left without a clear path for improvement. Therefore, the comment is not particularly helpful in guiding the authors to enhance their draft, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity and support of the claimed benefits, particularly Benefit 1, which is described as too abstract and lacking contextual detail. It also points out that Benefit 3 includes broad statements without supporting references. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to clarify and substantiate these benefits, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific claims about the benefits of understanding the agent\\'s performance post-training, particularly focusing on Benefit 1 and Benefit 3. It critiques Benefit 1 as being too abstract and lacking contextual detail, and it points out that Benefit 3 includes broad statements without supporting references. However, the comment does not specify which sections of the paper these benefits are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors might have an idea of where these benefits are mentioned, the comment lacks full grounding. It is specific about the issues with the claims but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the benefits of understanding the agent\\'s performance post-training are difficult to grasp, specifically mentioning that Benefit 1 is too abstract and lacks contextual detail. It also critiques Benefit 3 for including broad statements without supporting references. While the comment identifies specific issues with the claims, it lacks detailed reasoning or examples to fully substantiate the critique. The mention of \"big and complex problems\" without specific references or examples makes it challenging for the authors to understand the basis of the critique. Therefore, the comment is somewhat verifiable, as it provides some insight but lacks comprehensive support, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and support of the claimed benefits of the paper. It points out that Benefit 1 is too abstract and lacks contextual detail, which makes it difficult for the authors to understand and address. Additionally, it critiques Benefit 3 for including broad statements without supporting references, such as those related to \"big and complex problems.\" While the comment highlights areas for improvement, it does not provide detailed suggestions or examples on how to clarify or substantiate these benefits. The feedback is somewhat helpful as it directs the authors to specific weaknesses in their claims, but it could be more beneficial with additional guidance on how to address these issues. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for judging effectiveness. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include quantitative results, but it does not specify how to do so or what kind of quantitative analysis would be appropriate. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for judging effectiveness. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in its request for quantitative results and provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that qualitative results are impressive but insufficient for judging effectiveness. The reviewer suggests that quantitative results would provide a more robust evaluation. However, the comment does not provide specific examples or references to support the claim that quantitative results are necessary or how they would enhance the evaluation. This lack of detailed justification makes the claim somewhat verifiable, as it provides a logical suggestion but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that qualitative results alone may not be sufficient for judging effectiveness. This feedback is clear and actionable, as it directs the authors to include quantitative results to strengthen their evaluation. However, the comment could be more helpful by suggesting specific metrics or methods for presenting quantitative results. Overall, the comment provides valuable insight into an area needing improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the categorization of the paper under the topic of Fairness/Accountability/Transparency. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should reconsider the categorization, provide additional context, or address any potential misunderstandings. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the categorization of the paper under the topic of Fairness/Accountability/Transparency. However, it does not specify which part of the paper this question pertains to, such as the introduction, methodology, or discussion sections. Additionally, it lacks specificity regarding what aspects of the paper might be considered inappropriate for this category. Without clear grounding or specificity, the authors cannot effectively understand or address the concern. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the categorization of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the categorization of the paper under the topic of Fairness/Accountability/Transparency. While it highlights a potential issue with the paper\\'s categorization, it does not provide any specific guidance or suggestions on how the authors might address this concern or clarify the paper\\'s focus. The comment lacks actionable feedback or detailed insights that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential issue but does not offer a clear path for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a machine learning 2-step baseline when comparing their approach to baselines. The reviewer implies that the improvement could be due to the different class of algorithm rather than the authors\\' assertion that NaviFormer beats baselines due to its joint tackling of routing and path planning. While the comment provides a clear action\u2014adding a specific type of baseline\u2014it does not offer detailed guidance on how to implement this suggestion or what specific aspects of the baseline should be considered. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a machine learning 2-step baseline when comparing approaches to baselines, implying that the improvement could be due to the different class of algorithm rather than the authors\\' assertion. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors might infer that it relates to the comparison of methods, but this inference is not direct. The comment is specific in suggesting a particular type of baseline to include, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the improvement observed in the paper could be due to the different class of algorithm used, rather than the authors\\' assertion that NaviFormer beats baselines due to its joint tackling of routing and path planning. The comment implies that including a machine learning 2-step baseline would provide a better comparison. However, the claim lacks specific examples or references to support the assertion that the improvement is solely due to the algorithm class. This makes the comment somewhat verifiable, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the proposed method (NaviFormer) to baselines, suggesting that the improvement could be due to the different class of algorithm rather than the authors\\' assertion that NaviFormer outperforms baselines due to its joint tackling of routing and path planning. The comment provides a clear and actionable suggestion to include a machine learning 2-step baseline, which would help clarify the source of the improvement. This feedback is valuable as it guides the authors to strengthen their experimental setup and analysis, offering a concrete way to address the critique. However, the comment could be more helpful if it provided additional guidance on how to implement the suggested baseline or discussed potential challenges in doing so. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This feedback provides a clear and explicit action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The suggestion is concrete, as it outlines a specific approach to address the concern about the comparison with other methods. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results appear better than other compared methods but questions whether this is due to the better image generative model. It recommends a fair comparison by applying the planning and layering method to the design image generated by other image generative models. However, the comment does not specify which part of the paper this comparison should be applied to, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the results by suggesting that the improvement might be due to the better image generative model. It recommends a fair comparison by applying the planning and layering method to the design image generated by other image generative models. However, the comment lacks specific examples or references to support the claim that the results are not due to the image generative model. This makes the claim somewhat verifiable, as it provides a logical suggestion for improvement but lacks detailed justification or evidence to fully substantiate the initial claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of the results, questioning whether the observed improvements are due to the better image generative model rather than the planning and layering method. It provides a clear and actionable suggestion by recommending a fair comparison, specifically suggesting the application of the planning and layering method to the design image generated by other image generative models. This feedback is constructive and offers a concrete way for the authors to address the concern, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the comparative study should include state-of-the-art (SOTA) methods, providing specific examples of works that should be considered. This direct suggestion gives the authors a clear action to take, which is to expand their comparative study to include these SOTA methods. The comment also critiques the claim made by the authors, suggesting that the lack of comparison with SOTA methods undermines the justification for their claim. The feedback is specific and actionable, providing concrete guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparative study and the proposed method, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of state-of-the-art (SOTA) methods in the comparative study. The comment provides specific examples of SOTA methods that should be considered, which gives the authors clear guidance on how to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative study should include state-of-the-art (SOTA) methods to justify the authors\\' claim about the proposed method. The reviewer supports this claim by providing specific examples of SOTA methods that should be considered, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al., (2019). This detailed list of references provides a robust foundation for the claim, making it fully verifiable. The authors can easily understand the need for these comparisons and the justification for the claim based on the provided examples. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of state-of-the-art (SOTA) methods in the comparative study. It specifically lists several relevant works that should be considered, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al., (2019). This feedback is valuable as it guides the authors to enhance the rigor and relevance of their comparative analysis, which is crucial for substantiating their claims. Additionally, the comment critiques the authors\\' claim about the proposed method, suggesting that the lack of comparison with SOTA methods undermines its justification. This provides the authors with a clear direction for improving the validity of their claims. Overall, the comment is highly helpful as it offers specific and constructive suggestions for enhancing the paper\\'s quality and credibility.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the discussion of a dataset in lines 329-334, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The reviewer suggests that if these details are not relevant, they should not be mentioned. This feedback provides a clear and explicit action for the authors to take\u2014remove irrelevant information from the discussion. The comment is specific and actionable, as it guides the authors on how to improve their draft by ensuring the discussion is relevant and focused. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 329-334,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of a dataset is confusing, specifically mentioning the terms \"opinion holder\" and \"opinion targets\" in the context of plain polarity classification. The reviewer suggests that if these details are not relevant to the experiments, they should not be mentioned. While the comment identifies a potential issue with the clarity of the discussion, it lacks specific examples or references to support the claim that these terms are confusing or irrelevant. The reasoning is somewhat vague, making it somewhat verifiable. The authors would need to further explore the context to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion of a dataset in the paper, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The reviewer suggests that if these details are not relevant, they should not be mentioned in the discussion. This feedback is clear and actionable, as it provides the authors with a direct suggestion to improve the clarity and relevance of their discussion. By addressing this point, the authors can enhance the coherence and focus of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the unnecessary restriction of capsule networks and questions the benefits of enforcing equivariance strictly. It points out that the group CapNet is deeper than the simple CapNet and notes the absence of parameter counts for the group CapNet, which makes it difficult to judge the benefits of enforcing equivariance. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the \"group CapNet\" and the \"simple CapNet,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the necessity of restricting capsule networks and the lack of parameter counts for the group CapNet, which is crucial for judging the benefits of enforcing equivariance. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of restricting capsule networks and suggests that the group CapNet may be unnecessarily deep. It also notes the absence of parameter counts for the group CapNet, which makes it difficult to judge the benefits of enforcing equivariance. While the comment raises valid concerns, it lacks specific examples or references to support the claim about the depth of the group CapNet or the benefits of enforcing equivariance. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment continues the discussion from a previous point, questioning the necessity of restricting capsule networks and the depth of the group CapNet compared to the simple CapNet. It highlights the lack of parameter counts for the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. While the comment identifies a potential issue and points out a gap in the experimental setup, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it prompts the authors to consider the depth and parameter counts of their models, but it lacks actionable advice or detailed insights that would make it more helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific challenge discussed in the paper regarding obtaining meaningful gradients with respect to noisy images and mentions that this issue has been addressed in various approaches, such as DiME and FastDiME. It also references a paper by He et al. However, the comment does not provide explicit guidance or suggestions on how the authors should address this challenge in their work. While it acknowledges existing approaches, it lacks actionable advice for the authors to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it discusses the challenge of obtaining meaningful gradients with respect to noisy images and references specific approaches like DiME, FastDiME, and He et al. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the challenge of obtaining meaningful gradients with respect to noisy images, as discussed in the paper. It references existing approaches such as DiME, FastDiME, and He et al., which have addressed this issue by computing gradients with respect to denoised images. The comment provides specific references to external works, which helps substantiate the claim that this challenge has been addressed in the literature. However, it could be more fully verifiable by providing more detailed comparisons or examples of how these approaches have been applied. Overall, the comment is mostly verifiable, as it provides a solid foundation for the claim but could benefit from additional detail.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses a specific challenge discussed in the paper regarding the difficulty of obtaining meaningful gradients with respect to noisy images. It acknowledges that this issue has been addressed in various approaches, such as DiME, FastDiME, and He et al., and provides references to these works. This feedback is valuable as it situates the authors\\' work within the context of existing literature and suggests that they consider these approaches or their implementations for addressing the challenge. However, the comment could be more helpful if it provided more detailed guidance on how to integrate these approaches or discussed the potential benefits or drawbacks of doing so. Overall, the comment is somewhat helpful as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an evaluation of inference speed on the hardware. This is an explicit suggestion, as it directly instructs the authors to add a specific type of evaluation. However, it does not provide concrete details on how to conduct this evaluation or what specific aspects of inference speed should be considered. While the action is clear, the lack of detailed guidance makes it somewhat actionable, as the authors know what to do but may need to determine the specifics on their own.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an evaluation of inference speed on the hardware, but it does not specify which part of the paper this evaluation should be added to or how it relates to existing content. The authors might infer that it pertains to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting an additional evaluation, but it lacks grounding as it does not pinpoint a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including an evaluation of inference speed on the hardware would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an evaluation of inference speed on the hardware, which is a relevant and actionable piece of feedback. By recommending this additional analysis, the reviewer highlights an area that could enhance the paper\\'s comprehensiveness and practical relevance. However, the comment could be more helpful if it provided specific guidance on how to conduct this evaluation or what aspects of inference speed should be focused on. Despite this, the feedback is clear and actionable, making it mostly helpful for the authors to consider incorporating this evaluation into their draft. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for the SDP formulation, indicating that the authors should include this information in their draft. The action is direct and clear, as the authors know exactly what is being requested. However, the comment does not provide guidance on how to present the SDP formulation or where it should be included in the paper. While the action is explicit, the lack of detailed instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"modified problem\" and the need for an SDP formulation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the SDP formulation, which is a crucial aspect of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual statement asking for clarification on the SDP formulation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out that the modified problem is described as convex and solvable via an SDP (Semidefinite Programming) but does not provide the SDP formulation. This feedback is clear and actionable, as it directly instructs the authors to include the SDP formulation in their paper. By addressing this point, the authors can improve the completeness and clarity of their work. However, the comment could be more helpful if it provided additional guidance on how to present the SDP formulation or its significance in the context of the paper. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides a specific action for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two issues: the lack of information on the number of new task combinations used to evaluate compositional generalisability and the limited test results in Table 7, which are only from 30 composite instructions. The reviewer clearly states that these aspects need to be addressed, providing direct actions for the authors to take. The feedback is specific and actionable, as it outlines exactly what information is missing and where it should be included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the number of new task combinations used to evaluate compositional generalisability and the limited test results in Table 7. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of compositional generalisability, specifically questioning the number of new task combinations used and the limited test results in Table 7. While the comment highlights a potential issue, it does not provide specific reasoning or evidence to support why these aspects are problematic or how they impact the study. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered borderline verifiable, as it points out an area for improvement but lacks sufficient support or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of information on the number of new task combinations used to evaluate compositional generalisability and the limited test results in Table 7, which are only from 30 composite instructions. This feedback is clear and actionable, as it directs the authors to provide additional details on the evaluation methodology and expand the test results to include more composite instructions. By addressing these points, the authors can enhance the comprehensiveness and robustness of their evaluation, which is crucial for demonstrating the compositional generalisability of their approach. However, the comment could be more helpful if it suggested specific ways to present this information or provided examples of how to expand the test results. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper, particularly the figures, are not well-formatted. However, it does not provide any specific guidance or suggestions on how to improve the layout or what aspects of the layout are problematic. Without concrete details or examples, the authors are left without a clear understanding of what changes are needed to address the issue. As a result, the comment is vague and lacks actionable advice, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper, especially the figures, are not well-formatted. However, it does not specify which figures or sections are problematic, nor does it provide details on what aspects of the layout are lacking. This lack of specificity and grounding makes it difficult for the authors to identify and address the issues effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, are not well-formatted. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what constitutes poor layout, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the paper, particularly the figures, are not well-formatted. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the layout or what aspects of the figures are problematic. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. This lack of specificity and actionable content makes the comment not helpful at all, as it does not assist the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for clear differentiation from existing works and a detailed comparison with similar techniques to avoid the perception of incremental contributions or lack of novelty. However, it does not provide explicit guidance on how the authors should achieve this differentiation or comparison. The comment implies that the authors should include a more detailed analysis or discussion of their work in relation to existing literature, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the need for clear differentiation from existing works and a detailed comparison with similar techniques to avoid the perception of incremental contributions. However, it does not specify which parts of the paper lack this differentiation or comparison, making it difficult for the authors to pinpoint the exact areas that need improvement. While the authors might have an idea of where these comparisons should be included, the comment does not provide full grounding. It is specific about the need for differentiation and comparison but lacks detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s contributions may be perceived as incremental or lacking substantial novelty due to the lack of clear differentiation from existing works and a detailed comparison with similar techniques. This claim is somewhat verifiable as it logically suggests that a lack of differentiation and comparison could impact the perception of the work\\'s value. However, the comment does not provide specific examples of existing works or techniques that should be compared, which would strengthen the justification. Therefore, the claim is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clear differentiation from existing works and a detailed comparison with similar techniques. This is an important point as it could affect the perception of the paper\\'s contributions and its value within the NLP community. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending particular techniques or aspects to focus on for differentiation. While it highlights a significant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explain why the baseline results in Table 2 differ from those in Table 3 of a referenced source, [3]. This is a clear and direct action, leaving no ambiguity about what the authors need to do. The comment provides a specific task, which is to compare and explain the differences in baseline results, making it highly actionable. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Table 2\" and \"Table 3 in [3],\" allowing the authors to accurately identify the parts of the paper being addressed, making it fully grounded. It also specifies the issue by asking for an explanation of the differences in baseline results between the two tables, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the differences in baseline results between two tables. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests an explanation for the differences in baseline results between Table 2 and Table 3 in a referenced source. This feedback is somewhat helpful as it identifies a specific area where the authors need to clarify their work. However, it lacks depth and does not provide suggestions on how to address the issue or why it might be important. The authors are left with a task to investigate and explain the discrepancy, but without additional guidance, they may struggle to determine the significance of this difference or how to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the use of \"execution feedback\" in the title and Figure 2, noting that it is misleading as no execution feedback signal is actually used in the work. The reviewer provides a detailed explanation of the issue, including the assumption that any structural perturbation in the AST results in a failure as execution feedback and the definition of EF in terms of test suite pass/fail. This feedback is explicit and provides concrete guidance on what needs to be clarified or corrected in the paper. The authors are given a clear understanding of the issue and how to address it, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of \"execution feedback,\" explaining that it is misleading because no execution feedback signal is actually used in the work. The comment provides detailed reasoning, including references to specific lines (233-238) and Equation 1, to clarify the misunderstanding. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"execution feedback\" is misleading because it is not actually used in the work. The reviewer provides a detailed explanation, pointing out that execution feedback is approximated based on structural perturbations in the AST and that the authors assume any such perturbation results in a failure as execution feedback. This reasoning is supported by references to specific lines and equations in the paper, providing a clear and logical basis for the claim. The detailed explanation and references make the claim fully verifiable, as it offers a robust foundation for the reviewer\\'s argument.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of \"execution feedback\" in the paper, noting that it is misleading as no execution feedback signal is actually used. The reviewer provides a detailed explanation of the misunderstanding, clarifying that execution feedback is approximated based on structural perturbations in the AST and that the authors assume any such perturbation results in a failure. This feedback is clear and actionable, as it guides the authors to correct the misleading terminology and clarify their methodology. By addressing this point, the authors can improve the accuracy and clarity of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of information regarding the use of \"40 target words\" and the method of using \"a sequence of dots\" to remove bias in the model. It also mentions the absence of details about the number of games sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors can infer that they need to provide more details, but the comment lacks actionable guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the lack of information regarding the use of \"40 target words\" and the method of using \"a sequence of dots\" to remove bias in the model. It also points out the absence of details about the number of games sampled to demonstrate the severity of the bias problem. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the methodology or results sections where these details should be present. The comment is specific in detailing what information is missing, providing clear guidance on what needs to be addressed. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of information regarding the use of \"40 target words\" and the method of using \"a sequence of dots\" to remove bias in the model. It also questions the lack of detail about the number of games sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas where more information is needed, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The absence of detailed justification or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity and detail, particularly regarding the use of \"40 target words\" and the method of using \"a sequence of dots\" to remove bias in the model. It also points out the absence of details about the number of games sampled to demonstrate the severity of the bias problem. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to areas needing clarification, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the experiments are conducted on simple datasets and notes that the use of uniformly random missing is unrealistic in practice. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on whether the authors should use more complex datasets, adjust the experimental setup, or provide additional context or justification for their choice of datasets. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the experiments are conducted on some simple datasets and notes that the use of uniformly random missing is unrealistic in practice. However, it does not specify which part of the paper this observation is based on, nor does it provide details on how the experiments could be improved or what specific issues need to be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments are conducted on \"some simple datasets\" and that the use of uniformly random missing is unrealistic in practice. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the experiments are conducted on simple datasets and notes that the use of uniformly random missing is unrealistic in practice. While it identifies a potential limitation in the experimental setup, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental design. The comment lacks actionable feedback or detailed advice, leaving the authors with only a vague understanding of the problem. Therefore, it is rated as barely helpful, as it highlights an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 4 lacks legends for the plots, making it difficult to interpret. It provides a clear and direct action for the authors to include what each data point or plot corresponds to. This feedback is specific and provides a concrete suggestion for improvement, ensuring that the authors know exactly what needs to be done to enhance the clarity of their figure. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the lack of legends for the plots, and suggests including what each data point or plot corresponds to. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends for the plots, making it difficult to interpret. This is a factual observation about the figure\\'s presentation, which does not require verification. The comment does not express an opinion, judgment, or suggestion that would necessitate verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends for the plots, which makes it difficult to interpret. It provides a clear and actionable suggestion to include what each data point or plot corresponds to, which would significantly improve the figure\\'s clarity and usability. This feedback is precise and offers a straightforward way for the authors to enhance the presentation of their results, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper specifically addresses sequence-to-sequence models and suggests that the general quantization-aware training strategy could be extended to other models. It also asks the authors to highlight any specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models if there are any. While the comment implies that the authors should clarify or highlight any specific benefits, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and identification of specific benefits. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specificity of the paper regarding sequence-to-sequence models and the proposed robustness-aware quantization scheme. It suggests that the general quantization-aware training strategy could be extended to other models and asks for clarification if there are specific benefits for sequence-to-sequence models. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the benefits of the proposed scheme for sequence-to-sequence models. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, such as whether the paper specifically addresses sequence-to-sequence models and if there are benefits to the proposed robustness-aware quantization scheme for these models. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specificity of the paper regarding sequence-to-sequence models and the proposed robustness-aware quantization scheme. It suggests that the general quantization-aware training strategy could be applicable to other models and asks for clarification if there are specific benefits for sequence-to-sequence models. While the comment identifies a potential gap in the paper\\'s focus, it lacks specific guidance or suggestions on how the authors might address this issue or highlight the benefits for sequence-to-sequence models. The feedback is somewhat helpful as it prompts the authors to consider clarifying their work, but it could be more beneficial with additional direction or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to provide more ablation on how the algorithm\\'s behavior and the accuracy of its Q estimates change as the hyperparameter lambda changes. This request is clear and direct, giving the authors a specific action to take. The comment also specifies what aspect of the algorithm should be explored, providing concrete guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2\" and the hyperparameter \"lambda,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more ablation on how the algorithm\\'s behavior and accuracy of its Q estimates change as lambda changes. This provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for more ablation studies on how the algorithm\\'s behavior and accuracy change as the hyperparameter lambda varies. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more ablation studies on how the algorithm\\'s behavior and accuracy change as the hyperparameter lambda varies. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to explore the impact of this hyperparameter on the algorithm\\'s performance. By addressing this point, the authors can enhance the comprehensiveness and robustness of their analysis. However, the comment could be more helpful if it included suggestions on how to conduct these ablation studies or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the base encoder of the proposed model, asking whether it is trained from scratch or if there is a pre-trained model involved. While the question implies that the authors should clarify this aspect in their paper, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question or what information should be included. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the base encoder of the proposed model, asking whether it is trained from scratch or if there is a pre-trained model involved. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the base encoder, but without clear grounding, the authors may struggle to identify where this information should be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the base encoder of the proposed model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the base encoder of the proposed model, asking whether it is trained from scratch or if there is a pre-trained model involved. This is a relevant question that could help clarify the methodology and training process of the model. However, the comment does not provide any suggestions or guidance on how the authors might address this question in their paper. While it identifies a potential area of confusion, it lacks actionable feedback or specific advice on how to improve the draft. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the ethical statement should be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the ethical statement. The comment is concrete, as it outlines specific areas that need to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests extending the discussion to include challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This provides clear guidance on what needs to be addressed to improve the ethical statement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ethical statement is well-written but suggests that it should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these challenges are not adequately addressed. The suggestion is somewhat verifiable, as it offers a direction for improvement but requires the authors to further develop the rationale themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the ethical statement is well-written but suggests that it could be improved by including a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, providing the authors with specific areas to consider expanding upon in their ethical statement. By addressing these points, the authors can enhance the comprehensiveness and relevance of their ethical considerations. However, the comment could be more helpful if it offered examples or guidance on how to incorporate these discussions into the ethical statement. Overall, the feedback is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transformation of variables in equations (13) and (14), specifically asking how $$\\\\hat{m}_t$$ and $$g_t$$ become $$x$$ in equation (14). While the comment highlights a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the transformation process. However, the comment lacks concrete details on how to achieve this clarity, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the transformation of variables from $$\\\\hat{m}_t$$ and $$g_t$$ to $$x$$, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the transformation of variables in equations (13) and (14). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the transformation of variables in equations (13) and (14), specifically asking how $$\\\\hat{m}_t$$ and $$g_t$$ become $$x$$ in equation (14). This is a clear and specific inquiry that highlights a potential area of confusion in the paper. By pointing out this issue, the comment provides the authors with a direct and actionable suggestion to clarify their explanation, which could significantly improve the clarity and understanding of their work. However, the comment could be more helpful if it offered additional guidance or suggestions on how to address this issue. Overall, the comment is mostly helpful as it identifies a specific area for improvement and prompts the authors to provide a clearer explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the length of the mini-batches, tau_t, may be non-integers and suggests that this should be clarified to ensure there are no side effects. It also raises a specific question about what happens if tau_t is much smaller than 1 and questions the validity of the analysis under such conditions. This feedback provides a clear and explicit action for the authors to clarify the potential implications of non-integer mini-batch lengths and to address the validity of their analysis. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"length of the mini-batches tau_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of non-integer mini-batch lengths and raises a question about the potential side effects and the validity of the analysis if tau_t is much smaller than 1. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential side effects of non-integer mini-batch lengths, tau_t, and questions the validity of the analysis if tau_t is much smaller than 1. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that non-integer mini-batch lengths could affect the analysis. The reasoning is somewhat logical, but without detailed evidence or examples, the claim remains somewhat verifiable. The authors would need to further explore and substantiate the implications themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the length of mini-batches, tau_t, which may be non-integers. It suggests that this should be clarified to ensure there are no side effects, and it raises a specific question about what happens if tau_t is much smaller than 1. This feedback is somewhat helpful as it points out a specific area that may need clarification or further investigation. However, it lacks detailed guidance or suggestions on how the authors might address this issue or what specific analyses might be needed to validate the results under these conditions. While it provides some insight into a potential weakness, it does not offer comprehensive or actionable advice, making it somewhat helpful but not fully comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. While it identifies an area that needs attention, it does not provide explicit instructions or concrete steps on how to conduct this examination. The authors are left to infer that they should analyze the computational cost, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the inference cost associated with the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its request to examine the computational cost, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests examining the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. However, the comment does not provide any supporting evidence, examples, or references to justify why this examination is important or how it could impact the paper. Without additional context or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies an important aspect of the SCALE model that requires further examination: the computational cost associated with its inference process. It highlights the need to analyze the computational cost of both STM decoding and LLM decoding, which is a relevant and actionable point for the authors to consider. However, the comment lacks specific guidance or suggestions on how to conduct this analysis or what metrics to focus on. While it points out a critical area for improvement, it does not provide detailed direction, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the use of only a subset of the complete dataset and the lack of performance comparisons with state-of-the-art models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out a peculiar experimental result, where the unsupervised result outperforms the supervised result in the 5th row of Table 2. While the comment identifies these issues, it does not provide explicit guidance on how to address them, such as suggesting specific comparisons or analyses to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a subset of the complete dataset and the lack of performance comparisons with state-of-the-art models, allowing the authors to identify the relevant parts of the paper. It also specifies the issue with the experimental results, particularly the unsupervised result outperforming the supervised result in the 5th row of Table 2. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the article only uses a subset of the complete dataset and lacks performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it mentions a peculiar experimental result where the unsupervised result outperforms the supervised result in the 5th row of Table 2. While the comment identifies specific issues, it lacks detailed reasoning or evidence to support the claim about the dataset subset and the performance comparisons. The mention of the peculiar experimental result is more specific but still lacks detailed explanation or references. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed justification to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper. First, it points out that the article only uses a subset of the complete dataset, which limits the ability to demonstrate the effectiveness of the proposed methods. Second, it highlights the lack of performance comparisons with state-of-the-art models, which is crucial for evaluating the contribution of the work. Additionally, the comment notes a peculiar experimental result, where the unsupervised result outperforms the supervised result in the 5th row of Table 2. While the comment effectively identifies these weaknesses, it does not provide specific suggestions or guidance on how to address them, such as recommending additional experiments or comparisons. This limits the comment\\'s helpfulness, as it offers insight into areas needing improvement but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the phrase \"lacks inherent semantic meaning\" is used but not elaborated upon, suggesting that the authors should provide more explanation or context for this phrase. However, it does not explicitly instruct the authors to do so or offer guidance on how to elaborate on this point. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"lacks inherent semantic meaning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the phrase is not elaborated upon, indicating that the authors should provide more explanation or context for this phrase. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights the use of the phrase \"lacks inherent semantic meaning\" but notes that it is not elaborated upon. This is a factual observation about the content of the paper, as it points out a lack of explanation or elaboration. It does not contain an opinion, claim, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific phrase, \"lacks inherent semantic meaning,\" that is used in the paper but not elaborated upon. By pointing out this omission, the reviewer highlights an area where the authors could provide more context or explanation to enhance the clarity and depth of their work. However, the comment does not offer suggestions on how to elaborate on this phrase or what specific aspects should be addressed. While it provides some direction for improvement, it lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two specific issues: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros. While the comment identifies these areas as needing attention, it does not provide explicit guidance on how the authors should address these issues or what specific details or justifications should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the use of a large number of hidden units and an additional elementwise function, and the treatment of unobserved ratings as zeros. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is lacking in terms of justification and potential bias, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function. It also mentions that treating unobserved ratings as zeros may introduce bias, which is not justified. While the comment identifies potential issues, it lacks specific examples or detailed reasoning to support these claims. The absence of explicit evidence or references makes it challenging for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific areas where the paper lacks sufficient detail and justification: the use of a large number of hidden units and an additional elementwise function, and the treatment of unobserved ratings as zeros. By highlighting these issues, the comment provides the authors with clear directions for improvement, such as providing more detailed explanations or justifications for their methodological choices. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what kind of detail or justification would be beneficial. Overall, the feedback is somewhat helpful as it points out important areas for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a weakness in the claim regarding motivation, suggesting that the high accuracy achieved by MathGLM on a constructed dataset for complex computations could be achieved with 100% accuracy using other tools. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the robustness of their claim. The feedback lacks concrete details on how to strengthen the motivation or provide evidence to support the claim. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim regarding motivation, specifically the high accuracy achieved by MathGLM on a constructed dataset for complex computations. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out that the calculations could be done with 100% accuracy using other tools, providing a clear critique of the claim. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using MathGLM is not robust because the high accuracy achieved on a constructed dataset for complex computations could be attained with 100% accuracy using other tools. However, the comment lacks specific examples or references to these other tools, making it difficult for the authors to fully understand or address the critique. The absence of detailed evidence or comparisons renders the claim somewhat verifiable, as it provides a general critique but lacks the necessary support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s claim regarding motivation, specifically questioning the robustness of the claim that MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations. The comment suggests that these calculations could be done with 100% accuracy using other tools, which challenges the novelty and significance of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their claim. While it highlights an important area for improvement, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a significant weakness in the paper, noting that the reliance on synthetic datasets and evaluation in real-world settings does not truly reflect event-based dense tracking. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their evaluation. There is no guidance on potential modifications, alternative datasets, or additional experiments that could be conducted to better reflect event-based dense tracking. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance on synthetic datasets and the evaluation of event-based optical flow in real-world settings, suggesting that this does not truly reflect event-based dense tracking. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the evaluation approach but lacks grounding in terms of pinpointing the exact section or context where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reliance on synthetic datasets and evaluation in real-world settings does not truly reflect event-based dense tracking, which is a significant weakness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides a general critique but lacks the necessary support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the reliance on synthetic datasets and the evaluation of event-based optical flow in real-world settings. It points out that this approach does not truly reflect event-based dense tracking, which is a critical issue that the authors need to address. However, the comment does not provide specific suggestions or guidance on how the authors might overcome this limitation or improve their evaluation methodology. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the paper\\'s motivation, suggesting that it opposes a widely recognized understanding of the importance of diversity in instruction-tuning data without providing a strong justification. It also criticizes the experiments as weak due to limited dataset and LLM size, and questions the validity of the results. However, the comment does not provide specific guidance on how the authors could strengthen their motivation, improve the experiments, or address the concerns about the results. The feedback lacks actionable steps or suggestions, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper, questioning its alignment with existing research on the importance of diversity in instruction-tuning data. It also critiques the experiments, noting their limitations in dataset and LLM size, and expresses concern about the potential misleading nature of the results. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact areas needing revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issues with motivation and experiments but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s motivation is unclear and opposes a widely recognized understanding of the importance of diversity in instruction-tuning data without providing a strong justification. The reviewer also criticizes the experiments as weak due to limited dataset and LLM size, questioning the validity of the results. While the comment provides some reasoning by referencing common knowledge about the importance of diversity, it lacks specific examples or references to support the claim about the paper\\'s motivation or the weaknesses of the experiments. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s motivation, questioning its alignment with existing research on the importance of diversity in instruction-tuning data. It also critiques the experiments as weak due to limited dataset and LLM size, suggesting that the results may be unconvincing and potentially misleading. While the comment highlights significant weaknesses, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it points out important areas for improvement, but it could be more beneficial with actionable advice or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions why there are no confidence intervals on the substitution ASR in Table 3. While it implies that the authors should include confidence intervals, it does not explicitly instruct them to do so. The action is clear but communicated indirectly, making it mostly actionable. The authors can infer that they need to add confidence intervals, but the comment could be more explicit in its request.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of confidence intervals on the substitution ASR, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the absence of confidence intervals on the substitution ASR in Table 3. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks information, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the absence of confidence intervals on the substitution ASR in Table 3. While it identifies a potential gap in the presentation of results, it does not provide any guidance or suggestions on how the authors might address this issue or why it is important. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how to obtain or estimate the mean element mu_g for different kernel spaces. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify this aspect, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the estimation of the mean element mu_g for different kernel spaces. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem of unclear estimation methods, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of obtaining or estimating the mean element mu_g for different kernel spaces. However, it does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is factual and descriptive in nature. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the estimation of the mean element mu_g for different kernel spaces. This is a clear and actionable piece of feedback, as it highlights a potential gap in the explanation or methodology that the authors need to address. However, the comment does not provide suggestions or guidance on how the authors might clarify this aspect, which limits its helpfulness. While it points out an important issue, it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the experimental setup or discussion, but this inference is not direct. The comment is specific in suggesting a potential improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, the comment does not provide any supporting evidence or reasoning to justify why this would be beneficial or necessary. It lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable due to the absence of supporting information, making it challenging for the authors to address the feedback effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. While it identifies a potential area for improvement, the comment lacks specificity and actionable guidance. It does not explain why considering larger datasets would be beneficial or how it would enhance the study. Additionally, it does not provide suggestions on how to implement this change or what specific aspects of the current dataset might be lacking. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cosine similarity score would be more effective than the Euclidean distance when computing the Decidability. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should explore this alternative, test it, or provide additional analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of cosine similarity score versus Euclidean distance for computing the Decidability. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where these metrics are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests an alternative approach, it does not provide specific guidance or details on how to implement or evaluate this suggestion. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the use of cosine similarity score versus Euclidean distance for computing the Decidability, suggesting that cosine similarity might be more appropriate in biometric verification. However, the comment lacks specific evidence or references to support the claim that cosine similarity is more effective in this context. Without detailed reasoning or examples, the claim remains vague and difficult for the authors to verify or address. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the suitability of using cosine similarity score instead of Euclidean distance for computing the Decidability. While it points out a potential area for consideration, it lacks depth and does not provide specific guidance or suggestions on how the authors might explore this alternative. The comment is somewhat helpful as it prompts the authors to think about an alternative approach, but it does not offer actionable steps or detailed insights that would significantly enhance the draft. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experiments, including the lack of comparison with other methods and the insufficiency of the experimental results to validate the proposed method. However, it does not provide specific guidance on how to address these issues, such as suggesting which methods to compare or how to strengthen the experimental results. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental section of the paper, specifically mentioning the lack of comparison with other counterpart methods and the insufficiency of the experimental results. However, it does not specify which experiments are weak or which sections need improvement, making it difficult for the authors to pinpoint the exact areas that need attention. While the authors might have an idea of where the experiments are discussed, the comment lacks full grounding. It is specific about the issues with the experiments but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are weak due to the lack of comparison with other methods and insufficient results to validate the proposed method. However, the comment does not provide specific examples of other methods that should be compared or detailed reasoning on why the current results are insufficient. This lack of supporting evidence or references makes the claim borderline verifiable, as it provides some indication of the issue but lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the experimental section of the paper, specifically noting the lack of comparison with other methods and the insufficiency of the experimental results to validate the proposed method. This feedback is somewhat helpful as it highlights areas where the paper could be improved, such as by conducting more comprehensive experiments or including comparisons with existing methods. However, the comment does not provide specific suggestions or guidance on how to address these issues, which limits its helpfulness. To be more helpful, the comment could offer actionable advice on how to strengthen the experimental section or suggest specific methods to compare. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an issue with the figures related to completion errors not being referenced in the relevant analysis sections of the appendix. This provides a clear and direct action for the authors to take, which is to ensure that these figures are properly referenced. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the figures related to completion errors, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not referencing these figures in the relevant analysis sections of the appendix. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the lack of references to figures related to completion errors in the relevant analysis sections of the appendix. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures related to completion errors not being referenced in the relevant analysis sections of the appendix. This feedback is clear and actionable, as it directs the authors to ensure that these figures are properly integrated into the analysis sections. By addressing this point, the authors can improve the coherence and completeness of their paper. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these figures into the analysis or suggested alternative ways to present the information. Overall, the comment is mostly helpful as it highlights a clear area for improvement, but it could be more comprehensive with further suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether perplexity is measured on consistent validation sets across different levels. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment lacks concrete details on what needs to be done to clarify this aspect of the paper. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the measurement of perplexity on consistent validation sets across different levels. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where perplexity is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific guidance on what needs to be clarified or improved regarding the validation sets. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the measurement of perplexity on consistent validation sets across levels. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks information, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the consistency of perplexity measurements across different validation sets at different levels. This is a relevant point that could impact the validity and reproducibility of the results. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify their methodology. Without additional context or actionable advice, the authors are left with a vague indication of a potential problem but no clear path to resolution. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion that the setting and algorithm lack originality but acknowledges that the algorithm for graph labelings is efficient and new. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the originality of their work or suggestions for improvement. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this feedback to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides an opinion on the originality of the setting and algorithm, suggesting they are incremental combinations of existing methods. However, it does not specify which parts of the paper this opinion is based on, nor does it provide details on what aspects of the algorithm are considered incremental or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the setting and algorithm lack originality, suggesting they are incremental combinations of existing methods. However, the comment does not provide specific examples or references to support this claim, nor does it elaborate on how the algorithm is similar to existing ones. This lack of detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the setting and algorithm lack originality, suggesting they are incremental combinations of existing methods. However, it also acknowledges that the algorithm for graph labelings is efficient and new, which is a positive observation. The comment does not provide specific suggestions or guidance on how the authors might enhance the originality of their work or differentiate it from existing methods. While it offers some insight into the perceived lack of originality, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about using the state action of the current policy in the target environment as regularization, suggesting that it could harm learning by resulting in a suboptimal state action distribution. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the use of state action in the target environment as regularization, suggesting that it could harm learning. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with using suboptimal state action distributions for regularization. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using the state action of the current policy in the target environment as regularization can harm learning. The reasoning provided is that a suboptimal policy would result in a suboptimal state action distribution used for regularization. While the comment logically explains the potential issue, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the regularization approach used in the paper, specifically the use of the state action of the current policy in the target environment. It suggests that this could harm learning by resulting in a suboptimal state action distribution. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on the base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. While the comment identifies a potential problem and the need for discussion, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they should investigate and discuss the potential negative effects and mitigation strategies. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the objective of the feature compactness loss and sharpness-aware minimization, specifically mentioning their aim to reduce distances among base classes. It raises a concern about the potential negative impact on model performance on the base classes and suggests discussing mitigation strategies if such degradation occurs. However, the comment does not explicitly mention which part of the paper discusses these objectives, making it weakly grounded. The comment is specific in detailing the issue and suggesting a potential area for improvement, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on the base classes. The comment suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. However, the claim lacks specific evidence or examples to support the assertion that this operation could negatively impact performance. The reasoning is based on logical assumptions rather than concrete data or references, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the feature compactness loss and sharpness-aware minimization, suggesting that these operations might negatively impact the model\\'s performance on the base classes. It highlights the importance of discussing how this potential degradation could be mitigated to maintain performance on the base classes. This feedback is clear and actionable, as it directs the authors to consider and address a specific concern that could affect the overall performance of their model. However, the comment could be more helpful if it provided suggestions or examples on how to mitigate the potential issue. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses questions about the insight gained from the work and how to prevent attention collapse in CL. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the insights and address the attention collapse issue, but the comment lacks specific suggestions or details on how to implement these actions. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the insights gained from the work and how to prevent attention collapse in CL. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the questions suggest areas for improvement, they lack specificity in terms of what aspects of the work need to be addressed or how the authors might improve their insights. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of questions asking for clarification and insight into the work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is purely factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two important questions: what is the insight gained from the work to develop new methods, and how to prevent attention collapse in CL. These questions highlight potential gaps in the paper that the authors need to address to improve their work. However, the comment lacks specific suggestions or guidance on how the authors might explore these insights or address the attention collapse issue. While it points out areas for improvement, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. It also suggests that case studies or pilot experiments could illustrate the significance of this influence. While the comment implies that the authors should provide more information or examples to clarify the impact of the CHC model, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the question or what specific information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the \"extensive content\" dedicated to introducing the CHC model within the main content, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the impact of the CHC model on the capabilities of MLLMs and asks for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. Additionally, it suggests the inclusion of case studies or pilot experiments to illustrate the significance of this influence. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. The comment does not make a subjective claim or suggestion but rather seeks further explanation or evidence. It is a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the impact of the CHC model on the capabilities of MLLMs. It asks for clarification on the attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit and suggests that case studies or pilot experiments could illustrate this influence. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or examples to clarify the theoretical and practical implications of their work. By addressing this point, the authors can enhance the clarity and impact of their paper. However, the comment could be more helpful if it offered specific suggestions on how to present these examples or experiments. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider integrating more up-to-date pretraining models to demonstrate the significance and practical usage of their approach. The reviewer provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be integrated into the study. This feedback is explicit and provides concrete guidance on how to enhance the paper by incorporating more recent models. The authors know exactly what needs to be done and have clear examples to follow, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"pretraining model, Pre-GNN (Hu et al., 2020),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests integrating more up-to-date pretraining models to showcase the significance and practical usage of the approach. The comment provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which can guide the authors in updating their model selection. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pretraining model, Pre-GNN, is outdated and suggests integrating more recent models to demonstrate the significance and practical usage of the approach. The reviewer supports this claim by providing specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which are cited as examples of more powerful models. This provides a clear and specific reference to recent advancements in the field, making the claim fully verifiable. The inclusion of specific references and examples strengthens the justification, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the pretraining model, Pre-GNN, is relatively old compared to more recent advancements in the field. It suggests that integrating more up-to-date pretraining models could enhance the significance and practical usage of the approach. The reviewer provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be considered for integration. This feedback is clear and actionable, offering the authors concrete steps to improve their draft by aligning their work with current trends and methodologies. The inclusion of specific references provides a solid foundation for the authors to explore and incorporate these updates, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the potential engineering challenge associated with the model\\'s input, which involves taking the difference between current object pose and target object pose. However, it does not provide any explicit or implicit suggestions for how the authors might address this challenge or improve their approach. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to mitigate the challenge. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the potential engineering challenge associated with the model\\'s input, which involves taking the difference between current object pose and target object pose. The comment further acknowledges the authors\\' documentation of their approach in the mentioned section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the potential engineering challenge associated with the model\\'s input, which involves taking the difference between current object pose and target object pose. The reviewer acknowledges that the authors have documented their approach well in Section A.3. However, the comment does not provide specific examples or detailed reasoning to support the claim about the engineering challenge. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the potential engineering challenge associated with the model\\'s input, which involves taking the difference between current object pose and target object pose. It highlights the difficulty of object segmentation and pose tracking in the real world. However, the comment also commends the authors for documenting their approach well in Section A.3. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this challenge or improve their approach. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, leaving the authors with only a partial understanding of how to enhance their work. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more downstream performance of their controllable text generation models, specifically mentioning the need to connect the proposed models to real NLG applications and demonstrate the advantage of their model. The reviewer explicitly recommends style transfer as a potential starting point. While the comment provides a clear action for the authors to take, it lacks specific guidance on how to implement the suggested improvements, such as which downstream tasks to focus on or how to effectively demonstrate the model\\'s advantages. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more downstream performance of their controllable text generation models and recommends considering style transfer as a potential application. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance of their controllable text generation models, specifically mentioning the need to connect the proposed models to real NLG applications and demonstrate the advantage of their model. The reviewer recommends style transfer as a potential starting point. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that style transfer would be a beneficial approach. This makes the claim somewhat verifiable, as it provides a direction but requires more detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by recommending that the authors demonstrate the downstream performance of their controllable text generation models. It encourages the authors to connect their proposed models to real-world natural language generation (NLG) applications and highlights style transfer as a potential starting point. This feedback is valuable as it guides the authors on how to enhance the practical relevance and impact of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the test set performance on GLUE datasets and questions whether the labels are available to the public. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do to address this confusion or clarify the issue. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about the test set performance on GLUE datasets and questions whether the labels are available to the public. However, it does not specify which part of the paper this confusion pertains to, such as a specific section or table where the test set performance is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the test set performance is unclear or why the availability of labels is relevant. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses confusion about the test set performance on GLUE datasets and questions whether the labels are available to the public. However, it does not provide any supporting evidence, reasoning, or references to justify this confusion or the need for clarification. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the confusion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the test set performance on GLUE datasets, specifically questioning whether the labels are available to the public. While it highlights a potential issue that the authors should address, it lacks depth and does not provide specific guidance or suggestions on how to clarify this aspect of the paper. The comment points out a potential area of concern but does not offer actionable steps for the authors to improve their draft. Therefore, it is somewhat helpful, as it identifies a problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 could be shortened because many equations are not original to the work and are already well-known in the community. The reviewer implies that this would free up space to include missing important details. While the action is implicit, it is clear and concrete, as it specifies what the authors should do: shorten Section 3.2 to make space for more relevant content. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests shortening the section due to the inclusion of well-known equations that are not original to the work. The comment further specifies that this would free up space to include missing important details. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 could be shortened because many equations are not original to the work and are already well-known in the community. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to the well-known equations in question. Including such details would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that Section 3.2 could be shortened because many equations are not original to the work and are already well-known in the community. This feedback is somewhat helpful as it provides a clear suggestion for streamlining the paper by focusing on original contributions rather than repeating well-known equations. However, the comment could be more helpful if it offered specific examples of equations that could be removed or suggested alternative ways to present the material. Overall, the feedback provides a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the evaluation method used between automatic and human evaluation in specific figures and a table. While it highlights a potential area of confusion, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors can infer that they need to clarify or provide details about the evaluation methods used. However, the comment lacks concrete instructions on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3, Table 3, and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks a clear question about the evaluation method used between automatic and human evaluation. This provides the authors with a precise area to address and clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the evaluation method used in specific figures and a table. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the evaluation method used between automatic and human evaluation in specific figures and a table. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is somewhat helpful as it points out a specific area that needs clarification, but it lacks depth and actionable advice, leaving the authors with only a vague direction for improvement. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the understanding of the coverage rate and its relation to the theorem. It asks the authors to clarify whether the reviewer\\'s understanding is correct and, if not, what additional assumptions are needed to achieve the desired coverage rate. While the comment implies that the authors should address the issue of coverage rate and its assumptions, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper, \"1 -> 0.9, t=5: 0.9 -> 1, \u2026,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the understanding of the coverage rate and its relation to the theorem, asking for clarification or additional assumptions to achieve the desired coverage rate. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the understanding of the coverage rate and its relation to a theorem. It does not make a subjective claim or suggestion but rather seeks clarification. The comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the understanding of the coverage rate and its relation to a theorem, specifically questioning whether the reviewer\\'s interpretation is correct. It also seeks clarification on additional assumptions needed to achieve the desired coverage rate. While the comment identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their explanation. The feedback is somewhat helpful as it prompts the authors to reconsider their explanation and potentially revise it, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using a single translator per language may not be sufficient to produce accurate annotations, as different translators often make different choices. However, it does not provide explicit guidance on how to address this issue or suggest alternative approaches. The comment implies that the authors should consider using multiple translators or other methods to ensure consistency, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the use of a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the potential for different translators to make different choices. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results section, making it weakly grounded. Additionally, while it identifies a potential problem, it lacks specificity in detailing how this issue could be addressed or improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that using a single translator per language may not be sufficient due to the potential for different translators to make different choices. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general observation without sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a concern about the use of a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the potential for different translators to make different choices. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern, such as recommending the use of multiple translators or alternative methods to ensure consistency. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps for improvement, leaving the authors with only a general idea of what might be lacking. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a question asking for clarification about the statement \"people wear a hat and play guitar not vice-versa.\" However, it does not provide any explicit or implicit action for the authors to take. The comment lacks context and does not suggest any changes or improvements to the draft. As a result, the authors are left without any guidance on how to address this point, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, leaving the authors unable to identify the exact section or context being referred to. Additionally, the comment lacks specificity as it does not provide any details about what needs to be addressed or improved. Without clear grounding or specificity, the authors cannot effectively understand or respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about a statement. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of a question asking for clarification about a statement. It does not provide any constructive feedback, suggestions, or critique that would help the authors improve their draft. The comment lacks context and does not offer any actionable advice or insights, making it unhelpful for the authors. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the number of examples (2000) may be insufficient for the model to learn the transformation correctly. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this issue, such as increasing the number of examples, adjusting the model architecture, or providing additional training data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the number of examples (2000) may be insufficient for the model to learn a transformation correctly. However, it does not specify which part of the paper this issue pertains to, such as a particular section, experiment, or analysis. Without explicit references or detailed context, the authors cannot confidently determine which part of the paper needs attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"2000 examples may be insufficient for the model to learn this transformation correctly.\" However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of the number of examples (2000) for the model to learn a transformation correctly. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue. Without additional context or detailed feedback, the authors are left without a clear understanding of what changes, if any, are needed to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about Algorithm 1, specifically asking how it differs from variational inference and what advantages it offers. While the questions imply that the authors should provide an explanation or comparison, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by questioning how Algorithm 1 differs from variational inference and what advantages it offers. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and comparison with variational inference. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the relationship between Algorithm 1 and variational inference, specifically asking how Algorithm 1 differs from variational inference and what advantages it offers. This is a relevant point that could help the authors clarify and differentiate their approach from existing methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it prompts the authors to consider an important aspect of their work, it lacks actionable feedback that would help them make concrete improvements. Therefore, the comment is somewhat helpful, as it identifies an area for clarification but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the entailment exercise lacks basic details and suggests that it should be removed from the paper or provided with more empirical and analyzed information. This feedback is clear and provides a direct action for the authors to take, either by removing the exercise or enhancing it with additional details. The comment is specific in its guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the entailment exercise, which allows the authors to identify the specific part of the paper being discussed. However, it lacks specificity regarding which details are missing or how the exercise could be improved. The suggestion to remove it or provide more empirical and analyzed information is vague and does not offer clear guidance on what specific changes are needed. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details, making it difficult to assess the efficacy of the technique. The reviewer suggests that the exercise should be removed or provided with more empirical and analyzed information. However, the comment does not provide specific examples or detailed reasoning to support why the exercise is inadequate or how it could be improved. This lack of detailed justification makes the claim borderline verifiable, as it provides some insight but lacks the necessary depth to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details and is insufficient for assessing the efficacy of the technique. The reviewer suggests that the exercise should be removed or provided with more empirical and analyzed information. This feedback is clear and actionable, as it directs the authors to either revise the exercise or consider its removal, which could significantly improve the clarity and focus of the paper. However, the comment could be more helpful if it provided specific suggestions on how to enhance the exercise or what additional information should be included. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, describing it as ambiguous. This provides a clear and direct action for the authors to take, which is to clarify the mathematical expression to remove the ambiguity. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 225 and line 227,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue with the mathematical expression of the Gaussian distribution, indicating that it is ambiguous. This provides clear guidance on what needs to be clarified or corrected in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution in lines 225 and 227 is ambiguous. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, describing it as ambiguous. This feedback is clear and actionable, as it directs the authors to clarify the mathematical expression to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the expression or examples of what might be causing the ambiguity. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and guides the authors toward enhancing the clarity of their manuscript. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using only certain types of tokens is insufficient for testing and implies that additional types of responses should be considered. However, it does not provide specific guidance on which additional types of responses should be included or how to incorporate them into the testing process. The action is implicit and vague, leaving the authors without clear instructions on how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that using only certain types of tokens is insufficient for testing and implies that additional types of responses should be considered. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what additional types of responses should be considered. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that using only certain types of tokens is insufficient for testing and suggests considering additional types of responses. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the testing approach, specifically that using only certain types of tokens may not be sufficient. It suggests that additional types of responses should be considered, which is a valuable observation that could help the authors broaden their testing scope. However, the comment lacks specificity and does not provide detailed guidance on which additional types of responses should be included or how to incorporate them into the testing process. While it identifies a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the privacy protection capability of the paper, specifically questioning the effectiveness of using ChatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their approach to privacy protection. The comment lacks actionable guidance, such as recommending alternative methods or providing specific steps for enhancing privacy protection. As a result, the authors are left without a clear understanding of what changes, if any, are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the privacy protection capability of the paper, specifically questioning the effectiveness of using ChatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue with the privacy protection capability and provides a rationale for why the current approach may not be sufficient. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient, specifically questioning the effectiveness of using ChatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. The comment provides a logical reasoning by suggesting that merely relying on these methods may not effectively achieve text sanitization. However, it lacks specific examples or references to support the claim, such as studies or evidence showing the limitations of these methods in ensuring privacy. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the privacy protection capability of the paper, specifically questioning the effectiveness of using ChatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. It highlights a potential weakness in the approach, suggesting that merely relying on these methods may not effectively achieve text sanitization. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach to privacy protection. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the approach in sentimental analysis is not significant enough, but it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or improve the manuscript. There is no explicit or implicit action for the authors to take, leaving them without direction on how to address the issue of novelty. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the novelty of the approach in sentimental analysis is not significant enough, particularly regarding the use of word embeddings to define the weight of lexicon terms. This provides clear guidance on what aspect of the paper needs improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the approach in sentimental analysis is not significant enough, particularly regarding the use of word embeddings to define the weight of lexicon terms. However, the comment lacks specific examples or references to support this claim, such as comparisons to existing methods or studies that have already used similar approaches. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a perceived lack of novelty in the manuscript\\'s approach to sentimental analysis, specifically regarding the use of word embeddings to define the weight of lexicon terms. However, the comment does not provide any specific suggestions or guidance on how the authors might enhance the novelty or improve the manuscript. Without actionable feedback or detailed critique, the authors are left without a clear path to address the issue of novelty. Therefore, the comment is not particularly helpful in guiding the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should compare its method to non-NeRF methods on the tasks mentioned. This provides a clear and direct action for the authors to take, which is to include such comparisons in their draft. The suggestion is concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method to non-NeRF methods on the tasks mentioned, which provides a clear direction for improvement. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the comparison with non-NeRF methods, but lacks explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from comparing its method to non-NeRF methods to better understand its advantages. However, the comment does not provide specific examples or references to non-NeRF methods that should be considered for comparison. This lack of detailed justification or examples makes it difficult for the authors to fully understand the basis of the suggestion and how to implement it effectively. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary detail to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific improvement by recommending a comparison of the proposed method with non-NeRF methods on the tasks mentioned. This feedback is clear and actionable, as it provides a concrete way for the authors to enhance the comprehensiveness and clarity of their work. By comparing their method to conventional approaches, the authors can better demonstrate the advantages and limitations of their approach, which is crucial for readers to understand the contribution of the paper. However, the comment could be more helpful if it provided examples of specific non-NeRF methods to consider or discussed potential challenges in making such comparisons. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of the term \"NLU\" throughout the paper, questioning whether some of the lower-level tasks should be considered syntactic tasks instead. However, it does not provide explicit guidance on how the authors should address this issue or clarify the terminology. The comment implies that the authors should reconsider their terminology, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (178:181) and provides a reference to a specific work, \"LINSPECTOR: Multilingual Probing Tasks for Word Representations,\" which helps the authors identify the part of the paper being addressed. It also raises a specific concern about the use of the term \"NLU\" throughout the paper, questioning whether some of the lower-level tasks should be considered syntactic tasks. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of the term \"NLU\" throughout the paper, questioning whether some of the lower-level tasks should be considered syntactic tasks. The reviewer supports this claim by referencing a specific work, \"LINSPECTOR: Multilingual Probing Tasks for Word Representations,\" which provides a context for understanding the distinction between morphological and syntactic probing tasks. This reference helps substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or further elaboration on how the terminology is used in the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology used in the paper, specifically questioning whether some of the lower-level tasks should be considered syntactic tasks rather than NLU tasks. It also references a specific work, \"LINSPECTOR: Multilingual Probing Tasks for Word Representations,\" which could provide context for the authors to clarify their terminology. While the comment highlights an area for improvement, it lacks detailed guidance on how the authors should address this issue or clarify their terminology. The feedback is somewhat helpful as it points out a potential misunderstanding but could be more beneficial with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should briefly discuss the relationship of their idea to traditional attempts in motion segmentation, specifically mentioning the use of long-term motion trajectories. While the comment implies that this discussion would enhance the theoretical and academic value of the approach, it does not provide explicit instructions on how to incorporate this discussion or what specific aspects should be covered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of long-term motion trajectories and the distinction between Eulerian and Lagrangian views, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it suggests that the authors should briefly discuss the relationship of their idea to traditional attempts in motion segmentation, providing a clear direction for improvement. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using long-term motion trajectories is a traditional idea in computer vision, particularly for motion segmentation. The reviewer supports this claim by referencing a specific work by Keuper et al. (2015) as an example. This reference provides a clear and explicit example of the traditional use of long-term motion trajectories, making the claim fully verifiable. The inclusion of a specific reference strengthens the justification, allowing the authors to understand the basis of the critique and potentially address it effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment acknowledges the novelty of using Eulerian vs. Lagrangian views for temporal motion representations but suggests that the authors could enhance the theoretical and academic value of their approach by briefly discussing the relationship of their idea to traditional attempts in motion segmentation. This feedback is clear and actionable, providing a specific direction for the authors to strengthen their paper by situating their work within the existing literature. By addressing this point, the authors can improve the depth and context of their contribution, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the problem formalization section, specifically regarding the description of task types on graph data. It points out that the section focuses more on formalizing challenges rather than conveying the authors\\' task objectives. However, the comment does not provide explicit guidance on how to improve this section or what specific changes should be made to better align it with its intended purpose. The action is implicit, as the authors can infer that they need to clarify the task objectives and focus more on describing the task types, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the section, noting the lack of a clear description of the specific task types addressed on graph data and the focus on formalizing challenges rather than conveying the authors\\' task objectives. This provides clear guidance on what needs to be addressed to improve the section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks clarity in describing the specific task types addressed on graph data, focusing instead on formalizing challenges. The comment suggests that the section fails to convey the authors\\' task objectives, making it inconsistent with its intended purpose. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of explicit examples or references to external works or standards makes the claim somewhat verifiable, as it requires more detailed justification to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It points out that the section primarily focuses on formalizing challenges rather than conveying the authors\\' task objectives, which makes it inconsistent with its intended purpose. This feedback is clear and actionable, as it directs the authors to clarify the task objectives and better align the section with its intended purpose. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or examples of what information should be included. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. It suggests that such a study would help assess the specific impact of these techniques and compare YOSO\\'s performance with other models that might use them. While the comment implies that an ablation study should be conducted, it does not provide explicit instructions or detailed guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and determine how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically referencing \"Informative Prior Initialization (IPI)\" and \"v-prediction.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014a detailed assessment of the impact of these training techniques and a comparison with other models that might use them. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their impact and compare YOSO\\'s performance with other models. This claim is somewhat verifiable as it logically suggests that an ablation study would provide a clearer understanding of the techniques\\' impact. However, the comment lacks specific examples or references to other models that could benefit from these techniques, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of assessing the impact of these techniques and their potential benefits for other models. By emphasizing the need for an ablation study, the comment provides clear and actionable feedback that can guide the authors in improving their draft. However, the comment could be more helpful if it offered specific suggestions on how to conduct the ablation study or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues: redundant descriptions in the paper and the lack of a small-scale validation experiment. It explicitly suggests that the authors should remove redundant descriptions and conduct a small-scale validation experiment. The feedback provides clear and concrete actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, ensuring they can effectively address the reviewer\\'s feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (229 to 272) and provides a clear indication of the issue, which is redundant descriptions of the motivation and work approach. It also suggests a specific action, which is to present a small-scale validation experiment using datasets mentioned in the paper. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the content of the paper is limited and redundant, providing specific examples by referencing lines 229 to 272. This allows the authors to identify the exact sections that are redundant. Additionally, the suggestion to conduct a small-scale validation experiment is based on the acknowledgment of the lack of domain knowledge in LLMs for specific tasks. While the comment provides some reasoning, it lacks detailed examples or references to support the claim of redundancy. Therefore, the claim is mostly verifiable, as it provides a basis for the critique but could benefit from more detailed evidence or examples. This aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: redundancy in the content and the lack of a small-scale validation experiment. It provides clear examples of redundant descriptions, allowing the authors to pinpoint and address these issues. The suggestion to conduct a small-scale validation experiment is actionable and relevant, given the acknowledgment of the lack of domain knowledge in LLMs for specific tasks. This feedback is clear, actionable, and constructive, offering the authors specific guidance on how to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the theoretical contributions section to clarify how the provided theory supports the proposed method. It also specifies that the set of segregated feature vectors for backdoored versus clean data seems artificial and not directly related to EigenGuard. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the theoretical contributions section, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed: the need to clarify how the provided theory supports the proposed method and the artificial nature of having segregated feature vectors for backdoored versus clean data. This provides clear guidance on what the authors need to revise. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and unclear in their connection to the proposed method. The reviewer suggests that having segregated feature vectors for backdoored versus clean data seems artificial and not directly related to EigenGuard. However, the comment lacks specific examples or detailed reasoning to support why the theory is considered abstract or how it could be better integrated with the proposed method. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the theoretical contributions, describing them as too abstract and unclear in their connection to the proposed method. It specifically points out the artificial nature of having segregated feature vectors for backdoored versus clean data and suggests that this does not directly relate to EigenGuard. The comment provides a clear and actionable suggestion to rewrite the section to clarify the connections between the theory and the proposed method. This feedback is valuable as it guides the authors on how to improve the clarity and relevance of their theoretical contributions, making it mostly helpful. However, it could be further improved by offering more specific guidance on how to restructure the section or what aspects to focus on. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, specifically mentioning that the GCN implementation might be difficult to reproduce without the original code. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify their plans regarding code release, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. However, it does not specify which part of the paper this issue is discussed in, such as the methodology or results sections. The authors might infer that it relates to the methodology or supplementary materials, but this inference is not direct. The comment is specific in its concern about code release and the difficulty in reproducing the GCN implementation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases where code release was critical for reproducibility or examples of how the authors\\' descriptions and supplement information might not be sufficient. This makes the claim somewhat verifiable, as it highlights an issue but does not fully substantiate it with detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. While it acknowledges that the authors\\' descriptions are detailed and there is additional information in the supplement, it still highlights a potential issue with reproducibility. This feedback is somewhat helpful as it identifies a critical area for improvement, but it lacks specific suggestions or guidance on how the authors might address this concern. To be more helpful, the comment could suggest ways to enhance the clarity or provide additional details in the paper or supplement to facilitate reproducibility. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of using second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. While it raises a valid question, it does not provide explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should consider using the differential functions, but it lacks concrete instructions or details on how to implement this change. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of using second-order Taylor expansions instead of the differential functions themselves, providing a clear direction for the authors to consider an alternative approach. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of using second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. However, it does not provide any justification or reasoning for why this choice might be problematic or how using the differential functions would be beneficial. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. This is a relevant point that could impact the accuracy and validity of the mathematical analysis presented in the paper. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or why it is important. Without additional context or actionable advice, the authors are left with only a vague indication of a potential problem. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with Table 3, noting that the recall on lemmas/forms seen in training is missing for the en-cs BPE to character results. It provides references to related works that could be relevant to address this issue. However, the comment does not explicitly instruct the authors to include the missing recall or suggest how to incorporate these references into their work. The action is implicit, as the authors can infer that they need to address the missing recall, but it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of missing recall on lemmas/forms seen in training for the en-cs BPE to character results. Additionally, it provides references to related works that could be relevant to address this issue, which further clarifies the specific aspect that needs attention. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 3 is missing the recall on lemmas/forms seen in training for the en-cs BPE to character results. This claim is supported by references to related works, which provide a basis for the expectation that this information should be included. The references to specific studies suggest that the omission is a common issue in similar contexts, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that the recall on lemmas/forms seen in training is missing for the en-cs BPE to character results. This is a clear and actionable piece of feedback, as it highlights a gap in the presented data that the authors can address to improve the completeness and accuracy of their results. Additionally, the comment provides references to related works, which could be useful for the authors to consider in addressing this issue. However, the comment could be more helpful if it included suggestions on how to incorporate these references or additional guidance on how to present the missing data. Overall, the comment is mostly helpful as it provides a clear direction for improvement and includes relevant references, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim that better word-alignment improves many-to-many translation and questions why the proposed method has no impact on the MLSC setup, as shown in Table 3. While it highlights a potential inconsistency or lack of explanation in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide an explanation for the observed results, but it lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the claim that better word-alignment improves many-to-many translation and why the proposed method has no impact on the MLSC setup, as shown in Table 3. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation by pointing out that the proposed method has no impact on the MLSC setup, as shown in Table 3. The comment highlights a discrepancy between the claim and the observed results, suggesting that the authors should provide an explanation. However, the comment does not provide specific reasoning or evidence to support the claim that better word-alignment should impact the MLSC setup. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to address the comment effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the claim that better word-alignment improves many-to-many translation, specifically questioning why the proposed method has no impact on the MLSC setup as shown in Table 3. It points out that Section 4 touches on this issue but does not provide an explanation. This feedback is somewhat helpful as it identifies a potential inconsistency or lack of clarity in the paper, prompting the authors to address this gap. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or offered insights into potential explanations. Overall, the comment provides a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the method, specifically that it requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the applicability of their method. The feedback lacks actionable details, such as recommending ways to adapt the method for online settings or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a limitation of the method, specifically its requirement for pre-collected offline datasets and its inability to be applied in an online setting. However, it does not specify which part of the paper discusses the method or its assumptions, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the method is discussed, the comment lacks full grounding. It is specific about the issue of offline datasets and online applicability, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting, requiring pre-collected datasets and limiting its applicability in online settings. This claim is somewhat verifiable as it logically points out a limitation of the method based on the assumption of offline datasets. However, the comment lacks specific examples or references to support the claim fully, such as comparisons with other methods that operate in online settings. This makes it challenging for the authors to fully understand and address the issue, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation of the method, specifically its restriction to an offline setting and the requirement for pre-collected datasets. This feedback highlights a potential weakness in the applicability of the method, which could limit its practical use. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or adapt their method for online settings. While it points out an important area for consideration, the lack of actionable advice or detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of the learned representation is insufficient because it is limited to the linear evaluation setting. It implies that the authors should consider additional downstream tasks, such as fine-tuning, detection, and segmentation, as reported in the literature. While the comment provides a clear direction for expanding the evaluation, it does not specify which specific tasks should be included or how to implement them. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the learned representation, specifically mentioning that it was only evaluated in the linear evaluation setting. It suggests that this is insufficient and recommends considering other downstream tasks, such as fine-tuning, detection, and segmentation, as reported in the literature. However, the comment does not specify which part of the paper discusses the evaluation of the learned representation, making it weakly grounded. The suggestion to consider additional tasks is specific, but without clear grounding, the authors may struggle to identify where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient because it is limited to the linear evaluation setting. The reviewer suggests that additional downstream tasks, such as fine-tuning, detection, and segmentation, should be considered. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that these tasks are necessary or commonly used in the literature. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the learned representation, noting that it is only assessed in the linear evaluation setting. It suggests that this is insufficient and recommends considering additional downstream tasks, such as fine-tuning, detection, and segmentation, as reported in the literature. This feedback is clear and actionable, providing the authors with a specific direction for expanding their evaluation to provide a more comprehensive understanding of the learned representation. However, the comment could be more helpful if it included examples or references to specific tasks or studies that could be used for evaluation. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their evaluation framework.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment criticizes the novelty of the work, stating that stage-wise and progressive training methods have been widely used for a long time. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty of their work. The comment lacks actionable details, such as recommending new approaches, alternative methods, or specific areas for innovation. As a result, the authors are left without a clear understanding of what steps to take to address the concern about novelty. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, specifically mentioning stage-wise and progressive training methods, which have been used for a long time. However, it does not specify which part of the paper discusses these methods, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these methods are discussed, the comment lacks full grounding. It is specific about the issue of novelty but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is low, specifically mentioning that stage-wise and progressive training methods have been used for a long time and are common in many contexts. However, the comment does not provide specific examples or references to substantiate this claim, nor does it offer detailed reasoning or evidence to support why these methods, as used by the authors, lack novelty. This lack of supporting information makes the claim difficult for the authors to verify and address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment criticizes the novelty of the work, stating that stage-wise and progressive training methods have been widely used for a long time and are not novel in the context of the paper. However, the comment does not provide specific suggestions or guidance on how the authors could enhance the novelty of their work or differentiate it from existing methods. Without actionable feedback or constructive advice, the authors are left without a clear path to address the concern about novelty. Therefore, the comment is not particularly helpful in guiding the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the applicability of the analysis to more general cases, specifically asking whether it can handle more general Markov chains and what if there is FFN and nonlinearity on top of the attention layer. While these questions imply that the authors should consider and address these aspects in their analysis, they do not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to explore these questions or what specific analyses should be conducted. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the applicability of the analysis to more general cases, specifically asking whether it can handle more general Markov chains and what if there is FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the analysis and the potential impact of additional components, but without clear grounding, the authors may struggle to identify where these questions should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the applicability of the analysis to more general cases and the handling of specific scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the generalizability of the analysis presented in the paper. It asks whether the analysis can be extended to more general Markov chains and what would happen if there is FFN and nonlinearity on top of the attention layer. These questions prompt the authors to consider the broader applicability and robustness of their work, which is valuable for improving the comprehensiveness and impact of their findings. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or explore these scenarios, which limits its helpfulness. While it identifies areas for further exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the discussion of reference [19] in section 3.1 and line 57, noting that it is not clear whether [19] uses the same Fine state automaton or if there is a difference. This implies that the authors should clarify this aspect in their paper. However, the comment does not explicitly instruct the authors to make this clarification or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding whether [19] uses the same Fine state automaton or if there is a difference. This provides clear guidance on what needs to be clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the discussion regarding reference [19] in section 3.1 and line 57, specifically whether it uses the same Fine state automaton or if there is a difference. However, the comment does not provide any supporting evidence or reasoning to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding reference [19] in section 3.1 and line 57. It points out that it is not clear whether [19] uses the same Fine state automaton or if there is a difference. This feedback is somewhat helpful as it highlights a potential area of confusion that the authors need to address to improve the clarity of their paper. However, the comment could be more helpful if it provided suggestions on how to clarify this point or offered examples of how similar issues have been addressed in other papers. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in algorithm 1, noting that it requires intermediate gradients for each domain, which might consume a significant amount of memory. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or mitigate the memory requirements. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to alleviate the memory burden. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the auto_weight scheme, noting that it requires intermediate gradients for each domain, which might consume a lot of memory. The comment further supports this claim by referencing relevant literature, providing additional context and justification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the memory requirements of the auto_weight scheme in algorithm 1, noting that it involves intermediate gradients for each domain. The reviewer supports this claim by referencing two external works, \"FedGP: Buffer-based Gradient Projection for Continual Federated Learning\" by Dai et al. (2023) and \"FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings\" by Terrail et al. (2022). These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in algorithm 1, noting that it requires intermediate gradients for each domain, which might consume a significant amount of memory. This is a relevant concern that could impact the practicality and scalability of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or optimizations to reduce memory requirements. While it highlights an important area for consideration, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer specific guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that the backbone is constrained to a double LSTM while popular transformers are not involved. It suggests that the application of this method to more extensive model structures remains a potential concern. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or expand their approach to include transformers. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Since the comment is vague and does not offer a clear path for action, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitation of the paper in not involving popular transformers, despite the backbone being constrained to a double LSTM. It suggests that the application of the method to more extensive model structures is a potential concern. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation and suggesting a potential area for improvement, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the backbone is constrained to a double LSTM, while popular transformers are not involved, and suggests that this limitation could be a concern for more extensive model structures. The comment acknowledges that limitations are mentioned in Section 6, but it does not provide specific examples or detailed reasoning to support the claim about the potential concern. This makes the claim somewhat verifiable, as it highlights a potential issue but lacks comprehensive evidence or references to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically noting that the backbone is constrained to a double LSTM while popular transformers are not involved. It suggests that the application of this method to more extensive model structures remains a potential concern. The comment acknowledges that limitations are mentioned in Section 6, but it implies that these limitations are not sufficiently addressed. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this concern or expand their approach to include transformers. This limits the comment\\'s helpfulness, as it provides insight but not actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the contribution and novelty of the paper are limited, as it combines existing techniques and uses variational inference for parameter learning. However, it does not provide any explicit or implicit suggestions for how the authors might enhance the contribution or novelty of their work. There is no guidance on potential improvements, alternative approaches, or additional experiments that could be conducted to address the critique. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, specifically mentioning that the model combines existing techniques like structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for parameter learning. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on how these techniques are combined or what specific issues are raised. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution and novelty of the paper are limited, stating that the model combines existing techniques like structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for parameter learning. However, the comment does not provide specific examples or references to support this claim, nor does it elaborate on how these techniques are combined or what aspects of the paper are lacking in novelty. This lack of detailed justification makes the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the paper for having limited contribution and novelty, noting that the model proposed combines existing techniques like structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for parameter learning. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the contribution or novelty of their work. Without actionable feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting question about the efficiency of the MSLR approach, which requires tuning unimodal models before discarding them. It suggests comparing this approach to directly tuning a late-fusion model with separate learning rates for each modality, potentially with a similar or less compute budget. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the MSLR approach, which requires tuning unimodal models before discarding them. It suggests comparing this approach to directly tuning a late-fusion model with separate learning rates for each modality. However, the comment does not explicitly mention which section of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to compare the approaches and the potential benefits of doing so, providing clear guidance on what could be explored further. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the efficiency of the MSLR approach, suggesting that it requires tuning unimodal models before discarding them, which may be inefficient compared to directly tuning a late-fusion model. The comment provides a logical reasoning by highlighting the potential waste of resources in tuning unimodal models that are later discarded. However, it lacks specific examples or references to support the claim, such as data or studies comparing the efficiency of the two approaches. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an interesting point about the efficiency of the MSLR approach, which requires tuning unimodal models before discarding them. It suggests comparing this approach to directly tuning a late-fusion model with separate learning rates for each modality, potentially with a similar or less compute budget. This feedback is clear and actionable, as it provides a specific direction for the authors to explore in their work, potentially leading to more efficient and effective model tuning. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a valuable insight into improving the efficiency of the proposed method.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ambiguity in the notation for $L_{flow}(X)$, suggesting that $L_{flow}(F)$ or $L_{flow}(F,S)$ might be more appropriate to reflect the actual inputs. While the comment identifies a potential issue, it does not explicitly instruct the authors to make a specific change or provide guidance on how to resolve the ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ambiguity in the notation for $L_{flow}(X)$, suggesting that $L_{flow}(F)$ or $L_{flow}(F,S)$ might be more appropriate to reflect the actual inputs. However, it does not specify which part of the paper this notation appears in, making it weakly grounded. The comment is specific in identifying the issue with the notation and provides potential alternatives, which adds clarity to the feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ambiguity in the notation for $L_{flow}(X)$, suggesting that $L_{flow}(F)$ or $L_{flow}(F,S)$ might be more appropriate to reflect the actual inputs. However, the comment does not provide any supporting evidence or reasoning to justify why these alternatives would be more appropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, specifically the ambiguity in the notation for $L_{flow}(X)$. It suggests that $L_{flow}(F)$ or $L_{flow}(F,S)$ might be more appropriate to reflect the actual inputs. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and precision of the notation. By addressing this point, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it included additional context or examples of how the suggested notation would be applied. Overall, the comment is mostly helpful, as it effectively directs the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed before in the literature. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. The comment lacks actionable guidance, such as recommending ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of representing the input using 8 bits, referencing 8-bit batch norm proposed in literature. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the novelty of the work, as it references a specific paper that has already proposed 8-bit batch norm. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed in the literature. The reviewer supports this claim by referencing a specific paper, which provides a clear and explicit reference to external work that undermines the novelty of the current work. This reference allows the authors to understand the basis of the critique and consider how their work fits within the existing literature. Therefore, the claim is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed in the literature. This feedback highlights a potential issue with the originality of the work, which is crucial for the authors to address. However, the comment lacks specific guidance or suggestions on how the authors might enhance the novelty of their approach or differentiate it from existing work. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the practical relevance of their framework or suggestions for improvements. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this feedback to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the practical relevance of the proposed framework due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this concern pertains to, such as specific sections, experiments, or discussions. Without explicit references, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding how the framework could be improved to address this concern. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the practical relevance of the proposed framework, given the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While it identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the practicality of their framework. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an experiment should be conducted to demonstrate the necessity of $X$ by calculating $M_{t}$ using only $C$ without $X$. This feedback provides a clear and explicit action for the authors to take, which is to perform an additional experiment to address the question raised. The suggestion is concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an experiment to demonstrate the necessity of $X$ by calculating $M_{t}$ using only $C$ without $X$. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular experiment, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an experiment to demonstrate the necessity of $X$ by calculating $M_{t}$ using only $C$ without $X$. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this experiment is necessary or how it would impact the results. Without additional context or explanation, the claim is not verifiable, as it lacks the necessary justification to support the suggestion. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting an additional experiment to demonstrate the necessity of $X$ in the calculation of $M_{t}$. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental validation of the paper. By conducting this experiment, the authors can provide a more robust justification for the inclusion of $X$ in their methodology. However, the comment could be more helpful if it explained why this experiment is important or how it might impact the overall conclusions of the paper. Despite this, the feedback is mostly helpful as it offers a clear direction for improving the draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes an observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors\\' work or what changes, if any, should be made to address this issue. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment makes a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not specify which part of the paper this observation is based on, nor does it provide any guidance on how this information could be used to improve the paper. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing attention or improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment makes a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any specific feedback, suggestions, or guidance for the authors to improve their draft. Without actionable advice or a clear connection to the paper\\'s content, the comment does not assist the authors in enhancing their work. As a result, it is rated as not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests discussing the generalizability of the observations, particularly those in Figure 4. It highlights various hyperparameters that could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and learning stages. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to incorporate this discussion into the paper. The action is implicit and somewhat vague, as the authors need to infer the specific aspects to discuss and how to integrate them into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the generalizability of observations, particularly those in Figure 4, and mentions various hyperparameters that could influence implicit biases in the algorithm. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in detailing the hyperparameters that could affect neural representations, geometric metrics, and learning stages, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests discussing the generalizability of observations, particularly those in Figure 4, and highlights various hyperparameters that could influence implicit biases in the algorithm. While the comment provides a logical reasoning for the need to discuss generalizability, it lacks specific examples or references to substantiate the claim. The mention of hyperparameters is a relevant point, but without detailed evidence or examples, the claim remains somewhat verifiable. The authors would need to further explore and substantiate the impact of these hyperparameters on their own, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests discussing the generalizability of the observations, particularly those in Figure 4, by highlighting various hyperparameters that could influence implicit biases in the algorithm. It provides a clear and actionable suggestion for the authors to consider, which could help them improve the robustness and applicability of their findings. However, the comment could be more helpful if it offered specific examples or guidance on how to address these hyperparameters in the context of the paper. Overall, the feedback is mostly helpful as it identifies a critical area for improvement and provides a direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues: the paper\\'s lack of organization and the use of non-standard terminology. It provides an example of the non-standard terminology, \"semi-honst,\" and suggests using the more standard term \"honest-but-curious\" to describe the server. While the comment explicitly points out these issues, it does not provide detailed guidance on how to reorganize the paper or suggest specific changes to improve organization. The action is explicit but somewhat vague, as the authors know they need to address these issues but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and the term \"semi-honst,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of non-standard terminology and suggests using the term \"honest-but-curious\" instead of \"semi-honst\" to describe the server. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honst\" in section 4. The reviewer provides a suggestion to use the more standard term \"honest-but-curious\" to describe the server. This claim is somewhat verifiable as it identifies a specific issue with terminology and provides a suggestion for improvement. However, the comment lacks detailed reasoning or examples to fully substantiate why the paper\\'s organization is problematic or how the non-standard terminology impacts the paper\\'s clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two issues: the lack of organization in the paper and the use of non-standard terminology. It provides a specific example of the non-standard term \"semi-honst\" and suggests using the more standard term \"honest-but-curious\" to describe the server. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided additional suggestions on how to better organize the paper or offered more examples of non-standard terminology. Overall, the comment is mostly helpful as it provides specific guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of several experimental details, specifically mentioning the optimizer, initialization, and PPO-zero. While it identifies areas that need clarification, it does not provide explicit instructions on how to address these missing details. The authors can infer that they need to include this information, but the comment lacks concrete guidance on how to present it or what specific details to provide. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of experimental details, specifically mentioning the optimizer, initialization, and PPO-zero. However, it does not specify where these details are missing, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these details should be included, the comment lacks full grounding. It is specific about the missing details but does not provide enough context for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of factual statements requesting clarification on missing experimental details, such as the optimizer, initialization, and PPO-zero. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental details of the paper, specifically mentioning the absence of information about the optimizer, initialization, and PPO-zero. This feedback is clear and actionable, as it directs the authors to provide crucial details that are necessary for understanding and replicating the experiments. By addressing these missing details, the authors can significantly improve the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is important. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for a detailed comparison of the proposed method with existing works in terms of efficiency analysis, including total model parameter, FLOPs, and memory usage. It explicitly states that such a comparison is necessary, providing a clear action for the authors to take. However, while the action is explicit, it lacks concrete guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and its components, such as LaVIT and Eva-CLIP, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, a detailed comparison in terms of efficiency analysis (total model parameter, FLOPs, memory) with and without the detector/LaVIT. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method requires multiple additional components compared to existing works, specifically mentioning LaVIT and Eva-CLIP for image encoding and a detector for decoding. The reviewer suggests a detailed comparison in terms of efficiency analysis, including model parameters, FLOPs, and memory usage. While the comment identifies specific components and suggests a comparison, it lacks detailed examples or references to existing works that do not require these components. This makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the efficiency and complexity of the proposed method. It points out that the method requires multiple additional components, such as LaVIT and Eva-CLIP for image encoding, and a detector for decoding, which may not be necessary in other existing works. The comment suggests a detailed comparison in terms of efficiency analysis, including total model parameter, FLOPs, and memory usage, with and without these additional components. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their draft by addressing the efficiency and complexity of their method. However, it could be more helpful if it offered specific examples or methods for conducting the efficiency analysis. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims extrapolation error is a major issue in MARL but does not provide evidence to support this claim. It also notes that the proposed techniques are for bias/variance reduction, which may not directly address extrapolation error. The reviewer suggests that the authors need to provide evidence that their method mitigates extrapolation error for better performance. While the comment identifies a gap in the paper, it does not explicitly instruct the authors on how to address this issue or provide specific guidance on what evidence to include. The action is implicit and somewhat vague, as the authors know they need to provide evidence but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim about extrapolation error being a major issue in MARL and questions the evidence provided to support this claim. It also critiques the proposed techniques for bias/variance reduction, suggesting they may not directly address extrapolation error. However, the comment does not specify which part of the paper discusses these claims or techniques, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issues with the claims and techniques but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that extrapolation error is a major issue in MARL, noting that the authors do not provide evidence to support this assertion. It also critiques the proposed techniques for bias/variance reduction, suggesting they are not directly related to extrapolation error. The reviewer highlights the lack of evidence that the proposed method mitigates extrapolation error, which is crucial for better performance. While the comment identifies a gap in the paper, it does not provide specific examples or references to substantiate the claim about extrapolation error being a major issue. This makes the claim somewhat verifiable, as the authors would need to further develop the evidence themselves to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of evidence to support the claim that extrapolation error is a major issue in MARL. It also points out that the proposed techniques for bias/variance reduction may not directly address extrapolation error, which is crucial for better performance. This feedback is valuable as it highlights a critical gap in the paper that the authors need to address to strengthen their argument and claims. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate the impact of extrapolation error or how to better integrate the proposed techniques with the claim. Overall, the comment is somewhat helpful as it directs the authors to a key area needing improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME\\'s efficiency over conventional FFNs. It also specifies that details on benchmark configurations, hardware, and input shapes are necessary for fair comparisons. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what is expected in terms of additional analysis and reporting. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, namely the inclusion of detailed on-device results across ablation and comparison studies, as well as the necessity of providing details on benchmark configurations, hardware, and input shapes for fair comparisons. This level of detail provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SCHEME\\'s on-device efficiency is underexplored, despite theoretical complexity advantages. It supports this claim by pointing out that only limited throughput comparisons are presented in Tables 4 and 8. The reviewer suggests that including detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency. Additionally, the comment emphasizes the need for details on benchmark configurations, hardware, and input shapes for fair comparisons. This reasoning is mostly verifiable, as it provides a logical basis for the claim and suggests specific areas for improvement. However, it could be strengthened by providing examples or references to similar studies that successfully implemented such benchmarks. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the on-device efficiency of SCHEME, despite its theoretical complexity advantages. It points out that only limited throughput comparisons are presented in Tables 4 and 8, suggesting that detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, the comment emphasizes the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is clear and actionable, providing the authors with specific directions to enhance their draft by addressing the on-device efficiency aspect and providing necessary details for fair comparisons. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its similarity to Long Short Term Memory (LSTM), which could lead to confusion. However, it does not provide specific guidance on what alternative name might be more appropriate or how the authors should go about choosing a new name. The action is explicit in suggesting a change, but it lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its similarity to Long Short Term Memory (LSTM), which could lead to confusion. However, it does not specify which part of the paper this suggestion pertains to, such as the section where the strategy is introduced or discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential issue with the name but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its similarity to Long Short Term Memory (LSTM), which could lead to confusion. The comment provides a logical reasoning by pointing out the potential for misguidance due to the name's similarity to LSTM. However, it lacks specific examples or references to support the claim that the name is problematic. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore the potential issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its similarity to Long Short Term Memory (LSTM), which could lead to confusion. This feedback is somewhat helpful as it identifies a potential issue with the naming of the strategy and suggests a possible source of confusion. However, the comment lacks specific guidance on how to choose a more appropriate name or how to address the potential confusion. While it provides some insight into a potential weakness, it does not offer detailed, actionable suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the proposed method is not the best performer in terms of both robustness and fidelity, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue, such as suggesting ways to improve robustness or fidelity, or recommending additional experiments or analyses. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the experiments show the proposed method is not the best performer in terms of both robustness and fidelity. However, it does not specify which experiments or results are being referred to, making it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of robustness and fidelity are lacking or how they could be improved. Without explicit references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in terms of both robustness and fidelity. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the proposed method is not the best performer in terms of both robustness and fidelity, as indicated by the experimental results. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without further elaboration or guidance on how the authors might address this issue or enhance their method, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the paper regarding the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It explicitly suggests that the authors should clarify how disentanglement connects to isometry and why OT is required for isometry. The reviewer provides a clear direction for improvement by asking the authors to explain these connections more clearly. The feedback is explicit and provides concrete guidance on what the authors need to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It highlights the lack of clarity in explaining how disentanglement connects to isometry and why OT is required for isometry. This provides specific guidance on what needs to be clarified in the paper. However, the comment does not explicitly mention which sections or parts of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the introduction or motivation sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation and logical connection between the concepts of isometry, OT, and disentanglement are not clear. The reviewer provides a specific critique by pointing out that the connection between disentanglement and isometry is not well-explained, and questions the necessity of OT for isometry. While the comment identifies areas of confusion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the critique, making the comment somewhat verifiable. Therefore, the feedback is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the paper\\'s motivation and logical connection between the concepts of isometry, OT, and disentanglement. It points out that the connection between disentanglement and isometry is not well-explained, and questions the necessity of OT for isometry. The comment provides a clear direction for improvement by suggesting that the authors should clarify these connections more thoroughly. This feedback is actionable and offers specific guidance on how to enhance the paper\\'s clarity and coherence, making it mostly helpful. However, it could be more comprehensive by suggesting ways to structure the explanation or providing examples of how to clarify the connections. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the significance of the results on regular languages but questions their relevance to understanding real-world language models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their draft to better explain the connection between regular languages and real-world language models. As a result, the comment lacks actionability, leaving the authors without direction on how to proceed. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the results on regular languages as great but questions their relevance to understanding real-world language models. However, it does not specify which part of the paper discusses these results or how they are presented, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are considered great or how they could be more relevant to real-world language models. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the results on regular languages as great but questions their relevance to understanding real-world language models. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results might not be relevant or how they could be improved. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the significance of the results on regular languages but questions their relevance to understanding real-world language models. While it raises a valid point about the applicability of the results, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left with a general observation but without clear guidance on how to address the concern or enhance the relevance of their findings. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty of the paper compared to the Venom paper, specifically questioning whether the V:N:M proposal was not already introduced in the Venom paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what specific changes, if any, are needed to clarify the differences between the two papers. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper compared to the Venom paper, specifically questioning whether the V:N:M proposal was not already introduced in the Venom paper. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion where the V:N:M proposal is introduced. The authors might infer that it relates to the novelty or related work sections, but this inference is not direct. The comment is specific in its inquiry about the differences between the papers but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the novelty of the paper compared to the Venom paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper compared to the Venom paper, specifically questioning whether the V:N:M proposal was not already introduced in the Venom paper. While it identifies a potential area of concern regarding the originality of the work, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment does not offer actionable steps for the authors to clarify or differentiate their work from the Venom paper. As a result, the feedback is somewhat helpful, as it prompts the authors to consider the novelty of their work but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of qualitative intuition regarding the attribution maps, specifically noting that the attended areas of the image do not seem related to the task and that there are clusters of attended pixels without clear semantic meaning. However, the reviewer acknowledges that the resulting analysis using the attribution maps seems to work quantitatively. The comment does not provide explicit guidance on how to address the issue of qualitative value or suggest specific actions to improve the clarity or relevance of the attribution maps. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance the qualitative aspect of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2\" and \"sec 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the attribution maps, noting that the attended areas do not seem related to the task and that there are clusters of attended pixels without clear semantic meaning. The comment further acknowledges that the resulting analysis using the attribution maps seems to work quantitatively, but questions the qualitative value. This provides clear guidance on what needs to be addressed regarding the qualitative aspect of the attribution maps. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the qualitative value of the attribution maps, noting that the attended areas do not seem related to the task and that there are clusters of attended pixels without clear semantic meaning. However, the reviewer acknowledges that the resulting analysis using the attribution maps seems to work quantitatively. The comment provides some reasoning by pointing out the lack of qualitative intuition, but it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the qualitative value of the attribution maps, noting that the attended areas of the image do not seem related to the task and that there are clusters of attended pixels without clear semantic meaning. However, the reviewer acknowledges that the resulting analysis using the attribution maps seems to work quantitatively. This feedback highlights a potential issue with the interpretation of the attribution maps and suggests that the authors should address the lack of qualitative value. While the comment identifies a weakness, it does not provide specific suggestions or guidance on how to improve the qualitative aspect of the attribution maps. This limits the comment\\'s helpfulness, making it somewhat helpful as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the title overclaiming the paper\\'s contribution, specifically noting that the results are shown only on two language models, BERT and RoBERTa, and not on large language models (LLMs) like Llama2-70b. The reviewer explicitly asks for empirical justification if the proposed method can be scalable to LLMs. This provides a clear and direct action for the authors to take, which is to demonstrate the scalability of their method to LLMs. Additionally, the comment provides a minor correction regarding the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. This feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title and specific sections (Section 3.3 and the Introduction) where the term \"ROBERTA\" is used, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the title overclaiming the contribution and the need for empirical justification of the proposed method\\'s scalability to large language models (LLMs) like Llama2-70b. Additionally, it provides a minor comment on the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title overclaims the contribution of the paper, as it focuses on results from only two language models, BERT and RoBERTa, and does not include results from large language models (LLMs) like Llama2-70b. The reviewer questions the scalability of the proposed method to LLMs and requests empirical justification if it can be applied to them. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s scope and suggests a specific area for improvement. However, it lacks detailed examples or references to support the claim that the title overclaims the contribution, making it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a potential issue with the title overclaiming the paper\\'s contribution. It points out that the results are shown only on two language models, BERT and RoBERTa, and suggests that the paper should demonstrate its scalability to large language models (LLMs) like Llama2-70b. This feedback is actionable as it prompts the authors to provide empirical justification for the scalability of their method to LLMs, which could significantly enhance the paper\\'s credibility and relevance. Additionally, the comment provides a minor correction regarding the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction, which is a straightforward improvement. Overall, the comment offers valuable insights and actionable suggestions for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of motivation for choosing date and country as possible spurious correlating variables with gender, noting that the paper only speculates about their potential for showing spurious correlations. However, it does not provide any explicit guidance or suggestions on how the authors could address this issue or improve their justification. The comment lacks actionable details, such as recommending specific ways to provide a stronger rationale or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the motivation for choosing date and country as possible spurious correlating variables with gender. It highlights a lack of justification beyond speculation, which is a clear and specific critique. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for choosing date and country as possible spurious correlating variables with gender, noting that the justification is limited to speculation. However, the comment does not provide any specific reasoning or evidence to support this claim, such as alternative motivations or examples of better practices. This lack of detailed justification makes the claim difficult for the authors to address effectively, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it lacks motivation for choosing date and country as possible spurious correlating variables with gender. It points out that the justification is limited to speculation, which is a valid concern. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their justification. Without actionable feedback or specific advice, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is barely helpful, as it highlights a problem but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the contribution related to exchanging channels, noting that this is only achieved using Batch Normalization (BN). It also suggests that Theorem 1 is based on existing work and may be considered a simple fact. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their draft. It lacks actionable details, such as recommending ways to enhance the originality or providing specific feedback on how to strengthen the theoretical foundation. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific point about exchanging channels and the use of Batch Normalization (BN) in the paper. It questions the novelty of the contribution and suggests that Theorem 1 is based on existing work. However, it does not specify which section or part of the paper discusses these topics, making it weakly grounded. The comment is specific in its critique of the contribution and the reliance on existing work, but without clear references to specific sections, the authors may struggle to identify where these issues are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the contribution related to exchanging channels, suggesting that it is only achieved using Batch Normalization (BN). The reviewer also claims that Theorem 1 is based on existing work and may be considered a simple fact. However, the comment lacks specific references or detailed reasoning to support these claims. Without explicit examples or citations, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the contribution related to exchanging channels, noting that this is only achieved using Batch Normalization (BN). It questions whether this contribution is truly incremental and suggests that Theorem 1 is based on existing work, possibly making it a simple fact. While the comment identifies a potential issue with the originality of the contribution, it lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The feedback is somewhat helpful as it prompts the authors to reconsider the originality of their contribution, but it could be more beneficial with additional direction or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that if the method is meant to be a main contribution and practical, more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is an implicit suggestion that the authors should conduct additional studies to validate their contribution. However, it lacks concrete guidance on how to conduct these studies or what specific aspects should be explored. The second part is a clarification question about the notation \"K\" in Section 4.1, which is explicit and actionable. Overall, the comment provides some actionable feedback but lacks detailed guidance on the first part, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions \"4.1,\" allowing the authors to identify the section where the notation \"K\" appears. However, it does not specify which part of the paper discusses the main contribution or the need for more in-depth studies, making it weakly grounded. The comment is specific in its request for clarification about the notation \"K\" and whether it equals \"NC.\" Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two parts. The first part suggests that if the method is meant to be a main contribution and practical, more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s contribution but lacks specific examples or references to support the need for more in-depth studies. The second part is a clarification question about the notation \"K,\" which is factual and does not require verification. Therefore, the overall comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment addresses two distinct points. First, it questions the main contribution of the paper, suggesting that more in-depth studies are needed to establish whether the proposed method improves damping in second-order methods. This feedback highlights a potential gap in the paper\\'s claims and encourages the authors to provide stronger evidence for their contribution. However, the comment lacks specific guidance on how to conduct these studies or what aspects should be focused on. Second, it raises a minor point about the notation \"K,\" asking for clarification on its exact meaning. This part of the comment is more actionable, as it directly prompts the authors to clarify their notation. Overall, the comment provides some helpful insights but could be more comprehensive and detailed in its suggestions for improvement. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also implies that analyzing the running time or complexity, particularly the impact of k and N on the running time, would be beneficial. While the comment provides a clear direction for additional analysis, it does not specify how to conduct this analysis or what specific aspects to focus on. The minor comment about a potential mismatch between Figure 2 and its description is actionable but lacks detailed guidance. Overall, the review point provides some actionable feedback but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and the description \"the dimensionality reduction is only performed on $s_{k\u22121,t\u22121}$,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as conducting an in-depth analysis of the parameters k and N in the ablation study and analyzing the running time or complexity. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also proposes analyzing the running time or complexity, particularly the impact of k and N on the running time. The comment provides a logical reasoning for why these analyses would be beneficial, but it lacks specific examples or references to support the claim. While the suggestion is reasonable, the absence of detailed justification or evidence makes the claim somewhat verifiable. The authors would need to further develop the rationale themselves to fully understand and address the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of actionable feedback and a minor comment. It suggests an in-depth analysis of the parameters k and N in the ablation study, which would enhance readers\\' understanding of the algorithm. This is a clear and specific suggestion that can guide the authors in improving their draft. Additionally, the comment proposes analyzing the running time or complexity, particularly the impact of k and N on the running time, which is another actionable point. The minor comment about a potential mismatch between Figure 2 and its description is also helpful in ensuring accuracy and clarity. Overall, the comment is mostly helpful as it offers detailed and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the details provided in Appendix B regarding the averaging of results over 10 runs. It specifically asks why there is no indication of standard deviation and whether these 10 runs were done over random hyper-parameter configurations for all baselines or with the best selected hyperparameter values. While the comment implies that the authors should provide additional information or clarification, it does not explicitly instruct them to do so. The action is implicit but concrete, as it clearly identifies what information is missing and why it is important. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the details provided, such as the absence of standard deviation and the nature of the 10 runs (random hyper-parameter configurations or best selected values). This provides clear guidance on what needs to be clarified or addressed in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of standard deviation information in Appendix B and seeks clarification on the nature of the 10 runs. It does not make any subjective claims or judgments but rather requests additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the lack of standard deviation information in Appendix B, which is crucial for understanding the variability and reliability of the results. It also inquires about the nature of the 10 runs, whether they were conducted over random hyper-parameter configurations or with the best selected values. This feedback is clear and actionable, as it prompts the authors to provide additional details that could significantly enhance the transparency and robustness of their experimental results. However, the comment could be more helpful if it suggested how to present this information or why it is important. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more details about the task generation process in the main text rather than just in the appendix section. This direct suggestion provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details about the task generation process should be included in the main text rather than just in the appendix section. While it does not explicitly mention a specific section, the authors can infer that it relates to the sections discussing the experimental setup or methodology. The comment is specific in its request for more details about the task generation process, which would enhance the paper\\'s presentation. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text rather than just in the appendix section. This claim is based on the premise that including more details would enhance the reader\\'s understanding of the experimental setup and strengthen the paper\\'s presentation. However, the comment does not provide specific examples or reasoning to support why this change would be beneficial or necessary. Without detailed justification or examples, the claim is somewhat verifiable, as it lacks the depth needed to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that more details about the task generation process be included in the main text rather than just in the appendix section. This feedback is specific and constructive, as it directly addresses a potential area for enhancement that could strengthen the paper\\'s presentation and understanding for readers. By following this advice, the authors can significantly improve the clarity and comprehensiveness of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify that entropy depends on a datapoint, such as $H(p^a|x)$, to make formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$ more understandable. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be clarified in the paper. The suggestion is concrete, as it outlines a specific change that can be made to improve the clarity of the formulas. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Individual-level entropy and Group-level entropy\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification that entropy depends on a datapoint and the suggestion to use formulas like $H(p^a|x)$ to improve understanding. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the representation of entropy in the paper is unclear and recommends using a more explicit notation to clarify its dependence on a datapoint. The comment provides a specific suggestion for improvement, which is to use $H(p^a|x)$ instead of $H$ to make the formulas more understandable. This suggestion is based on logical reasoning and a clear explanation of what needs to be clarified, making the claim mostly verifiable. However, the comment could be strengthened by providing examples or references to similar practices in the literature, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors clarify the dependency of entropy on a datapoint, such as $H(p^a|x)$, to improve the understanding of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. This guidance is clear and directly addresses a potential source of confusion in the paper, helping the authors enhance the clarity and precision of their mathematical expressions. By offering a concrete suggestion for improvement, the comment is highly helpful, as it empowers the authors to make a specific change that can significantly improve the readability and comprehensibility of their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a brief description of the method but does not offer any explicit or implicit actions for the authors to take. It lacks guidance on whether this aspect of the method is a strength, a weakness, or needs further elaboration. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific aspect of the paper related to connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this description is based on, such as a particular section, figure, or table. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in describing the issue of connecting tokens but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a factual statement about the method, specifically mentioning the connection of tokens beyond local windows by forming new groups across previous local windows. It does not express an opinion, claim, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a brief description of the method, specifically mentioning the connection of tokens beyond local windows by forming new groups across previous local windows. However, it lacks any analysis, critique, or suggestions for improvement. Without additional context or guidance, the authors are left without actionable feedback on how to enhance their work. The comment does not identify any weaknesses or areas for improvement, making it unhelpful for the authors to address in their draft. Therefore, it aligns with a score of 1, as it is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the advantage of using a specific kind of distance metric in the proposed DD risk, compared to other metrics used in Distributionally Robust Optimization (DRO). It suggests that the authors provide a more comprehensive illustration to address this question. While the comment implies that the authors should include a more detailed explanation, it does not explicitly instruct them to do so. The action is clear but communicated indirectly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"DD risk\" and its relationship with \"Distributionally Robust Optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the advantage of using a specific kind of distance metric and suggests that the authors provide a more comprehensive illustration. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the advantage of using a specific kind of distance metric in the proposed DD risk, compared to other metrics used in Distributionally Robust Optimization (DRO). It references works using different distance metrics, such as $f$-divergence, Wasserstein distance, and MMD distance, and suggests that there are studies on deriving risk bounds for these metrics. The comment implies that the authors should provide a more comprehensive illustration of the advantages of their chosen metric. While the comment provides some context by referencing existing literature, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement by questioning the advantage of using a particular distance metric in the proposed DD risk compared to other metrics used in Distributionally Robust Optimization (DRO). It suggests that the authors provide a more comprehensive illustration to address this question, which could help clarify the rationale behind their choice of metric. This feedback is actionable and provides a clear direction for the authors to enhance their draft by offering a more detailed explanation of their approach. However, the comment could be more helpful if it included specific suggestions or examples of how to present this illustration. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset with no human labels. It also asks whether it is possible to evaluate the dataset on annotated datasets like TACRED or FewRel. While the comment implies that the authors should consider evaluating their dataset on annotated datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset with no human labels. It also asks whether it is possible to evaluate the dataset on annotated datasets like TACRED or FewRel. However, the comment does not specify which part of the paper discusses the T-REx dataset, making it weakly grounded. The comment is specific in its inquiry about the nature of the dataset and potential evaluation on other datasets, but without clear grounding, it is challenging for the authors to pinpoint where this feedback applies. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the nature of the T-REx dataset and whether it is possible to evaluate it on annotated datasets like TACRED or FewRel. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset with no human labels. It also asks whether it is possible to evaluate the dataset on annotated datasets like TACRED or FewRel. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their dataset and potentially explore alternative evaluation methods. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. It could be more helpful if it offered insights into the potential benefits or drawbacks of using annotated datasets for evaluation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests that the appendix should be proofread to ensure it adheres to the NeurIPS 2021 style files and highlights specific spelling errors (\"poster mean,\" \"peicewise-linear,\" and \"sugggest\") that need correction. Additionally, it recommends expanding on the discussion of potential negative societal impacts in the limitations and societal impacts section. Each of these points is clear and concrete, giving the authors specific guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix and provides specific examples of issues within it, such as the use of \"poster mean\" and \"peicewise-linear\" on page 6 and the spelling error \"sugggest\" on page 9. It also specifies the need for a proofread to ensure adherence to NeurIPS 2021 style files. Additionally, it suggests expanding on the discussion of potential negative societal impacts in the limitations and societal impacts section. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims: the appendix does not use NeurIPS 2021 style files, there are spelling errors (\"poster mean,\" \"peicewise-linear,\" and \"sugggest\"), and the discussion of societal impacts could be expanded. While the comment identifies specific issues, such as the need for a proofread and the potential for expanding on societal impacts, it lacks detailed reasoning or examples to fully substantiate these claims. The mention of style files and spelling errors is factual, but the suggestion for expanding societal impacts is more subjective. Overall, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or references to fully substantiate the claims. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable pieces of feedback. It highlights the need for a proofread of the appendix to ensure it adheres to the NeurIPS 2021 style files, which is a clear and specific suggestion for improvement. Additionally, it points out specific spelling errors (\"poster mean,\" \"peicewise-linear,\" and \"sugggest\") that need correction, providing the authors with precise areas to address. Furthermore, it suggests expanding on the discussion of potential negative societal impacts in the limitations and societal impacts section, offering a direction for enhancing the paper\\'s depth and comprehensiveness. This feedback is clear, actionable, and constructive, making it highly helpful for the authors in improving their draft. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include training and validation curves for the different losses and inquire about the model\\'s ability to reduce all three losses simultaneously. It also asks if there are any tricks related to weighing these losses. While the comment provides a clear action for the authors to take\u2014adding specific plots and addressing specific questions\u2014it does not offer detailed guidance on how to implement these suggestions. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests looking at training and validation curves for different losses and asks questions about the model\\'s ability to reduce all three losses simultaneously and any tricks related to weighing these losses. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or figures where these curves could be included. The authors might infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in its request for additional analysis but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests looking at training and validation curves for different losses and asks questions about the model\\'s ability to reduce all three losses simultaneously and any tricks related to weighing these losses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these analyses would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the importance of these suggestions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an additional analysis by recommending the inclusion of training and validation curves for different losses. It also raises questions about the model\\'s ability to reduce all three losses simultaneously and any tricks related to weighing these losses. This feedback is somewhat helpful as it provides a clear direction for further exploration and analysis, which could enhance the understanding of the model\\'s performance. However, the comment lacks specific guidance on how to implement these suggestions or what to look for in the curves, which limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the paper\\'s claim of NP-hardness for computing the GOSPA metric, pointing out that the paper lacks a rigorous theoretical argument or proof. It highlights that the claim is not generally true for assignment problems and suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. The comment also notes that the paper assumes access to the optimal assignment matrix, which limits its applicability. While the comment identifies specific issues with the claim and its implications, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rigorous theoretical argument or proof to support their claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the claim about the NP-hardness of computing the GOSPA metric, referencing a specific statement in the paper. It provides detailed feedback on the lack of a rigorous theoretical argument or proof, and it critiques the claim by pointing out that it is not generally true for assignment problems. Additionally, it suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem, which is a specific and actionable suggestion for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim of NP-hardness for computing the GOSPA metric, noting that the paper lacks a rigorous theoretical argument or proof. It critiques the statement by pointing out that it is not generally true for assignment problems and suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. The comment also highlights a contradiction in the paper, where NP-hardness is claimed but the paper later assumes access to the optimal assignment matrix. This critique is supported by logical reasoning and a clear explanation of the issues with the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim about reducing GOSPA to an assignment problem. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper\\'s claim regarding the NP-hardness of computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof to support this claim and highlights that the statement is not generally true for assignment problems. The comment suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem, which is a valuable insight for the authors to consider. Additionally, it notes a contradiction in the paper, where NP-hardness is claimed but the paper later assumes access to the optimal assignment matrix, which limits its applicability. This feedback is clear, actionable, and provides the authors with specific areas to address and improve upon in their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. While the suggestion is explicit, it lacks concrete details on how to implement this writeup or what specific aspects should be included. The authors are given a clear action to take but without detailed guidance on how to execute it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an algorithmic writeup of the solution to the pricing problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the pricing problem is discussed. Without explicit references, the authors cannot confidently determine where to incorporate this feedback. Additionally, the comment lacks specificity regarding what aspects of the algorithmic writeup should be included or how it should be structured. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. However, it does not provide any justification or reasoning for why this addition would be helpful or necessary. The comment lacks supporting evidence or examples that would help the authors understand the importance of this suggestion. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to act upon.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. While it identifies a specific area for improvement, it lacks depth and does not provide detailed guidance or examples on how to implement this suggestion. The comment is somewhat helpful as it points out a potential enhancement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off requires intelligent exploration and gradual updates during initialization, but it does not provide specific guidance on how the authors should address this issue. The comment implies that the authors should clarify the relationship between model averaging and the proposed technique, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the numerical evaluation of model averaging and its role in balancing the trade-off between KL divergence and reward. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of unclear effectiveness and the need for clarification on how model averaging achieves the desired trade-off. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. The reviewer provides a logical reasoning by suggesting that achieving this trade-off requires intelligent exploration and gradual updates during initialization. However, the comment lacks specific examples or references to support the claim that model averaging is ineffective in this context. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore the rationale themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It highlights the need for clarification on how model averaging achieves this balance and suggests that it may require intelligent exploration and gradual updates during initialization. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their explanation. While it points out a potential weakness, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the possibility of generalizing with a different distribution for the size of the batches. While it implies an action, it does not provide specific guidance on how to implement this discussion or what aspects should be covered. The authors can infer that they need to add a section or discussion on this topic, but the comment lacks concrete details on how to proceed. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting a particular topic for discussion, but without clear grounding, the authors may struggle to determine where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the generalization with a different distribution for the size of the batches could be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the comment unverifiable. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should discuss the possibility of generalizing with a different distribution for the size of the batches. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to incorporate this discussion or why it is important. The feedback is somewhat helpful as it points out a potential enhancement, but it could be more beneficial with additional context or suggestions on how to address this issue. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the analysis, noting that it only considers the case of batch size = 1 and questions the impact of batch size on the effective initialization scale. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should investigate the effect of different batch sizes, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific limitation in the analysis, noting that it only considers the case of batch size = 1 and questions the impact of batch size on the effective initialization scale. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the analysis and what needs to be addressed, providing clear guidance on what aspect of the paper should be expanded or clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the analysis, noting that it only considers the case of batch size = 1 and questioning the impact of batch size on the effective initialization scale. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the study. Without additional context or explanation, the authors may find it challenging to understand the importance of this issue or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the analysis, noting that it only considers the case of batch size = 1 and questioning the impact of batch size on the effective initialization scale. This feedback highlights a specific area where the paper could be improved by exploring the effects of different batch sizes. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or what specific experiments or analyses could be conducted to investigate the impact of batch size. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. While the comment highlights an interesting observation, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit, as the authors can infer that they might need to investigate or clarify this observation, but it remains vague without concrete steps or suggestions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the observation that more data leads to lower results on the ImageNet linear evaluation, providing a specific example of sampling 50% of the data yielding better results than sampling 100% of the data. This provides clear guidance on what aspect of the figure needs further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the results shown in Figure 7. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the results presented in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. This feedback is somewhat helpful as it points out a potential inconsistency or unexpected result in the data analysis. However, it lacks depth and does not offer suggestions or guidance on how the authors might investigate or address this issue. To be more helpful, the comment could include additional context or suggestions for further analysis. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comprehensive evaluation in the paper, specifically noting the absence of quantitative results on mainstream metrics like FVD. It suggests that including FVD would enhance the paper\\'s credibility and comparability with other video generation methods. While the comment clearly identifies an area for improvement, it does not provide explicit instructions on how to incorporate FVD or other metrics into the evaluation. The action is implicit and somewhat vague, as the authors know they need to add more metrics but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of VBench as the primary evaluation benchmark and the absence of quantitative results on mainstream metrics like FVD. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of FVD to enhance the paper\\'s credibility and comparability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comprehensive evaluation, specifically noting the absence of quantitative results on mainstream metrics like FVD. The reviewer provides a logical reasoning by stating that FVD is widely recognized and robust for evaluating temporal video prediction, which would enhance the paper\\'s credibility and comparability. However, the comment could be strengthened by providing specific examples or references to studies where FVD has been effectively used, which would make the claim fully verifiable. As it stands, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the score is 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s evaluation by pointing out the absence of quantitative results on mainstream metrics like FVD, which is widely recognized and robust for evaluating temporal video prediction. It suggests that including FVD would enhance the paper\\'s credibility and comparability with other video generation methods. This feedback is clear and actionable, providing the authors with a specific metric to consider for improving their evaluation section. However, the comment could be more helpful if it offered additional guidance on how to incorporate FVD or other metrics into the evaluation framework. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical details in section 2.2 are hard to follow, but it does not provide any specific guidance or suggestions on how to improve the clarity or what aspects of the technical details are particularly challenging. Without explicit instructions or concrete examples, the authors are left without a clear understanding of what changes are needed to make the section more accessible. The lack of actionable details makes it difficult for the authors to address the issue effectively. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"2.2,\" which provides full grounding as it explicitly identifies the section of the paper being addressed. However, the comment lacks specificity because it does not detail what aspects of the technical details are hard to follow or how they could be improved. Without specific guidance, the authors may struggle to understand exactly what needs to be clarified or revised. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that \"the technical details are hard to follow\" in section 2.2. However, it does not provide any specific examples or reasoning to support this claim, nor does it suggest how the technical details could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the technical details in section 2.2 are difficult to follow, which is a relevant observation that could help the authors improve the clarity of their paper. However, the comment lacks specificity and does not provide any guidance or suggestions on how to address the issue. Without detailed feedback or actionable advice, the authors are left with a general idea of what needs improvement but without a clear path to do so. Therefore, the comment is barely helpful, as it identifies a problem but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the improvements offered by EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It also questions whether the design choices, such as adding geometry information and motif-interpolation, provide benefits over prior backbones. While the comment highlights areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these questions or improve their work. The authors are left to infer that they need to provide a clearer explanation of their contributions and their benefits over existing methods. However, the lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"empirical evaluation for motif-coupling on the RFDiffusion benchmark and an in-silico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the improvements offered by EVA over the backbone models, such as OT-Flow, and questions the design choices and their benefits over prior backbones. This provides clear guidance on what the authors need to address or clarify in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the improvements offered by EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It questions whether the design choices, such as adding geometry information and motif-interpolation, provide benefits over prior backbones. While the comment highlights areas of concern, it does not provide specific evidence or examples to support the claim that the backbone models are better. The lack of detailed reasoning or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it raises valid questions but lacks sufficient evidence or justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the improvements offered by EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It questions whether the design choices, such as adding geometry information and motif-interpolation, provide benefits over prior backbones. This feedback is valuable as it prompts the authors to clarify and justify their contributions, which is essential for the paper\\'s credibility and impact. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might demonstrate these improvements. Overall, the comment is somewhat helpful as it identifies a key area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections. However, it does not provide specific guidance on how to address this issue, such as suggesting ways to rephrase or rewrite these sentences to avoid repetition. The action is implicit, as the authors can infer that they need to revise the text, but it remains vague because it lacks concrete instructions on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the repetition of sentences in the Abstract, Introduction, and Conclusion sections. However, it does not specify which sentences are identical or provide details on how this repetition affects the paper\\'s quality. This lack of specificity makes it difficult for the authors to address the issue effectively. The comment is fully grounded as it clearly indicates the sections where the issue occurs, but it is under-specific because it does not provide detailed guidance on how to resolve the problem. Therefore, this comment aligns with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there are \"too much identical sentences in Abstract, Introduction and Conclusion.\" However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand which sentences are identical and why this is a concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the repetition of sentences in the Abstract, Introduction, and Conclusion sections. This is a relevant observation that could improve the clarity and coherence of the paper. However, the comment lacks depth and does not provide specific examples or suggestions on how to address the issue. Without detailed guidance, the authors may struggle to understand which sentences are problematic and how to revise them. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the reward function used in the ablation studies, specifically asking if it is sEH. While the question implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the question or what specific information should be included. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Reward Function\" and the \"ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the reward function used in the ablation studies, specifically whether it is \"sEH.\" This provides clear guidance on what information is missing or needs clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reward function used in the ablation studies. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. While this question highlights a potential gap in the paper that the authors should address, it does not provide any guidance or suggestions on how to improve the clarity or completeness of the information presented. The comment is somewhat helpful as it points out an area that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully understand what changes are needed. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison between the current work and previous studies, specifically regarding the use of self-generated code versus a placeholder. It suggests that using self-generated code may not be a fair comparison because it samples the model twice for each generation, whereas the original technique only generates the code once. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and vague, as it lacks concrete steps for the authors to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the comparison between the current work and previous studies, specifically regarding the use of self-generated code versus a placeholder. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the comparison, explaining the potential unfairness due to the sampling process. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code for comparison is not fair because it samples the model twice for each generation, whereas the original technique only generates the code once. This claim is somewhat verifiable as it provides a logical reasoning for the potential unfairness in the comparison. However, it lacks specific examples or references to support the assertion fully, such as detailed comparisons or studies that highlight the impact of this sampling method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the current work and previous studies, specifically regarding the use of self-generated code versus a placeholder. It explains that using self-generated code may not be a fair comparison because it samples the model twice for each generation, whereas the original technique only generates the code once. This feedback is somewhat helpful as it highlights a critical aspect of the methodology that could impact the validity of the comparison. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their comparison methodology. To be more helpful, the comment could include recommendations on how to ensure a fair comparison or suggest alternative approaches. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the brevity of Sections 3 and 4, which are supposed to be the main contributions of the paper. It specifically points out the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. While the comment identifies a specific issue that needs addressing, it does not provide explicit guidance on how to expand these sections or what additional information should be included. The action is implicit and somewhat vague, as the authors know they need to add more detail but may not be entirely sure of the exact content or format of the additions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Sections 3 and 4, which are supposed to be the main contributions of the paper, are squeezed into a single page. It specifically mentions the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. While the comment identifies a specific issue with the presentation of the main contributions, it lacks detailed reasoning or examples to fully substantiate the claim. The mention of Eq (4) provides some context, but without further elaboration or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that Sections 3 and 4, which are supposed to be the main contributions, are compressed into a single page. It specifically points out the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. This feedback is clear and actionable, as it directs the authors to expand these sections and provide the necessary mathematical definitions to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to expand these sections or what additional information should be included. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the results with respect to under-represented groups, specifically mentioning females and blacks. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should investigate this aspect, how they might address it, or what specific steps they should consider to ensure fairness. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the results with respect to under-represented groups, specifically mentioning females and blacks. However, it does not specify which part of the paper this question pertains to, such as specific sections, experiments, or results that should be considered. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its inquiry about fairness, it is not grounded because it does not direct the authors to a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the fairness of the results with respect to under-represented groups. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the fairness of the results with respect to under-represented groups, specifically mentioning females and blacks. This is a relevant concern that could impact the ethical implications of the study. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or investigate it further. While it highlights a potential area for improvement, it does not offer actionable advice or detailed insights, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests that the paragraph describing co-variance in Section 1 is too long and should be shortened to improve legibility. It also recommends adding more details to the generation of two types of long-tailed datasets, as the experiments on these datasets are crucial for affirming the paper\\'s contribution. Additionally, it suggests that the authors use more pages for the experiments on long-tailed datasets due to their importance. Each of these points is specific and provides clear guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1\" and the \"paragraph that describes Co-variance,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the paragraph\\'s length, which affects legibility. Additionally, it provides specific suggestions for improvement, such as adding more details to the generation of long-tailed datasets and using more pages for experiments on long-tailed datasets. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims: (a) the paragraph describing co-variance is too long, affecting legibility; (b) the paper lacks detailed illustrations for generating long-tailed datasets, which are crucial for affirming the paper\\'s contribution; and (c) the tables and figures are dense due to page limitations, suggesting more space for long-tailed dataset experiments. While the comment identifies specific issues, it lacks detailed reasoning or evidence to support these claims. For instance, it does not provide examples of how the paragraph could be shortened or how the illustrations could be improved. The suggestion about page density is also not substantiated with specific examples. Therefore, the claims are somewhat verifiable, as they provide a direction for improvement but lack comprehensive justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It identifies specific issues, such as the length of the paragraph describing co-variance in Section 1, which affects legibility, and suggests shortening it. It also points out that the paper only provides two illustrations for generating long-tailed datasets, which are crucial for affirming the paper\\'s contribution, and recommends adding more details. Additionally, it notes that the tables and figures are dense due to page limitations and suggests using more pages for the experiments on long-tailed datasets. These suggestions are clear and constructive, offering the authors specific ways to enhance the clarity and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes to make EC-Diffusers work on real-world data. While it highlights an area of interest, it does not provide explicit guidance or suggestions for the authors to address this issue. The question implies that the authors should consider making changes, but it lacks concrete details on what those changes might be or how to implement them. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what specific changes are being referred to. Without explicit references or detailed guidance, the authors cannot confidently determine which sections need attention or how to address the issue. As a result, the comment lacks both grounding and specificity, making it not grounded at all.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification on necessary changes to make EC-Diffusers work on real-world data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the necessary changes to make EC-Diffusers work on real-world data. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is barely helpful, as it points out a potential area of concern but does not assist the authors in making improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reliability of the evaluation and suggests that a human study might be needed to assess the efficacy of the evaluation protocol. However, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit, as the authors need to infer that they should consider conducting a human study to validate the evaluation protocol. Additionally, the comment lacks specificity on how to implement such a study or what aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the reliability of the evaluation and suggests that a human study might be needed to assess the efficacy of the evaluation protocol. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in its request for a human study to validate the evaluation protocol, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the reliability of the evaluation and whether a human study is needed to assess the efficacy of the evaluation protocol. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid concern about the reliability of the evaluation and suggests that a human study might be necessary to assess the efficacy of the evaluation protocol. This is a relevant point that could impact the credibility and validity of the findings presented in the paper. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to conduct such a study or what aspects of the evaluation protocol should be examined. While it identifies an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. However, it does not provide specific guidance on how the authors could address this concern or enhance the novelty of their work. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the novelty of the work, specifically comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not specify which part of the paper this comparison is based on, nor does it provide details on how the current work differs from the prior work in terms of novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the work is somewhat incremental compared to prior work. However, it does not provide specific details or examples from the prior work to substantiate this claim. Without explicit references or detailed comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or examples to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. However, it does not provide specific examples or detailed comparisons to substantiate this claim, nor does it offer suggestions on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or guidance, the comment does not significantly assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct an analysis on the performance of PromptMix, specifically focusing on the quality of questions and answers generated by the LLM. It implies that a high-quality model is essential for the success of the task and suggests analyzing which open-source LLMs would work with this approach or identifying a parameter count cutoff below which performance might degrade. While the comment provides a general direction for analysis, it lacks specific guidance on how to conduct the analysis or which parameters to focus on. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the performance of PromptMix in relation to the quality of questions and answers generated by the LLM. It provides a specific suggestion to consider which open-source LLMs would work with this approach or to identify a parameter count cutoff below which performance might degrade. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without clear grounding, the authors may struggle to determine where to incorporate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions and answers generated by the LLM, and it proposes an analysis to determine which open-source LLMs would work with this approach or identify a parameter count cutoff below which performance might degrade. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the dependency on LLM quality. This makes the claim somewhat verifiable, as it provides a direction for analysis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, specifically the dependency of PromptMix on the quality of questions and answers generated by the LLM. It suggests conducting an analysis to determine which open-source LLMs would work with this approach or identifying a parameter count cutoff below which performance might degrade. This feedback is clear and actionable, providing the authors with a specific direction for further exploration and analysis. By addressing this point, the authors could enhance the robustness and applicability of their work. However, the comment could be more helpful if it included examples of specific LLMs or parameter counts to consider, which would provide even more detailed guidance. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should comment on the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm and scales with N^5. It explicitly asks for information on the runtimes of simulations for large models in Section 6. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional information should be included in the paper. The suggestion is concrete, as it guides the authors on how to address the concern about the feasibility of the approach. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should comment on the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm, and asks for information on the runtimes of simulations for large models in Section 6. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm and scales with N^5. It suggests that the authors should comment on this aspect and provides a specific example by asking about the runtimes of simulations for large models in Section 6. While the comment raises a valid concern, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion to comment on feasibility is logical, but the absence of specific examples or references makes the claim somewhat verifiable. The authors would need to further explore the issue themselves to fully address it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the complexity of the submodularity approach subroutine, which uses the SATURATE algorithm and scales with N^5. It suggests that the authors should comment on the feasibility of this approach, particularly in the context of large models. The comment is actionable as it provides a clear direction for the authors to address the issue by discussing the runtimes of simulations for large models in Section 6. This feedback is valuable as it prompts the authors to consider the practical implications of their approach and provides a concrete area for improvement. However, the comment could be more helpful if it offered additional guidance or suggestions on how to address the feasibility concern. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanation of inference at test time is brief and could benefit from more details. However, it does not specify what additional details are needed or how the authors should expand on this explanation. The action is implicit and vague, as the authors are left to infer what specific details are lacking and how to address them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"594,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the explanation of inference at test time is brief and could benefit from more details. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of inference at test time is brief and could benefit from more details. However, it does not provide any specific examples or reasoning to support why additional details are necessary or how they would improve the explanation. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the comment unverifiable. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved by suggesting that the explanation of inference at test time is brief and could benefit from more details. This feedback is actionable as it points out a particular aspect of the paper that needs further elaboration, which can help the authors enhance the clarity and comprehensiveness of their work. However, the comment lacks depth and does not provide specific suggestions or examples on what additional details could be included, which would make it more helpful. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully guide the authors on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the correctness and soundness of the paper, specifically questioning the evaluation of programs generated by CodeChain and the effectiveness of sub-module generation. It also mentions a performance drop in the 5th iteration of self-revise prompting. However, the comment does not provide explicit or implicit actions for the authors to take to address these concerns. It lacks specific guidance on how to evaluate the programs, improve the sub-module generation, or investigate the performance drop. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses multiple points related to the correctness and soundness of the paper. It questions the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of self-revisions. However, it does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment does provide some specificity by mentioning the use of GPT-4 prompts and the performance drop in the 5th iteration, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the correctness and soundness of the paper, specifically questioning the evaluation of programs generated by CodeChain and the effectiveness of sub-module generation. It also mentions a performance drop in the 5th iteration of self-revise prompting. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the correctness and soundness of the paper, specifically questioning the evaluation of programs generated by CodeChain and the effectiveness of sub-module generation. It also mentions a performance drop in the 5th iteration of self-revise prompting, suggesting a limitation. However, the comment lacks specificity and actionable guidance on how the authors might address these concerns or improve their work. It does not provide detailed suggestions or examples of how to evaluate the programs or sub-module generation effectively. As a result, the feedback is somewhat helpful, as it identifies areas for improvement but does not offer comprehensive guidance for the authors to act upon.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding deferring classifiers and their impact on subgroup accuracy. It seeks clarification on whether the differences in error rates between subgroups are larger for the deferring classifier, which could imply less fairness. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should clarify their argument or provide additional analysis. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 306-307,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the argument made in those lines regarding deferring classifiers and their impact on subgroup accuracy. The comment seeks clarification on whether the differences in error rates between subgroups are larger for the deferring classifier, which could imply less fairness. This provides clear guidance on what aspect of the argument needs further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification on the authors\\' argument regarding deferring classifiers and their impact on subgroup accuracy. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the authors\\' argument regarding deferring classifiers and their impact on subgroup accuracy. It seeks clarification on whether the differences in error rates between subgroups are larger for the deferring classifier, which could imply less fairness. This feedback is valuable as it prompts the authors to reconsider and clarify their argument, potentially leading to a more robust and fair analysis. However, the comment does not provide specific suggestions or guidance on how to address this issue, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the claim about the relational embedding module improving object classification lacks supporting evidence, such as results. It suggests that the authors should report the improvement on object classification directly, in addition to the overall scene graph results. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to strengthen the paper. The comment is highly actionable as it gives the authors a direct and specific task to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of results to support the claim about the relational embedding module improving object classification. The comment suggests reporting the improvement on object classification directly, in addition to the overall scene graph results. This provides clear guidance on what needs to be added to strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made in the paper regarding the relational embedding module\\'s impact on object classification. It points out the lack of supporting evidence or results to substantiate this claim. The reviewer suggests that reporting the improvement on object classification directly, in addition to the overall scene graph results, would strengthen the paper. While the comment highlights a gap in the evidence provided, it does not offer specific examples or references to support the claim that the relational embedding module indeed improves object classification. This makes the claim somewhat verifiable, as it requires the authors to provide additional evidence to substantiate their claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module improving object classification lacks supporting evidence. It suggests that the authors should report the improvement on object classification directly, in addition to the overall scene graph results. This feedback is clear and actionable, providing the authors with a concrete step to enhance the credibility and robustness of their claims. By addressing this point, the authors can significantly improve the quality and persuasiveness of their paper. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the manuscript\\'s scope, noting that the idea is interesting but narrow, and that the novelty is limited compared to existing work. It references a specific paper, \"Hypergraph Attention Networks for Multimodal Learning,\" which has explored similar concepts. The comment implies that the authors should consider how their work compares to existing literature and potentially expand on the novelty of their contribution. However, the feedback does not provide explicit guidance on how to enhance the novelty or suggest specific areas for improvement. The action is implicit and somewhat vague, as the authors need to infer that they should address the scope and novelty of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment provides a critique of the manuscript\\'s scope and novelty, comparing it to a specific paper from CVPR 2020. It suggests that the novelty of the manuscript is limited, as it primarily adds self-supervised learning to an existing concept explored in the referenced paper. However, the comment does not specify which parts of the manuscript are being critiqued, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might infer that it relates to the introduction or discussion of the methodology, the lack of explicit grounding makes it challenging to address the feedback effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point critiques the manuscript for its narrow scope and limited novelty, suggesting that the only novel aspect is the addition of self-supervised learning to an existing concept explored in a CVPR 2020 paper. The reviewer supports this claim by referencing the CVPR 2020 paper, providing a specific external reference that highlights the existing work in the field. This reference helps substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the CVPR 2020 paper to fully demonstrate the overlap. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critique of the manuscript\\'s scope and novelty, noting that the idea is interesting but narrow, and that the novelty is limited compared to existing work. It references a specific paper from CVPR 2020 that has explored similar concepts, suggesting that the only novel aspect of the manuscript is the addition of self-supervised learning. While the comment identifies a potential weakness in the manuscript, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a limitation, but it could be more beneficial with specific advice or examples on how to improve the manuscript. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difficulty of finding intuitive attention examples as shown in Figure 4. While it highlights a potential area of interest, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, how it might be addressed, or what specific changes could be made to improve the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"figure 4,\" which provides some grounding as it allows the authors to identify the specific part of the paper being addressed. However, it does not specify what aspect of the figure is being questioned or how it could be improved, making it under-specific. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point is a question asking for clarification about the difficulty of finding intuitive attention examples as shown in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difficulty of finding intuitive attention examples as shown in Figure 4. While it identifies a potential area of interest, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. The comment does not clarify what aspects of the examples are unclear or how they could be improved, leaving the authors without clear guidance on how to enhance their draft. As a result, the comment is barely helpful, as it points out a potential issue but does not offer meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difference between 01 and 10 in Figure 1. While it highlights a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the difference in their figure, but the comment lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the difference between 01 and 10, which is a clear and precise request for additional information. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the difference between 01 and 10 in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the difference between 01 and 10 in Figure 1. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the figure. The comment is somewhat helpful as it points out a specific area that may need clarification, but it lacks depth and actionable advice, leaving the authors with only a vague direction for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to keep a separate \"Related Work\" section and suggests shifting the bullet points \"Traditional AES,\" \"Deep Neural AES,\" and \"Pre-training AES\" from the \"Introduction\" section to the \"Related Work\" section. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the organization of their paper. The comment is concrete, as it outlines the specific changes required, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section and the specific bullet points (\"Traditional AES,\" \"Deep Neural AES,\" and \"Pre-training AES\") that need to be shifted to the \"Related Work\" section. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the relocation of these bullet points to the Related Work section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests separating the \"Related Work\" section from the \"Introduction\" section, providing a specific example of where the related work is currently integrated. The comment is somewhat verifiable as it logically suggests a structural improvement to better organize the paper. However, it lacks detailed reasoning or references to support why this separation is necessary or beneficial, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting a structural improvement in the paper. It identifies the issue of the \"Related Work\" section being integrated into the \"Introduction\" section, which results in a mix of introductory content and related work. The comment explicitly recommends shifting the bullet points related to \"Traditional AES,\" \"Deep Neural AES,\" and \"Pre-training AES\" to the \"Related Work\" section, which would help organize the content more effectively. This guidance is specific and actionable, allowing the authors to make a straightforward improvement to the structure of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the paper could present the overall process and rationale for constructing the benchmark more clearly. While it identifies an area for improvement, it does not provide specific guidance on how to achieve this clarity or what aspects of the process and rationale should be emphasized. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rules and various data augmentation methods used in constructing the benchmark,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the overall process and rationale for construction could be presented more clearly. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could present the overall process and rationale for constructing the benchmark more clearly. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks explicit evidence or references to illustrate why the current presentation is insufficient or how it could be improved. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved, noting that the description of rules and data augmentation methods used in constructing the benchmark is detailed but lacks clarity in presenting the overall process and rationale. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s presentation and suggests an area for improvement. However, it does not provide specific guidance or examples on how to enhance the clarity of the overall process and rationale. To be more helpful, the comment could include suggestions on how to better organize or present this information. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several specific areas where the paper lacks content, particularly in the literature review regarding recent advances in active learning communities, especially in the family of Bayesian learning. It points out the omission of relevant works like Bayesian Coreset, which is directly related to the paper, and suggests discussing how the current setup is more advanced than related studies. The comment provides explicit actions for the authors to take, such as including a literature review and discussing the advancements in their setup. The guidance is clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of content in the paper, particularly in the literature review regarding recent advances in active learning communities, especially in the family of Bayesian learning. It provides specific examples, such as the omission of Bayesian Coreset, which is directly relevant to the work, and suggests discussing how the current setup is more advanced than related studies. This level of detail allows the authors to accurately identify the parts of the paper that need attention and provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks content, specifically in the literature review regarding recent advances in active learning communities, particularly in the family of Bayesian learning. It provides specific examples, such as the omission of Bayesian Coreset, which is directly relevant to the work, and suggests discussing how the current setup is more advanced than related studies. The comment is well-supported by logical reasoning and specific references to external works, making it fully verifiable. The authors can easily understand the basis of the critique and how to address it by including these references and discussions. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of a comprehensive literature review on recent advances in active learning communities, particularly in the family of Bayesian learning. It points out the omission of relevant works like Bayesian Coreset, which is directly related to the paper, and suggests discussing how the current setup is more advanced than related studies. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. By incorporating these suggestions, the authors can enhance the depth and relevance of their literature review, which is crucial for situating their work within the existing body of knowledge. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a significant amount of noise. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the figure. The authors are left to infer that they might need to simplify the plot or reduce the noise, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the \"one-to-many relationship\" in the plot makes it difficult to understand the trends and that the plots contain a significant amount of noise. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the trends and that the plots contain a significant amount of noise. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without further explanation or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that the \"one-to-many relationship\" makes it difficult to understand the presented trends and that the plots contain a significant amount of noise. This feedback is valuable as it highlights a potential barrier to understanding the results presented in the figure. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending ways to simplify the plot or reduce the noise. While it points out a clear area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues regarding the comparison of DFSSATTEN with existing algorithms like Performer and Reformer. It suggests that the speedup achieved by DFSSATTEN is primarily due to low-level optimization and hardware support, which may not be the case for other algorithms. The reviewer also questions whether DFSSATTEN supports training from scratch, which is a significant direction in light of the popularity of pretraining. While the comment highlights areas for consideration, it does not provide explicit actions or concrete suggestions for the authors to address these issues. The authors are left to infer that they should clarify the comparison with existing algorithms and consider the impact of training from scratch on DFSSATTEN. However, the lack of specific guidance on how to address these points makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"DFSSATTEN\" and the \"introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the comparison to existing algorithms like Performer and Reformer, questioning the fairness of the comparison due to the lack of deep optimization. Additionally, it raises a question about whether DFSSATTEN supports training from scratch, which is a significant direction in light of the popularity of pretraining. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the speedup achieved by DFSSATTEN being primarily due to low-level optimization and hardware support, rather than the algorithm itself. It contrasts this with existing algorithms like Performer and Reformer, which are not deeply optimized. The reviewer questions the fairness of comparing DFSSATTEN with these algorithms and suggests that DFSSATTEN should support training from scratch, which is a significant direction in light of the popularity of pretraining. The comment provides logical reasoning by highlighting the differences in optimization levels and the importance of training from scratch, but it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical analysis of the paper\\'s claims regarding the speedup achieved by DFSSATTEN. It highlights that the speedup is primarily due to low-level optimization and hardware support, which may not be the case for other algorithms like Performer and Reformer. The comment questions the fairness of comparing DFSSATTEN with these algorithms and suggests that the authors should consider the impact of training from scratch, which is a significant direction in light of the popularity of pretraining. Additionally, it raises a question about whether DFSSATTEN supports training from scratch, which is an important aspect that the paper does not address. This feedback is mostly helpful as it identifies key areas for improvement and provides a clear direction for the authors to enhance their draft. However, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to incorporate training from scratch into the analysis. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that VMI-SI-TI-DI-FDSM was evaluated on a black-box setting when their method was evaluated on a defended model. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this observation is a concern, if it needs addressing, or how the authors might improve their evaluation setup. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"VMI-SI-TI-DI-FDSM\" and the evaluation on a \"black-box setting\" when their method was evaluated on a \"defended model.\" However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment also lacks specificity as it does not provide details on what aspect of the evaluation is problematic or how it could be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point makes a factual statement about the evaluation of VMI-SI-TI-DI-FDSM on a black-box setting when their method was evaluated on a defended model. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual observation about the evaluation of VMI-SI-TI-DI-FDSM on a black-box setting when their method was evaluated on a defended model. However, it does not offer any analysis, critique, or suggestions for improvement. Without identifying specific weaknesses or providing actionable feedback, the comment does not assist the authors in enhancing their draft. As a result, it is rated as not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide specific guidance on how to achieve this improvement. The reviewer refers to the \"questions section\" for details, but without knowing what those questions are, the authors are left without a clear understanding of what needs to be addressed. The action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not specify which part of the paper this issue pertains to. Additionally, it refers to the \"questions section\" for details, which further complicates the identification of the specific issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method\\'s description could be improved. However, it does not provide any specific examples or detailed reasoning to support this claim. The reference to the \"questions section\" is vague and does not offer sufficient context or justification for the claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it lacks specificity and actionable guidance. It refers to the \"questions section\" for details, but without providing those details here, the authors are left without a clear understanding of what needs to be clarified or improved. This lack of specificity and actionable feedback makes the comment barely helpful, as it does not offer the authors a clear path for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should be pruned in other layers as well. It asks whether such observations were made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide concrete guidance on how to incorporate this consideration into their work. The action is implicit and somewhat vague, as the authors need to infer the need for additional analysis or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should be pruned in other layers as well. It asks whether such observations were made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the pruning strategy is discussed. The comment is specific in detailing what needs to be addressed regarding the independence of the pruning strategy and the potential correlations across layers. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the independence of the pruning strategy across different layers in the GNN, suggesting that if an edge is pruned in one layer, it should be pruned in other layers as well. The comment implies that the authors should consider this correlation in their empirical evaluations or provide an explanation for its absence. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting question about the independence of the pruning strategy across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should be pruned in other layers as well, and asks whether such observations were made in the empirical evaluations or if the authors can explain why such correlations are not considered. This feedback is somewhat helpful as it prompts the authors to consider a potential oversight in their methodology or analysis. However, it lacks specific suggestions or guidance on how the authors might address this issue or what kind of analysis could be conducted to explore these correlations. To be more helpful, the comment could include suggestions for experiments or analyses that could be performed to investigate this aspect further. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the experimental results, specifically questioning whether the conclusions would hold for other in-distribution datasets. The reviewer acknowledges that this might be customary but suggests that the authors consider their remarks as genuine questions rather than weaknesses. While the comment implies that the authors should address the generalizability issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental validation section, specifically mentioning the use of CIFAR-10/100 as in-distribution data. This provides full grounding as it clearly identifies the part of the paper being discussed. However, the comment lacks specificity regarding what needs to be addressed or improved. It raises a concern about the generalizability of the results to other in-distribution datasets but does not provide specific guidance or suggestions on how to address this issue. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the generalizability of the experimental results, specifically noting that the validation only considers CIFAR-10/100 as in-distribution data. The reviewer acknowledges that the results are strong in this case but expresses uncertainty about their applicability to other datasets. The comment suggests that the conclusions might need to be nuanced, but it does not provide specific examples or references to support this claim. While the comment raises a valid concern, it lacks detailed justification or evidence to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the experimental results, specifically noting that the validation only considers CIFAR-10/100 as in-distribution data. It questions whether the conclusions would hold for other datasets and suggests that some nuance might be needed. While the comment acknowledges that this might be customary, it still encourages the authors to consider the broader applicability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional datasets for validation or suggesting methods to assess generalizability. This limits the comment\\'s helpfulness, as it identifies a potential weakness but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into why they do not benefit from the method. This is an explicit suggestion, as it directly instructs the authors to include a specific analysis to address the issue. The comment is also concrete, as it specifies exactly what additional information should be provided to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that AlphaNets trained with alpha-divergence do not benefit from the method and suggests showing the gradient conflicts ratio to provide insights. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that AlphaNets trained with alpha-divergence do not benefit from the method and suggests showing the gradient conflicts ratio to provide insights. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not explain why the gradient conflicts ratio would be relevant or how it might provide insights. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 8, noting that AlphaNets trained with alpha-divergence do not appear to benefit from the method. It suggests that showing the gradient conflicts ratio could provide insights into this observation. This feedback is clear and actionable, as it directs the authors to include additional analysis that could help clarify the results and potentially improve the understanding of the method\\'s effectiveness. However, the comment could be more helpful if it provided further guidance on how to interpret or present the gradient conflicts ratio. Overall, the comment is mostly helpful, as it offers a concrete suggestion for improvement but could be expanded to be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the complexity of the explicit SDF supervision setup, specifically questioning the need for occlusion handling and view-awareness. The reviewer suggests that a simpler approach could be used, where a subset of the sparse point cloud is sampled and the loss is applied without occlusion reasoning. The comment implies that the authors should provide a good reason or conduct an ablation study to justify the current setup. While the feedback is explicit in suggesting a potential alternative approach, it lacks concrete guidance on how to implement this suggestion or what specific aspects of the current setup should be addressed. The authors are left with a clear direction but without detailed instructions on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L. 165, L. 173, and L. 177-178) and sections (Sec. 3.2), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the explicit SDF supervision setup, questioning the necessity of occlusion handling and view-awareness. The reviewer suggests an alternative approach and implies that a good reason or ablation study is missing. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of the explicit SDF supervision setup with occlusion handling and view-awareness, suggesting a simpler approach. The reviewer provides a logical reasoning by stating that a subset of the sparse point cloud could be sampled and the loss applied without occlusion reasoning, which seems more straightforward. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is sound, the absence of explicit evidence or references makes the claim somewhat verifiable, as the authors would need to further explore and justify the suggested alternative approach. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explicit SDF supervision setup, particularly the inclusion of occlusion handling and view-awareness. It questions the necessity of these elements and suggests an alternative approach that could be simpler and more straightforward. The reviewer also implies that a good reason or ablation study is missing to justify the current setup. This feedback is mostly helpful as it highlights a potential weakness in the paper and provides a direction for improvement by suggesting an alternative approach and the need for a justification or study. However, it could be more helpful if it offered specific suggestions on how to implement the alternative approach or what aspects of the current setup should be addressed. Overall, the comment provides valuable insights for the authors to consider, aligning with a score of 4.', 'helpfulness_label': '4'}"}
